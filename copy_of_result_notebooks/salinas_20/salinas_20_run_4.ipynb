{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:28.532132Z",
     "iopub.status.busy": "2025-05-09T02:03:28.532132Z",
     "iopub.status.idle": "2025-05-09T02:03:28.536136Z",
     "shell.execute_reply": "2025-05-09T02:03:28.536136Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:28.538537Z",
     "iopub.status.busy": "2025-05-09T02:03:28.538537Z",
     "iopub.status.idle": "2025-05-09T02:03:30.711256Z",
     "shell.execute_reply": "2025-05-09T02:03:30.711256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:30.714262Z",
     "iopub.status.busy": "2025-05-09T02:03:30.713262Z",
     "iopub.status.idle": "2025-05-09T02:03:34.379376Z",
     "shell.execute_reply": "2025-05-09T02:03:34.379376Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:34.382387Z",
     "iopub.status.busy": "2025-05-09T02:03:34.382387Z",
     "iopub.status.idle": "2025-05-09T02:03:34.403627Z",
     "shell.execute_reply": "2025-05-09T02:03:34.403627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:34.405636Z",
     "iopub.status.busy": "2025-05-09T02:03:34.405636Z",
     "iopub.status.idle": "2025-05-09T02:03:34.852033Z",
     "shell.execute_reply": "2025-05-09T02:03:34.852033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (512, 217)\n",
      "Hypercube shape: (512, 217, 204)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Salinas_gt.mat'\n",
    "data_files = 'Salinas_corrected.mat'\n",
    "label_files = 'salinas_gt'\n",
    "hypercube_files = 'salinas_corrected'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:34.855039Z",
     "iopub.status.busy": "2025-05-09T02:03:34.855039Z",
     "iopub.status.idle": "2025-05-09T02:03:34.861046Z",
     "shell.execute_reply": "2025-05-09T02:03:34.861046Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:34.863334Z",
     "iopub.status.busy": "2025-05-09T02:03:34.863334Z",
     "iopub.status.idle": "2025-05-09T02:03:39.044802Z",
     "shell.execute_reply": "2025-05-09T02:03:39.044802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 54129\n",
      "Extracted windows shape: (54129, 5, 5, 204)\n",
      "Corresponding labels shape: (54129,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:39.047816Z",
     "iopub.status.busy": "2025-05-09T02:03:39.047816Z",
     "iopub.status.idle": "2025-05-09T02:03:39.056988Z",
     "shell.execute_reply": "2025-05-09T02:03:39.056988Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:39.059008Z",
     "iopub.status.busy": "2025-05-09T02:03:39.059008Z",
     "iopub.status.idle": "2025-05-09T02:03:43.005781Z",
     "shell.execute_reply": "2025-05-09T02:03:43.005781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 2009 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 3726 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 1976 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 1394 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 2678 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 3959 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 3579 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 11271 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 6203 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 3278 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 20 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 1068 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 20 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 1927 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 20 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 916 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 20 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 1070 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 20 training samples and 5 validation samples for class '14'\n",
      "\n",
      "Class: 15: Found 7268 samples\n",
      "Shuffled class indices for class '15'\n",
      "Selected 20 training samples and 5 validation samples for class '15'\n",
      "\n",
      "Class: 16: Found 1807 samples\n",
      "Shuffled class indices for class '16'\n",
      "Selected 20 training samples and 5 validation samples for class '16'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t320 samples\n",
      "\tshape (320, 5, 5, 204) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t80 samples\n",
      "\tshape (80, 5, 5, 204) --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- Test set created with: \n",
      "\t53729 samples\n",
      "\tshape (53729, 5, 5, 204) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(320, 5, 5, 204)\n",
      "(80, 5, 5, 204)\n",
      "(53729, 5, 5, 204)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:43.008787Z",
     "iopub.status.busy": "2025-05-09T02:03:43.008787Z",
     "iopub.status.idle": "2025-05-09T02:03:43.012799Z",
     "shell.execute_reply": "2025-05-09T02:03:43.012799Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:43.015057Z",
     "iopub.status.busy": "2025-05-09T02:03:43.015057Z",
     "iopub.status.idle": "2025-05-09T02:03:43.540408Z",
     "shell.execute_reply": "2025-05-09T02:03:43.540408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 320\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20, 14: 20, 15: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:43.543411Z",
     "iopub.status.busy": "2025-05-09T02:03:43.543411Z",
     "iopub.status.idle": "2025-05-09T02:03:43.548321Z",
     "shell.execute_reply": "2025-05-09T02:03:43.548321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:43.551325Z",
     "iopub.status.busy": "2025-05-09T02:03:43.550326Z",
     "iopub.status.idle": "2025-05-09T02:03:43.903268Z",
     "shell.execute_reply": "2025-05-09T02:03:43.903268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (43303, 5, 5, 204)\n",
      "Validation data shape: (10826, 5, 5, 204)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:43.906274Z",
     "iopub.status.busy": "2025-05-09T02:03:43.906274Z",
     "iopub.status.idle": "2025-05-09T02:03:43.909825Z",
     "shell.execute_reply": "2025-05-09T02:03:43.909825Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:43.911831Z",
     "iopub.status.busy": "2025-05-09T02:03:43.911831Z",
     "iopub.status.idle": "2025-05-09T02:03:44.084147Z",
     "shell.execute_reply": "2025-05-09T02:03:44.083132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:44.086145Z",
     "iopub.status.busy": "2025-05-09T02:03:44.086145Z",
     "iopub.status.idle": "2025-05-09T02:03:44.090650Z",
     "shell.execute_reply": "2025-05-09T02:03:44.090145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:44.093655Z",
     "iopub.status.busy": "2025-05-09T02:03:44.092655Z",
     "iopub.status.idle": "2025-05-09T02:03:44.099068Z",
     "shell.execute_reply": "2025-05-09T02:03:44.099068Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:03:44.102071Z",
     "iopub.status.busy": "2025-05-09T02:03:44.102071Z",
     "iopub.status.idle": "2025-05-09T02:05:51.666798Z",
     "shell.execute_reply": "2025-05-09T02:05:51.666798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/677], Loss: 0.1534, PSNR: 7.3085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0871, PSNR: 9.7011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0447, PSNR: 12.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0246, PSNR: 15.2527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.0658, PSNR: 11.6915\n",
      "\t[Val]   Batch [1/170] Loss: 0.0210, PSNR: 15.8621\n",
      "\t[Val]   Batch [10/170] Loss: 0.0206, PSNR: 16.0452\n",
      "\t[Val]   Batch [20/170] Loss: 0.0207, PSNR: 15.9366\n",
      "\t[Val]   Batch [30/170] Loss: 0.0215, PSNR: 15.7211\n",
      "\t[Val]   Batch [40/170] Loss: 0.0216, PSNR: 15.7995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0204, PSNR: 16.0183\n",
      "\t[Val]   Batch [60/170] Loss: 0.0214, PSNR: 15.8793\n",
      "\t[Val]   Batch [70/170] Loss: 0.0210, PSNR: 15.9556\n",
      "\t[Val]   Batch [80/170] Loss: 0.0213, PSNR: 15.7893\n",
      "\t[Val]   Batch [90/170] Loss: 0.0207, PSNR: 16.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0207, PSNR: 15.9407\n",
      "\t[Val]   Batch [110/170] Loss: 0.0207, PSNR: 15.9394\n",
      "\t[Val]   Batch [120/170] Loss: 0.0195, PSNR: 14.2505\n",
      "\t[Val]   Batch [130/170] Loss: 0.0206, PSNR: 16.0235\n",
      "\t[Val]   Batch [140/170] Loss: 0.0202, PSNR: 16.0920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0216, PSNR: 15.8304\n",
      "\t[Val]   Batch [160/170] Loss: 0.0213, PSNR: 15.8633\n",
      "\t[Val]   Batch [170/170] Loss: 0.0220, PSNR: 15.1721\n",
      "Epoch [1/50] Validation Loss: 0.0210, PSNR: 15.8570\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/677], Loss: 0.0207, PSNR: 15.6864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0145, PSNR: 17.4845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0105, PSNR: 18.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0092, PSNR: 19.5266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.0127, PSNR: 18.1895\n",
      "\t[Val]   Batch [1/170] Loss: 0.0084, PSNR: 19.8643\n",
      "\t[Val]   Batch [10/170] Loss: 0.0079, PSNR: 20.1866\n",
      "\t[Val]   Batch [20/170] Loss: 0.0080, PSNR: 20.0576\n",
      "\t[Val]   Batch [30/170] Loss: 0.0087, PSNR: 19.6724\n",
      "\t[Val]   Batch [40/170] Loss: 0.0089, PSNR: 19.6668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0078, PSNR: 20.2010\n",
      "\t[Val]   Batch [60/170] Loss: 0.0087, PSNR: 19.8100\n",
      "\t[Val]   Batch [70/170] Loss: 0.0084, PSNR: 19.9137\n",
      "\t[Val]   Batch [80/170] Loss: 0.0085, PSNR: 19.7689\n",
      "\t[Val]   Batch [90/170] Loss: 0.0082, PSNR: 20.0537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0082, PSNR: 19.9683\n",
      "\t[Val]   Batch [110/170] Loss: 0.0081, PSNR: 20.0265\n",
      "\t[Val]   Batch [120/170] Loss: 0.0071, PSNR: 18.6565\n",
      "\t[Val]   Batch [130/170] Loss: 0.0082, PSNR: 20.0564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/170] Loss: 0.0076, PSNR: 20.3334\n",
      "\t[Val]   Batch [150/170] Loss: 0.0089, PSNR: 19.7080\n",
      "\t[Val]   Batch [160/170] Loss: 0.0086, PSNR: 19.8049\n",
      "\t[Val]   Batch [170/170] Loss: 0.0089, PSNR: 19.1169\n",
      "Epoch [2/50] Validation Loss: 0.0083, PSNR: 19.9000\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/677], Loss: 0.0077, PSNR: 20.2622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0073, PSNR: 20.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0063, PSNR: 21.1973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0046, PSNR: 22.4706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.0062, PSNR: 21.2455\n",
      "\t[Val]   Batch [1/170] Loss: 0.0044, PSNR: 22.6505\n",
      "\t[Val]   Batch [10/170] Loss: 0.0042, PSNR: 22.9002\n",
      "\t[Val]   Batch [20/170] Loss: 0.0043, PSNR: 22.8068\n",
      "\t[Val]   Batch [30/170] Loss: 0.0046, PSNR: 22.4040\n",
      "\t[Val]   Batch [40/170] Loss: 0.0047, PSNR: 22.4455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0042, PSNR: 22.8549\n",
      "\t[Val]   Batch [60/170] Loss: 0.0046, PSNR: 22.5627\n",
      "\t[Val]   Batch [70/170] Loss: 0.0044, PSNR: 22.7105\n",
      "\t[Val]   Batch [80/170] Loss: 0.0045, PSNR: 22.5570\n",
      "\t[Val]   Batch [90/170] Loss: 0.0044, PSNR: 22.7764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0044, PSNR: 22.6292\n",
      "\t[Val]   Batch [110/170] Loss: 0.0043, PSNR: 22.7517\n",
      "\t[Val]   Batch [120/170] Loss: 0.0039, PSNR: 21.2684\n",
      "\t[Val]   Batch [130/170] Loss: 0.0044, PSNR: 22.7364\n",
      "\t[Val]   Batch [140/170] Loss: 0.0040, PSNR: 23.0794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0047, PSNR: 22.4758\n",
      "\t[Val]   Batch [160/170] Loss: 0.0045, PSNR: 22.5934\n",
      "\t[Val]   Batch [170/170] Loss: 0.0046, PSNR: 21.9413\n",
      "Epoch [3/50] Validation Loss: 0.0044, PSNR: 22.6464\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/677], Loss: 0.0045, PSNR: 22.6150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0037, PSNR: 23.1877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0038, PSNR: 23.3302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0028, PSNR: 24.6594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.0035, PSNR: 23.6795\n",
      "\t[Val]   Batch [1/170] Loss: 0.0026, PSNR: 24.9393\n",
      "\t[Val]   Batch [10/170] Loss: 0.0025, PSNR: 25.1723\n",
      "\t[Val]   Batch [20/170] Loss: 0.0026, PSNR: 25.0391\n",
      "\t[Val]   Batch [30/170] Loss: 0.0028, PSNR: 24.5949\n",
      "\t[Val]   Batch [40/170] Loss: 0.0027, PSNR: 24.8238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0026, PSNR: 25.0291\n",
      "\t[Val]   Batch [60/170] Loss: 0.0027, PSNR: 24.8326\n",
      "\t[Val]   Batch [70/170] Loss: 0.0026, PSNR: 25.0662\n",
      "\t[Val]   Batch [80/170] Loss: 0.0026, PSNR: 24.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [90/170] Loss: 0.0026, PSNR: 25.0449\n",
      "\t[Val]   Batch [100/170] Loss: 0.0027, PSNR: 24.7822\n",
      "\t[Val]   Batch [110/170] Loss: 0.0025, PSNR: 25.0833\n",
      "\t[Val]   Batch [120/170] Loss: 0.0024, PSNR: 23.3169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [130/170] Loss: 0.0027, PSNR: 24.8732\n",
      "\t[Val]   Batch [140/170] Loss: 0.0024, PSNR: 25.3300\n",
      "\t[Val]   Batch [150/170] Loss: 0.0028, PSNR: 24.7749\n",
      "\t[Val]   Batch [160/170] Loss: 0.0027, PSNR: 24.9016\n",
      "\t[Val]   Batch [170/170] Loss: 0.0027, PSNR: 24.2105\n",
      "Epoch [4/50] Validation Loss: 0.0026, PSNR: 24.8956\n",
      "\n",
      "LOG: Epoch [5/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/677], Loss: 0.0027, PSNR: 24.8589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0024, PSNR: 25.2633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0022, PSNR: 25.8291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0021, PSNR: 25.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.0024, PSNR: 25.4004\n",
      "\t[Val]   Batch [1/170] Loss: 0.0018, PSNR: 26.4758\n",
      "\t[Val]   Batch [10/170] Loss: 0.0018, PSNR: 26.7300\n",
      "\t[Val]   Batch [20/170] Loss: 0.0018, PSNR: 26.5368\n",
      "\t[Val]   Batch [30/170] Loss: 0.0020, PSNR: 26.0340\n",
      "\t[Val]   Batch [40/170] Loss: 0.0019, PSNR: 26.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0018, PSNR: 26.5243\n",
      "\t[Val]   Batch [60/170] Loss: 0.0019, PSNR: 26.3287\n",
      "\t[Val]   Batch [70/170] Loss: 0.0018, PSNR: 26.6579\n",
      "\t[Val]   Batch [80/170] Loss: 0.0019, PSNR: 26.3951\n",
      "\t[Val]   Batch [90/170] Loss: 0.0018, PSNR: 26.5912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0019, PSNR: 26.2224\n",
      "\t[Val]   Batch [110/170] Loss: 0.0017, PSNR: 26.7196\n",
      "\t[Val]   Batch [120/170] Loss: 0.0017, PSNR: 24.7715\n",
      "\t[Val]   Batch [130/170] Loss: 0.0019, PSNR: 26.2867\n",
      "\t[Val]   Batch [140/170] Loss: 0.0017, PSNR: 26.8915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0020, PSNR: 26.2692\n",
      "\t[Val]   Batch [160/170] Loss: 0.0019, PSNR: 26.4329\n",
      "\t[Val]   Batch [170/170] Loss: 0.0019, PSNR: 25.7040\n",
      "Epoch [5/50] Validation Loss: 0.0019, PSNR: 26.4055\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/677], Loss: 0.0021, PSNR: 25.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0019, PSNR: 26.3829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0016, PSNR: 27.0563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0016, PSNR: 27.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.0018, PSNR: 26.6435\n",
      "\t[Val]   Batch [1/170] Loss: 0.0013, PSNR: 27.8127\n",
      "\t[Val]   Batch [10/170] Loss: 0.0013, PSNR: 28.0890\n",
      "\t[Val]   Batch [20/170] Loss: 0.0013, PSNR: 27.8357\n",
      "\t[Val]   Batch [30/170] Loss: 0.0015, PSNR: 27.2886\n",
      "\t[Val]   Batch [40/170] Loss: 0.0014, PSNR: 27.8256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0014, PSNR: 27.7890\n",
      "\t[Val]   Batch [60/170] Loss: 0.0014, PSNR: 27.6375\n",
      "\t[Val]   Batch [70/170] Loss: 0.0013, PSNR: 28.0504\n",
      "\t[Val]   Batch [80/170] Loss: 0.0014, PSNR: 27.7463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [90/170] Loss: 0.0013, PSNR: 27.9297\n",
      "\t[Val]   Batch [100/170] Loss: 0.0015, PSNR: 27.4559\n",
      "\t[Val]   Batch [110/170] Loss: 0.0012, PSNR: 28.1815\n",
      "\t[Val]   Batch [120/170] Loss: 0.0013, PSNR: 25.9794\n",
      "\t[Val]   Batch [130/170] Loss: 0.0015, PSNR: 27.5309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/170] Loss: 0.0012, PSNR: 28.2439\n",
      "\t[Val]   Batch [150/170] Loss: 0.0015, PSNR: 27.5618\n",
      "\t[Val]   Batch [160/170] Loss: 0.0014, PSNR: 27.7620\n",
      "\t[Val]   Batch [170/170] Loss: 0.0014, PSNR: 27.0928\n",
      "Epoch [6/50] Validation Loss: 0.0014, PSNR: 27.7219\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/677], Loss: 0.0015, PSNR: 27.3219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0015, PSNR: 26.9172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0014, PSNR: 27.8187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0013, PSNR: 27.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0014, PSNR: 27.6259\n",
      "\t[Val]   Batch [1/170] Loss: 0.0011, PSNR: 28.7261\n",
      "\t[Val]   Batch [10/170] Loss: 0.0010, PSNR: 28.9704\n",
      "\t[Val]   Batch [20/170] Loss: 0.0011, PSNR: 28.7083\n",
      "\t[Val]   Batch [30/170] Loss: 0.0012, PSNR: 28.1209\n",
      "\t[Val]   Batch [40/170] Loss: 0.0011, PSNR: 28.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0011, PSNR: 28.6357\n",
      "\t[Val]   Batch [60/170] Loss: 0.0012, PSNR: 28.5198\n",
      "\t[Val]   Batch [70/170] Loss: 0.0010, PSNR: 29.0278\n",
      "\t[Val]   Batch [80/170] Loss: 0.0011, PSNR: 28.6498\n",
      "\t[Val]   Batch [90/170] Loss: 0.0011, PSNR: 28.8886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0012, PSNR: 28.3127\n",
      "\t[Val]   Batch [110/170] Loss: 0.0010, PSNR: 29.1370\n",
      "\t[Val]   Batch [120/170] Loss: 0.0011, PSNR: 26.8427\n",
      "\t[Val]   Batch [130/170] Loss: 0.0012, PSNR: 28.3996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/170] Loss: 0.0010, PSNR: 29.1727\n",
      "\t[Val]   Batch [150/170] Loss: 0.0012, PSNR: 28.4147\n",
      "\t[Val]   Batch [160/170] Loss: 0.0011, PSNR: 28.6799\n",
      "\t[Val]   Batch [170/170] Loss: 0.0012, PSNR: 27.9517\n",
      "Epoch [7/50] Validation Loss: 0.0011, PSNR: 28.6059\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/677], Loss: 0.0012, PSNR: 28.2643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0012, PSNR: 28.1523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0011, PSNR: 28.5966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0011, PSNR: 28.8173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0012, PSNR: 28.4283\n",
      "\t[Val]   Batch [1/170] Loss: 0.0009, PSNR: 29.6942\n",
      "\t[Val]   Batch [10/170] Loss: 0.0008, PSNR: 29.9673\n",
      "\t[Val]   Batch [20/170] Loss: 0.0009, PSNR: 29.6556\n",
      "\t[Val]   Batch [30/170] Loss: 0.0010, PSNR: 29.0582\n",
      "\t[Val]   Batch [40/170] Loss: 0.0009, PSNR: 29.7578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0009, PSNR: 29.5327\n",
      "\t[Val]   Batch [60/170] Loss: 0.0009, PSNR: 29.4715\n",
      "\t[Val]   Batch [70/170] Loss: 0.0008, PSNR: 30.0127\n",
      "\t[Val]   Batch [80/170] Loss: 0.0009, PSNR: 29.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [90/170] Loss: 0.0009, PSNR: 29.8556\n",
      "\t[Val]   Batch [100/170] Loss: 0.0010, PSNR: 29.2386\n",
      "\t[Val]   Batch [110/170] Loss: 0.0008, PSNR: 30.1597\n",
      "\t[Val]   Batch [120/170] Loss: 0.0009, PSNR: 27.7110\n",
      "\t[Val]   Batch [130/170] Loss: 0.0010, PSNR: 29.3252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/170] Loss: 0.0008, PSNR: 30.1456\n",
      "\t[Val]   Batch [150/170] Loss: 0.0010, PSNR: 29.3597\n",
      "\t[Val]   Batch [160/170] Loss: 0.0009, PSNR: 29.6342\n",
      "\t[Val]   Batch [170/170] Loss: 0.0009, PSNR: 29.0030\n",
      "Epoch [8/50] Validation Loss: 0.0009, PSNR: 29.5600\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/677], Loss: 0.0011, PSNR: 28.6524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0011, PSNR: 28.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0010, PSNR: 29.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0010, PSNR: 29.0684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0010, PSNR: 29.1767\n",
      "\t[Val]   Batch [1/170] Loss: 0.0007, PSNR: 30.6474\n",
      "\t[Val]   Batch [10/170] Loss: 0.0007, PSNR: 30.8945\n",
      "\t[Val]   Batch [20/170] Loss: 0.0007, PSNR: 30.5606\n",
      "\t[Val]   Batch [30/170] Loss: 0.0008, PSNR: 29.9783\n",
      "\t[Val]   Batch [40/170] Loss: 0.0007, PSNR: 30.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0007, PSNR: 30.4007\n",
      "\t[Val]   Batch [60/170] Loss: 0.0008, PSNR: 30.4103\n",
      "\t[Val]   Batch [70/170] Loss: 0.0007, PSNR: 30.9681\n",
      "\t[Val]   Batch [80/170] Loss: 0.0007, PSNR: 30.6150\n",
      "\t[Val]   Batch [90/170] Loss: 0.0007, PSNR: 30.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0008, PSNR: 30.2013\n",
      "\t[Val]   Batch [110/170] Loss: 0.0006, PSNR: 31.1587\n",
      "\t[Val]   Batch [120/170] Loss: 0.0007, PSNR: 28.5822\n",
      "\t[Val]   Batch [130/170] Loss: 0.0008, PSNR: 30.2730\n",
      "\t[Val]   Batch [140/170] Loss: 0.0006, PSNR: 31.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0008, PSNR: 30.2935\n",
      "\t[Val]   Batch [160/170] Loss: 0.0007, PSNR: 30.5549\n",
      "\t[Val]   Batch [170/170] Loss: 0.0007, PSNR: 29.9792\n",
      "Epoch [9/50] Validation Loss: 0.0007, PSNR: 30.4916\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/677], Loss: 0.0010, PSNR: 29.1940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0008, PSNR: 30.3014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0007, PSNR: 30.7460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0008, PSNR: 30.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0009, PSNR: 29.7994\n",
      "\t[Val]   Batch [1/170] Loss: 0.0006, PSNR: 31.3819\n",
      "\t[Val]   Batch [10/170] Loss: 0.0006, PSNR: 31.6878\n",
      "\t[Val]   Batch [20/170] Loss: 0.0006, PSNR: 31.2869\n",
      "\t[Val]   Batch [30/170] Loss: 0.0007, PSNR: 30.7585\n",
      "\t[Val]   Batch [40/170] Loss: 0.0006, PSNR: 31.4658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0006, PSNR: 31.1188\n",
      "\t[Val]   Batch [60/170] Loss: 0.0006, PSNR: 31.1819\n",
      "\t[Val]   Batch [70/170] Loss: 0.0006, PSNR: 31.6804\n",
      "\t[Val]   Batch [80/170] Loss: 0.0006, PSNR: 31.3975\n",
      "\t[Val]   Batch [90/170] Loss: 0.0006, PSNR: 31.6597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0006, PSNR: 31.0080\n",
      "\t[Val]   Batch [110/170] Loss: 0.0005, PSNR: 31.9231\n",
      "\t[Val]   Batch [120/170] Loss: 0.0006, PSNR: 29.3330\n",
      "\t[Val]   Batch [130/170] Loss: 0.0006, PSNR: 31.0791\n",
      "\t[Val]   Batch [140/170] Loss: 0.0005, PSNR: 31.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0006, PSNR: 31.0838\n",
      "\t[Val]   Batch [160/170] Loss: 0.0006, PSNR: 31.2597\n",
      "\t[Val]   Batch [170/170] Loss: 0.0006, PSNR: 30.8398\n",
      "Epoch [10/50] Validation Loss: 0.0006, PSNR: 31.2508\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/677], Loss: 0.0008, PSNR: 29.9427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0007, PSNR: 30.3927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0006, PSNR: 31.1055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0007, PSNR: 31.0362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0007, PSNR: 30.3968\n",
      "\t[Val]   Batch [1/170] Loss: 0.0005, PSNR: 32.1830\n",
      "\t[Val]   Batch [10/170] Loss: 0.0005, PSNR: 32.4911\n",
      "\t[Val]   Batch [20/170] Loss: 0.0005, PSNR: 32.0202\n",
      "\t[Val]   Batch [30/170] Loss: 0.0006, PSNR: 31.5935\n",
      "\t[Val]   Batch [40/170] Loss: 0.0005, PSNR: 32.2635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0005, PSNR: 31.9129\n",
      "\t[Val]   Batch [60/170] Loss: 0.0005, PSNR: 31.9880\n",
      "\t[Val]   Batch [70/170] Loss: 0.0005, PSNR: 32.4123\n",
      "\t[Val]   Batch [80/170] Loss: 0.0005, PSNR: 32.2343\n",
      "\t[Val]   Batch [90/170] Loss: 0.0005, PSNR: 32.5151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0005, PSNR: 31.8267\n",
      "\t[Val]   Batch [110/170] Loss: 0.0004, PSNR: 32.7544\n",
      "\t[Val]   Batch [120/170] Loss: 0.0005, PSNR: 30.1003\n",
      "\t[Val]   Batch [130/170] Loss: 0.0005, PSNR: 31.8919\n",
      "\t[Val]   Batch [140/170] Loss: 0.0004, PSNR: 32.6739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0005, PSNR: 31.8783\n",
      "\t[Val]   Batch [160/170] Loss: 0.0005, PSNR: 31.9912\n",
      "\t[Val]   Batch [170/170] Loss: 0.0005, PSNR: 31.7524\n",
      "Epoch [11/50] Validation Loss: 0.0005, PSNR: 32.0448\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/677], Loss: 0.0007, PSNR: 30.7549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0006, PSNR: 31.2106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0006, PSNR: 31.2334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0006, PSNR: 30.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0007, PSNR: 30.8766\n",
      "\t[Val]   Batch [1/170] Loss: 0.0004, PSNR: 32.7314\n",
      "\t[Val]   Batch [10/170] Loss: 0.0004, PSNR: 33.0868\n",
      "\t[Val]   Batch [20/170] Loss: 0.0005, PSNR: 32.5495\n",
      "\t[Val]   Batch [30/170] Loss: 0.0005, PSNR: 32.2121\n",
      "\t[Val]   Batch [40/170] Loss: 0.0004, PSNR: 32.8345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0005, PSNR: 32.4442\n",
      "\t[Val]   Batch [60/170] Loss: 0.0005, PSNR: 32.6011\n",
      "\t[Val]   Batch [70/170] Loss: 0.0004, PSNR: 32.9406\n",
      "\t[Val]   Batch [80/170] Loss: 0.0004, PSNR: 32.8419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [90/170] Loss: 0.0004, PSNR: 33.1440\n",
      "\t[Val]   Batch [100/170] Loss: 0.0005, PSNR: 32.4879\n",
      "\t[Val]   Batch [110/170] Loss: 0.0004, PSNR: 33.2938\n",
      "\t[Val]   Batch [120/170] Loss: 0.0004, PSNR: 30.6986\n",
      "\t[Val]   Batch [130/170] Loss: 0.0005, PSNR: 32.5504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/170] Loss: 0.0004, PSNR: 33.2318\n",
      "\t[Val]   Batch [150/170] Loss: 0.0005, PSNR: 32.5227\n",
      "\t[Val]   Batch [160/170] Loss: 0.0005, PSNR: 32.5257\n",
      "\t[Val]   Batch [170/170] Loss: 0.0004, PSNR: 32.4276\n",
      "Epoch [12/50] Validation Loss: 0.0004, PSNR: 32.6286\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/677], Loss: 0.0007, PSNR: 30.6990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0006, PSNR: 31.5343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0006, PSNR: 31.0608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0005, PSNR: 31.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0006, PSNR: 31.3541\n",
      "\t[Val]   Batch [1/170] Loss: 0.0004, PSNR: 33.2143\n",
      "\t[Val]   Batch [10/170] Loss: 0.0004, PSNR: 33.6064\n",
      "\t[Val]   Batch [20/170] Loss: 0.0004, PSNR: 33.0267\n",
      "\t[Val]   Batch [30/170] Loss: 0.0004, PSNR: 32.7533\n",
      "\t[Val]   Batch [40/170] Loss: 0.0004, PSNR: 33.2937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0004, PSNR: 32.9098\n",
      "\t[Val]   Batch [60/170] Loss: 0.0004, PSNR: 33.1264\n",
      "\t[Val]   Batch [70/170] Loss: 0.0004, PSNR: 33.3935\n",
      "\t[Val]   Batch [80/170] Loss: 0.0004, PSNR: 33.3632\n",
      "\t[Val]   Batch [90/170] Loss: 0.0004, PSNR: 33.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0004, PSNR: 33.0837\n",
      "\t[Val]   Batch [110/170] Loss: 0.0003, PSNR: 33.7712\n",
      "\t[Val]   Batch [120/170] Loss: 0.0004, PSNR: 31.2545\n",
      "\t[Val]   Batch [130/170] Loss: 0.0004, PSNR: 33.1485\n",
      "\t[Val]   Batch [140/170] Loss: 0.0003, PSNR: 33.7421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0004, PSNR: 33.0759\n",
      "\t[Val]   Batch [160/170] Loss: 0.0004, PSNR: 32.9749\n",
      "\t[Val]   Batch [170/170] Loss: 0.0004, PSNR: 33.0777\n",
      "Epoch [13/50] Validation Loss: 0.0004, PSNR: 33.1426\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/677], Loss: 0.0005, PSNR: 32.0589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0006, PSNR: 31.2306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0006, PSNR: 31.1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0005, PSNR: 32.2665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0005, PSNR: 31.7583\n",
      "\t[Val]   Batch [1/170] Loss: 0.0004, PSNR: 33.6267\n",
      "\t[Val]   Batch [10/170] Loss: 0.0003, PSNR: 33.9544\n",
      "\t[Val]   Batch [20/170] Loss: 0.0004, PSNR: 33.3741\n",
      "\t[Val]   Batch [30/170] Loss: 0.0004, PSNR: 33.1895\n",
      "\t[Val]   Batch [40/170] Loss: 0.0004, PSNR: 33.6577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0004, PSNR: 33.2805\n",
      "\t[Val]   Batch [60/170] Loss: 0.0004, PSNR: 33.5175\n",
      "\t[Val]   Batch [70/170] Loss: 0.0004, PSNR: 33.7042\n",
      "\t[Val]   Batch [80/170] Loss: 0.0003, PSNR: 33.7591\n",
      "\t[Val]   Batch [90/170] Loss: 0.0003, PSNR: 34.1415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0004, PSNR: 33.5249\n",
      "\t[Val]   Batch [110/170] Loss: 0.0003, PSNR: 34.1423\n",
      "\t[Val]   Batch [120/170] Loss: 0.0004, PSNR: 31.6638\n",
      "\t[Val]   Batch [130/170] Loss: 0.0004, PSNR: 33.5975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/170] Loss: 0.0003, PSNR: 34.1112\n",
      "\t[Val]   Batch [150/170] Loss: 0.0004, PSNR: 33.4936\n",
      "\t[Val]   Batch [160/170] Loss: 0.0004, PSNR: 33.3114\n",
      "\t[Val]   Batch [170/170] Loss: 0.0003, PSNR: 33.5173\n",
      "Epoch [14/50] Validation Loss: 0.0004, PSNR: 33.5290\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/677], Loss: 0.0005, PSNR: 32.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0005, PSNR: 31.3843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0005, PSNR: 31.5159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0005, PSNR: 32.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0005, PSNR: 32.0738\n",
      "\t[Val]   Batch [1/170] Loss: 0.0003, PSNR: 34.3365\n",
      "\t[Val]   Batch [10/170] Loss: 0.0003, PSNR: 34.7185\n",
      "\t[Val]   Batch [20/170] Loss: 0.0003, PSNR: 34.0249\n",
      "\t[Val]   Batch [30/170] Loss: 0.0003, PSNR: 33.9437\n",
      "\t[Val]   Batch [40/170] Loss: 0.0003, PSNR: 34.4562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0003, PSNR: 33.8745\n",
      "\t[Val]   Batch [60/170] Loss: 0.0003, PSNR: 34.3034\n",
      "\t[Val]   Batch [70/170] Loss: 0.0003, PSNR: 34.4208\n",
      "\t[Val]   Batch [80/170] Loss: 0.0003, PSNR: 34.5819\n",
      "\t[Val]   Batch [90/170] Loss: 0.0003, PSNR: 34.9044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0003, PSNR: 34.2836\n",
      "\t[Val]   Batch [110/170] Loss: 0.0003, PSNR: 34.8923\n",
      "\t[Val]   Batch [120/170] Loss: 0.0003, PSNR: 32.2365\n",
      "\t[Val]   Batch [130/170] Loss: 0.0003, PSNR: 34.3440\n",
      "\t[Val]   Batch [140/170] Loss: 0.0003, PSNR: 34.8277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0003, PSNR: 34.3119\n",
      "\t[Val]   Batch [160/170] Loss: 0.0003, PSNR: 33.9800\n",
      "\t[Val]   Batch [170/170] Loss: 0.0003, PSNR: 34.3936\n",
      "Epoch [15/50] Validation Loss: 0.0003, PSNR: 34.2666\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/677], Loss: 0.0005, PSNR: 32.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0005, PSNR: 31.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0005, PSNR: 32.6173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0004, PSNR: 33.3753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0005, PSNR: 32.3764\n",
      "\t[Val]   Batch [1/170] Loss: 0.0003, PSNR: 34.6400\n",
      "\t[Val]   Batch [10/170] Loss: 0.0003, PSNR: 35.0001\n",
      "\t[Val]   Batch [20/170] Loss: 0.0003, PSNR: 34.2780\n",
      "\t[Val]   Batch [30/170] Loss: 0.0003, PSNR: 34.2631\n",
      "\t[Val]   Batch [40/170] Loss: 0.0003, PSNR: 34.6961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0003, PSNR: 34.1933\n",
      "\t[Val]   Batch [60/170] Loss: 0.0003, PSNR: 34.6263\n",
      "\t[Val]   Batch [70/170] Loss: 0.0003, PSNR: 34.6753\n",
      "\t[Val]   Batch [80/170] Loss: 0.0003, PSNR: 34.8631\n",
      "\t[Val]   Batch [90/170] Loss: 0.0002, PSNR: 35.2421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0003, PSNR: 34.6162\n",
      "\t[Val]   Batch [110/170] Loss: 0.0002, PSNR: 35.1695\n",
      "\t[Val]   Batch [120/170] Loss: 0.0003, PSNR: 32.5560\n",
      "\t[Val]   Batch [130/170] Loss: 0.0003, PSNR: 34.6879\n",
      "\t[Val]   Batch [140/170] Loss: 0.0003, PSNR: 35.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0003, PSNR: 34.6215\n",
      "\t[Val]   Batch [160/170] Loss: 0.0003, PSNR: 34.2656\n",
      "\t[Val]   Batch [170/170] Loss: 0.0002, PSNR: 34.6574\n",
      "Epoch [16/50] Validation Loss: 0.0003, PSNR: 34.5470\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/677], Loss: 0.0005, PSNR: 31.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0005, PSNR: 32.1625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0005, PSNR: 32.2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0004, PSNR: 33.3204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0004, PSNR: 32.6446\n",
      "\t[Val]   Batch [1/170] Loss: 0.0002, PSNR: 35.1132\n",
      "\t[Val]   Batch [10/170] Loss: 0.0002, PSNR: 35.4608\n",
      "\t[Val]   Batch [20/170] Loss: 0.0003, PSNR: 34.6731\n",
      "\t[Val]   Batch [30/170] Loss: 0.0003, PSNR: 34.7841\n",
      "\t[Val]   Batch [40/170] Loss: 0.0002, PSNR: 35.1810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0003, PSNR: 34.5378\n",
      "\t[Val]   Batch [60/170] Loss: 0.0003, PSNR: 35.1426\n",
      "\t[Val]   Batch [70/170] Loss: 0.0003, PSNR: 35.1223\n",
      "\t[Val]   Batch [80/170] Loss: 0.0002, PSNR: 35.3986\n",
      "\t[Val]   Batch [90/170] Loss: 0.0002, PSNR: 35.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0002, PSNR: 35.1700\n",
      "\t[Val]   Batch [110/170] Loss: 0.0002, PSNR: 35.6235\n",
      "\t[Val]   Batch [120/170] Loss: 0.0003, PSNR: 32.9486\n",
      "\t[Val]   Batch [130/170] Loss: 0.0002, PSNR: 35.2292\n",
      "\t[Val]   Batch [140/170] Loss: 0.0002, PSNR: 35.5584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0003, PSNR: 35.1762\n",
      "\t[Val]   Batch [160/170] Loss: 0.0003, PSNR: 34.6857\n",
      "\t[Val]   Batch [170/170] Loss: 0.0002, PSNR: 35.3368\n",
      "Epoch [17/50] Validation Loss: 0.0003, PSNR: 35.0257\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/677], Loss: 0.0004, PSNR: 32.6073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0005, PSNR: 32.1238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0006, PSNR: 30.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0005, PSNR: 32.5020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0004, PSNR: 32.9214\n",
      "\t[Val]   Batch [1/170] Loss: 0.0002, PSNR: 35.4658\n",
      "\t[Val]   Batch [10/170] Loss: 0.0002, PSNR: 35.7581\n",
      "\t[Val]   Batch [20/170] Loss: 0.0003, PSNR: 34.9835\n",
      "\t[Val]   Batch [30/170] Loss: 0.0002, PSNR: 35.0980\n",
      "\t[Val]   Batch [40/170] Loss: 0.0002, PSNR: 35.4847\n",
      "\t[Val]   Batch [50/170] Loss: 0.0003, PSNR: 34.8658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [60/170] Loss: 0.0002, PSNR: 35.4743\n",
      "\t[Val]   Batch [70/170] Loss: 0.0002, PSNR: 35.4531\n",
      "\t[Val]   Batch [80/170] Loss: 0.0002, PSNR: 35.7124\n",
      "\t[Val]   Batch [90/170] Loss: 0.0002, PSNR: 36.1545\n",
      "\t[Val]   Batch [100/170] Loss: 0.0002, PSNR: 35.4935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [110/170] Loss: 0.0002, PSNR: 35.9716\n",
      "\t[Val]   Batch [120/170] Loss: 0.0002, PSNR: 33.3349\n",
      "\t[Val]   Batch [130/170] Loss: 0.0002, PSNR: 35.5832\n",
      "\t[Val]   Batch [140/170] Loss: 0.0002, PSNR: 35.9004\n",
      "\t[Val]   Batch [150/170] Loss: 0.0002, PSNR: 35.4653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [160/170] Loss: 0.0003, PSNR: 34.9842\n",
      "\t[Val]   Batch [170/170] Loss: 0.0002, PSNR: 35.6630\n",
      "Epoch [18/50] Validation Loss: 0.0002, PSNR: 35.3446\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/677], Loss: 0.0004, PSNR: 32.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/677], Loss: 0.0004, PSNR: 33.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/677], Loss: 0.0004, PSNR: 33.1692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/677], Loss: 0.0004, PSNR: 33.6363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0004, PSNR: 33.1198\n",
      "\t[Val]   Batch [1/170] Loss: 0.0002, PSNR: 36.0233\n",
      "\t[Val]   Batch [10/170] Loss: 0.0002, PSNR: 36.3159\n",
      "\t[Val]   Batch [20/170] Loss: 0.0002, PSNR: 35.4616\n",
      "\t[Val]   Batch [30/170] Loss: 0.0002, PSNR: 35.6797\n",
      "\t[Val]   Batch [40/170] Loss: 0.0002, PSNR: 36.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [50/170] Loss: 0.0002, PSNR: 35.2906\n",
      "\t[Val]   Batch [60/170] Loss: 0.0002, PSNR: 36.0335\n",
      "\t[Val]   Batch [70/170] Loss: 0.0002, PSNR: 35.9537\n",
      "\t[Val]   Batch [80/170] Loss: 0.0002, PSNR: 36.3189\n",
      "\t[Val]   Batch [90/170] Loss: 0.0002, PSNR: 36.7102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [100/170] Loss: 0.0002, PSNR: 36.0313\n",
      "\t[Val]   Batch [110/170] Loss: 0.0002, PSNR: 36.5302\n",
      "\t[Val]   Batch [120/170] Loss: 0.0002, PSNR: 33.7685\n",
      "\t[Val]   Batch [130/170] Loss: 0.0002, PSNR: 36.1489\n",
      "\t[Val]   Batch [140/170] Loss: 0.0002, PSNR: 36.4438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/170] Loss: 0.0002, PSNR: 36.0415\n",
      "\t[Val]   Batch [160/170] Loss: 0.0002, PSNR: 35.4926\n",
      "\t[Val]   Batch [170/170] Loss: 0.0002, PSNR: 36.4214\n",
      "Epoch [19/50] Validation Loss: 0.0002, PSNR: 35.8912\n",
      "Early stopping triggered at epoch 19. No improvement for 3 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:05:51.669804Z",
     "iopub.status.busy": "2025-05-09T02:05:51.669804Z",
     "iopub.status.idle": "2025-05-09T02:05:53.036604Z",
     "shell.execute_reply": "2025-05-09T02:05:53.036604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 101/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 201/210 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:05:53.038613Z",
     "iopub.status.busy": "2025-05-09T02:05:53.038613Z",
     "iopub.status.idle": "2025-05-09T02:05:53.043845Z",
     "shell.execute_reply": "2025-05-09T02:05:53.043845Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:05:53.045848Z",
     "iopub.status.busy": "2025-05-09T02:05:53.045848Z",
     "iopub.status.idle": "2025-05-09T02:06:02.375164Z",
     "shell.execute_reply": "2025-05-09T02:06:02.375164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n",
      "Epoch [1/1000] completed, Average Training Loss: 2.7949\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss improved from inf to 2.7755. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.7442\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.7053\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.6834\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.6586\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.6439\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.6340\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.6188\n",
      "    Validation Batch [1/1], Loss: 2.7754\n",
      "Validation Loss: 2.7754, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7755 to 2.7754. Saving model...\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.6062\n",
      "    Validation Batch [1/1], Loss: 2.7754\n",
      "Validation Loss: 2.7754, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.5962\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.5947\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.5681\n",
      "    Validation Batch [1/1], Loss: 2.7756\n",
      "Validation Loss: 2.7756, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 2.5660\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.5379\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.5278\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000] completed, Average Training Loss: 2.5190\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 2.5120\n",
      "    Validation Batch [1/1], Loss: 2.7755\n",
      "Validation Loss: 2.7755, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.5001\n",
      "    Validation Batch [1/1], Loss: 2.7754\n",
      "Validation Loss: 2.7754, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7754 to 2.7754. Saving model...\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.4806\n",
      "    Validation Batch [1/1], Loss: 2.7754\n",
      "Validation Loss: 2.7754, Validation Accuracy: 6.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.4714\n",
      "    Validation Batch [1/1], Loss: 2.7754\n",
      "Validation Loss: 2.7754, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7754 to 2.7754. Saving model...\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.4638\n",
      "    Validation Batch [1/1], Loss: 2.7752\n",
      "Validation Loss: 2.7752, Validation Accuracy: 11.25%\n",
      "Validation loss improved from 2.7754 to 2.7752. Saving model...\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 2.4603\n",
      "    Validation Batch [1/1], Loss: 2.7750\n",
      "Validation Loss: 2.7750, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7752 to 2.7750. Saving model...\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 2.4551\n",
      "    Validation Batch [1/1], Loss: 2.7747\n",
      "Validation Loss: 2.7747, Validation Accuracy: 8.75%\n",
      "Validation loss improved from 2.7750 to 2.7747. Saving model...\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 2.4382\n",
      "    Validation Batch [1/1], Loss: 2.7741\n",
      "Validation Loss: 2.7741, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7747 to 2.7741. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.4192\n",
      "    Validation Batch [1/1], Loss: 2.7735\n",
      "Validation Loss: 2.7735, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7741 to 2.7735. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 2.4193\n",
      "    Validation Batch [1/1], Loss: 2.7727\n",
      "Validation Loss: 2.7727, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7735 to 2.7727. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.3883\n",
      "    Validation Batch [1/1], Loss: 2.7717\n",
      "Validation Loss: 2.7717, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7727 to 2.7717. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.3862\n",
      "    Validation Batch [1/1], Loss: 2.7707\n",
      "Validation Loss: 2.7707, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7717 to 2.7707. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.3823\n",
      "    Validation Batch [1/1], Loss: 2.7695\n",
      "Validation Loss: 2.7695, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7707 to 2.7695. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.3757\n",
      "    Validation Batch [1/1], Loss: 2.7682\n",
      "Validation Loss: 2.7682, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7695 to 2.7682. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.3611\n",
      "    Validation Batch [1/1], Loss: 2.7666\n",
      "Validation Loss: 2.7666, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7682 to 2.7666. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 2.3382\n",
      "    Validation Batch [1/1], Loss: 2.7648\n",
      "Validation Loss: 2.7648, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7666 to 2.7648. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 2.3419\n",
      "    Validation Batch [1/1], Loss: 2.7629\n",
      "Validation Loss: 2.7629, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7648 to 2.7629. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 2.3380\n",
      "    Validation Batch [1/1], Loss: 2.7603\n",
      "Validation Loss: 2.7603, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7629 to 2.7603. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 2.3221\n",
      "    Validation Batch [1/1], Loss: 2.7566\n",
      "Validation Loss: 2.7566, Validation Accuracy: 6.25%\n",
      "Validation loss improved from 2.7603 to 2.7566. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 2.3214\n",
      "    Validation Batch [1/1], Loss: 2.7526\n",
      "Validation Loss: 2.7526, Validation Accuracy: 7.50%\n",
      "Validation loss improved from 2.7566 to 2.7526. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 2.3012\n",
      "    Validation Batch [1/1], Loss: 2.7482\n",
      "Validation Loss: 2.7482, Validation Accuracy: 11.25%\n",
      "Validation loss improved from 2.7526 to 2.7482. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 2.2930\n",
      "    Validation Batch [1/1], Loss: 2.7427\n",
      "Validation Loss: 2.7427, Validation Accuracy: 11.25%\n",
      "Validation loss improved from 2.7482 to 2.7427. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/1000] completed, Average Training Loss: 2.2767\n",
      "    Validation Batch [1/1], Loss: 2.7365\n",
      "Validation Loss: 2.7365, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7427 to 2.7365. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 2.2643\n",
      "    Validation Batch [1/1], Loss: 2.7294\n",
      "Validation Loss: 2.7294, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7365 to 2.7294. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 2.2594\n",
      "    Validation Batch [1/1], Loss: 2.7211\n",
      "Validation Loss: 2.7211, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7294 to 2.7211. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 2.2467\n",
      "    Validation Batch [1/1], Loss: 2.7137\n",
      "Validation Loss: 2.7137, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7211 to 2.7137. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 2.2348\n",
      "    Validation Batch [1/1], Loss: 2.7057\n",
      "Validation Loss: 2.7057, Validation Accuracy: 12.50%\n",
      "Validation loss improved from 2.7137 to 2.7057. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 2.2371\n",
      "    Validation Batch [1/1], Loss: 2.6956\n",
      "Validation Loss: 2.6956, Validation Accuracy: 15.00%\n",
      "Validation loss improved from 2.7057 to 2.6956. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 2.2281\n",
      "    Validation Batch [1/1], Loss: 2.6836\n",
      "Validation Loss: 2.6836, Validation Accuracy: 16.25%\n",
      "Validation loss improved from 2.6956 to 2.6836. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 2.2121\n",
      "    Validation Batch [1/1], Loss: 2.6711\n",
      "Validation Loss: 2.6711, Validation Accuracy: 18.75%\n",
      "Validation loss improved from 2.6836 to 2.6711. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 2.1985\n",
      "    Validation Batch [1/1], Loss: 2.6589\n",
      "Validation Loss: 2.6589, Validation Accuracy: 21.25%\n",
      "Validation loss improved from 2.6711 to 2.6589. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 2.1892\n",
      "    Validation Batch [1/1], Loss: 2.6462\n",
      "Validation Loss: 2.6462, Validation Accuracy: 25.00%\n",
      "Validation loss improved from 2.6589 to 2.6462. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 2.1846\n",
      "    Validation Batch [1/1], Loss: 2.6258\n",
      "Validation Loss: 2.6258, Validation Accuracy: 25.00%\n",
      "Validation loss improved from 2.6462 to 2.6258. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 2.1507\n",
      "    Validation Batch [1/1], Loss: 2.6046\n",
      "Validation Loss: 2.6046, Validation Accuracy: 26.25%\n",
      "Validation loss improved from 2.6258 to 2.6046. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 2.1436\n",
      "    Validation Batch [1/1], Loss: 2.5824\n",
      "Validation Loss: 2.5824, Validation Accuracy: 28.75%\n",
      "Validation loss improved from 2.6046 to 2.5824. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 2.1514\n",
      "    Validation Batch [1/1], Loss: 2.5502\n",
      "Validation Loss: 2.5502, Validation Accuracy: 35.00%\n",
      "Validation loss improved from 2.5824 to 2.5502. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 2.1205\n",
      "    Validation Batch [1/1], Loss: 2.5210\n",
      "Validation Loss: 2.5210, Validation Accuracy: 45.00%\n",
      "Validation loss improved from 2.5502 to 2.5210. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 2.1351\n",
      "    Validation Batch [1/1], Loss: 2.5018\n",
      "Validation Loss: 2.5018, Validation Accuracy: 46.25%\n",
      "Validation loss improved from 2.5210 to 2.5018. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 2.1221\n",
      "    Validation Batch [1/1], Loss: 2.4859\n",
      "Validation Loss: 2.4859, Validation Accuracy: 47.50%\n",
      "Validation loss improved from 2.5018 to 2.4859. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 2.1180\n",
      "    Validation Batch [1/1], Loss: 2.4561\n",
      "Validation Loss: 2.4561, Validation Accuracy: 47.50%\n",
      "Validation loss improved from 2.4859 to 2.4561. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 2.0873\n",
      "    Validation Batch [1/1], Loss: 2.4143\n",
      "Validation Loss: 2.4143, Validation Accuracy: 48.75%\n",
      "Validation loss improved from 2.4561 to 2.4143. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 2.0888\n",
      "    Validation Batch [1/1], Loss: 2.3826\n",
      "Validation Loss: 2.3826, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.4143 to 2.3826. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 2.0740\n",
      "    Validation Batch [1/1], Loss: 2.3707\n",
      "Validation Loss: 2.3707, Validation Accuracy: 48.75%\n",
      "Validation loss improved from 2.3826 to 2.3707. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 2.0695\n",
      "    Validation Batch [1/1], Loss: 2.3545\n",
      "Validation Loss: 2.3545, Validation Accuracy: 48.75%\n",
      "Validation loss improved from 2.3707 to 2.3545. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 2.0507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.3232\n",
      "Validation Loss: 2.3232, Validation Accuracy: 56.25%\n",
      "Validation loss improved from 2.3545 to 2.3232. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 2.0698\n",
      "    Validation Batch [1/1], Loss: 2.3007\n",
      "Validation Loss: 2.3007, Validation Accuracy: 62.50%\n",
      "Validation loss improved from 2.3232 to 2.3007. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 2.0294\n",
      "    Validation Batch [1/1], Loss: 2.2845\n",
      "Validation Loss: 2.2845, Validation Accuracy: 66.25%\n",
      "Validation loss improved from 2.3007 to 2.2845. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 2.0202\n",
      "    Validation Batch [1/1], Loss: 2.2496\n",
      "Validation Loss: 2.2496, Validation Accuracy: 65.00%\n",
      "Validation loss improved from 2.2845 to 2.2496. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 2.0239\n",
      "    Validation Batch [1/1], Loss: 2.2186\n",
      "Validation Loss: 2.2186, Validation Accuracy: 67.50%\n",
      "Validation loss improved from 2.2496 to 2.2186. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 2.0089\n",
      "    Validation Batch [1/1], Loss: 2.2031\n",
      "Validation Loss: 2.2031, Validation Accuracy: 68.75%\n",
      "Validation loss improved from 2.2186 to 2.2031. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.9862\n",
      "    Validation Batch [1/1], Loss: 2.1864\n",
      "Validation Loss: 2.1864, Validation Accuracy: 68.75%\n",
      "Validation loss improved from 2.2031 to 2.1864. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 2.0162\n",
      "    Validation Batch [1/1], Loss: 2.1679\n",
      "Validation Loss: 2.1679, Validation Accuracy: 68.75%\n",
      "Validation loss improved from 2.1864 to 2.1679. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.9883\n",
      "    Validation Batch [1/1], Loss: 2.1400\n",
      "Validation Loss: 2.1400, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 2.1679 to 2.1400. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.9876\n",
      "    Validation Batch [1/1], Loss: 2.1217\n",
      "Validation Loss: 2.1217, Validation Accuracy: 71.25%\n",
      "Validation loss improved from 2.1400 to 2.1217. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.9877\n",
      "    Validation Batch [1/1], Loss: 2.1118\n",
      "Validation Loss: 2.1118, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 2.1217 to 2.1118. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.9692\n",
      "    Validation Batch [1/1], Loss: 2.0912\n",
      "Validation Loss: 2.0912, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 2.1118 to 2.0912. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.9593\n",
      "    Validation Batch [1/1], Loss: 2.0811\n",
      "Validation Loss: 2.0811, Validation Accuracy: 68.75%\n",
      "Validation loss improved from 2.0912 to 2.0811. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/1000] completed, Average Training Loss: 1.9418\n",
      "    Validation Batch [1/1], Loss: 2.0787\n",
      "Validation Loss: 2.0787, Validation Accuracy: 68.75%\n",
      "Validation loss improved from 2.0811 to 2.0787. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.9015\n",
      "    Validation Batch [1/1], Loss: 2.0537\n",
      "Validation Loss: 2.0537, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 2.0787 to 2.0537. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.9232\n",
      "    Validation Batch [1/1], Loss: 2.0250\n",
      "Validation Loss: 2.0250, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 2.0537 to 2.0250. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.9198\n",
      "    Validation Batch [1/1], Loss: 2.0132\n",
      "Validation Loss: 2.0132, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 2.0250 to 2.0132. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.9115\n",
      "    Validation Batch [1/1], Loss: 2.0055\n",
      "Validation Loss: 2.0055, Validation Accuracy: 71.25%\n",
      "Validation loss improved from 2.0132 to 2.0055. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.9133\n",
      "    Validation Batch [1/1], Loss: 1.9919\n",
      "Validation Loss: 1.9919, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 2.0055 to 1.9919. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.8950\n",
      "    Validation Batch [1/1], Loss: 1.9805\n",
      "Validation Loss: 1.9805, Validation Accuracy: 71.25%\n",
      "Validation loss improved from 1.9919 to 1.9805. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.8898\n",
      "    Validation Batch [1/1], Loss: 1.9655\n",
      "Validation Loss: 1.9655, Validation Accuracy: 71.25%\n",
      "Validation loss improved from 1.9805 to 1.9655. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.8640\n",
      "    Validation Batch [1/1], Loss: 1.9493\n",
      "Validation Loss: 1.9493, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 1.9655 to 1.9493. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.8540\n",
      "    Validation Batch [1/1], Loss: 1.9244\n",
      "Validation Loss: 1.9244, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 1.9493 to 1.9244. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.8577\n",
      "    Validation Batch [1/1], Loss: 1.9169\n",
      "Validation Loss: 1.9169, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 1.9244 to 1.9169. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.8503\n",
      "    Validation Batch [1/1], Loss: 1.9260\n",
      "Validation Loss: 1.9260, Validation Accuracy: 71.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.8390\n",
      "    Validation Batch [1/1], Loss: 1.9040\n",
      "Validation Loss: 1.9040, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 1.9169 to 1.9040. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.8199\n",
      "    Validation Batch [1/1], Loss: 1.8920\n",
      "Validation Loss: 1.8920, Validation Accuracy: 72.50%\n",
      "Validation loss improved from 1.9040 to 1.8920. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.8309\n",
      "    Validation Batch [1/1], Loss: 1.8819\n",
      "Validation Loss: 1.8819, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.8920 to 1.8819. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.7905\n",
      "    Validation Batch [1/1], Loss: 1.8715\n",
      "Validation Loss: 1.8715, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.8819 to 1.8715. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.8095\n",
      "    Validation Batch [1/1], Loss: 1.8351\n",
      "Validation Loss: 1.8351, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.8715 to 1.8351. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.7668\n",
      "    Validation Batch [1/1], Loss: 1.8296\n",
      "Validation Loss: 1.8296, Validation Accuracy: 76.25%\n",
      "Validation loss improved from 1.8351 to 1.8296. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n",
      "Epoch [92/1000] completed, Average Training Loss: 1.7772\n",
      "    Validation Batch [1/1], Loss: 1.8296\n",
      "Validation Loss: 1.8296, Validation Accuracy: 73.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.7876\n",
      "    Validation Batch [1/1], Loss: 1.8238\n",
      "Validation Loss: 1.8238, Validation Accuracy: 73.75%\n",
      "Validation loss improved from 1.8296 to 1.8238. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.7729\n",
      "    Validation Batch [1/1], Loss: 1.8157\n",
      "Validation Loss: 1.8157, Validation Accuracy: 76.25%\n",
      "Validation loss improved from 1.8238 to 1.8157. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.7475\n",
      "    Validation Batch [1/1], Loss: 1.7916\n",
      "Validation Loss: 1.7916, Validation Accuracy: 76.25%\n",
      "Validation loss improved from 1.8157 to 1.7916. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.7490\n",
      "    Validation Batch [1/1], Loss: 1.8097\n",
      "Validation Loss: 1.8097, Validation Accuracy: 76.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/1000] completed, Average Training Loss: 1.7500\n",
      "    Validation Batch [1/1], Loss: 1.8085\n",
      "Validation Loss: 1.8085, Validation Accuracy: 76.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.7277\n",
      "    Validation Batch [1/1], Loss: 1.7856\n",
      "Validation Loss: 1.7856, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.7916 to 1.7856. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.7292\n",
      "    Validation Batch [1/1], Loss: 1.7716\n",
      "Validation Loss: 1.7716, Validation Accuracy: 76.25%\n",
      "Validation loss improved from 1.7856 to 1.7716. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.7077\n",
      "    Validation Batch [1/1], Loss: 1.7475\n",
      "Validation Loss: 1.7475, Validation Accuracy: 76.25%\n",
      "Validation loss improved from 1.7716 to 1.7475. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.6905\n",
      "    Validation Batch [1/1], Loss: 1.7267\n",
      "Validation Loss: 1.7267, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.7475 to 1.7267. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.7007\n",
      "    Validation Batch [1/1], Loss: 1.7143\n",
      "Validation Loss: 1.7143, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.7267 to 1.7143. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.7119\n",
      "    Validation Batch [1/1], Loss: 1.7134\n",
      "Validation Loss: 1.7134, Validation Accuracy: 75.00%\n",
      "Validation loss improved from 1.7143 to 1.7134. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.6802\n",
      "    Validation Batch [1/1], Loss: 1.7147\n",
      "Validation Loss: 1.7147, Validation Accuracy: 76.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.6700\n",
      "    Validation Batch [1/1], Loss: 1.7049\n",
      "Validation Loss: 1.7049, Validation Accuracy: 78.75%\n",
      "Validation loss improved from 1.7134 to 1.7049. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.6593\n",
      "    Validation Batch [1/1], Loss: 1.6623\n",
      "Validation Loss: 1.6623, Validation Accuracy: 82.50%\n",
      "Validation loss improved from 1.7049 to 1.6623. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.6198\n",
      "    Validation Batch [1/1], Loss: 1.6505\n",
      "Validation Loss: 1.6505, Validation Accuracy: 78.75%\n",
      "Validation loss improved from 1.6623 to 1.6505. Saving model...\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.6185\n",
      "    Validation Batch [1/1], Loss: 1.6606\n",
      "Validation Loss: 1.6606, Validation Accuracy: 77.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.5938\n",
      "    Validation Batch [1/1], Loss: 1.6483\n",
      "Validation Loss: 1.6483, Validation Accuracy: 78.75%\n",
      "Validation loss improved from 1.6505 to 1.6483. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.6293\n",
      "    Validation Batch [1/1], Loss: 1.6267\n",
      "Validation Loss: 1.6267, Validation Accuracy: 81.25%\n",
      "Validation loss improved from 1.6483 to 1.6267. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 1.5861\n",
      "    Validation Batch [1/1], Loss: 1.6435\n",
      "Validation Loss: 1.6435, Validation Accuracy: 78.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 1.6228\n",
      "    Validation Batch [1/1], Loss: 1.6216\n",
      "Validation Loss: 1.6216, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.6267 to 1.6216. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.5919\n",
      "    Validation Batch [1/1], Loss: 1.5853\n",
      "Validation Loss: 1.5853, Validation Accuracy: 81.25%\n",
      "Validation loss improved from 1.6216 to 1.5853. Saving model...\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 1.5952\n",
      "    Validation Batch [1/1], Loss: 1.5894\n",
      "Validation Loss: 1.5894, Validation Accuracy: 78.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.5617\n",
      "    Validation Batch [1/1], Loss: 1.5894\n",
      "Validation Loss: 1.5894, Validation Accuracy: 81.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 1.5870\n",
      "    Validation Batch [1/1], Loss: 1.5621\n",
      "Validation Loss: 1.5621, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.5853 to 1.5621. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 1.5356\n",
      "    Validation Batch [1/1], Loss: 1.5822\n",
      "Validation Loss: 1.5822, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 1.5540\n",
      "    Validation Batch [1/1], Loss: 1.6097\n",
      "Validation Loss: 1.6097, Validation Accuracy: 82.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 1.5398\n",
      "    Validation Batch [1/1], Loss: 1.5308\n",
      "Validation Loss: 1.5308, Validation Accuracy: 81.25%\n",
      "Validation loss improved from 1.5621 to 1.5308. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 1.5194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.5290\n",
      "Validation Loss: 1.5290, Validation Accuracy: 82.50%\n",
      "Validation loss improved from 1.5308 to 1.5290. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 1.5297\n",
      "    Validation Batch [1/1], Loss: 1.5413\n",
      "Validation Loss: 1.5413, Validation Accuracy: 81.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 1.5085\n",
      "    Validation Batch [1/1], Loss: 1.5096\n",
      "Validation Loss: 1.5096, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.5290 to 1.5096. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 1.5071\n",
      "    Validation Batch [1/1], Loss: 1.5231\n",
      "Validation Loss: 1.5231, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 1.5167\n",
      "    Validation Batch [1/1], Loss: 1.5057\n",
      "Validation Loss: 1.5057, Validation Accuracy: 83.75%\n",
      "Validation loss improved from 1.5096 to 1.5057. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 1.5169\n",
      "    Validation Batch [1/1], Loss: 1.4851\n",
      "Validation Loss: 1.4851, Validation Accuracy: 83.75%\n",
      "Validation loss improved from 1.5057 to 1.4851. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 1.4849\n",
      "    Validation Batch [1/1], Loss: 1.4731\n",
      "Validation Loss: 1.4731, Validation Accuracy: 82.50%\n",
      "Validation loss improved from 1.4851 to 1.4731. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 1.4916\n",
      "    Validation Batch [1/1], Loss: 1.4724\n",
      "Validation Loss: 1.4724, Validation Accuracy: 83.75%\n",
      "Validation loss improved from 1.4731 to 1.4724. Saving model...\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 1.4949\n",
      "    Validation Batch [1/1], Loss: 1.4806\n",
      "Validation Loss: 1.4806, Validation Accuracy: 83.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 1.4680\n",
      "    Validation Batch [1/1], Loss: 1.4631\n",
      "Validation Loss: 1.4631, Validation Accuracy: 82.50%\n",
      "Validation loss improved from 1.4724 to 1.4631. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 1.4683\n",
      "    Validation Batch [1/1], Loss: 1.4324\n",
      "Validation Loss: 1.4324, Validation Accuracy: 81.25%\n",
      "Validation loss improved from 1.4631 to 1.4324. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 1.4392\n",
      "    Validation Batch [1/1], Loss: 1.4443\n",
      "Validation Loss: 1.4443, Validation Accuracy: 85.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 1.4349\n",
      "    Validation Batch [1/1], Loss: 1.4277\n",
      "Validation Loss: 1.4277, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.4324 to 1.4277. Saving model...\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 1.4381\n",
      "    Validation Batch [1/1], Loss: 1.3938\n",
      "Validation Loss: 1.3938, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.4277 to 1.3938. Saving model...\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 1.4227\n",
      "    Validation Batch [1/1], Loss: 1.4024\n",
      "Validation Loss: 1.4024, Validation Accuracy: 86.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 1.4212\n",
      "    Validation Batch [1/1], Loss: 1.3998\n",
      "Validation Loss: 1.3998, Validation Accuracy: 83.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 1.4040\n",
      "    Validation Batch [1/1], Loss: 1.3942\n",
      "Validation Loss: 1.3942, Validation Accuracy: 83.75%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 1.3979\n",
      "    Validation Batch [1/1], Loss: 1.3840\n",
      "Validation Loss: 1.3840, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.3938 to 1.3840. Saving model...\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 1.3586\n",
      "    Validation Batch [1/1], Loss: 1.3692\n",
      "Validation Loss: 1.3692, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.3840 to 1.3692. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 1.3830\n",
      "    Validation Batch [1/1], Loss: 1.3560\n",
      "Validation Loss: 1.3560, Validation Accuracy: 82.50%\n",
      "Validation loss improved from 1.3692 to 1.3560. Saving model...\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 1.3885\n",
      "    Validation Batch [1/1], Loss: 1.3506\n",
      "Validation Loss: 1.3506, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.3560 to 1.3506. Saving model...\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 1.3327\n",
      "    Validation Batch [1/1], Loss: 1.3438\n",
      "Validation Loss: 1.3438, Validation Accuracy: 83.75%\n",
      "Validation loss improved from 1.3506 to 1.3438. Saving model...\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 1.3501\n",
      "    Validation Batch [1/1], Loss: 1.3435\n",
      "Validation Loss: 1.3435, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.3438 to 1.3435. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/1000] completed, Average Training Loss: 1.3228\n",
      "    Validation Batch [1/1], Loss: 1.3476\n",
      "Validation Loss: 1.3476, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 1.3344\n",
      "    Validation Batch [1/1], Loss: 1.3084\n",
      "Validation Loss: 1.3084, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.3435 to 1.3084. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 1.3323\n",
      "    Validation Batch [1/1], Loss: 1.3161\n",
      "Validation Loss: 1.3161, Validation Accuracy: 83.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 1.3140\n",
      "    Validation Batch [1/1], Loss: 1.3014\n",
      "Validation Loss: 1.3014, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.3084 to 1.3014. Saving model...\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 1.2700\n",
      "    Validation Batch [1/1], Loss: 1.2908\n",
      "Validation Loss: 1.2908, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.3014 to 1.2908. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 1.2897\n",
      "    Validation Batch [1/1], Loss: 1.2901\n",
      "Validation Loss: 1.2901, Validation Accuracy: 88.75%\n",
      "Validation loss improved from 1.2908 to 1.2901. Saving model...\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 1.3109\n",
      "    Validation Batch [1/1], Loss: 1.2806\n",
      "Validation Loss: 1.2806, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.2901 to 1.2806. Saving model...\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 1.3007\n",
      "    Validation Batch [1/1], Loss: 1.2641\n",
      "Validation Loss: 1.2641, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.2806 to 1.2641. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 1.2738\n",
      "    Validation Batch [1/1], Loss: 1.2706\n",
      "Validation Loss: 1.2706, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 1.2705\n",
      "    Validation Batch [1/1], Loss: 1.2631\n",
      "Validation Loss: 1.2631, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.2641 to 1.2631. Saving model...\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 1.2645\n",
      "    Validation Batch [1/1], Loss: 1.2563\n",
      "Validation Loss: 1.2563, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.2631 to 1.2563. Saving model...\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 1.2392\n",
      "    Validation Batch [1/1], Loss: 1.2393\n",
      "Validation Loss: 1.2393, Validation Accuracy: 83.75%\n",
      "Validation loss improved from 1.2563 to 1.2393. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 1.2505\n",
      "    Validation Batch [1/1], Loss: 1.2391\n",
      "Validation Loss: 1.2391, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.2393 to 1.2391. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 1.2181\n",
      "    Validation Batch [1/1], Loss: 1.2122\n",
      "Validation Loss: 1.2122, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.2391 to 1.2122. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 1.2252\n",
      "    Validation Batch [1/1], Loss: 1.2184\n",
      "Validation Loss: 1.2184, Validation Accuracy: 83.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 1.2249\n",
      "    Validation Batch [1/1], Loss: 1.2197\n",
      "Validation Loss: 1.2197, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 1.2221\n",
      "    Validation Batch [1/1], Loss: 1.1877\n",
      "Validation Loss: 1.1877, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.2122 to 1.1877. Saving model...\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 1.2009\n",
      "    Validation Batch [1/1], Loss: 1.1969\n",
      "Validation Loss: 1.1969, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 1.2049\n",
      "    Validation Batch [1/1], Loss: 1.1856\n",
      "Validation Loss: 1.1856, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.1877 to 1.1856. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 1.2247\n",
      "    Validation Batch [1/1], Loss: 1.1873\n",
      "Validation Loss: 1.1873, Validation Accuracy: 82.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 1.2066\n",
      "    Validation Batch [1/1], Loss: 1.1775\n",
      "Validation Loss: 1.1775, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.1856 to 1.1775. Saving model...\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 1.1808\n",
      "    Validation Batch [1/1], Loss: 1.1878\n",
      "Validation Loss: 1.1878, Validation Accuracy: 88.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/1000] completed, Average Training Loss: 1.1691\n",
      "    Validation Batch [1/1], Loss: 1.1634\n",
      "Validation Loss: 1.1634, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.1775 to 1.1634. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 1.1560\n",
      "    Validation Batch [1/1], Loss: 1.1644\n",
      "Validation Loss: 1.1644, Validation Accuracy: 88.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 1.1605\n",
      "    Validation Batch [1/1], Loss: 1.1419\n",
      "Validation Loss: 1.1419, Validation Accuracy: 88.75%\n",
      "Validation loss improved from 1.1634 to 1.1419. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 1.1293\n",
      "    Validation Batch [1/1], Loss: 1.1255\n",
      "Validation Loss: 1.1255, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.1419 to 1.1255. Saving model...\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 1.1128\n",
      "    Validation Batch [1/1], Loss: 1.1192\n",
      "Validation Loss: 1.1192, Validation Accuracy: 88.75%\n",
      "Validation loss improved from 1.1255 to 1.1192. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 1.1399\n",
      "    Validation Batch [1/1], Loss: 1.1315\n",
      "Validation Loss: 1.1315, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 1.1258\n",
      "    Validation Batch [1/1], Loss: 1.1047\n",
      "Validation Loss: 1.1047, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.1192 to 1.1047. Saving model...\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 1.0954\n",
      "    Validation Batch [1/1], Loss: 1.0994\n",
      "Validation Loss: 1.0994, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.1047 to 1.0994. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 1.1403\n",
      "    Validation Batch [1/1], Loss: 1.1096\n",
      "Validation Loss: 1.1096, Validation Accuracy: 86.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 1.0953\n",
      "    Validation Batch [1/1], Loss: 1.1157\n",
      "Validation Loss: 1.1157, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 1.0936\n",
      "    Validation Batch [1/1], Loss: 1.0891\n",
      "Validation Loss: 1.0891, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 1.0994 to 1.0891. Saving model...\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 1.0929\n",
      "    Validation Batch [1/1], Loss: 1.0723\n",
      "Validation Loss: 1.0723, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.0891 to 1.0723. Saving model...\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 1.0796\n",
      "    Validation Batch [1/1], Loss: 1.0776\n",
      "Validation Loss: 1.0776, Validation Accuracy: 85.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 1.0610\n",
      "    Validation Batch [1/1], Loss: 1.0674\n",
      "Validation Loss: 1.0674, Validation Accuracy: 86.25%\n",
      "Validation loss improved from 1.0723 to 1.0674. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 1.0800\n",
      "    Validation Batch [1/1], Loss: 1.0739\n",
      "Validation Loss: 1.0739, Validation Accuracy: 88.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 1.0566\n",
      "    Validation Batch [1/1], Loss: 1.0895\n",
      "Validation Loss: 1.0895, Validation Accuracy: 88.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 1.0519\n",
      "    Validation Batch [1/1], Loss: 1.0517\n",
      "Validation Loss: 1.0517, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.0674 to 1.0517. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 1.0449\n",
      "    Validation Batch [1/1], Loss: 1.0233\n",
      "Validation Loss: 1.0233, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.0517 to 1.0233. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 1.0356\n",
      "    Validation Batch [1/1], Loss: 1.0470\n",
      "Validation Loss: 1.0470, Validation Accuracy: 86.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 1.0278\n",
      "    Validation Batch [1/1], Loss: 1.0282\n",
      "Validation Loss: 1.0282, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 1.0045\n",
      "    Validation Batch [1/1], Loss: 1.0137\n",
      "Validation Loss: 1.0137, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.0233 to 1.0137. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 1.0044\n",
      "    Validation Batch [1/1], Loss: 1.0162\n",
      "Validation Loss: 1.0162, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 1.0271\n",
      "    Validation Batch [1/1], Loss: 1.0107\n",
      "Validation Loss: 1.0107, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.0137 to 1.0107. Saving model...\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/1000] completed, Average Training Loss: 1.0199\n",
      "    Validation Batch [1/1], Loss: 0.9997\n",
      "Validation Loss: 0.9997, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 1.0107 to 0.9997. Saving model...\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.9829\n",
      "    Validation Batch [1/1], Loss: 0.9974\n",
      "Validation Loss: 0.9974, Validation Accuracy: 87.50%\n",
      "Validation loss improved from 0.9997 to 0.9974. Saving model...\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.9880\n",
      "    Validation Batch [1/1], Loss: 0.9716\n",
      "Validation Loss: 0.9716, Validation Accuracy: 88.75%\n",
      "Validation loss improved from 0.9974 to 0.9716. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.9939\n",
      "    Validation Batch [1/1], Loss: 0.9601\n",
      "Validation Loss: 0.9601, Validation Accuracy: 85.00%\n",
      "Validation loss improved from 0.9716 to 0.9601. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.9634\n",
      "    Validation Batch [1/1], Loss: 0.9740\n",
      "Validation Loss: 0.9740, Validation Accuracy: 85.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.9573\n",
      "    Validation Batch [1/1], Loss: 0.9833\n",
      "Validation Loss: 0.9833, Validation Accuracy: 86.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.9651\n",
      "    Validation Batch [1/1], Loss: 0.9805\n",
      "Validation Loss: 0.9805, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.9452\n",
      "    Validation Batch [1/1], Loss: 0.9824\n",
      "Validation Loss: 0.9824, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.9519\n",
      "    Validation Batch [1/1], Loss: 1.0012\n",
      "Validation Loss: 1.0012, Validation Accuracy: 86.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.9354\n",
      "    Validation Batch [1/1], Loss: 0.9610\n",
      "Validation Loss: 0.9610, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.9645\n",
      "    Validation Batch [1/1], Loss: 0.9387\n",
      "Validation Loss: 0.9387, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.9601 to 0.9387. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.9166\n",
      "    Validation Batch [1/1], Loss: 0.9297\n",
      "Validation Loss: 0.9297, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9387 to 0.9297. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.9317\n",
      "    Validation Batch [1/1], Loss: 0.9077\n",
      "Validation Loss: 0.9077, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9297 to 0.9077. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.9149\n",
      "    Validation Batch [1/1], Loss: 0.9188\n",
      "Validation Loss: 0.9188, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.9203\n",
      "    Validation Batch [1/1], Loss: 0.9162\n",
      "Validation Loss: 0.9162, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.8809\n",
      "    Validation Batch [1/1], Loss: 0.9189\n",
      "Validation Loss: 0.9189, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.8899\n",
      "    Validation Batch [1/1], Loss: 0.9035\n",
      "Validation Loss: 0.9035, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.9077 to 0.9035. Saving model...\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.8589\n",
      "    Validation Batch [1/1], Loss: 0.8794\n",
      "Validation Loss: 0.8794, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.9035 to 0.8794. Saving model...\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.8732\n",
      "    Validation Batch [1/1], Loss: 0.8621\n",
      "Validation Loss: 0.8621, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.8794 to 0.8621. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.8635\n",
      "    Validation Batch [1/1], Loss: 0.8765\n",
      "Validation Loss: 0.8765, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.8713\n",
      "    Validation Batch [1/1], Loss: 0.8868\n",
      "Validation Loss: 0.8868, Validation Accuracy: 88.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.8406\n",
      "    Validation Batch [1/1], Loss: 0.8501\n",
      "Validation Loss: 0.8501, Validation Accuracy: 88.75%\n",
      "Validation loss improved from 0.8621 to 0.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.8383\n",
      "Validation Loss: 0.8383, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.8501 to 0.8383. Saving model...\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.8333\n",
      "    Validation Batch [1/1], Loss: 0.8378\n",
      "Validation Loss: 0.8378, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.8383 to 0.8378. Saving model...\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.8369\n",
      "    Validation Batch [1/1], Loss: 0.8408\n",
      "Validation Loss: 0.8408, Validation Accuracy: 87.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.8126\n",
      "    Validation Batch [1/1], Loss: 0.8453\n",
      "Validation Loss: 0.8453, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.8459\n",
      "    Validation Batch [1/1], Loss: 0.8544\n",
      "Validation Loss: 0.8544, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.8377\n",
      "    Validation Batch [1/1], Loss: 0.8195\n",
      "Validation Loss: 0.8195, Validation Accuracy: 88.75%\n",
      "Validation loss improved from 0.8378 to 0.8195. Saving model...\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.7962\n",
      "    Validation Batch [1/1], Loss: 0.8193\n",
      "Validation Loss: 0.8193, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.8195 to 0.8193. Saving model...\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.7956\n",
      "    Validation Batch [1/1], Loss: 0.8235\n",
      "Validation Loss: 0.8235, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.7907\n",
      "    Validation Batch [1/1], Loss: 0.8367\n",
      "Validation Loss: 0.8367, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.7721\n",
      "    Validation Batch [1/1], Loss: 0.8170\n",
      "Validation Loss: 0.8170, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.8193 to 0.8170. Saving model...\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.7836\n",
      "    Validation Batch [1/1], Loss: 0.7924\n",
      "Validation Loss: 0.7924, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.8170 to 0.7924. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.7644\n",
      "    Validation Batch [1/1], Loss: 0.7794\n",
      "Validation Loss: 0.7794, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.7924 to 0.7794. Saving model...\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.7893\n",
      "    Validation Batch [1/1], Loss: 0.7795\n",
      "Validation Loss: 0.7795, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.7642\n",
      "    Validation Batch [1/1], Loss: 0.7765\n",
      "Validation Loss: 0.7765, Validation Accuracy: 92.50%\n",
      "Validation loss improved from 0.7794 to 0.7765. Saving model...\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.7560\n",
      "    Validation Batch [1/1], Loss: 0.7589\n",
      "Validation Loss: 0.7589, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.7765 to 0.7589. Saving model...\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n",
      "Epoch [225/1000] completed, Average Training Loss: 0.7573\n",
      "    Validation Batch [1/1], Loss: 0.7575\n",
      "Validation Loss: 0.7575, Validation Accuracy: 92.50%\n",
      "Validation loss improved from 0.7589 to 0.7575. Saving model...\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.7520\n",
      "    Validation Batch [1/1], Loss: 0.7572\n",
      "Validation Loss: 0.7572, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.7575 to 0.7572. Saving model...\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.7424\n",
      "    Validation Batch [1/1], Loss: 0.7420\n",
      "Validation Loss: 0.7420, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.7572 to 0.7420. Saving model...\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.7330\n",
      "    Validation Batch [1/1], Loss: 0.7400\n",
      "Validation Loss: 0.7400, Validation Accuracy: 93.75%\n",
      "Validation loss improved from 0.7420 to 0.7400. Saving model...\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.7255\n",
      "    Validation Batch [1/1], Loss: 0.7283\n",
      "Validation Loss: 0.7283, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.7400 to 0.7283. Saving model...\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.7078\n",
      "    Validation Batch [1/1], Loss: 0.7318\n",
      "Validation Loss: 0.7318, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.7032\n",
      "    Validation Batch [1/1], Loss: 0.7537\n",
      "Validation Loss: 0.7537, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.6974\n",
      "    Validation Batch [1/1], Loss: 0.7271\n",
      "Validation Loss: 0.7271, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.7283 to 0.7271. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.6922\n",
      "    Validation Batch [1/1], Loss: 0.7190\n",
      "Validation Loss: 0.7190, Validation Accuracy: 93.75%\n",
      "Validation loss improved from 0.7271 to 0.7190. Saving model...\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/1000] completed, Average Training Loss: 0.6717\n",
      "    Validation Batch [1/1], Loss: 0.7062\n",
      "Validation Loss: 0.7062, Validation Accuracy: 91.25%\n",
      "Validation loss improved from 0.7190 to 0.7062. Saving model...\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.6885\n",
      "    Validation Batch [1/1], Loss: 0.6783\n",
      "Validation Loss: 0.6783, Validation Accuracy: 93.75%\n",
      "Validation loss improved from 0.7062 to 0.6783. Saving model...\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.6698\n",
      "    Validation Batch [1/1], Loss: 0.6939\n",
      "Validation Loss: 0.6939, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.7024\n",
      "    Validation Batch [1/1], Loss: 0.6899\n",
      "Validation Loss: 0.6899, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.6574\n",
      "    Validation Batch [1/1], Loss: 0.6679\n",
      "Validation Loss: 0.6679, Validation Accuracy: 92.50%\n",
      "Validation loss improved from 0.6783 to 0.6679. Saving model...\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.6708\n",
      "    Validation Batch [1/1], Loss: 0.6671\n",
      "Validation Loss: 0.6671, Validation Accuracy: 92.50%\n",
      "Validation loss improved from 0.6679 to 0.6671. Saving model...\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.6365\n",
      "    Validation Batch [1/1], Loss: 0.6789\n",
      "Validation Loss: 0.6789, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.6410\n",
      "    Validation Batch [1/1], Loss: 0.6690\n",
      "Validation Loss: 0.6690, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.6370\n",
      "    Validation Batch [1/1], Loss: 0.6722\n",
      "Validation Loss: 0.6722, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.6184\n",
      "    Validation Batch [1/1], Loss: 0.6513\n",
      "Validation Loss: 0.6513, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.6671 to 0.6513. Saving model...\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.6284\n",
      "    Validation Batch [1/1], Loss: 0.6577\n",
      "Validation Loss: 0.6577, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.6383\n",
      "    Validation Batch [1/1], Loss: 0.6631\n",
      "Validation Loss: 0.6631, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.6325\n",
      "    Validation Batch [1/1], Loss: 0.6456\n",
      "Validation Loss: 0.6456, Validation Accuracy: 92.50%\n",
      "Validation loss improved from 0.6513 to 0.6456. Saving model...\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.6229\n",
      "    Validation Batch [1/1], Loss: 0.6516\n",
      "Validation Loss: 0.6516, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.6076\n",
      "    Validation Batch [1/1], Loss: 0.6526\n",
      "Validation Loss: 0.6526, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.5999\n",
      "    Validation Batch [1/1], Loss: 0.6290\n",
      "Validation Loss: 0.6290, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.6456 to 0.6290. Saving model...\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.5979\n",
      "    Validation Batch [1/1], Loss: 0.6188\n",
      "Validation Loss: 0.6188, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.6290 to 0.6188. Saving model...\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.5944\n",
      "    Validation Batch [1/1], Loss: 0.6141\n",
      "Validation Loss: 0.6141, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.6188 to 0.6141. Saving model...\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.5903\n",
      "    Validation Batch [1/1], Loss: 0.6039\n",
      "Validation Loss: 0.6039, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.6141 to 0.6039. Saving model...\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.5559\n",
      "    Validation Batch [1/1], Loss: 0.6098\n",
      "Validation Loss: 0.6098, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.5606\n",
      "    Validation Batch [1/1], Loss: 0.6283\n",
      "Validation Loss: 0.6283, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.5648\n",
      "    Validation Batch [1/1], Loss: 0.5989\n",
      "Validation Loss: 0.5989, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.6039 to 0.5989. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.5747\n",
      "    Validation Batch [1/1], Loss: 0.5986\n",
      "Validation Loss: 0.5986, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5989 to 0.5986. Saving model...\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [257/1000] completed, Average Training Loss: 0.5487\n",
      "    Validation Batch [1/1], Loss: 0.5924\n",
      "Validation Loss: 0.5924, Validation Accuracy: 93.75%\n",
      "Validation loss improved from 0.5986 to 0.5924. Saving model...\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.5804\n",
      "    Validation Batch [1/1], Loss: 0.5795\n",
      "Validation Loss: 0.5795, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5924 to 0.5795. Saving model...\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.5649\n",
      "    Validation Batch [1/1], Loss: 0.5802\n",
      "Validation Loss: 0.5802, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.5443\n",
      "    Validation Batch [1/1], Loss: 0.5721\n",
      "Validation Loss: 0.5721, Validation Accuracy: 93.75%\n",
      "Validation loss improved from 0.5795 to 0.5721. Saving model...\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.5461\n",
      "    Validation Batch [1/1], Loss: 0.6236\n",
      "Validation Loss: 0.6236, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.5490\n",
      "    Validation Batch [1/1], Loss: 0.5954\n",
      "Validation Loss: 0.5954, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.5160\n",
      "    Validation Batch [1/1], Loss: 0.5679\n",
      "Validation Loss: 0.5679, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5721 to 0.5679. Saving model...\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.5497\n",
      "    Validation Batch [1/1], Loss: 0.6045\n",
      "Validation Loss: 0.6045, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.5133\n",
      "    Validation Batch [1/1], Loss: 0.5466\n",
      "Validation Loss: 0.5466, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5679 to 0.5466. Saving model...\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.5164\n",
      "    Validation Batch [1/1], Loss: 0.5501\n",
      "Validation Loss: 0.5501, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.4969\n",
      "    Validation Batch [1/1], Loss: 0.5536\n",
      "Validation Loss: 0.5536, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.5130\n",
      "    Validation Batch [1/1], Loss: 0.5398\n",
      "Validation Loss: 0.5398, Validation Accuracy: 92.50%\n",
      "Validation loss improved from 0.5466 to 0.5398. Saving model...\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.5230\n",
      "    Validation Batch [1/1], Loss: 0.5261\n",
      "Validation Loss: 0.5261, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5398 to 0.5261. Saving model...\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.4684\n",
      "    Validation Batch [1/1], Loss: 0.5496\n",
      "Validation Loss: 0.5496, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.4823\n",
      "    Validation Batch [1/1], Loss: 0.5126\n",
      "Validation Loss: 0.5126, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5261 to 0.5126. Saving model...\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.4884\n",
      "    Validation Batch [1/1], Loss: 0.5040\n",
      "Validation Loss: 0.5040, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.5126 to 0.5040. Saving model...\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.4746\n",
      "    Validation Batch [1/1], Loss: 0.5269\n",
      "Validation Loss: 0.5269, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.4715\n",
      "    Validation Batch [1/1], Loss: 0.5352\n",
      "Validation Loss: 0.5352, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.4642\n",
      "    Validation Batch [1/1], Loss: 0.5025\n",
      "Validation Loss: 0.5025, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.5040 to 0.5025. Saving model...\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.4555\n",
      "    Validation Batch [1/1], Loss: 0.5094\n",
      "Validation Loss: 0.5094, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.4605\n",
      "    Validation Batch [1/1], Loss: 0.5069\n",
      "Validation Loss: 0.5069, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.4650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.4932\n",
      "Validation Loss: 0.4932, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.5025 to 0.4932. Saving model...\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.4571\n",
      "    Validation Batch [1/1], Loss: 0.4857\n",
      "Validation Loss: 0.4857, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.4932 to 0.4857. Saving model...\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.4620\n",
      "    Validation Batch [1/1], Loss: 0.4893\n",
      "Validation Loss: 0.4893, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.4428\n",
      "    Validation Batch [1/1], Loss: 0.4925\n",
      "Validation Loss: 0.4925, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.4302\n",
      "    Validation Batch [1/1], Loss: 0.4859\n",
      "Validation Loss: 0.4859, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.4339\n",
      "    Validation Batch [1/1], Loss: 0.4817\n",
      "Validation Loss: 0.4817, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.4857 to 0.4817. Saving model...\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.4604\n",
      "    Validation Batch [1/1], Loss: 0.4952\n",
      "Validation Loss: 0.4952, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.4653\n",
      "    Validation Batch [1/1], Loss: 0.4893\n",
      "Validation Loss: 0.4893, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.4476\n",
      "    Validation Batch [1/1], Loss: 0.4545\n",
      "Validation Loss: 0.4545, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.4817 to 0.4545. Saving model...\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.4087\n",
      "    Validation Batch [1/1], Loss: 0.4760\n",
      "Validation Loss: 0.4760, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.4025\n",
      "    Validation Batch [1/1], Loss: 0.4473\n",
      "Validation Loss: 0.4473, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.4545 to 0.4473. Saving model...\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.4367\n",
      "    Validation Batch [1/1], Loss: 0.4448\n",
      "Validation Loss: 0.4448, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.4473 to 0.4448. Saving model...\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.3963\n",
      "    Validation Batch [1/1], Loss: 0.4542\n",
      "Validation Loss: 0.4542, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.3915\n",
      "    Validation Batch [1/1], Loss: 0.4372\n",
      "Validation Loss: 0.4372, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.4448 to 0.4372. Saving model...\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.3930\n",
      "    Validation Batch [1/1], Loss: 0.4290\n",
      "Validation Loss: 0.4290, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.4372 to 0.4290. Saving model...\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.3943\n",
      "    Validation Batch [1/1], Loss: 0.4290\n",
      "Validation Loss: 0.4290, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.3965\n",
      "    Validation Batch [1/1], Loss: 0.4392\n",
      "Validation Loss: 0.4392, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.3754\n",
      "    Validation Batch [1/1], Loss: 0.4546\n",
      "Validation Loss: 0.4546, Validation Accuracy: 91.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.3955\n",
      "    Validation Batch [1/1], Loss: 0.4164\n",
      "Validation Loss: 0.4164, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.4290 to 0.4164. Saving model...\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.3800\n",
      "    Validation Batch [1/1], Loss: 0.4275\n",
      "Validation Loss: 0.4275, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.3846\n",
      "    Validation Batch [1/1], Loss: 0.4396\n",
      "Validation Loss: 0.4396, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.3816\n",
      "    Validation Batch [1/1], Loss: 0.4157\n",
      "Validation Loss: 0.4157, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.4164 to 0.4157. Saving model...\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.3761\n",
      "    Validation Batch [1/1], Loss: 0.4276\n",
      "Validation Loss: 0.4276, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [301/1000] completed, Average Training Loss: 0.3971\n",
      "    Validation Batch [1/1], Loss: 0.4539\n",
      "Validation Loss: 0.4539, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.3618\n",
      "    Validation Batch [1/1], Loss: 0.4312\n",
      "Validation Loss: 0.4312, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.3730\n",
      "    Validation Batch [1/1], Loss: 0.4104\n",
      "Validation Loss: 0.4104, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.4157 to 0.4104. Saving model...\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.3754\n",
      "    Validation Batch [1/1], Loss: 0.4299\n",
      "Validation Loss: 0.4299, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.3489\n",
      "    Validation Batch [1/1], Loss: 0.4104\n",
      "Validation Loss: 0.4104, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.3396\n",
      "    Validation Batch [1/1], Loss: 0.3970\n",
      "Validation Loss: 0.3970, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.4104 to 0.3970. Saving model...\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.3468\n",
      "    Validation Batch [1/1], Loss: 0.3833\n",
      "Validation Loss: 0.3833, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3970 to 0.3833. Saving model...\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.3431\n",
      "    Validation Batch [1/1], Loss: 0.3837\n",
      "Validation Loss: 0.3837, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.3348\n",
      "    Validation Batch [1/1], Loss: 0.4095\n",
      "Validation Loss: 0.4095, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.3427\n",
      "    Validation Batch [1/1], Loss: 0.3803\n",
      "Validation Loss: 0.3803, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3833 to 0.3803. Saving model...\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.3093\n",
      "    Validation Batch [1/1], Loss: 0.3868\n",
      "Validation Loss: 0.3868, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.3453\n",
      "    Validation Batch [1/1], Loss: 0.4359\n",
      "Validation Loss: 0.4359, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.3085\n",
      "    Validation Batch [1/1], Loss: 0.4014\n",
      "Validation Loss: 0.4014, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.3446\n",
      "    Validation Batch [1/1], Loss: 0.3709\n",
      "Validation Loss: 0.3709, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3803 to 0.3709. Saving model...\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.3136\n",
      "    Validation Batch [1/1], Loss: 0.3769\n",
      "Validation Loss: 0.3769, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.3104\n",
      "    Validation Batch [1/1], Loss: 0.3966\n",
      "Validation Loss: 0.3966, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.3192\n",
      "    Validation Batch [1/1], Loss: 0.3721\n",
      "Validation Loss: 0.3721, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.3329\n",
      "    Validation Batch [1/1], Loss: 0.3728\n",
      "Validation Loss: 0.3728, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.3072\n",
      "    Validation Batch [1/1], Loss: 0.3464\n",
      "Validation Loss: 0.3464, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3709 to 0.3464. Saving model...\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.2790\n",
      "    Validation Batch [1/1], Loss: 0.3715\n",
      "Validation Loss: 0.3715, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.2893\n",
      "    Validation Batch [1/1], Loss: 0.3623\n",
      "Validation Loss: 0.3623, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.3071\n",
      "    Validation Batch [1/1], Loss: 0.3344\n",
      "Validation Loss: 0.3344, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3464 to 0.3344. Saving model...\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.2927\n",
      "    Validation Batch [1/1], Loss: 0.3389\n",
      "Validation Loss: 0.3389, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.3149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.3524\n",
      "Validation Loss: 0.3524, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.2820\n",
      "    Validation Batch [1/1], Loss: 0.3682\n",
      "Validation Loss: 0.3682, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.2710\n",
      "    Validation Batch [1/1], Loss: 0.3533\n",
      "Validation Loss: 0.3533, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.3236\n",
      "    Validation Batch [1/1], Loss: 0.3334\n",
      "Validation Loss: 0.3334, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3344 to 0.3334. Saving model...\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.2660\n",
      "    Validation Batch [1/1], Loss: 0.3290\n",
      "Validation Loss: 0.3290, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.3334 to 0.3290. Saving model...\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.2770\n",
      "    Validation Batch [1/1], Loss: 0.3469\n",
      "Validation Loss: 0.3469, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.2924\n",
      "    Validation Batch [1/1], Loss: 0.3323\n",
      "Validation Loss: 0.3323, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.2646\n",
      "    Validation Batch [1/1], Loss: 0.3373\n",
      "Validation Loss: 0.3373, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.2755\n",
      "    Validation Batch [1/1], Loss: 0.3240\n",
      "Validation Loss: 0.3240, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3290 to 0.3240. Saving model...\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.2586\n",
      "    Validation Batch [1/1], Loss: 0.3275\n",
      "Validation Loss: 0.3275, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.2824\n",
      "    Validation Batch [1/1], Loss: 0.3121\n",
      "Validation Loss: 0.3121, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3240 to 0.3121. Saving model...\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.2494\n",
      "    Validation Batch [1/1], Loss: 0.3118\n",
      "Validation Loss: 0.3118, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3121 to 0.3118. Saving model...\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.2764\n",
      "    Validation Batch [1/1], Loss: 0.3225\n",
      "Validation Loss: 0.3225, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.2737\n",
      "    Validation Batch [1/1], Loss: 0.3386\n",
      "Validation Loss: 0.3386, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.2763\n",
      "    Validation Batch [1/1], Loss: 0.3400\n",
      "Validation Loss: 0.3400, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.2683\n",
      "    Validation Batch [1/1], Loss: 0.3161\n",
      "Validation Loss: 0.3161, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.2564\n",
      "    Validation Batch [1/1], Loss: 0.3105\n",
      "Validation Loss: 0.3105, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.3118 to 0.3105. Saving model...\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.2637\n",
      "    Validation Batch [1/1], Loss: 0.3335\n",
      "Validation Loss: 0.3335, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.2713\n",
      "    Validation Batch [1/1], Loss: 0.3325\n",
      "Validation Loss: 0.3325, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.2496\n",
      "    Validation Batch [1/1], Loss: 0.3209\n",
      "Validation Loss: 0.3209, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.2407\n",
      "    Validation Batch [1/1], Loss: 0.3008\n",
      "Validation Loss: 0.3008, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.3105 to 0.3008. Saving model...\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.2573\n",
      "    Validation Batch [1/1], Loss: 0.2962\n",
      "Validation Loss: 0.2962, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.3008 to 0.2962. Saving model...\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.2367\n",
      "    Validation Batch [1/1], Loss: 0.3060\n",
      "Validation Loss: 0.3060, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [347/1000] completed, Average Training Loss: 0.2534\n",
      "    Validation Batch [1/1], Loss: 0.3156\n",
      "Validation Loss: 0.3156, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.2353\n",
      "    Validation Batch [1/1], Loss: 0.2963\n",
      "Validation Loss: 0.2963, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.2426\n",
      "    Validation Batch [1/1], Loss: 0.2915\n",
      "Validation Loss: 0.2915, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2962 to 0.2915. Saving model...\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.2405\n",
      "    Validation Batch [1/1], Loss: 0.3244\n",
      "Validation Loss: 0.3244, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.2400\n",
      "    Validation Batch [1/1], Loss: 0.2854\n",
      "Validation Loss: 0.2854, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2915 to 0.2854. Saving model...\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.2330\n",
      "    Validation Batch [1/1], Loss: 0.3009\n",
      "Validation Loss: 0.3009, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.2531\n",
      "    Validation Batch [1/1], Loss: 0.3014\n",
      "Validation Loss: 0.3014, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.2293\n",
      "    Validation Batch [1/1], Loss: 0.3279\n",
      "Validation Loss: 0.3279, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.2225\n",
      "    Validation Batch [1/1], Loss: 0.2884\n",
      "Validation Loss: 0.2884, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.2252\n",
      "    Validation Batch [1/1], Loss: 0.2840\n",
      "Validation Loss: 0.2840, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2854 to 0.2840. Saving model...\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.2200\n",
      "    Validation Batch [1/1], Loss: 0.3014\n",
      "Validation Loss: 0.3014, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.2331\n",
      "    Validation Batch [1/1], Loss: 0.2925\n",
      "Validation Loss: 0.2925, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.2215\n",
      "    Validation Batch [1/1], Loss: 0.2804\n",
      "Validation Loss: 0.2804, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2840 to 0.2804. Saving model...\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1989\n",
      "    Validation Batch [1/1], Loss: 0.2731\n",
      "Validation Loss: 0.2731, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2804 to 0.2731. Saving model...\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.2070\n",
      "    Validation Batch [1/1], Loss: 0.2738\n",
      "Validation Loss: 0.2738, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.2176\n",
      "    Validation Batch [1/1], Loss: 0.2837\n",
      "Validation Loss: 0.2837, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.2130\n",
      "    Validation Batch [1/1], Loss: 0.2954\n",
      "Validation Loss: 0.2954, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.2019\n",
      "    Validation Batch [1/1], Loss: 0.2858\n",
      "Validation Loss: 0.2858, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.1949\n",
      "    Validation Batch [1/1], Loss: 0.2900\n",
      "Validation Loss: 0.2900, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.2169\n",
      "    Validation Batch [1/1], Loss: 0.2856\n",
      "Validation Loss: 0.2856, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.2026\n",
      "    Validation Batch [1/1], Loss: 0.2882\n",
      "Validation Loss: 0.2882, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.2133\n",
      "    Validation Batch [1/1], Loss: 0.2975\n",
      "Validation Loss: 0.2975, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [369/1000] completed, Average Training Loss: 0.1880\n",
      "    Validation Batch [1/1], Loss: 0.2727\n",
      "Validation Loss: 0.2727, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2731 to 0.2727. Saving model...\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.1882\n",
      "    Validation Batch [1/1], Loss: 0.2563\n",
      "Validation Loss: 0.2563, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2727 to 0.2563. Saving model...\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.2026\n",
      "    Validation Batch [1/1], Loss: 0.2497\n",
      "Validation Loss: 0.2497, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2563 to 0.2497. Saving model...\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.1817\n",
      "    Validation Batch [1/1], Loss: 0.3109\n",
      "Validation Loss: 0.3109, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.2125\n",
      "    Validation Batch [1/1], Loss: 0.2823\n",
      "Validation Loss: 0.2823, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.2014\n",
      "    Validation Batch [1/1], Loss: 0.2718\n",
      "Validation Loss: 0.2718, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.1889\n",
      "    Validation Batch [1/1], Loss: 0.2737\n",
      "Validation Loss: 0.2737, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.2004\n",
      "    Validation Batch [1/1], Loss: 0.2882\n",
      "Validation Loss: 0.2882, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.1939\n",
      "    Validation Batch [1/1], Loss: 0.2940\n",
      "Validation Loss: 0.2940, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.1944\n",
      "    Validation Batch [1/1], Loss: 0.2583\n",
      "Validation Loss: 0.2583, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.2006\n",
      "    Validation Batch [1/1], Loss: 0.2743\n",
      "Validation Loss: 0.2743, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.1948\n",
      "    Validation Batch [1/1], Loss: 0.2663\n",
      "Validation Loss: 0.2663, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.1783\n",
      "    Validation Batch [1/1], Loss: 0.2860\n",
      "Validation Loss: 0.2860, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.1835\n",
      "    Validation Batch [1/1], Loss: 0.2738\n",
      "Validation Loss: 0.2738, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.1910\n",
      "    Validation Batch [1/1], Loss: 0.2480\n",
      "Validation Loss: 0.2480, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2497 to 0.2480. Saving model...\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.1972\n",
      "    Validation Batch [1/1], Loss: 0.2429\n",
      "Validation Loss: 0.2429, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2480 to 0.2429. Saving model...\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.1789\n",
      "    Validation Batch [1/1], Loss: 0.2668\n",
      "Validation Loss: 0.2668, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.1992\n",
      "    Validation Batch [1/1], Loss: 0.2730\n",
      "Validation Loss: 0.2730, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.1785\n",
      "    Validation Batch [1/1], Loss: 0.2591\n",
      "Validation Loss: 0.2591, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.1742\n",
      "    Validation Batch [1/1], Loss: 0.2573\n",
      "Validation Loss: 0.2573, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.1753\n",
      "    Validation Batch [1/1], Loss: 0.2477\n",
      "Validation Loss: 0.2477, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.1680\n",
      "    Validation Batch [1/1], Loss: 0.2639\n",
      "Validation Loss: 0.2639, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.1812\n",
      "    Validation Batch [1/1], Loss: 0.2739\n",
      "Validation Loss: 0.2739, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [392/1000] completed, Average Training Loss: 0.1662\n",
      "    Validation Batch [1/1], Loss: 0.2394\n",
      "Validation Loss: 0.2394, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2429 to 0.2394. Saving model...\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.1629\n",
      "    Validation Batch [1/1], Loss: 0.2627\n",
      "Validation Loss: 0.2627, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.1765\n",
      "    Validation Batch [1/1], Loss: 0.2430\n",
      "Validation Loss: 0.2430, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.1581\n",
      "    Validation Batch [1/1], Loss: 0.2834\n",
      "Validation Loss: 0.2834, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.1674\n",
      "    Validation Batch [1/1], Loss: 0.2485\n",
      "Validation Loss: 0.2485, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.1714\n",
      "    Validation Batch [1/1], Loss: 0.2394\n",
      "Validation Loss: 0.2394, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.1512\n",
      "    Validation Batch [1/1], Loss: 0.2469\n",
      "Validation Loss: 0.2469, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.1750\n",
      "    Validation Batch [1/1], Loss: 0.2476\n",
      "Validation Loss: 0.2476, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.1585\n",
      "    Validation Batch [1/1], Loss: 0.2764\n",
      "Validation Loss: 0.2764, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.1762\n",
      "    Validation Batch [1/1], Loss: 0.2683\n",
      "Validation Loss: 0.2683, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.1733\n",
      "    Validation Batch [1/1], Loss: 0.2431\n",
      "Validation Loss: 0.2431, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.1678\n",
      "    Validation Batch [1/1], Loss: 0.2427\n",
      "Validation Loss: 0.2427, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.1812\n",
      "    Validation Batch [1/1], Loss: 0.2213\n",
      "Validation Loss: 0.2213, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2394 to 0.2213. Saving model...\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.1549\n",
      "    Validation Batch [1/1], Loss: 0.2268\n",
      "Validation Loss: 0.2268, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.1478\n",
      "    Validation Batch [1/1], Loss: 0.2433\n",
      "Validation Loss: 0.2433, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.1526\n",
      "    Validation Batch [1/1], Loss: 0.2591\n",
      "Validation Loss: 0.2591, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.1528\n",
      "    Validation Batch [1/1], Loss: 0.2342\n",
      "Validation Loss: 0.2342, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.1499\n",
      "    Validation Batch [1/1], Loss: 0.2799\n",
      "Validation Loss: 0.2799, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.1523\n",
      "    Validation Batch [1/1], Loss: 0.2444\n",
      "Validation Loss: 0.2444, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.1481\n",
      "    Validation Batch [1/1], Loss: 0.2815\n",
      "Validation Loss: 0.2815, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.1465\n",
      "    Validation Batch [1/1], Loss: 0.2390\n",
      "Validation Loss: 0.2390, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.1467\n",
      "    Validation Batch [1/1], Loss: 0.2438\n",
      "Validation Loss: 0.2438, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.1495\n",
      "    Validation Batch [1/1], Loss: 0.2336\n",
      "Validation Loss: 0.2336, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [415/1000] completed, Average Training Loss: 0.1488\n",
      "    Validation Batch [1/1], Loss: 0.2487\n",
      "Validation Loss: 0.2487, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.1508\n",
      "    Validation Batch [1/1], Loss: 0.2585\n",
      "Validation Loss: 0.2585, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.1467\n",
      "    Validation Batch [1/1], Loss: 0.3157\n",
      "Validation Loss: 0.3157, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.1407\n",
      "    Validation Batch [1/1], Loss: 0.2890\n",
      "Validation Loss: 0.2890, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.1433\n",
      "    Validation Batch [1/1], Loss: 0.2472\n",
      "Validation Loss: 0.2472, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.1384\n",
      "    Validation Batch [1/1], Loss: 0.2476\n",
      "Validation Loss: 0.2476, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.1392\n",
      "    Validation Batch [1/1], Loss: 0.2388\n",
      "Validation Loss: 0.2388, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.1373\n",
      "    Validation Batch [1/1], Loss: 0.2343\n",
      "Validation Loss: 0.2343, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n",
      "Epoch [423/1000] completed, Average Training Loss: 0.1227\n",
      "    Validation Batch [1/1], Loss: 0.2331\n",
      "Validation Loss: 0.2331, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.1352\n",
      "    Validation Batch [1/1], Loss: 0.2213\n",
      "Validation Loss: 0.2213, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.1526\n",
      "    Validation Batch [1/1], Loss: 0.2312\n",
      "Validation Loss: 0.2312, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.1381\n",
      "    Validation Batch [1/1], Loss: 0.2246\n",
      "Validation Loss: 0.2246, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.1155\n",
      "    Validation Batch [1/1], Loss: 0.2414\n",
      "Validation Loss: 0.2414, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.1331\n",
      "    Validation Batch [1/1], Loss: 0.2402\n",
      "Validation Loss: 0.2402, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.1344\n",
      "    Validation Batch [1/1], Loss: 0.2224\n",
      "Validation Loss: 0.2224, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.1148\n",
      "    Validation Batch [1/1], Loss: 0.2226\n",
      "Validation Loss: 0.2226, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.1233\n",
      "    Validation Batch [1/1], Loss: 0.2230\n",
      "Validation Loss: 0.2230, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.1087\n",
      "    Validation Batch [1/1], Loss: 0.2239\n",
      "Validation Loss: 0.2239, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.1450\n",
      "    Validation Batch [1/1], Loss: 0.2317\n",
      "Validation Loss: 0.2317, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.1362\n",
      "    Validation Batch [1/1], Loss: 0.2196\n",
      "Validation Loss: 0.2196, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2213 to 0.2196. Saving model...\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.1287\n",
      "    Validation Batch [1/1], Loss: 0.2185\n",
      "Validation Loss: 0.2185, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.2196 to 0.2185. Saving model...\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.1303\n",
      "    Validation Batch [1/1], Loss: 0.2343\n",
      "Validation Loss: 0.2343, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [437/1000] completed, Average Training Loss: 0.1437\n",
      "    Validation Batch [1/1], Loss: 0.2194\n",
      "Validation Loss: 0.2194, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.1254\n",
      "    Validation Batch [1/1], Loss: 0.2076\n",
      "Validation Loss: 0.2076, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2185 to 0.2076. Saving model...\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.1237\n",
      "    Validation Batch [1/1], Loss: 0.1971\n",
      "Validation Loss: 0.1971, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.2076 to 0.1971. Saving model...\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.1122\n",
      "    Validation Batch [1/1], Loss: 0.2261\n",
      "Validation Loss: 0.2261, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.1147\n",
      "    Validation Batch [1/1], Loss: 0.2303\n",
      "Validation Loss: 0.2303, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.2260\n",
      "Validation Loss: 0.2260, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.1176\n",
      "    Validation Batch [1/1], Loss: 0.2227\n",
      "Validation Loss: 0.2227, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.1103\n",
      "    Validation Batch [1/1], Loss: 0.2255\n",
      "Validation Loss: 0.2255, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.1079\n",
      "    Validation Batch [1/1], Loss: 0.2350\n",
      "Validation Loss: 0.2350, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.1110\n",
      "    Validation Batch [1/1], Loss: 0.2176\n",
      "Validation Loss: 0.2176, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.1231\n",
      "    Validation Batch [1/1], Loss: 0.2069\n",
      "Validation Loss: 0.2069, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.1118\n",
      "    Validation Batch [1/1], Loss: 0.2109\n",
      "Validation Loss: 0.2109, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.1211\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.1161\n",
      "    Validation Batch [1/1], Loss: 0.2075\n",
      "Validation Loss: 0.2075, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.1231\n",
      "    Validation Batch [1/1], Loss: 0.2010\n",
      "Validation Loss: 0.2010, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.1107\n",
      "    Validation Batch [1/1], Loss: 0.2024\n",
      "Validation Loss: 0.2024, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.1203\n",
      "    Validation Batch [1/1], Loss: 0.2205\n",
      "Validation Loss: 0.2205, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.1169\n",
      "    Validation Batch [1/1], Loss: 0.2223\n",
      "Validation Loss: 0.2223, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.1156\n",
      "    Validation Batch [1/1], Loss: 0.2070\n",
      "Validation Loss: 0.2070, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.1068\n",
      "    Validation Batch [1/1], Loss: 0.2059\n",
      "Validation Loss: 0.2059, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.1132\n",
      "    Validation Batch [1/1], Loss: 0.2102\n",
      "Validation Loss: 0.2102, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.1219\n",
      "    Validation Batch [1/1], Loss: 0.2136\n",
      "Validation Loss: 0.2136, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [459/1000] completed, Average Training Loss: 0.1104\n",
      "    Validation Batch [1/1], Loss: 0.2162\n",
      "Validation Loss: 0.2162, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.1108\n",
      "    Validation Batch [1/1], Loss: 0.2144\n",
      "Validation Loss: 0.2144, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.1198\n",
      "    Validation Batch [1/1], Loss: 0.2066\n",
      "Validation Loss: 0.2066, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.1154\n",
      "    Validation Batch [1/1], Loss: 0.2024\n",
      "Validation Loss: 0.2024, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.0991\n",
      "    Validation Batch [1/1], Loss: 0.2098\n",
      "Validation Loss: 0.2098, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.1001\n",
      "    Validation Batch [1/1], Loss: 0.2051\n",
      "Validation Loss: 0.2051, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.1032\n",
      "    Validation Batch [1/1], Loss: 0.2006\n",
      "Validation Loss: 0.2006, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.0976\n",
      "    Validation Batch [1/1], Loss: 0.2072\n",
      "Validation Loss: 0.2072, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.1109\n",
      "    Validation Batch [1/1], Loss: 0.2132\n",
      "Validation Loss: 0.2132, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.1000\n",
      "    Validation Batch [1/1], Loss: 0.2460\n",
      "Validation Loss: 0.2460, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.1081\n",
      "    Validation Batch [1/1], Loss: 0.2464\n",
      "Validation Loss: 0.2464, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n",
      "Epoch [470/1000] completed, Average Training Loss: 0.1015\n",
      "    Validation Batch [1/1], Loss: 0.2142\n",
      "Validation Loss: 0.2142, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.1022\n",
      "    Validation Batch [1/1], Loss: 0.2017\n",
      "Validation Loss: 0.2017, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.2045\n",
      "Validation Loss: 0.2045, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.1152\n",
      "    Validation Batch [1/1], Loss: 0.2518\n",
      "Validation Loss: 0.2518, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0936\n",
      "    Validation Batch [1/1], Loss: 0.2602\n",
      "Validation Loss: 0.2602, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.1078\n",
      "    Validation Batch [1/1], Loss: 0.2215\n",
      "Validation Loss: 0.2215, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0999\n",
      "    Validation Batch [1/1], Loss: 0.2069\n",
      "Validation Loss: 0.2069, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.1075\n",
      "    Validation Batch [1/1], Loss: 0.1961\n",
      "Validation Loss: 0.1961, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1971 to 0.1961. Saving model...\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0976\n",
      "    Validation Batch [1/1], Loss: 0.2411\n",
      "Validation Loss: 0.2411, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.1173\n",
      "    Validation Batch [1/1], Loss: 0.1992\n",
      "Validation Loss: 0.1992, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.1039\n",
      "    Validation Batch [1/1], Loss: 0.2058\n",
      "Validation Loss: 0.2058, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.0980\n",
      "    Validation Batch [1/1], Loss: 0.2054\n",
      "Validation Loss: 0.2054, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [482/1000] completed, Average Training Loss: 0.0861\n",
      "    Validation Batch [1/1], Loss: 0.2179\n",
      "Validation Loss: 0.2179, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0858\n",
      "    Validation Batch [1/1], Loss: 0.2047\n",
      "Validation Loss: 0.2047, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.1009\n",
      "    Validation Batch [1/1], Loss: 0.2053\n",
      "Validation Loss: 0.2053, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.1044\n",
      "    Validation Batch [1/1], Loss: 0.2123\n",
      "Validation Loss: 0.2123, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0860\n",
      "    Validation Batch [1/1], Loss: 0.2218\n",
      "Validation Loss: 0.2218, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.1033\n",
      "    Validation Batch [1/1], Loss: 0.2116\n",
      "Validation Loss: 0.2116, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0907\n",
      "    Validation Batch [1/1], Loss: 0.1930\n",
      "Validation Loss: 0.1930, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1961 to 0.1930. Saving model...\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0937\n",
      "    Validation Batch [1/1], Loss: 0.2013\n",
      "Validation Loss: 0.2013, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0911\n",
      "    Validation Batch [1/1], Loss: 0.1997\n",
      "Validation Loss: 0.1997, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0929\n",
      "    Validation Batch [1/1], Loss: 0.1977\n",
      "Validation Loss: 0.1977, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0908\n",
      "    Validation Batch [1/1], Loss: 0.1917\n",
      "Validation Loss: 0.1917, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1930 to 0.1917. Saving model...\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0840\n",
      "    Validation Batch [1/1], Loss: 0.1950\n",
      "Validation Loss: 0.1950, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0959\n",
      "    Validation Batch [1/1], Loss: 0.1987\n",
      "Validation Loss: 0.1987, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0858\n",
      "    Validation Batch [1/1], Loss: 0.2209\n",
      "Validation Loss: 0.2209, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0907\n",
      "    Validation Batch [1/1], Loss: 0.2237\n",
      "Validation Loss: 0.2237, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0953\n",
      "    Validation Batch [1/1], Loss: 0.2114\n",
      "Validation Loss: 0.2114, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.1024\n",
      "    Validation Batch [1/1], Loss: 0.1996\n",
      "Validation Loss: 0.1996, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.1016\n",
      "    Validation Batch [1/1], Loss: 0.1968\n",
      "Validation Loss: 0.1968, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0936\n",
      "    Validation Batch [1/1], Loss: 0.2027\n",
      "Validation Loss: 0.2027, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0846\n",
      "    Validation Batch [1/1], Loss: 0.1837\n",
      "Validation Loss: 0.1837, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1917 to 0.1837. Saving model...\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0805\n",
      "    Validation Batch [1/1], Loss: 0.1849\n",
      "Validation Loss: 0.1849, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0855\n",
      "    Validation Batch [1/1], Loss: 0.1915\n",
      "Validation Loss: 0.1915, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0811\n",
      "    Validation Batch [1/1], Loss: 0.2272\n",
      "Validation Loss: 0.2272, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0853\n",
      "    Validation Batch [1/1], Loss: 0.2478\n",
      "Validation Loss: 0.2478, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [506/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.1941\n",
      "Validation Loss: 0.1941, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0825\n",
      "    Validation Batch [1/1], Loss: 0.1987\n",
      "Validation Loss: 0.1987, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0892\n",
      "    Validation Batch [1/1], Loss: 0.1861\n",
      "Validation Loss: 0.1861, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0895\n",
      "    Validation Batch [1/1], Loss: 0.2148\n",
      "Validation Loss: 0.2148, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0739\n",
      "    Validation Batch [1/1], Loss: 0.1975\n",
      "Validation Loss: 0.1975, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0872\n",
      "    Validation Batch [1/1], Loss: 0.1898\n",
      "Validation Loss: 0.1898, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0823\n",
      "    Validation Batch [1/1], Loss: 0.1948\n",
      "Validation Loss: 0.1948, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0919\n",
      "    Validation Batch [1/1], Loss: 0.1899\n",
      "Validation Loss: 0.1899, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0722\n",
      "    Validation Batch [1/1], Loss: 0.2308\n",
      "Validation Loss: 0.2308, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0842\n",
      "    Validation Batch [1/1], Loss: 0.2011\n",
      "Validation Loss: 0.2011, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0735\n",
      "    Validation Batch [1/1], Loss: 0.1886\n",
      "Validation Loss: 0.1886, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0850\n",
      "    Validation Batch [1/1], Loss: 0.1897\n",
      "Validation Loss: 0.1897, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0702\n",
      "    Validation Batch [1/1], Loss: 0.1948\n",
      "Validation Loss: 0.1948, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n",
      "Epoch [519/1000] completed, Average Training Loss: 0.0869\n",
      "    Validation Batch [1/1], Loss: 0.2061\n",
      "Validation Loss: 0.2061, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0710\n",
      "    Validation Batch [1/1], Loss: 0.2075\n",
      "Validation Loss: 0.2075, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0832\n",
      "    Validation Batch [1/1], Loss: 0.1825\n",
      "Validation Loss: 0.1825, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.1837 to 0.1825. Saving model...\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0840\n",
      "    Validation Batch [1/1], Loss: 0.1814\n",
      "Validation Loss: 0.1814, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1825 to 0.1814. Saving model...\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0800\n",
      "    Validation Batch [1/1], Loss: 0.1895\n",
      "Validation Loss: 0.1895, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0774\n",
      "    Validation Batch [1/1], Loss: 0.2044\n",
      "Validation Loss: 0.2044, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0824\n",
      "    Validation Batch [1/1], Loss: 0.2119\n",
      "Validation Loss: 0.2119, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0669\n",
      "    Validation Batch [1/1], Loss: 0.2096\n",
      "Validation Loss: 0.2096, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0823\n",
      "    Validation Batch [1/1], Loss: 0.1858\n",
      "Validation Loss: 0.1858, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/1000] completed, Average Training Loss: 0.0877\n",
      "    Validation Batch [1/1], Loss: 0.1746\n",
      "Validation Loss: 0.1746, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1814 to 0.1746. Saving model...\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0714\n",
      "    Validation Batch [1/1], Loss: 0.1848\n",
      "Validation Loss: 0.1848, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0779\n",
      "    Validation Batch [1/1], Loss: 0.2031\n",
      "Validation Loss: 0.2031, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0757\n",
      "    Validation Batch [1/1], Loss: 0.1917\n",
      "Validation Loss: 0.1917, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0711\n",
      "    Validation Batch [1/1], Loss: 0.2011\n",
      "Validation Loss: 0.2011, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0908\n",
      "    Validation Batch [1/1], Loss: 0.2005\n",
      "Validation Loss: 0.2005, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0854\n",
      "    Validation Batch [1/1], Loss: 0.1970\n",
      "Validation Loss: 0.1970, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0747\n",
      "    Validation Batch [1/1], Loss: 0.1944\n",
      "Validation Loss: 0.1944, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0734\n",
      "    Validation Batch [1/1], Loss: 0.1926\n",
      "Validation Loss: 0.1926, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0846\n",
      "    Validation Batch [1/1], Loss: 0.2155\n",
      "Validation Loss: 0.2155, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0874\n",
      "    Validation Batch [1/1], Loss: 0.2097\n",
      "Validation Loss: 0.2097, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0806\n",
      "    Validation Batch [1/1], Loss: 0.1961\n",
      "Validation Loss: 0.1961, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.1840\n",
      "Validation Loss: 0.1840, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0738\n",
      "    Validation Batch [1/1], Loss: 0.1846\n",
      "Validation Loss: 0.1846, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0758\n",
      "    Validation Batch [1/1], Loss: 0.1818\n",
      "Validation Loss: 0.1818, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0700\n",
      "    Validation Batch [1/1], Loss: 0.1767\n",
      "Validation Loss: 0.1767, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0701\n",
      "    Validation Batch [1/1], Loss: 0.1747\n",
      "Validation Loss: 0.1747, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0743\n",
      "    Validation Batch [1/1], Loss: 0.1800\n",
      "Validation Loss: 0.1800, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0711\n",
      "    Validation Batch [1/1], Loss: 0.1858\n",
      "Validation Loss: 0.1858, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0694\n",
      "    Validation Batch [1/1], Loss: 0.1929\n",
      "Validation Loss: 0.1929, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0766\n",
      "    Validation Batch [1/1], Loss: 0.1987\n",
      "Validation Loss: 0.1987, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0754\n",
      "    Validation Batch [1/1], Loss: 0.2009\n",
      "Validation Loss: 0.2009, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0718\n",
      "    Validation Batch [1/1], Loss: 0.1895\n",
      "Validation Loss: 0.1895, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [551/1000] completed, Average Training Loss: 0.0667\n",
      "    Validation Batch [1/1], Loss: 0.1903\n",
      "Validation Loss: 0.1903, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0699\n",
      "    Validation Batch [1/1], Loss: 0.1983\n",
      "Validation Loss: 0.1983, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0637\n",
      "    Validation Batch [1/1], Loss: 0.1898\n",
      "Validation Loss: 0.1898, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0738\n",
      "    Validation Batch [1/1], Loss: 0.1926\n",
      "Validation Loss: 0.1926, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0611\n",
      "    Validation Batch [1/1], Loss: 0.2267\n",
      "Validation Loss: 0.2267, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.2276\n",
      "Validation Loss: 0.2276, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0690\n",
      "    Validation Batch [1/1], Loss: 0.1857\n",
      "Validation Loss: 0.1857, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.1653\n",
      "Validation Loss: 0.1653, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1746 to 0.1653. Saving model...\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0727\n",
      "    Validation Batch [1/1], Loss: 0.1694\n",
      "Validation Loss: 0.1694, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0643\n",
      "    Validation Batch [1/1], Loss: 0.1739\n",
      "Validation Loss: 0.1739, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0738\n",
      "    Validation Batch [1/1], Loss: 0.1788\n",
      "Validation Loss: 0.1788, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0668\n",
      "    Validation Batch [1/1], Loss: 0.2068\n",
      "Validation Loss: 0.2068, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0567\n",
      "    Validation Batch [1/1], Loss: 0.2192\n",
      "Validation Loss: 0.2192, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0634\n",
      "    Validation Batch [1/1], Loss: 0.2242\n",
      "Validation Loss: 0.2242, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0652\n",
      "    Validation Batch [1/1], Loss: 0.2286\n",
      "Validation Loss: 0.2286, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.1992\n",
      "Validation Loss: 0.1992, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.1765\n",
      "Validation Loss: 0.1765, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0696\n",
      "    Validation Batch [1/1], Loss: 0.1836\n",
      "Validation Loss: 0.1836, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0667\n",
      "    Validation Batch [1/1], Loss: 0.1836\n",
      "Validation Loss: 0.1836, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0645\n",
      "    Validation Batch [1/1], Loss: 0.1781\n",
      "Validation Loss: 0.1781, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0618\n",
      "    Validation Batch [1/1], Loss: 0.1756\n",
      "Validation Loss: 0.1756, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0713\n",
      "    Validation Batch [1/1], Loss: 0.1762\n",
      "Validation Loss: 0.1762, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0575\n",
      "    Validation Batch [1/1], Loss: 0.1787\n",
      "Validation Loss: 0.1787, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0755\n",
      "    Validation Batch [1/1], Loss: 0.1850\n",
      "Validation Loss: 0.1850, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [575/1000] completed, Average Training Loss: 0.0630\n",
      "    Validation Batch [1/1], Loss: 0.1779\n",
      "Validation Loss: 0.1779, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0546\n",
      "    Validation Batch [1/1], Loss: 0.1667\n",
      "Validation Loss: 0.1667, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0584\n",
      "    Validation Batch [1/1], Loss: 0.1579\n",
      "Validation Loss: 0.1579, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1653 to 0.1579. Saving model...\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0592\n",
      "    Validation Batch [1/1], Loss: 0.1658\n",
      "Validation Loss: 0.1658, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0618\n",
      "    Validation Batch [1/1], Loss: 0.2265\n",
      "Validation Loss: 0.2265, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0707\n",
      "    Validation Batch [1/1], Loss: 0.2278\n",
      "Validation Loss: 0.2278, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0537\n",
      "    Validation Batch [1/1], Loss: 0.1835\n",
      "Validation Loss: 0.1835, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0578\n",
      "    Validation Batch [1/1], Loss: 0.2006\n",
      "Validation Loss: 0.2006, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0606\n",
      "    Validation Batch [1/1], Loss: 0.2017\n",
      "Validation Loss: 0.2017, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0524\n",
      "    Validation Batch [1/1], Loss: 0.1886\n",
      "Validation Loss: 0.1886, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0646\n",
      "    Validation Batch [1/1], Loss: 0.2000\n",
      "Validation Loss: 0.2000, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0733\n",
      "    Validation Batch [1/1], Loss: 0.2293\n",
      "Validation Loss: 0.2293, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0547\n",
      "    Validation Batch [1/1], Loss: 0.2260\n",
      "Validation Loss: 0.2260, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0603\n",
      "    Validation Batch [1/1], Loss: 0.2130\n",
      "Validation Loss: 0.2130, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0582\n",
      "    Validation Batch [1/1], Loss: 0.1878\n",
      "Validation Loss: 0.1878, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.1847\n",
      "Validation Loss: 0.1847, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0562\n",
      "    Validation Batch [1/1], Loss: 0.1959\n",
      "Validation Loss: 0.1959, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0576\n",
      "    Validation Batch [1/1], Loss: 0.1958\n",
      "Validation Loss: 0.1958, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0562\n",
      "    Validation Batch [1/1], Loss: 0.1986\n",
      "Validation Loss: 0.1986, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0651\n",
      "    Validation Batch [1/1], Loss: 0.1910\n",
      "Validation Loss: 0.1910, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.1830\n",
      "Validation Loss: 0.1830, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0522\n",
      "    Validation Batch [1/1], Loss: 0.1811\n",
      "Validation Loss: 0.1811, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0611\n",
      "    Validation Batch [1/1], Loss: 0.1812\n",
      "Validation Loss: 0.1812, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1872\n",
      "Validation Loss: 0.1872, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0546\n",
      "    Validation Batch [1/1], Loss: 0.1876\n",
      "Validation Loss: 0.1876, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0682\n",
      "    Validation Batch [1/1], Loss: 0.1808\n",
      "Validation Loss: 0.1808, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.2120\n",
      "Validation Loss: 0.2120, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0500\n",
      "    Validation Batch [1/1], Loss: 0.2487\n",
      "Validation Loss: 0.2487, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0583\n",
      "    Validation Batch [1/1], Loss: 0.2101\n",
      "Validation Loss: 0.2101, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0579\n",
      "    Validation Batch [1/1], Loss: 0.1852\n",
      "Validation Loss: 0.1852, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.1951\n",
      "Validation Loss: 0.1951, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0655\n",
      "    Validation Batch [1/1], Loss: 0.1971\n",
      "Validation Loss: 0.1971, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0601\n",
      "    Validation Batch [1/1], Loss: 0.2178\n",
      "Validation Loss: 0.2178, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0513\n",
      "    Validation Batch [1/1], Loss: 0.2051\n",
      "Validation Loss: 0.2051, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0523\n",
      "    Validation Batch [1/1], Loss: 0.1812\n",
      "Validation Loss: 0.1812, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0551\n",
      "    Validation Batch [1/1], Loss: 0.1834\n",
      "Validation Loss: 0.1834, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0558\n",
      "    Validation Batch [1/1], Loss: 0.1978\n",
      "Validation Loss: 0.1978, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0636\n",
      "    Validation Batch [1/1], Loss: 0.1963\n",
      "Validation Loss: 0.1963, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.1723\n",
      "Validation Loss: 0.1723, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0537\n",
      "    Validation Batch [1/1], Loss: 0.1665\n",
      "Validation Loss: 0.1665, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.1721\n",
      "Validation Loss: 0.1721, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0572\n",
      "    Validation Batch [1/1], Loss: 0.1777\n",
      "Validation Loss: 0.1777, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0623\n",
      "    Validation Batch [1/1], Loss: 0.1851\n",
      "Validation Loss: 0.1851, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0495\n",
      "    Validation Batch [1/1], Loss: 0.1900\n",
      "Validation Loss: 0.1900, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0450\n",
      "    Validation Batch [1/1], Loss: 0.1873\n",
      "Validation Loss: 0.1873, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0562\n",
      "    Validation Batch [1/1], Loss: 0.1852\n",
      "Validation Loss: 0.1852, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0488\n",
      "    Validation Batch [1/1], Loss: 0.1757\n",
      "Validation Loss: 0.1757, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [622/1000] completed, Average Training Loss: 0.0442\n",
      "    Validation Batch [1/1], Loss: 0.1704\n",
      "Validation Loss: 0.1704, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.1714\n",
      "Validation Loss: 0.1714, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0565\n",
      "    Validation Batch [1/1], Loss: 0.1719\n",
      "Validation Loss: 0.1719, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0557\n",
      "    Validation Batch [1/1], Loss: 0.1735\n",
      "Validation Loss: 0.1735, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0499\n",
      "    Validation Batch [1/1], Loss: 0.1780\n",
      "Validation Loss: 0.1780, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0558\n",
      "    Validation Batch [1/1], Loss: 0.1644\n",
      "Validation Loss: 0.1644, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0573\n",
      "    Validation Batch [1/1], Loss: 0.1682\n",
      "Validation Loss: 0.1682, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0501\n",
      "    Validation Batch [1/1], Loss: 0.1728\n",
      "Validation Loss: 0.1728, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0444\n",
      "    Validation Batch [1/1], Loss: 0.1669\n",
      "Validation Loss: 0.1669, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0553\n",
      "    Validation Batch [1/1], Loss: 0.1830\n",
      "Validation Loss: 0.1830, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0491\n",
      "    Validation Batch [1/1], Loss: 0.1861\n",
      "Validation Loss: 0.1861, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0510\n",
      "    Validation Batch [1/1], Loss: 0.1693\n",
      "Validation Loss: 0.1693, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0442\n",
      "    Validation Batch [1/1], Loss: 0.1773\n",
      "Validation Loss: 0.1773, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0548\n",
      "    Validation Batch [1/1], Loss: 0.1957\n",
      "Validation Loss: 0.1957, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0543\n",
      "    Validation Batch [1/1], Loss: 0.2477\n",
      "Validation Loss: 0.2477, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.2790\n",
      "Validation Loss: 0.2790, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.2087\n",
      "Validation Loss: 0.2087, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0617\n",
      "    Validation Batch [1/1], Loss: 0.1976\n",
      "Validation Loss: 0.1976, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0594\n",
      "    Validation Batch [1/1], Loss: 0.1889\n",
      "Validation Loss: 0.1889, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0487\n",
      "    Validation Batch [1/1], Loss: 0.1756\n",
      "Validation Loss: 0.1756, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0495\n",
      "    Validation Batch [1/1], Loss: 0.1914\n",
      "Validation Loss: 0.1914, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.1716\n",
      "Validation Loss: 0.1716, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1601\n",
      "Validation Loss: 0.1601, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0446\n",
      "    Validation Batch [1/1], Loss: 0.1627\n",
      "Validation Loss: 0.1627, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.1642\n",
      "Validation Loss: 0.1642, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.1719\n",
      "Validation Loss: 0.1719, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0479\n",
      "    Validation Batch [1/1], Loss: 0.1772\n",
      "Validation Loss: 0.1772, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0459\n",
      "    Validation Batch [1/1], Loss: 0.1756\n",
      "Validation Loss: 0.1756, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0559\n",
      "    Validation Batch [1/1], Loss: 0.1732\n",
      "Validation Loss: 0.1732, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0462\n",
      "    Validation Batch [1/1], Loss: 0.1737\n",
      "Validation Loss: 0.1737, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0442\n",
      "    Validation Batch [1/1], Loss: 0.1796\n",
      "Validation Loss: 0.1796, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.1802\n",
      "Validation Loss: 0.1802, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.1837\n",
      "Validation Loss: 0.1837, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0520\n",
      "    Validation Batch [1/1], Loss: 0.1842\n",
      "Validation Loss: 0.1842, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0432\n",
      "    Validation Batch [1/1], Loss: 0.1704\n",
      "Validation Loss: 0.1704, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0495\n",
      "    Validation Batch [1/1], Loss: 0.1678\n",
      "Validation Loss: 0.1678, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.1626\n",
      "Validation Loss: 0.1626, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0381\n",
      "    Validation Batch [1/1], Loss: 0.1573\n",
      "Validation Loss: 0.1573, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1579 to 0.1573. Saving model...\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.1751\n",
      "Validation Loss: 0.1751, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0484\n",
      "    Validation Batch [1/1], Loss: 0.2070\n",
      "Validation Loss: 0.2070, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0464\n",
      "    Validation Batch [1/1], Loss: 0.2175\n",
      "Validation Loss: 0.2175, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0508\n",
      "    Validation Batch [1/1], Loss: 0.1850\n",
      "Validation Loss: 0.1850, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0501\n",
      "    Validation Batch [1/1], Loss: 0.1809\n",
      "Validation Loss: 0.1809, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.1824\n",
      "Validation Loss: 0.1824, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0405\n",
      "    Validation Batch [1/1], Loss: 0.1759\n",
      "Validation Loss: 0.1759, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1700\n",
      "Validation Loss: 0.1700, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0525\n",
      "    Validation Batch [1/1], Loss: 0.1743\n",
      "Validation Loss: 0.1743, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.1775\n",
      "Validation Loss: 0.1775, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0463\n",
      "    Validation Batch [1/1], Loss: 0.1690\n",
      "Validation Loss: 0.1690, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.1673\n",
      "Validation Loss: 0.1673, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.1726\n",
      "Validation Loss: 0.1726, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.1871\n",
      "Validation Loss: 0.1871, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.2072\n",
      "Validation Loss: 0.2072, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0394\n",
      "    Validation Batch [1/1], Loss: 0.1900\n",
      "Validation Loss: 0.1900, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.1768\n",
      "Validation Loss: 0.1768, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0561\n",
      "    Validation Batch [1/1], Loss: 0.1742\n",
      "Validation Loss: 0.1742, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.1782\n",
      "Validation Loss: 0.1782, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.1754\n",
      "Validation Loss: 0.1754, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0400\n",
      "    Validation Batch [1/1], Loss: 0.1753\n",
      "Validation Loss: 0.1753, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.2099\n",
      "Validation Loss: 0.2099, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0418\n",
      "    Validation Batch [1/1], Loss: 0.2200\n",
      "Validation Loss: 0.2200, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.2057\n",
      "Validation Loss: 0.2057, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0490\n",
      "    Validation Batch [1/1], Loss: 0.1974\n",
      "Validation Loss: 0.1974, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.1738\n",
      "Validation Loss: 0.1738, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.1679\n",
      "Validation Loss: 0.1679, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0409\n",
      "    Validation Batch [1/1], Loss: 0.1654\n",
      "Validation Loss: 0.1654, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.1697\n",
      "Validation Loss: 0.1697, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0459\n",
      "    Validation Batch [1/1], Loss: 0.1719\n",
      "Validation Loss: 0.1719, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1717\n",
      "Validation Loss: 0.1717, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0393\n",
      "    Validation Batch [1/1], Loss: 0.1663\n",
      "Validation Loss: 0.1663, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0432\n",
      "    Validation Batch [1/1], Loss: 0.1631\n",
      "Validation Loss: 0.1631, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.1742\n",
      "Validation Loss: 0.1742, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0501\n",
      "    Validation Batch [1/1], Loss: 0.1684\n",
      "Validation Loss: 0.1684, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0379\n",
      "    Validation Batch [1/1], Loss: 0.1667\n",
      "Validation Loss: 0.1667, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.1754\n",
      "Validation Loss: 0.1754, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0379\n",
      "    Validation Batch [1/1], Loss: 0.1803\n",
      "Validation Loss: 0.1803, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0400\n",
      "    Validation Batch [1/1], Loss: 0.1836\n",
      "Validation Loss: 0.1836, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.1862\n",
      "Validation Loss: 0.1862, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0347\n",
      "    Validation Batch [1/1], Loss: 0.1741\n",
      "Validation Loss: 0.1741, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0454\n",
      "    Validation Batch [1/1], Loss: 0.1591\n",
      "Validation Loss: 0.1591, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0421\n",
      "    Validation Batch [1/1], Loss: 0.1628\n",
      "Validation Loss: 0.1628, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.1649\n",
      "Validation Loss: 0.1649, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0369\n",
      "    Validation Batch [1/1], Loss: 0.1693\n",
      "Validation Loss: 0.1693, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0546\n",
      "    Validation Batch [1/1], Loss: 0.1760\n",
      "Validation Loss: 0.1760, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.1721\n",
      "Validation Loss: 0.1721, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0463\n",
      "    Validation Batch [1/1], Loss: 0.1658\n",
      "Validation Loss: 0.1658, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0456\n",
      "    Validation Batch [1/1], Loss: 0.1738\n",
      "Validation Loss: 0.1738, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0421\n",
      "    Validation Batch [1/1], Loss: 0.1773\n",
      "Validation Loss: 0.1773, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.2025\n",
      "Validation Loss: 0.2025, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.2516\n",
      "Validation Loss: 0.2516, Validation Accuracy: 92.50%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.2104\n",
      "Validation Loss: 0.2104, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [713/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.1717\n",
      "Validation Loss: 0.1717, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.1743\n",
      "Validation Loss: 0.1743, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0356\n",
      "    Validation Batch [1/1], Loss: 0.1696\n",
      "Validation Loss: 0.1696, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.1919\n",
      "Validation Loss: 0.1919, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.2191\n",
      "Validation Loss: 0.2191, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0461\n",
      "    Validation Batch [1/1], Loss: 0.2082\n",
      "Validation Loss: 0.2082, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.1690\n",
      "Validation Loss: 0.1690, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.1616\n",
      "Validation Loss: 0.1616, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0410\n",
      "    Validation Batch [1/1], Loss: 0.1884\n",
      "Validation Loss: 0.1884, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.1780\n",
      "Validation Loss: 0.1780, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.1600\n",
      "Validation Loss: 0.1600, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0356\n",
      "    Validation Batch [1/1], Loss: 0.1662\n",
      "Validation Loss: 0.1662, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.1766\n",
      "Validation Loss: 0.1766, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0377\n",
      "    Validation Batch [1/1], Loss: 0.1827\n",
      "Validation Loss: 0.1827, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0373\n",
      "    Validation Batch [1/1], Loss: 0.1815\n",
      "Validation Loss: 0.1815, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0416\n",
      "    Validation Batch [1/1], Loss: 0.1553\n",
      "Validation Loss: 0.1553, Validation Accuracy: 96.25%\n",
      "Validation loss improved from 0.1573 to 0.1553. Saving model...\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0388\n",
      "    Validation Batch [1/1], Loss: 0.1454\n",
      "Validation Loss: 0.1454, Validation Accuracy: 95.00%\n",
      "Validation loss improved from 0.1553 to 0.1454. Saving model...\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.1458\n",
      "Validation Loss: 0.1458, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.1527\n",
      "Validation Loss: 0.1527, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.1703\n",
      "Validation Loss: 0.1703, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.1861\n",
      "Validation Loss: 0.1861, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.1840\n",
      "Validation Loss: 0.1840, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0380\n",
      "    Validation Batch [1/1], Loss: 0.1732\n",
      "Validation Loss: 0.1732, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [736/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.1696\n",
      "Validation Loss: 0.1696, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0335\n",
      "    Validation Batch [1/1], Loss: 0.1656\n",
      "Validation Loss: 0.1656, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.1738\n",
      "Validation Loss: 0.1738, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.2094\n",
      "Validation Loss: 0.2094, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.2232\n",
      "Validation Loss: 0.2232, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0402\n",
      "    Validation Batch [1/1], Loss: 0.1866\n",
      "Validation Loss: 0.1866, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.1848\n",
      "Validation Loss: 0.1848, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.1902\n",
      "Validation Loss: 0.1902, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0397\n",
      "    Validation Batch [1/1], Loss: 0.1861\n",
      "Validation Loss: 0.1861, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.1698\n",
      "Validation Loss: 0.1698, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n",
      "Epoch [746/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.1766\n",
      "Validation Loss: 0.1766, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0432\n",
      "    Validation Batch [1/1], Loss: 0.1735\n",
      "Validation Loss: 0.1735, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0472\n",
      "    Validation Batch [1/1], Loss: 0.1644\n",
      "Validation Loss: 0.1644, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0393\n",
      "    Validation Batch [1/1], Loss: 0.1684\n",
      "Validation Loss: 0.1684, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.1693\n",
      "Validation Loss: 0.1693, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.1709\n",
      "Validation Loss: 0.1709, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0380\n",
      "    Validation Batch [1/1], Loss: 0.2103\n",
      "Validation Loss: 0.2103, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0376\n",
      "    Validation Batch [1/1], Loss: 0.2398\n",
      "Validation Loss: 0.2398, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0378\n",
      "    Validation Batch [1/1], Loss: 0.2183\n",
      "Validation Loss: 0.2183, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0354\n",
      "    Validation Batch [1/1], Loss: 0.1836\n",
      "Validation Loss: 0.1836, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.1862\n",
      "Validation Loss: 0.1862, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0288\n",
      "    Validation Batch [1/1], Loss: 0.1947\n",
      "Validation Loss: 0.1947, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1907\n",
      "Validation Loss: 0.1907, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.1911\n",
      "Validation Loss: 0.1911, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.1903\n",
      "Validation Loss: 0.1903, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.1750\n",
      "Validation Loss: 0.1750, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.1585\n",
      "Validation Loss: 0.1585, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.1549\n",
      "Validation Loss: 0.1549, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.1578\n",
      "Validation Loss: 0.1578, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0267\n",
      "    Validation Batch [1/1], Loss: 0.1629\n",
      "Validation Loss: 0.1629, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.1816\n",
      "Validation Loss: 0.1816, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0455\n",
      "    Validation Batch [1/1], Loss: 0.1780\n",
      "Validation Loss: 0.1780, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n",
      "Epoch [768/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.1673\n",
      "Validation Loss: 0.1673, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.1652\n",
      "Validation Loss: 0.1652, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.1745\n",
      "Validation Loss: 0.1745, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.1839\n",
      "Validation Loss: 0.1839, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.1886\n",
      "Validation Loss: 0.1886, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0345\n",
      "    Validation Batch [1/1], Loss: 0.1960\n",
      "Validation Loss: 0.1960, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0330\n",
      "    Validation Batch [1/1], Loss: 0.1943\n",
      "Validation Loss: 0.1943, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.1854\n",
      "Validation Loss: 0.1854, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n",
      "Epoch [776/1000] completed, Average Training Loss: 0.0334\n",
      "    Validation Batch [1/1], Loss: 0.1704\n",
      "Validation Loss: 0.1704, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.1659\n",
      "Validation Loss: 0.1659, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.1617\n",
      "Validation Loss: 0.1617, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0314\n",
      "    Validation Batch [1/1], Loss: 0.1608\n",
      "Validation Loss: 0.1608, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n",
      "Epoch [780/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.1746\n",
      "Validation Loss: 0.1746, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n",
      "Epoch [781/1000] completed, Average Training Loss: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1975\n",
      "Validation Loss: 0.1975, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.1932\n",
      "Validation Loss: 0.1932, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.1796\n",
      "Validation Loss: 0.1796, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.1798\n",
      "Validation Loss: 0.1798, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n",
      "Epoch [785/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.1753\n",
      "Validation Loss: 0.1753, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.1653\n",
      "Validation Loss: 0.1653, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0369\n",
      "    Validation Batch [1/1], Loss: 0.1544\n",
      "Validation Loss: 0.1544, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.1481\n",
      "Validation Loss: 0.1481, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.1457\n",
      "Validation Loss: 0.1457, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.1680\n",
      "Validation Loss: 0.1680, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.1949\n",
      "Validation Loss: 0.1949, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n",
      "Epoch [792/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.2195\n",
      "Validation Loss: 0.2195, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0353\n",
      "    Validation Batch [1/1], Loss: 0.2004\n",
      "Validation Loss: 0.2004, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.1716\n",
      "Validation Loss: 0.1716, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.1652\n",
      "Validation Loss: 0.1652, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.1671\n",
      "Validation Loss: 0.1671, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.1729\n",
      "Validation Loss: 0.1729, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.1744\n",
      "Validation Loss: 0.1744, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.1747\n",
      "Validation Loss: 0.1747, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n",
      "Epoch [800/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.1703\n",
      "Validation Loss: 0.1703, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.1737\n",
      "Validation Loss: 0.1737, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.1792\n",
      "Validation Loss: 0.1792, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [803/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.1821\n",
      "Validation Loss: 0.1821, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.1922\n",
      "Validation Loss: 0.1922, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n",
      "Epoch [805/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.1992\n",
      "Validation Loss: 0.1992, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0327\n",
      "    Validation Batch [1/1], Loss: 0.1963\n",
      "Validation Loss: 0.1963, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.1943\n",
      "Validation Loss: 0.1943, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0275\n",
      "    Validation Batch [1/1], Loss: 0.1927\n",
      "Validation Loss: 0.1927, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n",
      "Epoch [809/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.1984\n",
      "Validation Loss: 0.1984, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.1970\n",
      "Validation Loss: 0.1970, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.1923\n",
      "Validation Loss: 0.1923, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.1926\n",
      "Validation Loss: 0.1926, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0343\n",
      "    Validation Batch [1/1], Loss: 0.1927\n",
      "Validation Loss: 0.1927, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n",
      "Epoch [814/1000] completed, Average Training Loss: 0.0279\n",
      "    Validation Batch [1/1], Loss: 0.1855\n",
      "Validation Loss: 0.1855, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1808\n",
      "Validation Loss: 0.1808, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.1744\n",
      "Validation Loss: 0.1744, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.1604\n",
      "Validation Loss: 0.1604, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.1559\n",
      "Validation Loss: 0.1559, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.1595\n",
      "Validation Loss: 0.1595, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0267\n",
      "    Validation Batch [1/1], Loss: 0.1640\n",
      "Validation Loss: 0.1640, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.1714\n",
      "Validation Loss: 0.1714, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0335\n",
      "    Validation Batch [1/1], Loss: 0.1800\n",
      "Validation Loss: 0.1800, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n",
      "Epoch [823/1000] completed, Average Training Loss: 0.0279\n",
      "    Validation Batch [1/1], Loss: 0.1957\n",
      "Validation Loss: 0.1957, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [824/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.2097\n",
      "Validation Loss: 0.2097, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n",
      "Epoch [825/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.2045\n",
      "Validation Loss: 0.2045, Validation Accuracy: 93.75%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1882\n",
      "Validation Loss: 0.1882, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n",
      "Epoch [827/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.1686\n",
      "Validation Loss: 0.1686, Validation Accuracy: 95.00%\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n",
      "Epoch [828/1000] completed, Average Training Loss: 0.0270\n",
      "    Validation Batch [1/1], Loss: 0.1657\n",
      "Validation Loss: 0.1657, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.1664\n",
      "Validation Loss: 0.1664, Validation Accuracy: 96.25%\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 829. No improvement for 100 epochs.\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACRHUlEQVR4nOzdeVxUVf8H8M+9w74LigwugLgiuYvinivuW4+VqWVquVVq/nLLpVVtebLStJ5yKbM0MTU1XFLTFMVyFzM1FFNwAQXZYeb+/pgYGRhm7sAMMwOf9+s1L+XOufeegbHmwznnewRJkiQQERERERFRqURrd4CIiIiIiMjWMTgREREREREZweBERERERERkBIMTERERERGREQxORERERERERjA4ERERERERGcHgREREREREZASDExERERERkREMTkREREREREYwOBGR2QmCIOtx8ODBct1n0aJFEAShTOcePHjQLH2wdc899xyCg4NLff7u3btwcnLCU089VWqb9PR0uLm5YdCgQbLvu3btWgiCgGvXrsnuS1GCIGDRokWy71fo1q1bWLRoEU6fPl3iufK8X8orODgYAwYMsMq9TZWSkoI5c+YgLCwMbm5u8PLyQvv27bFixQrk5+dbu3sldOvWrdT/xsh9v1lS4fvu3r171u4KEZWTg7U7QESVT2xsrM7Xb731Fg4cOID9+/frHA8LCyvXfcaPH4+oqKgynduqVSvExsaWuw/2rkaNGhg0aBC2bt2K+/fvo1q1aiXafP/998jOzsa4cePKda/58+fjlVdeKdc1jLl16xbeeOMNBAcHo0WLFjrPlef9UlX8+eef6N27NzIyMvDqq6+iQ4cOyM7Oxo4dO/DKK6/ghx9+wK5du+Dm5mbtruqoV68evv322xLHnZ2drdAbIqqsGJyIyOzat2+v83WNGjUgimKJ48VlZWWZ9IGsdu3aqF27dpn6WPhbdALGjRuH6OhofPvtt5g6dWqJ51evXo2aNWuif//+5bpPaGhouc4vr/K8X6oClUqF4cOHIz09HXFxcWjYsKH2uX79+qFr16546qmnMGPGDKxatarC+iVJEnJycuDq6lpqG1dXV/57JiKL41Q9IrKKbt26ITw8HIcOHUKHDh3g5uaG559/HgCwceNG9O7dG0qlEq6urmjSpAlmz56NzMxMnWvom3pVOCUqJiYGrVq1gqurKxo3bozVq1frtNM3Ve+5556Dh4cHrly5gn79+sHDwwN16tTBq6++itzcXJ3z//nnHzzxxBPw9PSEj48PnnnmGZw4cQKCIGDt2rUGX/vdu3cxefJkhIWFwcPDA/7+/ujevTsOHz6s0+7atWsQBAEffPAB/vvf/yIkJAQeHh6IjIzEsWPHSlx37dq1aNSoEZydndGkSRN8/fXXBvtRqE+fPqhduzbWrFlT4rmLFy/i+PHjGDNmDBwcHLB3714MHjwYtWvXhouLC+rXr48XX3xR1jQkfVP10tPTMWHCBPj5+cHDwwNRUVH466+/Spx75coVjB07Fg0aNICbmxtq1aqFgQMH4ty5c9o2Bw8eRNu2bQEAY8eO1U7XKpzyp+/9olar8d5776Fx48ZwdnaGv78/xowZg3/++UenXeH79cSJE+jcuTPc3NxQr149LFmyBGq12uhrlyMnJwdz5sxBSEgInJycUKtWLUyZMgUPHjzQabd//35069YNfn5+cHV1Rd26dTF8+HBkZWVp26xcuRLNmzeHh4cHPD090bhxY8ydO9fg/X/88UfEx8dj9uzZOqGp0JNPPonevXvjq6++QnJyMvLz8+Hv74/Ro0eXaPvgwQO4urpixowZ2mPp6emYOXOmzuubNm1aiX/XgiBg6tSpWLVqFZo0aQJnZ2esW7dOzrfQoMLpo3v37sXYsWPh6+sLd3d3DBw4EH///XeJ9qtXr0bz5s3h4uICX19fDB06FBcvXizR7vjx4xg4cCD8/Pzg4uKC0NBQTJs2rUS727dv4+mnn4a3tzdq1qyJ559/HmlpaTptfvjhB7Rr1w7e3t7a91jhfxeJyPoYnIjIapKSkjBq1CiMHDkSu3btwuTJkwEAly9fRr9+/fDVV18hJiYG06ZNw6ZNmzBw4EBZ1z1z5gxeffVVTJ8+Hdu2bUOzZs0wbtw4HDp0yOi5+fn5GDRoEHr06IFt27bh+eefx0cffYSlS5dq22RmZuLxxx/HgQMHsHTpUmzatAk1a9bEk08+Kat/qampAICFCxdi586dWLNmDerVq4du3brpXXO1YsUK7N27F8uWLcO3336LzMxM9OvXT+dD19q1azF27Fg0adIE0dHReP311/HWW2+VmB6pjyiKeO6553Dy5EmcOXNG57nCMFX44e3q1auIjIzEypUrsWfPHixYsADHjx9Hp06dTF7/IkkShgwZgm+++QavvvoqfvzxR7Rv3x59+/Yt0fbWrVvw8/PDkiVLEBMTgxUrVsDBwQHt2rXDpUuXAGimXxb29/XXX0dsbCxiY2Mxfvz4UvswadIkzJo1C7169cL27dvx1ltvISYmBh06dCgRBpOTk/HMM89g1KhR2L59O/r27Ys5c+Zg/fr1Jr1uQ9+LDz74AKNHj8bOnTsxY8YMrFu3Dt27d9cG92vXrqF///5wcnLC6tWrERMTgyVLlsDd3R15eXkANFMrJ0+ejK5du+LHH3/E1q1bMX369BIBpbi9e/cCAIYMGVJqmyFDhqCgoAAHDx6Eo6MjRo0ahejoaKSnp+u0++6775CTk4OxY8cC0Iwmd+3aFevWrcPLL7+Mn3/+GbNmzcLatWsxaNAgSJKkc/7WrVuxcuVKLFiwALt370bnzp2Nfg8LCgpKPPSF2nHjxkEURWzYsAHLli1DXFwcunXrphNQFy9ejHHjxqFp06bYsmULPv74Y5w9exaRkZG4fPmytl1h3xITE/Hf//4XP//8M15//XXcvn27xH2HDx+Ohg0bIjo6GrNnz8aGDRswffp07fOxsbF48sknUa9ePXz//ffYuXMnFixYgIKCAqOvnYgqiEREZGHPPvus5O7urnOsa9euEgDpl19+MXiuWq2W8vPzpV9//VUCIJ05c0b73MKFC6Xi/xkLCgqSXFxcpOvXr2uPZWdnS76+vtKLL76oPXbgwAEJgHTgwAGdfgKQNm3apHPNfv36SY0aNdJ+vWLFCgmA9PPPP+u0e/HFFyUA0po1awy+puIKCgqk/Px8qUePHtLQoUO1xxMSEiQA0mOPPSYVFBRoj8fFxUkApO+++06SJElSqVRSYGCg1KpVK0mtVmvbXbt2TXJ0dJSCgoKM9uHvv/+WBEGQXn75Ze2x/Px8KSAgQOrYsaPecwp/NtevX5cASNu2bdM+t2bNGgmAlJCQoD327LPP6vTl559/lgBIH3/8sc5133nnHQmAtHDhwlL7W1BQIOXl5UkNGjSQpk+frj1+4sSJUn8Gxd8vFy9elABIkydP1ml3/PhxCYA0d+5c7bHC9+vx48d12oaFhUl9+vQptZ+FgoKCpP79+5f6fExMjARAeu+993SOb9y4UQIgffHFF5IkSdLmzZslANLp06dLvdbUqVMlHx8fo30qLioqSgIg5eTklNqm8Ge2dOlSSZIk6ezZszr9KxQRESG1bt1a+/XixYslURSlEydO6LQrfD27du3SHgMgeXt7S6mpqbL6Xfiz0fcYN26ctl3he7LovzFJkqQjR45IAKS3335bkiRJun//vuTq6ir169dPp11iYqLk7OwsjRw5UnssNDRUCg0NlbKzs0vtX+H7rvjPdvLkyZKLi4v23+wHH3wgAZAePHgg63UTUcXjiBMRWU21atXQvXv3Esf//vtvjBw5EgEBAVAoFHB0dETXrl0BQO9UmeJatGiBunXrar92cXFBw4YNcf36daPnCoJQYmSrWbNmOuf++uuv8PT0LFFo4OmnnzZ6/UKrVq1Cq1at4OLiAgcHBzg6OuKXX37R+/r69+8PhUKh0x8A2j5dunQJt27dwsiRI3WmogUFBaFDhw6y+hMSEoLHH38c3377rXbk4ueff0ZycrLOVKE7d+5g4sSJqFOnjrbfQUFBAOT9bIo6cOAAAOCZZ57ROT5y5MgSbQsKCvDuu+8iLCwMTk5OcHBwgJOTEy5fvmzyfYvf/7nnntM5HhERgSZNmuCXX37ROR4QEICIiAidY8XfG2VVODJYvC//+c9/4O7uru1LixYt4OTkhBdeeAHr1q3TO8UsIiICDx48wNNPP41t27aZtZqb9O/IUOH77LHHHkPr1q11pnlevHgRcXFxOu+bHTt2IDw8HC1atNAZEerTp4/e6pbdu3fXW6ikNKGhoThx4kSJx/z580u0Lf5+69ChA4KCgrTvh9jYWGRnZ5f4WdSpUwfdu3fX/iz++usvXL16FePGjYOLi4vRPhavStmsWTPk5OTgzp07AKCdZjpixAhs2rQJN2/elPfiiajCMDgRkdUolcoSxzIyMtC5c2ccP34cb7/9Ng4ePIgTJ05gy5YtAIDs7Gyj1/Xz8ytxzNnZWda5bm5uJT4EOTs7IycnR/t1SkoKatasWeJcfcf0+e9//4tJkyahXbt2iI6OxrFjx3DixAlERUXp7WPx11NYKaywbUpKCgDNB/vi9B0rzbhx45CSkoLt27cD0EzT8/DwwIgRIwBo1gP17t0bW7ZswWuvvYZffvkFcXFx2vVWcr6/RaWkpMDBwaHE69PX5xkzZmD+/PkYMmQIfvrpJxw/fhwnTpxA8+bNTb5v0fsD+t+HgYGB2ucLled9JacvDg4OqFGjhs5xQRAQEBCg7UtoaCj27dsHf39/TJkyBaGhoQgNDcXHH3+sPWf06NFYvXo1rl+/juHDh8Pf3x/t2rXTTsUrTeEvGxISEkptU1hevk6dOtpjzz//PGJjY/Hnn38C0LxvnJ2ddX6RcPv2bZw9exaOjo46D09PT0iSVCLc6fuZGOLi4oI2bdqUeBSG+qJK+3dS+D2W+764e/cuAMguOGLs33GXLl2wdetWFBQUYMyYMahduzbCw8Px3Xffybo+EVkeq+oRkdXo21Nn//79uHXrFg4ePKgdZQJQYoG8Nfn5+SEuLq7E8eTkZFnnr1+/Ht26dcPKlSt1jj98+LDM/Snt/nL7BADDhg1DtWrVsHr1anTt2hU7duzAmDFj4OHhAQA4f/48zpw5g7Vr1+LZZ5/VnnflypUy97ugoAApKSk6Hyr19Xn9+vUYM2YM3n33XZ3j9+7dg4+PT5nvD2jW2hX/8Hvr1i1Ur169TNcta18KCgpw9+5dnfAkSRKSk5O1oxEA0LlzZ3Tu3BkqlQq///47Pv30U0ybNg01a9bU7sc1duxYjB07FpmZmTh06BAWLlyIAQMG4K+//tIbJgCgV69e+OKLL7B161bMnj1bb5utW7fCwcEB3bp10x57+umnMWPGDKxduxbvvPMOvvnmGwwZMkRnxKh69epwdXUtUaSl6PNFWXK/rdL+ndSvXx+A7vuiuKLvi8KfU/FCIuUxePBgDB48GLm5uTh27BgWL16MkSNHIjg4GJGRkWa7DxGVDUeciMimFH5gKr7/yueff26N7ujVtWtXPHz4ED///LPO8e+//17W+YIglHh9Z8+eLbH/lVyNGjWCUqnEd999p7PI/vr16zh69Kjs67i4uGDkyJHYs2cPli5divz8fJ3pVub+2Tz++OMAUGL/nQ0bNpRoq+97tnPnzhLTmYr/Ft+QwmmixYs7nDhxAhcvXkSPHj2MXsNcCu9VvC/R0dHIzMzU2xeFQoF27dphxYoVAICTJ0+WaOPu7o6+ffti3rx5yMvLw4ULF0rtw9ChQxEWFoYlS5borWy4ceNG7NmzB+PHj9cZtalWrRqGDBmCr7/+Gjt27CgxvRMABgwYgKtXr8LPz0/vyFBFblRb/P129OhRXL9+XRsGIyMj4erqWuJn8c8//2D//v3an0XDhg0RGhqK1atXl6i6WV7Ozs7o2rWrtijNqVOnzHp9IiobjjgRkU3p0KEDqlWrhokTJ2LhwoVwdHTEt99+W6LamzU9++yz+OijjzBq1Ci8/fbbqF+/Pn7++Wfs3r0bgKZKnSEDBgzAW2+9hYULF6Jr1664dOkS3nzzTYSEhJSpgpYoinjrrbcwfvx4DB06FBMmTMCDBw+waNEik6bqAZrpeitWrMB///tfNG7cWGeNVOPGjREaGorZs2dDkiT4+vrip59+MjoFrDS9e/dGly5d8NprryEzMxNt2rTBkSNH8M0335RoO2DAAKxduxaNGzdGs2bN8Mcff+D9998vMVIUGhoKV1dXfPvtt2jSpAk8PDwQGBiIwMDAEtds1KgRXnjhBXz66acQRRF9+/bFtWvXMH/+fNSpU0en4pk5JCcnY/PmzSWOBwcHo1evXujTpw9mzZqF9PR0dOzYEWfPnsXChQvRsmVLbcnvVatWYf/+/ejfvz/q1q2LnJwc7ShOz549AQATJkyAq6srOnbsCKVSieTkZCxevBje3t46I1fFKRQKREdHo1evXoiMjMSrr76KyMhI5Obm4qeffsIXX3yBrl274sMPPyxx7vPPP4+NGzdi6tSpqF27trYvhaZNm4bo6Gh06dIF06dPR7NmzaBWq5GYmIg9e/bg1VdfRbt27cr8vc3OztZboh8oua/c77//jvHjx+M///kPbty4gXnz5qFWrVraqp4+Pj6YP38+5s6dizFjxuDpp59GSkoK3njjDbi4uGDhwoXaa61YsQIDBw5E+/btMX36dNStWxeJiYnYvXu33g15DVmwYAH++ecf9OjRA7Vr18aDBw/w8ccf66zxJCIrs2ppCiKqEkqrqte0aVO97Y8ePSpFRkZKbm5uUo0aNaTx48dLJ0+eLFEtrbSqevqql3Xt2lXq2rWr9uvSquoV72dp90lMTJSGDRsmeXh4SJ6entLw4cOlXbt2lagup09ubq40c+ZMqVatWpKLi4vUqlUraevWrSWqzhVW1Xv//fdLXAN6qs59+eWXUoMGDSQnJyepYcOG0urVq0tcU46WLVvqrQImSZIUHx8v9erVS/L09JSqVasm/ec//5ESExNL9EdOVT1JkqQHDx5Izz//vOTj4yO5ublJvXr1kv78888S17t//740btw4yd/fX3Jzc5M6deokHT58uMTPVZIk6bvvvpMaN24sOTo66lxH389RpVJJS5culRo2bCg5OjpK1atXl0aNGiXduHFDp11p71e539+goKBSK789++yzkiRpqj/OmjVLCgoKkhwdHSWlUilNmjRJun//vvY6sbGx0tChQ6WgoCDJ2dlZ8vPzk7p27Spt375d22bdunXS448/LtWsWVNycnKSAgMDpREjRkhnz5412k9JkqR79+5Js2fPlho3biy5uLhIHh4eUkREhLR8+XIpLy9P7zkqlUqqU6eOBECaN2+e3jYZGRnS66+/LjVq1EhycnKSvL29pccee0yaPn26lJycrG0HQJoyZYqsvkqS4ap6AKT8/HxJkh69J/fs2SONHj1a8vHx0VbPu3z5conrfvnll1KzZs20fR08eLB04cKFEu1iY2Olvn37St7e3pKzs7MUGhqqU+mx8H139+5dnfOK/xvZsWOH1LdvX6lWrVqSk5OT5O/vL/Xr1086fPiw7O8FEVmWIEnFNk8gIqIyeffdd/H6668jMTFR9oJxIqoYhXudnThxAm3atLF2d4jIDnGqHhFRGSxfvhyAZvpafn4+9u/fj08++QSjRo1iaCIiIqqEGJyIiMrAzc0NH330Ea5du4bc3FzUrVsXs2bNwuuvv27trhEREZEFcKoeERERERGRESxHTkREREREZASDExERERERkREMTkREREREREZUueIQarUat27dgqenJwRBsHZ3iIiIiIjISiRJwsOHDxEYGGh0A/sqF5xu3bqFOnXqWLsbRERERERkI27cuGF0O5EqF5w8PT0BaL45Xl5eVu4NERERERFZS3p6OurUqaPNCIZUueBUOD3Py8uLwYmIiIiIiGQt4WFxCCIiIiIiIiMYnIiIiIiIiIxgcCIiIiIiIjKiyq1xIiIiIiLbI0kSCgoKoFKprN0VqmQcHR2hUCjKfR0GJyIiIiKyqry8PCQlJSErK8vaXaFKSBAE1K5dGx4eHuW6DoMTEREREVmNWq1GQkICFAoFAgMD4eTkJKvCGZEckiTh7t27+Oeff9CgQYNyjTwxOBERERGR1eTl5UGtVqNOnTpwc3OzdneoEqpRowauXbuG/Pz8cgUnFocgIiIiIqsTRX4sJcsw1wgm36FERERERERGMDgREREREREZweBERERERHZPpZYQezUF207fROzVFKjUkrW7ZLJu3bph2rRpsttfu3YNgiDg9OnTFusTPcLiEERERERk12LOJ+GNn+KRlJajPab0dsHCgWGIClea/X7G1sw8++yzWLt2rcnX3bJlCxwdHWW3r1OnDpKSklC9enWT72WKa9euISQkBKdOnUKLFi0sei9bxuBERERERHYr5nwSJq0/ieLjS8lpOZi0/iRWjmpl9vCUlJSk/fvGjRuxYMECXLp0SXvM1dVVp31+fr6sQOTr62tSPxQKBQICAkw6h8qOU/WsqDIMKRMRERGZmyRJyMorMPp4mJOPhdsvlAhNALTHFm2Px8OcfFnXkyR5n8UCAgK0D29vbwiCoP06JycHPj4+2LRpE7p16wYXFxesX78eKSkpePrpp1G7dm24ubnhsccew3fffadz3eJT9YKDg/Huu+/i+eefh6enJ+rWrYsvvvhC+3zxqXoHDx6EIAj45Zdf0KZNG7i5uaFDhw46oQ4A3n77bfj7+8PT0xPjx4/H7NmzyzWSlJubi5dffhn+/v5wcXFBp06dcOLECe3z9+/fxzPPPIMaNWrA1dUVDRo0wJo1awBoytFPnToVSqUSLi4uCA4OxuLFi8vcF0viiJOVVPSQMhEREZG9yM5XIWzB7nJfRwKQnJ6DxxbtkdU+/s0+cHMyz8fjWbNm4cMPP8SaNWvg7OyMnJwctG7dGrNmzYKXlxd27tyJ0aNHo169emjXrl2p1/nwww/x1ltvYe7cudi8eTMmTZqELl26oHHjxqWeM2/ePHz44YeoUaMGJk6ciOeffx5HjhwBAHz77bd455138Nlnn6Fjx474/vvv8eGHHyIkJKTMr/W1115DdHQ01q1bh6CgILz33nvo06cPrly5Al9fX8yfPx/x8fH4+eefUb16dVy5cgXZ2dkAgE8++QTbt2/Hpk2bULduXdy4cQM3btwoc18sicHJCqwxpExEREREFWfatGkYNmyYzrGZM2dq//7SSy8hJiYGP/zwg8Hg1K9fP0yePBmAJox99NFHOHjwoMHg9M4776Br164AgNmzZ6N///7IycmBi4sLPv30U4wbNw5jx44FACxYsAB79uxBRkZGmV5nZmYmVq5cibVr16Jv374AgP/973/Yu3cvvvrqK/zf//0fEhMT0bJlS7Rp0waAZiStUGJiIho0aIBOnTpBEAQEBQWVqR8VgcGpgqnUEt74KR4SAAcU4FlFDNqKl+CKHKTCCxIESJtFqE8oIKqyAQdXwL0GIACQJCDzHlBQ5Dj0HCtcryiIgE8dIKQrENwJEMu+UzIRERFRRXF1VCD+zT5G28UlpOK5NSeMtls7ti0iQoyvH3J1NN9npcKQUEilUmHJkiXYuHEjbt68idzcXOTm5sLd3d3gdZo1a6b9e+GUwDt37sg+R6nU/DL+zp07qFu3Li5duqQNYoUiIiKwf/9+Wa+ruKtXryI/Px8dO3bUHnN0dERERAQuXrwIAJg0aRKGDx+OkydPonfv3hgyZAg6dOgAAHjuuefQq1cvNGrUCFFRURgwYAB69+5dpr5YGoNTBYtLSEVSWg5mKzZggsMOKEorynLdjDc9/CEgOgIN+wIR4xmiiIiIyKYJgiBrylznBjWg9HZBclqO3nVOAoAAbxd0blADCtFwJTxzKx6IPvzwQ3z00UdYtmwZHnvsMbi7u2PatGnIy8szeJ3iRSUEQYBarZZ9TmEFwKLnFK8KKHdtlz6F5+q7ZuGxvn374vr169i5cyf27duHHj16YMqUKfjggw/QqlUrJCQk4Oeff8a+ffswYsQI9OzZE5s3by5znyyFxSEq2J2HmtD0osOOiv3mq/OBP7cDXw8C3gkE9i8G1KqK7AERERGRWSlEAQsHhgF4NOGmUOHXCweGVXho0ufw4cMYPHgwRo0ahebNm6NevXq4fPlyhfejUaNGiIuL0zn2+++/l/l69evXh5OTE3777Tftsfz8fPz+++9o0qSJ9liNGjXw3HPPYf369Vi2bJlOkQsvLy88+eST+N///oeNGzciOjoaqampZe6TpXDEqYL5u4oY4LADAGBkCwDLUeUAh5YAv30IDP0CeGyY8XOIiIiIbFBUuBIrR7UqUXQrwMaKbtWvXx/R0dE4evQoqlWrhv/+979ITk7WCRcV4aWXXsKECRPQpk0bdOjQARs3bsTZs2dRr149o+cWr84HAGFhYZg0aRL+7//+D76+vqhbty7ee+89ZGVlYdy4cQA066hat26Npk2bIjc3Fzt27NC+7o8++ghKpRItWrSAKIr44YcfEBAQAB8fH7O+bnNgcKpgESlbSp+eV9HU+UD0WODcJmDk99buDREREVGZRIUr0SssAHEJqbjzMAf+ni6ICPG1iZGmQvPnz0dCQgL69OkDNzc3vPDCCxgyZAjS0tIqtB/PPPMM/v77b8ycORM5OTkYMWIEnnvuuRKjUPo89dRTJY4lJCRgyZIlUKvVGD16NB4+fIg2bdpg9+7dqFatGgDAyckJc+bMwbVr1+Dq6orOnTvj++81nz09PDywdOlSXL58GQqFAm3btsWuXbsgirY3MU6QyjOp0Q6lp6fD29sbaWlp8PLyqvgO7Po/IO4L4+0qWoMo4JmN1u4FERERVTE5OTlISEhASEgIXFxcrN2dKqlXr14ICAjAN998Y+2uWISh95gp2YAjThWtWrC1e6Df5RggZjYQtcTaPSEiIiIiC8nKysKqVavQp08fKBQKfPfdd9i3bx/27t1r7a7ZPNsbA6vkVK3HQwUBNjnOd2wlEDPX2r0gIiIiIgsRBAG7du1C586d0bp1a/z000+Ijo5Gz549rd01m8cRpwoWdyMDZ/L740WHHZAkKxaIKM2xFZo/o961bj+IiIiIyOxcXV2xb98+a3fDLjE4VbA7D3OwRDUSADT7OFm5P3oxPBERERER6WBwqmD+npoFaUtUI/GBagSeVcSgrXgJrshBKrwgQQAg4XGlgGpOBYCDK+BeQ7MZgSQBmfeAguxHx6HnWPpN4OYfgNrwhmoGHVsBCCLQ521zvGwiIiIiIrvG4FTBIkJ8tTtcF8ABX6kG4CvVAJ02Pm6OGDyxF1CeEppqFZBwGLh2CLh2FLhxDNC7p7YBsZ8CtdsATYeUvR9ERERERJUAi0NUsMIdrg1FmAdZ+dgbn1y+G4kKILQb0GMBMC4GWJAC1Gpr+nW2TdWEMCIiIiKiKozByQp6hQXAx82x1OcFAG/8FA+V2oyl90QFMGEf0H6SaeflPdSMXBERERERVWEMTlYQl5CKB1n5pT4vAUhKy0FcQqr5bx61BGg/xbRz/lht/n4QEREREdkRBicruPMwx6ztTBb1rmnh6VIMp+sRERGRbStc331us+ZPO/js0q1bN0ybNk37dXBwMJYtW2bwHEEQsHXr1nLf21zXqUoYnKygsLKeMdfuZVmuE1HvAk2GyGurygWix1uuL0RERETlEb8dWBYOrBsARI/T/LksXHPcAgYOHFjqhrGxsbEQBAEnT540+bonTpzACy+8UN7u6Vi0aBFatGhR4nhSUhL69u1r1nsVt3btWvj4+Fj0HhWJwckKIkJ8EeDlbLTd9ycSzbvOqbj/rAYUxvsBALiwBbiw1XJ9ISIiIiqL+O3ApjFA+i3d4+lJmuMWCE/jxo3D/v37cf369RLPrV69Gi1atECrVq1Mvm6NGjXg5uZmji4aFRAQAGdnmZ8DCQCDk1UoRAFPR9Q12s5i65wKiQqg86vy27PCHhEREVUESQLyMo0/ctKBn1+D/i1X/j0WM0vTTs71JHm/sB4wYAD8/f2xdu1aneNZWVnYuHEjxo0bh5SUFDz99NOoXbs23Nzc8Nhjj+G7774zeN3iU/UuX76MLl26wMXFBWFhYdi7d2+Jc2bNmoWGDRvCzc0N9erVw/z585Gfr1lLv3btWrzxxhs4c+YMBEGAIAjaPhefqnfu3Dl0794drq6u8PPzwwsvvICMjAzt88899xyGDBmCDz74AEqlEn5+fpgyZYr2XmWRmJiIwYMHw8PDA15eXhgxYgRu376tff7MmTN4/PHH4enpCS8vL7Ru3Rq///47AOD69esYOHAgqlWrBnd3dzRt2hS7du0qc1/k4D5OVhJc3V1Wu73xyYgM9bNcR7rMBI58DORnGm+b9xA49AHQbZbl+kNERESUnwW8G2iGC0makagldeQ1n3sLcDL+Gc3BwQFjxozB2rVrsWDBAgiCZu/NH374AXl5eXjmmWeQlZWF1q1bY9asWfDy8sLOnTsxevRo1KtXD+3atTN6D7VajWHDhqF69eo4duwY0tPTddZDFfL09MTatWsRGBiIc+fOYcKECfD09MRrr72GJ598EufPn0dMTAz27dsHAPD29i5xjaysLERFRaF9+/Y4ceIE7ty5g/Hjx2Pq1Kk64fDAgQNQKpU4cOAArly5gieffBItWrTAhAkTjL6e4iRJwpAhQ+Du7o5ff/0VBQUFmDx5Mp588kkcPHgQAPDMM8+gZcuWWLlyJRQKBU6fPg1HR01l6ilTpiAvLw+HDh2Cu7s74uPj4eHhYXI/TMHgZCVy1zltO30L8/qHQVGezXANERVAx1eAg+/Ka3/0E03YEhWW6Q8RERGRHXj++efx/vvv4+DBg3j88ccBaKbpDRs2DNWqVUO1atUwc+ZMbfuXXnoJMTEx+OGHH2QFp3379uHixYu4du0aateuDQB49913S6xLev3117V/Dw4OxquvvoqNGzfitddeg6urKzw8PODg4ICAgIBS7/Xtt98iOzsbX3/9NdzdNcFx+fLlGDhwIJYuXYqaNWsCAKpVq4bly5dDoVCgcePG6N+/P3755ZcyBad9+/bh7NmzSEhIQJ06mmD7zTffoGnTpjhx4gTatm2LxMRE/N///R8aN24MAGjQoIH2/MTERAwfPhyPPfYYAKBevXom98FUDE5WEhHiC193R6RmGh7eTMnMQ1xCquVHnY5+qhlRMiYvg6NOREREZFmObprRH2OuHwW+fcJ4u2c2A0Ed5N1XpsaNG6NDhw5YvXo1Hn/8cVy9ehWHDx/Gnj17AAAqlQpLlizBxo0bcfPmTeTm5iI3N1cbTIy5ePEi6tatqw1NABAZGVmi3ebNm7Fs2TJcuXIFGRkZKCgogJeXl+zXUXiv5s2b6/StY8eOUKvVuHTpkjY4NW3aFArFo1+eK5VKnDt3zqR7Fb1nnTp1tKEJAMLCwuDj44OLFy+ibdu2mDFjBsaPH49vvvkGPXv2xH/+8x+EhoYCAF5++WVMmjQJe/bsQc+ePTF8+HA0a9asTH2Ri2ucrEQhChjaopastv87fNWynREVwKDl8tsfX8W1TkRERGQ5gqCZMmfsEdod8AoEUNrMHAHwqqVpJ+d6gmkzfMaNG4fo6Gikp6djzZo1CAoKQo8ePQAAH374IT766CO89tpr2L9/P06fPo0+ffogLy9P1rUlPeuthGL9O3bsGJ566in07dsXO3bswKlTpzBv3jzZ9yh6r+LX1nfPwmlyRZ9Tq9Um3cvYPYseX7RoES5cuID+/ftj//79CAsLw48//ggAGD9+PP7++2+MHj0a586dQ5s2bfDpp5+WqS9yMThZUc+w0odMi9r/513sOptk2c6EDwGaDpPXNjtV8xseIiIiImsSFUDU0n+/KP4h/N+vo5ZYbInBiBEjoFAosGHDBqxbtw5jx47Vfug/fPgwBg8ejFGjRqF58+aoV68eLl++LPvaYWFhSExMxK1bj0beYmNjddocOXIEQUFBmDdvHtq0aYMGDRqUqPTn5OQElcrwL7zDwsJw+vRpZGY+WvN+5MgRiKKIhg0byu6zKQpf340bN7TH4uPjkZaWhiZNmmiPNWzYENOnT8eePXswbNgwrFmzRvtcnTp1MHHiRGzZsgWvvvoq/ve//1mkr4UYnKyocLqeHK9Fn7VsaXIAGP4l4Chv+BgZt423ISIiIrK0sEHAiK8BL6Xuca9AzfGwQRa7tYeHB5588knMnTsXt27dwnPPPad9rn79+ti7dy+OHj2Kixcv4sUXX0RycrLsa/fs2RONGjXCmDFjcObMGRw+fBjz5s3TaVO/fn0kJibi+++/x9WrV/HJJ59oR2QKBQcHIyEhAadPn8a9e/eQm5tb4l7PPPMMXFxc8Oyzz+L8+fM4cOAAXnrpJYwePVo7Ta+sVCoVTp8+rfOIj49Hz5490axZMzzzzDM4efIk4uLiMGbMGHTt2hVt2rRBdnY2pk6dioMHD+L69es4cuQITpw4oQ1V06ZNw+7du5GQkICTJ09i//79OoHLEhicrMiU6XoZuQVYvv+KZTskKoAOL8lr61bdsn0hIiIikitsEDDtPPDsDmD4V5o/p52zaGgqNG7cONy/fx89e/ZE3bqPtpuZP38+WrVqhT59+qBbt24ICAjAkCFDZF9XFEX8+OOPyM3NRUREBMaPH4933nlHp83gwYMxffp0TJ06FS1atMDRo0cxf/58nTbDhw9HVFQUHn/8cdSoUUNvSXQ3Nzfs3r0bqampaNu2LZ544gn06NEDy5ebsJSjFBkZGWjZsqXOo1+/ftpy6NWqVUOXLl3Qs2dP1KtXDxs3bgQAKBQKpKSkYMyYMWjYsCFGjBiBvn374o033gCgCWRTpkxBkyZNEBUVhUaNGuGzzz4rd38NESR9EygrsfT0dHh7eyMtLc3khXOWEHs1BU//75istj5ujvjj9V6Wq7AHAH//Cnwt4z8yY7YD9bparh9ERERUJeTk5CAhIQEhISFwcZFXdZjIFIbeY6ZkA444WZkp0/UeZOVbdkNcAMi8a952RERERESVAIOTlSlEAW8PDpfdfs8FCxeJ8JA5jzXFwpX+iIiIiIhsCIOTDejXLBCR9arJarvm6HXEnLdgeArqAHgqjbc7uY4lyYmIiIioymBwshEj2gbJbvvGT/GWq7AnKoDWY423S7/JkuREREREVGUwONmIAC/5iyGT0nIsu9bJL1Reu0u7LNcHIiIiqlKqWL0yqkDmem8xONmIiBBf+LjKKxIBAHvj5e8DYDK565zObuJ0PSIiIioXR0fN55+srCwr94Qqq7y8PACaEufl4WCOzlD5KUQBYzsG46N98naUXn3kGiJCfBEVLmM9kqmCOgBufkBWiuF2Wfc00/VCOpu/D0RERFQlKBQK+Pj44M6dOwA0ewoJggW3XqEqRa1W4+7du3Bzc4ODQ/miD4OTDZnavQFWH0lAWnaBrPZv/BSPXmEB5t/XSVQAzZ4EjsnYRCzjtnnvTURERFVOQEAAAGjDE5E5iaKIunXrljuQMzjZEIUoYOnwZpi4/qSs9oVrnSJD/czfmUb95AUnudP6iIiIiEohCAKUSiX8/f2Rn59v7e5QJePk5ARRLP8KJQYnGxMVrsS4jsH46sg1We3vPMyxTEeCOgBegUD6LcPtjE3nIyIiIpJJoVCUex0KkaWwOIQN6hkWILutv6f8anwmERVA78XG2+2eywIRRERERFTpMTjZoIgQXwR4Octqu/9PC64xcpcxBZD7ORERERFRFcDgZIMUooBFg5rKavu/wwnYdTbJMh2RW/iBBSKIiIiIqJJjcLJRUeFKTO/ZQFbb+dvOQ6W2wKZxcgs/pFw1/72JiIiIiGwIg5MNC67uLqtdSmYe4hJSzd+BoA6Ap4x9ok6u4zonIiIiIqrUGJxsmCmFH744ZIFRH1EBtB5rvB3XORERERFRJWfV4LR48WK0bdsWnp6e8Pf3x5AhQ3Dp0iWD5xw8eBCCIJR4/PnnnxXU64oTEeILTxd5JTkPXLprmbVOfqHy2l3aZf57ExERERHZCKsGp19//RVTpkzBsWPHsHfvXhQUFKB3797IzMw0eu6lS5eQlJSkfTRoIG89kD1RiAKeaFVbdnuLrHWSu87p7CZO1yMiIiKiSsuqG+DGxMTofL1mzRr4+/vjjz/+QJcuXQye6+/vDx8fH6P3yM3NRW5urvbr9PT0MvXVWno3VWLN0euy2haudYoMlVFGXK6gDoCbn/GNbrPuaabrhXQ2372JiIiIiGyETa1xSktLAwD4+voabduyZUsolUr06NEDBw4cKLXd4sWL4e3trX3UqVPHbP2tCBEhvvB1d5Tdfm98snk7ICqAZk/Ka8vpekRERERUSdlMcJIkCTNmzECnTp0QHh5eajulUokvvvgC0dHR2LJlCxo1aoQePXrg0KFDetvPmTMHaWlp2seNGzcs9RIsQiEKeHtw6d+P4r6PSzT/dL1G/eS143Q9IiIiIqqkBEmSLLABkOmmTJmCnTt34rfffkPt2vLX9QDAwIEDIQgCtm/fbrRteno6vL29kZaWBi8vr7J2t8K9s/MC/nf4mqy2rep6Y8vkTua7uVoFfNDA+HQ9AHh2B6frEREREZFdMCUb2MSI00svvYTt27fjwIEDJocmAGjfvj0uX75sgZ7Zjnn9m+LxRjVktT2ZmIbx606Y7+amTNfLuG2++xIRERER2QirBidJkjB16lRs2bIF+/fvR0hISJmuc+rUKSiVMjZqtXMvdJFZGhzAvot38NOZW+a7udzpenKr8BERERER2RGrVtWbMmUKNmzYgG3btsHT0xPJyZrCBt7e3nB1dQWgWaN08+ZNfP311wCAZcuWITg4GE2bNkVeXh7Wr1+P6OhoREdHW+11VJSIEF/4uDriQXa+rPbzfjyHfo8poRCF8t+8TjtAEAFJXXobQaFpR0RERERUyVh1xGnlypVIS0tDt27doFQqtY+NGzdq2yQlJSExMVH7dV5eHmbOnIlmzZqhc+fO+O2337Bz504MGzbMGi+hQilEAWM7Bstun55TgLiEVPPc/MZxw6EJACSVph0RERERUSVjM8UhKoq9FocopFJLaLowBjn5RkLMv57vGIwFA5uW/8bnNgPR44y3G/4V8NgT5b8fEREREZGF2V1xCJJPIQr4YHgz2e23nrppnvLkctcucY0TEREREVVCDE52aECLWujZRF6FvdSsfCzff6X8Nw3qAHgFAjCwXsrVV9OOiIiIiKiSYXCyU18+G4HwQHlTDT/a9xdizieV74aiAohaCsDA6FV2KvDnzvLdh4iIiIjIBjE42bF5/cNkt33jp/jyT9lr3F8zqlQqAYiZrdkwl4iIiIioEmFwsmMRIb7wdXeU1TYpLaf8FfauH9WMKpVKAtJvatoREREREVUiDE52TCEKGNqiluz2dx7mlO+GGbfN246IiIiIyE4wONm5nmEBstuuO5pQvpuxsh4RERERVVEMTnYuIsQXAV7OstqeTEzD+HUnyn4zbWU9I7JSyn4PIiIiIiIbxOBk5xSigEWD5G9wu+/iHfx05lbZbiYqgN6LjbfbMZ0FIoiIiIioUmFwqgSiwpUY1zFYdvvXNp8pe4U9dz/jbbJTgUMflO36REREREQ2iMGpkjBlrVN2vrrsm+LKLfxw9BOOOhERERFRpcHgVElEhPjC00Uhu/3qI3+XbdRJbuGHvAyOOhERERFRpcHgVEkoRAGLhzwmu31adgE++eWy6TcK6gC4+shre3wVR52IiIiIqFJgcKpEBrSohZ5Nashu//Evl7F4V7xpNxEVQLvJ8tpmp3IzXCIiIiKqFBicKpkvn41Aq7o+stt/figBu84mmXaTLjMBR3d5bbkZLhERERFVAgxOldAPEzvA28VBdvvXos+att5JVAAdX5HXlpvhEhEREVElwOBUCSlEAc93CpHdPiO3wPQqe11mAq6+xttxM1wiIiIiqgQYnCqp4Ooyp9L96/NDV00fder/kfF2u+eyQAQRERER2T0Gp0rK39PFpPZZeSocu2ri6JCczXDTb7JABBERERHZPQanSioixBdKb9PCU+zf90y7idzCDywQQURERER2jsGpklKIAhYODINgwjlHrpg44iS38EPKVdOuS0RERERkYxicKrGocCVWjmqFam6OstqfuvHAtNLkQR0AT6XxdifXcZ0TEREREdk1BqdKLipcieNze8LFUd6P2qTS5KICaD3WeDuucyIiIiIiO8fgVAU4OYh4JqKurLYmlyb3lVn2/KGJm+wSEREREdkQBqcqomdYgOy2q369In/UKfOuedsREREREdkgBqcqIiLEF77u8tY6Zeer8cr3p+Rd2L2GedsREREREdkgBqcqQiEKeHtwuOz2O84mySsUIac4hCntiIiIiIhsEINTFdKvWSAGNpM/Ze//Np8xPmUvqAPgFWj8YlkmljonIiIiIrIhDE5VzLKnWsHNSSGrbWaeyviUPVEB9F5s/GK757IkORERERHZLQanKkYhCnixSz3Z7WVN2XP3M34hliQnIiIiIjvG4FQFTe3eAO7O8kadABl7O2Xclnchue2IiIiIiGwMg1MVpBAFvD+8mez2Rvd28qgp70Jy2xERERER2RgGpyqqX7NARNarJrv954eulj7qxAIRRERERFTJMThVYSPaBslum5WnKn3USW6BiB3TWSCCiIiIiOwSg1MVFuDlYlJ7g6NOcgpEZKcChz4w6Z5ERERERLaAwakKiwjxhdJbfngyOOokt/DD8VUcdSIiIiIiu8PgVIUpRAELB4aZdM6Kg1f0jzrJLfyQncqy5ERERERkdxicqriocCVWjWoluzx5XoFa/6a4QR0AVx95N720S34HiYiIiIhsAIMTISpciVPze8PZQd7bYee5JOQVqHUPigqg3WR5Nzy7idP1iIiIiMiuMDgRAMDJQcTkbqGy2koS8E3stZJPdJkJOHkav0DWPU7XIyIiIiK7wuBEWlO7N4CTQpDVNiEls+RBUQG0Gi3vZpyuR0RERER2hMGJtBSigEHNZWxkC2Db6VuIOZ9U8olG/eTdjNP1iIiIiMiOMDiRjneHNYMgY9DpYU4BJq0/WTI8BXUA3GTs6cTpekRERERkRxicSIeTg4jxnYJltZUALNp+Qbc8uagAmj0p72Zy934iIiIiIrIyBicqoXvjANltk9NzS26KK3e6nty9n4iIiIiIrIzBiUq48zDHpPYf7ftLd8penXaAYOStJSg07YiIiIiI7ACDE5Xg7+li8jkzNp15NGXvxnFAUhs+QVJp2hERERER2QEGJyohIsQXvu6OJp2TlafCK9+f0nwhd+1S7Kcm9oyIiIiIyDoYnKgEhSjg7cHhJp+381wS8grU8tcu/bUbuLDV5PsQEREREVU0BifSq1+zQLzYJcSkcyQJ+Cb2mvyS5ACw81Xu50RERERENo/BiUo1p18YxnYINumc66lZppUk535ORERERGQHGJzIoN5N5ZcmB4Cs3ALNX+SWJAeAP3eYdA8iIiIioorG4EQGRYT4Quktv8re5pM3NaXJTZmud/xzrnUiIiIiIpvG4EQGKUQBCweGQTDhnOkbT+PI3/eh6vehzDMk4IdngfjtZekiEREREZHFMTiRUVHhSqwc1Up2ifLsfDWe+fI4Ov3khdsB3eTfKGY2C0UQERERkU1icCJZosKVmD+gqUnnJKXl4JXETvJPSL/JQhFEREREZJMYnEi2AC/5a50KnVA3Rho85J8gd/NcIiIiIqIKxOBEskWE+CLAy9mkc1QQ8WV+H/knpFw1sVdERERERJbH4ESyKUQBiwaZNl0PAFaohiLX0Vte45PruM6JiIiIiGwOgxOZJCpcic9GtjTpHDVEXOuwWF5jrnMiIiIiIhvE4EQm69csEMufkh+efN0cUb/rSKD9ZHkncJ0TEREREdkYBicqkwEtAtGjcQ1ZbR9k5+PdnfG44Cmzwp5HzXL0jIiIiIjI/BicqMzGdw6V1U4tAV8duYbBPxVABRGSwdYCUKedObpHRERERGQ2DE5UZhEhvrI3xQWANuJfUEANwWArCfjxxfJ2jYiIiIjIrKwanBYvXoy2bdvC09MT/v7+GDJkCC5dumT0vF9//RWtW7eGi4sL6tWrh1WrVlVAb6k4hShgaItastv744G8hhe2ABe2lqlPRERERESWYNXg9Ouvv2LKlCk4duwY9u7di4KCAvTu3RuZmZmlnpOQkIB+/fqhc+fOOHXqFObOnYuXX34Z0dHRFdhzKtQzLEB22zvwkX/hbVNZlpyIiIiIbIYgSZLhJScV6O7du/D398evv/6KLl266G0za9YsbN++HRcvXtQemzhxIs6cOYPY2Fij90hPT4e3tzfS0tLg5eVltr5XVSq1hLbv7EVqZr7RtiLU+MP5RVQTSg/GOrrNBbrNKmcPiYiIiIj0MyUb2NQap7S0NACAr69vqW1iY2PRu3dvnWN9+vTB77//jvz8kh/ec3NzkZ6ervMg81GIAt4eHC6rrRoiVhdEyb/40U846kRERERENsFmgpMkSZgxYwY6deqE8PDSP4gnJyejZk3dctU1a9ZEQUEB7t27V6L94sWL4e3trX3UqVPH7H2v6vo1C8SLXUJktV2hGop0yUXehfMygEMflKNnRERERETmYTPBaerUqTh79iy+++47o20FQbcuW+Fsw+LHAWDOnDlIS0vTPm7cuGGeDpOOOf3CZG2Kq4aI1/JfgOwJohx1IiIiIiIbYBPB6aWXXsL27dtx4MAB1K5d22DbgIAAJCcn6xy7c+cOHBwc4OfnV6K9s7MzvLy8dB5kGQNaBGJsh2Cj7WLU7fGTqr28i3LUiYiIiIhsgFWDkyRJmDp1KrZs2YL9+/cjJMT4dK/IyEjs3btX59iePXvQpk0bODrK31OILKN3U3lV9qYVTEWG5CzvosdXcdSJiIiIiKzKqsFpypQpWL9+PTZs2ABPT08kJycjOTkZ2dnZ2jZz5szBmDFjtF9PnDgR169fx4wZM3Dx4kWsXr0aX331FWbOnGmNl0DFRIT4IsDLeCBSQ8TnBQPkXTQ7Fbh+tJw9IyIiIiIqO6sGp5UrVyItLQ3dunWDUqnUPjZu3Khtk5SUhMTERO3XISEh2LVrFw4ePIgWLVrgrbfewieffILhw4db4yVQMQpRwKJBTWW1XaEaKn/U6dKucvSKiIiIiKh8bGofp4rAfZwqRsz5JMzecg4Psgzv7/SSIhqvOsrYvNjVD/i/y4CoMFMPiYiIiKiqs9t9nKjyiApX4o/Xe+GbsRFwcSz9bSa7PHl2CotEEBEREZHVMDiRxShEAZ0b1cB//9O81DZqiNik6ibvggffBeK3m6dzREREREQmYHAii+vXLBA9Gtco9fl96jbyLxYzmxX2iIiIiKjCMThRhRjfObTU535XN4RKEuRtipt+kxX2iIiIiKjCMThRhYgI8YWvu/59ttqIf0EhSBAEmRfLuG2+jhERERERycDgRBVCIQoY2qKW3uf88cC0i6VcLX+HiIiIiIhMwOBEFaZ7k5p6j9+Bj2kXOraS65yIiIiIqEIxOFHFKWUNU5y6Me5JnvKvk3MfiB5vnj4REREREcnA4EQV5l5mrt7jaoh4PX8sJAnyCkQAwIUtwIWtZusbEREREZEhDE5UYfw9S9/oNkbdHp8XDDDtgtumcsoeEREREVUIBieqMBEhvlB6u6C04nlLVCMxJf8lqOWOOuU9BA59YK7uERERERGVisGJKoxCFLBwYBgAlBqedqkjsaxguPyLHl/FUSciIiIisjgGJ6pQUeFKrBzVCgHepU/bW64ainSp9Od1ZKdyQ1wiIiIisjgHa3eAqp6ocCV6hQUgLiEVdx7mYMPx6ziecF/7vBoiXst/ASsdP5G3KS43xCUiIiIiC+OIE1mFQhQQGeqHwS1qoW2wb4nnY9Tt8ZOqvbyLeejfH4qIiIiIyFwYnMgG6B9WmlYwFRmSi/ES5Zl3zd8lIiIiIqIiGJzI6iJD/Up9Lk/ObNLNY4Hd88zYIyIiIiIiXQxOZHXt6/nB27VkQIoQ/4SvkCFvnVPscmDjs6ywR0REREQWweBEVqcQBSwd3qzEcX88MO1CF7cCS+oC8dvN0i8iIiIiokIMTmQTosKVWDWqFZwdHr0l78DH9AvlZQCbRjM8EREREZFZMTiRzYgKV+Lcoj5wcdS8LePUjXFP8izbxWJmc9oeEREREZkNgxPZFCcHEc9E1AWg2c/p9fyxkCQYr6xXXPpNboxLRERERGbD4EQ2p2dYgPbvMer2+LxgQNkuxI1xiYiIiMhMGJzI5kSE+ELp7aL9eolqJCbnv4JsSUZp8qJSrpq5Z0RERERUVTE4kc1RiAIWDgzTOfazuh2a5q7FEVVj+Rc6vorrnIiIiIjILBicyCZFhSsxrmOwzjE1RGxU9ZR/kexU4NAH5u0YEREREVVJDE5ks4qudSpkcolyjjoRERERkRkwOJHNigjxRYCXs86xOHVj3JJ8oZZbZS87ldX1iIiIiKjcGJzIZilEAU//W5q8kBoi3sgfA8CEEuWsrkdERERE5cTgRDYtuLp7iWO71RGYlD8ND+Gi5ww9WF2PiIiIiMqJwYlsmr+n/nC0Wx2BVrlf4KHkYnzk6eQ6rnMiIiIionJhcCKbVrink6DnuQI44IuC/hD0PVlU+k0g4bAlukdEREREVQSDE9m0ons66ctH1yWlvAttHAnEbzdfx4iIiIioSmFwIpsXFa7EylGtEOBdctqe3PLkUl4msGk0wxMRERERlQmDE9mFqHAlfpvVHd+Oawc3J4X2eJy6Me5JnkbPFwBIAPDTK1zvREREREQmY3Aiu6EQBXRsUB3/HdFce0wNEVtVHWWdLwCafZ0OfWCZDhIRERFRpcXgRHYnKlyJ6T0baL/ep25j2gWOr+KoExERERGZhMGJ7NLU7g0Q4KVZ8xSnbowMyVn+ydmpwPWjFuoZEREREVVGDE5klxSigEWDNNX21BCxU9XOtAtk3LZAr4iIiIiosmJwIrtVdMrevILxUEmC8c1wC3nUtFzHiIiIiKjSYXAiuza1ewN4uzqiAA74X0F/ADAYniQJyHNwB+qYOEJFRERERFUagxPZNYUo4PmOwQCAJaqR+LxgANQG2gsC4FSQCenDRtzTiYiIiIhkY3Aiuze1ewP4uDkC0ISnJrlrkSU5GZ62l52q2RD3/NYK6SMRERER2TcGJ7J7ClHAkmGPab9uJV6Bm5AHQSj9HO1Tm58DLmy1YO+IiIiIqDJgcKJKISpcic9GtoQAwB8PTDhTAn54ltP2iIiIiMggBieqNPo1C8SnT7XEHfiYdJ4EADGzuSkuEREREZWKwYkqlQEtAuHftCvuS+6yzxEAIP0mN8UlIiIiolIxOFGl89HTbbFB6G/yeVeO7wDObQYSDnP0iYiIiIh0CJIke8vQSiE9PR3e3t5IS0uDl5eXtbtDFhJz7h9EbG6HasgwWCSiVF6BQNRSIGyQ2ftGRERERLbBlGzAESeqlHo1rYW3hRch97cCJX59kJ4EbBrDohFEREREBIDBiSqpuIRUbMlpjdWqKFntS45K/ZukWDSCiIiIiMDgRJXUnYc5AIB96jbluIrEohFEREREBIDBiSopf08XAECcujFuSb5Ql2clX8Zt83SKiIiIiOwWgxNVShEhvgjwcoYaIt7IHwNAzzomuTxqmq9jRERERGSXGJyoUlKIAhYNagoA2K2OwKT8abgP+Xs7Af+ucvKqBQR1MH8HiYiIiMiuMDhRpRUVrsS4jsEANOFpSv4rpl+kz7uAqDBvx4iIiIjI7jA4UaXWMyxA+/caSDfpXAEA3PzM2yEiIiIisksMTlSpRYT4wtfdEQBwBz6mX4CFIYiIiIgIDE5UySlEAW8PDgdQtgp7Fy9f5j5ORERERMTgRJVfv2aBeLFLiE6FPbmanF0CaVk4EL/dQr0jIiIiInvA4ERVwpx+YfhsZCuccO2E1aoo005OvwVsGsPwRERERFSFMThRldGvmRIn5vWEMmK4SecJACRIyN3xGlQFBZbpHBERERHZNAYnqlIUooCofsNwG34mrXUSADhnJeGlpSsQcz7JYv0jIiIiItvE4ERVjsLBAScavwYAJoUnAGiVFYtJ608yPBERERFVMQxOVCWpGg/EpPxpSIO7SeeNcDgIAWq88VM8VKamLiIiIiKyW1YNTocOHcLAgQMRGBgIQRCwdetWg+0PHjwIQRBKPP7888+K6TBVGv6eLtitjsDk/FdMOs9LyMYUxVYkpeXg2NUUC/WOiIiIiGyNVYNTZmYmmjdvjuXLl5t03qVLl5CUlKR9NGjQwEI9pMoqIsQXSm8XxKnDcE/yNOnc5x1iIEKNCd/8zil7RERERFWEVYNT37598fbbb2PYsGEmnefv74+AgADtQ6FQWKiHVFkpRAELB4ZBDRGv54+FJAGSzJl31YQMPKeIQU5ePiZyvRMRERFRlWCXa5xatmwJpVKJHj164MCBAwbb5ubmIj09XedBBABR4UqsHNUKpz264vOCASadu8BxPX5zfhl9xDiudyIiIiKqAuwqOCmVSnzxxReIjo7Gli1b0KhRI/To0QOHDh0q9ZzFixfD29tb+6hTp04F9phsXVS4Ekdm90Du44vwUYFp+zspkYqVjsvQ7OEhxCWkWqiHRERERGQLBEmSO0HJsgRBwI8//oghQ4aYdN7AgQMhCAK2b9+u9/nc3Fzk5uZqv05PT0edOnWQlpYGLy+v8nSZKpkdpxLRemsXBOA+BEHeOZIEJMEPJ4YcxOCWdS3bQSIiIiIyq/T0dHh7e8vKBmUacbpx4wb++ecf7ddxcXGYNm0avvjii7Jcrlzat2+Py5cvl/q8s7MzvLy8dB5E+gxoWRdH6r8GU36TIAhAoJCCa3/ss1i/iIiIiMj6yhScRo4cqV1blJycjF69eiEuLg5z587Fm2++adYOGnPq1CkolcoKvSdVXk+MnozDtSaYfJ7HtT3IK1BboEdEREREZAvKFJzOnz+PiIgIAMCmTZsQHh6Oo0ePYsOGDVi7dq3s62RkZOD06dM4ffo0ACAhIQGnT59GYmIiAGDOnDkYM2aMtv2yZcuwdetWXL58GRcuXMCcOXMQHR2NqVOnluVlEOnVdfxSqF18TDrnP4qD+PrIFYv0h4iIiIisr0zBKT8/H87OzgCAffv2YdCgQQCAxo0bIylJfmnm33//HS1btkTLli0BADNmzEDLli2xYMECAEBSUpI2RAFAXl4eZs6ciWbNmqFz58747bffsHPnTpPLmRMZJCogtp9s0ileQjayfnmPpcmJiIiIKqkyFYdo164dHn/8cfTv3x+9e/fGsWPH0Lx5cxw7dgxPPPGEzvonW2PKAjCqwtQq4L1QSDn3IbNOBO5LHmiTuworRrVBVDinjxIRERHZOosXh1i6dCk+//xzdOvWDU8//TSaN28OANi+fbt2Ch+RXRMVwKBPIACyi0VUEzLQVvwTi7Zf4L5ORERERJVMmcuRq1QqpKeno1q1atpj165dg5ubG/z9/c3WQXPjiBOZJH47sG0qkJsmq/mX+X3xtmo0pvdsiFd6NrBw54iIiIioPCw+4pSdnY3c3FxtaLp+/TqWLVuGS5cu2XRoIjJZ2CDgyW9kNx/icAQi1Pho319c70RERERUiZQpOA0ePBhff/01AODBgwdo164dPvzwQwwZMgQrV640aweJrC7zruym1YV0tBPjAQBv/BTPKXtERERElUSZgtPJkyfRuXNnAMDmzZtRs2ZNXL9+HV9//TU++eQTs3aQyOo8aprUfLXj+4gSjyEpLQdxCakW6hQRERERVaQyBaesrCx4enoCAPbs2YNhw4ZBFEW0b98e169fN2sHiawuqAPgFSi7SISrkI+Vjp9gtmIDvo5N4KgTERERUSVQpuBUv359bN26FTdu3MDu3bvRu3dvAMCdO3dYcIEqH1EBRC01qcIeALzosAOI346OS/ZzvRMRERGRnStTcFqwYAFmzpyJ4OBgREREIDIyEoBm9KlwM1uiSiVsEDDiGwguPrKaC4Lm8ZbjGtxJz8Kk9ScZnoiIiIjsWJnLkScnJyMpKQnNmzeHKGryV1xcHLy8vNC4cWOzdtKcWI6cyuXvX4GvB5l0ylN5r+OYOgxKbxf8Nqs7FKLcLXWJiIiIyJJMyQYOZb1JQEAAAgIC8M8//0AQBNSqVYub31LlZ0KFvUI1oSkQUVgsIjLUz9y9IiIiIiILK9NUPbVajTfffBPe3t4ICgpC3bp14ePjg7feegtqtdrcfSSyHSZW2AOAjuJ57d/vPMwxZ2+IiIiIqIKUacRp3rx5+Oqrr7BkyRJ07NgRkiThyJEjWLRoEXJycvDOO++Yu59EtuHfCntIvyX7lEGKo/hR3QnH1WHw93SxYOeIiIiIyFLKtMYpMDAQq1atwqBBums9tm3bhsmTJ+PmzZtm66C5cY0TlVv8dmDTGJhWYw9Iknxxq/0itO77rGX6RUREREQmMSUblGmqXmpqqt4CEI0bN0ZqKjf8pEoubBAw4mvAU2nSaQFIRatjL+OPn9dapl9EREREZDFlCk7NmzfH8uXLSxxfvnw5mjVrVu5OEdm8sEHA9Au4XmeI7FOEf4vphRybh11n/rFMv4iIiIjIIsq0xum9995D//79sW/fPkRGRkIQBBw9ehQ3btzArl27zN1HItskKnCry/vwW/8zPIRcWacIAuCLDHyz8VuIijGICjdt1IqIiIiIrKNMI05du3bFX3/9haFDh+LBgwdITU3FsGHDcOHCBaxZs8bcfSSyWRGhNbBBMdTk8yLFeLzxUzxU6jJto0ZEREREFazMG+Dqc+bMGbRq1QoqlcpclzQ7Focgc4s59w86bG4NL0F+qfGdBRGYUjAN8/s3wXMdQ7gpLhEREZEVWLw4BBE9EvVYbVyNXGJSjb1+ijj0EePw1s6L6LjkF8ScT7JY/4iIiIio/BiciMygZdRY3GwyDqaM3y52/BIi1EhOz8XE9ScZnoiIiIhsGIMTkZko//Mh1gkDZYUnQQB8hQxMVfyoPTZ7yzmueSIiIiKyUSZV1Rs2bJjB5x88eFCevhDZNYUoIK3TAnx0wAkzHKNlnTPNIRpXpEDsUkfiQVY+jl1NQccG1S3cUyIiIiIylUkjTt7e3gYfQUFBGDNmjKX6SmTzpnZvgDtOtWW3FwVgheOnmK3YAACI/fuepbpGREREROVg0ogTS40TGaYQBQzr3Ao4ZNp5LzrswBkpFEB9i/SLiIiIiMqHa5yIzCyi20BkuwZALbO9IGgeSx0/x7U7aRbtGxERERGVDYMTkbmJCrgOfB8CYFKJci8hB70uzcc7O+Mt1TMiIiIiKiMGJyJLCBsEYcQ3gJOHSacNUhxD9aNvY8fpWxbqGBERERGVBYMTkaWEDcKx4b/joeQie38nQQBecNiJXT+swq6z3NeJiIiIyFYwOBFZ0J1sNWbmTzRpyp4gAG86rMbUDb9zU1wiIiIiG8HgRGRB/p4u2K2OwGpVlEnnVRceYopiK974KZ6b4hIRERHZAAYnIguKCPGF0tsF+9RtTD53hsNmNHt4CKt/S8C20zcRezWFIYqIiIjISkzax4mITKMQBSwcGIYp67NwS/JFAFIhCvLPX+i4Dp12tYH6399xKL1dsHBgGKLClRbqMRERERHpwxEnIguLCldixag2+MRxPABA7qCRIACBwn1MUWzVHktOy8Gk9Se59omIiIiogjE4EVWAqHAl3pk7F5e7fYZc15omnTvDYTP6iHEAHu0LxbVPRERERBWLwYmogihEAY0efwaur11EQuvXTTp3oeM6iFAD0ISnpLQcxCWkWqCXRERERKQPgxNRRRMVqNt3Om7DV9b+ToVT9r51fBuR4nltgLrzMMfCHSUiIiKiQgxORFagcHDArchFJu3vFKn4E985vYvfnSeijxiH6u7OFusfEREREelicCKykpZ9nsXl6t1NPq8aMrDKcRl8b+y2QK+IiIiISB8GJyIrqt/3ZZPPEf4tZx4YuwhQq8zbISIiIiLSi8GJyIoU9bog18lH1lqnogQB8M6/A9W1I5bpGBERERHpYHAisiZRAechnwImbIpb1Om9G8zbHyIiIiLSi8GJyNrCBkHoNrdMp7a69R3++HmdeftDRERERCUwOBHZgi4zAa/AMp2qPLYIMef+MXOHiIiIiKgoBiciWyAqgKilJp+m2eMpFZu3/IAfT91E7NUUqNQmLpgiIiIiIqMcrN0BIvpX2CBgxDfA9peAnAcmnRqZdwzTNzYEACi9XbBwYBiiwpUW6CQRERFR1cQRJyJbEjYIeO1voOkwkzbHfc5hN/qKxwEAyWk5mLT+JGLOJ1mmj0RERERVEIMTka0RFcB/1kB4Yg3UMk9RCBI+c/wYrzt8jXZiPESo8cZP8Zy2R0RERGQmDE5Etip8GKQn1soeeRIEYLxDDL53ehuHnV9Gs4eHEJeQatEuEhEREVUVDE5ENkwRPhRXwl4y+TwlUrHScRkUl36yQK+IiIiIqh4GJyIb1+CJN5Cp8DbpHEHQ7Knb/PwSQK2yTMeIiIiIqhAGJyJbJyqQ1nCYyacJAuCclQQcWAwkHGaAIiIiIioHBiciO1CzrenBSevw+8C6AcCycCB+u/k6RURERFSFMDgR2QFFcEdkKHzKd5H0JGDTGIYnIiIiojJgcCKyB6ICNzu+Dalc1cX/PTlmNqftEREREZmIwYnITtTvNgp7xY7lvIoEpN8Erh81S5+IiIiIqgoGJyI7oRAFqId9gYeSS/kvlnG7/NcgIiIiqkIYnIjsSNRjtfFXu8WQJJRv2p5HTbP1iYiIiKgqYHAisjOt+z2PvxuOK/P5WXAFgjqYsUdERERElR+DE5EdCn3mvzgduQz34WXyua5SNo5+/pIFekVERERUeTE4EdmpllFj4fV6Av5uOcfkcyOTv8Ufu9ZYoFdERERElRODE5EdUzg4oN7A/0O26Cb7HEHQPIKPL8CRv25DpS5XjXMiIiKiKoHBicjeiQokdnrP5IIRfkI6lq9di7bv7MWus7cs1z8iIiKiSoDBiagSqN9tFNYrhph83mrH9xGRfRiTN5zC4l3x5u8YERERUSXB4ERUCShEATWGLcHk/FeQInnIPs9VyMdKx08wW7EBnx9KwK6zSRbsJREREZH9YnAiqiSiwpUYPHISBjmvwaaCziad+6LDDvQTYzF/23moCgqAhMPAuc2aP9UqC/WYiIiIyH5YNTgdOnQIAwcORGBgIARBwNatW42e8+uvv6J169ZwcXFBvXr1sGrVKst3lMhORIUrcWh2LzTvOkz2OYXFIpY7fooXctag4L9NgXUDgOhxmj+XhQPx2y3YayIiIiLbZ9XglJmZiebNm2P58uWy2ickJKBfv37o3LkzTp06hblz5+Lll19GdHS0hXtKZD8UooBG9RuYfJ4oAC847IRTVrLuE+lJwKYxDE9ERERUpTlY8+Z9+/ZF3759ZbdftWoV6tati2XLlgEAmjRpgt9//x0ffPABhg8fbqFeEtmhoA6QPJVAehIEQf5p+ttKAAQgZjbQuD8gKszUSSIiIiL7YVdrnGJjY9G7d2+dY3369MHvv/+O/Px8vefk5uYiPT1d50FU6YkKCH3fA0wITYZJQPpN4PpRc12QiIiIyK7YVXBKTk5GzZo1dY7VrFkTBQUFuHfvnt5zFi9eDG9vb+2jTp06FdFVIusLG4S/uiyHSjJbegIybpvvWkRERER2xK6CEwAIxeYSSf/u+Fn8eKE5c+YgLS1N+7hx44bF+0hkK+p3G4XXHWaYvDluqTxqGm9DREREVAnZVXAKCAhAcrLuwvU7d+7AwcEBfn5+es9xdnaGl5eXzoOoqlCIAroOnYCJ+dOQhGrlutY9yQsxGSFm6hkRERGRfbGr4BQZGYm9e/fqHNuzZw/atGkDR0dHK/WKyLZFhSsxdOREDBBXYmNBlzJf57QqFG/suASV2hxDV0RERET2xarBKSMjA6dPn8bp06cBaMqNnz59GomJiQA00+zGjBmjbT9x4kRcv34dM2bMwMWLF7F69Wp89dVXmDlzpjW6T2Q3osKVODE/Co91GlLma7RQXMXttCzEJaSar2NEREREdsKqwen3339Hy5Yt0bJlSwDAjBkz0LJlSyxYsAAAkJSUpA1RABASEoJdu3bh4MGDaNGiBd566y188sknLEVOJINCFBDWqGGZz68upCNC/BN3HuaYsVdERERE9kGQJLMsGbcb6enp8Pb2RlpaGtc7UdWjVgHv1wOyH5Tp9H0FLXGh2//wSk/TN9glIiIisjWmZAO7WuNEROUkKoB2k8t8eg/FKXgenIdjv2zVhDAiIiKiKoLBiaiq6TITcPVFWYaaBQF43mE32h9+FtnvhwHx283ePSIiIiJbxOBEVNWICmDgxxAglCk8FXLJSoa0aQzDExEREVUJDE5EVVHYIGDE1xC8Ast8Cc2e0xKkmNmctkdERESVHoMTUVUVNgiYdh54dgd+bvg2ns6bixTJ06RLCACE9JvA9aOW6SMRERGRjWBwIqrKRAUQ0hm9n5qKiy4tMS9/LCQJMLnW5t8HOepERERElRqDExFBIQpYMuwxxKjb4ydV+3+n4Zng8AfAsnCudyIiIqJKi8GJiAAAUeFKfDayJX6R2pTpfCk9CWCxCCIiIqqkGJyISKtfs0A83b1tmc4VIGmq9LFYBBEREVVCDE5EpKP94wOR7RoAdRnOFSABLBZBRERElRCDExHpEhVwHfg+BAhlCk8AoI7fBiQc5sgTERERVRoMTkRUUtggCCO+RqaTf5lOF0/8D1g3ABILRhAREVElweBERPqFDcLZ4b/hzfxRZb9G+i1ILBhBRERElQCDExGVqn0Df/zg0B/3TNwYt5AAAJKEjC0vAQV5Zu0bERERUUVicCKiUilEASPaBGGrqmOZryEIgEfBA+S+15AjT0RERGS3GJyIyKCeYQHYpy7b3k5FOeXd57Q9IiIislsMTkRkUESIL254NMctyRdqqezXEQAAEvd5IiIiIrvE4EREBilEAfMHPYY388cAQPnDE/d5IiIiIjvE4ERERkWFKzFk5ETMdXwNqfAo/wUv7Sr/NYiIiIgqEIMTEckSFa7EO3Pn4uKIODyUXCCVY+QJZzdxuh4RERHZFQYnIpJNIQro3LQWdtdfAABlD09Z96C6dsR8HSMiIiKyMAYnIjLZE6OnYGXAQjwox7S9H75ZhZjzSWbsFREREZHlMDgRUZlMnjQDazvsxdN5c7E8fxCyJAeTRqBGqHdi+4YVDE9ERERkFxiciKjMXu7VBAkebfCB6ilMz58KCfKn74kCsMLxU9zdMhuq8pTqIyIiIqoADE5EVGYKUcCiQWEQAOxWR2BS/jRkwMWka4xSbcWVA+st00EiIiIiM2FwIqJyiQpXYuWoVvB0UWC3OgLNc7/EW/lPyzpXEDSPoNjXgb9/Bc5tBhIOs+IeERER2RxBkspVVNjupKenw9vbG2lpafDy8rJ2d4gqjew8FZosiAEAiFDjD+cXUU3ILNvFvAKBqKVA2CAz9pCIiIhIlynZgCNORGQWrk4KTOgcDABQQ8TqgqiyXyw9Cdg0Bojfbp7OEREREZUTgxMRmc28/k3ROsgHALBCNRSpknsZ93r696SY2Zy2R0RERDaBwYmIzGrTix3g4+oINUTMyZ+Ass8FloD0m8D1o2bsHREREVHZMDgRkVkpRAFLhj8GQFNp76OC4eW7YMZtM/SKiIiIqHwYnIjI7KLClfhsZEvNXk2qoUiRPMt+sT93mq9jRERERGXE4EREFtGvWSCWP90KaoiYlz8WkiR/c9xCEgBc2AJc2GqBHhIRERHJx+BERBbTr5kSq0a1wjGXzvi8YIDJ5wv//pn/4xSoCgrM2zkiIiIiEzA4EZFFRYUr8cfrvZD7+CJMV78MdRmqRTgWZGD1u5MQcz7J/B0kIiIikoHBiYgsTiEKeKVnA3z4xpvY2WhxmUqUj1NtwrYNKxmeiIiIyCoYnIiowihEAQNHTsZXAa+bHJ5EAfjM8WMc3LoaqrIMWxERERGVA4MTEVW4GpEj8UVB/zIVjJib/wniLidbpmNEREREpWBwIqIK5+/pgsWqZ/B5wQCotSUgjBMEwEvIQduNzYH9iwG1yoK9JCIiInqEwYmIKlxEiC983R2xRDUSjXLX4a38kciRHGWPPjmoc4FDS4B3lMDBpQxQREREZHEMTkRU4RSigLcHhwMACuCAr1QDMC1/kukXUuUCB98F3q8PxG83cy+JiIiIHmFwIiKr6NcsEBM6B2u/fgAvCPJn7enKTgU2jeb0PSIiIrIYBicispp5/ZtiXKdgAIA/HpT/goeWAO+HcvSJiIiIzI7BiYisav6Apni8UQ3cgY95Lph9XzP6xPBEREREZsTgRERW90KXUMSpG+OW5AuzbdG0YzpwdhOQcJjT94iIiKjcGJyIyOoiQnxR09sNb+SPAWD63k56Zd0DtkwA1g0AloVrRqDUKk2QOreZgYqIiIhMIkiSWT6i2I309HR4e3sjLS0NXl5e1u4OEf0r5nwSJq0/id5iHBY7fglfIcOMVxcASICrr6aQRCGvQCBqKRA2yIz3IiIiInthSjbgiBMR2YSocCVWjmqFMx6d0SZ3FT7MfwIZkouZrv7v74eKhiYASE8CNo3heigiIiIyiiNORGRTVGoJy/dfwUf7/oIINdqJ8eggXMB4h11wQX7ZS5Yb4hkITD8PiAoLXJyIiIhsFUeciMhuKUQBr/RsgOk9G0ANEbHqcHyoehLT8qdAgpnWPxX38BZw6AMLXJiIiIgqCwYnIrJJU7s3QIDXo6l6u9URmJQ/DffhbpkbHnyXU/aIiIioVAxORGSTFKKARYPCUHRm3m51BNrkfo4P85/AfckCASpmNivtERERkV4MTkRkswoLRvi6O2qPqSHiU9UwtM79HPtVzcx7w/SbwPWj5r0mERERVQoMTkRk06LClTg2pyd83Z10jqsh4oX8mebbMLdQxm0zX5CIiIgqAwYnIrJ5Tg4i3h0ajuIF9QrggB2q9ua9mUdN816PiIiIKgUGJyKyC4XT9pTeuns7TSuYigzJxTzV9py9gKAOZrgQERERVTYO1u4AEZFcUeFK9AoLQFxCKpLTsjHvx3PIygdezZ+IlY7LAAnl2+dJpQL+PgRkp2hGnoI6cG8nIiIiAsANcK3dHSIqh5jzSZi4/iQAoI8Yh4WOXyNQSDXfDbwCgailQNgg812TiIiIbAY3wCWiKiEqXIlVo1rBUSFgtzoCnXI/wVN5r+MPVX3z3CD9FrBpNHBwKcuUExERVXEMTkRk16LClVg7NgKAptLeMXUY/pO/CPclD/OsewI0m+MuC+cGuURERFUYgxMR2b17Gbk6X6shYnb+eEiA+cJT+i1g0xiGJyIioiqKwYmI7J6/p0uJY7vVEZiUPw334WHem8XM5rQ9IiKiKojBiYjsXkSIb4ky5YAmPLXJXYUP85/AfckcAUoC0m8C14+a4VpERERkTxiciMjuKUQBCweGldggF9BM2/tUNQytc1fhzfxR5rnhpV3muQ4RERHZDQYnIqoUStsgt5AaItaqonBL8oW6vOuejn0GnN8KJBwGzm3W/Mnpe0RERJWa1YPTZ599hpCQELi4uKB169Y4fPhwqW0PHjwIQRBKPP78888K7DER2aqocCV+m9Ud301oj+c7BsPX3UnneTVEvJE/RvP38oanzc8C6wYA0eM0f37QQBOmiIiIqFKyanDauHEjpk2bhnnz5uHUqVPo3Lkz+vbti8TERIPnXbp0CUlJSdpHgwYNKqjHRGTrFKKAyFA/LBjYFCfm9dSGKGcHzX/uCotGJMPXvDfOStGEqT3zzXtdIiIisgmCJJmtWK/J2rVrh1atWmHlypXaY02aNMGQIUOwePHiEu0PHjyIxx9/HPfv34ePj0+Z7mnK7sBEVHkcuXIPz3x5XPu1CDXaifFY4/g+XIR8897siTVA+DDzXpOIiIjMzpRsYLURp7y8PPzxxx/o3bu3zvHevXvj6FHDFatatmwJpVKJHj164MCBAwbb5ubmIj09XedBRFVP+3p+8HV31H6thohYdThWFAwy/82ixwEXtpr/ukRERGQ1VgtO9+7dg0qlQs2aNXWO16xZE8nJyXrPUSqV+OKLLxAdHY0tW7agUaNG6NGjBw4dOlTqfRYvXgxvb2/to06dOmZ9HURkHxSigLcHh5c4vkI1FOmS/oISZSapgR+e5Wa5RERElYjVi0MIgm4BYUmSShwr1KhRI0yYMAGtWrVCZGQkPvvsM/Tv3x8ffPBBqdefM2cO0tLStI8bN26Ytf9EZD/6NQvEi11CdI6pIeK1/BcgSYDZJy5zs1wiIqJKw2rBqXr16lAoFCVGl+7cuVNiFMqQ9u3b4/Lly6U+7+zsDC8vL50HEVVdc/qFYflTLVH09zMx6vb4vGCA+W+WfhO4erBk2XK1iqXMiYiI7IyDtW7s5OSE1q1bY+/evRg6dKj2+N69ezF48GDZ1zl16hSUSqUlukhEldSAFoEQRQGTN5zUHluiGokzUijedlwNP+Gh+W727XAARYayXKsBEIDs1EfHvAKBqKVAmAXWWxEREZFZWC04AcCMGTMwevRotGnTBpGRkfjiiy+QmJiIiRMnAtBMs7t58ya+/vprAMCyZcsQHByMpk2bIi8vD+vXr0d0dDSio6Ot+TKIyA71a6bEKrEVZm0+i7ScAgDAz+p22J3bFhHin/DHA4QINzHN4UcAQCkziGUoNv8v+37JJulJwKYxwIivH4UntQq4fhTIuA141ASCOgCioqydICIionKyanB68sknkZKSgjfffBNJSUkIDw/Hrl27EBQUBABISkrS2dMpLy8PM2fOxM2bN+Hq6oqmTZti586d6Nevn7VeAhHZsahwJTxdHHXKlKsh4pg6TPu1K/LxosMOC/fk33D18yygcX/gz51AzCwg/dajJhyVIiIisiqr7uNkDdzHiYiKUqkldFq6H0lpOaW26SseN/8UvtI0HQZc+BElRqrw75BX0VEpIiIiKhdTsgGDExFVeTHnkzBp/ckSUaUoEWrtFL4G4g285LCtwvr3iKAZeZp2jtP2iIiIzMAuNsAlIrIVUeFKrBzVCkrv0vdzKpzCt13dAUfUj1Vg74qSNJX6rhveJJyIiIjMz6prnIiIbEVUuBK9wgIQl5CK5LRsrDx4FX/dydDbNk7dGLckXwQgFWKZi0aUQ8ZtK9yUiIioauOIExHRvxSigMhQPwxtVRt7ZnTFhM4heqvpqSHijfwxACywaa4cGbe59xMREVEF4xonIiID8grU+Cb2GraduYmz/6TrPNdHjMNixy/hK+gfmbIoVtkjIiIqN65xIiIyEycHEeM618OPkzvB21V3dvNudQTa5K7Ch/lPIFuq4JnPhXs/xW+v2PsSERFVUQxOREQyKEQBS4c3K3FcDRGfqoahae5abC9oV4FT9/69UcxsTtsjIiKqAAxOREQyRYUrsWpUK/i4OZZ4Tg0RLxe8gsn5r+ChVHp1PvP6t8pewuEKuh8REVHVxTVOREQmUqklHL18DxPW/46cfHWJ50Wo0U6MxyhxH/op4gBAb5EJs3HxAdpPBvxCAY+aQFAH7vNEREQkAzfANYDBiYjMZdfZW5i84ZTBNn3EOCx0XIdA4X4F9QosHEFERCQTg5MBDE5EZE6Ld8Xj80MJBtuIUCNC/BM1kQo/IR0pkheChNuY5hBt2X2gRnzD8ERERGSAKdmAG+ASEZXDnH5heCzQB1O/L33kSQ0Rx9Rhep+b4Rhtqa4BP04EXLyB4E6cukdERFROLA5BRFROA1oE4rORrUw+b7lqKFIld8tV4svPBL4eBHzQADi/VXOsIA+IXQHs+j/NnwV5Fro5ERFR5cKpekREZhJzPgmzo8/hQXa+7HP6iHFY6bgMAixcQAIAAlsBSacBqVhBi1ptgXrdgJDOHJ0iIqIqhWucDGBwIiJLKqy4N3HDH8jMlbe/Uh8xDosdv4SvkGHh3sng6gsM/FizNkqtAq4fBTJuA27VNcku8y4r9xERUaXB4GQAgxMRVYSY80mYtP4k5P4HtmgJ8y6KM/AUci3aP6M6vAyc3wyk39L/PCv3ERFRJcDgZACDExFVlJjzSXjjp3gkpeVojwmA0TBVWIWvp/AHhjr8Bj/hoUX7WTb/zisc8bXx8FR05MrWRqtsuW9ERGRxDE4GMDgRUUVSqSXEJaTizsMc+Hu64H5mHiZvOCn7fBFqPKeIwQLH9RbsZVkJmpGnaedKDxvx24GYWbojV7YyWmXLfSMiogrB4GQAgxMRWduus7cwZcMpk6bx/eb8MgKQatl9n8pq9DYgtJvuMbUKOPQBcPBdPSeYMFplKfHbgU1jUHL8zwb6RkREFYbByQAGJyKyBTtO3zK491NxhdX3ANheeHLxAQZ8DLj6ANd/A+7+BVw7DGSnGj7PrToQtRjwVFbsFDm1ClgWXvr6LTkjaUREVCkwOBnA4EREtmLxrnh8fihBdvs+YhwWOq5DoHDfgr2yEjc/oNmTQKN+xkNUedclJRwG1g0w3u7ZHZoS7UREVGmZkg0cKqhPRERUzJx+YWheuxpe33YeqZnGN6LdrY7A3tw2mKLYihkOmyHBBkefyiorBTj2meZhaJ1RWdYlqVWasHT9t39n5qn1tysu47apr4LIdrEQClG5ccSJiMjKVGoJH+39C8sPXJF9jmb06WsECo+mw0lSBWyiW5HaT9aMQNVpB9w4DlzapQlWxtoX/UAYvx346WUguwyjdBxxosqChVCISsWpegYwOBGRLYq9moKn/3fMpHMKy5b74wHuwAe+SMNbjmtttHx5OQgiIMkcJQI00/76/RcQRWDT6DLeUwHMSwYcnMp2PpGtYCEUIoMYnAxgcCIiW6RSS+i0dL/Onk9lUTRMBQu3MN1hC4BKNhIll6M7kJ9Z9vPtYcSJ06/IEBZCITKKa5yIiOyMQhSwcGAYJq0/KbtMuT5qiDimDtN+fUmqi8WOX8IXGeXvpL0pT2gCbH+N04WtwM5Xgax7j45x+hUVdf2ogdAEABKQflPTztZ/SVAe/AUDmQmDExGRjYgKV2LlqFZ446f4co88FSosKNFOjEekEA8IwDF1YwDAM+Iv6Kc4AaCKjkgZ41HT2j3QVbTIxdWDwM0TJduk39JMyzL39Ct+8DSfivxeyg3/tv5LgvLg+i4yIwYnIiIbEhWuRK+wAMQlpCI5LRupmXnw9XBGakYu3tp5sUzXVENErDocsQjXOX5U3QyzpQ140WGHObpe+WTeLVmRL6QzENyp4kODSUUuJE1bF2/z9JUfPM2nor+XcsO/rf2SwFxKW9+VnmSZXzDIxV9E2C2ucSIisgPmWgOlT1/xON52XG20qESlq9onh6AAJJXuMZdqQPtJgF+oZhNfQdCErOIfgMz14Sh+e9mLXJT3Q7ncwgL8IGicNYo0nN8KbH7WcBuvWpVzjZOtru/iLyJsDotDGMDgRET2KuZ8UrnXQJWmaFGJu/BChHAR4x1+hqfwKKipJAEKoUr9L8N0rr5AUCfNvlTJZ4C8ImvLyvLhSK0CPmoKPEwqY4fK8aFc7gfPPu8Cu+fYzgdBY6OEpo4iltYekH8da3yIN3rPf/1nHdB0iHnuaUtscaNrVji0SQxOBjA4EZE9izmfZNY1UIYUL3f+u7oh2op/YqZiE1qJV/SOPhX+D6WqDUyZZMQ3QOP+8j50y/3wZ4yrHzD8KyA7Rf+IkL5wAABfl/VDnJU+CJY2pdHVFxj4saas/bapQN5D/c8X72tp13Py0PyZV6zoSmnXkftz7PMu0G6iecJTRQQHc4w0Wmq08txmIHqc8XYRLwBNBpXvvnJeg62NgHGUWIvByQAGJyKydyq1hLiEVNx5mAN/Txfcy8jFnC3nkJFbUGF96Csex3uOn+uMSAFAquSBE0JT9MHxCuuL3REUgKNryQ/djh5AaHfNcz61gZCumg81WyaYvw+Fe12FDyk9HChcAFV5ArqeD4JyP6yV5UNdeaY0FhrxzaPQU57rFb0OIP9DPGC+0Tq59xz+FfDYE6Zf3xxTziw5bc3UXzqU9b5yX4MtjYBxuqAOBicDGJyIqDJSqSUs338Fa44k4EF2foXcU4Rap1pfrDoMx9VhaCfG4zundyukD5We6AioLfjzbNQPuLTLctcHgGZPAi2e0Uxf3DlTM+pVyFMJ9H1P98Oavg91RYOePuWe0vivwvU+QPmu5+oL/N+VR2GvLCOHxcOXqSz5Qd3UKWf6gvCfO0u5xr/K+/q1IzxJpd+jvPc15ftg6SArlzWmC9pKkZ1SMDgZwOBERJVZ4WhUclo2frt8F1tO3bLImihDRKjxu/NEVEOG/ul8EqAG10tREY0HaUbaCrKBi9tLb9fhZaD3W5q/F/0wlnodOL/JPH159t8qk+WdItlkMBAxQRMS4n8yXqShOEd34Onvyv4BU1ZwEIAnVgPhw0y77vv1gezU0q9ZdKRRXxD2VAK5D0uOuhZVPHyWRakhwQC595Wzhqxo4Y2rB4FvBhu//+htQGg3+f01hal9LnpeYfA1VBBHH2PTZ21ghIsb4BIRVVEKUUBkqB8AYGir2ujRJACTN5ys0D6oIWJO/nisclxWohJf4a/qpuS/hAfwgj8eIFhIwnSHaEDg2qgq608DYamoo58AtVpr/q5vrZI5mGtPo4vbNA9PJVCQa/r5+ZmaNWbGRttKIyo0U682jTHQSAI2jwUu/gQM/1JeSDn0gYHQ9O81CzfVzb6vP7jIGcnLTtXcq9ss420NcXID8kzYDFvufY1uLgzdzYWvx8q7/9+/an4OxgJJQR5w4n/A/WtAtWCg7QTAwcnw6I6pfQb0b7RdlMIZCGwNBEdqphcXDfqGprtmp2qeK+/IYgXjiBMRUSWnr6BEgJcz2gT7YsfZck5tMqCPGIdFjl9DKTz6kHVL8sUb+WOwWx2h03a2QrOfVPERqipZAp0MK/faKyNGbwPuXAB2z7XcPcqiyRDAwRF4cAPwqQs0HwnU62K4GuChD4Ajy4D8LOPXd60GDPzE8IdYtQp4vx6Q/cD49Yb9D9i30PgHdUOcPIDZiYZfY2lr4cqzRs2lGvDaVf0FHgrvdzse+O1D49fqNAPoNgf4sIG871shfdNYC+1+HTi2QlPsREsAGkYBN46VPrqjypM3XbD9ZCBqMbBnvuaXFaZwqQYM+kRTAOe9UCDHyN5zNlAOn1P1DGBwIqKqqHhBiYgQXyhEATHnkzA7+pzF1kUVr8wXp24MNUS9bfXtJ3VL8sUJVUN0UZxHNcHAtB4ic3H2AnLTrd0LeZw8gEErAHc/3fBw8acyjsgJumtcCvKAuM81oyX5WZppWud/kHepXm8De1838f56dJtbcvRHrQJ+fQ+IXa6/5H/j/vJKsRvSeSbg5vtoRMdTCeyZV7ZrOnmWfXR0+BogI+lRP/7+Fbi8u2zXChsKxP9ovJ1bdaDvUvkFTfRpOgy4sEVe24osCa8Hg5MBDE5ERLqsUViiNKUFrcLjNZGK2s6ZqB8UjPqh9SGpJST+cw0ZCl8MvjIXLgXphqf7OXkCUOtO3fGqBUQtAdQFwObnYdJ6CCJb4+ACFJRjRM7RHWjUF0g6C6T8VY6OCDDLvyWFCxA5SfNh3sMfSLmqGUUz9BqbPw2c+a7896aKUTjCZSUMTgYwOBER6Ve0sERqZh58PZzh7+GM7+ISseOc5ab0mUsfMQ4rHZdBQMl1VRKAq01fQoMn3tAcLG16z4WtwA8mLuInIqKyc/UD/u+y1abrMTgZwOBERGS6XWeT8Pq280jNzLN2VwzqI8ZhoeM6BAqP5tXfknzxZv4YnPHsgt9mdYdCNLJoSl8VMHP99pyIiErSNyWzgjA4GcDgRERUNiq1hGNXUzB5w0mkWXlKnyGG1lVN6RaKTg1qaNd4lUZVUIA/j+9G9v2bcK1WC43b9oTiRiyQcBC4eRpwdNFUBks6XSGviYio0rNShT0GJwMYnIiIyifmfBImrT9p1+MvzgoBj9X2Ri0fVwiCgFrVXNEhtDra1/PD3vjkElUIld4uWDgwDFHhykeFNtIz0e/nznDIe1DKuipBU6nM0aV8i9SJiKoCK1XYY3AygMGJiKj89JU4rwwUAqDS83/FwmD0QpcQbD+TpH3dfcQ4rHJaptNG54wRX2sqfBWuqbq4Q7O3T/EywoGtAb9QwKc2ICiA378CslJKdsStumbh+/nN8vbCAYC6HQD36oY3liUisgVWqLDH4GQAgxMRkXkULXF+7V4WvotLRHJ65QpScmjWVX2NwCL7VWW7BsB14Pv6p52UtnFlUYX7xTxMAjLvAu41NOWQCwtZFN+/JisF2D1Hd2TLrTrQ78NHG6fqXbtVjMJZs9eLXY8nEpHdGv4V8NgTFXpLBicDGJyIiCyjeJD6/NBVZOWprN2tClF8XdUJdWOsGNUGUeHKiuuEoc1A9bVxq64Z+Uo8qslJIZ2B4E6aPYAMVRZ0cAYKci3zGhQuQLuJwD8ngMQjlrmHRbB4CFUhdToADftoRrFv/WHea3PEybYwOBERVQyVWsKnv1zGl7/9jYzcRwHK190RQ1vUQs+wANzPzMPcrefwIMt2i02UldLbBb/N6g4AOmXefdyckJqZiwfZ+RAgIDLUD22DffHH9fu48zAH1d2dAQG4l5Grs1lxhdI3OlU4ghU2sPTwFdRB0zbxKHD3L+DqL7oblBpTdHG4nBGyQmFDAb96wIN/AK8A4OinxaZDWki7iUDjAUCddprvyfXfNN8HQQCOfWb4tXsGAq2f00zRTLkKHF8JZN8vvT2RtTl5AENW6o6kb3pO3qa6cnCNk+1hcCIiqlhFR6L0BYHCan2xf9+DWgKquTnhn/tZ2BCXiHx9C47sSFTTmoi7dr9cZdx93R3x9uBw9GsWqHNc3/cVgMHvtUnkjGDJuUbC4UeBIqSzJhwUn1ZYuAlx8amNhX34cyfwx1qgIFv3eSdPYNDyR9MRC+2ZDxz9pPR+KVsCmbfLV7Sj62zg8TmlP1/42q8d0gQ678BHm7gWnXZZvP2BtzUjbpbSqB9w65T8NXJkeV1nA7HLTfslQ0ULGwI8sVr/KPaSuubpO6vq2R4GJyIi+1A4YrXiwBXkq6vU/6r0GtgsAN0b10RqZh4SU7Ow5dRNPMwp0D7v5ihCApCd/2ikpWg1QJtSllCmL4QFdyr9vD3zNR9GdUaeRCByMtDnnZJ9qNUG+GM1kPo3cHoDkJ9Vel9cfYH/u2K534xf2ArsfBXIuvfomJMn0H4K4N8I2PV/us/JUXTNm1oFHPoAOPiu4XOqNwSaDARER00QNfQ9AQBBNDzS5+gBtJ8MCBKgKgBy0zWjc771NGFy5wzLjLo5eQLtJmlmVBobCSzvfQYtB0QR+Oll46/F1RcY+LEmLJzfCmw2YfNtJ0/NiOUfq4G8zPL02rDiayX1MbXvxRX9PlgBg5MBDE5ERPaltCl/JN8TrWrBxUkBAUDLOtWg9HEtdTQqr0CNb2Kv4XpqFoJ83TA6MhhODmLFd9oc5BTi0Cd+O7BpDEpdt1QRvxk3FC6LPpdyFTi5Vnf0zNkLaPYU4BtcsrBIUfHbga0T9XzwFoAOLwG939Ltz+ZxBqZlCcATawF3P8Nr6AyFzeKjdKVVmSwMkTWbADumlQwoojMQPgyo373kay/+vftjLfCwHCOPTQYC1RuXfH2F4bT4FEwHV6B+LyBifMnvh7GRUgCo3RboPv/RuWoV8Ot7wJFlQEGx4jyO7kC+jFDl6ge0GQtAePS9yrxr2kizsb47eQCDVgCuPro/35Cuxt8XFsbgZACDExGRfSqcmrbnQhLWHL1u7e7YPW8XB/QKq4nI0Op4kJUHXw9n/BJ/GzvPJ6HoJwMBwPjOwZjXv6nV+moV+tZYlTal0NrKM61SrQKuHgTObQRyM4GgSCDihdIDpr7RMEt/X4yFSFNGIg1d2626ZgQs865meuiFLYbP7fCybrg0te/6XNgKbJsK5D3UPV7atNSi99H3fdi3yHgYM9cvAgyNlHZ7zarhyBAGJwMYnIiI7J++faQKp6Wp1cDr286Xa10RlRReywvz+oWhdVA1nEhI1a5J83Z1RHrOo0IX7ev5ATC81qr4+qzWQdW0xTEssl6rrMyxzqsyqirfl7KGmPIqbxgsrrTXYYkpcnb43mBwMoDBiYiocjBUdKLoc9XdnaGWJMT+fQ837z8qLnDrQTZO/5Nm9wUobI2TQoBCFHTWWrk5igiv5Y3WwdVwOy0Xu+OTkVlk2qUoAEWXsbk7aaYGZuY9ukaAlzMWDWpqe+u1qHIzd4ixlsryOiyAwckABiciIipUWNHv8JU7+Oq3awxRduDl7qFoV6867qTn4F5G6WXdi45kFZaC9/VwRoCX4dErY1UgTW1HRLaNwckABiciItIn5nwSJq0/yW1MK5HStqWt5uaA0e2DUKCWcPN+NgRBgNLHBXfSc7Hv4h2kZT/aV0zp7YL5/ZugmruzNiTdz8zDWzv1TxUtbUSMQYvINjE4GcDgREREpdG3dorIFGM7BKFnkwCoJQnHE1KgloDb6TklApmvuyPeHNgU1dydEfv3PcDAGjF9a8DKGroqVdVEIjNgcDKAwYmIiAwpHBnYG5+MradvGS0yoak6F4JvYq8jp8DAHjZEMjg5CBAh6LyXio+c+bg6YmzHYEzqVh8nElJx5Opd7chZrWquaB/iB1EUcC8jV7vG73hCCo5cScHpfx7oVE0UBWBC5xDM6RemPVae0TE5G15bcuSNI3tkKgYnAxiciIhIrqIfwhLuZuLrY9d1glTR6Vly9ptyEAFHhahTOKG06WREFaldsA9aBfvi94RUnLuVjpyixT2cRPQND0CH0BpIzdSsK5P+raj4IDsPt/4tupKUloMLSek6hT8Ky953bFADiSlZ+C4uEcnpj0Z03Z0U6NKwBkZG1AUAHE9IASCgXYivNvzJHXXTN2Ls6+6ItweHo1+zwBKvuSJCFoOc7WNwMoDBiYiIykrOh6DCNrfuZ+Hkjfu4k54HD2cFhrWqjQ71qwPQPw0rOS1bW+zg77uZ2Bd/G/nqKvW/aCLZAryc8XREXdT1dcO9jFz8kXgfMedvl9q+XbAP2oT4aQuJpGXll1in5iACLev4IKKeHzqEVi+12EjxsvnHrqbgyNW7uPUgR2fEb198MjafvImHOQXae5QW5Er7b4sp/81hOCsbBicDGJyIiMgeqNQSPt77F7747W+d3/57uzigZxN/ZOar8NvlezqjWxy9Iqo4DqLm35uqDDN0A72cEeDjAldHB7g7OyD275QSAWt4q9r46UySzghdNTdHDGtZC90a+uPP2w9x+Mpd/H7tPrLyHv13QN9UzsJQ1yG0unYd3bGrKSXW15labVLOthCFVS193Jy0m20bq25ZkRicDGBwIiIieyJ3v6qivxHfcyEJ3524oRO4iIgAwPnfYiC5xdZkOorA441qoLqnpsJkdl4B/DyckZSWjbM305Bb8CgyOCsE1PZ1xT/3s0scb1bHBz5ujjhyJUUn0BXn7qTAhM4heKlHQ6sGKAYnAxiciIioKijcoyr273tQS0A1Nyf4umt+4+vj5oSjV+8h5oLuRrSF600a1fTE2qPX8KBIFTgiIktwd1LgwxHNrba5NYOTAQxOREREGsZGs45dTcH649fws4G1I0RE5rBqVCurhCcGJwMYnIiIiEyjr1pZ4eL8tOx8WWXb3ZxEiIKIjNwCg+2quTkgsp4fJAg4npBq9LpEVDkovV3w26zuFT5tj8HJAAYnIiIi05m61upEQqrBjV2ruzsDAnAnPQepmfoXjBe9buF+RLF/3yuxZ1FcQgr+91sC13QR2bnvJrRHZKhfhd6TwckABiciIqLKp3gFr8IgVlgwQ9+Gxu7OCkzoFILJjzfAZweuGNyDi4gs7+OnWmBwi1oVek+7Ck6fffYZ3n//fSQlJaFp06ZYtmwZOnfuXGr7X3/9FTNmzMCFCxcQGBiI1157DRMnTpR9PwYnIiKiqsnYfjf6RriKbsgKABviruNwsTLwhZu8RoZWx72MHFxMeoiEe5n4+16mTolpJ4UIhQidDZAdFQIkCSjgnl1ENj/i5FBBfdJr48aNmDZtGj777DN07NgRn3/+Ofr27Yv4+HjUrVu3RPuEhAT069cPEyZMwPr163HkyBFMnjwZNWrUwPDhw63wCoiIiMheKETB4Icyfc93blijxNdyNxzV1w6A3mNF99RpF+ILURS00xj/eZCNbUbWkbk7KdCtUQ3E/l36urDC9WPB1T3g7eqIk4n3sf/PO8hX6YY2RxFoGuiFP5MzkFPA6Y9UMZTej/492Cqrjji1a9cOrVq1wsqVK7XHmjRpgiFDhmDx4sUl2s+aNQvbt2/HxYsXtccmTpyIM2fOIDY2Vu89cnNzkZubq/06PT0dderU4YgTERER2Q1Do2FFNy8t3g4CcC8jt9SAV7Rsvb5rFS9pfystG1tP3cT9rEel6gO8nLFgQBi8XZ2w/vi1EiNybo4imgZ6IdDHFYIgQOnjAh9XJ6Tn5OPKnQwcvaq7+WvxjZzLurGzgwiIgoA8lfGzHQTA39MZdzPzSgRJqhisqmdAXl4e3Nzc8MMPP2Do0KHa46+88gpOnz6NX3/9tcQ5Xbp0QcuWLfHxxx9rj/34448YMWIEsrKy4OjoWOKcRYsW4Y033ihxnMGJiIiIyHSmTHk0NCJXWvvCdWnFv05Oy8a9jFykZuUh6UEOano7IzNHBUEQUNfXFQ39PXHieir0FSTZcyEJm0/e1AloLo4iujWsgdGRwSXC4uErd3Dun3S4Oonw93SBl4sjktKyS/S9MAjeSc/Fvot3kFZk7zNDgc9BBHzdnPAguwB5qqo9qlfNzRGLhz1mF/s4WW2q3r1796BSqVCzZk2d4zVr1kRycrLec5KTk/W2LygowL1796BUlvyGz5kzBzNmzNB+XTjiRERERESmK8uUR1OvZ+zr0nRt7F/iWGSoHyJD/fD6gKZGA51CFNCxQXV0bFBddv8LGQqApY3+FS9q4uPmhNRMTTi89W/1yKIjdJIEeLs6av9ezc0J1T2d4e/hjOMJKVh9JEFntM/dWYGuDarj0OWUUrcCcHMUofRxwc0HOTqVKR1EoEVtb9Sq5ib7e3DrQTbO3UrXuY6ro4j/tK6NOr5uOq+rVjVXdAitrg2t9sCqa5wATVIvSpKkEseMtdd3vJCzszOcnZ3L2UsiIiIismemBjpzXN/Y/czZp44NquOVng31hkN90y6re+puAWDqSGFpzHUdW2S14FS9enUoFIoSo0t37twpMapUKCAgQG97BwcH+PlVbAUOIiIiIiJbUloQkzOSZq4QZ+mAak2itW7s5OSE1q1bY+/evTrH9+7diw4dOug9JzIyskT7PXv2oE2bNnrXNxEREREREZmD1YITAMyYMQNffvklVq9ejYsXL2L69OlITEzU7ss0Z84cjBkzRtt+4sSJuH79OmbMmIGLFy9i9erV+OqrrzBz5kxrvQQiIiIiIqoCrLrG6cknn0RKSgrefPNNJCUlITw8HLt27UJQUBAAICkpCYmJidr2ISEh2LVrF6ZPn44VK1YgMDAQn3zyCfdwIiIiIiIii7LqPk7WYErJQSIiIiIiqrxMyQZWnapHRERERERkDxiciIiIiIiIjGBwIiIiIiIiMoLBiYiIiIiIyAgGJyIiIiIiIiMYnIiIiIiIiIxgcCIiIiIiIjKCwYmIiIiIiMgIBiciIiIiIiIjHKzdgYomSRIAzS7BRERERERUdRVmgsKMYEiVC04PHz4EANSpU8fKPSEiIiIiIlvw8OFDeHt7G2wjSHLiVSWiVqtx69YteHp6QhAEq/YlPT0dderUwY0bN+Dl5WXVvhCVhu9Tsgd8n5I94PuU7EFVe59KkoSHDx8iMDAQomh4FVOVG3ESRRG1a9e2djd0eHl5VYk3Jtk3vk/JHvB9SvaA71OyB1XpfWpspKkQi0MQEREREREZweBERERERERkBIOTFTk7O2PhwoVwdna2dleISsX3KdkDvk/JHvB9SvaA79PSVbniEERERERERKbiiBMREREREZERDE5ERERERERGMDgREREREREZweBERERERERkBIOTlXz22WcICQmBi4sLWrdujcOHD1u7S1SFLF68GG3btoWnpyf8/f0xZMgQXLp0SaeNJElYtGgRAgMD4erqim7duuHChQs6bXJzc/HSSy+hevXqcHd3x6BBg/DPP/9U5EuhKmTx4sUQBAHTpk3THuP7lGzBzZs3MWrUKPj5+cHNzQ0tWrTAH3/8oX3+/9u7/5gqyz6O458DBw5wYgxkchAnwrIISadQy2Q5tRlKbZX9YqhQfzhK6JircKXTSou/qrUVLWb8A43GokbNWWDFpq1wsKPHtKxF6lJGzvIXKen5Pn+0595zHqxDz2MchPdru7fDdX3P4bq3z8747r7vC3KKaLt48aI2bNignJwcJSYmKjc3V88//7xCoZBTQ05HwDDqWlpaLC4uzhoaGuzAgQPm9/vN6/Xa4cOHo700TBB33HGHNTY22v79+y0QCFhpaalNmzbNzp4969TU1dVZcnKyvffeexYMBu3BBx+0zMxMO336tFNTVVVlWVlZ1tHRYb29vbZw4UKbPXu2Xbx4MRqnhXGsu7vbpk+fbrNmzTK/3++Mk1NE28mTJy07O9sqKyvtq6++sr6+Puvs7LTvv//eqSGniLYtW7bYpEmT7KOPPrK+vj5rbW21a665xl599VWnhpxGRuMUBTfffLNVVVWFjeXl5dn69eujtCJMdAMDAybJurq6zMwsFAqZz+ezuro6p+b8+fOWkpJib775ppmZ/frrrxYXF2ctLS1OzU8//WQxMTG2Y8eO0T0BjGtnzpyxGTNmWEdHhy1YsMBpnMgpxoLa2lorLi7+03lyirGgtLTUHnnkkbCxe++911asWGFm5HSkuFVvlA0NDamnp0dLliwJG1+yZIm++OKLKK0KE92pU6ckSWlpaZKkvr4+9ff3h+XU4/FowYIFTk57enr0+++/h9VMmTJFBQUFZBlX1Jo1a1RaWqrbb789bJycYixob29XUVGR7r//fk2ePFlz5sxRQ0ODM09OMRYUFxdr586dOnTokCRp79692rVrl5YtWyaJnI6UO9oLmGhOnDihS5cuKSMjI2w8IyND/f39UVoVJjIz07p161RcXKyCggJJcrJ4uZwePnzYqYmPj1dqauqwGrKMK6WlpUW9vb3as2fPsDlyirHghx9+UH19vdatW6dnnnlG3d3devzxx+XxeLRq1SpyijGhtrZWp06dUl5enmJjY3Xp0iVt3bpVZWVlkvg+HSkapyhxuVxhP5vZsDFgNFRXV2vfvn3atWvXsLn/JadkGVfK0aNH5ff79cknnyghIeFP68gpoikUCqmoqEgvvviiJGnOnDn6+uuvVV9fr1WrVjl15BTR9O6776qpqUnvvPOOZs6cqUAgoLVr12rKlCmqqKhw6sjpX+NWvVGWnp6u2NjYYZ35wMDAsC4f+KfV1NSovb1dn332maZOneqM+3w+SfrLnPp8Pg0NDemXX3750xrg/9HT06OBgQEVFhbK7XbL7Xarq6tLr732mtxut5MzcopoyszMVH5+ftjYDTfcoCNHjkji+xRjw1NPPaX169froYce0o033qiVK1fqiSee0EsvvSSJnI4UjdMoi4+PV2FhoTo6OsLGOzo6dOutt0ZpVZhozEzV1dVqa2vTp59+qpycnLD5nJwc+Xy+sJwODQ2pq6vLyWlhYaHi4uLCao4fP679+/eTZVwRixcvVjAYVCAQcI6ioiKVl5crEAgoNzeXnCLq5s+fP+zfORw6dEjZ2dmS+D7F2DA4OKiYmPA/+2NjY53tyMnpCEVpU4oJ7d/bkW/bts0OHDhga9euNa/Xaz/++GO0l4YJ4tFHH7WUlBT7/PPP7fjx484xODjo1NTV1VlKSoq1tbVZMBi0srKyy25LOnXqVOvs7LTe3l5btGjRhNqWFKPvP3fVMyOniL7u7m5zu922detW++6776y5udmSkpKsqanJqSGniLaKigrLyspytiNva2uz9PR0e/rpp50achoZjVOUvP7665adnW3x8fE2d+5cZxtoYDRIuuzR2Njo1IRCIdu0aZP5fD7zeDx22223WTAYDPuc3377zaqrqy0tLc0SExPtzjvvtCNHjozy2WAi+e/GiZxiLPjwww+toKDAPB6P5eXl2VtvvRU2T04RbadPnza/32/Tpk2zhIQEy83NtWeffdYuXLjg1JDTyFxmZtG84gUAAAAAYx3POAEAAABABDROAAAAABABjRMAAAAAREDjBAAAAAAR0DgBAAAAQAQ0TgAAAAAQAY0TAAAAAERA4wQAAAAAEdA4AQDwN7hcLn3wwQfRXgYAYJTROAEArhqVlZVyuVzDjpKSkmgvDQAwzrmjvQAAAP6OkpISNTY2ho15PJ4orQYAMFFwxQkAcFXxeDzy+XxhR2pqqqQ/bqOrr6/X0qVLlZiYqJycHLW2toa9PxgMatGiRUpMTNSkSZO0evVqnT17Nqzm7bff1syZM+XxeJSZmanq6uqw+RMnTuiee+5RUlKSZsyYofb29n/2pAEAUUfjBAAYVzZu3Kjly5dr7969WrFihcrKynTw4EFJ0uDgoEpKSpSamqo9e/aotbVVnZ2dYY1RfX291qxZo9WrVysYDKq9vV3XXntt2O947rnn9MADD2jfvn1atmyZysvLdfLkyVE9TwDA6HKZmUV7EQAAjERlZaWampqUkJAQNl5bW6uNGzfK5XKpqqpK9fX1ztwtt9yiuXPn6o033lBDQ4Nqa2t19OhReb1eSdL27dt111136dixY8rIyFBWVpYefvhhbdmy5bJrcLlc2rBhg1544QVJ0rlz55ScnKzt27fzrBUAjGM84wQAuKosXLgwrDGSpLS0NOf1vHnzwubmzZunQCAgSTp48KBmz57tNE2SNH/+fIVCIX377bdyuVw6duyYFi9e/JdrmDVrlvPa6/UqOTlZAwMD/+spAQCuAjROAICritfrHXbrXCQul0uSZGbO68vVJCYmjujz4uLihr03FAr9rTUBAK4uPOMEABhXvvzyy2E/5+XlSZLy8/MVCAR07tw5Z3737t2KiYnRddddp+TkZE2fPl07d+4c1TUDAMY+rjgBAK4qFy5cUH9/f9iY2+1Wenq6JKm1tVVFRUUqLi5Wc3Ozuru7tW3bNklSeXm5Nm3apIqKCm3evFk///yzampqtHLlSmVkZEiSNm/erKqqKk2ePFlLly7VmTNntHv3btXU1IzuiQIAxhQaJwDAVWXHjh3KzMwMG7v++uv1zTffSPpjx7uWlhY99thj8vl8am5uVn5+viQpKSlJH3/8sfx+v2666SYlJSVp+fLlevnll53Pqqio0Pnz5/XKK6/oySefVHp6uu67777RO0EAwJjErnoAgHHD5XLp/fff19133x3tpQAAxhmecQIAAACACGicAAAAACACnnECAIwb3H0OAPincMUJAAAAACKgcQIAAACACGicAAAAACACGicAAAAAiIDGCQAAAAAioHECAAAAgAhonAAAAAAgAhonAAAAAIjgX2sY01I/Opn9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/210], Loss: 0.2993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.4977, Test Accuracy: 89.27%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:02.377172Z",
     "iopub.status.busy": "2025-05-09T02:06:02.377172Z",
     "iopub.status.idle": "2025-05-09T02:06:03.471812Z",
     "shell.execute_reply": "2025-05-09T02:06:03.471812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/210 for test dataset.\n",
      "  Processed batch 20/210 for test dataset.\n",
      "  Processed batch 30/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 40/210 for test dataset.\n",
      "  Processed batch 50/210 for test dataset.\n",
      "  Processed batch 60/210 for test dataset.\n",
      "  Processed batch 70/210 for test dataset.\n",
      "  Processed batch 80/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 90/210 for test dataset.\n",
      "  Processed batch 100/210 for test dataset.\n",
      "  Processed batch 110/210 for test dataset.\n",
      "  Processed batch 120/210 for test dataset.\n",
      "  Processed batch 130/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 140/210 for test dataset.\n",
      "  Processed batch 150/210 for test dataset.\n",
      "  Processed batch 160/210 for test dataset.\n",
      "  Processed batch 170/210 for test dataset.\n",
      "  Processed batch 180/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 190/210 for test dataset.\n",
      "  Processed batch 200/210 for test dataset.\n",
      "  Processed batch 210/210 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:03.473820Z",
     "iopub.status.busy": "2025-05-09T02:06:03.473820Z",
     "iopub.status.idle": "2025-05-09T02:06:03.477820Z",
     "shell.execute_reply": "2025-05-09T02:06:03.477820Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:03.479942Z",
     "iopub.status.busy": "2025-05-09T02:06:03.479942Z",
     "iopub.status.idle": "2025-05-09T02:06:05.327600Z",
     "shell.execute_reply": "2025-05-09T02:06:05.327600Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:05.330614Z",
     "iopub.status.busy": "2025-05-09T02:06:05.330614Z",
     "iopub.status.idle": "2025-05-09T02:06:05.335630Z",
     "shell.execute_reply": "2025-05-09T02:06:05.335630Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:05.338643Z",
     "iopub.status.busy": "2025-05-09T02:06:05.337643Z",
     "iopub.status.idle": "2025-05-09T02:06:06.668591Z",
     "shell.execute_reply": "2025-05-09T02:06:06.668591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 320 samples with 64 features each\n",
      "LOG: Labels shape: (320,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 80 samples with 64 features each\n",
      "LOG: Labels shape: (80,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 53729 samples with 64 features each\n",
      "LOG: Labels shape: (53729,)\n",
      "\n",
      "LOG: Training features shape: (320, 64), Training labels shape: (320,)\n",
      "LOG: Validation features shape: (80, 64), Validation labels shape: (80,)\n",
      "LOG: Test features shape: (53729, 64), Test labels shape: (53729,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 87.50%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      0.80      0.89         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.38      0.60      0.46         5\n",
      "           8       0.83      1.00      0.91         5\n",
      "           9       0.75      0.60      0.67         5\n",
      "          10       0.80      0.80      0.80         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.33      0.20      0.25         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.88        80\n",
      "   macro avg       0.88      0.88      0.87        80\n",
      "weighted avg       0.88      0.88      0.87        80\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 82.46%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1984\n",
      "           1       1.00      0.98      0.99      3701\n",
      "           2       0.96      0.89      0.92      1951\n",
      "           3       0.99      0.98      0.99      1369\n",
      "           4       0.93      0.98      0.95      2653\n",
      "           5       1.00      0.98      0.99      3934\n",
      "           6       0.96      0.94      0.95      3554\n",
      "           7       0.73      0.63      0.68     11246\n",
      "           8       0.98      0.92      0.95      6178\n",
      "           9       0.82      0.76      0.79      3253\n",
      "          10       0.55      0.88      0.67      1043\n",
      "          11       0.86      0.98      0.92      1902\n",
      "          12       0.78      0.99      0.87       891\n",
      "          13       0.80      0.94      0.86      1045\n",
      "          14       0.55      0.60      0.58      7243\n",
      "          15       0.71      0.88      0.78      1782\n",
      "\n",
      "    accuracy                           0.82     53729\n",
      "   macro avg       0.85      0.90      0.87     53729\n",
      "weighted avg       0.83      0.82      0.83     53729\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:06.671597Z",
     "iopub.status.busy": "2025-05-09T02:06:06.671597Z",
     "iopub.status.idle": "2025-05-09T02:06:06.675946Z",
     "shell.execute_reply": "2025-05-09T02:06:06.675946Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:06.678955Z",
     "iopub.status.busy": "2025-05-09T02:06:06.677955Z",
     "iopub.status.idle": "2025-05-09T02:06:06.734517Z",
     "shell.execute_reply": "2025-05-09T02:06:06.734192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 320 samples with 64 features each\n",
      "LOG: Labels shape: (320,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 80 samples with 64 features each\n",
      "LOG: Labels shape: (80,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 53729 samples with 64 features each\n",
      "LOG: Labels shape: (53729,)\n",
      "Train reps shape: (320, 64)\n",
      "Train labels shape: (320,)\n",
      "Val reps shape: (80, 64)\n",
      "Val labels shape: (80,)\n",
      "Test reps shape: (53729, 64)\n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:06.736525Z",
     "iopub.status.busy": "2025-05-09T02:06:06.736525Z",
     "iopub.status.idle": "2025-05-09T02:06:06.742627Z",
     "shell.execute_reply": "2025-05-09T02:06:06.742627Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:06.745634Z",
     "iopub.status.busy": "2025-05-09T02:06:06.744631Z",
     "iopub.status.idle": "2025-05-09T02:06:09.458656Z",
     "shell.execute_reply": "2025-05-09T02:06:09.458656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.8192  |  Val Loss: 2.6267\n",
      "Validation loss improved from inf to 2.6267.\n",
      "[Epoch 2/1000] Train Loss: 2.5570  |  Val Loss: 2.4595\n",
      "Validation loss improved from 2.6267 to 2.4595.\n",
      "[Epoch 3/1000] Train Loss: 2.4049  |  Val Loss: 2.3308\n",
      "Validation loss improved from 2.4595 to 2.3308.\n",
      "[Epoch 4/1000] Train Loss: 2.2762  |  Val Loss: 2.2046\n",
      "Validation loss improved from 2.3308 to 2.2046.\n",
      "[Epoch 5/1000] Train Loss: 2.1389  |  Val Loss: 2.0607\n",
      "Validation loss improved from 2.2046 to 2.0607.\n",
      "[Epoch 6/1000] Train Loss: 1.9950  |  Val Loss: 1.9149\n",
      "Validation loss improved from 2.0607 to 1.9149.\n",
      "[Epoch 7/1000] Train Loss: 1.8434  |  Val Loss: 1.7654\n",
      "Validation loss improved from 1.9149 to 1.7654.\n",
      "[Epoch 8/1000] Train Loss: 1.6997  |  Val Loss: 1.6271\n",
      "Validation loss improved from 1.7654 to 1.6271.\n",
      "[Epoch 9/1000] Train Loss: 1.5610  |  Val Loss: 1.4862\n",
      "Validation loss improved from 1.6271 to 1.4862.\n",
      "[Epoch 10/1000] Train Loss: 1.4145  |  Val Loss: 1.3671\n",
      "Validation loss improved from 1.4862 to 1.3671.\n",
      "[Epoch 11/1000] Train Loss: 1.2962  |  Val Loss: 1.2445\n",
      "Validation loss improved from 1.3671 to 1.2445.\n",
      "[Epoch 12/1000] Train Loss: 1.1761  |  Val Loss: 1.1448\n",
      "Validation loss improved from 1.2445 to 1.1448.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/1000] Train Loss: 1.0743  |  Val Loss: 1.0516\n",
      "Validation loss improved from 1.1448 to 1.0516.\n",
      "[Epoch 14/1000] Train Loss: 0.9849  |  Val Loss: 0.9823\n",
      "Validation loss improved from 1.0516 to 0.9823.\n",
      "[Epoch 15/1000] Train Loss: 0.9114  |  Val Loss: 0.9163\n",
      "Validation loss improved from 0.9823 to 0.9163.\n",
      "[Epoch 16/1000] Train Loss: 0.8435  |  Val Loss: 0.8655\n",
      "Validation loss improved from 0.9163 to 0.8655.\n",
      "[Epoch 17/1000] Train Loss: 0.7825  |  Val Loss: 0.8195\n",
      "Validation loss improved from 0.8655 to 0.8195.\n",
      "[Epoch 18/1000] Train Loss: 0.7299  |  Val Loss: 0.7721\n",
      "Validation loss improved from 0.8195 to 0.7721.\n",
      "[Epoch 19/1000] Train Loss: 0.6936  |  Val Loss: 0.7359\n",
      "Validation loss improved from 0.7721 to 0.7359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/1000] Train Loss: 0.6524  |  Val Loss: 0.7106\n",
      "Validation loss improved from 0.7359 to 0.7106.\n",
      "[Epoch 21/1000] Train Loss: 0.6189  |  Val Loss: 0.6724\n",
      "Validation loss improved from 0.7106 to 0.6724.\n",
      "[Epoch 22/1000] Train Loss: 0.5858  |  Val Loss: 0.6540\n",
      "Validation loss improved from 0.6724 to 0.6540.\n",
      "[Epoch 23/1000] Train Loss: 0.5548  |  Val Loss: 0.6212\n",
      "Validation loss improved from 0.6540 to 0.6212.\n",
      "[Epoch 24/1000] Train Loss: 0.5284  |  Val Loss: 0.6050\n",
      "Validation loss improved from 0.6212 to 0.6050.\n",
      "[Epoch 25/1000] Train Loss: 0.5039  |  Val Loss: 0.5693\n",
      "Validation loss improved from 0.6050 to 0.5693.\n",
      "[Epoch 26/1000] Train Loss: 0.4789  |  Val Loss: 0.5639\n",
      "Validation loss improved from 0.5693 to 0.5639.\n",
      "[Epoch 27/1000] Train Loss: 0.4614  |  Val Loss: 0.5447\n",
      "Validation loss improved from 0.5639 to 0.5447.\n",
      "[Epoch 28/1000] Train Loss: 0.4501  |  Val Loss: 0.5116\n",
      "Validation loss improved from 0.5447 to 0.5116.\n",
      "[Epoch 29/1000] Train Loss: 0.4198  |  Val Loss: 0.5146\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 30/1000] Train Loss: 0.4058  |  Val Loss: 0.5105\n",
      "Validation loss improved from 0.5116 to 0.5105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/1000] Train Loss: 0.3953  |  Val Loss: 0.4705\n",
      "Validation loss improved from 0.5105 to 0.4705.\n",
      "[Epoch 32/1000] Train Loss: 0.3758  |  Val Loss: 0.4635\n",
      "Validation loss improved from 0.4705 to 0.4635.\n",
      "[Epoch 33/1000] Train Loss: 0.3599  |  Val Loss: 0.4630\n",
      "Validation loss improved from 0.4635 to 0.4630.\n",
      "[Epoch 34/1000] Train Loss: 0.3449  |  Val Loss: 0.4528\n",
      "Validation loss improved from 0.4630 to 0.4528.\n",
      "[Epoch 35/1000] Train Loss: 0.3406  |  Val Loss: 0.4288\n",
      "Validation loss improved from 0.4528 to 0.4288.\n",
      "[Epoch 36/1000] Train Loss: 0.3228  |  Val Loss: 0.4272\n",
      "Validation loss improved from 0.4288 to 0.4272.\n",
      "[Epoch 37/1000] Train Loss: 0.3080  |  Val Loss: 0.4148\n",
      "Validation loss improved from 0.4272 to 0.4148.\n",
      "[Epoch 38/1000] Train Loss: 0.3035  |  Val Loss: 0.4098\n",
      "Validation loss improved from 0.4148 to 0.4098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/1000] Train Loss: 0.2879  |  Val Loss: 0.4136\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 40/1000] Train Loss: 0.2889  |  Val Loss: 0.3973\n",
      "Validation loss improved from 0.4098 to 0.3973.\n",
      "[Epoch 41/1000] Train Loss: 0.2824  |  Val Loss: 0.3925\n",
      "Validation loss improved from 0.3973 to 0.3925.\n",
      "[Epoch 42/1000] Train Loss: 0.2728  |  Val Loss: 0.3807\n",
      "Validation loss improved from 0.3925 to 0.3807.\n",
      "[Epoch 43/1000] Train Loss: 0.2580  |  Val Loss: 0.3865\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 44/1000] Train Loss: 0.2507  |  Val Loss: 0.3849\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 45/1000] Train Loss: 0.2444  |  Val Loss: 0.3683\n",
      "Validation loss improved from 0.3807 to 0.3683.\n",
      "[Epoch 46/1000] Train Loss: 0.2437  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 47/1000] Train Loss: 0.2481  |  Val Loss: 0.3591\n",
      "Validation loss improved from 0.3683 to 0.3591.\n",
      "[Epoch 48/1000] Train Loss: 0.2371  |  Val Loss: 0.3647\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 49/1000] Train Loss: 0.2207  |  Val Loss: 0.3633\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 50/1000] Train Loss: 0.2261  |  Val Loss: 0.3629\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51/1000] Train Loss: 0.2098  |  Val Loss: 0.3564\n",
      "Validation loss improved from 0.3591 to 0.3564.\n",
      "[Epoch 52/1000] Train Loss: 0.2127  |  Val Loss: 0.3487\n",
      "Validation loss improved from 0.3564 to 0.3487.\n",
      "[Epoch 53/1000] Train Loss: 0.2106  |  Val Loss: 0.3536\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 54/1000] Train Loss: 0.2077  |  Val Loss: 0.3530\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 55/1000] Train Loss: 0.2084  |  Val Loss: 0.3532\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 56/1000] Train Loss: 0.1898  |  Val Loss: 0.3502\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 57/1000] Train Loss: 0.2015  |  Val Loss: 0.3316\n",
      "Validation loss improved from 0.3487 to 0.3316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] Train Loss: 0.1960  |  Val Loss: 0.3228\n",
      "Validation loss improved from 0.3316 to 0.3228.\n",
      "[Epoch 59/1000] Train Loss: 0.1926  |  Val Loss: 0.3760\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 60/1000] Train Loss: 0.1903  |  Val Loss: 0.3358\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 61/1000] Train Loss: 0.1850  |  Val Loss: 0.3250\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 62/1000] Train Loss: 0.1690  |  Val Loss: 0.3402\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 63/1000] Train Loss: 0.1708  |  Val Loss: 0.3226\n",
      "Validation loss improved from 0.3228 to 0.3226.\n",
      "[Epoch 64/1000] Train Loss: 0.1684  |  Val Loss: 0.3280\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 65/1000] Train Loss: 0.1756  |  Val Loss: 0.3212\n",
      "Validation loss improved from 0.3226 to 0.3212.\n",
      "[Epoch 66/1000] Train Loss: 0.1731  |  Val Loss: 0.3406\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 67/1000] Train Loss: 0.1606  |  Val Loss: 0.3325\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] Train Loss: 0.1807  |  Val Loss: 0.3429\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 69/1000] Train Loss: 0.1595  |  Val Loss: 0.3284\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 70/1000] Train Loss: 0.1484  |  Val Loss: 0.3216\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 71/1000] Train Loss: 0.1549  |  Val Loss: 0.3139\n",
      "Validation loss improved from 0.3212 to 0.3139.\n",
      "[Epoch 72/1000] Train Loss: 0.1464  |  Val Loss: 0.3282\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 73/1000] Train Loss: 0.1465  |  Val Loss: 0.3214\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 74/1000] Train Loss: 0.1488  |  Val Loss: 0.3138\n",
      "Validation loss improved from 0.3139 to 0.3138.\n",
      "[Epoch 75/1000] Train Loss: 0.1488  |  Val Loss: 0.3195\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 76/1000] Train Loss: 0.1372  |  Val Loss: 0.3117\n",
      "Validation loss improved from 0.3138 to 0.3117.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 0.1397  |  Val Loss: 0.3079\n",
      "Validation loss improved from 0.3117 to 0.3079.\n",
      "[Epoch 78/1000] Train Loss: 0.1345  |  Val Loss: 0.3183\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 79/1000] Train Loss: 0.1341  |  Val Loss: 0.3265\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 80/1000] Train Loss: 0.1304  |  Val Loss: 0.3061\n",
      "Validation loss improved from 0.3079 to 0.3061.\n",
      "[Epoch 81/1000] Train Loss: 0.1311  |  Val Loss: 0.3119\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 82/1000] Train Loss: 0.1349  |  Val Loss: 0.3217\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 83/1000] Train Loss: 0.1268  |  Val Loss: 0.3176\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 84/1000] Train Loss: 0.1254  |  Val Loss: 0.3099\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 85/1000] Train Loss: 0.1273  |  Val Loss: 0.2967\n",
      "Validation loss improved from 0.3061 to 0.2967.\n",
      "[Epoch 86/1000] Train Loss: 0.1185  |  Val Loss: 0.3216\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 87/1000] Train Loss: 0.1229  |  Val Loss: 0.3079\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 88/1000] Train Loss: 0.1298  |  Val Loss: 0.3209\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 89/1000] Train Loss: 0.1303  |  Val Loss: 0.3260\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 90/1000] Train Loss: 0.1242  |  Val Loss: 0.3380\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 91/1000] Train Loss: 0.1209  |  Val Loss: 0.3227\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 92/1000] Train Loss: 0.1287  |  Val Loss: 0.3208\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 93/1000] Train Loss: 0.1230  |  Val Loss: 0.3185\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 94/1000] Train Loss: 0.1135  |  Val Loss: 0.3044\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 95/1000] Train Loss: 0.1151  |  Val Loss: 0.3214\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/1000] Train Loss: 0.1284  |  Val Loss: 0.3061\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 97/1000] Train Loss: 0.1094  |  Val Loss: 0.3196\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 98/1000] Train Loss: 0.1188  |  Val Loss: 0.3320\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 99/1000] Train Loss: 0.1226  |  Val Loss: 0.3499\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 100/1000] Train Loss: 0.1206  |  Val Loss: 0.3296\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 101/1000] Train Loss: 0.1218  |  Val Loss: 0.3751\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 102/1000] Train Loss: 0.1217  |  Val Loss: 0.3489\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 103/1000] Train Loss: 0.1313  |  Val Loss: 0.3199\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 104/1000] Train Loss: 0.1045  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 105/1000] Train Loss: 0.0997  |  Val Loss: 0.3176\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 106/1000] Train Loss: 0.1163  |  Val Loss: 0.2970\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 107/1000] Train Loss: 0.1185  |  Val Loss: 0.3344\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/1000] Train Loss: 0.1072  |  Val Loss: 0.2958\n",
      "Validation loss improved from 0.2967 to 0.2958.\n",
      "[Epoch 109/1000] Train Loss: 0.1108  |  Val Loss: 0.3179\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 110/1000] Train Loss: 0.1041  |  Val Loss: 0.3174\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 111/1000] Train Loss: 0.0971  |  Val Loss: 0.3089\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 112/1000] Train Loss: 0.0951  |  Val Loss: 0.3217\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 113/1000] Train Loss: 0.1009  |  Val Loss: 0.3187\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 114/1000] Train Loss: 0.0951  |  Val Loss: 0.2932\n",
      "Validation loss improved from 0.2958 to 0.2932.\n",
      "[Epoch 115/1000] Train Loss: 0.0964  |  Val Loss: 0.3163\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 116/1000] Train Loss: 0.0878  |  Val Loss: 0.3064\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 117/1000] Train Loss: 0.0949  |  Val Loss: 0.3140\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 118/1000] Train Loss: 0.0855  |  Val Loss: 0.3044\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 119/1000] Train Loss: 0.0875  |  Val Loss: 0.3031\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 120/1000] Train Loss: 0.0922  |  Val Loss: 0.3182\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 121/1000] Train Loss: 0.0879  |  Val Loss: 0.3012\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 122/1000] Train Loss: 0.0930  |  Val Loss: 0.3225\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 123/1000] Train Loss: 0.0908  |  Val Loss: 0.3165\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 124/1000] Train Loss: 0.0947  |  Val Loss: 0.2999\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 125/1000] Train Loss: 0.0881  |  Val Loss: 0.3658\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 126/1000] Train Loss: 0.0944  |  Val Loss: 0.3077\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/1000] Train Loss: 0.0993  |  Val Loss: 0.3027\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 128/1000] Train Loss: 0.0991  |  Val Loss: 0.3395\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 129/1000] Train Loss: 0.0868  |  Val Loss: 0.3228\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 130/1000] Train Loss: 0.0862  |  Val Loss: 0.3270\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 131/1000] Train Loss: 0.0911  |  Val Loss: 0.3055\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 132/1000] Train Loss: 0.0977  |  Val Loss: 0.3135\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 133/1000] Train Loss: 0.0793  |  Val Loss: 0.3382\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 134/1000] Train Loss: 0.0850  |  Val Loss: 0.2923\n",
      "Validation loss improved from 0.2932 to 0.2923.\n",
      "[Epoch 135/1000] Train Loss: 0.0813  |  Val Loss: 0.3078\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 136/1000] Train Loss: 0.0898  |  Val Loss: 0.3298\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 137/1000] Train Loss: 0.0872  |  Val Loss: 0.2931\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 138/1000] Train Loss: 0.0744  |  Val Loss: 0.3293\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 139/1000] Train Loss: 0.0851  |  Val Loss: 0.3256\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 140/1000] Train Loss: 0.0886  |  Val Loss: 0.3015\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 141/1000] Train Loss: 0.0881  |  Val Loss: 0.3353\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 142/1000] Train Loss: 0.0828  |  Val Loss: 0.3052\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 143/1000] Train Loss: 0.0781  |  Val Loss: 0.3105\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 144/1000] Train Loss: 0.0794  |  Val Loss: 0.3067\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 145/1000] Train Loss: 0.0836  |  Val Loss: 0.3494\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 146/1000] Train Loss: 0.0875  |  Val Loss: 0.3163\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 147/1000] Train Loss: 0.0934  |  Val Loss: 0.3175\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 148/1000] Train Loss: 0.1142  |  Val Loss: 0.3393\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 149/1000] Train Loss: 0.1002  |  Val Loss: 0.3253\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 150/1000] Train Loss: 0.0803  |  Val Loss: 0.3564\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 151/1000] Train Loss: 0.0848  |  Val Loss: 0.3636\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 152/1000] Train Loss: 0.0742  |  Val Loss: 0.3253\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 153/1000] Train Loss: 0.0946  |  Val Loss: 0.3306\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 154/1000] Train Loss: 0.0797  |  Val Loss: 0.3230\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 155/1000] Train Loss: 0.0804  |  Val Loss: 0.3125\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 156/1000] Train Loss: 0.0889  |  Val Loss: 0.3189\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 157/1000] Train Loss: 0.0672  |  Val Loss: 0.3404\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 158/1000] Train Loss: 0.0801  |  Val Loss: 0.3330\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 159/1000] Train Loss: 0.0716  |  Val Loss: 0.3379\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 160/1000] Train Loss: 0.0712  |  Val Loss: 0.3155\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 161/1000] Train Loss: 0.0735  |  Val Loss: 0.3492\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 162/1000] Train Loss: 0.0619  |  Val Loss: 0.3133\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 163/1000] Train Loss: 0.0645  |  Val Loss: 0.3231\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 164/1000] Train Loss: 0.0575  |  Val Loss: 0.3419\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 165/1000] Train Loss: 0.0680  |  Val Loss: 0.3287\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 166/1000] Train Loss: 0.0630  |  Val Loss: 0.3214\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 167/1000] Train Loss: 0.0634  |  Val Loss: 0.3332\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 168/1000] Train Loss: 0.0592  |  Val Loss: 0.3172\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 169/1000] Train Loss: 0.0628  |  Val Loss: 0.3321\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 170/1000] Train Loss: 0.0598  |  Val Loss: 0.3516\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 171/1000] Train Loss: 0.0581  |  Val Loss: 0.3221\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 172/1000] Train Loss: 0.0593  |  Val Loss: 0.3240\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 173/1000] Train Loss: 0.0587  |  Val Loss: 0.3340\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 174/1000] Train Loss: 0.0624  |  Val Loss: 0.3169\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 175/1000] Train Loss: 0.0593  |  Val Loss: 0.3318\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 176/1000] Train Loss: 0.0563  |  Val Loss: 0.3374\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 177/1000] Train Loss: 0.0540  |  Val Loss: 0.3422\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 178/1000] Train Loss: 0.0552  |  Val Loss: 0.3355\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 179/1000] Train Loss: 0.0552  |  Val Loss: 0.3462\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 180/1000] Train Loss: 0.0580  |  Val Loss: 0.3228\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 181/1000] Train Loss: 0.0533  |  Val Loss: 0.3493\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 182/1000] Train Loss: 0.0538  |  Val Loss: 0.3312\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 183/1000] Train Loss: 0.0519  |  Val Loss: 0.3194\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 184/1000] Train Loss: 0.0522  |  Val Loss: 0.3301\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 185/1000] Train Loss: 0.0624  |  Val Loss: 0.3593\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 186/1000] Train Loss: 0.0549  |  Val Loss: 0.3264\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 187/1000] Train Loss: 0.0595  |  Val Loss: 0.3626\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 188/1000] Train Loss: 0.0541  |  Val Loss: 0.3588\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 189/1000] Train Loss: 0.0558  |  Val Loss: 0.3232\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 190/1000] Train Loss: 0.0555  |  Val Loss: 0.3658\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 191/1000] Train Loss: 0.0554  |  Val Loss: 0.3550\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 192/1000] Train Loss: 0.0625  |  Val Loss: 0.3395\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 193/1000] Train Loss: 0.0516  |  Val Loss: 0.3591\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 194/1000] Train Loss: 0.0690  |  Val Loss: 0.3676\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 195/1000] Train Loss: 0.0518  |  Val Loss: 0.3415\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 196/1000] Train Loss: 0.0521  |  Val Loss: 0.3684\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 197/1000] Train Loss: 0.0625  |  Val Loss: 0.3720\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 198/1000] Train Loss: 0.0520  |  Val Loss: 0.3389\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 199/1000] Train Loss: 0.0484  |  Val Loss: 0.3619\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 200/1000] Train Loss: 0.0493  |  Val Loss: 0.3416\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 201/1000] Train Loss: 0.0465  |  Val Loss: 0.3515\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 202/1000] Train Loss: 0.0501  |  Val Loss: 0.3486\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 203/1000] Train Loss: 0.0508  |  Val Loss: 0.3530\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 204/1000] Train Loss: 0.0520  |  Val Loss: 0.3462\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 205/1000] Train Loss: 0.0577  |  Val Loss: 0.3637\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 206/1000] Train Loss: 0.0589  |  Val Loss: 0.3904\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 207/1000] Train Loss: 0.0451  |  Val Loss: 0.3540\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 208/1000] Train Loss: 0.0645  |  Val Loss: 0.3630\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 209/1000] Train Loss: 0.0587  |  Val Loss: 0.3890\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 210/1000] Train Loss: 0.0478  |  Val Loss: 0.3332\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 211/1000] Train Loss: 0.0477  |  Val Loss: 0.3612\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 212/1000] Train Loss: 0.0518  |  Val Loss: 0.3700\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 213/1000] Train Loss: 0.0469  |  Val Loss: 0.3580\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 214/1000] Train Loss: 0.0500  |  Val Loss: 0.3760\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 215/1000] Train Loss: 0.0515  |  Val Loss: 0.3912\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 216/1000] Train Loss: 0.0454  |  Val Loss: 0.3651\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 217/1000] Train Loss: 0.0431  |  Val Loss: 0.3988\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 218/1000] Train Loss: 0.0432  |  Val Loss: 0.3889\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 219/1000] Train Loss: 0.0421  |  Val Loss: 0.3705\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 220/1000] Train Loss: 0.0417  |  Val Loss: 0.3818\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 221/1000] Train Loss: 0.0443  |  Val Loss: 0.3840\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 222/1000] Train Loss: 0.0431  |  Val Loss: 0.3729\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 223/1000] Train Loss: 0.0472  |  Val Loss: 0.3717\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 224/1000] Train Loss: 0.0472  |  Val Loss: 0.3817\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 225/1000] Train Loss: 0.0524  |  Val Loss: 0.4097\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 226/1000] Train Loss: 0.0472  |  Val Loss: 0.3633\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 227/1000] Train Loss: 0.0459  |  Val Loss: 0.3708\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 228/1000] Train Loss: 0.0464  |  Val Loss: 0.4020\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 229/1000] Train Loss: 0.0540  |  Val Loss: 0.3558\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 230/1000] Train Loss: 0.0530  |  Val Loss: 0.3847\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 231/1000] Train Loss: 0.0498  |  Val Loss: 0.3554\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 232/1000] Train Loss: 0.0497  |  Val Loss: 0.4193\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 233/1000] Train Loss: 0.0431  |  Val Loss: 0.3649\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 234/1000] Train Loss: 0.0380  |  Val Loss: 0.3763\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 234 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:09.461662Z",
     "iopub.status.busy": "2025-05-09T02:06:09.461662Z",
     "iopub.status.idle": "2025-05-09T02:06:10.416126Z",
     "shell.execute_reply": "2025-05-09T02:06:10.416126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.9564 | Test Accuracy: 83.26%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:10.419132Z",
     "iopub.status.busy": "2025-05-09T02:06:10.419132Z",
     "iopub.status.idle": "2025-05-09T02:06:10.478165Z",
     "shell.execute_reply": "2025-05-09T02:06:10.478165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 320 samples with 64 features each\n",
      "LOG: Labels shape: (320,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 80 samples with 64 features each\n",
      "LOG: Labels shape: (80,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 53729 samples with 64 features each\n",
      "LOG: Labels shape: (53729,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (320, 64), \n",
      "Train labels shape: (320,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (80, 64), \n",
      "Val labels shape: (80,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (53729, 64), \n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:10.480171Z",
     "iopub.status.busy": "2025-05-09T02:06:10.480171Z",
     "iopub.status.idle": "2025-05-09T02:06:10.502269Z",
     "shell.execute_reply": "2025-05-09T02:06:10.502269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20, 14: 20, 15: 20}\n",
      "Training batch size: 320\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:10.505274Z",
     "iopub.status.busy": "2025-05-09T02:06:10.505274Z",
     "iopub.status.idle": "2025-05-09T02:06:10.509714Z",
     "shell.execute_reply": "2025-05-09T02:06:10.509714Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:10.511718Z",
     "iopub.status.busy": "2025-05-09T02:06:10.511718Z",
     "iopub.status.idle": "2025-05-09T02:06:10.515218Z",
     "shell.execute_reply": "2025-05-09T02:06:10.515218Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:10.517221Z",
     "iopub.status.busy": "2025-05-09T02:06:10.517221Z",
     "iopub.status.idle": "2025-05-09T02:06:21.627725Z",
     "shell.execute_reply": "2025-05-09T02:06:21.627725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.0422\n",
      "Epoch [1/2000], Avg Train Loss: 8.0422\n",
      "Epoch [1/2000], Avg Val Loss: 2.8084\n",
      "Validation loss improved from inf to 2.8084. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8923\n",
      "Epoch [2/2000], Avg Train Loss: 7.8923\n",
      "Epoch [2/2000], Avg Val Loss: 2.7990\n",
      "Validation loss improved from 2.8084 to 2.7990. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8985\n",
      "Epoch [3/2000], Avg Train Loss: 7.8985\n",
      "Epoch [3/2000], Avg Val Loss: 2.7901\n",
      "Validation loss improved from 2.7990 to 2.7901. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 7.8673\n",
      "Epoch [4/2000], Avg Train Loss: 7.8673\n",
      "Epoch [4/2000], Avg Val Loss: 2.7817\n",
      "Validation loss improved from 2.7901 to 2.7817. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6430\n",
      "Epoch [5/2000], Avg Train Loss: 7.6430\n",
      "Epoch [5/2000], Avg Val Loss: 2.7736\n",
      "Validation loss improved from 2.7817 to 2.7736. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7146\n",
      "Epoch [6/2000], Avg Train Loss: 7.7146\n",
      "Epoch [6/2000], Avg Val Loss: 2.7657\n",
      "Validation loss improved from 2.7736 to 2.7657. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5497\n",
      "Epoch [7/2000], Avg Train Loss: 7.5497\n",
      "Epoch [7/2000], Avg Val Loss: 2.7583\n",
      "Validation loss improved from 2.7657 to 2.7583. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6219\n",
      "Epoch [8/2000], Avg Train Loss: 7.6219\n",
      "Epoch [8/2000], Avg Val Loss: 2.7511\n",
      "Validation loss improved from 2.7583 to 2.7511. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5249\n",
      "Epoch [9/2000], Avg Train Loss: 7.5249\n",
      "Epoch [9/2000], Avg Val Loss: 2.7442\n",
      "Validation loss improved from 2.7511 to 2.7442. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4190\n",
      "Epoch [10/2000], Avg Train Loss: 7.4190\n",
      "Epoch [10/2000], Avg Val Loss: 2.7377\n",
      "Validation loss improved from 2.7442 to 2.7377. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4005\n",
      "Epoch [11/2000], Avg Train Loss: 7.4005\n",
      "Epoch [11/2000], Avg Val Loss: 2.7315\n",
      "Validation loss improved from 2.7377 to 2.7315. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3306\n",
      "Epoch [12/2000], Avg Train Loss: 7.3306\n",
      "Epoch [12/2000], Avg Val Loss: 2.7256\n",
      "Validation loss improved from 2.7315 to 2.7256. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3077\n",
      "Epoch [13/2000], Avg Train Loss: 7.3077\n",
      "Epoch [13/2000], Avg Val Loss: 2.7201\n",
      "Validation loss improved from 2.7256 to 2.7201. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1850\n",
      "Epoch [14/2000], Avg Train Loss: 7.1850\n",
      "Epoch [14/2000], Avg Val Loss: 2.7149\n",
      "Validation loss improved from 2.7201 to 2.7149. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3693\n",
      "Epoch [15/2000], Avg Train Loss: 7.3693\n",
      "Epoch [15/2000], Avg Val Loss: 2.7099\n",
      "Validation loss improved from 2.7149 to 2.7099. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9629\n",
      "Epoch [16/2000], Avg Train Loss: 6.9629\n",
      "Epoch [16/2000], Avg Val Loss: 2.7051\n",
      "Validation loss improved from 2.7099 to 2.7051. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0248\n",
      "Epoch [17/2000], Avg Train Loss: 7.0248\n",
      "Epoch [17/2000], Avg Val Loss: 2.7005\n",
      "Validation loss improved from 2.7051 to 2.7005. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.9322\n",
      "Epoch [18/2000], Avg Train Loss: 6.9322\n",
      "Epoch [18/2000], Avg Val Loss: 2.6963\n",
      "Validation loss improved from 2.7005 to 2.6963. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8245\n",
      "Epoch [19/2000], Avg Train Loss: 6.8245\n",
      "Epoch [19/2000], Avg Val Loss: 2.6923\n",
      "Validation loss improved from 2.6963 to 2.6923. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7586\n",
      "Epoch [20/2000], Avg Train Loss: 6.7586\n",
      "Epoch [20/2000], Avg Val Loss: 2.6885\n",
      "Validation loss improved from 2.6923 to 2.6885. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7162\n",
      "Epoch [21/2000], Avg Train Loss: 6.7162\n",
      "Epoch [21/2000], Avg Val Loss: 2.6850\n",
      "Validation loss improved from 2.6885 to 2.6850. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6912\n",
      "Epoch [22/2000], Avg Train Loss: 6.6912\n",
      "Epoch [22/2000], Avg Val Loss: 2.6818\n",
      "Validation loss improved from 2.6850 to 2.6818. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6217\n",
      "Epoch [23/2000], Avg Train Loss: 6.6217\n",
      "Epoch [23/2000], Avg Val Loss: 2.6788\n",
      "Validation loss improved from 2.6818 to 2.6788. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6644\n",
      "Epoch [24/2000], Avg Train Loss: 6.6644\n",
      "Epoch [24/2000], Avg Val Loss: 2.6759\n",
      "Validation loss improved from 2.6788 to 2.6759. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5684\n",
      "Epoch [25/2000], Avg Train Loss: 6.5684\n",
      "Epoch [25/2000], Avg Val Loss: 2.6732\n",
      "Validation loss improved from 2.6759 to 2.6732. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6919\n",
      "Epoch [26/2000], Avg Train Loss: 6.6919\n",
      "Epoch [26/2000], Avg Val Loss: 2.6708\n",
      "Validation loss improved from 2.6732 to 2.6708. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4524\n",
      "Epoch [27/2000], Avg Train Loss: 6.4524\n",
      "Epoch [27/2000], Avg Val Loss: 2.6684\n",
      "Validation loss improved from 2.6708 to 2.6684. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3736\n",
      "Epoch [28/2000], Avg Train Loss: 6.3736\n",
      "Epoch [28/2000], Avg Val Loss: 2.6661\n",
      "Validation loss improved from 2.6684 to 2.6661. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4335\n",
      "Epoch [29/2000], Avg Train Loss: 6.4335\n",
      "Epoch [29/2000], Avg Val Loss: 2.6641\n",
      "Validation loss improved from 2.6661 to 2.6641. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3977\n",
      "Epoch [30/2000], Avg Train Loss: 6.3977\n",
      "Epoch [30/2000], Avg Val Loss: 2.6621\n",
      "Validation loss improved from 2.6641 to 2.6621. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3438\n",
      "Epoch [31/2000], Avg Train Loss: 6.3438\n",
      "Epoch [31/2000], Avg Val Loss: 2.6603\n",
      "Validation loss improved from 2.6621 to 2.6603. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3388\n",
      "Epoch [32/2000], Avg Train Loss: 6.3388\n",
      "Epoch [32/2000], Avg Val Loss: 2.6586\n",
      "Validation loss improved from 2.6603 to 2.6586. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1235\n",
      "Epoch [33/2000], Avg Train Loss: 6.1235\n",
      "Epoch [33/2000], Avg Val Loss: 2.6571\n",
      "Validation loss improved from 2.6586 to 2.6571. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3254\n",
      "Epoch [34/2000], Avg Train Loss: 6.3254\n",
      "Epoch [34/2000], Avg Val Loss: 2.6557\n",
      "Validation loss improved from 2.6571 to 2.6557. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2128\n",
      "Epoch [35/2000], Avg Train Loss: 6.2128\n",
      "Epoch [35/2000], Avg Val Loss: 2.6544\n",
      "Validation loss improved from 2.6557 to 2.6544. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0145\n",
      "Epoch [36/2000], Avg Train Loss: 6.0145\n",
      "Epoch [36/2000], Avg Val Loss: 2.6532\n",
      "Validation loss improved from 2.6544 to 2.6532. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0945\n",
      "Epoch [37/2000], Avg Train Loss: 6.0945\n",
      "Epoch [37/2000], Avg Val Loss: 2.6522\n",
      "Validation loss improved from 2.6532 to 2.6522. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0763\n",
      "Epoch [38/2000], Avg Train Loss: 6.0763\n",
      "Epoch [38/2000], Avg Val Loss: 2.6513\n",
      "Validation loss improved from 2.6522 to 2.6513. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0098\n",
      "Epoch [39/2000], Avg Train Loss: 6.0098\n",
      "Epoch [39/2000], Avg Val Loss: 2.6504\n",
      "Validation loss improved from 2.6513 to 2.6504. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.9559\n",
      "Epoch [40/2000], Avg Train Loss: 5.9559\n",
      "Epoch [40/2000], Avg Val Loss: 2.6497\n",
      "Validation loss improved from 2.6504 to 2.6497. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0139\n",
      "Epoch [41/2000], Avg Train Loss: 6.0139\n",
      "Epoch [41/2000], Avg Val Loss: 2.6491\n",
      "Validation loss improved from 2.6497 to 2.6491. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9429\n",
      "Epoch [42/2000], Avg Train Loss: 5.9429\n",
      "Epoch [42/2000], Avg Val Loss: 2.6486\n",
      "Validation loss improved from 2.6491 to 2.6486. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8775\n",
      "Epoch [43/2000], Avg Train Loss: 5.8775\n",
      "Epoch [43/2000], Avg Val Loss: 2.6481\n",
      "Validation loss improved from 2.6486 to 2.6481. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7698\n",
      "Epoch [44/2000], Avg Train Loss: 5.7698\n",
      "Epoch [44/2000], Avg Val Loss: 2.6478\n",
      "Validation loss improved from 2.6481 to 2.6478. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7542\n",
      "Epoch [45/2000], Avg Train Loss: 5.7542\n",
      "Epoch [45/2000], Avg Val Loss: 2.6474\n",
      "Validation loss improved from 2.6478 to 2.6474. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7769\n",
      "Epoch [46/2000], Avg Train Loss: 5.7769\n",
      "Epoch [46/2000], Avg Val Loss: 2.6471\n",
      "Validation loss improved from 2.6474 to 2.6471. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7035\n",
      "Epoch [47/2000], Avg Train Loss: 5.7035\n",
      "Epoch [47/2000], Avg Val Loss: 2.6469\n",
      "Validation loss improved from 2.6471 to 2.6469. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7551\n",
      "Epoch [48/2000], Avg Train Loss: 5.7551\n",
      "Epoch [48/2000], Avg Val Loss: 2.6467\n",
      "Validation loss improved from 2.6469 to 2.6467. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7554\n",
      "Epoch [49/2000], Avg Train Loss: 5.7554\n",
      "Epoch [49/2000], Avg Val Loss: 2.6467\n",
      "Validation loss improved from 2.6467 to 2.6467. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6547\n",
      "Epoch [50/2000], Avg Train Loss: 5.6547\n",
      "Epoch [50/2000], Avg Val Loss: 2.6467\n",
      "Validation loss improved from 2.6467 to 2.6467. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6179\n",
      "Epoch [51/2000], Avg Train Loss: 5.6179\n",
      "Epoch [51/2000], Avg Val Loss: 2.6467\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6429\n",
      "Epoch [52/2000], Avg Train Loss: 5.6429\n",
      "Epoch [52/2000], Avg Val Loss: 2.6468\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5184\n",
      "Epoch [53/2000], Avg Train Loss: 5.5184\n",
      "Epoch [53/2000], Avg Val Loss: 2.6469\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5251\n",
      "Epoch [54/2000], Avg Train Loss: 5.5251\n",
      "Epoch [54/2000], Avg Val Loss: 2.6470\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5765\n",
      "Epoch [55/2000], Avg Train Loss: 5.5765\n",
      "Epoch [55/2000], Avg Val Loss: 2.6472\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5732\n",
      "Epoch [56/2000], Avg Train Loss: 5.5732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/2000], Avg Val Loss: 2.6474\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5038\n",
      "Epoch [57/2000], Avg Train Loss: 5.5038\n",
      "Epoch [57/2000], Avg Val Loss: 2.6477\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5443\n",
      "Epoch [58/2000], Avg Train Loss: 5.5443\n",
      "Epoch [58/2000], Avg Val Loss: 2.6480\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5351\n",
      "Epoch [59/2000], Avg Train Loss: 5.5351\n",
      "Epoch [59/2000], Avg Val Loss: 2.6483\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4127\n",
      "Epoch [60/2000], Avg Train Loss: 5.4127\n",
      "Epoch [60/2000], Avg Val Loss: 2.6487\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4340\n",
      "Epoch [61/2000], Avg Train Loss: 5.4340\n",
      "Epoch [61/2000], Avg Val Loss: 2.6491\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3997\n",
      "Epoch [62/2000], Avg Train Loss: 5.3997\n",
      "Epoch [62/2000], Avg Val Loss: 2.6495\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4368\n",
      "Epoch [63/2000], Avg Train Loss: 5.4368\n",
      "Epoch [63/2000], Avg Val Loss: 2.6499\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4013\n",
      "Epoch [64/2000], Avg Train Loss: 5.4013\n",
      "Epoch [64/2000], Avg Val Loss: 2.6504\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4445\n",
      "Epoch [65/2000], Avg Train Loss: 5.4445\n",
      "Epoch [65/2000], Avg Val Loss: 2.6508\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3783\n",
      "Epoch [66/2000], Avg Train Loss: 5.3783\n",
      "Epoch [66/2000], Avg Val Loss: 2.6514\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3480\n",
      "Epoch [67/2000], Avg Train Loss: 5.3480\n",
      "Epoch [67/2000], Avg Val Loss: 2.6519\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3333\n",
      "Epoch [68/2000], Avg Train Loss: 5.3333\n",
      "Epoch [68/2000], Avg Val Loss: 2.6524\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2553\n",
      "Epoch [69/2000], Avg Train Loss: 5.2553\n",
      "Epoch [69/2000], Avg Val Loss: 2.6529\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3028\n",
      "Epoch [70/2000], Avg Train Loss: 5.3028\n",
      "Epoch [70/2000], Avg Val Loss: 2.6534\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2647\n",
      "Epoch [71/2000], Avg Train Loss: 5.2647\n",
      "Epoch [71/2000], Avg Val Loss: 2.6539\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2227\n",
      "Epoch [72/2000], Avg Train Loss: 5.2227\n",
      "Epoch [72/2000], Avg Val Loss: 2.6544\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2815\n",
      "Epoch [73/2000], Avg Train Loss: 5.2815\n",
      "Epoch [73/2000], Avg Val Loss: 2.6549\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.2444\n",
      "Epoch [74/2000], Avg Train Loss: 5.2444\n",
      "Epoch [74/2000], Avg Val Loss: 2.6554\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2412\n",
      "Epoch [75/2000], Avg Train Loss: 5.2412\n",
      "Epoch [75/2000], Avg Val Loss: 2.6558\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1740\n",
      "Epoch [76/2000], Avg Train Loss: 5.1740\n",
      "Epoch [76/2000], Avg Val Loss: 2.6563\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1574\n",
      "Epoch [77/2000], Avg Train Loss: 5.1574\n",
      "Epoch [77/2000], Avg Val Loss: 2.6567\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1808\n",
      "Epoch [78/2000], Avg Train Loss: 5.1808\n",
      "Epoch [78/2000], Avg Val Loss: 2.6572\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2121\n",
      "Epoch [79/2000], Avg Train Loss: 5.2121\n",
      "Epoch [79/2000], Avg Val Loss: 2.6576\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0911\n",
      "Epoch [80/2000], Avg Train Loss: 5.0911\n",
      "Epoch [80/2000], Avg Val Loss: 2.6579\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0916\n",
      "Epoch [81/2000], Avg Train Loss: 5.0916\n",
      "Epoch [81/2000], Avg Val Loss: 2.6582\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1387\n",
      "Epoch [82/2000], Avg Train Loss: 5.1387\n",
      "Epoch [82/2000], Avg Val Loss: 2.6585\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1796\n",
      "Epoch [83/2000], Avg Train Loss: 5.1796\n",
      "Epoch [83/2000], Avg Val Loss: 2.6588\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0886\n",
      "Epoch [84/2000], Avg Train Loss: 5.0886\n",
      "Epoch [84/2000], Avg Val Loss: 2.6591\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0034\n",
      "Epoch [85/2000], Avg Train Loss: 5.0034\n",
      "Epoch [85/2000], Avg Val Loss: 2.6593\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0836\n",
      "Epoch [86/2000], Avg Train Loss: 5.0836\n",
      "Epoch [86/2000], Avg Val Loss: 2.6594\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0992\n",
      "Epoch [87/2000], Avg Train Loss: 5.0992\n",
      "Epoch [87/2000], Avg Val Loss: 2.6595\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0378\n",
      "Epoch [88/2000], Avg Train Loss: 5.0378\n",
      "Epoch [88/2000], Avg Val Loss: 2.6596\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0451\n",
      "Epoch [89/2000], Avg Train Loss: 5.0451\n",
      "Epoch [89/2000], Avg Val Loss: 2.6597\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0446\n",
      "Epoch [90/2000], Avg Train Loss: 5.0446\n",
      "Epoch [90/2000], Avg Val Loss: 2.6597\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0429\n",
      "Epoch [91/2000], Avg Train Loss: 5.0429\n",
      "Epoch [91/2000], Avg Val Loss: 2.6597\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0747\n",
      "Epoch [92/2000], Avg Train Loss: 5.0747\n",
      "Epoch [92/2000], Avg Val Loss: 2.6597\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9588\n",
      "Epoch [93/2000], Avg Train Loss: 4.9588\n",
      "Epoch [93/2000], Avg Val Loss: 2.6597\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0619\n",
      "Epoch [94/2000], Avg Train Loss: 5.0619\n",
      "Epoch [94/2000], Avg Val Loss: 2.6596\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9894\n",
      "Epoch [95/2000], Avg Train Loss: 4.9894\n",
      "Epoch [95/2000], Avg Val Loss: 2.6595\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0459\n",
      "Epoch [96/2000], Avg Train Loss: 5.0459\n",
      "Epoch [96/2000], Avg Val Loss: 2.6595\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9757\n",
      "Epoch [97/2000], Avg Train Loss: 4.9757\n",
      "Epoch [97/2000], Avg Val Loss: 2.6594\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9997\n",
      "Epoch [98/2000], Avg Train Loss: 4.9997\n",
      "Epoch [98/2000], Avg Val Loss: 2.6593\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0034\n",
      "Epoch [99/2000], Avg Train Loss: 5.0034\n",
      "Epoch [99/2000], Avg Val Loss: 2.6592\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9723\n",
      "Epoch [100/2000], Avg Train Loss: 4.9723\n",
      "Epoch [100/2000], Avg Val Loss: 2.6591\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9106\n",
      "Epoch [101/2000], Avg Train Loss: 4.9106\n",
      "Epoch [101/2000], Avg Val Loss: 2.6590\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9395\n",
      "Epoch [102/2000], Avg Train Loss: 4.9395\n",
      "Epoch [102/2000], Avg Val Loss: 2.6588\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9463\n",
      "Epoch [103/2000], Avg Train Loss: 4.9463\n",
      "Epoch [103/2000], Avg Val Loss: 2.6587\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9322\n",
      "Epoch [104/2000], Avg Train Loss: 4.9322\n",
      "Epoch [104/2000], Avg Val Loss: 2.6584\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9566\n",
      "Epoch [105/2000], Avg Train Loss: 4.9566\n",
      "Epoch [105/2000], Avg Val Loss: 2.6582\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9646\n",
      "Epoch [106/2000], Avg Train Loss: 4.9646\n",
      "Epoch [106/2000], Avg Val Loss: 2.6580\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9092\n",
      "Epoch [107/2000], Avg Train Loss: 4.9092\n",
      "Epoch [107/2000], Avg Val Loss: 2.6578\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9096\n",
      "Epoch [108/2000], Avg Train Loss: 4.9096\n",
      "Epoch [108/2000], Avg Val Loss: 2.6575\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8499\n",
      "Epoch [109/2000], Avg Train Loss: 4.8499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/2000], Avg Val Loss: 2.6572\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9014\n",
      "Epoch [110/2000], Avg Train Loss: 4.9014\n",
      "Epoch [110/2000], Avg Val Loss: 2.6568\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9101\n",
      "Epoch [111/2000], Avg Train Loss: 4.9101\n",
      "Epoch [111/2000], Avg Val Loss: 2.6565\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9280\n",
      "Epoch [112/2000], Avg Train Loss: 4.9280\n",
      "Epoch [112/2000], Avg Val Loss: 2.6562\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8549\n",
      "Epoch [113/2000], Avg Train Loss: 4.8549\n",
      "Epoch [113/2000], Avg Val Loss: 2.6558\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8542\n",
      "Epoch [114/2000], Avg Train Loss: 4.8542\n",
      "Epoch [114/2000], Avg Val Loss: 2.6553\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8925\n",
      "Epoch [115/2000], Avg Train Loss: 4.8925\n",
      "Epoch [115/2000], Avg Val Loss: 2.6549\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9049\n",
      "Epoch [116/2000], Avg Train Loss: 4.9049\n",
      "Epoch [116/2000], Avg Val Loss: 2.6544\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8615\n",
      "Epoch [117/2000], Avg Train Loss: 4.8615\n",
      "Epoch [117/2000], Avg Val Loss: 2.6540\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8393\n",
      "Epoch [118/2000], Avg Train Loss: 4.8393\n",
      "Epoch [118/2000], Avg Val Loss: 2.6535\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8300\n",
      "Epoch [119/2000], Avg Train Loss: 4.8300\n",
      "Epoch [119/2000], Avg Val Loss: 2.6530\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8262\n",
      "Epoch [120/2000], Avg Train Loss: 4.8262\n",
      "Epoch [120/2000], Avg Val Loss: 2.6525\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8731\n",
      "Epoch [121/2000], Avg Train Loss: 4.8731\n",
      "Epoch [121/2000], Avg Val Loss: 2.6520\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8499\n",
      "Epoch [122/2000], Avg Train Loss: 4.8499\n",
      "Epoch [122/2000], Avg Val Loss: 2.6515\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8596\n",
      "Epoch [123/2000], Avg Train Loss: 4.8596\n",
      "Epoch [123/2000], Avg Val Loss: 2.6510\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8163\n",
      "Epoch [124/2000], Avg Train Loss: 4.8163\n",
      "Epoch [124/2000], Avg Val Loss: 2.6505\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8053\n",
      "Epoch [125/2000], Avg Train Loss: 4.8053\n",
      "Epoch [125/2000], Avg Val Loss: 2.6499\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8070\n",
      "Epoch [126/2000], Avg Train Loss: 4.8070\n",
      "Epoch [126/2000], Avg Val Loss: 2.6494\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8470\n",
      "Epoch [127/2000], Avg Train Loss: 4.8470\n",
      "Epoch [127/2000], Avg Val Loss: 2.6488\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7633\n",
      "Epoch [128/2000], Avg Train Loss: 4.7633\n",
      "Epoch [128/2000], Avg Val Loss: 2.6482\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7385\n",
      "Epoch [129/2000], Avg Train Loss: 4.7385\n",
      "Epoch [129/2000], Avg Val Loss: 2.6476\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7401\n",
      "Epoch [130/2000], Avg Train Loss: 4.7401\n",
      "Epoch [130/2000], Avg Val Loss: 2.6470\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7990\n",
      "Epoch [131/2000], Avg Train Loss: 4.7990\n",
      "Epoch [131/2000], Avg Val Loss: 2.6463\n",
      "Validation loss improved from 2.6467 to 2.6463. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8009\n",
      "Epoch [132/2000], Avg Train Loss: 4.8009\n",
      "Epoch [132/2000], Avg Val Loss: 2.6456\n",
      "Validation loss improved from 2.6463 to 2.6456. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7452\n",
      "Epoch [133/2000], Avg Train Loss: 4.7452\n",
      "Epoch [133/2000], Avg Val Loss: 2.6449\n",
      "Validation loss improved from 2.6456 to 2.6449. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7642\n",
      "Epoch [134/2000], Avg Train Loss: 4.7642\n",
      "Epoch [134/2000], Avg Val Loss: 2.6442\n",
      "Validation loss improved from 2.6449 to 2.6442. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7612\n",
      "Epoch [135/2000], Avg Train Loss: 4.7612\n",
      "Epoch [135/2000], Avg Val Loss: 2.6435\n",
      "Validation loss improved from 2.6442 to 2.6435. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7627\n",
      "Epoch [136/2000], Avg Train Loss: 4.7627\n",
      "Epoch [136/2000], Avg Val Loss: 2.6428\n",
      "Validation loss improved from 2.6435 to 2.6428. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7096\n",
      "Epoch [137/2000], Avg Train Loss: 4.7096\n",
      "Epoch [137/2000], Avg Val Loss: 2.6421\n",
      "Validation loss improved from 2.6428 to 2.6421. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7352\n",
      "Epoch [138/2000], Avg Train Loss: 4.7352\n",
      "Epoch [138/2000], Avg Val Loss: 2.6413\n",
      "Validation loss improved from 2.6421 to 2.6413. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7060\n",
      "Epoch [139/2000], Avg Train Loss: 4.7060\n",
      "Epoch [139/2000], Avg Val Loss: 2.6406\n",
      "Validation loss improved from 2.6413 to 2.6406. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7211\n",
      "Epoch [140/2000], Avg Train Loss: 4.7211\n",
      "Epoch [140/2000], Avg Val Loss: 2.6398\n",
      "Validation loss improved from 2.6406 to 2.6398. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6768\n",
      "Epoch [141/2000], Avg Train Loss: 4.6768\n",
      "Epoch [141/2000], Avg Val Loss: 2.6389\n",
      "Validation loss improved from 2.6398 to 2.6389. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6987\n",
      "Epoch [142/2000], Avg Train Loss: 4.6987\n",
      "Epoch [142/2000], Avg Val Loss: 2.6381\n",
      "Validation loss improved from 2.6389 to 2.6381. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7325\n",
      "Epoch [143/2000], Avg Train Loss: 4.7325\n",
      "Epoch [143/2000], Avg Val Loss: 2.6372\n",
      "Validation loss improved from 2.6381 to 2.6372. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7282\n",
      "Epoch [144/2000], Avg Train Loss: 4.7282\n",
      "Epoch [144/2000], Avg Val Loss: 2.6364\n",
      "Validation loss improved from 2.6372 to 2.6364. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7665\n",
      "Epoch [145/2000], Avg Train Loss: 4.7665\n",
      "Epoch [145/2000], Avg Val Loss: 2.6355\n",
      "Validation loss improved from 2.6364 to 2.6355. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7202\n",
      "Epoch [146/2000], Avg Train Loss: 4.7202\n",
      "Epoch [146/2000], Avg Val Loss: 2.6347\n",
      "Validation loss improved from 2.6355 to 2.6347. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6799\n",
      "Epoch [147/2000], Avg Train Loss: 4.6799\n",
      "Epoch [147/2000], Avg Val Loss: 2.6339\n",
      "Validation loss improved from 2.6347 to 2.6339. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6927\n",
      "Epoch [148/2000], Avg Train Loss: 4.6927\n",
      "Epoch [148/2000], Avg Val Loss: 2.6330\n",
      "Validation loss improved from 2.6339 to 2.6330. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7408\n",
      "Epoch [149/2000], Avg Train Loss: 4.7408\n",
      "Epoch [149/2000], Avg Val Loss: 2.6322\n",
      "Validation loss improved from 2.6330 to 2.6322. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6747\n",
      "Epoch [150/2000], Avg Train Loss: 4.6747\n",
      "Epoch [150/2000], Avg Val Loss: 2.6313\n",
      "Validation loss improved from 2.6322 to 2.6313. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6737\n",
      "Epoch [151/2000], Avg Train Loss: 4.6737\n",
      "Epoch [151/2000], Avg Val Loss: 2.6304\n",
      "Validation loss improved from 2.6313 to 2.6304. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7339\n",
      "Epoch [152/2000], Avg Train Loss: 4.7339\n",
      "Epoch [152/2000], Avg Val Loss: 2.6295\n",
      "Validation loss improved from 2.6304 to 2.6295. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6677\n",
      "Epoch [153/2000], Avg Train Loss: 4.6677\n",
      "Epoch [153/2000], Avg Val Loss: 2.6286\n",
      "Validation loss improved from 2.6295 to 2.6286. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6702\n",
      "Epoch [154/2000], Avg Train Loss: 4.6702\n",
      "Epoch [154/2000], Avg Val Loss: 2.6277\n",
      "Validation loss improved from 2.6286 to 2.6277. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6690\n",
      "Epoch [155/2000], Avg Train Loss: 4.6690\n",
      "Epoch [155/2000], Avg Val Loss: 2.6269\n",
      "Validation loss improved from 2.6277 to 2.6269. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6898\n",
      "Epoch [156/2000], Avg Train Loss: 4.6898\n",
      "Epoch [156/2000], Avg Val Loss: 2.6260\n",
      "Validation loss improved from 2.6269 to 2.6260. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6978\n",
      "Epoch [157/2000], Avg Train Loss: 4.6978\n",
      "Epoch [157/2000], Avg Val Loss: 2.6250\n",
      "Validation loss improved from 2.6260 to 2.6250. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7111\n",
      "Epoch [158/2000], Avg Train Loss: 4.7111\n",
      "Epoch [158/2000], Avg Val Loss: 2.6241\n",
      "Validation loss improved from 2.6250 to 2.6241. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6700\n",
      "Epoch [159/2000], Avg Train Loss: 4.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/2000], Avg Val Loss: 2.6232\n",
      "Validation loss improved from 2.6241 to 2.6232. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6469\n",
      "Epoch [160/2000], Avg Train Loss: 4.6469\n",
      "Epoch [160/2000], Avg Val Loss: 2.6222\n",
      "Validation loss improved from 2.6232 to 2.6222. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6916\n",
      "Epoch [161/2000], Avg Train Loss: 4.6916\n",
      "Epoch [161/2000], Avg Val Loss: 2.6213\n",
      "Validation loss improved from 2.6222 to 2.6213. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6928\n",
      "Epoch [162/2000], Avg Train Loss: 4.6928\n",
      "Epoch [162/2000], Avg Val Loss: 2.6203\n",
      "Validation loss improved from 2.6213 to 2.6203. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6543\n",
      "Epoch [163/2000], Avg Train Loss: 4.6543\n",
      "Epoch [163/2000], Avg Val Loss: 2.6194\n",
      "Validation loss improved from 2.6203 to 2.6194. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6904\n",
      "Epoch [164/2000], Avg Train Loss: 4.6904\n",
      "Epoch [164/2000], Avg Val Loss: 2.6185\n",
      "Validation loss improved from 2.6194 to 2.6185. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6539\n",
      "Epoch [165/2000], Avg Train Loss: 4.6539\n",
      "Epoch [165/2000], Avg Val Loss: 2.6176\n",
      "Validation loss improved from 2.6185 to 2.6176. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6238\n",
      "Epoch [166/2000], Avg Train Loss: 4.6238\n",
      "Epoch [166/2000], Avg Val Loss: 2.6166\n",
      "Validation loss improved from 2.6176 to 2.6166. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6125\n",
      "Epoch [167/2000], Avg Train Loss: 4.6125\n",
      "Epoch [167/2000], Avg Val Loss: 2.6156\n",
      "Validation loss improved from 2.6166 to 2.6156. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6357\n",
      "Epoch [168/2000], Avg Train Loss: 4.6357\n",
      "Epoch [168/2000], Avg Val Loss: 2.6146\n",
      "Validation loss improved from 2.6156 to 2.6146. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6296\n",
      "Epoch [169/2000], Avg Train Loss: 4.6296\n",
      "Epoch [169/2000], Avg Val Loss: 2.6137\n",
      "Validation loss improved from 2.6146 to 2.6137. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6016\n",
      "Epoch [170/2000], Avg Train Loss: 4.6016\n",
      "Epoch [170/2000], Avg Val Loss: 2.6127\n",
      "Validation loss improved from 2.6137 to 2.6127. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6256\n",
      "Epoch [171/2000], Avg Train Loss: 4.6256\n",
      "Epoch [171/2000], Avg Val Loss: 2.6117\n",
      "Validation loss improved from 2.6127 to 2.6117. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6315\n",
      "Epoch [172/2000], Avg Train Loss: 4.6315\n",
      "Epoch [172/2000], Avg Val Loss: 2.6107\n",
      "Validation loss improved from 2.6117 to 2.6107. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5708\n",
      "Epoch [173/2000], Avg Train Loss: 4.5708\n",
      "Epoch [173/2000], Avg Val Loss: 2.6097\n",
      "Validation loss improved from 2.6107 to 2.6097. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5643\n",
      "Epoch [174/2000], Avg Train Loss: 4.5643\n",
      "Epoch [174/2000], Avg Val Loss: 2.6087\n",
      "Validation loss improved from 2.6097 to 2.6087. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5909\n",
      "Epoch [175/2000], Avg Train Loss: 4.5909\n",
      "Epoch [175/2000], Avg Val Loss: 2.6076\n",
      "Validation loss improved from 2.6087 to 2.6076. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5718\n",
      "Epoch [176/2000], Avg Train Loss: 4.5718\n",
      "Epoch [176/2000], Avg Val Loss: 2.6066\n",
      "Validation loss improved from 2.6076 to 2.6066. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5709\n",
      "Epoch [177/2000], Avg Train Loss: 4.5709\n",
      "Epoch [177/2000], Avg Val Loss: 2.6056\n",
      "Validation loss improved from 2.6066 to 2.6056. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5393\n",
      "Epoch [178/2000], Avg Train Loss: 4.5393\n",
      "Epoch [178/2000], Avg Val Loss: 2.6045\n",
      "Validation loss improved from 2.6056 to 2.6045. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6295\n",
      "Epoch [179/2000], Avg Train Loss: 4.6295\n",
      "Epoch [179/2000], Avg Val Loss: 2.6035\n",
      "Validation loss improved from 2.6045 to 2.6035. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5772\n",
      "Epoch [180/2000], Avg Train Loss: 4.5772\n",
      "Epoch [180/2000], Avg Val Loss: 2.6025\n",
      "Validation loss improved from 2.6035 to 2.6025. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6129\n",
      "Epoch [181/2000], Avg Train Loss: 4.6129\n",
      "Epoch [181/2000], Avg Val Loss: 2.6014\n",
      "Validation loss improved from 2.6025 to 2.6014. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5562\n",
      "Epoch [182/2000], Avg Train Loss: 4.5562\n",
      "Epoch [182/2000], Avg Val Loss: 2.6004\n",
      "Validation loss improved from 2.6014 to 2.6004. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5714\n",
      "Epoch [183/2000], Avg Train Loss: 4.5714\n",
      "Epoch [183/2000], Avg Val Loss: 2.5994\n",
      "Validation loss improved from 2.6004 to 2.5994. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5450\n",
      "Epoch [184/2000], Avg Train Loss: 4.5450\n",
      "Epoch [184/2000], Avg Val Loss: 2.5983\n",
      "Validation loss improved from 2.5994 to 2.5983. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5400\n",
      "Epoch [185/2000], Avg Train Loss: 4.5400\n",
      "Epoch [185/2000], Avg Val Loss: 2.5973\n",
      "Validation loss improved from 2.5983 to 2.5973. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5473\n",
      "Epoch [186/2000], Avg Train Loss: 4.5473\n",
      "Epoch [186/2000], Avg Val Loss: 2.5963\n",
      "Validation loss improved from 2.5973 to 2.5963. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5534\n",
      "Epoch [187/2000], Avg Train Loss: 4.5534\n",
      "Epoch [187/2000], Avg Val Loss: 2.5952\n",
      "Validation loss improved from 2.5963 to 2.5952. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5422\n",
      "Epoch [188/2000], Avg Train Loss: 4.5422\n",
      "Epoch [188/2000], Avg Val Loss: 2.5942\n",
      "Validation loss improved from 2.5952 to 2.5942. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5646\n",
      "Epoch [189/2000], Avg Train Loss: 4.5646\n",
      "Epoch [189/2000], Avg Val Loss: 2.5932\n",
      "Validation loss improved from 2.5942 to 2.5932. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5908\n",
      "Epoch [190/2000], Avg Train Loss: 4.5908\n",
      "Epoch [190/2000], Avg Val Loss: 2.5923\n",
      "Validation loss improved from 2.5932 to 2.5923. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5487\n",
      "Epoch [191/2000], Avg Train Loss: 4.5487\n",
      "Epoch [191/2000], Avg Val Loss: 2.5913\n",
      "Validation loss improved from 2.5923 to 2.5913. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5694\n",
      "Epoch [192/2000], Avg Train Loss: 4.5694\n",
      "Epoch [192/2000], Avg Val Loss: 2.5904\n",
      "Validation loss improved from 2.5913 to 2.5904. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5230\n",
      "Epoch [193/2000], Avg Train Loss: 4.5230\n",
      "Epoch [193/2000], Avg Val Loss: 2.5894\n",
      "Validation loss improved from 2.5904 to 2.5894. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5487\n",
      "Epoch [194/2000], Avg Train Loss: 4.5487\n",
      "Epoch [194/2000], Avg Val Loss: 2.5885\n",
      "Validation loss improved from 2.5894 to 2.5885. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5458\n",
      "Epoch [195/2000], Avg Train Loss: 4.5458\n",
      "Epoch [195/2000], Avg Val Loss: 2.5875\n",
      "Validation loss improved from 2.5885 to 2.5875. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5409\n",
      "Epoch [196/2000], Avg Train Loss: 4.5409\n",
      "Epoch [196/2000], Avg Val Loss: 2.5866\n",
      "Validation loss improved from 2.5875 to 2.5866. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5163\n",
      "Epoch [197/2000], Avg Train Loss: 4.5163\n",
      "Epoch [197/2000], Avg Val Loss: 2.5857\n",
      "Validation loss improved from 2.5866 to 2.5857. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5388\n",
      "Epoch [198/2000], Avg Train Loss: 4.5388\n",
      "Epoch [198/2000], Avg Val Loss: 2.5847\n",
      "Validation loss improved from 2.5857 to 2.5847. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5487\n",
      "Epoch [199/2000], Avg Train Loss: 4.5487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/2000], Avg Val Loss: 2.5838\n",
      "Validation loss improved from 2.5847 to 2.5838. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5769\n",
      "Epoch [200/2000], Avg Train Loss: 4.5769\n",
      "Epoch [200/2000], Avg Val Loss: 2.5829\n",
      "Validation loss improved from 2.5838 to 2.5829. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4918\n",
      "Epoch [201/2000], Avg Train Loss: 4.4918\n",
      "Epoch [201/2000], Avg Val Loss: 2.5819\n",
      "Validation loss improved from 2.5829 to 2.5819. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5063\n",
      "Epoch [202/2000], Avg Train Loss: 4.5063\n",
      "Epoch [202/2000], Avg Val Loss: 2.5810\n",
      "Validation loss improved from 2.5819 to 2.5810. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5247\n",
      "Epoch [203/2000], Avg Train Loss: 4.5247\n",
      "Epoch [203/2000], Avg Val Loss: 2.5801\n",
      "Validation loss improved from 2.5810 to 2.5801. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5318\n",
      "Epoch [204/2000], Avg Train Loss: 4.5318\n",
      "Epoch [204/2000], Avg Val Loss: 2.5792\n",
      "Validation loss improved from 2.5801 to 2.5792. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4856\n",
      "Epoch [205/2000], Avg Train Loss: 4.4856\n",
      "Epoch [205/2000], Avg Val Loss: 2.5784\n",
      "Validation loss improved from 2.5792 to 2.5784. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5370\n",
      "Epoch [206/2000], Avg Train Loss: 4.5370\n",
      "Epoch [206/2000], Avg Val Loss: 2.5775\n",
      "Validation loss improved from 2.5784 to 2.5775. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4900\n",
      "Epoch [207/2000], Avg Train Loss: 4.4900\n",
      "Epoch [207/2000], Avg Val Loss: 2.5766\n",
      "Validation loss improved from 2.5775 to 2.5766. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5593\n",
      "Epoch [208/2000], Avg Train Loss: 4.5593\n",
      "Epoch [208/2000], Avg Val Loss: 2.5757\n",
      "Validation loss improved from 2.5766 to 2.5757. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5300\n",
      "Epoch [209/2000], Avg Train Loss: 4.5300\n",
      "Epoch [209/2000], Avg Val Loss: 2.5748\n",
      "Validation loss improved from 2.5757 to 2.5748. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4831\n",
      "Epoch [210/2000], Avg Train Loss: 4.4831\n",
      "Epoch [210/2000], Avg Val Loss: 2.5739\n",
      "Validation loss improved from 2.5748 to 2.5739. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5150\n",
      "Epoch [211/2000], Avg Train Loss: 4.5150\n",
      "Epoch [211/2000], Avg Val Loss: 2.5730\n",
      "Validation loss improved from 2.5739 to 2.5730. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5031\n",
      "Epoch [212/2000], Avg Train Loss: 4.5031\n",
      "Epoch [212/2000], Avg Val Loss: 2.5721\n",
      "Validation loss improved from 2.5730 to 2.5721. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4414\n",
      "Epoch [213/2000], Avg Train Loss: 4.4414\n",
      "Epoch [213/2000], Avg Val Loss: 2.5712\n",
      "Validation loss improved from 2.5721 to 2.5712. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5085\n",
      "Epoch [214/2000], Avg Train Loss: 4.5085\n",
      "Epoch [214/2000], Avg Val Loss: 2.5703\n",
      "Validation loss improved from 2.5712 to 2.5703. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4847\n",
      "Epoch [215/2000], Avg Train Loss: 4.4847\n",
      "Epoch [215/2000], Avg Val Loss: 2.5694\n",
      "Validation loss improved from 2.5703 to 2.5694. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4683\n",
      "Epoch [216/2000], Avg Train Loss: 4.4683\n",
      "Epoch [216/2000], Avg Val Loss: 2.5685\n",
      "Validation loss improved from 2.5694 to 2.5685. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5320\n",
      "Epoch [217/2000], Avg Train Loss: 4.5320\n",
      "Epoch [217/2000], Avg Val Loss: 2.5675\n",
      "Validation loss improved from 2.5685 to 2.5675. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4571\n",
      "Epoch [218/2000], Avg Train Loss: 4.4571\n",
      "Epoch [218/2000], Avg Val Loss: 2.5666\n",
      "Validation loss improved from 2.5675 to 2.5666. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4838\n",
      "Epoch [219/2000], Avg Train Loss: 4.4838\n",
      "Epoch [219/2000], Avg Val Loss: 2.5657\n",
      "Validation loss improved from 2.5666 to 2.5657. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4465\n",
      "Epoch [220/2000], Avg Train Loss: 4.4465\n",
      "Epoch [220/2000], Avg Val Loss: 2.5647\n",
      "Validation loss improved from 2.5657 to 2.5647. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4639\n",
      "Epoch [221/2000], Avg Train Loss: 4.4639\n",
      "Epoch [221/2000], Avg Val Loss: 2.5637\n",
      "Validation loss improved from 2.5647 to 2.5637. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4536\n",
      "Epoch [222/2000], Avg Train Loss: 4.4536\n",
      "Epoch [222/2000], Avg Val Loss: 2.5627\n",
      "Validation loss improved from 2.5637 to 2.5627. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4766\n",
      "Epoch [223/2000], Avg Train Loss: 4.4766\n",
      "Epoch [223/2000], Avg Val Loss: 2.5617\n",
      "Validation loss improved from 2.5627 to 2.5617. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4898\n",
      "Epoch [224/2000], Avg Train Loss: 4.4898\n",
      "Epoch [224/2000], Avg Val Loss: 2.5608\n",
      "Validation loss improved from 2.5617 to 2.5608. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4691\n",
      "Epoch [225/2000], Avg Train Loss: 4.4691\n",
      "Epoch [225/2000], Avg Val Loss: 2.5598\n",
      "Validation loss improved from 2.5608 to 2.5598. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4539\n",
      "Epoch [226/2000], Avg Train Loss: 4.4539\n",
      "Epoch [226/2000], Avg Val Loss: 2.5588\n",
      "Validation loss improved from 2.5598 to 2.5588. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4690\n",
      "Epoch [227/2000], Avg Train Loss: 4.4690\n",
      "Epoch [227/2000], Avg Val Loss: 2.5579\n",
      "Validation loss improved from 2.5588 to 2.5579. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4339\n",
      "Epoch [228/2000], Avg Train Loss: 4.4339\n",
      "Epoch [228/2000], Avg Val Loss: 2.5569\n",
      "Validation loss improved from 2.5579 to 2.5569. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4439\n",
      "Epoch [229/2000], Avg Train Loss: 4.4439\n",
      "Epoch [229/2000], Avg Val Loss: 2.5559\n",
      "Validation loss improved from 2.5569 to 2.5559. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4421\n",
      "Epoch [230/2000], Avg Train Loss: 4.4421\n",
      "Epoch [230/2000], Avg Val Loss: 2.5550\n",
      "Validation loss improved from 2.5559 to 2.5550. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4596\n",
      "Epoch [231/2000], Avg Train Loss: 4.4596\n",
      "Epoch [231/2000], Avg Val Loss: 2.5541\n",
      "Validation loss improved from 2.5550 to 2.5541. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4438\n",
      "Epoch [232/2000], Avg Train Loss: 4.4438\n",
      "Epoch [232/2000], Avg Val Loss: 2.5531\n",
      "Validation loss improved from 2.5541 to 2.5531. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4426\n",
      "Epoch [233/2000], Avg Train Loss: 4.4426\n",
      "Epoch [233/2000], Avg Val Loss: 2.5521\n",
      "Validation loss improved from 2.5531 to 2.5521. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4342\n",
      "Epoch [234/2000], Avg Train Loss: 4.4342\n",
      "Epoch [234/2000], Avg Val Loss: 2.5512\n",
      "Validation loss improved from 2.5521 to 2.5512. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4380\n",
      "Epoch [235/2000], Avg Train Loss: 4.4380\n",
      "Epoch [235/2000], Avg Val Loss: 2.5502\n",
      "Validation loss improved from 2.5512 to 2.5502. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4532\n",
      "Epoch [236/2000], Avg Train Loss: 4.4532\n",
      "Epoch [236/2000], Avg Val Loss: 2.5492\n",
      "Validation loss improved from 2.5502 to 2.5492. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4497\n",
      "Epoch [237/2000], Avg Train Loss: 4.4497\n",
      "Epoch [237/2000], Avg Val Loss: 2.5483\n",
      "Validation loss improved from 2.5492 to 2.5483. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3739\n",
      "Epoch [238/2000], Avg Train Loss: 4.3739\n",
      "Epoch [238/2000], Avg Val Loss: 2.5473\n",
      "Validation loss improved from 2.5483 to 2.5473. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4097\n",
      "Epoch [239/2000], Avg Train Loss: 4.4097\n",
      "Epoch [239/2000], Avg Val Loss: 2.5463\n",
      "Validation loss improved from 2.5473 to 2.5463. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3799\n",
      "Epoch [240/2000], Avg Train Loss: 4.3799\n",
      "Epoch [240/2000], Avg Val Loss: 2.5454\n",
      "Validation loss improved from 2.5463 to 2.5454. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4226\n",
      "Epoch [241/2000], Avg Train Loss: 4.4226\n",
      "Epoch [241/2000], Avg Val Loss: 2.5444\n",
      "Validation loss improved from 2.5454 to 2.5444. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4296\n",
      "Epoch [242/2000], Avg Train Loss: 4.4296\n",
      "Epoch [242/2000], Avg Val Loss: 2.5434\n",
      "Validation loss improved from 2.5444 to 2.5434. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3877\n",
      "Epoch [243/2000], Avg Train Loss: 4.3877\n",
      "Epoch [243/2000], Avg Val Loss: 2.5424\n",
      "Validation loss improved from 2.5434 to 2.5424. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3636\n",
      "Epoch [244/2000], Avg Train Loss: 4.3636\n",
      "Epoch [244/2000], Avg Val Loss: 2.5414\n",
      "Validation loss improved from 2.5424 to 2.5414. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4208\n",
      "Epoch [245/2000], Avg Train Loss: 4.4208\n",
      "Epoch [245/2000], Avg Val Loss: 2.5404\n",
      "Validation loss improved from 2.5414 to 2.5404. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4161\n",
      "Epoch [246/2000], Avg Train Loss: 4.4161\n",
      "Epoch [246/2000], Avg Val Loss: 2.5395\n",
      "Validation loss improved from 2.5404 to 2.5395. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3482\n",
      "Epoch [247/2000], Avg Train Loss: 4.3482\n",
      "Epoch [247/2000], Avg Val Loss: 2.5385\n",
      "Validation loss improved from 2.5395 to 2.5385. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4050\n",
      "Epoch [248/2000], Avg Train Loss: 4.4050\n",
      "Epoch [248/2000], Avg Val Loss: 2.5375\n",
      "Validation loss improved from 2.5385 to 2.5375. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3936\n",
      "Epoch [249/2000], Avg Train Loss: 4.3936\n",
      "Epoch [249/2000], Avg Val Loss: 2.5366\n",
      "Validation loss improved from 2.5375 to 2.5366. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4039\n",
      "Epoch [250/2000], Avg Train Loss: 4.4039\n",
      "Epoch [250/2000], Avg Val Loss: 2.5357\n",
      "Validation loss improved from 2.5366 to 2.5357. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3996\n",
      "Epoch [251/2000], Avg Train Loss: 4.3996\n",
      "Epoch [251/2000], Avg Val Loss: 2.5347\n",
      "Validation loss improved from 2.5357 to 2.5347. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3622\n",
      "Epoch [252/2000], Avg Train Loss: 4.3622\n",
      "Epoch [252/2000], Avg Val Loss: 2.5338\n",
      "Validation loss improved from 2.5347 to 2.5338. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4032\n",
      "Epoch [253/2000], Avg Train Loss: 4.4032\n",
      "Epoch [253/2000], Avg Val Loss: 2.5329\n",
      "Validation loss improved from 2.5338 to 2.5329. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3558\n",
      "Epoch [254/2000], Avg Train Loss: 4.3558\n",
      "Epoch [254/2000], Avg Val Loss: 2.5320\n",
      "Validation loss improved from 2.5329 to 2.5320. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4176\n",
      "Epoch [255/2000], Avg Train Loss: 4.4176\n",
      "Epoch [255/2000], Avg Val Loss: 2.5311\n",
      "Validation loss improved from 2.5320 to 2.5311. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3826\n",
      "Epoch [256/2000], Avg Train Loss: 4.3826\n",
      "Epoch [256/2000], Avg Val Loss: 2.5302\n",
      "Validation loss improved from 2.5311 to 2.5302. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4086\n",
      "Epoch [257/2000], Avg Train Loss: 4.4086\n",
      "Epoch [257/2000], Avg Val Loss: 2.5294\n",
      "Validation loss improved from 2.5302 to 2.5294. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4082\n",
      "Epoch [258/2000], Avg Train Loss: 4.4082\n",
      "Epoch [258/2000], Avg Val Loss: 2.5286\n",
      "Validation loss improved from 2.5294 to 2.5286. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3765\n",
      "Epoch [259/2000], Avg Train Loss: 4.3765\n",
      "Epoch [259/2000], Avg Val Loss: 2.5277\n",
      "Validation loss improved from 2.5286 to 2.5277. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3645\n",
      "Epoch [260/2000], Avg Train Loss: 4.3645\n",
      "Epoch [260/2000], Avg Val Loss: 2.5269\n",
      "Validation loss improved from 2.5277 to 2.5269. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3654\n",
      "Epoch [261/2000], Avg Train Loss: 4.3654\n",
      "Epoch [261/2000], Avg Val Loss: 2.5260\n",
      "Validation loss improved from 2.5269 to 2.5260. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3954\n",
      "Epoch [262/2000], Avg Train Loss: 4.3954\n",
      "Epoch [262/2000], Avg Val Loss: 2.5252\n",
      "Validation loss improved from 2.5260 to 2.5252. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3512\n",
      "Epoch [263/2000], Avg Train Loss: 4.3512\n",
      "Epoch [263/2000], Avg Val Loss: 2.5243\n",
      "Validation loss improved from 2.5252 to 2.5243. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3500\n",
      "Epoch [264/2000], Avg Train Loss: 4.3500\n",
      "Epoch [264/2000], Avg Val Loss: 2.5234\n",
      "Validation loss improved from 2.5243 to 2.5234. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3667\n",
      "Epoch [265/2000], Avg Train Loss: 4.3667\n",
      "Epoch [265/2000], Avg Val Loss: 2.5226\n",
      "Validation loss improved from 2.5234 to 2.5226. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3475\n",
      "Epoch [266/2000], Avg Train Loss: 4.3475\n",
      "Epoch [266/2000], Avg Val Loss: 2.5217\n",
      "Validation loss improved from 2.5226 to 2.5217. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3638\n",
      "Epoch [267/2000], Avg Train Loss: 4.3638\n",
      "Epoch [267/2000], Avg Val Loss: 2.5208\n",
      "Validation loss improved from 2.5217 to 2.5208. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3367\n",
      "Epoch [268/2000], Avg Train Loss: 4.3367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [268/2000], Avg Val Loss: 2.5199\n",
      "Validation loss improved from 2.5208 to 2.5199. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3430\n",
      "Epoch [269/2000], Avg Train Loss: 4.3430\n",
      "Epoch [269/2000], Avg Val Loss: 2.5190\n",
      "Validation loss improved from 2.5199 to 2.5190. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3513\n",
      "Epoch [270/2000], Avg Train Loss: 4.3513\n",
      "Epoch [270/2000], Avg Val Loss: 2.5181\n",
      "Validation loss improved from 2.5190 to 2.5181. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3723\n",
      "Epoch [271/2000], Avg Train Loss: 4.3723\n",
      "Epoch [271/2000], Avg Val Loss: 2.5173\n",
      "Validation loss improved from 2.5181 to 2.5173. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3616\n",
      "Epoch [272/2000], Avg Train Loss: 4.3616\n",
      "Epoch [272/2000], Avg Val Loss: 2.5164\n",
      "Validation loss improved from 2.5173 to 2.5164. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2854\n",
      "Epoch [273/2000], Avg Train Loss: 4.2854\n",
      "Epoch [273/2000], Avg Val Loss: 2.5156\n",
      "Validation loss improved from 2.5164 to 2.5156. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3586\n",
      "Epoch [274/2000], Avg Train Loss: 4.3586\n",
      "Epoch [274/2000], Avg Val Loss: 2.5148\n",
      "Validation loss improved from 2.5156 to 2.5148. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3363\n",
      "Epoch [275/2000], Avg Train Loss: 4.3363\n",
      "Epoch [275/2000], Avg Val Loss: 2.5140\n",
      "Validation loss improved from 2.5148 to 2.5140. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3286\n",
      "Epoch [276/2000], Avg Train Loss: 4.3286\n",
      "Epoch [276/2000], Avg Val Loss: 2.5132\n",
      "Validation loss improved from 2.5140 to 2.5132. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3153\n",
      "Epoch [277/2000], Avg Train Loss: 4.3153\n",
      "Epoch [277/2000], Avg Val Loss: 2.5124\n",
      "Validation loss improved from 2.5132 to 2.5124. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3143\n",
      "Epoch [278/2000], Avg Train Loss: 4.3143\n",
      "Epoch [278/2000], Avg Val Loss: 2.5116\n",
      "Validation loss improved from 2.5124 to 2.5116. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3229\n",
      "Epoch [279/2000], Avg Train Loss: 4.3229\n",
      "Epoch [279/2000], Avg Val Loss: 2.5108\n",
      "Validation loss improved from 2.5116 to 2.5108. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3312\n",
      "Epoch [280/2000], Avg Train Loss: 4.3312\n",
      "Epoch [280/2000], Avg Val Loss: 2.5101\n",
      "Validation loss improved from 2.5108 to 2.5101. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3272\n",
      "Epoch [281/2000], Avg Train Loss: 4.3272\n",
      "Epoch [281/2000], Avg Val Loss: 2.5093\n",
      "Validation loss improved from 2.5101 to 2.5093. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3511\n",
      "Epoch [282/2000], Avg Train Loss: 4.3511\n",
      "Epoch [282/2000], Avg Val Loss: 2.5086\n",
      "Validation loss improved from 2.5093 to 2.5086. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3033\n",
      "Epoch [283/2000], Avg Train Loss: 4.3033\n",
      "Epoch [283/2000], Avg Val Loss: 2.5078\n",
      "Validation loss improved from 2.5086 to 2.5078. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3802\n",
      "Epoch [284/2000], Avg Train Loss: 4.3802\n",
      "Epoch [284/2000], Avg Val Loss: 2.5071\n",
      "Validation loss improved from 2.5078 to 2.5071. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3162\n",
      "Epoch [285/2000], Avg Train Loss: 4.3162\n",
      "Epoch [285/2000], Avg Val Loss: 2.5064\n",
      "Validation loss improved from 2.5071 to 2.5064. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3354\n",
      "Epoch [286/2000], Avg Train Loss: 4.3354\n",
      "Epoch [286/2000], Avg Val Loss: 2.5056\n",
      "Validation loss improved from 2.5064 to 2.5056. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3311\n",
      "Epoch [287/2000], Avg Train Loss: 4.3311\n",
      "Epoch [287/2000], Avg Val Loss: 2.5049\n",
      "Validation loss improved from 2.5056 to 2.5049. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3163\n",
      "Epoch [288/2000], Avg Train Loss: 4.3163\n",
      "Epoch [288/2000], Avg Val Loss: 2.5041\n",
      "Validation loss improved from 2.5049 to 2.5041. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2766\n",
      "Epoch [289/2000], Avg Train Loss: 4.2766\n",
      "Epoch [289/2000], Avg Val Loss: 2.5034\n",
      "Validation loss improved from 2.5041 to 2.5034. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3585\n",
      "Epoch [290/2000], Avg Train Loss: 4.3585\n",
      "Epoch [290/2000], Avg Val Loss: 2.5027\n",
      "Validation loss improved from 2.5034 to 2.5027. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3468\n",
      "Epoch [291/2000], Avg Train Loss: 4.3468\n",
      "Epoch [291/2000], Avg Val Loss: 2.5020\n",
      "Validation loss improved from 2.5027 to 2.5020. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3194\n",
      "Epoch [292/2000], Avg Train Loss: 4.3194\n",
      "Epoch [292/2000], Avg Val Loss: 2.5013\n",
      "Validation loss improved from 2.5020 to 2.5013. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2508\n",
      "Epoch [293/2000], Avg Train Loss: 4.2508\n",
      "Epoch [293/2000], Avg Val Loss: 2.5006\n",
      "Validation loss improved from 2.5013 to 2.5006. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2885\n",
      "Epoch [294/2000], Avg Train Loss: 4.2885\n",
      "Epoch [294/2000], Avg Val Loss: 2.5000\n",
      "Validation loss improved from 2.5006 to 2.5000. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2739\n",
      "Epoch [295/2000], Avg Train Loss: 4.2739\n",
      "Epoch [295/2000], Avg Val Loss: 2.4994\n",
      "Validation loss improved from 2.5000 to 2.4994. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3044\n",
      "Epoch [296/2000], Avg Train Loss: 4.3044\n",
      "Epoch [296/2000], Avg Val Loss: 2.4988\n",
      "Validation loss improved from 2.4994 to 2.4988. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3620\n",
      "Epoch [297/2000], Avg Train Loss: 4.3620\n",
      "Epoch [297/2000], Avg Val Loss: 2.4982\n",
      "Validation loss improved from 2.4988 to 2.4982. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2853\n",
      "Epoch [298/2000], Avg Train Loss: 4.2853\n",
      "Epoch [298/2000], Avg Val Loss: 2.4976\n",
      "Validation loss improved from 2.4982 to 2.4976. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2783\n",
      "Epoch [299/2000], Avg Train Loss: 4.2783\n",
      "Epoch [299/2000], Avg Val Loss: 2.4970\n",
      "Validation loss improved from 2.4976 to 2.4970. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2869\n",
      "Epoch [300/2000], Avg Train Loss: 4.2869\n",
      "Epoch [300/2000], Avg Val Loss: 2.4965\n",
      "Validation loss improved from 2.4970 to 2.4965. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3244\n",
      "Epoch [301/2000], Avg Train Loss: 4.3244\n",
      "Epoch [301/2000], Avg Val Loss: 2.4959\n",
      "Validation loss improved from 2.4965 to 2.4959. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2919\n",
      "Epoch [302/2000], Avg Train Loss: 4.2919\n",
      "Epoch [302/2000], Avg Val Loss: 2.4954\n",
      "Validation loss improved from 2.4959 to 2.4954. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3023\n",
      "Epoch [303/2000], Avg Train Loss: 4.3023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [303/2000], Avg Val Loss: 2.4948\n",
      "Validation loss improved from 2.4954 to 2.4948. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3269\n",
      "Epoch [304/2000], Avg Train Loss: 4.3269\n",
      "Epoch [304/2000], Avg Val Loss: 2.4942\n",
      "Validation loss improved from 2.4948 to 2.4942. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2948\n",
      "Epoch [305/2000], Avg Train Loss: 4.2948\n",
      "Epoch [305/2000], Avg Val Loss: 2.4937\n",
      "Validation loss improved from 2.4942 to 2.4937. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3027\n",
      "Epoch [306/2000], Avg Train Loss: 4.3027\n",
      "Epoch [306/2000], Avg Val Loss: 2.4931\n",
      "Validation loss improved from 2.4937 to 2.4931. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3087\n",
      "Epoch [307/2000], Avg Train Loss: 4.3087\n",
      "Epoch [307/2000], Avg Val Loss: 2.4924\n",
      "Validation loss improved from 2.4931 to 2.4924. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2736\n",
      "Epoch [308/2000], Avg Train Loss: 4.2736\n",
      "Epoch [308/2000], Avg Val Loss: 2.4918\n",
      "Validation loss improved from 2.4924 to 2.4918. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2940\n",
      "Epoch [309/2000], Avg Train Loss: 4.2940\n",
      "Epoch [309/2000], Avg Val Loss: 2.4911\n",
      "Validation loss improved from 2.4918 to 2.4911. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3051\n",
      "Epoch [310/2000], Avg Train Loss: 4.3051\n",
      "Epoch [310/2000], Avg Val Loss: 2.4905\n",
      "Validation loss improved from 2.4911 to 2.4905. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2849\n",
      "Epoch [311/2000], Avg Train Loss: 4.2849\n",
      "Epoch [311/2000], Avg Val Loss: 2.4899\n",
      "Validation loss improved from 2.4905 to 2.4899. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3090\n",
      "Epoch [312/2000], Avg Train Loss: 4.3090\n",
      "Epoch [312/2000], Avg Val Loss: 2.4892\n",
      "Validation loss improved from 2.4899 to 2.4892. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2861\n",
      "Epoch [313/2000], Avg Train Loss: 4.2861\n",
      "Epoch [313/2000], Avg Val Loss: 2.4886\n",
      "Validation loss improved from 2.4892 to 2.4886. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2836\n",
      "Epoch [314/2000], Avg Train Loss: 4.2836\n",
      "Epoch [314/2000], Avg Val Loss: 2.4880\n",
      "Validation loss improved from 2.4886 to 2.4880. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2905\n",
      "Epoch [315/2000], Avg Train Loss: 4.2905\n",
      "Epoch [315/2000], Avg Val Loss: 2.4873\n",
      "Validation loss improved from 2.4880 to 2.4873. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2636\n",
      "Epoch [316/2000], Avg Train Loss: 4.2636\n",
      "Epoch [316/2000], Avg Val Loss: 2.4867\n",
      "Validation loss improved from 2.4873 to 2.4867. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2780\n",
      "Epoch [317/2000], Avg Train Loss: 4.2780\n",
      "Epoch [317/2000], Avg Val Loss: 2.4861\n",
      "Validation loss improved from 2.4867 to 2.4861. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2249\n",
      "Epoch [318/2000], Avg Train Loss: 4.2249\n",
      "Epoch [318/2000], Avg Val Loss: 2.4856\n",
      "Validation loss improved from 2.4861 to 2.4856. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2933\n",
      "Epoch [319/2000], Avg Train Loss: 4.2933\n",
      "Epoch [319/2000], Avg Val Loss: 2.4850\n",
      "Validation loss improved from 2.4856 to 2.4850. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2419\n",
      "Epoch [320/2000], Avg Train Loss: 4.2419\n",
      "Epoch [320/2000], Avg Val Loss: 2.4844\n",
      "Validation loss improved from 2.4850 to 2.4844. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2245\n",
      "Epoch [321/2000], Avg Train Loss: 4.2245\n",
      "Epoch [321/2000], Avg Val Loss: 2.4838\n",
      "Validation loss improved from 2.4844 to 2.4838. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2591\n",
      "Epoch [322/2000], Avg Train Loss: 4.2591\n",
      "Epoch [322/2000], Avg Val Loss: 2.4832\n",
      "Validation loss improved from 2.4838 to 2.4832. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2758\n",
      "Epoch [323/2000], Avg Train Loss: 4.2758\n",
      "Epoch [323/2000], Avg Val Loss: 2.4826\n",
      "Validation loss improved from 2.4832 to 2.4826. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2727\n",
      "Epoch [324/2000], Avg Train Loss: 4.2727\n",
      "Epoch [324/2000], Avg Val Loss: 2.4820\n",
      "Validation loss improved from 2.4826 to 2.4820. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2401\n",
      "Epoch [325/2000], Avg Train Loss: 4.2401\n",
      "Epoch [325/2000], Avg Val Loss: 2.4814\n",
      "Validation loss improved from 2.4820 to 2.4814. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2853\n",
      "Epoch [326/2000], Avg Train Loss: 4.2853\n",
      "Epoch [326/2000], Avg Val Loss: 2.4808\n",
      "Validation loss improved from 2.4814 to 2.4808. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2705\n",
      "Epoch [327/2000], Avg Train Loss: 4.2705\n",
      "Epoch [327/2000], Avg Val Loss: 2.4803\n",
      "Validation loss improved from 2.4808 to 2.4803. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2237\n",
      "Epoch [328/2000], Avg Train Loss: 4.2237\n",
      "Epoch [328/2000], Avg Val Loss: 2.4797\n",
      "Validation loss improved from 2.4803 to 2.4797. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2212\n",
      "Epoch [329/2000], Avg Train Loss: 4.2212\n",
      "Epoch [329/2000], Avg Val Loss: 2.4791\n",
      "Validation loss improved from 2.4797 to 2.4791. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2965\n",
      "Epoch [330/2000], Avg Train Loss: 4.2965\n",
      "Epoch [330/2000], Avg Val Loss: 2.4786\n",
      "Validation loss improved from 2.4791 to 2.4786. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1982\n",
      "Epoch [331/2000], Avg Train Loss: 4.1982\n",
      "Epoch [331/2000], Avg Val Loss: 2.4780\n",
      "Validation loss improved from 2.4786 to 2.4780. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2372\n",
      "Epoch [332/2000], Avg Train Loss: 4.2372\n",
      "Epoch [332/2000], Avg Val Loss: 2.4774\n",
      "Validation loss improved from 2.4780 to 2.4774. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2391\n",
      "Epoch [333/2000], Avg Train Loss: 4.2391\n",
      "Epoch [333/2000], Avg Val Loss: 2.4768\n",
      "Validation loss improved from 2.4774 to 2.4768. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2237\n",
      "Epoch [334/2000], Avg Train Loss: 4.2237\n",
      "Epoch [334/2000], Avg Val Loss: 2.4762\n",
      "Validation loss improved from 2.4768 to 2.4762. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2566\n",
      "Epoch [335/2000], Avg Train Loss: 4.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [335/2000], Avg Val Loss: 2.4756\n",
      "Validation loss improved from 2.4762 to 2.4756. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2210\n",
      "Epoch [336/2000], Avg Train Loss: 4.2210\n",
      "Epoch [336/2000], Avg Val Loss: 2.4750\n",
      "Validation loss improved from 2.4756 to 2.4750. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2616\n",
      "Epoch [337/2000], Avg Train Loss: 4.2616\n",
      "Epoch [337/2000], Avg Val Loss: 2.4744\n",
      "Validation loss improved from 2.4750 to 2.4744. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2634\n",
      "Epoch [338/2000], Avg Train Loss: 4.2634\n",
      "Epoch [338/2000], Avg Val Loss: 2.4738\n",
      "Validation loss improved from 2.4744 to 2.4738. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2460\n",
      "Epoch [339/2000], Avg Train Loss: 4.2460\n",
      "Epoch [339/2000], Avg Val Loss: 2.4732\n",
      "Validation loss improved from 2.4738 to 2.4732. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2404\n",
      "Epoch [340/2000], Avg Train Loss: 4.2404\n",
      "Epoch [340/2000], Avg Val Loss: 2.4726\n",
      "Validation loss improved from 2.4732 to 2.4726. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2639\n",
      "Epoch [341/2000], Avg Train Loss: 4.2639\n",
      "Epoch [341/2000], Avg Val Loss: 2.4720\n",
      "Validation loss improved from 2.4726 to 2.4720. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2852\n",
      "Epoch [342/2000], Avg Train Loss: 4.2852\n",
      "Epoch [342/2000], Avg Val Loss: 2.4715\n",
      "Validation loss improved from 2.4720 to 2.4715. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2097\n",
      "Epoch [343/2000], Avg Train Loss: 4.2097\n",
      "Epoch [343/2000], Avg Val Loss: 2.4709\n",
      "Validation loss improved from 2.4715 to 2.4709. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2653\n",
      "Epoch [344/2000], Avg Train Loss: 4.2653\n",
      "Epoch [344/2000], Avg Val Loss: 2.4703\n",
      "Validation loss improved from 2.4709 to 2.4703. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2207\n",
      "Epoch [345/2000], Avg Train Loss: 4.2207\n",
      "Epoch [345/2000], Avg Val Loss: 2.4697\n",
      "Validation loss improved from 2.4703 to 2.4697. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2397\n",
      "Epoch [346/2000], Avg Train Loss: 4.2397\n",
      "Epoch [346/2000], Avg Val Loss: 2.4691\n",
      "Validation loss improved from 2.4697 to 2.4691. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2555\n",
      "Epoch [347/2000], Avg Train Loss: 4.2555\n",
      "Epoch [347/2000], Avg Val Loss: 2.4685\n",
      "Validation loss improved from 2.4691 to 2.4685. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2488\n",
      "Epoch [348/2000], Avg Train Loss: 4.2488\n",
      "Epoch [348/2000], Avg Val Loss: 2.4679\n",
      "Validation loss improved from 2.4685 to 2.4679. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2518\n",
      "Epoch [349/2000], Avg Train Loss: 4.2518\n",
      "Epoch [349/2000], Avg Val Loss: 2.4674\n",
      "Validation loss improved from 2.4679 to 2.4674. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2260\n",
      "Epoch [350/2000], Avg Train Loss: 4.2260\n",
      "Epoch [350/2000], Avg Val Loss: 2.4668\n",
      "Validation loss improved from 2.4674 to 2.4668. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1870\n",
      "Epoch [351/2000], Avg Train Loss: 4.1870\n",
      "Epoch [351/2000], Avg Val Loss: 2.4662\n",
      "Validation loss improved from 2.4668 to 2.4662. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2090\n",
      "Epoch [352/2000], Avg Train Loss: 4.2090\n",
      "Epoch [352/2000], Avg Val Loss: 2.4657\n",
      "Validation loss improved from 2.4662 to 2.4657. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2129\n",
      "Epoch [353/2000], Avg Train Loss: 4.2129\n",
      "Epoch [353/2000], Avg Val Loss: 2.4651\n",
      "Validation loss improved from 2.4657 to 2.4651. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1614\n",
      "Epoch [354/2000], Avg Train Loss: 4.1614\n",
      "Epoch [354/2000], Avg Val Loss: 2.4645\n",
      "Validation loss improved from 2.4651 to 2.4645. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1805\n",
      "Epoch [355/2000], Avg Train Loss: 4.1805\n",
      "Epoch [355/2000], Avg Val Loss: 2.4640\n",
      "Validation loss improved from 2.4645 to 2.4640. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1859\n",
      "Epoch [356/2000], Avg Train Loss: 4.1859\n",
      "Epoch [356/2000], Avg Val Loss: 2.4634\n",
      "Validation loss improved from 2.4640 to 2.4634. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1906\n",
      "Epoch [357/2000], Avg Train Loss: 4.1906\n",
      "Epoch [357/2000], Avg Val Loss: 2.4629\n",
      "Validation loss improved from 2.4634 to 2.4629. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2037\n",
      "Epoch [358/2000], Avg Train Loss: 4.2037\n",
      "Epoch [358/2000], Avg Val Loss: 2.4623\n",
      "Validation loss improved from 2.4629 to 2.4623. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2254\n",
      "Epoch [359/2000], Avg Train Loss: 4.2254\n",
      "Epoch [359/2000], Avg Val Loss: 2.4619\n",
      "Validation loss improved from 2.4623 to 2.4619. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1922\n",
      "Epoch [360/2000], Avg Train Loss: 4.1922\n",
      "Epoch [360/2000], Avg Val Loss: 2.4614\n",
      "Validation loss improved from 2.4619 to 2.4614. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2298\n",
      "Epoch [361/2000], Avg Train Loss: 4.2298\n",
      "Epoch [361/2000], Avg Val Loss: 2.4610\n",
      "Validation loss improved from 2.4614 to 2.4610. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1727\n",
      "Epoch [362/2000], Avg Train Loss: 4.1727\n",
      "Epoch [362/2000], Avg Val Loss: 2.4605\n",
      "Validation loss improved from 2.4610 to 2.4605. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2015\n",
      "Epoch [363/2000], Avg Train Loss: 4.2015\n",
      "Epoch [363/2000], Avg Val Loss: 2.4601\n",
      "Validation loss improved from 2.4605 to 2.4601. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2136\n",
      "Epoch [364/2000], Avg Train Loss: 4.2136\n",
      "Epoch [364/2000], Avg Val Loss: 2.4596\n",
      "Validation loss improved from 2.4601 to 2.4596. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2053\n",
      "Epoch [365/2000], Avg Train Loss: 4.2053\n",
      "Epoch [365/2000], Avg Val Loss: 2.4592\n",
      "Validation loss improved from 2.4596 to 2.4592. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1968\n",
      "Epoch [366/2000], Avg Train Loss: 4.1968\n",
      "Epoch [366/2000], Avg Val Loss: 2.4588\n",
      "Validation loss improved from 2.4592 to 2.4588. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1922\n",
      "Epoch [367/2000], Avg Train Loss: 4.1922\n",
      "Epoch [367/2000], Avg Val Loss: 2.4583\n",
      "Validation loss improved from 2.4588 to 2.4583. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1759\n",
      "Epoch [368/2000], Avg Train Loss: 4.1759\n",
      "Epoch [368/2000], Avg Val Loss: 2.4579\n",
      "Validation loss improved from 2.4583 to 2.4579. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1978\n",
      "Epoch [369/2000], Avg Train Loss: 4.1978\n",
      "Epoch [369/2000], Avg Val Loss: 2.4574\n",
      "Validation loss improved from 2.4579 to 2.4574. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2119\n",
      "Epoch [370/2000], Avg Train Loss: 4.2119\n",
      "Epoch [370/2000], Avg Val Loss: 2.4570\n",
      "Validation loss improved from 2.4574 to 2.4570. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1881\n",
      "Epoch [371/2000], Avg Train Loss: 4.1881\n",
      "Epoch [371/2000], Avg Val Loss: 2.4566\n",
      "Validation loss improved from 2.4570 to 2.4566. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2032\n",
      "Epoch [372/2000], Avg Train Loss: 4.2032\n",
      "Epoch [372/2000], Avg Val Loss: 2.4561\n",
      "Validation loss improved from 2.4566 to 2.4561. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1884\n",
      "Epoch [373/2000], Avg Train Loss: 4.1884\n",
      "Epoch [373/2000], Avg Val Loss: 2.4557\n",
      "Validation loss improved from 2.4561 to 2.4557. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2101\n",
      "Epoch [374/2000], Avg Train Loss: 4.2101\n",
      "Epoch [374/2000], Avg Val Loss: 2.4553\n",
      "Validation loss improved from 2.4557 to 2.4553. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1861\n",
      "Epoch [375/2000], Avg Train Loss: 4.1861\n",
      "Epoch [375/2000], Avg Val Loss: 2.4548\n",
      "Validation loss improved from 2.4553 to 2.4548. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2312\n",
      "Epoch [376/2000], Avg Train Loss: 4.2312\n",
      "Epoch [376/2000], Avg Val Loss: 2.4544\n",
      "Validation loss improved from 2.4548 to 2.4544. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1655\n",
      "Epoch [377/2000], Avg Train Loss: 4.1655\n",
      "Epoch [377/2000], Avg Val Loss: 2.4540\n",
      "Validation loss improved from 2.4544 to 2.4540. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1719\n",
      "Epoch [378/2000], Avg Train Loss: 4.1719\n",
      "Epoch [378/2000], Avg Val Loss: 2.4535\n",
      "Validation loss improved from 2.4540 to 2.4535. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1981\n",
      "Epoch [379/2000], Avg Train Loss: 4.1981\n",
      "Epoch [379/2000], Avg Val Loss: 2.4531\n",
      "Validation loss improved from 2.4535 to 2.4531. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1895\n",
      "Epoch [380/2000], Avg Train Loss: 4.1895\n",
      "Epoch [380/2000], Avg Val Loss: 2.4526\n",
      "Validation loss improved from 2.4531 to 2.4526. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1678\n",
      "Epoch [381/2000], Avg Train Loss: 4.1678\n",
      "Epoch [381/2000], Avg Val Loss: 2.4522\n",
      "Validation loss improved from 2.4526 to 2.4522. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1685\n",
      "Epoch [382/2000], Avg Train Loss: 4.1685\n",
      "Epoch [382/2000], Avg Val Loss: 2.4518\n",
      "Validation loss improved from 2.4522 to 2.4518. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1903\n",
      "Epoch [383/2000], Avg Train Loss: 4.1903\n",
      "Epoch [383/2000], Avg Val Loss: 2.4514\n",
      "Validation loss improved from 2.4518 to 2.4514. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1667\n",
      "Epoch [384/2000], Avg Train Loss: 4.1667\n",
      "Epoch [384/2000], Avg Val Loss: 2.4510\n",
      "Validation loss improved from 2.4514 to 2.4510. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1770\n",
      "Epoch [385/2000], Avg Train Loss: 4.1770\n",
      "Epoch [385/2000], Avg Val Loss: 2.4507\n",
      "Validation loss improved from 2.4510 to 2.4507. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1442\n",
      "Epoch [386/2000], Avg Train Loss: 4.1442\n",
      "Epoch [386/2000], Avg Val Loss: 2.4503\n",
      "Validation loss improved from 2.4507 to 2.4503. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2018\n",
      "Epoch [387/2000], Avg Train Loss: 4.2018\n",
      "Epoch [387/2000], Avg Val Loss: 2.4499\n",
      "Validation loss improved from 2.4503 to 2.4499. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2006\n",
      "Epoch [388/2000], Avg Train Loss: 4.2006\n",
      "Epoch [388/2000], Avg Val Loss: 2.4496\n",
      "Validation loss improved from 2.4499 to 2.4496. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1513\n",
      "Epoch [389/2000], Avg Train Loss: 4.1513\n",
      "Epoch [389/2000], Avg Val Loss: 2.4492\n",
      "Validation loss improved from 2.4496 to 2.4492. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1742\n",
      "Epoch [390/2000], Avg Train Loss: 4.1742\n",
      "Epoch [390/2000], Avg Val Loss: 2.4489\n",
      "Validation loss improved from 2.4492 to 2.4489. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1481\n",
      "Epoch [391/2000], Avg Train Loss: 4.1481\n",
      "Epoch [391/2000], Avg Val Loss: 2.4486\n",
      "Validation loss improved from 2.4489 to 2.4486. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1632\n",
      "Epoch [392/2000], Avg Train Loss: 4.1632\n",
      "Epoch [392/2000], Avg Val Loss: 2.4482\n",
      "Validation loss improved from 2.4486 to 2.4482. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1471\n",
      "Epoch [393/2000], Avg Train Loss: 4.1471\n",
      "Epoch [393/2000], Avg Val Loss: 2.4479\n",
      "Validation loss improved from 2.4482 to 2.4479. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2035\n",
      "Epoch [394/2000], Avg Train Loss: 4.2035\n",
      "Epoch [394/2000], Avg Val Loss: 2.4475\n",
      "Validation loss improved from 2.4479 to 2.4475. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1754\n",
      "Epoch [395/2000], Avg Train Loss: 4.1754\n",
      "Epoch [395/2000], Avg Val Loss: 2.4472\n",
      "Validation loss improved from 2.4475 to 2.4472. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1688\n",
      "Epoch [396/2000], Avg Train Loss: 4.1688\n",
      "Epoch [396/2000], Avg Val Loss: 2.4469\n",
      "Validation loss improved from 2.4472 to 2.4469. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1387\n",
      "Epoch [397/2000], Avg Train Loss: 4.1387\n",
      "Epoch [397/2000], Avg Val Loss: 2.4465\n",
      "Validation loss improved from 2.4469 to 2.4465. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1505\n",
      "Epoch [398/2000], Avg Train Loss: 4.1505\n",
      "Epoch [398/2000], Avg Val Loss: 2.4462\n",
      "Validation loss improved from 2.4465 to 2.4462. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1297\n",
      "Epoch [399/2000], Avg Train Loss: 4.1297\n",
      "Epoch [399/2000], Avg Val Loss: 2.4458\n",
      "Validation loss improved from 2.4462 to 2.4458. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1487\n",
      "Epoch [400/2000], Avg Train Loss: 4.1487\n",
      "Epoch [400/2000], Avg Val Loss: 2.4455\n",
      "Validation loss improved from 2.4458 to 2.4455. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1878\n",
      "Epoch [401/2000], Avg Train Loss: 4.1878\n",
      "Epoch [401/2000], Avg Val Loss: 2.4451\n",
      "Validation loss improved from 2.4455 to 2.4451. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1366\n",
      "Epoch [402/2000], Avg Train Loss: 4.1366\n",
      "Epoch [402/2000], Avg Val Loss: 2.4447\n",
      "Validation loss improved from 2.4451 to 2.4447. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1261\n",
      "Epoch [403/2000], Avg Train Loss: 4.1261\n",
      "Epoch [403/2000], Avg Val Loss: 2.4442\n",
      "Validation loss improved from 2.4447 to 2.4442. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1764\n",
      "Epoch [404/2000], Avg Train Loss: 4.1764\n",
      "Epoch [404/2000], Avg Val Loss: 2.4437\n",
      "Validation loss improved from 2.4442 to 2.4437. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1649\n",
      "Epoch [405/2000], Avg Train Loss: 4.1649\n",
      "Epoch [405/2000], Avg Val Loss: 2.4433\n",
      "Validation loss improved from 2.4437 to 2.4433. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1530\n",
      "Epoch [406/2000], Avg Train Loss: 4.1530\n",
      "Epoch [406/2000], Avg Val Loss: 2.4428\n",
      "Validation loss improved from 2.4433 to 2.4428. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1825\n",
      "Epoch [407/2000], Avg Train Loss: 4.1825\n",
      "Epoch [407/2000], Avg Val Loss: 2.4423\n",
      "Validation loss improved from 2.4428 to 2.4423. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1088\n",
      "Epoch [408/2000], Avg Train Loss: 4.1088\n",
      "Epoch [408/2000], Avg Val Loss: 2.4418\n",
      "Validation loss improved from 2.4423 to 2.4418. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1190\n",
      "Epoch [409/2000], Avg Train Loss: 4.1190\n",
      "Epoch [409/2000], Avg Val Loss: 2.4413\n",
      "Validation loss improved from 2.4418 to 2.4413. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1271\n",
      "Epoch [410/2000], Avg Train Loss: 4.1271\n",
      "Epoch [410/2000], Avg Val Loss: 2.4408\n",
      "Validation loss improved from 2.4413 to 2.4408. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1246\n",
      "Epoch [411/2000], Avg Train Loss: 4.1246\n",
      "Epoch [411/2000], Avg Val Loss: 2.4403\n",
      "Validation loss improved from 2.4408 to 2.4403. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1381\n",
      "Epoch [412/2000], Avg Train Loss: 4.1381\n",
      "Epoch [412/2000], Avg Val Loss: 2.4398\n",
      "Validation loss improved from 2.4403 to 2.4398. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1133\n",
      "Epoch [413/2000], Avg Train Loss: 4.1133\n",
      "Epoch [413/2000], Avg Val Loss: 2.4393\n",
      "Validation loss improved from 2.4398 to 2.4393. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1700\n",
      "Epoch [414/2000], Avg Train Loss: 4.1700\n",
      "Epoch [414/2000], Avg Val Loss: 2.4388\n",
      "Validation loss improved from 2.4393 to 2.4388. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1618\n",
      "Epoch [415/2000], Avg Train Loss: 4.1618\n",
      "Epoch [415/2000], Avg Val Loss: 2.4384\n",
      "Validation loss improved from 2.4388 to 2.4384. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1329\n",
      "Epoch [416/2000], Avg Train Loss: 4.1329\n",
      "Epoch [416/2000], Avg Val Loss: 2.4379\n",
      "Validation loss improved from 2.4384 to 2.4379. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1472\n",
      "Epoch [417/2000], Avg Train Loss: 4.1472\n",
      "Epoch [417/2000], Avg Val Loss: 2.4374\n",
      "Validation loss improved from 2.4379 to 2.4374. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1503\n",
      "Epoch [418/2000], Avg Train Loss: 4.1503\n",
      "Epoch [418/2000], Avg Val Loss: 2.4370\n",
      "Validation loss improved from 2.4374 to 2.4370. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1344\n",
      "Epoch [419/2000], Avg Train Loss: 4.1344\n",
      "Epoch [419/2000], Avg Val Loss: 2.4366\n",
      "Validation loss improved from 2.4370 to 2.4366. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1186\n",
      "Epoch [420/2000], Avg Train Loss: 4.1186\n",
      "Epoch [420/2000], Avg Val Loss: 2.4362\n",
      "Validation loss improved from 2.4366 to 2.4362. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1787\n",
      "Epoch [421/2000], Avg Train Loss: 4.1787\n",
      "Epoch [421/2000], Avg Val Loss: 2.4358\n",
      "Validation loss improved from 2.4362 to 2.4358. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1523\n",
      "Epoch [422/2000], Avg Train Loss: 4.1523\n",
      "Epoch [422/2000], Avg Val Loss: 2.4354\n",
      "Validation loss improved from 2.4358 to 2.4354. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1547\n",
      "Epoch [423/2000], Avg Train Loss: 4.1547\n",
      "Epoch [423/2000], Avg Val Loss: 2.4351\n",
      "Validation loss improved from 2.4354 to 2.4351. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1108\n",
      "Epoch [424/2000], Avg Train Loss: 4.1108\n",
      "Epoch [424/2000], Avg Val Loss: 2.4347\n",
      "Validation loss improved from 2.4351 to 2.4347. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0955\n",
      "Epoch [425/2000], Avg Train Loss: 4.0955\n",
      "Epoch [425/2000], Avg Val Loss: 2.4343\n",
      "Validation loss improved from 2.4347 to 2.4343. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0949\n",
      "Epoch [426/2000], Avg Train Loss: 4.0949\n",
      "Epoch [426/2000], Avg Val Loss: 2.4339\n",
      "Validation loss improved from 2.4343 to 2.4339. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1380\n",
      "Epoch [427/2000], Avg Train Loss: 4.1380\n",
      "Epoch [427/2000], Avg Val Loss: 2.4335\n",
      "Validation loss improved from 2.4339 to 2.4335. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1290\n",
      "Epoch [428/2000], Avg Train Loss: 4.1290\n",
      "Epoch [428/2000], Avg Val Loss: 2.4331\n",
      "Validation loss improved from 2.4335 to 2.4331. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1387\n",
      "Epoch [429/2000], Avg Train Loss: 4.1387\n",
      "Epoch [429/2000], Avg Val Loss: 2.4327\n",
      "Validation loss improved from 2.4331 to 2.4327. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1171\n",
      "Epoch [430/2000], Avg Train Loss: 4.1171\n",
      "Epoch [430/2000], Avg Val Loss: 2.4323\n",
      "Validation loss improved from 2.4327 to 2.4323. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1047\n",
      "Epoch [431/2000], Avg Train Loss: 4.1047\n",
      "Epoch [431/2000], Avg Val Loss: 2.4319\n",
      "Validation loss improved from 2.4323 to 2.4319. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1092\n",
      "Epoch [432/2000], Avg Train Loss: 4.1092\n",
      "Epoch [432/2000], Avg Val Loss: 2.4315\n",
      "Validation loss improved from 2.4319 to 2.4315. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1191\n",
      "Epoch [433/2000], Avg Train Loss: 4.1191\n",
      "Epoch [433/2000], Avg Val Loss: 2.4311\n",
      "Validation loss improved from 2.4315 to 2.4311. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1454\n",
      "Epoch [434/2000], Avg Train Loss: 4.1454\n",
      "Epoch [434/2000], Avg Val Loss: 2.4307\n",
      "Validation loss improved from 2.4311 to 2.4307. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1210\n",
      "Epoch [435/2000], Avg Train Loss: 4.1210\n",
      "Epoch [435/2000], Avg Val Loss: 2.4303\n",
      "Validation loss improved from 2.4307 to 2.4303. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1310\n",
      "Epoch [436/2000], Avg Train Loss: 4.1310\n",
      "Epoch [436/2000], Avg Val Loss: 2.4299\n",
      "Validation loss improved from 2.4303 to 2.4299. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1191\n",
      "Epoch [437/2000], Avg Train Loss: 4.1191\n",
      "Epoch [437/2000], Avg Val Loss: 2.4294\n",
      "Validation loss improved from 2.4299 to 2.4294. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1242\n",
      "Epoch [438/2000], Avg Train Loss: 4.1242\n",
      "Epoch [438/2000], Avg Val Loss: 2.4290\n",
      "Validation loss improved from 2.4294 to 2.4290. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1412\n",
      "Epoch [439/2000], Avg Train Loss: 4.1412\n",
      "Epoch [439/2000], Avg Val Loss: 2.4285\n",
      "Validation loss improved from 2.4290 to 2.4285. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0858\n",
      "Epoch [440/2000], Avg Train Loss: 4.0858\n",
      "Epoch [440/2000], Avg Val Loss: 2.4281\n",
      "Validation loss improved from 2.4285 to 2.4281. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0911\n",
      "Epoch [441/2000], Avg Train Loss: 4.0911\n",
      "Epoch [441/2000], Avg Val Loss: 2.4276\n",
      "Validation loss improved from 2.4281 to 2.4276. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1088\n",
      "Epoch [442/2000], Avg Train Loss: 4.1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [442/2000], Avg Val Loss: 2.4271\n",
      "Validation loss improved from 2.4276 to 2.4271. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0927\n",
      "Epoch [443/2000], Avg Train Loss: 4.0927\n",
      "Epoch [443/2000], Avg Val Loss: 2.4266\n",
      "Validation loss improved from 2.4271 to 2.4266. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1215\n",
      "Epoch [444/2000], Avg Train Loss: 4.1215\n",
      "Epoch [444/2000], Avg Val Loss: 2.4261\n",
      "Validation loss improved from 2.4266 to 2.4261. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1067\n",
      "Epoch [445/2000], Avg Train Loss: 4.1067\n",
      "Epoch [445/2000], Avg Val Loss: 2.4256\n",
      "Validation loss improved from 2.4261 to 2.4256. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1085\n",
      "Epoch [446/2000], Avg Train Loss: 4.1085\n",
      "Epoch [446/2000], Avg Val Loss: 2.4252\n",
      "Validation loss improved from 2.4256 to 2.4252. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0999\n",
      "Epoch [447/2000], Avg Train Loss: 4.0999\n",
      "Epoch [447/2000], Avg Val Loss: 2.4247\n",
      "Validation loss improved from 2.4252 to 2.4247. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0667\n",
      "Epoch [448/2000], Avg Train Loss: 4.0667\n",
      "Epoch [448/2000], Avg Val Loss: 2.4243\n",
      "Validation loss improved from 2.4247 to 2.4243. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0892\n",
      "Epoch [449/2000], Avg Train Loss: 4.0892\n",
      "Epoch [449/2000], Avg Val Loss: 2.4238\n",
      "Validation loss improved from 2.4243 to 2.4238. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0769\n",
      "Epoch [450/2000], Avg Train Loss: 4.0769\n",
      "Epoch [450/2000], Avg Val Loss: 2.4234\n",
      "Validation loss improved from 2.4238 to 2.4234. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1354\n",
      "Epoch [451/2000], Avg Train Loss: 4.1354\n",
      "Epoch [451/2000], Avg Val Loss: 2.4229\n",
      "Validation loss improved from 2.4234 to 2.4229. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1018\n",
      "Epoch [452/2000], Avg Train Loss: 4.1018\n",
      "Epoch [452/2000], Avg Val Loss: 2.4225\n",
      "Validation loss improved from 2.4229 to 2.4225. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0863\n",
      "Epoch [453/2000], Avg Train Loss: 4.0863\n",
      "Epoch [453/2000], Avg Val Loss: 2.4221\n",
      "Validation loss improved from 2.4225 to 2.4221. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1160\n",
      "Epoch [454/2000], Avg Train Loss: 4.1160\n",
      "Epoch [454/2000], Avg Val Loss: 2.4217\n",
      "Validation loss improved from 2.4221 to 2.4217. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1168\n",
      "Epoch [455/2000], Avg Train Loss: 4.1168\n",
      "Epoch [455/2000], Avg Val Loss: 2.4213\n",
      "Validation loss improved from 2.4217 to 2.4213. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0870\n",
      "Epoch [456/2000], Avg Train Loss: 4.0870\n",
      "Epoch [456/2000], Avg Val Loss: 2.4209\n",
      "Validation loss improved from 2.4213 to 2.4209. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1089\n",
      "Epoch [457/2000], Avg Train Loss: 4.1089\n",
      "Epoch [457/2000], Avg Val Loss: 2.4205\n",
      "Validation loss improved from 2.4209 to 2.4205. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1168\n",
      "Epoch [458/2000], Avg Train Loss: 4.1168\n",
      "Epoch [458/2000], Avg Val Loss: 2.4202\n",
      "Validation loss improved from 2.4205 to 2.4202. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0571\n",
      "Epoch [459/2000], Avg Train Loss: 4.0571\n",
      "Epoch [459/2000], Avg Val Loss: 2.4198\n",
      "Validation loss improved from 2.4202 to 2.4198. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0775\n",
      "Epoch [460/2000], Avg Train Loss: 4.0775\n",
      "Epoch [460/2000], Avg Val Loss: 2.4195\n",
      "Validation loss improved from 2.4198 to 2.4195. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0922\n",
      "Epoch [461/2000], Avg Train Loss: 4.0922\n",
      "Epoch [461/2000], Avg Val Loss: 2.4191\n",
      "Validation loss improved from 2.4195 to 2.4191. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0523\n",
      "Epoch [462/2000], Avg Train Loss: 4.0523\n",
      "Epoch [462/2000], Avg Val Loss: 2.4187\n",
      "Validation loss improved from 2.4191 to 2.4187. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0547\n",
      "Epoch [463/2000], Avg Train Loss: 4.0547\n",
      "Epoch [463/2000], Avg Val Loss: 2.4184\n",
      "Validation loss improved from 2.4187 to 2.4184. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1252\n",
      "Epoch [464/2000], Avg Train Loss: 4.1252\n",
      "Epoch [464/2000], Avg Val Loss: 2.4180\n",
      "Validation loss improved from 2.4184 to 2.4180. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0679\n",
      "Epoch [465/2000], Avg Train Loss: 4.0679\n",
      "Epoch [465/2000], Avg Val Loss: 2.4176\n",
      "Validation loss improved from 2.4180 to 2.4176. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0737\n",
      "Epoch [466/2000], Avg Train Loss: 4.0737\n",
      "Epoch [466/2000], Avg Val Loss: 2.4173\n",
      "Validation loss improved from 2.4176 to 2.4173. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0865\n",
      "Epoch [467/2000], Avg Train Loss: 4.0865\n",
      "Epoch [467/2000], Avg Val Loss: 2.4169\n",
      "Validation loss improved from 2.4173 to 2.4169. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0961\n",
      "Epoch [468/2000], Avg Train Loss: 4.0961\n",
      "Epoch [468/2000], Avg Val Loss: 2.4165\n",
      "Validation loss improved from 2.4169 to 2.4165. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0899\n",
      "Epoch [469/2000], Avg Train Loss: 4.0899\n",
      "Epoch [469/2000], Avg Val Loss: 2.4161\n",
      "Validation loss improved from 2.4165 to 2.4161. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0883\n",
      "Epoch [470/2000], Avg Train Loss: 4.0883\n",
      "Epoch [470/2000], Avg Val Loss: 2.4157\n",
      "Validation loss improved from 2.4161 to 2.4157. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0756\n",
      "Epoch [471/2000], Avg Train Loss: 4.0756\n",
      "Epoch [471/2000], Avg Val Loss: 2.4153\n",
      "Validation loss improved from 2.4157 to 2.4153. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0553\n",
      "Epoch [472/2000], Avg Train Loss: 4.0553\n",
      "Epoch [472/2000], Avg Val Loss: 2.4149\n",
      "Validation loss improved from 2.4153 to 2.4149. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1101\n",
      "Epoch [473/2000], Avg Train Loss: 4.1101\n",
      "Epoch [473/2000], Avg Val Loss: 2.4145\n",
      "Validation loss improved from 2.4149 to 2.4145. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0537\n",
      "Epoch [474/2000], Avg Train Loss: 4.0537\n",
      "Epoch [474/2000], Avg Val Loss: 2.4141\n",
      "Validation loss improved from 2.4145 to 2.4141. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0242\n",
      "Epoch [475/2000], Avg Train Loss: 4.0242\n",
      "Epoch [475/2000], Avg Val Loss: 2.4137\n",
      "Validation loss improved from 2.4141 to 2.4137. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0875\n",
      "Epoch [476/2000], Avg Train Loss: 4.0875\n",
      "Epoch [476/2000], Avg Val Loss: 2.4133\n",
      "Validation loss improved from 2.4137 to 2.4133. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0671\n",
      "Epoch [477/2000], Avg Train Loss: 4.0671\n",
      "Epoch [477/2000], Avg Val Loss: 2.4129\n",
      "Validation loss improved from 2.4133 to 2.4129. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0740\n",
      "Epoch [478/2000], Avg Train Loss: 4.0740\n",
      "Epoch [478/2000], Avg Val Loss: 2.4125\n",
      "Validation loss improved from 2.4129 to 2.4125. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0988\n",
      "Epoch [479/2000], Avg Train Loss: 4.0988\n",
      "Epoch [479/2000], Avg Val Loss: 2.4122\n",
      "Validation loss improved from 2.4125 to 2.4122. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0896\n",
      "Epoch [480/2000], Avg Train Loss: 4.0896\n",
      "Epoch [480/2000], Avg Val Loss: 2.4118\n",
      "Validation loss improved from 2.4122 to 2.4118. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0463\n",
      "Epoch [481/2000], Avg Train Loss: 4.0463\n",
      "Epoch [481/2000], Avg Val Loss: 2.4115\n",
      "Validation loss improved from 2.4118 to 2.4115. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0587\n",
      "Epoch [482/2000], Avg Train Loss: 4.0587\n",
      "Epoch [482/2000], Avg Val Loss: 2.4112\n",
      "Validation loss improved from 2.4115 to 2.4112. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0664\n",
      "Epoch [483/2000], Avg Train Loss: 4.0664\n",
      "Epoch [483/2000], Avg Val Loss: 2.4110\n",
      "Validation loss improved from 2.4112 to 2.4110. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0811\n",
      "Epoch [484/2000], Avg Train Loss: 4.0811\n",
      "Epoch [484/2000], Avg Val Loss: 2.4107\n",
      "Validation loss improved from 2.4110 to 2.4107. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0637\n",
      "Epoch [485/2000], Avg Train Loss: 4.0637\n",
      "Epoch [485/2000], Avg Val Loss: 2.4104\n",
      "Validation loss improved from 2.4107 to 2.4104. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0921\n",
      "Epoch [486/2000], Avg Train Loss: 4.0921\n",
      "Epoch [486/2000], Avg Val Loss: 2.4102\n",
      "Validation loss improved from 2.4104 to 2.4102. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0458\n",
      "Epoch [487/2000], Avg Train Loss: 4.0458\n",
      "Epoch [487/2000], Avg Val Loss: 2.4099\n",
      "Validation loss improved from 2.4102 to 2.4099. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0427\n",
      "Epoch [488/2000], Avg Train Loss: 4.0427\n",
      "Epoch [488/2000], Avg Val Loss: 2.4096\n",
      "Validation loss improved from 2.4099 to 2.4096. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0504\n",
      "Epoch [489/2000], Avg Train Loss: 4.0504\n",
      "Epoch [489/2000], Avg Val Loss: 2.4093\n",
      "Validation loss improved from 2.4096 to 2.4093. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0611\n",
      "Epoch [490/2000], Avg Train Loss: 4.0611\n",
      "Epoch [490/2000], Avg Val Loss: 2.4091\n",
      "Validation loss improved from 2.4093 to 2.4091. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0258\n",
      "Epoch [491/2000], Avg Train Loss: 4.0258\n",
      "Epoch [491/2000], Avg Val Loss: 2.4088\n",
      "Validation loss improved from 2.4091 to 2.4088. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0540\n",
      "Epoch [492/2000], Avg Train Loss: 4.0540\n",
      "Epoch [492/2000], Avg Val Loss: 2.4085\n",
      "Validation loss improved from 2.4088 to 2.4085. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0474\n",
      "Epoch [493/2000], Avg Train Loss: 4.0474\n",
      "Epoch [493/2000], Avg Val Loss: 2.4083\n",
      "Validation loss improved from 2.4085 to 2.4083. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0667\n",
      "Epoch [494/2000], Avg Train Loss: 4.0667\n",
      "Epoch [494/2000], Avg Val Loss: 2.4080\n",
      "Validation loss improved from 2.4083 to 2.4080. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0624\n",
      "Epoch [495/2000], Avg Train Loss: 4.0624\n",
      "Epoch [495/2000], Avg Val Loss: 2.4077\n",
      "Validation loss improved from 2.4080 to 2.4077. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0437\n",
      "Epoch [496/2000], Avg Train Loss: 4.0437\n",
      "Epoch [496/2000], Avg Val Loss: 2.4074\n",
      "Validation loss improved from 2.4077 to 2.4074. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0272\n",
      "Epoch [497/2000], Avg Train Loss: 4.0272\n",
      "Epoch [497/2000], Avg Val Loss: 2.4071\n",
      "Validation loss improved from 2.4074 to 2.4071. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0158\n",
      "Epoch [498/2000], Avg Train Loss: 4.0158\n",
      "Epoch [498/2000], Avg Val Loss: 2.4068\n",
      "Validation loss improved from 2.4071 to 2.4068. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0474\n",
      "Epoch [499/2000], Avg Train Loss: 4.0474\n",
      "Epoch [499/2000], Avg Val Loss: 2.4065\n",
      "Validation loss improved from 2.4068 to 2.4065. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0633\n",
      "Epoch [500/2000], Avg Train Loss: 4.0633\n",
      "Epoch [500/2000], Avg Val Loss: 2.4061\n",
      "Validation loss improved from 2.4065 to 2.4061. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0962\n",
      "Epoch [501/2000], Avg Train Loss: 4.0962\n",
      "Epoch [501/2000], Avg Val Loss: 2.4058\n",
      "Validation loss improved from 2.4061 to 2.4058. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0467\n",
      "Epoch [502/2000], Avg Train Loss: 4.0467\n",
      "Epoch [502/2000], Avg Val Loss: 2.4055\n",
      "Validation loss improved from 2.4058 to 2.4055. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0471\n",
      "Epoch [503/2000], Avg Train Loss: 4.0471\n",
      "Epoch [503/2000], Avg Val Loss: 2.4052\n",
      "Validation loss improved from 2.4055 to 2.4052. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0279\n",
      "Epoch [504/2000], Avg Train Loss: 4.0279\n",
      "Epoch [504/2000], Avg Val Loss: 2.4050\n",
      "Validation loss improved from 2.4052 to 2.4050. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0372\n",
      "Epoch [505/2000], Avg Train Loss: 4.0372\n",
      "Epoch [505/2000], Avg Val Loss: 2.4047\n",
      "Validation loss improved from 2.4050 to 2.4047. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0539\n",
      "Epoch [506/2000], Avg Train Loss: 4.0539\n",
      "Epoch [506/2000], Avg Val Loss: 2.4045\n",
      "Validation loss improved from 2.4047 to 2.4045. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0252\n",
      "Epoch [507/2000], Avg Train Loss: 4.0252\n",
      "Epoch [507/2000], Avg Val Loss: 2.4042\n",
      "Validation loss improved from 2.4045 to 2.4042. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0219\n",
      "Epoch [508/2000], Avg Train Loss: 4.0219\n",
      "Epoch [508/2000], Avg Val Loss: 2.4040\n",
      "Validation loss improved from 2.4042 to 2.4040. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0404\n",
      "Epoch [509/2000], Avg Train Loss: 4.0404\n",
      "Epoch [509/2000], Avg Val Loss: 2.4038\n",
      "Validation loss improved from 2.4040 to 2.4038. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0302\n",
      "Epoch [510/2000], Avg Train Loss: 4.0302\n",
      "Epoch [510/2000], Avg Val Loss: 2.4036\n",
      "Validation loss improved from 2.4038 to 2.4036. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0117\n",
      "Epoch [511/2000], Avg Train Loss: 4.0117\n",
      "Epoch [511/2000], Avg Val Loss: 2.4033\n",
      "Validation loss improved from 2.4036 to 2.4033. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0407\n",
      "Epoch [512/2000], Avg Train Loss: 4.0407\n",
      "Epoch [512/2000], Avg Val Loss: 2.4031\n",
      "Validation loss improved from 2.4033 to 2.4031. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0331\n",
      "Epoch [513/2000], Avg Train Loss: 4.0331\n",
      "Epoch [513/2000], Avg Val Loss: 2.4028\n",
      "Validation loss improved from 2.4031 to 2.4028. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0166\n",
      "Epoch [514/2000], Avg Train Loss: 4.0166\n",
      "Epoch [514/2000], Avg Val Loss: 2.4025\n",
      "Validation loss improved from 2.4028 to 2.4025. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0488\n",
      "Epoch [515/2000], Avg Train Loss: 4.0488\n",
      "Epoch [515/2000], Avg Val Loss: 2.4023\n",
      "Validation loss improved from 2.4025 to 2.4023. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0040\n",
      "Epoch [516/2000], Avg Train Loss: 4.0040\n",
      "Epoch [516/2000], Avg Val Loss: 2.4021\n",
      "Validation loss improved from 2.4023 to 2.4021. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0430\n",
      "Epoch [517/2000], Avg Train Loss: 4.0430\n",
      "Epoch [517/2000], Avg Val Loss: 2.4018\n",
      "Validation loss improved from 2.4021 to 2.4018. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0178\n",
      "Epoch [518/2000], Avg Train Loss: 4.0178\n",
      "Epoch [518/2000], Avg Val Loss: 2.4016\n",
      "Validation loss improved from 2.4018 to 2.4016. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0167\n",
      "Epoch [519/2000], Avg Train Loss: 4.0167\n",
      "Epoch [519/2000], Avg Val Loss: 2.4013\n",
      "Validation loss improved from 2.4016 to 2.4013. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0419\n",
      "Epoch [520/2000], Avg Train Loss: 4.0419\n",
      "Epoch [520/2000], Avg Val Loss: 2.4010\n",
      "Validation loss improved from 2.4013 to 2.4010. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0432\n",
      "Epoch [521/2000], Avg Train Loss: 4.0432\n",
      "Epoch [521/2000], Avg Val Loss: 2.4008\n",
      "Validation loss improved from 2.4010 to 2.4008. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0171\n",
      "Epoch [522/2000], Avg Train Loss: 4.0171\n",
      "Epoch [522/2000], Avg Val Loss: 2.4005\n",
      "Validation loss improved from 2.4008 to 2.4005. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0238\n",
      "Epoch [523/2000], Avg Train Loss: 4.0238\n",
      "Epoch [523/2000], Avg Val Loss: 2.4002\n",
      "Validation loss improved from 2.4005 to 2.4002. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0183\n",
      "Epoch [524/2000], Avg Train Loss: 4.0183\n",
      "Epoch [524/2000], Avg Val Loss: 2.3999\n",
      "Validation loss improved from 2.4002 to 2.3999. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0599\n",
      "Epoch [525/2000], Avg Train Loss: 4.0599\n",
      "Epoch [525/2000], Avg Val Loss: 2.3996\n",
      "Validation loss improved from 2.3999 to 2.3996. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0018\n",
      "Epoch [526/2000], Avg Train Loss: 4.0018\n",
      "Epoch [526/2000], Avg Val Loss: 2.3993\n",
      "Validation loss improved from 2.3996 to 2.3993. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0540\n",
      "Epoch [527/2000], Avg Train Loss: 4.0540\n",
      "Epoch [527/2000], Avg Val Loss: 2.3990\n",
      "Validation loss improved from 2.3993 to 2.3990. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0260\n",
      "Epoch [528/2000], Avg Train Loss: 4.0260\n",
      "Epoch [528/2000], Avg Val Loss: 2.3987\n",
      "Validation loss improved from 2.3990 to 2.3987. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0143\n",
      "Epoch [529/2000], Avg Train Loss: 4.0143\n",
      "Epoch [529/2000], Avg Val Loss: 2.3984\n",
      "Validation loss improved from 2.3987 to 2.3984. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0291\n",
      "Epoch [530/2000], Avg Train Loss: 4.0291\n",
      "Epoch [530/2000], Avg Val Loss: 2.3981\n",
      "Validation loss improved from 2.3984 to 2.3981. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0359\n",
      "Epoch [531/2000], Avg Train Loss: 4.0359\n",
      "Epoch [531/2000], Avg Val Loss: 2.3978\n",
      "Validation loss improved from 2.3981 to 2.3978. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0784\n",
      "Epoch [532/2000], Avg Train Loss: 4.0784\n",
      "Epoch [532/2000], Avg Val Loss: 2.3976\n",
      "Validation loss improved from 2.3978 to 2.3976. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0226\n",
      "Epoch [533/2000], Avg Train Loss: 4.0226\n",
      "Epoch [533/2000], Avg Val Loss: 2.3973\n",
      "Validation loss improved from 2.3976 to 2.3973. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0658\n",
      "Epoch [534/2000], Avg Train Loss: 4.0658\n",
      "Epoch [534/2000], Avg Val Loss: 2.3971\n",
      "Validation loss improved from 2.3973 to 2.3971. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9853\n",
      "Epoch [535/2000], Avg Train Loss: 3.9853\n",
      "Epoch [535/2000], Avg Val Loss: 2.3969\n",
      "Validation loss improved from 2.3971 to 2.3969. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0441\n",
      "Epoch [536/2000], Avg Train Loss: 4.0441\n",
      "Epoch [536/2000], Avg Val Loss: 2.3967\n",
      "Validation loss improved from 2.3969 to 2.3967. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0245\n",
      "Epoch [537/2000], Avg Train Loss: 4.0245\n",
      "Epoch [537/2000], Avg Val Loss: 2.3965\n",
      "Validation loss improved from 2.3967 to 2.3965. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0252\n",
      "Epoch [538/2000], Avg Train Loss: 4.0252\n",
      "Epoch [538/2000], Avg Val Loss: 2.3964\n",
      "Validation loss improved from 2.3965 to 2.3964. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0324\n",
      "Epoch [539/2000], Avg Train Loss: 4.0324\n",
      "Epoch [539/2000], Avg Val Loss: 2.3962\n",
      "Validation loss improved from 2.3964 to 2.3962. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0319\n",
      "Epoch [540/2000], Avg Train Loss: 4.0319\n",
      "Epoch [540/2000], Avg Val Loss: 2.3960\n",
      "Validation loss improved from 2.3962 to 2.3960. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9732\n",
      "Epoch [541/2000], Avg Train Loss: 3.9732\n",
      "Epoch [541/2000], Avg Val Loss: 2.3958\n",
      "Validation loss improved from 2.3960 to 2.3958. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0187\n",
      "Epoch [542/2000], Avg Train Loss: 4.0187\n",
      "Epoch [542/2000], Avg Val Loss: 2.3956\n",
      "Validation loss improved from 2.3958 to 2.3956. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0072\n",
      "Epoch [543/2000], Avg Train Loss: 4.0072\n",
      "Epoch [543/2000], Avg Val Loss: 2.3954\n",
      "Validation loss improved from 2.3956 to 2.3954. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0053\n",
      "Epoch [544/2000], Avg Train Loss: 4.0053\n",
      "Epoch [544/2000], Avg Val Loss: 2.3952\n",
      "Validation loss improved from 2.3954 to 2.3952. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0221\n",
      "Epoch [545/2000], Avg Train Loss: 4.0221\n",
      "Epoch [545/2000], Avg Val Loss: 2.3949\n",
      "Validation loss improved from 2.3952 to 2.3949. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0178\n",
      "Epoch [546/2000], Avg Train Loss: 4.0178\n",
      "Epoch [546/2000], Avg Val Loss: 2.3947\n",
      "Validation loss improved from 2.3949 to 2.3947. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9941\n",
      "Epoch [547/2000], Avg Train Loss: 3.9941\n",
      "Epoch [547/2000], Avg Val Loss: 2.3944\n",
      "Validation loss improved from 2.3947 to 2.3944. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9856\n",
      "Epoch [548/2000], Avg Train Loss: 3.9856\n",
      "Epoch [548/2000], Avg Val Loss: 2.3942\n",
      "Validation loss improved from 2.3944 to 2.3942. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0098\n",
      "Epoch [549/2000], Avg Train Loss: 4.0098\n",
      "Epoch [549/2000], Avg Val Loss: 2.3940\n",
      "Validation loss improved from 2.3942 to 2.3940. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0109\n",
      "Epoch [550/2000], Avg Train Loss: 4.0109\n",
      "Epoch [550/2000], Avg Val Loss: 2.3938\n",
      "Validation loss improved from 2.3940 to 2.3938. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0021\n",
      "Epoch [551/2000], Avg Train Loss: 4.0021\n",
      "Epoch [551/2000], Avg Val Loss: 2.3935\n",
      "Validation loss improved from 2.3938 to 2.3935. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0035\n",
      "Epoch [552/2000], Avg Train Loss: 4.0035\n",
      "Epoch [552/2000], Avg Val Loss: 2.3933\n",
      "Validation loss improved from 2.3935 to 2.3933. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0109\n",
      "Epoch [553/2000], Avg Train Loss: 4.0109\n",
      "Epoch [553/2000], Avg Val Loss: 2.3930\n",
      "Validation loss improved from 2.3933 to 2.3930. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9777\n",
      "Epoch [554/2000], Avg Train Loss: 3.9777\n",
      "Epoch [554/2000], Avg Val Loss: 2.3927\n",
      "Validation loss improved from 2.3930 to 2.3927. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0121\n",
      "Epoch [555/2000], Avg Train Loss: 4.0121\n",
      "Epoch [555/2000], Avg Val Loss: 2.3924\n",
      "Validation loss improved from 2.3927 to 2.3924. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0021\n",
      "Epoch [556/2000], Avg Train Loss: 4.0021\n",
      "Epoch [556/2000], Avg Val Loss: 2.3921\n",
      "Validation loss improved from 2.3924 to 2.3921. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9912\n",
      "Epoch [557/2000], Avg Train Loss: 3.9912\n",
      "Epoch [557/2000], Avg Val Loss: 2.3918\n",
      "Validation loss improved from 2.3921 to 2.3918. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9781\n",
      "Epoch [558/2000], Avg Train Loss: 3.9781\n",
      "Epoch [558/2000], Avg Val Loss: 2.3915\n",
      "Validation loss improved from 2.3918 to 2.3915. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0075\n",
      "Epoch [559/2000], Avg Train Loss: 4.0075\n",
      "Epoch [559/2000], Avg Val Loss: 2.3912\n",
      "Validation loss improved from 2.3915 to 2.3912. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9986\n",
      "Epoch [560/2000], Avg Train Loss: 3.9986\n",
      "Epoch [560/2000], Avg Val Loss: 2.3910\n",
      "Validation loss improved from 2.3912 to 2.3910. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0007\n",
      "Epoch [561/2000], Avg Train Loss: 4.0007\n",
      "Epoch [561/2000], Avg Val Loss: 2.3907\n",
      "Validation loss improved from 2.3910 to 2.3907. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0309\n",
      "Epoch [562/2000], Avg Train Loss: 4.0309\n",
      "Epoch [562/2000], Avg Val Loss: 2.3904\n",
      "Validation loss improved from 2.3907 to 2.3904. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9978\n",
      "Epoch [563/2000], Avg Train Loss: 3.9978\n",
      "Epoch [563/2000], Avg Val Loss: 2.3901\n",
      "Validation loss improved from 2.3904 to 2.3901. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9716\n",
      "Epoch [564/2000], Avg Train Loss: 3.9716\n",
      "Epoch [564/2000], Avg Val Loss: 2.3899\n",
      "Validation loss improved from 2.3901 to 2.3899. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9932\n",
      "Epoch [565/2000], Avg Train Loss: 3.9932\n",
      "Epoch [565/2000], Avg Val Loss: 2.3897\n",
      "Validation loss improved from 2.3899 to 2.3897. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0025\n",
      "Epoch [566/2000], Avg Train Loss: 4.0025\n",
      "Epoch [566/2000], Avg Val Loss: 2.3894\n",
      "Validation loss improved from 2.3897 to 2.3894. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0133\n",
      "Epoch [567/2000], Avg Train Loss: 4.0133\n",
      "Epoch [567/2000], Avg Val Loss: 2.3892\n",
      "Validation loss improved from 2.3894 to 2.3892. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0110\n",
      "Epoch [568/2000], Avg Train Loss: 4.0110\n",
      "Epoch [568/2000], Avg Val Loss: 2.3889\n",
      "Validation loss improved from 2.3892 to 2.3889. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0024\n",
      "Epoch [569/2000], Avg Train Loss: 4.0024\n",
      "Epoch [569/2000], Avg Val Loss: 2.3886\n",
      "Validation loss improved from 2.3889 to 2.3886. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0218\n",
      "Epoch [570/2000], Avg Train Loss: 4.0218\n",
      "Epoch [570/2000], Avg Val Loss: 2.3884\n",
      "Validation loss improved from 2.3886 to 2.3884. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9673\n",
      "Epoch [571/2000], Avg Train Loss: 3.9673\n",
      "Epoch [571/2000], Avg Val Loss: 2.3881\n",
      "Validation loss improved from 2.3884 to 2.3881. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0105\n",
      "Epoch [572/2000], Avg Train Loss: 4.0105\n",
      "Epoch [572/2000], Avg Val Loss: 2.3878\n",
      "Validation loss improved from 2.3881 to 2.3878. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9664\n",
      "Epoch [573/2000], Avg Train Loss: 3.9664\n",
      "Epoch [573/2000], Avg Val Loss: 2.3874\n",
      "Validation loss improved from 2.3878 to 2.3874. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9995\n",
      "Epoch [574/2000], Avg Train Loss: 3.9995\n",
      "Epoch [574/2000], Avg Val Loss: 2.3871\n",
      "Validation loss improved from 2.3874 to 2.3871. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9920\n",
      "Epoch [575/2000], Avg Train Loss: 3.9920\n",
      "Epoch [575/2000], Avg Val Loss: 2.3867\n",
      "Validation loss improved from 2.3871 to 2.3867. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0103\n",
      "Epoch [576/2000], Avg Train Loss: 4.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [576/2000], Avg Val Loss: 2.3864\n",
      "Validation loss improved from 2.3867 to 2.3864. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9738\n",
      "Epoch [577/2000], Avg Train Loss: 3.9738\n",
      "Epoch [577/2000], Avg Val Loss: 2.3860\n",
      "Validation loss improved from 2.3864 to 2.3860. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0002\n",
      "Epoch [578/2000], Avg Train Loss: 4.0002\n",
      "Epoch [578/2000], Avg Val Loss: 2.3857\n",
      "Validation loss improved from 2.3860 to 2.3857. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9941\n",
      "Epoch [579/2000], Avg Train Loss: 3.9941\n",
      "Epoch [579/2000], Avg Val Loss: 2.3854\n",
      "Validation loss improved from 2.3857 to 2.3854. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9900\n",
      "Epoch [580/2000], Avg Train Loss: 3.9900\n",
      "Epoch [580/2000], Avg Val Loss: 2.3850\n",
      "Validation loss improved from 2.3854 to 2.3850. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9841\n",
      "Epoch [581/2000], Avg Train Loss: 3.9841\n",
      "Epoch [581/2000], Avg Val Loss: 2.3847\n",
      "Validation loss improved from 2.3850 to 2.3847. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9890\n",
      "Epoch [582/2000], Avg Train Loss: 3.9890\n",
      "Epoch [582/2000], Avg Val Loss: 2.3843\n",
      "Validation loss improved from 2.3847 to 2.3843. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9894\n",
      "Epoch [583/2000], Avg Train Loss: 3.9894\n",
      "Epoch [583/2000], Avg Val Loss: 2.3840\n",
      "Validation loss improved from 2.3843 to 2.3840. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9956\n",
      "Epoch [584/2000], Avg Train Loss: 3.9956\n",
      "Epoch [584/2000], Avg Val Loss: 2.3836\n",
      "Validation loss improved from 2.3840 to 2.3836. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9551\n",
      "Epoch [585/2000], Avg Train Loss: 3.9551\n",
      "Epoch [585/2000], Avg Val Loss: 2.3832\n",
      "Validation loss improved from 2.3836 to 2.3832. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9750\n",
      "Epoch [586/2000], Avg Train Loss: 3.9750\n",
      "Epoch [586/2000], Avg Val Loss: 2.3829\n",
      "Validation loss improved from 2.3832 to 2.3829. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0084\n",
      "Epoch [587/2000], Avg Train Loss: 4.0084\n",
      "Epoch [587/2000], Avg Val Loss: 2.3826\n",
      "Validation loss improved from 2.3829 to 2.3826. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9875\n",
      "Epoch [588/2000], Avg Train Loss: 3.9875\n",
      "Epoch [588/2000], Avg Val Loss: 2.3823\n",
      "Validation loss improved from 2.3826 to 2.3823. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0022\n",
      "Epoch [589/2000], Avg Train Loss: 4.0022\n",
      "Epoch [589/2000], Avg Val Loss: 2.3820\n",
      "Validation loss improved from 2.3823 to 2.3820. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9923\n",
      "Epoch [590/2000], Avg Train Loss: 3.9923\n",
      "Epoch [590/2000], Avg Val Loss: 2.3817\n",
      "Validation loss improved from 2.3820 to 2.3817. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0133\n",
      "Epoch [591/2000], Avg Train Loss: 4.0133\n",
      "Epoch [591/2000], Avg Val Loss: 2.3814\n",
      "Validation loss improved from 2.3817 to 2.3814. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9491\n",
      "Epoch [592/2000], Avg Train Loss: 3.9491\n",
      "Epoch [592/2000], Avg Val Loss: 2.3811\n",
      "Validation loss improved from 2.3814 to 2.3811. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9679\n",
      "Epoch [593/2000], Avg Train Loss: 3.9679\n",
      "Epoch [593/2000], Avg Val Loss: 2.3809\n",
      "Validation loss improved from 2.3811 to 2.3809. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9801\n",
      "Epoch [594/2000], Avg Train Loss: 3.9801\n",
      "Epoch [594/2000], Avg Val Loss: 2.3807\n",
      "Validation loss improved from 2.3809 to 2.3807. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9720\n",
      "Epoch [595/2000], Avg Train Loss: 3.9720\n",
      "Epoch [595/2000], Avg Val Loss: 2.3804\n",
      "Validation loss improved from 2.3807 to 2.3804. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0038\n",
      "Epoch [596/2000], Avg Train Loss: 4.0038\n",
      "Epoch [596/2000], Avg Val Loss: 2.3802\n",
      "Validation loss improved from 2.3804 to 2.3802. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9718\n",
      "Epoch [597/2000], Avg Train Loss: 3.9718\n",
      "Epoch [597/2000], Avg Val Loss: 2.3800\n",
      "Validation loss improved from 2.3802 to 2.3800. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9650\n",
      "Epoch [598/2000], Avg Train Loss: 3.9650\n",
      "Epoch [598/2000], Avg Val Loss: 2.3797\n",
      "Validation loss improved from 2.3800 to 2.3797. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0030\n",
      "Epoch [599/2000], Avg Train Loss: 4.0030\n",
      "Epoch [599/2000], Avg Val Loss: 2.3795\n",
      "Validation loss improved from 2.3797 to 2.3795. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9648\n",
      "Epoch [600/2000], Avg Train Loss: 3.9648\n",
      "Epoch [600/2000], Avg Val Loss: 2.3794\n",
      "Validation loss improved from 2.3795 to 2.3794. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9468\n",
      "Epoch [601/2000], Avg Train Loss: 3.9468\n",
      "Epoch [601/2000], Avg Val Loss: 2.3792\n",
      "Validation loss improved from 2.3794 to 2.3792. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9741\n",
      "Epoch [602/2000], Avg Train Loss: 3.9741\n",
      "Epoch [602/2000], Avg Val Loss: 2.3791\n",
      "Validation loss improved from 2.3792 to 2.3791. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9670\n",
      "Epoch [603/2000], Avg Train Loss: 3.9670\n",
      "Epoch [603/2000], Avg Val Loss: 2.3789\n",
      "Validation loss improved from 2.3791 to 2.3789. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9650\n",
      "Epoch [604/2000], Avg Train Loss: 3.9650\n",
      "Epoch [604/2000], Avg Val Loss: 2.3787\n",
      "Validation loss improved from 2.3789 to 2.3787. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9488\n",
      "Epoch [605/2000], Avg Train Loss: 3.9488\n",
      "Epoch [605/2000], Avg Val Loss: 2.3786\n",
      "Validation loss improved from 2.3787 to 2.3786. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9190\n",
      "Epoch [606/2000], Avg Train Loss: 3.9190\n",
      "Epoch [606/2000], Avg Val Loss: 2.3783\n",
      "Validation loss improved from 2.3786 to 2.3783. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9636\n",
      "Epoch [607/2000], Avg Train Loss: 3.9636\n",
      "Epoch [607/2000], Avg Val Loss: 2.3781\n",
      "Validation loss improved from 2.3783 to 2.3781. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9436\n",
      "Epoch [608/2000], Avg Train Loss: 3.9436\n",
      "Epoch [608/2000], Avg Val Loss: 2.3778\n",
      "Validation loss improved from 2.3781 to 2.3778. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9730\n",
      "Epoch [609/2000], Avg Train Loss: 3.9730\n",
      "Epoch [609/2000], Avg Val Loss: 2.3776\n",
      "Validation loss improved from 2.3778 to 2.3776. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9192\n",
      "Epoch [610/2000], Avg Train Loss: 3.9192\n",
      "Epoch [610/2000], Avg Val Loss: 2.3774\n",
      "Validation loss improved from 2.3776 to 2.3774. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9482\n",
      "Epoch [611/2000], Avg Train Loss: 3.9482\n",
      "Epoch [611/2000], Avg Val Loss: 2.3772\n",
      "Validation loss improved from 2.3774 to 2.3772. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9532\n",
      "Epoch [612/2000], Avg Train Loss: 3.9532\n",
      "Epoch [612/2000], Avg Val Loss: 2.3769\n",
      "Validation loss improved from 2.3772 to 2.3769. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9288\n",
      "Epoch [613/2000], Avg Train Loss: 3.9288\n",
      "Epoch [613/2000], Avg Val Loss: 2.3767\n",
      "Validation loss improved from 2.3769 to 2.3767. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9589\n",
      "Epoch [614/2000], Avg Train Loss: 3.9589\n",
      "Epoch [614/2000], Avg Val Loss: 2.3765\n",
      "Validation loss improved from 2.3767 to 2.3765. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9738\n",
      "Epoch [615/2000], Avg Train Loss: 3.9738\n",
      "Epoch [615/2000], Avg Val Loss: 2.3763\n",
      "Validation loss improved from 2.3765 to 2.3763. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9593\n",
      "Epoch [616/2000], Avg Train Loss: 3.9593\n",
      "Epoch [616/2000], Avg Val Loss: 2.3761\n",
      "Validation loss improved from 2.3763 to 2.3761. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9581\n",
      "Epoch [617/2000], Avg Train Loss: 3.9581\n",
      "Epoch [617/2000], Avg Val Loss: 2.3758\n",
      "Validation loss improved from 2.3761 to 2.3758. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9267\n",
      "Epoch [618/2000], Avg Train Loss: 3.9267\n",
      "Epoch [618/2000], Avg Val Loss: 2.3756\n",
      "Validation loss improved from 2.3758 to 2.3756. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9752\n",
      "Epoch [619/2000], Avg Train Loss: 3.9752\n",
      "Epoch [619/2000], Avg Val Loss: 2.3753\n",
      "Validation loss improved from 2.3756 to 2.3753. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9429\n",
      "Epoch [620/2000], Avg Train Loss: 3.9429\n",
      "Epoch [620/2000], Avg Val Loss: 2.3750\n",
      "Validation loss improved from 2.3753 to 2.3750. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9486\n",
      "Epoch [621/2000], Avg Train Loss: 3.9486\n",
      "Epoch [621/2000], Avg Val Loss: 2.3748\n",
      "Validation loss improved from 2.3750 to 2.3748. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9666\n",
      "Epoch [622/2000], Avg Train Loss: 3.9666\n",
      "Epoch [622/2000], Avg Val Loss: 2.3745\n",
      "Validation loss improved from 2.3748 to 2.3745. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9560\n",
      "Epoch [623/2000], Avg Train Loss: 3.9560\n",
      "Epoch [623/2000], Avg Val Loss: 2.3742\n",
      "Validation loss improved from 2.3745 to 2.3742. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9249\n",
      "Epoch [624/2000], Avg Train Loss: 3.9249\n",
      "Epoch [624/2000], Avg Val Loss: 2.3739\n",
      "Validation loss improved from 2.3742 to 2.3739. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9715\n",
      "Epoch [625/2000], Avg Train Loss: 3.9715\n",
      "Epoch [625/2000], Avg Val Loss: 2.3735\n",
      "Validation loss improved from 2.3739 to 2.3735. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9835\n",
      "Epoch [626/2000], Avg Train Loss: 3.9835\n",
      "Epoch [626/2000], Avg Val Loss: 2.3732\n",
      "Validation loss improved from 2.3735 to 2.3732. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8883\n",
      "Epoch [627/2000], Avg Train Loss: 3.8883\n",
      "Epoch [627/2000], Avg Val Loss: 2.3729\n",
      "Validation loss improved from 2.3732 to 2.3729. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9430\n",
      "Epoch [628/2000], Avg Train Loss: 3.9430\n",
      "Epoch [628/2000], Avg Val Loss: 2.3727\n",
      "Validation loss improved from 2.3729 to 2.3727. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9835\n",
      "Epoch [629/2000], Avg Train Loss: 3.9835\n",
      "Epoch [629/2000], Avg Val Loss: 2.3724\n",
      "Validation loss improved from 2.3727 to 2.3724. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9740\n",
      "Epoch [630/2000], Avg Train Loss: 3.9740\n",
      "Epoch [630/2000], Avg Val Loss: 2.3722\n",
      "Validation loss improved from 2.3724 to 2.3722. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9646\n",
      "Epoch [631/2000], Avg Train Loss: 3.9646\n",
      "Epoch [631/2000], Avg Val Loss: 2.3719\n",
      "Validation loss improved from 2.3722 to 2.3719. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9333\n",
      "Epoch [632/2000], Avg Train Loss: 3.9333\n",
      "Epoch [632/2000], Avg Val Loss: 2.3716\n",
      "Validation loss improved from 2.3719 to 2.3716. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9332\n",
      "Epoch [633/2000], Avg Train Loss: 3.9332\n",
      "Epoch [633/2000], Avg Val Loss: 2.3713\n",
      "Validation loss improved from 2.3716 to 2.3713. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9645\n",
      "Epoch [634/2000], Avg Train Loss: 3.9645\n",
      "Epoch [634/2000], Avg Val Loss: 2.3710\n",
      "Validation loss improved from 2.3713 to 2.3710. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9488\n",
      "Epoch [635/2000], Avg Train Loss: 3.9488\n",
      "Epoch [635/2000], Avg Val Loss: 2.3707\n",
      "Validation loss improved from 2.3710 to 2.3707. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9303\n",
      "Epoch [636/2000], Avg Train Loss: 3.9303\n",
      "Epoch [636/2000], Avg Val Loss: 2.3705\n",
      "Validation loss improved from 2.3707 to 2.3705. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9629\n",
      "Epoch [637/2000], Avg Train Loss: 3.9629\n",
      "Epoch [637/2000], Avg Val Loss: 2.3702\n",
      "Validation loss improved from 2.3705 to 2.3702. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9834\n",
      "Epoch [638/2000], Avg Train Loss: 3.9834\n",
      "Epoch [638/2000], Avg Val Loss: 2.3700\n",
      "Validation loss improved from 2.3702 to 2.3700. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9578\n",
      "Epoch [639/2000], Avg Train Loss: 3.9578\n",
      "Epoch [639/2000], Avg Val Loss: 2.3698\n",
      "Validation loss improved from 2.3700 to 2.3698. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9452\n",
      "Epoch [640/2000], Avg Train Loss: 3.9452\n",
      "Epoch [640/2000], Avg Val Loss: 2.3695\n",
      "Validation loss improved from 2.3698 to 2.3695. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9334\n",
      "Epoch [641/2000], Avg Train Loss: 3.9334\n",
      "Epoch [641/2000], Avg Val Loss: 2.3693\n",
      "Validation loss improved from 2.3695 to 2.3693. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8985\n",
      "Epoch [642/2000], Avg Train Loss: 3.8985\n",
      "Epoch [642/2000], Avg Val Loss: 2.3690\n",
      "Validation loss improved from 2.3693 to 2.3690. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9403\n",
      "Epoch [643/2000], Avg Train Loss: 3.9403\n",
      "Epoch [643/2000], Avg Val Loss: 2.3688\n",
      "Validation loss improved from 2.3690 to 2.3688. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9525\n",
      "Epoch [644/2000], Avg Train Loss: 3.9525\n",
      "Epoch [644/2000], Avg Val Loss: 2.3686\n",
      "Validation loss improved from 2.3688 to 2.3686. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9392\n",
      "Epoch [645/2000], Avg Train Loss: 3.9392\n",
      "Epoch [645/2000], Avg Val Loss: 2.3683\n",
      "Validation loss improved from 2.3686 to 2.3683. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9175\n",
      "Epoch [646/2000], Avg Train Loss: 3.9175\n",
      "Epoch [646/2000], Avg Val Loss: 2.3680\n",
      "Validation loss improved from 2.3683 to 2.3680. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9332\n",
      "Epoch [647/2000], Avg Train Loss: 3.9332\n",
      "Epoch [647/2000], Avg Val Loss: 2.3678\n",
      "Validation loss improved from 2.3680 to 2.3678. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9224\n",
      "Epoch [648/2000], Avg Train Loss: 3.9224\n",
      "Epoch [648/2000], Avg Val Loss: 2.3675\n",
      "Validation loss improved from 2.3678 to 2.3675. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9337\n",
      "Epoch [649/2000], Avg Train Loss: 3.9337\n",
      "Epoch [649/2000], Avg Val Loss: 2.3672\n",
      "Validation loss improved from 2.3675 to 2.3672. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8961\n",
      "Epoch [650/2000], Avg Train Loss: 3.8961\n",
      "Epoch [650/2000], Avg Val Loss: 2.3669\n",
      "Validation loss improved from 2.3672 to 2.3669. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9363\n",
      "Epoch [651/2000], Avg Train Loss: 3.9363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [651/2000], Avg Val Loss: 2.3666\n",
      "Validation loss improved from 2.3669 to 2.3666. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9282\n",
      "Epoch [652/2000], Avg Train Loss: 3.9282\n",
      "Epoch [652/2000], Avg Val Loss: 2.3663\n",
      "Validation loss improved from 2.3666 to 2.3663. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9255\n",
      "Epoch [653/2000], Avg Train Loss: 3.9255\n",
      "Epoch [653/2000], Avg Val Loss: 2.3660\n",
      "Validation loss improved from 2.3663 to 2.3660. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9108\n",
      "Epoch [654/2000], Avg Train Loss: 3.9108\n",
      "Epoch [654/2000], Avg Val Loss: 2.3658\n",
      "Validation loss improved from 2.3660 to 2.3658. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9264\n",
      "Epoch [655/2000], Avg Train Loss: 3.9264\n",
      "Epoch [655/2000], Avg Val Loss: 2.3656\n",
      "Validation loss improved from 2.3658 to 2.3656. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9329\n",
      "Epoch [656/2000], Avg Train Loss: 3.9329\n",
      "Epoch [656/2000], Avg Val Loss: 2.3653\n",
      "Validation loss improved from 2.3656 to 2.3653. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9271\n",
      "Epoch [657/2000], Avg Train Loss: 3.9271\n",
      "Epoch [657/2000], Avg Val Loss: 2.3651\n",
      "Validation loss improved from 2.3653 to 2.3651. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9272\n",
      "Epoch [658/2000], Avg Train Loss: 3.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [658/2000], Avg Val Loss: 2.3649\n",
      "Validation loss improved from 2.3651 to 2.3649. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9729\n",
      "Epoch [659/2000], Avg Train Loss: 3.9729\n",
      "Epoch [659/2000], Avg Val Loss: 2.3646\n",
      "Validation loss improved from 2.3649 to 2.3646. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9401\n",
      "Epoch [660/2000], Avg Train Loss: 3.9401\n",
      "Epoch [660/2000], Avg Val Loss: 2.3644\n",
      "Validation loss improved from 2.3646 to 2.3644. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9153\n",
      "Epoch [661/2000], Avg Train Loss: 3.9153\n",
      "Epoch [661/2000], Avg Val Loss: 2.3642\n",
      "Validation loss improved from 2.3644 to 2.3642. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9397\n",
      "Epoch [662/2000], Avg Train Loss: 3.9397\n",
      "Epoch [662/2000], Avg Val Loss: 2.3640\n",
      "Validation loss improved from 2.3642 to 2.3640. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9184\n",
      "Epoch [663/2000], Avg Train Loss: 3.9184\n",
      "Epoch [663/2000], Avg Val Loss: 2.3638\n",
      "Validation loss improved from 2.3640 to 2.3638. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9131\n",
      "Epoch [664/2000], Avg Train Loss: 3.9131\n",
      "Epoch [664/2000], Avg Val Loss: 2.3636\n",
      "Validation loss improved from 2.3638 to 2.3636. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9535\n",
      "Epoch [665/2000], Avg Train Loss: 3.9535\n",
      "Epoch [665/2000], Avg Val Loss: 2.3635\n",
      "Validation loss improved from 2.3636 to 2.3635. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9209\n",
      "Epoch [666/2000], Avg Train Loss: 3.9209\n",
      "Epoch [666/2000], Avg Val Loss: 2.3633\n",
      "Validation loss improved from 2.3635 to 2.3633. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9255\n",
      "Epoch [667/2000], Avg Train Loss: 3.9255\n",
      "Epoch [667/2000], Avg Val Loss: 2.3631\n",
      "Validation loss improved from 2.3633 to 2.3631. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9243\n",
      "Epoch [668/2000], Avg Train Loss: 3.9243\n",
      "Epoch [668/2000], Avg Val Loss: 2.3629\n",
      "Validation loss improved from 2.3631 to 2.3629. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9189\n",
      "Epoch [669/2000], Avg Train Loss: 3.9189\n",
      "Epoch [669/2000], Avg Val Loss: 2.3626\n",
      "Validation loss improved from 2.3629 to 2.3626. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9301\n",
      "Epoch [670/2000], Avg Train Loss: 3.9301\n",
      "Epoch [670/2000], Avg Val Loss: 2.3624\n",
      "Validation loss improved from 2.3626 to 2.3624. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9401\n",
      "Epoch [671/2000], Avg Train Loss: 3.9401\n",
      "Epoch [671/2000], Avg Val Loss: 2.3621\n",
      "Validation loss improved from 2.3624 to 2.3621. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8976\n",
      "Epoch [672/2000], Avg Train Loss: 3.8976\n",
      "Epoch [672/2000], Avg Val Loss: 2.3619\n",
      "Validation loss improved from 2.3621 to 2.3619. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9127\n",
      "Epoch [673/2000], Avg Train Loss: 3.9127\n",
      "Epoch [673/2000], Avg Val Loss: 2.3616\n",
      "Validation loss improved from 2.3619 to 2.3616. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8861\n",
      "Epoch [674/2000], Avg Train Loss: 3.8861\n",
      "Epoch [674/2000], Avg Val Loss: 2.3614\n",
      "Validation loss improved from 2.3616 to 2.3614. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9204\n",
      "Epoch [675/2000], Avg Train Loss: 3.9204\n",
      "Epoch [675/2000], Avg Val Loss: 2.3611\n",
      "Validation loss improved from 2.3614 to 2.3611. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9273\n",
      "Epoch [676/2000], Avg Train Loss: 3.9273\n",
      "Epoch [676/2000], Avg Val Loss: 2.3609\n",
      "Validation loss improved from 2.3611 to 2.3609. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9630\n",
      "Epoch [677/2000], Avg Train Loss: 3.9630\n",
      "Epoch [677/2000], Avg Val Loss: 2.3606\n",
      "Validation loss improved from 2.3609 to 2.3606. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9077\n",
      "Epoch [678/2000], Avg Train Loss: 3.9077\n",
      "Epoch [678/2000], Avg Val Loss: 2.3603\n",
      "Validation loss improved from 2.3606 to 2.3603. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9438\n",
      "Epoch [679/2000], Avg Train Loss: 3.9438\n",
      "Epoch [679/2000], Avg Val Loss: 2.3600\n",
      "Validation loss improved from 2.3603 to 2.3600. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9394\n",
      "Epoch [680/2000], Avg Train Loss: 3.9394\n",
      "Epoch [680/2000], Avg Val Loss: 2.3598\n",
      "Validation loss improved from 2.3600 to 2.3598. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9318\n",
      "Epoch [681/2000], Avg Train Loss: 3.9318\n",
      "Epoch [681/2000], Avg Val Loss: 2.3595\n",
      "Validation loss improved from 2.3598 to 2.3595. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9108\n",
      "Epoch [682/2000], Avg Train Loss: 3.9108\n",
      "Epoch [682/2000], Avg Val Loss: 2.3593\n",
      "Validation loss improved from 2.3595 to 2.3593. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9106\n",
      "Epoch [683/2000], Avg Train Loss: 3.9106\n",
      "Epoch [683/2000], Avg Val Loss: 2.3591\n",
      "Validation loss improved from 2.3593 to 2.3591. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9219\n",
      "Epoch [684/2000], Avg Train Loss: 3.9219\n",
      "Epoch [684/2000], Avg Val Loss: 2.3590\n",
      "Validation loss improved from 2.3591 to 2.3590. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9386\n",
      "Epoch [685/2000], Avg Train Loss: 3.9386\n",
      "Epoch [685/2000], Avg Val Loss: 2.3588\n",
      "Validation loss improved from 2.3590 to 2.3588. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9405\n",
      "Epoch [686/2000], Avg Train Loss: 3.9405\n",
      "Epoch [686/2000], Avg Val Loss: 2.3587\n",
      "Validation loss improved from 2.3588 to 2.3587. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9192\n",
      "Epoch [687/2000], Avg Train Loss: 3.9192\n",
      "Epoch [687/2000], Avg Val Loss: 2.3586\n",
      "Validation loss improved from 2.3587 to 2.3586. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9325\n",
      "Epoch [688/2000], Avg Train Loss: 3.9325\n",
      "Epoch [688/2000], Avg Val Loss: 2.3585\n",
      "Validation loss improved from 2.3586 to 2.3585. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9154\n",
      "Epoch [689/2000], Avg Train Loss: 3.9154\n",
      "Epoch [689/2000], Avg Val Loss: 2.3584\n",
      "Validation loss improved from 2.3585 to 2.3584. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9107\n",
      "Epoch [690/2000], Avg Train Loss: 3.9107\n",
      "Epoch [690/2000], Avg Val Loss: 2.3582\n",
      "Validation loss improved from 2.3584 to 2.3582. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9122\n",
      "Epoch [691/2000], Avg Train Loss: 3.9122\n",
      "Epoch [691/2000], Avg Val Loss: 2.3580\n",
      "Validation loss improved from 2.3582 to 2.3580. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9118\n",
      "Epoch [692/2000], Avg Train Loss: 3.9118\n",
      "Epoch [692/2000], Avg Val Loss: 2.3577\n",
      "Validation loss improved from 2.3580 to 2.3577. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9410\n",
      "Epoch [693/2000], Avg Train Loss: 3.9410\n",
      "Epoch [693/2000], Avg Val Loss: 2.3574\n",
      "Validation loss improved from 2.3577 to 2.3574. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8945\n",
      "Epoch [694/2000], Avg Train Loss: 3.8945\n",
      "Epoch [694/2000], Avg Val Loss: 2.3571\n",
      "Validation loss improved from 2.3574 to 2.3571. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8951\n",
      "Epoch [695/2000], Avg Train Loss: 3.8951\n",
      "Epoch [695/2000], Avg Val Loss: 2.3569\n",
      "Validation loss improved from 2.3571 to 2.3569. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9297\n",
      "Epoch [696/2000], Avg Train Loss: 3.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [696/2000], Avg Val Loss: 2.3567\n",
      "Validation loss improved from 2.3569 to 2.3567. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9075\n",
      "Epoch [697/2000], Avg Train Loss: 3.9075\n",
      "Epoch [697/2000], Avg Val Loss: 2.3564\n",
      "Validation loss improved from 2.3567 to 2.3564. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8987\n",
      "Epoch [698/2000], Avg Train Loss: 3.8987\n",
      "Epoch [698/2000], Avg Val Loss: 2.3562\n",
      "Validation loss improved from 2.3564 to 2.3562. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9004\n",
      "Epoch [699/2000], Avg Train Loss: 3.9004\n",
      "Epoch [699/2000], Avg Val Loss: 2.3560\n",
      "Validation loss improved from 2.3562 to 2.3560. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9045\n",
      "Epoch [700/2000], Avg Train Loss: 3.9045\n",
      "Epoch [700/2000], Avg Val Loss: 2.3558\n",
      "Validation loss improved from 2.3560 to 2.3558. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8994\n",
      "Epoch [701/2000], Avg Train Loss: 3.8994\n",
      "Epoch [701/2000], Avg Val Loss: 2.3556\n",
      "Validation loss improved from 2.3558 to 2.3556. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9008\n",
      "Epoch [702/2000], Avg Train Loss: 3.9008\n",
      "Epoch [702/2000], Avg Val Loss: 2.3554\n",
      "Validation loss improved from 2.3556 to 2.3554. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8995\n",
      "Epoch [703/2000], Avg Train Loss: 3.8995\n",
      "Epoch [703/2000], Avg Val Loss: 2.3552\n",
      "Validation loss improved from 2.3554 to 2.3552. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9227\n",
      "Epoch [704/2000], Avg Train Loss: 3.9227\n",
      "Epoch [704/2000], Avg Val Loss: 2.3551\n",
      "Validation loss improved from 2.3552 to 2.3551. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8943\n",
      "Epoch [705/2000], Avg Train Loss: 3.8943\n",
      "Epoch [705/2000], Avg Val Loss: 2.3549\n",
      "Validation loss improved from 2.3551 to 2.3549. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8962\n",
      "Epoch [706/2000], Avg Train Loss: 3.8962\n",
      "Epoch [706/2000], Avg Val Loss: 2.3547\n",
      "Validation loss improved from 2.3549 to 2.3547. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8706\n",
      "Epoch [707/2000], Avg Train Loss: 3.8706\n",
      "Epoch [707/2000], Avg Val Loss: 2.3544\n",
      "Validation loss improved from 2.3547 to 2.3544. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9046\n",
      "Epoch [708/2000], Avg Train Loss: 3.9046\n",
      "Epoch [708/2000], Avg Val Loss: 2.3541\n",
      "Validation loss improved from 2.3544 to 2.3541. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8864\n",
      "Epoch [709/2000], Avg Train Loss: 3.8864\n",
      "Epoch [709/2000], Avg Val Loss: 2.3538\n",
      "Validation loss improved from 2.3541 to 2.3538. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8999\n",
      "Epoch [710/2000], Avg Train Loss: 3.8999\n",
      "Epoch [710/2000], Avg Val Loss: 2.3535\n",
      "Validation loss improved from 2.3538 to 2.3535. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8922\n",
      "Epoch [711/2000], Avg Train Loss: 3.8922\n",
      "Epoch [711/2000], Avg Val Loss: 2.3532\n",
      "Validation loss improved from 2.3535 to 2.3532. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9029\n",
      "Epoch [712/2000], Avg Train Loss: 3.9029\n",
      "Epoch [712/2000], Avg Val Loss: 2.3530\n",
      "Validation loss improved from 2.3532 to 2.3530. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9165\n",
      "Epoch [713/2000], Avg Train Loss: 3.9165\n",
      "Epoch [713/2000], Avg Val Loss: 2.3528\n",
      "Validation loss improved from 2.3530 to 2.3528. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8827\n",
      "Epoch [714/2000], Avg Train Loss: 3.8827\n",
      "Epoch [714/2000], Avg Val Loss: 2.3526\n",
      "Validation loss improved from 2.3528 to 2.3526. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9109\n",
      "Epoch [715/2000], Avg Train Loss: 3.9109\n",
      "Epoch [715/2000], Avg Val Loss: 2.3524\n",
      "Validation loss improved from 2.3526 to 2.3524. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8635\n",
      "Epoch [716/2000], Avg Train Loss: 3.8635\n",
      "Epoch [716/2000], Avg Val Loss: 2.3523\n",
      "Validation loss improved from 2.3524 to 2.3523. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8709\n",
      "Epoch [717/2000], Avg Train Loss: 3.8709\n",
      "Epoch [717/2000], Avg Val Loss: 2.3521\n",
      "Validation loss improved from 2.3523 to 2.3521. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8800\n",
      "Epoch [718/2000], Avg Train Loss: 3.8800\n",
      "Epoch [718/2000], Avg Val Loss: 2.3519\n",
      "Validation loss improved from 2.3521 to 2.3519. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8848\n",
      "Epoch [719/2000], Avg Train Loss: 3.8848\n",
      "Epoch [719/2000], Avg Val Loss: 2.3518\n",
      "Validation loss improved from 2.3519 to 2.3518. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8740\n",
      "Epoch [720/2000], Avg Train Loss: 3.8740\n",
      "Epoch [720/2000], Avg Val Loss: 2.3517\n",
      "Validation loss improved from 2.3518 to 2.3517. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8953\n",
      "Epoch [721/2000], Avg Train Loss: 3.8953\n",
      "Epoch [721/2000], Avg Val Loss: 2.3516\n",
      "Validation loss improved from 2.3517 to 2.3516. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9173\n",
      "Epoch [722/2000], Avg Train Loss: 3.9173\n",
      "Epoch [722/2000], Avg Val Loss: 2.3515\n",
      "Validation loss improved from 2.3516 to 2.3515. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8787\n",
      "Epoch [723/2000], Avg Train Loss: 3.8787\n",
      "Epoch [723/2000], Avg Val Loss: 2.3515\n",
      "Validation loss improved from 2.3515 to 2.3515. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9168\n",
      "Epoch [724/2000], Avg Train Loss: 3.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [724/2000], Avg Val Loss: 2.3515\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9112\n",
      "Epoch [725/2000], Avg Train Loss: 3.9112\n",
      "Epoch [725/2000], Avg Val Loss: 2.3515\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9282\n",
      "Epoch [726/2000], Avg Train Loss: 3.9282\n",
      "Epoch [726/2000], Avg Val Loss: 2.3515\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8914\n",
      "Epoch [727/2000], Avg Train Loss: 3.8914\n",
      "Epoch [727/2000], Avg Val Loss: 2.3514\n",
      "Validation loss improved from 2.3515 to 2.3514. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8507\n",
      "Epoch [728/2000], Avg Train Loss: 3.8507\n",
      "Epoch [728/2000], Avg Val Loss: 2.3514\n",
      "Validation loss improved from 2.3514 to 2.3514. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8567\n",
      "Epoch [729/2000], Avg Train Loss: 3.8567\n",
      "Epoch [729/2000], Avg Val Loss: 2.3513\n",
      "Validation loss improved from 2.3514 to 2.3513. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8851\n",
      "Epoch [730/2000], Avg Train Loss: 3.8851\n",
      "Epoch [730/2000], Avg Val Loss: 2.3512\n",
      "Validation loss improved from 2.3513 to 2.3512. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8874\n",
      "Epoch [731/2000], Avg Train Loss: 3.8874\n",
      "Epoch [731/2000], Avg Val Loss: 2.3511\n",
      "Validation loss improved from 2.3512 to 2.3511. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8655\n",
      "Epoch [732/2000], Avg Train Loss: 3.8655\n",
      "Epoch [732/2000], Avg Val Loss: 2.3509\n",
      "Validation loss improved from 2.3511 to 2.3509. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9042\n",
      "Epoch [733/2000], Avg Train Loss: 3.9042\n",
      "Epoch [733/2000], Avg Val Loss: 2.3508\n",
      "Validation loss improved from 2.3509 to 2.3508. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8890\n",
      "Epoch [734/2000], Avg Train Loss: 3.8890\n",
      "Epoch [734/2000], Avg Val Loss: 2.3507\n",
      "Validation loss improved from 2.3508 to 2.3507. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8887\n",
      "Epoch [735/2000], Avg Train Loss: 3.8887\n",
      "Epoch [735/2000], Avg Val Loss: 2.3505\n",
      "Validation loss improved from 2.3507 to 2.3505. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8774\n",
      "Epoch [736/2000], Avg Train Loss: 3.8774\n",
      "Epoch [736/2000], Avg Val Loss: 2.3504\n",
      "Validation loss improved from 2.3505 to 2.3504. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8700\n",
      "Epoch [737/2000], Avg Train Loss: 3.8700\n",
      "Epoch [737/2000], Avg Val Loss: 2.3502\n",
      "Validation loss improved from 2.3504 to 2.3502. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8848\n",
      "Epoch [738/2000], Avg Train Loss: 3.8848\n",
      "Epoch [738/2000], Avg Val Loss: 2.3501\n",
      "Validation loss improved from 2.3502 to 2.3501. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8853\n",
      "Epoch [739/2000], Avg Train Loss: 3.8853\n",
      "Epoch [739/2000], Avg Val Loss: 2.3498\n",
      "Validation loss improved from 2.3501 to 2.3498. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9019\n",
      "Epoch [740/2000], Avg Train Loss: 3.9019\n",
      "Epoch [740/2000], Avg Val Loss: 2.3496\n",
      "Validation loss improved from 2.3498 to 2.3496. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8643\n",
      "Epoch [741/2000], Avg Train Loss: 3.8643\n",
      "Epoch [741/2000], Avg Val Loss: 2.3494\n",
      "Validation loss improved from 2.3496 to 2.3494. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9044\n",
      "Epoch [742/2000], Avg Train Loss: 3.9044\n",
      "Epoch [742/2000], Avg Val Loss: 2.3492\n",
      "Validation loss improved from 2.3494 to 2.3492. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8814\n",
      "Epoch [743/2000], Avg Train Loss: 3.8814\n",
      "Epoch [743/2000], Avg Val Loss: 2.3490\n",
      "Validation loss improved from 2.3492 to 2.3490. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9125\n",
      "Epoch [744/2000], Avg Train Loss: 3.9125\n",
      "Epoch [744/2000], Avg Val Loss: 2.3487\n",
      "Validation loss improved from 2.3490 to 2.3487. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8644\n",
      "Epoch [745/2000], Avg Train Loss: 3.8644\n",
      "Epoch [745/2000], Avg Val Loss: 2.3485\n",
      "Validation loss improved from 2.3487 to 2.3485. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8586\n",
      "Epoch [746/2000], Avg Train Loss: 3.8586\n",
      "Epoch [746/2000], Avg Val Loss: 2.3483\n",
      "Validation loss improved from 2.3485 to 2.3483. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8764\n",
      "Epoch [747/2000], Avg Train Loss: 3.8764\n",
      "Epoch [747/2000], Avg Val Loss: 2.3481\n",
      "Validation loss improved from 2.3483 to 2.3481. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8659\n",
      "Epoch [748/2000], Avg Train Loss: 3.8659\n",
      "Epoch [748/2000], Avg Val Loss: 2.3480\n",
      "Validation loss improved from 2.3481 to 2.3480. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8713\n",
      "Epoch [749/2000], Avg Train Loss: 3.8713\n",
      "Epoch [749/2000], Avg Val Loss: 2.3478\n",
      "Validation loss improved from 2.3480 to 2.3478. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8454\n",
      "Epoch [750/2000], Avg Train Loss: 3.8454\n",
      "Epoch [750/2000], Avg Val Loss: 2.3476\n",
      "Validation loss improved from 2.3478 to 2.3476. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9164\n",
      "Epoch [751/2000], Avg Train Loss: 3.9164\n",
      "Epoch [751/2000], Avg Val Loss: 2.3475\n",
      "Validation loss improved from 2.3476 to 2.3475. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8591\n",
      "Epoch [752/2000], Avg Train Loss: 3.8591\n",
      "Epoch [752/2000], Avg Val Loss: 2.3473\n",
      "Validation loss improved from 2.3475 to 2.3473. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8727\n",
      "Epoch [753/2000], Avg Train Loss: 3.8727\n",
      "Epoch [753/2000], Avg Val Loss: 2.3471\n",
      "Validation loss improved from 2.3473 to 2.3471. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9002\n",
      "Epoch [754/2000], Avg Train Loss: 3.9002\n",
      "Epoch [754/2000], Avg Val Loss: 2.3470\n",
      "Validation loss improved from 2.3471 to 2.3470. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8601\n",
      "Epoch [755/2000], Avg Train Loss: 3.8601\n",
      "Epoch [755/2000], Avg Val Loss: 2.3468\n",
      "Validation loss improved from 2.3470 to 2.3468. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9011\n",
      "Epoch [756/2000], Avg Train Loss: 3.9011\n",
      "Epoch [756/2000], Avg Val Loss: 2.3466\n",
      "Validation loss improved from 2.3468 to 2.3466. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8649\n",
      "Epoch [757/2000], Avg Train Loss: 3.8649\n",
      "Epoch [757/2000], Avg Val Loss: 2.3466\n",
      "Validation loss improved from 2.3466 to 2.3466. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8816\n",
      "Epoch [758/2000], Avg Train Loss: 3.8816\n",
      "Epoch [758/2000], Avg Val Loss: 2.3465\n",
      "Validation loss improved from 2.3466 to 2.3465. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8562\n",
      "Epoch [759/2000], Avg Train Loss: 3.8562\n",
      "Epoch [759/2000], Avg Val Loss: 2.3463\n",
      "Validation loss improved from 2.3465 to 2.3463. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8376\n",
      "Epoch [760/2000], Avg Train Loss: 3.8376\n",
      "Epoch [760/2000], Avg Val Loss: 2.3462\n",
      "Validation loss improved from 2.3463 to 2.3462. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8851\n",
      "Epoch [761/2000], Avg Train Loss: 3.8851\n",
      "Epoch [761/2000], Avg Val Loss: 2.3461\n",
      "Validation loss improved from 2.3462 to 2.3461. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8529\n",
      "Epoch [762/2000], Avg Train Loss: 3.8529\n",
      "Epoch [762/2000], Avg Val Loss: 2.3460\n",
      "Validation loss improved from 2.3461 to 2.3460. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8551\n",
      "Epoch [763/2000], Avg Train Loss: 3.8551\n",
      "Epoch [763/2000], Avg Val Loss: 2.3458\n",
      "Validation loss improved from 2.3460 to 2.3458. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8620\n",
      "Epoch [764/2000], Avg Train Loss: 3.8620\n",
      "Epoch [764/2000], Avg Val Loss: 2.3457\n",
      "Validation loss improved from 2.3458 to 2.3457. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8271\n",
      "Epoch [765/2000], Avg Train Loss: 3.8271\n",
      "Epoch [765/2000], Avg Val Loss: 2.3456\n",
      "Validation loss improved from 2.3457 to 2.3456. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8607\n",
      "Epoch [766/2000], Avg Train Loss: 3.8607\n",
      "Epoch [766/2000], Avg Val Loss: 2.3455\n",
      "Validation loss improved from 2.3456 to 2.3455. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8798\n",
      "Epoch [767/2000], Avg Train Loss: 3.8798\n",
      "Epoch [767/2000], Avg Val Loss: 2.3454\n",
      "Validation loss improved from 2.3455 to 2.3454. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8233\n",
      "Epoch [768/2000], Avg Train Loss: 3.8233\n",
      "Epoch [768/2000], Avg Val Loss: 2.3453\n",
      "Validation loss improved from 2.3454 to 2.3453. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8389\n",
      "Epoch [769/2000], Avg Train Loss: 3.8389\n",
      "Epoch [769/2000], Avg Val Loss: 2.3453\n",
      "Validation loss improved from 2.3453 to 2.3453. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8625\n",
      "Epoch [770/2000], Avg Train Loss: 3.8625\n",
      "Epoch [770/2000], Avg Val Loss: 2.3452\n",
      "Validation loss improved from 2.3453 to 2.3452. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8445\n",
      "Epoch [771/2000], Avg Train Loss: 3.8445\n",
      "Epoch [771/2000], Avg Val Loss: 2.3451\n",
      "Validation loss improved from 2.3452 to 2.3451. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8842\n",
      "Epoch [772/2000], Avg Train Loss: 3.8842\n",
      "Epoch [772/2000], Avg Val Loss: 2.3450\n",
      "Validation loss improved from 2.3451 to 2.3450. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8767\n",
      "Epoch [773/2000], Avg Train Loss: 3.8767\n",
      "Epoch [773/2000], Avg Val Loss: 2.3448\n",
      "Validation loss improved from 2.3450 to 2.3448. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8649\n",
      "Epoch [774/2000], Avg Train Loss: 3.8649\n",
      "Epoch [774/2000], Avg Val Loss: 2.3447\n",
      "Validation loss improved from 2.3448 to 2.3447. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8800\n",
      "Epoch [775/2000], Avg Train Loss: 3.8800\n",
      "Epoch [775/2000], Avg Val Loss: 2.3445\n",
      "Validation loss improved from 2.3447 to 2.3445. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8809\n",
      "Epoch [776/2000], Avg Train Loss: 3.8809\n",
      "Epoch [776/2000], Avg Val Loss: 2.3442\n",
      "Validation loss improved from 2.3445 to 2.3442. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8543\n",
      "Epoch [777/2000], Avg Train Loss: 3.8543\n",
      "Epoch [777/2000], Avg Val Loss: 2.3440\n",
      "Validation loss improved from 2.3442 to 2.3440. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8789\n",
      "Epoch [778/2000], Avg Train Loss: 3.8789\n",
      "Epoch [778/2000], Avg Val Loss: 2.3437\n",
      "Validation loss improved from 2.3440 to 2.3437. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8495\n",
      "Epoch [779/2000], Avg Train Loss: 3.8495\n",
      "Epoch [779/2000], Avg Val Loss: 2.3435\n",
      "Validation loss improved from 2.3437 to 2.3435. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8491\n",
      "Epoch [780/2000], Avg Train Loss: 3.8491\n",
      "Epoch [780/2000], Avg Val Loss: 2.3432\n",
      "Validation loss improved from 2.3435 to 2.3432. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8541\n",
      "Epoch [781/2000], Avg Train Loss: 3.8541\n",
      "Epoch [781/2000], Avg Val Loss: 2.3430\n",
      "Validation loss improved from 2.3432 to 2.3430. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8715\n",
      "Epoch [782/2000], Avg Train Loss: 3.8715\n",
      "Epoch [782/2000], Avg Val Loss: 2.3428\n",
      "Validation loss improved from 2.3430 to 2.3428. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8624\n",
      "Epoch [783/2000], Avg Train Loss: 3.8624\n",
      "Epoch [783/2000], Avg Val Loss: 2.3425\n",
      "Validation loss improved from 2.3428 to 2.3425. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8712\n",
      "Epoch [784/2000], Avg Train Loss: 3.8712\n",
      "Epoch [784/2000], Avg Val Loss: 2.3422\n",
      "Validation loss improved from 2.3425 to 2.3422. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8845\n",
      "Epoch [785/2000], Avg Train Loss: 3.8845\n",
      "Epoch [785/2000], Avg Val Loss: 2.3421\n",
      "Validation loss improved from 2.3422 to 2.3421. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8599\n",
      "Epoch [786/2000], Avg Train Loss: 3.8599\n",
      "Epoch [786/2000], Avg Val Loss: 2.3419\n",
      "Validation loss improved from 2.3421 to 2.3419. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8467\n",
      "Epoch [787/2000], Avg Train Loss: 3.8467\n",
      "Epoch [787/2000], Avg Val Loss: 2.3416\n",
      "Validation loss improved from 2.3419 to 2.3416. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8537\n",
      "Epoch [788/2000], Avg Train Loss: 3.8537\n",
      "Epoch [788/2000], Avg Val Loss: 2.3414\n",
      "Validation loss improved from 2.3416 to 2.3414. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8429\n",
      "Epoch [789/2000], Avg Train Loss: 3.8429\n",
      "Epoch [789/2000], Avg Val Loss: 2.3411\n",
      "Validation loss improved from 2.3414 to 2.3411. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8735\n",
      "Epoch [790/2000], Avg Train Loss: 3.8735\n",
      "Epoch [790/2000], Avg Val Loss: 2.3409\n",
      "Validation loss improved from 2.3411 to 2.3409. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8628\n",
      "Epoch [791/2000], Avg Train Loss: 3.8628\n",
      "Epoch [791/2000], Avg Val Loss: 2.3406\n",
      "Validation loss improved from 2.3409 to 2.3406. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8363\n",
      "Epoch [792/2000], Avg Train Loss: 3.8363\n",
      "Epoch [792/2000], Avg Val Loss: 2.3404\n",
      "Validation loss improved from 2.3406 to 2.3404. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8251\n",
      "Epoch [793/2000], Avg Train Loss: 3.8251\n",
      "Epoch [793/2000], Avg Val Loss: 2.3401\n",
      "Validation loss improved from 2.3404 to 2.3401. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8499\n",
      "Epoch [794/2000], Avg Train Loss: 3.8499\n",
      "Epoch [794/2000], Avg Val Loss: 2.3398\n",
      "Validation loss improved from 2.3401 to 2.3398. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8611\n",
      "Epoch [795/2000], Avg Train Loss: 3.8611\n",
      "Epoch [795/2000], Avg Val Loss: 2.3395\n",
      "Validation loss improved from 2.3398 to 2.3395. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8515\n",
      "Epoch [796/2000], Avg Train Loss: 3.8515\n",
      "Epoch [796/2000], Avg Val Loss: 2.3391\n",
      "Validation loss improved from 2.3395 to 2.3391. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8176\n",
      "Epoch [797/2000], Avg Train Loss: 3.8176\n",
      "Epoch [797/2000], Avg Val Loss: 2.3388\n",
      "Validation loss improved from 2.3391 to 2.3388. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8583\n",
      "Epoch [798/2000], Avg Train Loss: 3.8583\n",
      "Epoch [798/2000], Avg Val Loss: 2.3385\n",
      "Validation loss improved from 2.3388 to 2.3385. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7952\n",
      "Epoch [799/2000], Avg Train Loss: 3.7952\n",
      "Epoch [799/2000], Avg Val Loss: 2.3382\n",
      "Validation loss improved from 2.3385 to 2.3382. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8849\n",
      "Epoch [800/2000], Avg Train Loss: 3.8849\n",
      "Epoch [800/2000], Avg Val Loss: 2.3379\n",
      "Validation loss improved from 2.3382 to 2.3379. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8004\n",
      "Epoch [801/2000], Avg Train Loss: 3.8004\n",
      "Epoch [801/2000], Avg Val Loss: 2.3375\n",
      "Validation loss improved from 2.3379 to 2.3375. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8492\n",
      "Epoch [802/2000], Avg Train Loss: 3.8492\n",
      "Epoch [802/2000], Avg Val Loss: 2.3372\n",
      "Validation loss improved from 2.3375 to 2.3372. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8674\n",
      "Epoch [803/2000], Avg Train Loss: 3.8674\n",
      "Epoch [803/2000], Avg Val Loss: 2.3369\n",
      "Validation loss improved from 2.3372 to 2.3369. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8385\n",
      "Epoch [804/2000], Avg Train Loss: 3.8385\n",
      "Epoch [804/2000], Avg Val Loss: 2.3366\n",
      "Validation loss improved from 2.3369 to 2.3366. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8532\n",
      "Epoch [805/2000], Avg Train Loss: 3.8532\n",
      "Epoch [805/2000], Avg Val Loss: 2.3363\n",
      "Validation loss improved from 2.3366 to 2.3363. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8444\n",
      "Epoch [806/2000], Avg Train Loss: 3.8444\n",
      "Epoch [806/2000], Avg Val Loss: 2.3360\n",
      "Validation loss improved from 2.3363 to 2.3360. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8582\n",
      "Epoch [807/2000], Avg Train Loss: 3.8582\n",
      "Epoch [807/2000], Avg Val Loss: 2.3358\n",
      "Validation loss improved from 2.3360 to 2.3358. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8742\n",
      "Epoch [808/2000], Avg Train Loss: 3.8742\n",
      "Epoch [808/2000], Avg Val Loss: 2.3356\n",
      "Validation loss improved from 2.3358 to 2.3356. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8183\n",
      "Epoch [809/2000], Avg Train Loss: 3.8183\n",
      "Epoch [809/2000], Avg Val Loss: 2.3354\n",
      "Validation loss improved from 2.3356 to 2.3354. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8373\n",
      "Epoch [810/2000], Avg Train Loss: 3.8373\n",
      "Epoch [810/2000], Avg Val Loss: 2.3352\n",
      "Validation loss improved from 2.3354 to 2.3352. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8696\n",
      "Epoch [811/2000], Avg Train Loss: 3.8696\n",
      "Epoch [811/2000], Avg Val Loss: 2.3349\n",
      "Validation loss improved from 2.3352 to 2.3349. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8431\n",
      "Epoch [812/2000], Avg Train Loss: 3.8431\n",
      "Epoch [812/2000], Avg Val Loss: 2.3346\n",
      "Validation loss improved from 2.3349 to 2.3346. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8408\n",
      "Epoch [813/2000], Avg Train Loss: 3.8408\n",
      "Epoch [813/2000], Avg Val Loss: 2.3343\n",
      "Validation loss improved from 2.3346 to 2.3343. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8503\n",
      "Epoch [814/2000], Avg Train Loss: 3.8503\n",
      "Epoch [814/2000], Avg Val Loss: 2.3340\n",
      "Validation loss improved from 2.3343 to 2.3340. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7970\n",
      "Epoch [815/2000], Avg Train Loss: 3.7970\n",
      "Epoch [815/2000], Avg Val Loss: 2.3337\n",
      "Validation loss improved from 2.3340 to 2.3337. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8558\n",
      "Epoch [816/2000], Avg Train Loss: 3.8558\n",
      "Epoch [816/2000], Avg Val Loss: 2.3334\n",
      "Validation loss improved from 2.3337 to 2.3334. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8282\n",
      "Epoch [817/2000], Avg Train Loss: 3.8282\n",
      "Epoch [817/2000], Avg Val Loss: 2.3331\n",
      "Validation loss improved from 2.3334 to 2.3331. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8254\n",
      "Epoch [818/2000], Avg Train Loss: 3.8254\n",
      "Epoch [818/2000], Avg Val Loss: 2.3329\n",
      "Validation loss improved from 2.3331 to 2.3329. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8468\n",
      "Epoch [819/2000], Avg Train Loss: 3.8468\n",
      "Epoch [819/2000], Avg Val Loss: 2.3326\n",
      "Validation loss improved from 2.3329 to 2.3326. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8389\n",
      "Epoch [820/2000], Avg Train Loss: 3.8389\n",
      "Epoch [820/2000], Avg Val Loss: 2.3323\n",
      "Validation loss improved from 2.3326 to 2.3323. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8260\n",
      "Epoch [821/2000], Avg Train Loss: 3.8260\n",
      "Epoch [821/2000], Avg Val Loss: 2.3319\n",
      "Validation loss improved from 2.3323 to 2.3319. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8384\n",
      "Epoch [822/2000], Avg Train Loss: 3.8384\n",
      "Epoch [822/2000], Avg Val Loss: 2.3316\n",
      "Validation loss improved from 2.3319 to 2.3316. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8724\n",
      "Epoch [823/2000], Avg Train Loss: 3.8724\n",
      "Epoch [823/2000], Avg Val Loss: 2.3314\n",
      "Validation loss improved from 2.3316 to 2.3314. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8210\n",
      "Epoch [824/2000], Avg Train Loss: 3.8210\n",
      "Epoch [824/2000], Avg Val Loss: 2.3311\n",
      "Validation loss improved from 2.3314 to 2.3311. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8292\n",
      "Epoch [825/2000], Avg Train Loss: 3.8292\n",
      "Epoch [825/2000], Avg Val Loss: 2.3308\n",
      "Validation loss improved from 2.3311 to 2.3308. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8032\n",
      "Epoch [826/2000], Avg Train Loss: 3.8032\n",
      "Epoch [826/2000], Avg Val Loss: 2.3305\n",
      "Validation loss improved from 2.3308 to 2.3305. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8378\n",
      "Epoch [827/2000], Avg Train Loss: 3.8378\n",
      "Epoch [827/2000], Avg Val Loss: 2.3302\n",
      "Validation loss improved from 2.3305 to 2.3302. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8259\n",
      "Epoch [828/2000], Avg Train Loss: 3.8259\n",
      "Epoch [828/2000], Avg Val Loss: 2.3299\n",
      "Validation loss improved from 2.3302 to 2.3299. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8370\n",
      "Epoch [829/2000], Avg Train Loss: 3.8370\n",
      "Epoch [829/2000], Avg Val Loss: 2.3296\n",
      "Validation loss improved from 2.3299 to 2.3296. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8032\n",
      "Epoch [830/2000], Avg Train Loss: 3.8032\n",
      "Epoch [830/2000], Avg Val Loss: 2.3293\n",
      "Validation loss improved from 2.3296 to 2.3293. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8286\n",
      "Epoch [831/2000], Avg Train Loss: 3.8286\n",
      "Epoch [831/2000], Avg Val Loss: 2.3290\n",
      "Validation loss improved from 2.3293 to 2.3290. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8665\n",
      "Epoch [832/2000], Avg Train Loss: 3.8665\n",
      "Epoch [832/2000], Avg Val Loss: 2.3288\n",
      "Validation loss improved from 2.3290 to 2.3288. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8138\n",
      "Epoch [833/2000], Avg Train Loss: 3.8138\n",
      "Epoch [833/2000], Avg Val Loss: 2.3285\n",
      "Validation loss improved from 2.3288 to 2.3285. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8101\n",
      "Epoch [834/2000], Avg Train Loss: 3.8101\n",
      "Epoch [834/2000], Avg Val Loss: 2.3283\n",
      "Validation loss improved from 2.3285 to 2.3283. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8222\n",
      "Epoch [835/2000], Avg Train Loss: 3.8222\n",
      "Epoch [835/2000], Avg Val Loss: 2.3281\n",
      "Validation loss improved from 2.3283 to 2.3281. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8890\n",
      "Epoch [836/2000], Avg Train Loss: 3.8890\n",
      "Epoch [836/2000], Avg Val Loss: 2.3281\n",
      "Validation loss improved from 2.3281 to 2.3281. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8136\n",
      "Epoch [837/2000], Avg Train Loss: 3.8136\n",
      "Epoch [837/2000], Avg Val Loss: 2.3280\n",
      "Validation loss improved from 2.3281 to 2.3280. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8650\n",
      "Epoch [838/2000], Avg Train Loss: 3.8650\n",
      "Epoch [838/2000], Avg Val Loss: 2.3279\n",
      "Validation loss improved from 2.3280 to 2.3279. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8065\n",
      "Epoch [839/2000], Avg Train Loss: 3.8065\n",
      "Epoch [839/2000], Avg Val Loss: 2.3278\n",
      "Validation loss improved from 2.3279 to 2.3278. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8272\n",
      "Epoch [840/2000], Avg Train Loss: 3.8272\n",
      "Epoch [840/2000], Avg Val Loss: 2.3278\n",
      "Validation loss improved from 2.3278 to 2.3278. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8532\n",
      "Epoch [841/2000], Avg Train Loss: 3.8532\n",
      "Epoch [841/2000], Avg Val Loss: 2.3277\n",
      "Validation loss improved from 2.3278 to 2.3277. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8255\n",
      "Epoch [842/2000], Avg Train Loss: 3.8255\n",
      "Epoch [842/2000], Avg Val Loss: 2.3277\n",
      "Validation loss improved from 2.3277 to 2.3277. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8508\n",
      "Epoch [843/2000], Avg Train Loss: 3.8508\n",
      "Epoch [843/2000], Avg Val Loss: 2.3278\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7954\n",
      "Epoch [844/2000], Avg Train Loss: 3.7954\n",
      "Epoch [844/2000], Avg Val Loss: 2.3278\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8440\n",
      "Epoch [845/2000], Avg Train Loss: 3.8440\n",
      "Epoch [845/2000], Avg Val Loss: 2.3277\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8170\n",
      "Epoch [846/2000], Avg Train Loss: 3.8170\n",
      "Epoch [846/2000], Avg Val Loss: 2.3277\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8429\n",
      "Epoch [847/2000], Avg Train Loss: 3.8429\n",
      "Epoch [847/2000], Avg Val Loss: 2.3277\n",
      "Validation loss improved from 2.3277 to 2.3277. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8303\n",
      "Epoch [848/2000], Avg Train Loss: 3.8303\n",
      "Epoch [848/2000], Avg Val Loss: 2.3276\n",
      "Validation loss improved from 2.3277 to 2.3276. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8049\n",
      "Epoch [849/2000], Avg Train Loss: 3.8049\n",
      "Epoch [849/2000], Avg Val Loss: 2.3276\n",
      "Validation loss improved from 2.3276 to 2.3276. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8246\n",
      "Epoch [850/2000], Avg Train Loss: 3.8246\n",
      "Epoch [850/2000], Avg Val Loss: 2.3275\n",
      "Validation loss improved from 2.3276 to 2.3275. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8308\n",
      "Epoch [851/2000], Avg Train Loss: 3.8308\n",
      "Epoch [851/2000], Avg Val Loss: 2.3274\n",
      "Validation loss improved from 2.3275 to 2.3274. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8301\n",
      "Epoch [852/2000], Avg Train Loss: 3.8301\n",
      "Epoch [852/2000], Avg Val Loss: 2.3272\n",
      "Validation loss improved from 2.3274 to 2.3272. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8224\n",
      "Epoch [853/2000], Avg Train Loss: 3.8224\n",
      "Epoch [853/2000], Avg Val Loss: 2.3270\n",
      "Validation loss improved from 2.3272 to 2.3270. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7987\n",
      "Epoch [854/2000], Avg Train Loss: 3.7987\n",
      "Epoch [854/2000], Avg Val Loss: 2.3268\n",
      "Validation loss improved from 2.3270 to 2.3268. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8147\n",
      "Epoch [855/2000], Avg Train Loss: 3.8147\n",
      "Epoch [855/2000], Avg Val Loss: 2.3265\n",
      "Validation loss improved from 2.3268 to 2.3265. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8198\n",
      "Epoch [856/2000], Avg Train Loss: 3.8198\n",
      "Epoch [856/2000], Avg Val Loss: 2.3262\n",
      "Validation loss improved from 2.3265 to 2.3262. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8343\n",
      "Epoch [857/2000], Avg Train Loss: 3.8343\n",
      "Epoch [857/2000], Avg Val Loss: 2.3259\n",
      "Validation loss improved from 2.3262 to 2.3259. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8014\n",
      "Epoch [858/2000], Avg Train Loss: 3.8014\n",
      "Epoch [858/2000], Avg Val Loss: 2.3256\n",
      "Validation loss improved from 2.3259 to 2.3256. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8264\n",
      "Epoch [859/2000], Avg Train Loss: 3.8264\n",
      "Epoch [859/2000], Avg Val Loss: 2.3253\n",
      "Validation loss improved from 2.3256 to 2.3253. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8285\n",
      "Epoch [860/2000], Avg Train Loss: 3.8285\n",
      "Epoch [860/2000], Avg Val Loss: 2.3251\n",
      "Validation loss improved from 2.3253 to 2.3251. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8299\n",
      "Epoch [861/2000], Avg Train Loss: 3.8299\n",
      "Epoch [861/2000], Avg Val Loss: 2.3248\n",
      "Validation loss improved from 2.3251 to 2.3248. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8413\n",
      "Epoch [862/2000], Avg Train Loss: 3.8413\n",
      "Epoch [862/2000], Avg Val Loss: 2.3245\n",
      "Validation loss improved from 2.3248 to 2.3245. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8043\n",
      "Epoch [863/2000], Avg Train Loss: 3.8043\n",
      "Epoch [863/2000], Avg Val Loss: 2.3242\n",
      "Validation loss improved from 2.3245 to 2.3242. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8196\n",
      "Epoch [864/2000], Avg Train Loss: 3.8196\n",
      "Epoch [864/2000], Avg Val Loss: 2.3239\n",
      "Validation loss improved from 2.3242 to 2.3239. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8380\n",
      "Epoch [865/2000], Avg Train Loss: 3.8380\n",
      "Epoch [865/2000], Avg Val Loss: 2.3237\n",
      "Validation loss improved from 2.3239 to 2.3237. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8320\n",
      "Epoch [866/2000], Avg Train Loss: 3.8320\n",
      "Epoch [866/2000], Avg Val Loss: 2.3234\n",
      "Validation loss improved from 2.3237 to 2.3234. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8109\n",
      "Epoch [867/2000], Avg Train Loss: 3.8109\n",
      "Epoch [867/2000], Avg Val Loss: 2.3232\n",
      "Validation loss improved from 2.3234 to 2.3232. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8286\n",
      "Epoch [868/2000], Avg Train Loss: 3.8286\n",
      "Epoch [868/2000], Avg Val Loss: 2.3230\n",
      "Validation loss improved from 2.3232 to 2.3230. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8276\n",
      "Epoch [869/2000], Avg Train Loss: 3.8276\n",
      "Epoch [869/2000], Avg Val Loss: 2.3228\n",
      "Validation loss improved from 2.3230 to 2.3228. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7650\n",
      "Epoch [870/2000], Avg Train Loss: 3.7650\n",
      "Epoch [870/2000], Avg Val Loss: 2.3227\n",
      "Validation loss improved from 2.3228 to 2.3227. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8243\n",
      "Epoch [871/2000], Avg Train Loss: 3.8243\n",
      "Epoch [871/2000], Avg Val Loss: 2.3225\n",
      "Validation loss improved from 2.3227 to 2.3225. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8163\n",
      "Epoch [872/2000], Avg Train Loss: 3.8163\n",
      "Epoch [872/2000], Avg Val Loss: 2.3224\n",
      "Validation loss improved from 2.3225 to 2.3224. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8185\n",
      "Epoch [873/2000], Avg Train Loss: 3.8185\n",
      "Epoch [873/2000], Avg Val Loss: 2.3223\n",
      "Validation loss improved from 2.3224 to 2.3223. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8189\n",
      "Epoch [874/2000], Avg Train Loss: 3.8189\n",
      "Epoch [874/2000], Avg Val Loss: 2.3222\n",
      "Validation loss improved from 2.3223 to 2.3222. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7958\n",
      "Epoch [875/2000], Avg Train Loss: 3.7958\n",
      "Epoch [875/2000], Avg Val Loss: 2.3220\n",
      "Validation loss improved from 2.3222 to 2.3220. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8557\n",
      "Epoch [876/2000], Avg Train Loss: 3.8557\n",
      "Epoch [876/2000], Avg Val Loss: 2.3219\n",
      "Validation loss improved from 2.3220 to 2.3219. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8298\n",
      "Epoch [877/2000], Avg Train Loss: 3.8298\n",
      "Epoch [877/2000], Avg Val Loss: 2.3218\n",
      "Validation loss improved from 2.3219 to 2.3218. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7951\n",
      "Epoch [878/2000], Avg Train Loss: 3.7951\n",
      "Epoch [878/2000], Avg Val Loss: 2.3216\n",
      "Validation loss improved from 2.3218 to 2.3216. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7974\n",
      "Epoch [879/2000], Avg Train Loss: 3.7974\n",
      "Epoch [879/2000], Avg Val Loss: 2.3214\n",
      "Validation loss improved from 2.3216 to 2.3214. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8059\n",
      "Epoch [880/2000], Avg Train Loss: 3.8059\n",
      "Epoch [880/2000], Avg Val Loss: 2.3212\n",
      "Validation loss improved from 2.3214 to 2.3212. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8035\n",
      "Epoch [881/2000], Avg Train Loss: 3.8035\n",
      "Epoch [881/2000], Avg Val Loss: 2.3211\n",
      "Validation loss improved from 2.3212 to 2.3211. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7962\n",
      "Epoch [882/2000], Avg Train Loss: 3.7962\n",
      "Epoch [882/2000], Avg Val Loss: 2.3210\n",
      "Validation loss improved from 2.3211 to 2.3210. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8045\n",
      "Epoch [883/2000], Avg Train Loss: 3.8045\n",
      "Epoch [883/2000], Avg Val Loss: 2.3208\n",
      "Validation loss improved from 2.3210 to 2.3208. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8153\n",
      "Epoch [884/2000], Avg Train Loss: 3.8153\n",
      "Epoch [884/2000], Avg Val Loss: 2.3207\n",
      "Validation loss improved from 2.3208 to 2.3207. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8165\n",
      "Epoch [885/2000], Avg Train Loss: 3.8165\n",
      "Epoch [885/2000], Avg Val Loss: 2.3205\n",
      "Validation loss improved from 2.3207 to 2.3205. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8010\n",
      "Epoch [886/2000], Avg Train Loss: 3.8010\n",
      "Epoch [886/2000], Avg Val Loss: 2.3203\n",
      "Validation loss improved from 2.3205 to 2.3203. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8140\n",
      "Epoch [887/2000], Avg Train Loss: 3.8140\n",
      "Epoch [887/2000], Avg Val Loss: 2.3202\n",
      "Validation loss improved from 2.3203 to 2.3202. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7931\n",
      "Epoch [888/2000], Avg Train Loss: 3.7931\n",
      "Epoch [888/2000], Avg Val Loss: 2.3200\n",
      "Validation loss improved from 2.3202 to 2.3200. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8244\n",
      "Epoch [889/2000], Avg Train Loss: 3.8244\n",
      "Epoch [889/2000], Avg Val Loss: 2.3200\n",
      "Validation loss improved from 2.3200 to 2.3200. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8144\n",
      "Epoch [890/2000], Avg Train Loss: 3.8144\n",
      "Epoch [890/2000], Avg Val Loss: 2.3199\n",
      "Validation loss improved from 2.3200 to 2.3199. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7930\n",
      "Epoch [891/2000], Avg Train Loss: 3.7930\n",
      "Epoch [891/2000], Avg Val Loss: 2.3199\n",
      "Validation loss improved from 2.3199 to 2.3199. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7943\n",
      "Epoch [892/2000], Avg Train Loss: 3.7943\n",
      "Epoch [892/2000], Avg Val Loss: 2.3198\n",
      "Validation loss improved from 2.3199 to 2.3198. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7655\n",
      "Epoch [893/2000], Avg Train Loss: 3.7655\n",
      "Epoch [893/2000], Avg Val Loss: 2.3198\n",
      "Validation loss improved from 2.3198 to 2.3198. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8266\n",
      "Epoch [894/2000], Avg Train Loss: 3.8266\n",
      "Epoch [894/2000], Avg Val Loss: 2.3197\n",
      "Validation loss improved from 2.3198 to 2.3197. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7971\n",
      "Epoch [895/2000], Avg Train Loss: 3.7971\n",
      "Epoch [895/2000], Avg Val Loss: 2.3196\n",
      "Validation loss improved from 2.3197 to 2.3196. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8257\n",
      "Epoch [896/2000], Avg Train Loss: 3.8257\n",
      "Epoch [896/2000], Avg Val Loss: 2.3195\n",
      "Validation loss improved from 2.3196 to 2.3195. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7875\n",
      "Epoch [897/2000], Avg Train Loss: 3.7875\n",
      "Epoch [897/2000], Avg Val Loss: 2.3193\n",
      "Validation loss improved from 2.3195 to 2.3193. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8074\n",
      "Epoch [898/2000], Avg Train Loss: 3.8074\n",
      "Epoch [898/2000], Avg Val Loss: 2.3192\n",
      "Validation loss improved from 2.3193 to 2.3192. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7795\n",
      "Epoch [899/2000], Avg Train Loss: 3.7795\n",
      "Epoch [899/2000], Avg Val Loss: 2.3190\n",
      "Validation loss improved from 2.3192 to 2.3190. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7764\n",
      "Epoch [900/2000], Avg Train Loss: 3.7764\n",
      "Epoch [900/2000], Avg Val Loss: 2.3189\n",
      "Validation loss improved from 2.3190 to 2.3189. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8066\n",
      "Epoch [901/2000], Avg Train Loss: 3.8066\n",
      "Epoch [901/2000], Avg Val Loss: 2.3187\n",
      "Validation loss improved from 2.3189 to 2.3187. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7662\n",
      "Epoch [902/2000], Avg Train Loss: 3.7662\n",
      "Epoch [902/2000], Avg Val Loss: 2.3186\n",
      "Validation loss improved from 2.3187 to 2.3186. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7743\n",
      "Epoch [903/2000], Avg Train Loss: 3.7743\n",
      "Epoch [903/2000], Avg Val Loss: 2.3184\n",
      "Validation loss improved from 2.3186 to 2.3184. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7777\n",
      "Epoch [904/2000], Avg Train Loss: 3.7777\n",
      "Epoch [904/2000], Avg Val Loss: 2.3184\n",
      "Validation loss improved from 2.3184 to 2.3184. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8046\n",
      "Epoch [905/2000], Avg Train Loss: 3.8046\n",
      "Epoch [905/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8291\n",
      "Epoch [906/2000], Avg Train Loss: 3.8291\n",
      "Epoch [906/2000], Avg Val Loss: 2.3185\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7626\n",
      "Epoch [907/2000], Avg Train Loss: 3.7626\n",
      "Epoch [907/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7751\n",
      "Epoch [908/2000], Avg Train Loss: 3.7751\n",
      "Epoch [908/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7912\n",
      "Epoch [909/2000], Avg Train Loss: 3.7912\n",
      "Epoch [909/2000], Avg Val Loss: 2.3183\n",
      "Validation loss improved from 2.3184 to 2.3183. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7644\n",
      "Epoch [910/2000], Avg Train Loss: 3.7644\n",
      "Epoch [910/2000], Avg Val Loss: 2.3183\n",
      "Validation loss improved from 2.3183 to 2.3183. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7802\n",
      "Epoch [911/2000], Avg Train Loss: 3.7802\n",
      "Epoch [911/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7800\n",
      "Epoch [912/2000], Avg Train Loss: 3.7800\n",
      "Epoch [912/2000], Avg Val Loss: 2.3185\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7868\n",
      "Epoch [913/2000], Avg Train Loss: 3.7868\n",
      "Epoch [913/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8130\n",
      "Epoch [914/2000], Avg Train Loss: 3.8130\n",
      "Epoch [914/2000], Avg Val Loss: 2.3187\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7437\n",
      "Epoch [915/2000], Avg Train Loss: 3.7437\n",
      "Epoch [915/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8333\n",
      "Epoch [916/2000], Avg Train Loss: 3.8333\n",
      "Epoch [916/2000], Avg Val Loss: 2.3190\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7619\n",
      "Epoch [917/2000], Avg Train Loss: 3.7619\n",
      "Epoch [917/2000], Avg Val Loss: 2.3191\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7798\n",
      "Epoch [918/2000], Avg Train Loss: 3.7798\n",
      "Epoch [918/2000], Avg Val Loss: 2.3191\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8121\n",
      "Epoch [919/2000], Avg Train Loss: 3.8121\n",
      "Epoch [919/2000], Avg Val Loss: 2.3190\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7534\n",
      "Epoch [920/2000], Avg Train Loss: 3.7534\n",
      "Epoch [920/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8065\n",
      "Epoch [921/2000], Avg Train Loss: 3.8065\n",
      "Epoch [921/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7931\n",
      "Epoch [922/2000], Avg Train Loss: 3.7931\n",
      "Epoch [922/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7713\n",
      "Epoch [923/2000], Avg Train Loss: 3.7713\n",
      "Epoch [923/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7860\n",
      "Epoch [924/2000], Avg Train Loss: 3.7860\n",
      "Epoch [924/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8109\n",
      "Epoch [925/2000], Avg Train Loss: 3.8109\n",
      "Epoch [925/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7884\n",
      "Epoch [926/2000], Avg Train Loss: 3.7884\n",
      "Epoch [926/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7821\n",
      "Epoch [927/2000], Avg Train Loss: 3.7821\n",
      "Epoch [927/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7757\n",
      "Epoch [928/2000], Avg Train Loss: 3.7757\n",
      "Epoch [928/2000], Avg Val Loss: 2.3190\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7744\n",
      "Epoch [929/2000], Avg Train Loss: 3.7744\n",
      "Epoch [929/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7976\n",
      "Epoch [930/2000], Avg Train Loss: 3.7976\n",
      "Epoch [930/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7560\n",
      "Epoch [931/2000], Avg Train Loss: 3.7560\n",
      "Epoch [931/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7812\n",
      "Epoch [932/2000], Avg Train Loss: 3.7812\n",
      "Epoch [932/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7901\n",
      "Epoch [933/2000], Avg Train Loss: 3.7901\n",
      "Epoch [933/2000], Avg Val Loss: 2.3181\n",
      "Validation loss improved from 2.3183 to 2.3181. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7757\n",
      "Epoch [934/2000], Avg Train Loss: 3.7757\n",
      "Epoch [934/2000], Avg Val Loss: 2.3178\n",
      "Validation loss improved from 2.3181 to 2.3178. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7999\n",
      "Epoch [935/2000], Avg Train Loss: 3.7999\n",
      "Epoch [935/2000], Avg Val Loss: 2.3175\n",
      "Validation loss improved from 2.3178 to 2.3175. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7719\n",
      "Epoch [936/2000], Avg Train Loss: 3.7719\n",
      "Epoch [936/2000], Avg Val Loss: 2.3173\n",
      "Validation loss improved from 2.3175 to 2.3173. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7604\n",
      "Epoch [937/2000], Avg Train Loss: 3.7604\n",
      "Epoch [937/2000], Avg Val Loss: 2.3170\n",
      "Validation loss improved from 2.3173 to 2.3170. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7684\n",
      "Epoch [938/2000], Avg Train Loss: 3.7684\n",
      "Epoch [938/2000], Avg Val Loss: 2.3167\n",
      "Validation loss improved from 2.3170 to 2.3167. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7283\n",
      "Epoch [939/2000], Avg Train Loss: 3.7283\n",
      "Epoch [939/2000], Avg Val Loss: 2.3165\n",
      "Validation loss improved from 2.3167 to 2.3165. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7585\n",
      "Epoch [940/2000], Avg Train Loss: 3.7585\n",
      "Epoch [940/2000], Avg Val Loss: 2.3162\n",
      "Validation loss improved from 2.3165 to 2.3162. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7839\n",
      "Epoch [941/2000], Avg Train Loss: 3.7839\n",
      "Epoch [941/2000], Avg Val Loss: 2.3160\n",
      "Validation loss improved from 2.3162 to 2.3160. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7912\n",
      "Epoch [942/2000], Avg Train Loss: 3.7912\n",
      "Epoch [942/2000], Avg Val Loss: 2.3158\n",
      "Validation loss improved from 2.3160 to 2.3158. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8079\n",
      "Epoch [943/2000], Avg Train Loss: 3.8079\n",
      "Epoch [943/2000], Avg Val Loss: 2.3156\n",
      "Validation loss improved from 2.3158 to 2.3156. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7389\n",
      "Epoch [944/2000], Avg Train Loss: 3.7389\n",
      "Epoch [944/2000], Avg Val Loss: 2.3153\n",
      "Validation loss improved from 2.3156 to 2.3153. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7730\n",
      "Epoch [945/2000], Avg Train Loss: 3.7730\n",
      "Epoch [945/2000], Avg Val Loss: 2.3150\n",
      "Validation loss improved from 2.3153 to 2.3150. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7791\n",
      "Epoch [946/2000], Avg Train Loss: 3.7791\n",
      "Epoch [946/2000], Avg Val Loss: 2.3147\n",
      "Validation loss improved from 2.3150 to 2.3147. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7727\n",
      "Epoch [947/2000], Avg Train Loss: 3.7727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [947/2000], Avg Val Loss: 2.3144\n",
      "Validation loss improved from 2.3147 to 2.3144. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7768\n",
      "Epoch [948/2000], Avg Train Loss: 3.7768\n",
      "Epoch [948/2000], Avg Val Loss: 2.3142\n",
      "Validation loss improved from 2.3144 to 2.3142. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8041\n",
      "Epoch [949/2000], Avg Train Loss: 3.8041\n",
      "Epoch [949/2000], Avg Val Loss: 2.3139\n",
      "Validation loss improved from 2.3142 to 2.3139. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7876\n",
      "Epoch [950/2000], Avg Train Loss: 3.7876\n",
      "Epoch [950/2000], Avg Val Loss: 2.3137\n",
      "Validation loss improved from 2.3139 to 2.3137. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7797\n",
      "Epoch [951/2000], Avg Train Loss: 3.7797\n",
      "Epoch [951/2000], Avg Val Loss: 2.3136\n",
      "Validation loss improved from 2.3137 to 2.3136. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7883\n",
      "Epoch [952/2000], Avg Train Loss: 3.7883\n",
      "Epoch [952/2000], Avg Val Loss: 2.3134\n",
      "Validation loss improved from 2.3136 to 2.3134. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7567\n",
      "Epoch [953/2000], Avg Train Loss: 3.7567\n",
      "Epoch [953/2000], Avg Val Loss: 2.3131\n",
      "Validation loss improved from 2.3134 to 2.3131. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7641\n",
      "Epoch [954/2000], Avg Train Loss: 3.7641\n",
      "Epoch [954/2000], Avg Val Loss: 2.3129\n",
      "Validation loss improved from 2.3131 to 2.3129. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7684\n",
      "Epoch [955/2000], Avg Train Loss: 3.7684\n",
      "Epoch [955/2000], Avg Val Loss: 2.3127\n",
      "Validation loss improved from 2.3129 to 2.3127. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7838\n",
      "Epoch [956/2000], Avg Train Loss: 3.7838\n",
      "Epoch [956/2000], Avg Val Loss: 2.3125\n",
      "Validation loss improved from 2.3127 to 2.3125. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7508\n",
      "Epoch [957/2000], Avg Train Loss: 3.7508\n",
      "Epoch [957/2000], Avg Val Loss: 2.3124\n",
      "Validation loss improved from 2.3125 to 2.3124. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7560\n",
      "Epoch [958/2000], Avg Train Loss: 3.7560\n",
      "Epoch [958/2000], Avg Val Loss: 2.3122\n",
      "Validation loss improved from 2.3124 to 2.3122. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7762\n",
      "Epoch [959/2000], Avg Train Loss: 3.7762\n",
      "Epoch [959/2000], Avg Val Loss: 2.3119\n",
      "Validation loss improved from 2.3122 to 2.3119. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7557\n",
      "Epoch [960/2000], Avg Train Loss: 3.7557\n",
      "Epoch [960/2000], Avg Val Loss: 2.3118\n",
      "Validation loss improved from 2.3119 to 2.3118. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7344\n",
      "Epoch [961/2000], Avg Train Loss: 3.7344\n",
      "Epoch [961/2000], Avg Val Loss: 2.3116\n",
      "Validation loss improved from 2.3118 to 2.3116. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8014\n",
      "Epoch [962/2000], Avg Train Loss: 3.8014\n",
      "Epoch [962/2000], Avg Val Loss: 2.3114\n",
      "Validation loss improved from 2.3116 to 2.3114. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7662\n",
      "Epoch [963/2000], Avg Train Loss: 3.7662\n",
      "Epoch [963/2000], Avg Val Loss: 2.3112\n",
      "Validation loss improved from 2.3114 to 2.3112. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7719\n",
      "Epoch [964/2000], Avg Train Loss: 3.7719\n",
      "Epoch [964/2000], Avg Val Loss: 2.3111\n",
      "Validation loss improved from 2.3112 to 2.3111. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7872\n",
      "Epoch [965/2000], Avg Train Loss: 3.7872\n",
      "Epoch [965/2000], Avg Val Loss: 2.3110\n",
      "Validation loss improved from 2.3111 to 2.3110. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7804\n",
      "Epoch [966/2000], Avg Train Loss: 3.7804\n",
      "Epoch [966/2000], Avg Val Loss: 2.3109\n",
      "Validation loss improved from 2.3110 to 2.3109. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8007\n",
      "Epoch [967/2000], Avg Train Loss: 3.8007\n",
      "Epoch [967/2000], Avg Val Loss: 2.3108\n",
      "Validation loss improved from 2.3109 to 2.3108. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7735\n",
      "Epoch [968/2000], Avg Train Loss: 3.7735\n",
      "Epoch [968/2000], Avg Val Loss: 2.3106\n",
      "Validation loss improved from 2.3108 to 2.3106. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7736\n",
      "Epoch [969/2000], Avg Train Loss: 3.7736\n",
      "Epoch [969/2000], Avg Val Loss: 2.3105\n",
      "Validation loss improved from 2.3106 to 2.3105. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7499\n",
      "Epoch [970/2000], Avg Train Loss: 3.7499\n",
      "Epoch [970/2000], Avg Val Loss: 2.3104\n",
      "Validation loss improved from 2.3105 to 2.3104. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7669\n",
      "Epoch [971/2000], Avg Train Loss: 3.7669\n",
      "Epoch [971/2000], Avg Val Loss: 2.3104\n",
      "Validation loss improved from 2.3104 to 2.3104. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7834\n",
      "Epoch [972/2000], Avg Train Loss: 3.7834\n",
      "Epoch [972/2000], Avg Val Loss: 2.3104\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7743\n",
      "Epoch [973/2000], Avg Train Loss: 3.7743\n",
      "Epoch [973/2000], Avg Val Loss: 2.3105\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7147\n",
      "Epoch [974/2000], Avg Train Loss: 3.7147\n",
      "Epoch [974/2000], Avg Val Loss: 2.3106\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7520\n",
      "Epoch [975/2000], Avg Train Loss: 3.7520\n",
      "Epoch [975/2000], Avg Val Loss: 2.3107\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7864\n",
      "Epoch [976/2000], Avg Train Loss: 3.7864\n",
      "Epoch [976/2000], Avg Val Loss: 2.3107\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7969\n",
      "Epoch [977/2000], Avg Train Loss: 3.7969\n",
      "Epoch [977/2000], Avg Val Loss: 2.3106\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7805\n",
      "Epoch [978/2000], Avg Train Loss: 3.7805\n",
      "Epoch [978/2000], Avg Val Loss: 2.3104\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7716\n",
      "Epoch [979/2000], Avg Train Loss: 3.7716\n",
      "Epoch [979/2000], Avg Val Loss: 2.3103\n",
      "Validation loss improved from 2.3104 to 2.3103. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7386\n",
      "Epoch [980/2000], Avg Train Loss: 3.7386\n",
      "Epoch [980/2000], Avg Val Loss: 2.3100\n",
      "Validation loss improved from 2.3103 to 2.3100. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7863\n",
      "Epoch [981/2000], Avg Train Loss: 3.7863\n",
      "Epoch [981/2000], Avg Val Loss: 2.3098\n",
      "Validation loss improved from 2.3100 to 2.3098. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7253\n",
      "Epoch [982/2000], Avg Train Loss: 3.7253\n",
      "Epoch [982/2000], Avg Val Loss: 2.3095\n",
      "Validation loss improved from 2.3098 to 2.3095. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7716\n",
      "Epoch [983/2000], Avg Train Loss: 3.7716\n",
      "Epoch [983/2000], Avg Val Loss: 2.3093\n",
      "Validation loss improved from 2.3095 to 2.3093. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7392\n",
      "Epoch [984/2000], Avg Train Loss: 3.7392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [984/2000], Avg Val Loss: 2.3090\n",
      "Validation loss improved from 2.3093 to 2.3090. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7637\n",
      "Epoch [985/2000], Avg Train Loss: 3.7637\n",
      "Epoch [985/2000], Avg Val Loss: 2.3087\n",
      "Validation loss improved from 2.3090 to 2.3087. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7380\n",
      "Epoch [986/2000], Avg Train Loss: 3.7380\n",
      "Epoch [986/2000], Avg Val Loss: 2.3084\n",
      "Validation loss improved from 2.3087 to 2.3084. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7484\n",
      "Epoch [987/2000], Avg Train Loss: 3.7484\n",
      "Epoch [987/2000], Avg Val Loss: 2.3082\n",
      "Validation loss improved from 2.3084 to 2.3082. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7379\n",
      "Epoch [988/2000], Avg Train Loss: 3.7379\n",
      "Epoch [988/2000], Avg Val Loss: 2.3080\n",
      "Validation loss improved from 2.3082 to 2.3080. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7311\n",
      "Epoch [989/2000], Avg Train Loss: 3.7311\n",
      "Epoch [989/2000], Avg Val Loss: 2.3079\n",
      "Validation loss improved from 2.3080 to 2.3079. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7467\n",
      "Epoch [990/2000], Avg Train Loss: 3.7467\n",
      "Epoch [990/2000], Avg Val Loss: 2.3076\n",
      "Validation loss improved from 2.3079 to 2.3076. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7535\n",
      "Epoch [991/2000], Avg Train Loss: 3.7535\n",
      "Epoch [991/2000], Avg Val Loss: 2.3074\n",
      "Validation loss improved from 2.3076 to 2.3074. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7451\n",
      "Epoch [992/2000], Avg Train Loss: 3.7451\n",
      "Epoch [992/2000], Avg Val Loss: 2.3071\n",
      "Validation loss improved from 2.3074 to 2.3071. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7625\n",
      "Epoch [993/2000], Avg Train Loss: 3.7625\n",
      "Epoch [993/2000], Avg Val Loss: 2.3068\n",
      "Validation loss improved from 2.3071 to 2.3068. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7487\n",
      "Epoch [994/2000], Avg Train Loss: 3.7487\n",
      "Epoch [994/2000], Avg Val Loss: 2.3066\n",
      "Validation loss improved from 2.3068 to 2.3066. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7787\n",
      "Epoch [995/2000], Avg Train Loss: 3.7787\n",
      "Epoch [995/2000], Avg Val Loss: 2.3064\n",
      "Validation loss improved from 2.3066 to 2.3064. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7412\n",
      "Epoch [996/2000], Avg Train Loss: 3.7412\n",
      "Epoch [996/2000], Avg Val Loss: 2.3062\n",
      "Validation loss improved from 2.3064 to 2.3062. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7099\n",
      "Epoch [997/2000], Avg Train Loss: 3.7099\n",
      "Epoch [997/2000], Avg Val Loss: 2.3061\n",
      "Validation loss improved from 2.3062 to 2.3061. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7496\n",
      "Epoch [998/2000], Avg Train Loss: 3.7496\n",
      "Epoch [998/2000], Avg Val Loss: 2.3059\n",
      "Validation loss improved from 2.3061 to 2.3059. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7575\n",
      "Epoch [999/2000], Avg Train Loss: 3.7575\n",
      "Epoch [999/2000], Avg Val Loss: 2.3058\n",
      "Validation loss improved from 2.3059 to 2.3058. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7475\n",
      "Epoch [1000/2000], Avg Train Loss: 3.7475\n",
      "Epoch [1000/2000], Avg Val Loss: 2.3055\n",
      "Validation loss improved from 2.3058 to 2.3055. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7321\n",
      "Epoch [1001/2000], Avg Train Loss: 3.7321\n",
      "Epoch [1001/2000], Avg Val Loss: 2.3053\n",
      "Validation loss improved from 2.3055 to 2.3053. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7405\n",
      "Epoch [1002/2000], Avg Train Loss: 3.7405\n",
      "Epoch [1002/2000], Avg Val Loss: 2.3051\n",
      "Validation loss improved from 2.3053 to 2.3051. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7586\n",
      "Epoch [1003/2000], Avg Train Loss: 3.7586\n",
      "Epoch [1003/2000], Avg Val Loss: 2.3048\n",
      "Validation loss improved from 2.3051 to 2.3048. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7093\n",
      "Epoch [1004/2000], Avg Train Loss: 3.7093\n",
      "Epoch [1004/2000], Avg Val Loss: 2.3044\n",
      "Validation loss improved from 2.3048 to 2.3044. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7614\n",
      "Epoch [1005/2000], Avg Train Loss: 3.7614\n",
      "Epoch [1005/2000], Avg Val Loss: 2.3040\n",
      "Validation loss improved from 2.3044 to 2.3040. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7319\n",
      "Epoch [1006/2000], Avg Train Loss: 3.7319\n",
      "Epoch [1006/2000], Avg Val Loss: 2.3037\n",
      "Validation loss improved from 2.3040 to 2.3037. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7304\n",
      "Epoch [1007/2000], Avg Train Loss: 3.7304\n",
      "Epoch [1007/2000], Avg Val Loss: 2.3035\n",
      "Validation loss improved from 2.3037 to 2.3035. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7564\n",
      "Epoch [1008/2000], Avg Train Loss: 3.7564\n",
      "Epoch [1008/2000], Avg Val Loss: 2.3032\n",
      "Validation loss improved from 2.3035 to 2.3032. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7296\n",
      "Epoch [1009/2000], Avg Train Loss: 3.7296\n",
      "Epoch [1009/2000], Avg Val Loss: 2.3030\n",
      "Validation loss improved from 2.3032 to 2.3030. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7450\n",
      "Epoch [1010/2000], Avg Train Loss: 3.7450\n",
      "Epoch [1010/2000], Avg Val Loss: 2.3027\n",
      "Validation loss improved from 2.3030 to 2.3027. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7421\n",
      "Epoch [1011/2000], Avg Train Loss: 3.7421\n",
      "Epoch [1011/2000], Avg Val Loss: 2.3024\n",
      "Validation loss improved from 2.3027 to 2.3024. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7054\n",
      "Epoch [1012/2000], Avg Train Loss: 3.7054\n",
      "Epoch [1012/2000], Avg Val Loss: 2.3021\n",
      "Validation loss improved from 2.3024 to 2.3021. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7612\n",
      "Epoch [1013/2000], Avg Train Loss: 3.7612\n",
      "Epoch [1013/2000], Avg Val Loss: 2.3019\n",
      "Validation loss improved from 2.3021 to 2.3019. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7667\n",
      "Epoch [1014/2000], Avg Train Loss: 3.7667\n",
      "Epoch [1014/2000], Avg Val Loss: 2.3017\n",
      "Validation loss improved from 2.3019 to 2.3017. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7443\n",
      "Epoch [1015/2000], Avg Train Loss: 3.7443\n",
      "Epoch [1015/2000], Avg Val Loss: 2.3015\n",
      "Validation loss improved from 2.3017 to 2.3015. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7255\n",
      "Epoch [1016/2000], Avg Train Loss: 3.7255\n",
      "Epoch [1016/2000], Avg Val Loss: 2.3013\n",
      "Validation loss improved from 2.3015 to 2.3013. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7157\n",
      "Epoch [1017/2000], Avg Train Loss: 3.7157\n",
      "Epoch [1017/2000], Avg Val Loss: 2.3011\n",
      "Validation loss improved from 2.3013 to 2.3011. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7172\n",
      "Epoch [1018/2000], Avg Train Loss: 3.7172\n",
      "Epoch [1018/2000], Avg Val Loss: 2.3009\n",
      "Validation loss improved from 2.3011 to 2.3009. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7751\n",
      "Epoch [1019/2000], Avg Train Loss: 3.7751\n",
      "Epoch [1019/2000], Avg Val Loss: 2.3009\n",
      "Validation loss improved from 2.3009 to 2.3009. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7128\n",
      "Epoch [1020/2000], Avg Train Loss: 3.7128\n",
      "Epoch [1020/2000], Avg Val Loss: 2.3008\n",
      "Validation loss improved from 2.3009 to 2.3008. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7529\n",
      "Epoch [1021/2000], Avg Train Loss: 3.7529\n",
      "Epoch [1021/2000], Avg Val Loss: 2.3007\n",
      "Validation loss improved from 2.3008 to 2.3007. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7708\n",
      "Epoch [1022/2000], Avg Train Loss: 3.7708\n",
      "Epoch [1022/2000], Avg Val Loss: 2.3005\n",
      "Validation loss improved from 2.3007 to 2.3005. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7475\n",
      "Epoch [1023/2000], Avg Train Loss: 3.7475\n",
      "Epoch [1023/2000], Avg Val Loss: 2.3004\n",
      "Validation loss improved from 2.3005 to 2.3004. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7541\n",
      "Epoch [1024/2000], Avg Train Loss: 3.7541\n",
      "Epoch [1024/2000], Avg Val Loss: 2.3003\n",
      "Validation loss improved from 2.3004 to 2.3003. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7575\n",
      "Epoch [1025/2000], Avg Train Loss: 3.7575\n",
      "Epoch [1025/2000], Avg Val Loss: 2.3002\n",
      "Validation loss improved from 2.3003 to 2.3002. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7326\n",
      "Epoch [1026/2000], Avg Train Loss: 3.7326\n",
      "Epoch [1026/2000], Avg Val Loss: 2.3002\n",
      "Validation loss improved from 2.3002 to 2.3002. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7648\n",
      "Epoch [1027/2000], Avg Train Loss: 3.7648\n",
      "Epoch [1027/2000], Avg Val Loss: 2.3001\n",
      "Validation loss improved from 2.3002 to 2.3001. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7178\n",
      "Epoch [1028/2000], Avg Train Loss: 3.7178\n",
      "Epoch [1028/2000], Avg Val Loss: 2.3001\n",
      "Validation loss improved from 2.3001 to 2.3001. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7435\n",
      "Epoch [1029/2000], Avg Train Loss: 3.7435\n",
      "Epoch [1029/2000], Avg Val Loss: 2.3000\n",
      "Validation loss improved from 2.3001 to 2.3000. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7325\n",
      "Epoch [1030/2000], Avg Train Loss: 3.7325\n",
      "Epoch [1030/2000], Avg Val Loss: 2.2999\n",
      "Validation loss improved from 2.3000 to 2.2999. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7341\n",
      "Epoch [1031/2000], Avg Train Loss: 3.7341\n",
      "Epoch [1031/2000], Avg Val Loss: 2.2998\n",
      "Validation loss improved from 2.2999 to 2.2998. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7502\n",
      "Epoch [1032/2000], Avg Train Loss: 3.7502\n",
      "Epoch [1032/2000], Avg Val Loss: 2.2997\n",
      "Validation loss improved from 2.2998 to 2.2997. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7232\n",
      "Epoch [1033/2000], Avg Train Loss: 3.7232\n",
      "Epoch [1033/2000], Avg Val Loss: 2.2995\n",
      "Validation loss improved from 2.2997 to 2.2995. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7293\n",
      "Epoch [1034/2000], Avg Train Loss: 3.7293\n",
      "Epoch [1034/2000], Avg Val Loss: 2.2994\n",
      "Validation loss improved from 2.2995 to 2.2994. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7460\n",
      "Epoch [1035/2000], Avg Train Loss: 3.7460\n",
      "Epoch [1035/2000], Avg Val Loss: 2.2994\n",
      "Validation loss improved from 2.2994 to 2.2994. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7624\n",
      "Epoch [1036/2000], Avg Train Loss: 3.7624\n",
      "Epoch [1036/2000], Avg Val Loss: 2.2994\n",
      "Validation loss improved from 2.2994 to 2.2994. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7589\n",
      "Epoch [1037/2000], Avg Train Loss: 3.7589\n",
      "Epoch [1037/2000], Avg Val Loss: 2.2994\n",
      "Validation loss improved from 2.2994 to 2.2994. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7322\n",
      "Epoch [1038/2000], Avg Train Loss: 3.7322\n",
      "Epoch [1038/2000], Avg Val Loss: 2.2993\n",
      "Validation loss improved from 2.2994 to 2.2993. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6970\n",
      "Epoch [1039/2000], Avg Train Loss: 3.6970\n",
      "Epoch [1039/2000], Avg Val Loss: 2.2993\n",
      "Validation loss improved from 2.2993 to 2.2993. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7244\n",
      "Epoch [1040/2000], Avg Train Loss: 3.7244\n",
      "Epoch [1040/2000], Avg Val Loss: 2.2992\n",
      "Validation loss improved from 2.2993 to 2.2992. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7170\n",
      "Epoch [1041/2000], Avg Train Loss: 3.7170\n",
      "Epoch [1041/2000], Avg Val Loss: 2.2992\n",
      "Validation loss improved from 2.2992 to 2.2992. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7353\n",
      "Epoch [1042/2000], Avg Train Loss: 3.7353\n",
      "Epoch [1042/2000], Avg Val Loss: 2.2992\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7264\n",
      "Epoch [1043/2000], Avg Train Loss: 3.7264\n",
      "Epoch [1043/2000], Avg Val Loss: 2.2991\n",
      "Validation loss improved from 2.2992 to 2.2991. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7387\n",
      "Epoch [1044/2000], Avg Train Loss: 3.7387\n",
      "Epoch [1044/2000], Avg Val Loss: 2.2991\n",
      "Validation loss improved from 2.2991 to 2.2991. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7015\n",
      "Epoch [1045/2000], Avg Train Loss: 3.7015\n",
      "Epoch [1045/2000], Avg Val Loss: 2.2990\n",
      "Validation loss improved from 2.2991 to 2.2990. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7239\n",
      "Epoch [1046/2000], Avg Train Loss: 3.7239\n",
      "Epoch [1046/2000], Avg Val Loss: 2.2989\n",
      "Validation loss improved from 2.2990 to 2.2989. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7171\n",
      "Epoch [1047/2000], Avg Train Loss: 3.7171\n",
      "Epoch [1047/2000], Avg Val Loss: 2.2988\n",
      "Validation loss improved from 2.2989 to 2.2988. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7415\n",
      "Epoch [1048/2000], Avg Train Loss: 3.7415\n",
      "Epoch [1048/2000], Avg Val Loss: 2.2986\n",
      "Validation loss improved from 2.2988 to 2.2986. Saving model...\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7337\n",
      "Epoch [1049/2000], Avg Train Loss: 3.7337\n",
      "Epoch [1049/2000], Avg Val Loss: 2.2983\n",
      "Validation loss improved from 2.2986 to 2.2983. Saving model...\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7189\n",
      "Epoch [1050/2000], Avg Train Loss: 3.7189\n",
      "Epoch [1050/2000], Avg Val Loss: 2.2980\n",
      "Validation loss improved from 2.2983 to 2.2980. Saving model...\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7221\n",
      "Epoch [1051/2000], Avg Train Loss: 3.7221\n",
      "Epoch [1051/2000], Avg Val Loss: 2.2976\n",
      "Validation loss improved from 2.2980 to 2.2976. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7140\n",
      "Epoch [1052/2000], Avg Train Loss: 3.7140\n",
      "Epoch [1052/2000], Avg Val Loss: 2.2971\n",
      "Validation loss improved from 2.2976 to 2.2971. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7551\n",
      "Epoch [1053/2000], Avg Train Loss: 3.7551\n",
      "Epoch [1053/2000], Avg Val Loss: 2.2967\n",
      "Validation loss improved from 2.2971 to 2.2967. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7123\n",
      "Epoch [1054/2000], Avg Train Loss: 3.7123\n",
      "Epoch [1054/2000], Avg Val Loss: 2.2963\n",
      "Validation loss improved from 2.2967 to 2.2963. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7016\n",
      "Epoch [1055/2000], Avg Train Loss: 3.7016\n",
      "Epoch [1055/2000], Avg Val Loss: 2.2959\n",
      "Validation loss improved from 2.2963 to 2.2959. Saving model...\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7532\n",
      "Epoch [1056/2000], Avg Train Loss: 3.7532\n",
      "Epoch [1056/2000], Avg Val Loss: 2.2955\n",
      "Validation loss improved from 2.2959 to 2.2955. Saving model...\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7613\n",
      "Epoch [1057/2000], Avg Train Loss: 3.7613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1057/2000], Avg Val Loss: 2.2953\n",
      "Validation loss improved from 2.2955 to 2.2953. Saving model...\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7258\n",
      "Epoch [1058/2000], Avg Train Loss: 3.7258\n",
      "Epoch [1058/2000], Avg Val Loss: 2.2952\n",
      "Validation loss improved from 2.2953 to 2.2952. Saving model...\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7081\n",
      "Epoch [1059/2000], Avg Train Loss: 3.7081\n",
      "Epoch [1059/2000], Avg Val Loss: 2.2951\n",
      "Validation loss improved from 2.2952 to 2.2951. Saving model...\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7286\n",
      "Epoch [1060/2000], Avg Train Loss: 3.7286\n",
      "Epoch [1060/2000], Avg Val Loss: 2.2950\n",
      "Validation loss improved from 2.2951 to 2.2950. Saving model...\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7040\n",
      "Epoch [1061/2000], Avg Train Loss: 3.7040\n",
      "Epoch [1061/2000], Avg Val Loss: 2.2950\n",
      "Validation loss improved from 2.2950 to 2.2950. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7415\n",
      "Epoch [1062/2000], Avg Train Loss: 3.7415\n",
      "Epoch [1062/2000], Avg Val Loss: 2.2949\n",
      "Validation loss improved from 2.2950 to 2.2949. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7610\n",
      "Epoch [1063/2000], Avg Train Loss: 3.7610\n",
      "Epoch [1063/2000], Avg Val Loss: 2.2948\n",
      "Validation loss improved from 2.2949 to 2.2948. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7404\n",
      "Epoch [1064/2000], Avg Train Loss: 3.7404\n",
      "Epoch [1064/2000], Avg Val Loss: 2.2947\n",
      "Validation loss improved from 2.2948 to 2.2947. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7200\n",
      "Epoch [1065/2000], Avg Train Loss: 3.7200\n",
      "Epoch [1065/2000], Avg Val Loss: 2.2947\n",
      "Validation loss improved from 2.2947 to 2.2947. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7095\n",
      "Epoch [1066/2000], Avg Train Loss: 3.7095\n",
      "Epoch [1066/2000], Avg Val Loss: 2.2948\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7230\n",
      "Epoch [1067/2000], Avg Train Loss: 3.7230\n",
      "Epoch [1067/2000], Avg Val Loss: 2.2950\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7038\n",
      "Epoch [1068/2000], Avg Train Loss: 3.7038\n",
      "Epoch [1068/2000], Avg Val Loss: 2.2952\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7225\n",
      "Epoch [1069/2000], Avg Train Loss: 3.7225\n",
      "Epoch [1069/2000], Avg Val Loss: 2.2953\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7135\n",
      "Epoch [1070/2000], Avg Train Loss: 3.7135\n",
      "Epoch [1070/2000], Avg Val Loss: 2.2954\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7161\n",
      "Epoch [1071/2000], Avg Train Loss: 3.7161\n",
      "Epoch [1071/2000], Avg Val Loss: 2.2955\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7129\n",
      "Epoch [1072/2000], Avg Train Loss: 3.7129\n",
      "Epoch [1072/2000], Avg Val Loss: 2.2954\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7266\n",
      "Epoch [1073/2000], Avg Train Loss: 3.7266\n",
      "Epoch [1073/2000], Avg Val Loss: 2.2954\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7606\n",
      "Epoch [1074/2000], Avg Train Loss: 3.7606\n",
      "Epoch [1074/2000], Avg Val Loss: 2.2953\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7530\n",
      "Epoch [1075/2000], Avg Train Loss: 3.7530\n",
      "Epoch [1075/2000], Avg Val Loss: 2.2952\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6962\n",
      "Epoch [1076/2000], Avg Train Loss: 3.6962\n",
      "Epoch [1076/2000], Avg Val Loss: 2.2949\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7506\n",
      "Epoch [1077/2000], Avg Train Loss: 3.7506\n",
      "Epoch [1077/2000], Avg Val Loss: 2.2946\n",
      "Validation loss improved from 2.2947 to 2.2946. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7144\n",
      "Epoch [1078/2000], Avg Train Loss: 3.7144\n",
      "Epoch [1078/2000], Avg Val Loss: 2.2945\n",
      "Validation loss improved from 2.2946 to 2.2945. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7018\n",
      "Epoch [1079/2000], Avg Train Loss: 3.7018\n",
      "Epoch [1079/2000], Avg Val Loss: 2.2942\n",
      "Validation loss improved from 2.2945 to 2.2942. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7246\n",
      "Epoch [1080/2000], Avg Train Loss: 3.7246\n",
      "Epoch [1080/2000], Avg Val Loss: 2.2940\n",
      "Validation loss improved from 2.2942 to 2.2940. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7191\n",
      "Epoch [1081/2000], Avg Train Loss: 3.7191\n",
      "Epoch [1081/2000], Avg Val Loss: 2.2939\n",
      "Validation loss improved from 2.2940 to 2.2939. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7503\n",
      "Epoch [1082/2000], Avg Train Loss: 3.7503\n",
      "Epoch [1082/2000], Avg Val Loss: 2.2937\n",
      "Validation loss improved from 2.2939 to 2.2937. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6993\n",
      "Epoch [1083/2000], Avg Train Loss: 3.6993\n",
      "Epoch [1083/2000], Avg Val Loss: 2.2934\n",
      "Validation loss improved from 2.2937 to 2.2934. Saving model...\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7144\n",
      "Epoch [1084/2000], Avg Train Loss: 3.7144\n",
      "Epoch [1084/2000], Avg Val Loss: 2.2932\n",
      "Validation loss improved from 2.2934 to 2.2932. Saving model...\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7113\n",
      "Epoch [1085/2000], Avg Train Loss: 3.7113\n",
      "Epoch [1085/2000], Avg Val Loss: 2.2930\n",
      "Validation loss improved from 2.2932 to 2.2930. Saving model...\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7097\n",
      "Epoch [1086/2000], Avg Train Loss: 3.7097\n",
      "Epoch [1086/2000], Avg Val Loss: 2.2928\n",
      "Validation loss improved from 2.2930 to 2.2928. Saving model...\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7188\n",
      "Epoch [1087/2000], Avg Train Loss: 3.7188\n",
      "Epoch [1087/2000], Avg Val Loss: 2.2927\n",
      "Validation loss improved from 2.2928 to 2.2927. Saving model...\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7341\n",
      "Epoch [1088/2000], Avg Train Loss: 3.7341\n",
      "Epoch [1088/2000], Avg Val Loss: 2.2927\n",
      "Validation loss improved from 2.2927 to 2.2927. Saving model...\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7176\n",
      "Epoch [1089/2000], Avg Train Loss: 3.7176\n",
      "Epoch [1089/2000], Avg Val Loss: 2.2927\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6977\n",
      "Epoch [1090/2000], Avg Train Loss: 3.6977\n",
      "Epoch [1090/2000], Avg Val Loss: 2.2927\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7167\n",
      "Epoch [1091/2000], Avg Train Loss: 3.7167\n",
      "Epoch [1091/2000], Avg Val Loss: 2.2925\n",
      "Validation loss improved from 2.2927 to 2.2925. Saving model...\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6929\n",
      "Epoch [1092/2000], Avg Train Loss: 3.6929\n",
      "Epoch [1092/2000], Avg Val Loss: 2.2924\n",
      "Validation loss improved from 2.2925 to 2.2924. Saving model...\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7563\n",
      "Epoch [1093/2000], Avg Train Loss: 3.7563\n",
      "Epoch [1093/2000], Avg Val Loss: 2.2922\n",
      "Validation loss improved from 2.2924 to 2.2922. Saving model...\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7022\n",
      "Epoch [1094/2000], Avg Train Loss: 3.7022\n",
      "Epoch [1094/2000], Avg Val Loss: 2.2920\n",
      "Validation loss improved from 2.2922 to 2.2920. Saving model...\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7026\n",
      "Epoch [1095/2000], Avg Train Loss: 3.7026\n",
      "Epoch [1095/2000], Avg Val Loss: 2.2918\n",
      "Validation loss improved from 2.2920 to 2.2918. Saving model...\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7104\n",
      "Epoch [1096/2000], Avg Train Loss: 3.7104\n",
      "Epoch [1096/2000], Avg Val Loss: 2.2915\n",
      "Validation loss improved from 2.2918 to 2.2915. Saving model...\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7444\n",
      "Epoch [1097/2000], Avg Train Loss: 3.7444\n",
      "Epoch [1097/2000], Avg Val Loss: 2.2911\n",
      "Validation loss improved from 2.2915 to 2.2911. Saving model...\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7137\n",
      "Epoch [1098/2000], Avg Train Loss: 3.7137\n",
      "Epoch [1098/2000], Avg Val Loss: 2.2907\n",
      "Validation loss improved from 2.2911 to 2.2907. Saving model...\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7268\n",
      "Epoch [1099/2000], Avg Train Loss: 3.7268\n",
      "Epoch [1099/2000], Avg Val Loss: 2.2903\n",
      "Validation loss improved from 2.2907 to 2.2903. Saving model...\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6848\n",
      "Epoch [1100/2000], Avg Train Loss: 3.6848\n",
      "Epoch [1100/2000], Avg Val Loss: 2.2900\n",
      "Validation loss improved from 2.2903 to 2.2900. Saving model...\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6967\n",
      "Epoch [1101/2000], Avg Train Loss: 3.6967\n",
      "Epoch [1101/2000], Avg Val Loss: 2.2898\n",
      "Validation loss improved from 2.2900 to 2.2898. Saving model...\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6939\n",
      "Epoch [1102/2000], Avg Train Loss: 3.6939\n",
      "Epoch [1102/2000], Avg Val Loss: 2.2896\n",
      "Validation loss improved from 2.2898 to 2.2896. Saving model...\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7420\n",
      "Epoch [1103/2000], Avg Train Loss: 3.7420\n",
      "Epoch [1103/2000], Avg Val Loss: 2.2895\n",
      "Validation loss improved from 2.2896 to 2.2895. Saving model...\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7627\n",
      "Epoch [1104/2000], Avg Train Loss: 3.7627\n",
      "Epoch [1104/2000], Avg Val Loss: 2.2895\n",
      "Validation loss improved from 2.2895 to 2.2895. Saving model...\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7288\n",
      "Epoch [1105/2000], Avg Train Loss: 3.7288\n",
      "Epoch [1105/2000], Avg Val Loss: 2.2895\n",
      "Validation loss improved from 2.2895 to 2.2895. Saving model...\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7084\n",
      "Epoch [1106/2000], Avg Train Loss: 3.7084\n",
      "Epoch [1106/2000], Avg Val Loss: 2.2894\n",
      "Validation loss improved from 2.2895 to 2.2894. Saving model...\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7031\n",
      "Epoch [1107/2000], Avg Train Loss: 3.7031\n",
      "Epoch [1107/2000], Avg Val Loss: 2.2894\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6956\n",
      "Epoch [1108/2000], Avg Train Loss: 3.6956\n",
      "Epoch [1108/2000], Avg Val Loss: 2.2894\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7041\n",
      "Epoch [1109/2000], Avg Train Loss: 3.7041\n",
      "Epoch [1109/2000], Avg Val Loss: 2.2895\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7171\n",
      "Epoch [1110/2000], Avg Train Loss: 3.7171\n",
      "Epoch [1110/2000], Avg Val Loss: 2.2897\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7403\n",
      "Epoch [1111/2000], Avg Train Loss: 3.7403\n",
      "Epoch [1111/2000], Avg Val Loss: 2.2898\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7220\n",
      "Epoch [1112/2000], Avg Train Loss: 3.7220\n",
      "Epoch [1112/2000], Avg Val Loss: 2.2899\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7378\n",
      "Epoch [1113/2000], Avg Train Loss: 3.7378\n",
      "Epoch [1113/2000], Avg Val Loss: 2.2899\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6927\n",
      "Epoch [1114/2000], Avg Train Loss: 3.6927\n",
      "Epoch [1114/2000], Avg Val Loss: 2.2898\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7232\n",
      "Epoch [1115/2000], Avg Train Loss: 3.7232\n",
      "Epoch [1115/2000], Avg Val Loss: 2.2898\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7261\n",
      "Epoch [1116/2000], Avg Train Loss: 3.7261\n",
      "Epoch [1116/2000], Avg Val Loss: 2.2897\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6894\n",
      "Epoch [1117/2000], Avg Train Loss: 3.6894\n",
      "Epoch [1117/2000], Avg Val Loss: 2.2894\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6959\n",
      "Epoch [1118/2000], Avg Train Loss: 3.6959\n",
      "Epoch [1118/2000], Avg Val Loss: 2.2891\n",
      "Validation loss improved from 2.2894 to 2.2891. Saving model...\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7077\n",
      "Epoch [1119/2000], Avg Train Loss: 3.7077\n",
      "Epoch [1119/2000], Avg Val Loss: 2.2887\n",
      "Validation loss improved from 2.2891 to 2.2887. Saving model...\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6984\n",
      "Epoch [1120/2000], Avg Train Loss: 3.6984\n",
      "Epoch [1120/2000], Avg Val Loss: 2.2884\n",
      "Validation loss improved from 2.2887 to 2.2884. Saving model...\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7389\n",
      "Epoch [1121/2000], Avg Train Loss: 3.7389\n",
      "Epoch [1121/2000], Avg Val Loss: 2.2881\n",
      "Validation loss improved from 2.2884 to 2.2881. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6863\n",
      "Epoch [1122/2000], Avg Train Loss: 3.6863\n",
      "Epoch [1122/2000], Avg Val Loss: 2.2880\n",
      "Validation loss improved from 2.2881 to 2.2880. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7307\n",
      "Epoch [1123/2000], Avg Train Loss: 3.7307\n",
      "Epoch [1123/2000], Avg Val Loss: 2.2877\n",
      "Validation loss improved from 2.2880 to 2.2877. Saving model...\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7017\n",
      "Epoch [1124/2000], Avg Train Loss: 3.7017\n",
      "Epoch [1124/2000], Avg Val Loss: 2.2875\n",
      "Validation loss improved from 2.2877 to 2.2875. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7009\n",
      "Epoch [1125/2000], Avg Train Loss: 3.7009\n",
      "Epoch [1125/2000], Avg Val Loss: 2.2870\n",
      "Validation loss improved from 2.2875 to 2.2870. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6879\n",
      "Epoch [1126/2000], Avg Train Loss: 3.6879\n",
      "Epoch [1126/2000], Avg Val Loss: 2.2867\n",
      "Validation loss improved from 2.2870 to 2.2867. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6870\n",
      "Epoch [1127/2000], Avg Train Loss: 3.6870\n",
      "Epoch [1127/2000], Avg Val Loss: 2.2864\n",
      "Validation loss improved from 2.2867 to 2.2864. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7594\n",
      "Epoch [1128/2000], Avg Train Loss: 3.7594\n",
      "Epoch [1128/2000], Avg Val Loss: 2.2862\n",
      "Validation loss improved from 2.2864 to 2.2862. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6685\n",
      "Epoch [1129/2000], Avg Train Loss: 3.6685\n",
      "Epoch [1129/2000], Avg Val Loss: 2.2861\n",
      "Validation loss improved from 2.2862 to 2.2861. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7240\n",
      "Epoch [1130/2000], Avg Train Loss: 3.7240\n",
      "Epoch [1130/2000], Avg Val Loss: 2.2860\n",
      "Validation loss improved from 2.2861 to 2.2860. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7128\n",
      "Epoch [1131/2000], Avg Train Loss: 3.7128\n",
      "Epoch [1131/2000], Avg Val Loss: 2.2859\n",
      "Validation loss improved from 2.2860 to 2.2859. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7072\n",
      "Epoch [1132/2000], Avg Train Loss: 3.7072\n",
      "Epoch [1132/2000], Avg Val Loss: 2.2858\n",
      "Validation loss improved from 2.2859 to 2.2858. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7131\n",
      "Epoch [1133/2000], Avg Train Loss: 3.7131\n",
      "Epoch [1133/2000], Avg Val Loss: 2.2856\n",
      "Validation loss improved from 2.2858 to 2.2856. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7119\n",
      "Epoch [1134/2000], Avg Train Loss: 3.7119\n",
      "Epoch [1134/2000], Avg Val Loss: 2.2854\n",
      "Validation loss improved from 2.2856 to 2.2854. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6894\n",
      "Epoch [1135/2000], Avg Train Loss: 3.6894\n",
      "Epoch [1135/2000], Avg Val Loss: 2.2852\n",
      "Validation loss improved from 2.2854 to 2.2852. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7108\n",
      "Epoch [1136/2000], Avg Train Loss: 3.7108\n",
      "Epoch [1136/2000], Avg Val Loss: 2.2850\n",
      "Validation loss improved from 2.2852 to 2.2850. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6639\n",
      "Epoch [1137/2000], Avg Train Loss: 3.6639\n",
      "Epoch [1137/2000], Avg Val Loss: 2.2849\n",
      "Validation loss improved from 2.2850 to 2.2849. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7037\n",
      "Epoch [1138/2000], Avg Train Loss: 3.7037\n",
      "Epoch [1138/2000], Avg Val Loss: 2.2850\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7072\n",
      "Epoch [1139/2000], Avg Train Loss: 3.7072\n",
      "Epoch [1139/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6694\n",
      "Epoch [1140/2000], Avg Train Loss: 3.6694\n",
      "Epoch [1140/2000], Avg Val Loss: 2.2852\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7039\n",
      "Epoch [1141/2000], Avg Train Loss: 3.7039\n",
      "Epoch [1141/2000], Avg Val Loss: 2.2853\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7113\n",
      "Epoch [1142/2000], Avg Train Loss: 3.7113\n",
      "Epoch [1142/2000], Avg Val Loss: 2.2853\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6965\n",
      "Epoch [1143/2000], Avg Train Loss: 3.6965\n",
      "Epoch [1143/2000], Avg Val Loss: 2.2852\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7424\n",
      "Epoch [1144/2000], Avg Train Loss: 3.7424\n",
      "Epoch [1144/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6983\n",
      "Epoch [1145/2000], Avg Train Loss: 3.6983\n",
      "Epoch [1145/2000], Avg Val Loss: 2.2850\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6891\n",
      "Epoch [1146/2000], Avg Train Loss: 3.6891\n",
      "Epoch [1146/2000], Avg Val Loss: 2.2850\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7056\n",
      "Epoch [1147/2000], Avg Train Loss: 3.7056\n",
      "Epoch [1147/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6927\n",
      "Epoch [1148/2000], Avg Train Loss: 3.6927\n",
      "Epoch [1148/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6910\n",
      "Epoch [1149/2000], Avg Train Loss: 3.6910\n",
      "Epoch [1149/2000], Avg Val Loss: 2.2852\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6792\n",
      "Epoch [1150/2000], Avg Train Loss: 3.6792\n",
      "Epoch [1150/2000], Avg Val Loss: 2.2852\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6946\n",
      "Epoch [1151/2000], Avg Train Loss: 3.6946\n",
      "Epoch [1151/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6615\n",
      "Epoch [1152/2000], Avg Train Loss: 3.6615\n",
      "Epoch [1152/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7164\n",
      "Epoch [1153/2000], Avg Train Loss: 3.7164\n",
      "Epoch [1153/2000], Avg Val Loss: 2.2851\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6985\n",
      "Epoch [1154/2000], Avg Train Loss: 3.6985\n",
      "Epoch [1154/2000], Avg Val Loss: 2.2848\n",
      "Validation loss improved from 2.2849 to 2.2848. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6718\n",
      "Epoch [1155/2000], Avg Train Loss: 3.6718\n",
      "Epoch [1155/2000], Avg Val Loss: 2.2846\n",
      "Validation loss improved from 2.2848 to 2.2846. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6996\n",
      "Epoch [1156/2000], Avg Train Loss: 3.6996\n",
      "Epoch [1156/2000], Avg Val Loss: 2.2842\n",
      "Validation loss improved from 2.2846 to 2.2842. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6964\n",
      "Epoch [1157/2000], Avg Train Loss: 3.6964\n",
      "Epoch [1157/2000], Avg Val Loss: 2.2839\n",
      "Validation loss improved from 2.2842 to 2.2839. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6810\n",
      "Epoch [1158/2000], Avg Train Loss: 3.6810\n",
      "Epoch [1158/2000], Avg Val Loss: 2.2836\n",
      "Validation loss improved from 2.2839 to 2.2836. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6660\n",
      "Epoch [1159/2000], Avg Train Loss: 3.6660\n",
      "Epoch [1159/2000], Avg Val Loss: 2.2834\n",
      "Validation loss improved from 2.2836 to 2.2834. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7340\n",
      "Epoch [1160/2000], Avg Train Loss: 3.7340\n",
      "Epoch [1160/2000], Avg Val Loss: 2.2833\n",
      "Validation loss improved from 2.2834 to 2.2833. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6885\n",
      "Epoch [1161/2000], Avg Train Loss: 3.6885\n",
      "Epoch [1161/2000], Avg Val Loss: 2.2832\n",
      "Validation loss improved from 2.2833 to 2.2832. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7066\n",
      "Epoch [1162/2000], Avg Train Loss: 3.7066\n",
      "Epoch [1162/2000], Avg Val Loss: 2.2832\n",
      "Validation loss improved from 2.2832 to 2.2832. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6637\n",
      "Epoch [1163/2000], Avg Train Loss: 3.6637\n",
      "Epoch [1163/2000], Avg Val Loss: 2.2831\n",
      "Validation loss improved from 2.2832 to 2.2831. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6788\n",
      "Epoch [1164/2000], Avg Train Loss: 3.6788\n",
      "Epoch [1164/2000], Avg Val Loss: 2.2830\n",
      "Validation loss improved from 2.2831 to 2.2830. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7084\n",
      "Epoch [1165/2000], Avg Train Loss: 3.7084\n",
      "Epoch [1165/2000], Avg Val Loss: 2.2830\n",
      "Validation loss improved from 2.2830 to 2.2830. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7046\n",
      "Epoch [1166/2000], Avg Train Loss: 3.7046\n",
      "Epoch [1166/2000], Avg Val Loss: 2.2829\n",
      "Validation loss improved from 2.2830 to 2.2829. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6777\n",
      "Epoch [1167/2000], Avg Train Loss: 3.6777\n",
      "Epoch [1167/2000], Avg Val Loss: 2.2828\n",
      "Validation loss improved from 2.2829 to 2.2828. Saving model...\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6783\n",
      "Epoch [1168/2000], Avg Train Loss: 3.6783\n",
      "Epoch [1168/2000], Avg Val Loss: 2.2828\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6757\n",
      "Epoch [1169/2000], Avg Train Loss: 3.6757\n",
      "Epoch [1169/2000], Avg Val Loss: 2.2828\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7153\n",
      "Epoch [1170/2000], Avg Train Loss: 3.7153\n",
      "Epoch [1170/2000], Avg Val Loss: 2.2828\n",
      "Validation loss improved from 2.2828 to 2.2828. Saving model...\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6842\n",
      "Epoch [1171/2000], Avg Train Loss: 3.6842\n",
      "Epoch [1171/2000], Avg Val Loss: 2.2827\n",
      "Validation loss improved from 2.2828 to 2.2827. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6777\n",
      "Epoch [1172/2000], Avg Train Loss: 3.6777\n",
      "Epoch [1172/2000], Avg Val Loss: 2.2829\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7296\n",
      "Epoch [1173/2000], Avg Train Loss: 3.7296\n",
      "Epoch [1173/2000], Avg Val Loss: 2.2831\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6861\n",
      "Epoch [1174/2000], Avg Train Loss: 3.6861\n",
      "Epoch [1174/2000], Avg Val Loss: 2.2833\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6890\n",
      "Epoch [1175/2000], Avg Train Loss: 3.6890\n",
      "Epoch [1175/2000], Avg Val Loss: 2.2834\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6506\n",
      "Epoch [1176/2000], Avg Train Loss: 3.6506\n",
      "Epoch [1176/2000], Avg Val Loss: 2.2835\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6655\n",
      "Epoch [1177/2000], Avg Train Loss: 3.6655\n",
      "Epoch [1177/2000], Avg Val Loss: 2.2834\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6701\n",
      "Epoch [1178/2000], Avg Train Loss: 3.6701\n",
      "Epoch [1178/2000], Avg Val Loss: 2.2834\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6935\n",
      "Epoch [1179/2000], Avg Train Loss: 3.6935\n",
      "Epoch [1179/2000], Avg Val Loss: 2.2832\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6626\n",
      "Epoch [1180/2000], Avg Train Loss: 3.6626\n",
      "Epoch [1180/2000], Avg Val Loss: 2.2829\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6842\n",
      "Epoch [1181/2000], Avg Train Loss: 3.6842\n",
      "Epoch [1181/2000], Avg Val Loss: 2.2825\n",
      "Validation loss improved from 2.2827 to 2.2825. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6882\n",
      "Epoch [1182/2000], Avg Train Loss: 3.6882\n",
      "Epoch [1182/2000], Avg Val Loss: 2.2823\n",
      "Validation loss improved from 2.2825 to 2.2823. Saving model...\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6541\n",
      "Epoch [1183/2000], Avg Train Loss: 3.6541\n",
      "Epoch [1183/2000], Avg Val Loss: 2.2820\n",
      "Validation loss improved from 2.2823 to 2.2820. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7207\n",
      "Epoch [1184/2000], Avg Train Loss: 3.7207\n",
      "Epoch [1184/2000], Avg Val Loss: 2.2817\n",
      "Validation loss improved from 2.2820 to 2.2817. Saving model...\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6815\n",
      "Epoch [1185/2000], Avg Train Loss: 3.6815\n",
      "Epoch [1185/2000], Avg Val Loss: 2.2814\n",
      "Validation loss improved from 2.2817 to 2.2814. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6925\n",
      "Epoch [1186/2000], Avg Train Loss: 3.6925\n",
      "Epoch [1186/2000], Avg Val Loss: 2.2812\n",
      "Validation loss improved from 2.2814 to 2.2812. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6739\n",
      "Epoch [1187/2000], Avg Train Loss: 3.6739\n",
      "Epoch [1187/2000], Avg Val Loss: 2.2809\n",
      "Validation loss improved from 2.2812 to 2.2809. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6671\n",
      "Epoch [1188/2000], Avg Train Loss: 3.6671\n",
      "Epoch [1188/2000], Avg Val Loss: 2.2806\n",
      "Validation loss improved from 2.2809 to 2.2806. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6362\n",
      "Epoch [1189/2000], Avg Train Loss: 3.6362\n",
      "Epoch [1189/2000], Avg Val Loss: 2.2801\n",
      "Validation loss improved from 2.2806 to 2.2801. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6895\n",
      "Epoch [1190/2000], Avg Train Loss: 3.6895\n",
      "Epoch [1190/2000], Avg Val Loss: 2.2797\n",
      "Validation loss improved from 2.2801 to 2.2797. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6697\n",
      "Epoch [1191/2000], Avg Train Loss: 3.6697\n",
      "Epoch [1191/2000], Avg Val Loss: 2.2793\n",
      "Validation loss improved from 2.2797 to 2.2793. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6755\n",
      "Epoch [1192/2000], Avg Train Loss: 3.6755\n",
      "Epoch [1192/2000], Avg Val Loss: 2.2788\n",
      "Validation loss improved from 2.2793 to 2.2788. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6834\n",
      "Epoch [1193/2000], Avg Train Loss: 3.6834\n",
      "Epoch [1193/2000], Avg Val Loss: 2.2784\n",
      "Validation loss improved from 2.2788 to 2.2784. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6687\n",
      "Epoch [1194/2000], Avg Train Loss: 3.6687\n",
      "Epoch [1194/2000], Avg Val Loss: 2.2780\n",
      "Validation loss improved from 2.2784 to 2.2780. Saving model...\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6860\n",
      "Epoch [1195/2000], Avg Train Loss: 3.6860\n",
      "Epoch [1195/2000], Avg Val Loss: 2.2777\n",
      "Validation loss improved from 2.2780 to 2.2777. Saving model...\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6880\n",
      "Epoch [1196/2000], Avg Train Loss: 3.6880\n",
      "Epoch [1196/2000], Avg Val Loss: 2.2773\n",
      "Validation loss improved from 2.2777 to 2.2773. Saving model...\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7003\n",
      "Epoch [1197/2000], Avg Train Loss: 3.7003\n",
      "Epoch [1197/2000], Avg Val Loss: 2.2771\n",
      "Validation loss improved from 2.2773 to 2.2771. Saving model...\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7067\n",
      "Epoch [1198/2000], Avg Train Loss: 3.7067\n",
      "Epoch [1198/2000], Avg Val Loss: 2.2768\n",
      "Validation loss improved from 2.2771 to 2.2768. Saving model...\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6735\n",
      "Epoch [1199/2000], Avg Train Loss: 3.6735\n",
      "Epoch [1199/2000], Avg Val Loss: 2.2765\n",
      "Validation loss improved from 2.2768 to 2.2765. Saving model...\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6916\n",
      "Epoch [1200/2000], Avg Train Loss: 3.6916\n",
      "Epoch [1200/2000], Avg Val Loss: 2.2761\n",
      "Validation loss improved from 2.2765 to 2.2761. Saving model...\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6723\n",
      "Epoch [1201/2000], Avg Train Loss: 3.6723\n",
      "Epoch [1201/2000], Avg Val Loss: 2.2757\n",
      "Validation loss improved from 2.2761 to 2.2757. Saving model...\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6688\n",
      "Epoch [1202/2000], Avg Train Loss: 3.6688\n",
      "Epoch [1202/2000], Avg Val Loss: 2.2755\n",
      "Validation loss improved from 2.2757 to 2.2755. Saving model...\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6717\n",
      "Epoch [1203/2000], Avg Train Loss: 3.6717\n",
      "Epoch [1203/2000], Avg Val Loss: 2.2752\n",
      "Validation loss improved from 2.2755 to 2.2752. Saving model...\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6869\n",
      "Epoch [1204/2000], Avg Train Loss: 3.6869\n",
      "Epoch [1204/2000], Avg Val Loss: 2.2749\n",
      "Validation loss improved from 2.2752 to 2.2749. Saving model...\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6934\n",
      "Epoch [1205/2000], Avg Train Loss: 3.6934\n",
      "Epoch [1205/2000], Avg Val Loss: 2.2747\n",
      "Validation loss improved from 2.2749 to 2.2747. Saving model...\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6765\n",
      "Epoch [1206/2000], Avg Train Loss: 3.6765\n",
      "Epoch [1206/2000], Avg Val Loss: 2.2744\n",
      "Validation loss improved from 2.2747 to 2.2744. Saving model...\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6751\n",
      "Epoch [1207/2000], Avg Train Loss: 3.6751\n",
      "Epoch [1207/2000], Avg Val Loss: 2.2743\n",
      "Validation loss improved from 2.2744 to 2.2743. Saving model...\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6705\n",
      "Epoch [1208/2000], Avg Train Loss: 3.6705\n",
      "Epoch [1208/2000], Avg Val Loss: 2.2741\n",
      "Validation loss improved from 2.2743 to 2.2741. Saving model...\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6339\n",
      "Epoch [1209/2000], Avg Train Loss: 3.6339\n",
      "Epoch [1209/2000], Avg Val Loss: 2.2740\n",
      "Validation loss improved from 2.2741 to 2.2740. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6327\n",
      "Epoch [1210/2000], Avg Train Loss: 3.6327\n",
      "Epoch [1210/2000], Avg Val Loss: 2.2739\n",
      "Validation loss improved from 2.2740 to 2.2739. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6677\n",
      "Epoch [1211/2000], Avg Train Loss: 3.6677\n",
      "Epoch [1211/2000], Avg Val Loss: 2.2737\n",
      "Validation loss improved from 2.2739 to 2.2737. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6686\n",
      "Epoch [1212/2000], Avg Train Loss: 3.6686\n",
      "Epoch [1212/2000], Avg Val Loss: 2.2735\n",
      "Validation loss improved from 2.2737 to 2.2735. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6672\n",
      "Epoch [1213/2000], Avg Train Loss: 3.6672\n",
      "Epoch [1213/2000], Avg Val Loss: 2.2733\n",
      "Validation loss improved from 2.2735 to 2.2733. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6594\n",
      "Epoch [1214/2000], Avg Train Loss: 3.6594\n",
      "Epoch [1214/2000], Avg Val Loss: 2.2730\n",
      "Validation loss improved from 2.2733 to 2.2730. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6578\n",
      "Epoch [1215/2000], Avg Train Loss: 3.6578\n",
      "Epoch [1215/2000], Avg Val Loss: 2.2727\n",
      "Validation loss improved from 2.2730 to 2.2727. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6597\n",
      "Epoch [1216/2000], Avg Train Loss: 3.6597\n",
      "Epoch [1216/2000], Avg Val Loss: 2.2724\n",
      "Validation loss improved from 2.2727 to 2.2724. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6797\n",
      "Epoch [1217/2000], Avg Train Loss: 3.6797\n",
      "Epoch [1217/2000], Avg Val Loss: 2.2721\n",
      "Validation loss improved from 2.2724 to 2.2721. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6617\n",
      "Epoch [1218/2000], Avg Train Loss: 3.6617\n",
      "Epoch [1218/2000], Avg Val Loss: 2.2717\n",
      "Validation loss improved from 2.2721 to 2.2717. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6908\n",
      "Epoch [1219/2000], Avg Train Loss: 3.6908\n",
      "Epoch [1219/2000], Avg Val Loss: 2.2714\n",
      "Validation loss improved from 2.2717 to 2.2714. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6701\n",
      "Epoch [1220/2000], Avg Train Loss: 3.6701\n",
      "Epoch [1220/2000], Avg Val Loss: 2.2710\n",
      "Validation loss improved from 2.2714 to 2.2710. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6499\n",
      "Epoch [1221/2000], Avg Train Loss: 3.6499\n",
      "Epoch [1221/2000], Avg Val Loss: 2.2707\n",
      "Validation loss improved from 2.2710 to 2.2707. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6832\n",
      "Epoch [1222/2000], Avg Train Loss: 3.6832\n",
      "Epoch [1222/2000], Avg Val Loss: 2.2703\n",
      "Validation loss improved from 2.2707 to 2.2703. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6951\n",
      "Epoch [1223/2000], Avg Train Loss: 3.6951\n",
      "Epoch [1223/2000], Avg Val Loss: 2.2700\n",
      "Validation loss improved from 2.2703 to 2.2700. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6680\n",
      "Epoch [1224/2000], Avg Train Loss: 3.6680\n",
      "Epoch [1224/2000], Avg Val Loss: 2.2698\n",
      "Validation loss improved from 2.2700 to 2.2698. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6608\n",
      "Epoch [1225/2000], Avg Train Loss: 3.6608\n",
      "Epoch [1225/2000], Avg Val Loss: 2.2697\n",
      "Validation loss improved from 2.2698 to 2.2697. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6757\n",
      "Epoch [1226/2000], Avg Train Loss: 3.6757\n",
      "Epoch [1226/2000], Avg Val Loss: 2.2697\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6718\n",
      "Epoch [1227/2000], Avg Train Loss: 3.6718\n",
      "Epoch [1227/2000], Avg Val Loss: 2.2696\n",
      "Validation loss improved from 2.2697 to 2.2696. Saving model...\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6518\n",
      "Epoch [1228/2000], Avg Train Loss: 3.6518\n",
      "Epoch [1228/2000], Avg Val Loss: 2.2695\n",
      "Validation loss improved from 2.2696 to 2.2695. Saving model...\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6623\n",
      "Epoch [1229/2000], Avg Train Loss: 3.6623\n",
      "Epoch [1229/2000], Avg Val Loss: 2.2695\n",
      "Validation loss improved from 2.2695 to 2.2695. Saving model...\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6419\n",
      "Epoch [1230/2000], Avg Train Loss: 3.6419\n",
      "Epoch [1230/2000], Avg Val Loss: 2.2695\n",
      "Validation loss improved from 2.2695 to 2.2695. Saving model...\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6488\n",
      "Epoch [1231/2000], Avg Train Loss: 3.6488\n",
      "Epoch [1231/2000], Avg Val Loss: 2.2694\n",
      "Validation loss improved from 2.2695 to 2.2694. Saving model...\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6551\n",
      "Epoch [1232/2000], Avg Train Loss: 3.6551\n",
      "Epoch [1232/2000], Avg Val Loss: 2.2693\n",
      "Validation loss improved from 2.2694 to 2.2693. Saving model...\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6815\n",
      "Epoch [1233/2000], Avg Train Loss: 3.6815\n",
      "Epoch [1233/2000], Avg Val Loss: 2.2693\n",
      "Validation loss improved from 2.2693 to 2.2693. Saving model...\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6565\n",
      "Epoch [1234/2000], Avg Train Loss: 3.6565\n",
      "Epoch [1234/2000], Avg Val Loss: 2.2693\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6597\n",
      "Epoch [1235/2000], Avg Train Loss: 3.6597\n",
      "Epoch [1235/2000], Avg Val Loss: 2.2695\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6873\n",
      "Epoch [1236/2000], Avg Train Loss: 3.6873\n",
      "Epoch [1236/2000], Avg Val Loss: 2.2696\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6643\n",
      "Epoch [1237/2000], Avg Train Loss: 3.6643\n",
      "Epoch [1237/2000], Avg Val Loss: 2.2697\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6642\n",
      "Epoch [1238/2000], Avg Train Loss: 3.6642\n",
      "Epoch [1238/2000], Avg Val Loss: 2.2699\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6519\n",
      "Epoch [1239/2000], Avg Train Loss: 3.6519\n",
      "Epoch [1239/2000], Avg Val Loss: 2.2700\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6639\n",
      "Epoch [1240/2000], Avg Train Loss: 3.6639\n",
      "Epoch [1240/2000], Avg Val Loss: 2.2702\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6812\n",
      "Epoch [1241/2000], Avg Train Loss: 3.6812\n",
      "Epoch [1241/2000], Avg Val Loss: 2.2703\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6341\n",
      "Epoch [1242/2000], Avg Train Loss: 3.6341\n",
      "Epoch [1242/2000], Avg Val Loss: 2.2704\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6653\n",
      "Epoch [1243/2000], Avg Train Loss: 3.6653\n",
      "Epoch [1243/2000], Avg Val Loss: 2.2705\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6944\n",
      "Epoch [1244/2000], Avg Train Loss: 3.6944\n",
      "Epoch [1244/2000], Avg Val Loss: 2.2705\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6708\n",
      "Epoch [1245/2000], Avg Train Loss: 3.6708\n",
      "Epoch [1245/2000], Avg Val Loss: 2.2706\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7103\n",
      "Epoch [1246/2000], Avg Train Loss: 3.7103\n",
      "Epoch [1246/2000], Avg Val Loss: 2.2707\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6701\n",
      "Epoch [1247/2000], Avg Train Loss: 3.6701\n",
      "Epoch [1247/2000], Avg Val Loss: 2.2709\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6660\n",
      "Epoch [1248/2000], Avg Train Loss: 3.6660\n",
      "Epoch [1248/2000], Avg Val Loss: 2.2711\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6846\n",
      "Epoch [1249/2000], Avg Train Loss: 3.6846\n",
      "Epoch [1249/2000], Avg Val Loss: 2.2715\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6553\n",
      "Epoch [1250/2000], Avg Train Loss: 3.6553\n",
      "Epoch [1250/2000], Avg Val Loss: 2.2718\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6569\n",
      "Epoch [1251/2000], Avg Train Loss: 3.6569\n",
      "Epoch [1251/2000], Avg Val Loss: 2.2722\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6727\n",
      "Epoch [1252/2000], Avg Train Loss: 3.6727\n",
      "Epoch [1252/2000], Avg Val Loss: 2.2725\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6581\n",
      "Epoch [1253/2000], Avg Train Loss: 3.6581\n",
      "Epoch [1253/2000], Avg Val Loss: 2.2727\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6372\n",
      "Epoch [1254/2000], Avg Train Loss: 3.6372\n",
      "Epoch [1254/2000], Avg Val Loss: 2.2729\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6580\n",
      "Epoch [1255/2000], Avg Train Loss: 3.6580\n",
      "Epoch [1255/2000], Avg Val Loss: 2.2730\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6820\n",
      "Epoch [1256/2000], Avg Train Loss: 3.6820\n",
      "Epoch [1256/2000], Avg Val Loss: 2.2731\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6195\n",
      "Epoch [1257/2000], Avg Train Loss: 3.6195\n",
      "Epoch [1257/2000], Avg Val Loss: 2.2732\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6719\n",
      "Epoch [1258/2000], Avg Train Loss: 3.6719\n",
      "Epoch [1258/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6438\n",
      "Epoch [1259/2000], Avg Train Loss: 3.6438\n",
      "Epoch [1259/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6465\n",
      "Epoch [1260/2000], Avg Train Loss: 3.6465\n",
      "Epoch [1260/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6751\n",
      "Epoch [1261/2000], Avg Train Loss: 3.6751\n",
      "Epoch [1261/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6518\n",
      "Epoch [1262/2000], Avg Train Loss: 3.6518\n",
      "Epoch [1262/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7072\n",
      "Epoch [1263/2000], Avg Train Loss: 3.7072\n",
      "Epoch [1263/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6675\n",
      "Epoch [1264/2000], Avg Train Loss: 3.6675\n",
      "Epoch [1264/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6231\n",
      "Epoch [1265/2000], Avg Train Loss: 3.6231\n",
      "Epoch [1265/2000], Avg Val Loss: 2.2735\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6764\n",
      "Epoch [1266/2000], Avg Train Loss: 3.6764\n",
      "Epoch [1266/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6267\n",
      "Epoch [1267/2000], Avg Train Loss: 3.6267\n",
      "Epoch [1267/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6295\n",
      "Epoch [1268/2000], Avg Train Loss: 3.6295\n",
      "Epoch [1268/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6620\n",
      "Epoch [1269/2000], Avg Train Loss: 3.6620\n",
      "Epoch [1269/2000], Avg Val Loss: 2.2733\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6456\n",
      "Epoch [1270/2000], Avg Train Loss: 3.6456\n",
      "Epoch [1270/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6626\n",
      "Epoch [1271/2000], Avg Train Loss: 3.6626\n",
      "Epoch [1271/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6653\n",
      "Epoch [1272/2000], Avg Train Loss: 3.6653\n",
      "Epoch [1272/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6470\n",
      "Epoch [1273/2000], Avg Train Loss: 3.6470\n",
      "Epoch [1273/2000], Avg Val Loss: 2.2734\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6738\n",
      "Epoch [1274/2000], Avg Train Loss: 3.6738\n",
      "Epoch [1274/2000], Avg Val Loss: 2.2732\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6485\n",
      "Epoch [1275/2000], Avg Train Loss: 3.6485\n",
      "Epoch [1275/2000], Avg Val Loss: 2.2729\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6559\n",
      "Epoch [1276/2000], Avg Train Loss: 3.6559\n",
      "Epoch [1276/2000], Avg Val Loss: 2.2727\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6565\n",
      "Epoch [1277/2000], Avg Train Loss: 3.6565\n",
      "Epoch [1277/2000], Avg Val Loss: 2.2726\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6381\n",
      "Epoch [1278/2000], Avg Train Loss: 3.6381\n",
      "Epoch [1278/2000], Avg Val Loss: 2.2725\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6436\n",
      "Epoch [1279/2000], Avg Train Loss: 3.6436\n",
      "Epoch [1279/2000], Avg Val Loss: 2.2725\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6390\n",
      "Epoch [1280/2000], Avg Train Loss: 3.6390\n",
      "Epoch [1280/2000], Avg Val Loss: 2.2725\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6663\n",
      "Epoch [1281/2000], Avg Train Loss: 3.6663\n",
      "Epoch [1281/2000], Avg Val Loss: 2.2725\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6587\n",
      "Epoch [1282/2000], Avg Train Loss: 3.6587\n",
      "Epoch [1282/2000], Avg Val Loss: 2.2724\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6616\n",
      "Epoch [1283/2000], Avg Train Loss: 3.6616\n",
      "Epoch [1283/2000], Avg Val Loss: 2.2723\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6210\n",
      "Epoch [1284/2000], Avg Train Loss: 3.6210\n",
      "Epoch [1284/2000], Avg Val Loss: 2.2723\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6324\n",
      "Epoch [1285/2000], Avg Train Loss: 3.6324\n",
      "Epoch [1285/2000], Avg Val Loss: 2.2723\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6420\n",
      "Epoch [1286/2000], Avg Train Loss: 3.6420\n",
      "Epoch [1286/2000], Avg Val Loss: 2.2723\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6774\n",
      "Epoch [1287/2000], Avg Train Loss: 3.6774\n",
      "Epoch [1287/2000], Avg Val Loss: 2.2722\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6577\n",
      "Epoch [1288/2000], Avg Train Loss: 3.6577\n",
      "Epoch [1288/2000], Avg Val Loss: 2.2720\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6330\n",
      "Epoch [1289/2000], Avg Train Loss: 3.6330\n",
      "Epoch [1289/2000], Avg Val Loss: 2.2719\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6768\n",
      "Epoch [1290/2000], Avg Train Loss: 3.6768\n",
      "Epoch [1290/2000], Avg Val Loss: 2.2717\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6578\n",
      "Epoch [1291/2000], Avg Train Loss: 3.6578\n",
      "Epoch [1291/2000], Avg Val Loss: 2.2716\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6293\n",
      "Epoch [1292/2000], Avg Train Loss: 3.6293\n",
      "Epoch [1292/2000], Avg Val Loss: 2.2715\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6685\n",
      "Epoch [1293/2000], Avg Train Loss: 3.6685\n",
      "Epoch [1293/2000], Avg Val Loss: 2.2714\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6488\n",
      "Epoch [1294/2000], Avg Train Loss: 3.6488\n",
      "Epoch [1294/2000], Avg Val Loss: 2.2712\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6275\n",
      "Epoch [1295/2000], Avg Train Loss: 3.6275\n",
      "Epoch [1295/2000], Avg Val Loss: 2.2710\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6621\n",
      "Epoch [1296/2000], Avg Train Loss: 3.6621\n",
      "Epoch [1296/2000], Avg Val Loss: 2.2709\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6338\n",
      "Epoch [1297/2000], Avg Train Loss: 3.6338\n",
      "Epoch [1297/2000], Avg Val Loss: 2.2708\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6382\n",
      "Epoch [1298/2000], Avg Train Loss: 3.6382\n",
      "Epoch [1298/2000], Avg Val Loss: 2.2707\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6450\n",
      "Epoch [1299/2000], Avg Train Loss: 3.6450\n",
      "Epoch [1299/2000], Avg Val Loss: 2.2704\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6137\n",
      "Epoch [1300/2000], Avg Train Loss: 3.6137\n",
      "Epoch [1300/2000], Avg Val Loss: 2.2699\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6197\n",
      "Epoch [1301/2000], Avg Train Loss: 3.6197\n",
      "Epoch [1301/2000], Avg Val Loss: 2.2696\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6321\n",
      "Epoch [1302/2000], Avg Train Loss: 3.6321\n",
      "Epoch [1302/2000], Avg Val Loss: 2.2694\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6433\n",
      "Epoch [1303/2000], Avg Train Loss: 3.6433\n",
      "Epoch [1303/2000], Avg Val Loss: 2.2692\n",
      "Validation loss improved from 2.2693 to 2.2692. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6222\n",
      "Epoch [1304/2000], Avg Train Loss: 3.6222\n",
      "Epoch [1304/2000], Avg Val Loss: 2.2691\n",
      "Validation loss improved from 2.2692 to 2.2691. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6742\n",
      "Epoch [1305/2000], Avg Train Loss: 3.6742\n",
      "Epoch [1305/2000], Avg Val Loss: 2.2691\n",
      "Validation loss improved from 2.2691 to 2.2691. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6464\n",
      "Epoch [1306/2000], Avg Train Loss: 3.6464\n",
      "Epoch [1306/2000], Avg Val Loss: 2.2690\n",
      "Validation loss improved from 2.2691 to 2.2690. Saving model...\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6334\n",
      "Epoch [1307/2000], Avg Train Loss: 3.6334\n",
      "Epoch [1307/2000], Avg Val Loss: 2.2689\n",
      "Validation loss improved from 2.2690 to 2.2689. Saving model...\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6550\n",
      "Epoch [1308/2000], Avg Train Loss: 3.6550\n",
      "Epoch [1308/2000], Avg Val Loss: 2.2688\n",
      "Validation loss improved from 2.2689 to 2.2688. Saving model...\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6795\n",
      "Epoch [1309/2000], Avg Train Loss: 3.6795\n",
      "Epoch [1309/2000], Avg Val Loss: 2.2688\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6658\n",
      "Epoch [1310/2000], Avg Train Loss: 3.6658\n",
      "Epoch [1310/2000], Avg Val Loss: 2.2688\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6357\n",
      "Epoch [1311/2000], Avg Train Loss: 3.6357\n",
      "Epoch [1311/2000], Avg Val Loss: 2.2688\n",
      "Validation loss improved from 2.2688 to 2.2688. Saving model...\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6649\n",
      "Epoch [1312/2000], Avg Train Loss: 3.6649\n",
      "Epoch [1312/2000], Avg Val Loss: 2.2686\n",
      "Validation loss improved from 2.2688 to 2.2686. Saving model...\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6100\n",
      "Epoch [1313/2000], Avg Train Loss: 3.6100\n",
      "Epoch [1313/2000], Avg Val Loss: 2.2684\n",
      "Validation loss improved from 2.2686 to 2.2684. Saving model...\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6461\n",
      "Epoch [1314/2000], Avg Train Loss: 3.6461\n",
      "Epoch [1314/2000], Avg Val Loss: 2.2683\n",
      "Validation loss improved from 2.2684 to 2.2683. Saving model...\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6626\n",
      "Epoch [1315/2000], Avg Train Loss: 3.6626\n",
      "Epoch [1315/2000], Avg Val Loss: 2.2682\n",
      "Validation loss improved from 2.2683 to 2.2682. Saving model...\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5932\n",
      "Epoch [1316/2000], Avg Train Loss: 3.5932\n",
      "Epoch [1316/2000], Avg Val Loss: 2.2680\n",
      "Validation loss improved from 2.2682 to 2.2680. Saving model...\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6345\n",
      "Epoch [1317/2000], Avg Train Loss: 3.6345\n",
      "Epoch [1317/2000], Avg Val Loss: 2.2678\n",
      "Validation loss improved from 2.2680 to 2.2678. Saving model...\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6356\n",
      "Epoch [1318/2000], Avg Train Loss: 3.6356\n",
      "Epoch [1318/2000], Avg Val Loss: 2.2678\n",
      "Validation loss improved from 2.2678 to 2.2678. Saving model...\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6277\n",
      "Epoch [1319/2000], Avg Train Loss: 3.6277\n",
      "Epoch [1319/2000], Avg Val Loss: 2.2677\n",
      "Validation loss improved from 2.2678 to 2.2677. Saving model...\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6251\n",
      "Epoch [1320/2000], Avg Train Loss: 3.6251\n",
      "Epoch [1320/2000], Avg Val Loss: 2.2676\n",
      "Validation loss improved from 2.2677 to 2.2676. Saving model...\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6276\n",
      "Epoch [1321/2000], Avg Train Loss: 3.6276\n",
      "Epoch [1321/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6196\n",
      "Epoch [1322/2000], Avg Train Loss: 3.6196\n",
      "Epoch [1322/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6433\n",
      "Epoch [1323/2000], Avg Train Loss: 3.6433\n",
      "Epoch [1323/2000], Avg Val Loss: 2.2676\n",
      "Validation loss improved from 2.2676 to 2.2676. Saving model...\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6499\n",
      "Epoch [1324/2000], Avg Train Loss: 3.6499\n",
      "Epoch [1324/2000], Avg Val Loss: 2.2676\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6320\n",
      "Epoch [1325/2000], Avg Train Loss: 3.6320\n",
      "Epoch [1325/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6357\n",
      "Epoch [1326/2000], Avg Train Loss: 3.6357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1326/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6197\n",
      "Epoch [1327/2000], Avg Train Loss: 3.6197\n",
      "Epoch [1327/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6113\n",
      "Epoch [1328/2000], Avg Train Loss: 3.6113\n",
      "Epoch [1328/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6214\n",
      "Epoch [1329/2000], Avg Train Loss: 3.6214\n",
      "Epoch [1329/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6171\n",
      "Epoch [1330/2000], Avg Train Loss: 3.6171\n",
      "Epoch [1330/2000], Avg Val Loss: 2.2677\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6162\n",
      "Epoch [1331/2000], Avg Train Loss: 3.6162\n",
      "Epoch [1331/2000], Avg Val Loss: 2.2676\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6751\n",
      "Epoch [1332/2000], Avg Train Loss: 3.6751\n",
      "Epoch [1332/2000], Avg Val Loss: 2.2675\n",
      "Validation loss improved from 2.2676 to 2.2675. Saving model...\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6178\n",
      "Epoch [1333/2000], Avg Train Loss: 3.6178\n",
      "Epoch [1333/2000], Avg Val Loss: 2.2673\n",
      "Validation loss improved from 2.2675 to 2.2673. Saving model...\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6131\n",
      "Epoch [1334/2000], Avg Train Loss: 3.6131\n",
      "Epoch [1334/2000], Avg Val Loss: 2.2672\n",
      "Validation loss improved from 2.2673 to 2.2672. Saving model...\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6561\n",
      "Epoch [1335/2000], Avg Train Loss: 3.6561\n",
      "Epoch [1335/2000], Avg Val Loss: 2.2670\n",
      "Validation loss improved from 2.2672 to 2.2670. Saving model...\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6371\n",
      "Epoch [1336/2000], Avg Train Loss: 3.6371\n",
      "Epoch [1336/2000], Avg Val Loss: 2.2669\n",
      "Validation loss improved from 2.2670 to 2.2669. Saving model...\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6473\n",
      "Epoch [1337/2000], Avg Train Loss: 3.6473\n",
      "Epoch [1337/2000], Avg Val Loss: 2.2668\n",
      "Validation loss improved from 2.2669 to 2.2668. Saving model...\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6199\n",
      "Epoch [1338/2000], Avg Train Loss: 3.6199\n",
      "Epoch [1338/2000], Avg Val Loss: 2.2666\n",
      "Validation loss improved from 2.2668 to 2.2666. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6166\n",
      "Epoch [1339/2000], Avg Train Loss: 3.6166\n",
      "Epoch [1339/2000], Avg Val Loss: 2.2664\n",
      "Validation loss improved from 2.2666 to 2.2664. Saving model...\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6357\n",
      "Epoch [1340/2000], Avg Train Loss: 3.6357\n",
      "Epoch [1340/2000], Avg Val Loss: 2.2663\n",
      "Validation loss improved from 2.2664 to 2.2663. Saving model...\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5968\n",
      "Epoch [1341/2000], Avg Train Loss: 3.5968\n",
      "Epoch [1341/2000], Avg Val Loss: 2.2661\n",
      "Validation loss improved from 2.2663 to 2.2661. Saving model...\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6210\n",
      "Epoch [1342/2000], Avg Train Loss: 3.6210\n",
      "Epoch [1342/2000], Avg Val Loss: 2.2659\n",
      "Validation loss improved from 2.2661 to 2.2659. Saving model...\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6181\n",
      "Epoch [1343/2000], Avg Train Loss: 3.6181\n",
      "Epoch [1343/2000], Avg Val Loss: 2.2658\n",
      "Validation loss improved from 2.2659 to 2.2658. Saving model...\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6834\n",
      "Epoch [1344/2000], Avg Train Loss: 3.6834\n",
      "Epoch [1344/2000], Avg Val Loss: 2.2656\n",
      "Validation loss improved from 2.2658 to 2.2656. Saving model...\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6324\n",
      "Epoch [1345/2000], Avg Train Loss: 3.6324\n",
      "Epoch [1345/2000], Avg Val Loss: 2.2654\n",
      "Validation loss improved from 2.2656 to 2.2654. Saving model...\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6598\n",
      "Epoch [1346/2000], Avg Train Loss: 3.6598\n",
      "Epoch [1346/2000], Avg Val Loss: 2.2652\n",
      "Validation loss improved from 2.2654 to 2.2652. Saving model...\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6060\n",
      "Epoch [1347/2000], Avg Train Loss: 3.6060\n",
      "Epoch [1347/2000], Avg Val Loss: 2.2652\n",
      "Validation loss improved from 2.2652 to 2.2652. Saving model...\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5995\n",
      "Epoch [1348/2000], Avg Train Loss: 3.5995\n",
      "Epoch [1348/2000], Avg Val Loss: 2.2652\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6533\n",
      "Epoch [1349/2000], Avg Train Loss: 3.6533\n",
      "Epoch [1349/2000], Avg Val Loss: 2.2653\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6065\n",
      "Epoch [1350/2000], Avg Train Loss: 3.6065\n",
      "Epoch [1350/2000], Avg Val Loss: 2.2653\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6184\n",
      "Epoch [1351/2000], Avg Train Loss: 3.6184\n",
      "Epoch [1351/2000], Avg Val Loss: 2.2651\n",
      "Validation loss improved from 2.2652 to 2.2651. Saving model...\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6322\n",
      "Epoch [1352/2000], Avg Train Loss: 3.6322\n",
      "Epoch [1352/2000], Avg Val Loss: 2.2652\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6628\n",
      "Epoch [1353/2000], Avg Train Loss: 3.6628\n",
      "Epoch [1353/2000], Avg Val Loss: 2.2652\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5991\n",
      "Epoch [1354/2000], Avg Train Loss: 3.5991\n",
      "Epoch [1354/2000], Avg Val Loss: 2.2650\n",
      "Validation loss improved from 2.2651 to 2.2650. Saving model...\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6152\n",
      "Epoch [1355/2000], Avg Train Loss: 3.6152\n",
      "Epoch [1355/2000], Avg Val Loss: 2.2649\n",
      "Validation loss improved from 2.2650 to 2.2649. Saving model...\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6098\n",
      "Epoch [1356/2000], Avg Train Loss: 3.6098\n",
      "Epoch [1356/2000], Avg Val Loss: 2.2647\n",
      "Validation loss improved from 2.2649 to 2.2647. Saving model...\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5964\n",
      "Epoch [1357/2000], Avg Train Loss: 3.5964\n",
      "Epoch [1357/2000], Avg Val Loss: 2.2646\n",
      "Validation loss improved from 2.2647 to 2.2646. Saving model...\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6212\n",
      "Epoch [1358/2000], Avg Train Loss: 3.6212\n",
      "Epoch [1358/2000], Avg Val Loss: 2.2646\n",
      "Validation loss improved from 2.2646 to 2.2646. Saving model...\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6342\n",
      "Epoch [1359/2000], Avg Train Loss: 3.6342\n",
      "Epoch [1359/2000], Avg Val Loss: 2.2645\n",
      "Validation loss improved from 2.2646 to 2.2645. Saving model...\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6039\n",
      "Epoch [1360/2000], Avg Train Loss: 3.6039\n",
      "Epoch [1360/2000], Avg Val Loss: 2.2644\n",
      "Validation loss improved from 2.2645 to 2.2644. Saving model...\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5845\n",
      "Epoch [1361/2000], Avg Train Loss: 3.5845\n",
      "Epoch [1361/2000], Avg Val Loss: 2.2644\n",
      "Validation loss improved from 2.2644 to 2.2644. Saving model...\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6410\n",
      "Epoch [1362/2000], Avg Train Loss: 3.6410\n",
      "Epoch [1362/2000], Avg Val Loss: 2.2645\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6071\n",
      "Epoch [1363/2000], Avg Train Loss: 3.6071\n",
      "Epoch [1363/2000], Avg Val Loss: 2.2646\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6142\n",
      "Epoch [1364/2000], Avg Train Loss: 3.6142\n",
      "Epoch [1364/2000], Avg Val Loss: 2.2646\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5912\n",
      "Epoch [1365/2000], Avg Train Loss: 3.5912\n",
      "Epoch [1365/2000], Avg Val Loss: 2.2646\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6255\n",
      "Epoch [1366/2000], Avg Train Loss: 3.6255\n",
      "Epoch [1366/2000], Avg Val Loss: 2.2646\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6409\n",
      "Epoch [1367/2000], Avg Train Loss: 3.6409\n",
      "Epoch [1367/2000], Avg Val Loss: 2.2645\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6272\n",
      "Epoch [1368/2000], Avg Train Loss: 3.6272\n",
      "Epoch [1368/2000], Avg Val Loss: 2.2643\n",
      "Validation loss improved from 2.2644 to 2.2643. Saving model...\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6200\n",
      "Epoch [1369/2000], Avg Train Loss: 3.6200\n",
      "Epoch [1369/2000], Avg Val Loss: 2.2641\n",
      "Validation loss improved from 2.2643 to 2.2641. Saving model...\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6086\n",
      "Epoch [1370/2000], Avg Train Loss: 3.6086\n",
      "Epoch [1370/2000], Avg Val Loss: 2.2637\n",
      "Validation loss improved from 2.2641 to 2.2637. Saving model...\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6269\n",
      "Epoch [1371/2000], Avg Train Loss: 3.6269\n",
      "Epoch [1371/2000], Avg Val Loss: 2.2635\n",
      "Validation loss improved from 2.2637 to 2.2635. Saving model...\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5804\n",
      "Epoch [1372/2000], Avg Train Loss: 3.5804\n",
      "Epoch [1372/2000], Avg Val Loss: 2.2632\n",
      "Validation loss improved from 2.2635 to 2.2632. Saving model...\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6324\n",
      "Epoch [1373/2000], Avg Train Loss: 3.6324\n",
      "Epoch [1373/2000], Avg Val Loss: 2.2630\n",
      "Validation loss improved from 2.2632 to 2.2630. Saving model...\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6144\n",
      "Epoch [1374/2000], Avg Train Loss: 3.6144\n",
      "Epoch [1374/2000], Avg Val Loss: 2.2626\n",
      "Validation loss improved from 2.2630 to 2.2626. Saving model...\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6311\n",
      "Epoch [1375/2000], Avg Train Loss: 3.6311\n",
      "Epoch [1375/2000], Avg Val Loss: 2.2624\n",
      "Validation loss improved from 2.2626 to 2.2624. Saving model...\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5999\n",
      "Epoch [1376/2000], Avg Train Loss: 3.5999\n",
      "Epoch [1376/2000], Avg Val Loss: 2.2622\n",
      "Validation loss improved from 2.2624 to 2.2622. Saving model...\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6345\n",
      "Epoch [1377/2000], Avg Train Loss: 3.6345\n",
      "Epoch [1377/2000], Avg Val Loss: 2.2621\n",
      "Validation loss improved from 2.2622 to 2.2621. Saving model...\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6235\n",
      "Epoch [1378/2000], Avg Train Loss: 3.6235\n",
      "Epoch [1378/2000], Avg Val Loss: 2.2619\n",
      "Validation loss improved from 2.2621 to 2.2619. Saving model...\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5973\n",
      "Epoch [1379/2000], Avg Train Loss: 3.5973\n",
      "Epoch [1379/2000], Avg Val Loss: 2.2619\n",
      "Validation loss improved from 2.2619 to 2.2619. Saving model...\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6214\n",
      "Epoch [1380/2000], Avg Train Loss: 3.6214\n",
      "Epoch [1380/2000], Avg Val Loss: 2.2619\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5902\n",
      "Epoch [1381/2000], Avg Train Loss: 3.5902\n",
      "Epoch [1381/2000], Avg Val Loss: 2.2620\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6004\n",
      "Epoch [1382/2000], Avg Train Loss: 3.6004\n",
      "Epoch [1382/2000], Avg Val Loss: 2.2620\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6361\n",
      "Epoch [1383/2000], Avg Train Loss: 3.6361\n",
      "Epoch [1383/2000], Avg Val Loss: 2.2618\n",
      "Validation loss improved from 2.2619 to 2.2618. Saving model...\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5994\n",
      "Epoch [1384/2000], Avg Train Loss: 3.5994\n",
      "Epoch [1384/2000], Avg Val Loss: 2.2616\n",
      "Validation loss improved from 2.2618 to 2.2616. Saving model...\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6056\n",
      "Epoch [1385/2000], Avg Train Loss: 3.6056\n",
      "Epoch [1385/2000], Avg Val Loss: 2.2613\n",
      "Validation loss improved from 2.2616 to 2.2613. Saving model...\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5957\n",
      "Epoch [1386/2000], Avg Train Loss: 3.5957\n",
      "Epoch [1386/2000], Avg Val Loss: 2.2611\n",
      "Validation loss improved from 2.2613 to 2.2611. Saving model...\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6203\n",
      "Epoch [1387/2000], Avg Train Loss: 3.6203\n",
      "Epoch [1387/2000], Avg Val Loss: 2.2609\n",
      "Validation loss improved from 2.2611 to 2.2609. Saving model...\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5836\n",
      "Epoch [1388/2000], Avg Train Loss: 3.5836\n",
      "Epoch [1388/2000], Avg Val Loss: 2.2609\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6064\n",
      "Epoch [1389/2000], Avg Train Loss: 3.6064\n",
      "Epoch [1389/2000], Avg Val Loss: 2.2610\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6117\n",
      "Epoch [1390/2000], Avg Train Loss: 3.6117\n",
      "Epoch [1390/2000], Avg Val Loss: 2.2612\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5707\n",
      "Epoch [1391/2000], Avg Train Loss: 3.5707\n",
      "Epoch [1391/2000], Avg Val Loss: 2.2614\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5971\n",
      "Epoch [1392/2000], Avg Train Loss: 3.5971\n",
      "Epoch [1392/2000], Avg Val Loss: 2.2616\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5970\n",
      "Epoch [1393/2000], Avg Train Loss: 3.5970\n",
      "Epoch [1393/2000], Avg Val Loss: 2.2616\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6237\n",
      "Epoch [1394/2000], Avg Train Loss: 3.6237\n",
      "Epoch [1394/2000], Avg Val Loss: 2.2615\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6249\n",
      "Epoch [1395/2000], Avg Train Loss: 3.6249\n",
      "Epoch [1395/2000], Avg Val Loss: 2.2615\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5989\n",
      "Epoch [1396/2000], Avg Train Loss: 3.5989\n",
      "Epoch [1396/2000], Avg Val Loss: 2.2614\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6137\n",
      "Epoch [1397/2000], Avg Train Loss: 3.6137\n",
      "Epoch [1397/2000], Avg Val Loss: 2.2612\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6355\n",
      "Epoch [1398/2000], Avg Train Loss: 3.6355\n",
      "Epoch [1398/2000], Avg Val Loss: 2.2612\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5811\n",
      "Epoch [1399/2000], Avg Train Loss: 3.5811\n",
      "Epoch [1399/2000], Avg Val Loss: 2.2610\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6243\n",
      "Epoch [1400/2000], Avg Train Loss: 3.6243\n",
      "Epoch [1400/2000], Avg Val Loss: 2.2608\n",
      "Validation loss improved from 2.2609 to 2.2608. Saving model...\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6285\n",
      "Epoch [1401/2000], Avg Train Loss: 3.6285\n",
      "Epoch [1401/2000], Avg Val Loss: 2.2606\n",
      "Validation loss improved from 2.2608 to 2.2606. Saving model...\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5976\n",
      "Epoch [1402/2000], Avg Train Loss: 3.5976\n",
      "Epoch [1402/2000], Avg Val Loss: 2.2605\n",
      "Validation loss improved from 2.2606 to 2.2605. Saving model...\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6153\n",
      "Epoch [1403/2000], Avg Train Loss: 3.6153\n",
      "Epoch [1403/2000], Avg Val Loss: 2.2603\n",
      "Validation loss improved from 2.2605 to 2.2603. Saving model...\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5845\n",
      "Epoch [1404/2000], Avg Train Loss: 3.5845\n",
      "Epoch [1404/2000], Avg Val Loss: 2.2602\n",
      "Validation loss improved from 2.2603 to 2.2602. Saving model...\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5979\n",
      "Epoch [1405/2000], Avg Train Loss: 3.5979\n",
      "Epoch [1405/2000], Avg Val Loss: 2.2601\n",
      "Validation loss improved from 2.2602 to 2.2601. Saving model...\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6304\n",
      "Epoch [1406/2000], Avg Train Loss: 3.6304\n",
      "Epoch [1406/2000], Avg Val Loss: 2.2602\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6129\n",
      "Epoch [1407/2000], Avg Train Loss: 3.6129\n",
      "Epoch [1407/2000], Avg Val Loss: 2.2601\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5962\n",
      "Epoch [1408/2000], Avg Train Loss: 3.5962\n",
      "Epoch [1408/2000], Avg Val Loss: 2.2598\n",
      "Validation loss improved from 2.2601 to 2.2598. Saving model...\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6350\n",
      "Epoch [1409/2000], Avg Train Loss: 3.6350\n",
      "Epoch [1409/2000], Avg Val Loss: 2.2597\n",
      "Validation loss improved from 2.2598 to 2.2597. Saving model...\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6671\n",
      "Epoch [1410/2000], Avg Train Loss: 3.6671\n",
      "Epoch [1410/2000], Avg Val Loss: 2.2594\n",
      "Validation loss improved from 2.2597 to 2.2594. Saving model...\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5917\n",
      "Epoch [1411/2000], Avg Train Loss: 3.5917\n",
      "Epoch [1411/2000], Avg Val Loss: 2.2591\n",
      "Validation loss improved from 2.2594 to 2.2591. Saving model...\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5836\n",
      "Epoch [1412/2000], Avg Train Loss: 3.5836\n",
      "Epoch [1412/2000], Avg Val Loss: 2.2587\n",
      "Validation loss improved from 2.2591 to 2.2587. Saving model...\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5958\n",
      "Epoch [1413/2000], Avg Train Loss: 3.5958\n",
      "Epoch [1413/2000], Avg Val Loss: 2.2583\n",
      "Validation loss improved from 2.2587 to 2.2583. Saving model...\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6084\n",
      "Epoch [1414/2000], Avg Train Loss: 3.6084\n",
      "Epoch [1414/2000], Avg Val Loss: 2.2578\n",
      "Validation loss improved from 2.2583 to 2.2578. Saving model...\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6056\n",
      "Epoch [1415/2000], Avg Train Loss: 3.6056\n",
      "Epoch [1415/2000], Avg Val Loss: 2.2574\n",
      "Validation loss improved from 2.2578 to 2.2574. Saving model...\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5651\n",
      "Epoch [1416/2000], Avg Train Loss: 3.5651\n",
      "Epoch [1416/2000], Avg Val Loss: 2.2569\n",
      "Validation loss improved from 2.2574 to 2.2569. Saving model...\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6031\n",
      "Epoch [1417/2000], Avg Train Loss: 3.6031\n",
      "Epoch [1417/2000], Avg Val Loss: 2.2567\n",
      "Validation loss improved from 2.2569 to 2.2567. Saving model...\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6103\n",
      "Epoch [1418/2000], Avg Train Loss: 3.6103\n",
      "Epoch [1418/2000], Avg Val Loss: 2.2564\n",
      "Validation loss improved from 2.2567 to 2.2564. Saving model...\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5771\n",
      "Epoch [1419/2000], Avg Train Loss: 3.5771\n",
      "Epoch [1419/2000], Avg Val Loss: 2.2562\n",
      "Validation loss improved from 2.2564 to 2.2562. Saving model...\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5960\n",
      "Epoch [1420/2000], Avg Train Loss: 3.5960\n",
      "Epoch [1420/2000], Avg Val Loss: 2.2560\n",
      "Validation loss improved from 2.2562 to 2.2560. Saving model...\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6026\n",
      "Epoch [1421/2000], Avg Train Loss: 3.6026\n",
      "Epoch [1421/2000], Avg Val Loss: 2.2556\n",
      "Validation loss improved from 2.2560 to 2.2556. Saving model...\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6047\n",
      "Epoch [1422/2000], Avg Train Loss: 3.6047\n",
      "Epoch [1422/2000], Avg Val Loss: 2.2552\n",
      "Validation loss improved from 2.2556 to 2.2552. Saving model...\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6079\n",
      "Epoch [1423/2000], Avg Train Loss: 3.6079\n",
      "Epoch [1423/2000], Avg Val Loss: 2.2549\n",
      "Validation loss improved from 2.2552 to 2.2549. Saving model...\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6024\n",
      "Epoch [1424/2000], Avg Train Loss: 3.6024\n",
      "Epoch [1424/2000], Avg Val Loss: 2.2546\n",
      "Validation loss improved from 2.2549 to 2.2546. Saving model...\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5774\n",
      "Epoch [1425/2000], Avg Train Loss: 3.5774\n",
      "Epoch [1425/2000], Avg Val Loss: 2.2545\n",
      "Validation loss improved from 2.2546 to 2.2545. Saving model...\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6164\n",
      "Epoch [1426/2000], Avg Train Loss: 3.6164\n",
      "Epoch [1426/2000], Avg Val Loss: 2.2543\n",
      "Validation loss improved from 2.2545 to 2.2543. Saving model...\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5837\n",
      "Epoch [1427/2000], Avg Train Loss: 3.5837\n",
      "Epoch [1427/2000], Avg Val Loss: 2.2542\n",
      "Validation loss improved from 2.2543 to 2.2542. Saving model...\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6081\n",
      "Epoch [1428/2000], Avg Train Loss: 3.6081\n",
      "Epoch [1428/2000], Avg Val Loss: 2.2541\n",
      "Validation loss improved from 2.2542 to 2.2541. Saving model...\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6180\n",
      "Epoch [1429/2000], Avg Train Loss: 3.6180\n",
      "Epoch [1429/2000], Avg Val Loss: 2.2542\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5840\n",
      "Epoch [1430/2000], Avg Train Loss: 3.5840\n",
      "Epoch [1430/2000], Avg Val Loss: 2.2544\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5644\n",
      "Epoch [1431/2000], Avg Train Loss: 3.5644\n",
      "Epoch [1431/2000], Avg Val Loss: 2.2545\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6226\n",
      "Epoch [1432/2000], Avg Train Loss: 3.6226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1432/2000], Avg Val Loss: 2.2546\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5938\n",
      "Epoch [1433/2000], Avg Train Loss: 3.5938\n",
      "Epoch [1433/2000], Avg Val Loss: 2.2545\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6138\n",
      "Epoch [1434/2000], Avg Train Loss: 3.6138\n",
      "Epoch [1434/2000], Avg Val Loss: 2.2545\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6099\n",
      "Epoch [1435/2000], Avg Train Loss: 3.6099\n",
      "Epoch [1435/2000], Avg Val Loss: 2.2544\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6082\n",
      "Epoch [1436/2000], Avg Train Loss: 3.6082\n",
      "Epoch [1436/2000], Avg Val Loss: 2.2544\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5910\n",
      "Epoch [1437/2000], Avg Train Loss: 3.5910\n",
      "Epoch [1437/2000], Avg Val Loss: 2.2543\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5868\n",
      "Epoch [1438/2000], Avg Train Loss: 3.5868\n",
      "Epoch [1438/2000], Avg Val Loss: 2.2543\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5899\n",
      "Epoch [1439/2000], Avg Train Loss: 3.5899\n",
      "Epoch [1439/2000], Avg Val Loss: 2.2541\n",
      "Validation loss improved from 2.2541 to 2.2541. Saving model...\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6089\n",
      "Epoch [1440/2000], Avg Train Loss: 3.6089\n",
      "Epoch [1440/2000], Avg Val Loss: 2.2541\n",
      "Validation loss improved from 2.2541 to 2.2541. Saving model...\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5869\n",
      "Epoch [1441/2000], Avg Train Loss: 3.5869\n",
      "Epoch [1441/2000], Avg Val Loss: 2.2542\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6489\n",
      "Epoch [1442/2000], Avg Train Loss: 3.6489\n",
      "Epoch [1442/2000], Avg Val Loss: 2.2544\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6298\n",
      "Epoch [1443/2000], Avg Train Loss: 3.6298\n",
      "Epoch [1443/2000], Avg Val Loss: 2.2547\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6072\n",
      "Epoch [1444/2000], Avg Train Loss: 3.6072\n",
      "Epoch [1444/2000], Avg Val Loss: 2.2552\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6254\n",
      "Epoch [1445/2000], Avg Train Loss: 3.6254\n",
      "Epoch [1445/2000], Avg Val Loss: 2.2557\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5780\n",
      "Epoch [1446/2000], Avg Train Loss: 3.5780\n",
      "Epoch [1446/2000], Avg Val Loss: 2.2563\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5757\n",
      "Epoch [1447/2000], Avg Train Loss: 3.5757\n",
      "Epoch [1447/2000], Avg Val Loss: 2.2567\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5832\n",
      "Epoch [1448/2000], Avg Train Loss: 3.5832\n",
      "Epoch [1448/2000], Avg Val Loss: 2.2569\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5715\n",
      "Epoch [1449/2000], Avg Train Loss: 3.5715\n",
      "Epoch [1449/2000], Avg Val Loss: 2.2571\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5912\n",
      "Epoch [1450/2000], Avg Train Loss: 3.5912\n",
      "Epoch [1450/2000], Avg Val Loss: 2.2572\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6152\n",
      "Epoch [1451/2000], Avg Train Loss: 3.6152\n",
      "Epoch [1451/2000], Avg Val Loss: 2.2572\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6125\n",
      "Epoch [1452/2000], Avg Train Loss: 3.6125\n",
      "Epoch [1452/2000], Avg Val Loss: 2.2572\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5774\n",
      "Epoch [1453/2000], Avg Train Loss: 3.5774\n",
      "Epoch [1453/2000], Avg Val Loss: 2.2570\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6344\n",
      "Epoch [1454/2000], Avg Train Loss: 3.6344\n",
      "Epoch [1454/2000], Avg Val Loss: 2.2568\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6326\n",
      "Epoch [1455/2000], Avg Train Loss: 3.6326\n",
      "Epoch [1455/2000], Avg Val Loss: 2.2566\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5961\n",
      "Epoch [1456/2000], Avg Train Loss: 3.5961\n",
      "Epoch [1456/2000], Avg Val Loss: 2.2563\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5887\n",
      "Epoch [1457/2000], Avg Train Loss: 3.5887\n",
      "Epoch [1457/2000], Avg Val Loss: 2.2558\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6094\n",
      "Epoch [1458/2000], Avg Train Loss: 3.6094\n",
      "Epoch [1458/2000], Avg Val Loss: 2.2556\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5908\n",
      "Epoch [1459/2000], Avg Train Loss: 3.5908\n",
      "Epoch [1459/2000], Avg Val Loss: 2.2555\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5775\n",
      "Epoch [1460/2000], Avg Train Loss: 3.5775\n",
      "Epoch [1460/2000], Avg Val Loss: 2.2554\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6154\n",
      "Epoch [1461/2000], Avg Train Loss: 3.6154\n",
      "Epoch [1461/2000], Avg Val Loss: 2.2555\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6085\n",
      "Epoch [1462/2000], Avg Train Loss: 3.6085\n",
      "Epoch [1462/2000], Avg Val Loss: 2.2557\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6113\n",
      "Epoch [1463/2000], Avg Train Loss: 3.6113\n",
      "Epoch [1463/2000], Avg Val Loss: 2.2561\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5914\n",
      "Epoch [1464/2000], Avg Train Loss: 3.5914\n",
      "Epoch [1464/2000], Avg Val Loss: 2.2563\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6009\n",
      "Epoch [1465/2000], Avg Train Loss: 3.6009\n",
      "Epoch [1465/2000], Avg Val Loss: 2.2565\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5940\n",
      "Epoch [1466/2000], Avg Train Loss: 3.5940\n",
      "Epoch [1466/2000], Avg Val Loss: 2.2567\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5760\n",
      "Epoch [1467/2000], Avg Train Loss: 3.5760\n",
      "Epoch [1467/2000], Avg Val Loss: 2.2568\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5815\n",
      "Epoch [1468/2000], Avg Train Loss: 3.5815\n",
      "Epoch [1468/2000], Avg Val Loss: 2.2570\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6410\n",
      "Epoch [1469/2000], Avg Train Loss: 3.6410\n",
      "Epoch [1469/2000], Avg Val Loss: 2.2571\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5989\n",
      "Epoch [1470/2000], Avg Train Loss: 3.5989\n",
      "Epoch [1470/2000], Avg Val Loss: 2.2573\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5760\n",
      "Epoch [1471/2000], Avg Train Loss: 3.5760\n",
      "Epoch [1471/2000], Avg Val Loss: 2.2574\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6238\n",
      "Epoch [1472/2000], Avg Train Loss: 3.6238\n",
      "Epoch [1472/2000], Avg Val Loss: 2.2573\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5805\n",
      "Epoch [1473/2000], Avg Train Loss: 3.5805\n",
      "Epoch [1473/2000], Avg Val Loss: 2.2572\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6079\n",
      "Epoch [1474/2000], Avg Train Loss: 3.6079\n",
      "Epoch [1474/2000], Avg Val Loss: 2.2571\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6044\n",
      "Epoch [1475/2000], Avg Train Loss: 3.6044\n",
      "Epoch [1475/2000], Avg Val Loss: 2.2572\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5649\n",
      "Epoch [1476/2000], Avg Train Loss: 3.5649\n",
      "Epoch [1476/2000], Avg Val Loss: 2.2570\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5735\n",
      "Epoch [1477/2000], Avg Train Loss: 3.5735\n",
      "Epoch [1477/2000], Avg Val Loss: 2.2568\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5933\n",
      "Epoch [1478/2000], Avg Train Loss: 3.5933\n",
      "Epoch [1478/2000], Avg Val Loss: 2.2564\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6041\n",
      "Epoch [1479/2000], Avg Train Loss: 3.6041\n",
      "Epoch [1479/2000], Avg Val Loss: 2.2559\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5952\n",
      "Epoch [1480/2000], Avg Train Loss: 3.5952\n",
      "Epoch [1480/2000], Avg Val Loss: 2.2554\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5767\n",
      "Epoch [1481/2000], Avg Train Loss: 3.5767\n",
      "Epoch [1481/2000], Avg Val Loss: 2.2549\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5672\n",
      "Epoch [1482/2000], Avg Train Loss: 3.5672\n",
      "Epoch [1482/2000], Avg Val Loss: 2.2544\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5952\n",
      "Epoch [1483/2000], Avg Train Loss: 3.5952\n",
      "Epoch [1483/2000], Avg Val Loss: 2.2540\n",
      "Validation loss improved from 2.2541 to 2.2540. Saving model...\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5732\n",
      "Epoch [1484/2000], Avg Train Loss: 3.5732\n",
      "Epoch [1484/2000], Avg Val Loss: 2.2536\n",
      "Validation loss improved from 2.2540 to 2.2536. Saving model...\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6003\n",
      "Epoch [1485/2000], Avg Train Loss: 3.6003\n",
      "Epoch [1485/2000], Avg Val Loss: 2.2534\n",
      "Validation loss improved from 2.2536 to 2.2534. Saving model...\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6021\n",
      "Epoch [1486/2000], Avg Train Loss: 3.6021\n",
      "Epoch [1486/2000], Avg Val Loss: 2.2533\n",
      "Validation loss improved from 2.2534 to 2.2533. Saving model...\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6057\n",
      "Epoch [1487/2000], Avg Train Loss: 3.6057\n",
      "Epoch [1487/2000], Avg Val Loss: 2.2533\n",
      "Validation loss improved from 2.2533 to 2.2533. Saving model...\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5536\n",
      "Epoch [1488/2000], Avg Train Loss: 3.5536\n",
      "Epoch [1488/2000], Avg Val Loss: 2.2533\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5803\n",
      "Epoch [1489/2000], Avg Train Loss: 3.5803\n",
      "Epoch [1489/2000], Avg Val Loss: 2.2533\n",
      "Validation loss improved from 2.2533 to 2.2533. Saving model...\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5832\n",
      "Epoch [1490/2000], Avg Train Loss: 3.5832\n",
      "Epoch [1490/2000], Avg Val Loss: 2.2534\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5747\n",
      "Epoch [1491/2000], Avg Train Loss: 3.5747\n",
      "Epoch [1491/2000], Avg Val Loss: 2.2537\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6033\n",
      "Epoch [1492/2000], Avg Train Loss: 3.6033\n",
      "Epoch [1492/2000], Avg Val Loss: 2.2541\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6146\n",
      "Epoch [1493/2000], Avg Train Loss: 3.6146\n",
      "Epoch [1493/2000], Avg Val Loss: 2.2545\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5931\n",
      "Epoch [1494/2000], Avg Train Loss: 3.5931\n",
      "Epoch [1494/2000], Avg Val Loss: 2.2548\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6048\n",
      "Epoch [1495/2000], Avg Train Loss: 3.6048\n",
      "Epoch [1495/2000], Avg Val Loss: 2.2550\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5672\n",
      "Epoch [1496/2000], Avg Train Loss: 3.5672\n",
      "Epoch [1496/2000], Avg Val Loss: 2.2551\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6228\n",
      "Epoch [1497/2000], Avg Train Loss: 3.6228\n",
      "Epoch [1497/2000], Avg Val Loss: 2.2551\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5701\n",
      "Epoch [1498/2000], Avg Train Loss: 3.5701\n",
      "Epoch [1498/2000], Avg Val Loss: 2.2551\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5744\n",
      "Epoch [1499/2000], Avg Train Loss: 3.5744\n",
      "Epoch [1499/2000], Avg Val Loss: 2.2552\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6179\n",
      "Epoch [1500/2000], Avg Train Loss: 3.6179\n",
      "Epoch [1500/2000], Avg Val Loss: 2.2554\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5759\n",
      "Epoch [1501/2000], Avg Train Loss: 3.5759\n",
      "Epoch [1501/2000], Avg Val Loss: 2.2555\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5986\n",
      "Epoch [1502/2000], Avg Train Loss: 3.5986\n",
      "Epoch [1502/2000], Avg Val Loss: 2.2555\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5771\n",
      "Epoch [1503/2000], Avg Train Loss: 3.5771\n",
      "Epoch [1503/2000], Avg Val Loss: 2.2553\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5918\n",
      "Epoch [1504/2000], Avg Train Loss: 3.5918\n",
      "Epoch [1504/2000], Avg Val Loss: 2.2550\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5680\n",
      "Epoch [1505/2000], Avg Train Loss: 3.5680\n",
      "Epoch [1505/2000], Avg Val Loss: 2.2547\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5539\n",
      "Epoch [1506/2000], Avg Train Loss: 3.5539\n",
      "Epoch [1506/2000], Avg Val Loss: 2.2543\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5782\n",
      "Epoch [1507/2000], Avg Train Loss: 3.5782\n",
      "Epoch [1507/2000], Avg Val Loss: 2.2541\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5965\n",
      "Epoch [1508/2000], Avg Train Loss: 3.5965\n",
      "Epoch [1508/2000], Avg Val Loss: 2.2539\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5549\n",
      "Epoch [1509/2000], Avg Train Loss: 3.5549\n",
      "Epoch [1509/2000], Avg Val Loss: 2.2537\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5782\n",
      "Epoch [1510/2000], Avg Train Loss: 3.5782\n",
      "Epoch [1510/2000], Avg Val Loss: 2.2534\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5682\n",
      "Epoch [1511/2000], Avg Train Loss: 3.5682\n",
      "Epoch [1511/2000], Avg Val Loss: 2.2532\n",
      "Validation loss improved from 2.2533 to 2.2532. Saving model...\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5871\n",
      "Epoch [1512/2000], Avg Train Loss: 3.5871\n",
      "Epoch [1512/2000], Avg Val Loss: 2.2531\n",
      "Validation loss improved from 2.2532 to 2.2531. Saving model...\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5831\n",
      "Epoch [1513/2000], Avg Train Loss: 3.5831\n",
      "Epoch [1513/2000], Avg Val Loss: 2.2530\n",
      "Validation loss improved from 2.2531 to 2.2530. Saving model...\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5715\n",
      "Epoch [1514/2000], Avg Train Loss: 3.5715\n",
      "Epoch [1514/2000], Avg Val Loss: 2.2527\n",
      "Validation loss improved from 2.2530 to 2.2527. Saving model...\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5665\n",
      "Epoch [1515/2000], Avg Train Loss: 3.5665\n",
      "Epoch [1515/2000], Avg Val Loss: 2.2525\n",
      "Validation loss improved from 2.2527 to 2.2525. Saving model...\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5535\n",
      "Epoch [1516/2000], Avg Train Loss: 3.5535\n",
      "Epoch [1516/2000], Avg Val Loss: 2.2522\n",
      "Validation loss improved from 2.2525 to 2.2522. Saving model...\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5576\n",
      "Epoch [1517/2000], Avg Train Loss: 3.5576\n",
      "Epoch [1517/2000], Avg Val Loss: 2.2519\n",
      "Validation loss improved from 2.2522 to 2.2519. Saving model...\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5912\n",
      "Epoch [1518/2000], Avg Train Loss: 3.5912\n",
      "Epoch [1518/2000], Avg Val Loss: 2.2516\n",
      "Validation loss improved from 2.2519 to 2.2516. Saving model...\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6013\n",
      "Epoch [1519/2000], Avg Train Loss: 3.6013\n",
      "Epoch [1519/2000], Avg Val Loss: 2.2513\n",
      "Validation loss improved from 2.2516 to 2.2513. Saving model...\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5743\n",
      "Epoch [1520/2000], Avg Train Loss: 3.5743\n",
      "Epoch [1520/2000], Avg Val Loss: 2.2510\n",
      "Validation loss improved from 2.2513 to 2.2510. Saving model...\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5768\n",
      "Epoch [1521/2000], Avg Train Loss: 3.5768\n",
      "Epoch [1521/2000], Avg Val Loss: 2.2509\n",
      "Validation loss improved from 2.2510 to 2.2509. Saving model...\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5818\n",
      "Epoch [1522/2000], Avg Train Loss: 3.5818\n",
      "Epoch [1522/2000], Avg Val Loss: 2.2508\n",
      "Validation loss improved from 2.2509 to 2.2508. Saving model...\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5949\n",
      "Epoch [1523/2000], Avg Train Loss: 3.5949\n",
      "Epoch [1523/2000], Avg Val Loss: 2.2508\n",
      "Validation loss improved from 2.2508 to 2.2508. Saving model...\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5984\n",
      "Epoch [1524/2000], Avg Train Loss: 3.5984\n",
      "Epoch [1524/2000], Avg Val Loss: 2.2506\n",
      "Validation loss improved from 2.2508 to 2.2506. Saving model...\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5777\n",
      "Epoch [1525/2000], Avg Train Loss: 3.5777\n",
      "Epoch [1525/2000], Avg Val Loss: 2.2504\n",
      "Validation loss improved from 2.2506 to 2.2504. Saving model...\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5639\n",
      "Epoch [1526/2000], Avg Train Loss: 3.5639\n",
      "Epoch [1526/2000], Avg Val Loss: 2.2500\n",
      "Validation loss improved from 2.2504 to 2.2500. Saving model...\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5970\n",
      "Epoch [1527/2000], Avg Train Loss: 3.5970\n",
      "Epoch [1527/2000], Avg Val Loss: 2.2496\n",
      "Validation loss improved from 2.2500 to 2.2496. Saving model...\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5813\n",
      "Epoch [1528/2000], Avg Train Loss: 3.5813\n",
      "Epoch [1528/2000], Avg Val Loss: 2.2493\n",
      "Validation loss improved from 2.2496 to 2.2493. Saving model...\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5607\n",
      "Epoch [1529/2000], Avg Train Loss: 3.5607\n",
      "Epoch [1529/2000], Avg Val Loss: 2.2490\n",
      "Validation loss improved from 2.2493 to 2.2490. Saving model...\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6074\n",
      "Epoch [1530/2000], Avg Train Loss: 3.6074\n",
      "Epoch [1530/2000], Avg Val Loss: 2.2488\n",
      "Validation loss improved from 2.2490 to 2.2488. Saving model...\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5877\n",
      "Epoch [1531/2000], Avg Train Loss: 3.5877\n",
      "Epoch [1531/2000], Avg Val Loss: 2.2485\n",
      "Validation loss improved from 2.2488 to 2.2485. Saving model...\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5791\n",
      "Epoch [1532/2000], Avg Train Loss: 3.5791\n",
      "Epoch [1532/2000], Avg Val Loss: 2.2484\n",
      "Validation loss improved from 2.2485 to 2.2484. Saving model...\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5617\n",
      "Epoch [1533/2000], Avg Train Loss: 3.5617\n",
      "Epoch [1533/2000], Avg Val Loss: 2.2482\n",
      "Validation loss improved from 2.2484 to 2.2482. Saving model...\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5581\n",
      "Epoch [1534/2000], Avg Train Loss: 3.5581\n",
      "Epoch [1534/2000], Avg Val Loss: 2.2481\n",
      "Validation loss improved from 2.2482 to 2.2481. Saving model...\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5793\n",
      "Epoch [1535/2000], Avg Train Loss: 3.5793\n",
      "Epoch [1535/2000], Avg Val Loss: 2.2480\n",
      "Validation loss improved from 2.2481 to 2.2480. Saving model...\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5796\n",
      "Epoch [1536/2000], Avg Train Loss: 3.5796\n",
      "Epoch [1536/2000], Avg Val Loss: 2.2479\n",
      "Validation loss improved from 2.2480 to 2.2479. Saving model...\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6179\n",
      "Epoch [1537/2000], Avg Train Loss: 3.6179\n",
      "Epoch [1537/2000], Avg Val Loss: 2.2481\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5888\n",
      "Epoch [1538/2000], Avg Train Loss: 3.5888\n",
      "Epoch [1538/2000], Avg Val Loss: 2.2483\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5715\n",
      "Epoch [1539/2000], Avg Train Loss: 3.5715\n",
      "Epoch [1539/2000], Avg Val Loss: 2.2484\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5712\n",
      "Epoch [1540/2000], Avg Train Loss: 3.5712\n",
      "Epoch [1540/2000], Avg Val Loss: 2.2485\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5767\n",
      "Epoch [1541/2000], Avg Train Loss: 3.5767\n",
      "Epoch [1541/2000], Avg Val Loss: 2.2488\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5410\n",
      "Epoch [1542/2000], Avg Train Loss: 3.5410\n",
      "Epoch [1542/2000], Avg Val Loss: 2.2491\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5629\n",
      "Epoch [1543/2000], Avg Train Loss: 3.5629\n",
      "Epoch [1543/2000], Avg Val Loss: 2.2493\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5737\n",
      "Epoch [1544/2000], Avg Train Loss: 3.5737\n",
      "Epoch [1544/2000], Avg Val Loss: 2.2496\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5797\n",
      "Epoch [1545/2000], Avg Train Loss: 3.5797\n",
      "Epoch [1545/2000], Avg Val Loss: 2.2501\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5893\n",
      "Epoch [1546/2000], Avg Train Loss: 3.5893\n",
      "Epoch [1546/2000], Avg Val Loss: 2.2504\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5586\n",
      "Epoch [1547/2000], Avg Train Loss: 3.5586\n",
      "Epoch [1547/2000], Avg Val Loss: 2.2506\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5726\n",
      "Epoch [1548/2000], Avg Train Loss: 3.5726\n",
      "Epoch [1548/2000], Avg Val Loss: 2.2511\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5459\n",
      "Epoch [1549/2000], Avg Train Loss: 3.5459\n",
      "Epoch [1549/2000], Avg Val Loss: 2.2515\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5751\n",
      "Epoch [1550/2000], Avg Train Loss: 3.5751\n",
      "Epoch [1550/2000], Avg Val Loss: 2.2518\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5835\n",
      "Epoch [1551/2000], Avg Train Loss: 3.5835\n",
      "Epoch [1551/2000], Avg Val Loss: 2.2520\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5904\n",
      "Epoch [1552/2000], Avg Train Loss: 3.5904\n",
      "Epoch [1552/2000], Avg Val Loss: 2.2521\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5598\n",
      "Epoch [1553/2000], Avg Train Loss: 3.5598\n",
      "Epoch [1553/2000], Avg Val Loss: 2.2523\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5635\n",
      "Epoch [1554/2000], Avg Train Loss: 3.5635\n",
      "Epoch [1554/2000], Avg Val Loss: 2.2523\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5746\n",
      "Epoch [1555/2000], Avg Train Loss: 3.5746\n",
      "Epoch [1555/2000], Avg Val Loss: 2.2522\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5496\n",
      "Epoch [1556/2000], Avg Train Loss: 3.5496\n",
      "Epoch [1556/2000], Avg Val Loss: 2.2521\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5780\n",
      "Epoch [1557/2000], Avg Train Loss: 3.5780\n",
      "Epoch [1557/2000], Avg Val Loss: 2.2519\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5659\n",
      "Epoch [1558/2000], Avg Train Loss: 3.5659\n",
      "Epoch [1558/2000], Avg Val Loss: 2.2518\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5301\n",
      "Epoch [1559/2000], Avg Train Loss: 3.5301\n",
      "Epoch [1559/2000], Avg Val Loss: 2.2517\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5662\n",
      "Epoch [1560/2000], Avg Train Loss: 3.5662\n",
      "Epoch [1560/2000], Avg Val Loss: 2.2516\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5733\n",
      "Epoch [1561/2000], Avg Train Loss: 3.5733\n",
      "Epoch [1561/2000], Avg Val Loss: 2.2514\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5565\n",
      "Epoch [1562/2000], Avg Train Loss: 3.5565\n",
      "Epoch [1562/2000], Avg Val Loss: 2.2513\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5555\n",
      "Epoch [1563/2000], Avg Train Loss: 3.5555\n",
      "Epoch [1563/2000], Avg Val Loss: 2.2510\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5481\n",
      "Epoch [1564/2000], Avg Train Loss: 3.5481\n",
      "Epoch [1564/2000], Avg Val Loss: 2.2506\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5511\n",
      "Epoch [1565/2000], Avg Train Loss: 3.5511\n",
      "Epoch [1565/2000], Avg Val Loss: 2.2502\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5603\n",
      "Epoch [1566/2000], Avg Train Loss: 3.5603\n",
      "Epoch [1566/2000], Avg Val Loss: 2.2497\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5774\n",
      "Epoch [1567/2000], Avg Train Loss: 3.5774\n",
      "Epoch [1567/2000], Avg Val Loss: 2.2493\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5302\n",
      "Epoch [1568/2000], Avg Train Loss: 3.5302\n",
      "Epoch [1568/2000], Avg Val Loss: 2.2489\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5633\n",
      "Epoch [1569/2000], Avg Train Loss: 3.5633\n",
      "Epoch [1569/2000], Avg Val Loss: 2.2485\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5402\n",
      "Epoch [1570/2000], Avg Train Loss: 3.5402\n",
      "Epoch [1570/2000], Avg Val Loss: 2.2481\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5823\n",
      "Epoch [1571/2000], Avg Train Loss: 3.5823\n",
      "Epoch [1571/2000], Avg Val Loss: 2.2479\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5585\n",
      "Epoch [1572/2000], Avg Train Loss: 3.5585\n",
      "Epoch [1572/2000], Avg Val Loss: 2.2478\n",
      "Validation loss improved from 2.2479 to 2.2478. Saving model...\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5959\n",
      "Epoch [1573/2000], Avg Train Loss: 3.5959\n",
      "Epoch [1573/2000], Avg Val Loss: 2.2475\n",
      "Validation loss improved from 2.2478 to 2.2475. Saving model...\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6025\n",
      "Epoch [1574/2000], Avg Train Loss: 3.6025\n",
      "Epoch [1574/2000], Avg Val Loss: 2.2472\n",
      "Validation loss improved from 2.2475 to 2.2472. Saving model...\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5784\n",
      "Epoch [1575/2000], Avg Train Loss: 3.5784\n",
      "Epoch [1575/2000], Avg Val Loss: 2.2470\n",
      "Validation loss improved from 2.2472 to 2.2470. Saving model...\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5317\n",
      "Epoch [1576/2000], Avg Train Loss: 3.5317\n",
      "Epoch [1576/2000], Avg Val Loss: 2.2469\n",
      "Validation loss improved from 2.2470 to 2.2469. Saving model...\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5759\n",
      "Epoch [1577/2000], Avg Train Loss: 3.5759\n",
      "Epoch [1577/2000], Avg Val Loss: 2.2468\n",
      "Validation loss improved from 2.2469 to 2.2468. Saving model...\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5498\n",
      "Epoch [1578/2000], Avg Train Loss: 3.5498\n",
      "Epoch [1578/2000], Avg Val Loss: 2.2470\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5497\n",
      "Epoch [1579/2000], Avg Train Loss: 3.5497\n",
      "Epoch [1579/2000], Avg Val Loss: 2.2471\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5410\n",
      "Epoch [1580/2000], Avg Train Loss: 3.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1580/2000], Avg Val Loss: 2.2473\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5370\n",
      "Epoch [1581/2000], Avg Train Loss: 3.5370\n",
      "Epoch [1581/2000], Avg Val Loss: 2.2476\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5552\n",
      "Epoch [1582/2000], Avg Train Loss: 3.5552\n",
      "Epoch [1582/2000], Avg Val Loss: 2.2481\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5448\n",
      "Epoch [1583/2000], Avg Train Loss: 3.5448\n",
      "Epoch [1583/2000], Avg Val Loss: 2.2485\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5505\n",
      "Epoch [1584/2000], Avg Train Loss: 3.5505\n",
      "Epoch [1584/2000], Avg Val Loss: 2.2489\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5680\n",
      "Epoch [1585/2000], Avg Train Loss: 3.5680\n",
      "Epoch [1585/2000], Avg Val Loss: 2.2492\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5675\n",
      "Epoch [1586/2000], Avg Train Loss: 3.5675\n",
      "Epoch [1586/2000], Avg Val Loss: 2.2497\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5690\n",
      "Epoch [1587/2000], Avg Train Loss: 3.5690\n",
      "Epoch [1587/2000], Avg Val Loss: 2.2501\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5355\n",
      "Epoch [1588/2000], Avg Train Loss: 3.5355\n",
      "Epoch [1588/2000], Avg Val Loss: 2.2503\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5546\n",
      "Epoch [1589/2000], Avg Train Loss: 3.5546\n",
      "Epoch [1589/2000], Avg Val Loss: 2.2505\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5506\n",
      "Epoch [1590/2000], Avg Train Loss: 3.5506\n",
      "Epoch [1590/2000], Avg Val Loss: 2.2506\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5778\n",
      "Epoch [1591/2000], Avg Train Loss: 3.5778\n",
      "Epoch [1591/2000], Avg Val Loss: 2.2503\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5267\n",
      "Epoch [1592/2000], Avg Train Loss: 3.5267\n",
      "Epoch [1592/2000], Avg Val Loss: 2.2501\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5833\n",
      "Epoch [1593/2000], Avg Train Loss: 3.5833\n",
      "Epoch [1593/2000], Avg Val Loss: 2.2497\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5551\n",
      "Epoch [1594/2000], Avg Train Loss: 3.5551\n",
      "Epoch [1594/2000], Avg Val Loss: 2.2494\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5528\n",
      "Epoch [1595/2000], Avg Train Loss: 3.5528\n",
      "Epoch [1595/2000], Avg Val Loss: 2.2491\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5509\n",
      "Epoch [1596/2000], Avg Train Loss: 3.5509\n",
      "Epoch [1596/2000], Avg Val Loss: 2.2487\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5482\n",
      "Epoch [1597/2000], Avg Train Loss: 3.5482\n",
      "Epoch [1597/2000], Avg Val Loss: 2.2485\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5525\n",
      "Epoch [1598/2000], Avg Train Loss: 3.5525\n",
      "Epoch [1598/2000], Avg Val Loss: 2.2481\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5645\n",
      "Epoch [1599/2000], Avg Train Loss: 3.5645\n",
      "Epoch [1599/2000], Avg Val Loss: 2.2479\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5545\n",
      "Epoch [1600/2000], Avg Train Loss: 3.5545\n",
      "Epoch [1600/2000], Avg Val Loss: 2.2477\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5427\n",
      "Epoch [1601/2000], Avg Train Loss: 3.5427\n",
      "Epoch [1601/2000], Avg Val Loss: 2.2474\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5355\n",
      "Epoch [1602/2000], Avg Train Loss: 3.5355\n",
      "Epoch [1602/2000], Avg Val Loss: 2.2470\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5549\n",
      "Epoch [1603/2000], Avg Train Loss: 3.5549\n",
      "Epoch [1603/2000], Avg Val Loss: 2.2464\n",
      "Validation loss improved from 2.2468 to 2.2464. Saving model...\n",
      "\n",
      "LOG: Epoch [1604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5726\n",
      "Epoch [1604/2000], Avg Train Loss: 3.5726\n",
      "Epoch [1604/2000], Avg Val Loss: 2.2461\n",
      "Validation loss improved from 2.2464 to 2.2461. Saving model...\n",
      "\n",
      "LOG: Epoch [1605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5592\n",
      "Epoch [1605/2000], Avg Train Loss: 3.5592\n",
      "Epoch [1605/2000], Avg Val Loss: 2.2457\n",
      "Validation loss improved from 2.2461 to 2.2457. Saving model...\n",
      "\n",
      "LOG: Epoch [1606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5464\n",
      "Epoch [1606/2000], Avg Train Loss: 3.5464\n",
      "Epoch [1606/2000], Avg Val Loss: 2.2456\n",
      "Validation loss improved from 2.2457 to 2.2456. Saving model...\n",
      "\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5030\n",
      "Epoch [1607/2000], Avg Train Loss: 3.5030\n",
      "Epoch [1607/2000], Avg Val Loss: 2.2455\n",
      "Validation loss improved from 2.2456 to 2.2455. Saving model...\n",
      "\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5649\n",
      "Epoch [1608/2000], Avg Train Loss: 3.5649\n",
      "Epoch [1608/2000], Avg Val Loss: 2.2456\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5504\n",
      "Epoch [1609/2000], Avg Train Loss: 3.5504\n",
      "Epoch [1609/2000], Avg Val Loss: 2.2459\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5484\n",
      "Epoch [1610/2000], Avg Train Loss: 3.5484\n",
      "Epoch [1610/2000], Avg Val Loss: 2.2464\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5493\n",
      "Epoch [1611/2000], Avg Train Loss: 3.5493\n",
      "Epoch [1611/2000], Avg Val Loss: 2.2469\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5518\n",
      "Epoch [1612/2000], Avg Train Loss: 3.5518\n",
      "Epoch [1612/2000], Avg Val Loss: 2.2474\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5249\n",
      "Epoch [1613/2000], Avg Train Loss: 3.5249\n",
      "Epoch [1613/2000], Avg Val Loss: 2.2478\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5418\n",
      "Epoch [1614/2000], Avg Train Loss: 3.5418\n",
      "Epoch [1614/2000], Avg Val Loss: 2.2482\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5491\n",
      "Epoch [1615/2000], Avg Train Loss: 3.5491\n",
      "Epoch [1615/2000], Avg Val Loss: 2.2485\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5625\n",
      "Epoch [1616/2000], Avg Train Loss: 3.5625\n",
      "Epoch [1616/2000], Avg Val Loss: 2.2487\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5299\n",
      "Epoch [1617/2000], Avg Train Loss: 3.5299\n",
      "Epoch [1617/2000], Avg Val Loss: 2.2490\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5249\n",
      "Epoch [1618/2000], Avg Train Loss: 3.5249\n",
      "Epoch [1618/2000], Avg Val Loss: 2.2493\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5426\n",
      "Epoch [1619/2000], Avg Train Loss: 3.5426\n",
      "Epoch [1619/2000], Avg Val Loss: 2.2496\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5349\n",
      "Epoch [1620/2000], Avg Train Loss: 3.5349\n",
      "Epoch [1620/2000], Avg Val Loss: 2.2499\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5373\n",
      "Epoch [1621/2000], Avg Train Loss: 3.5373\n",
      "Epoch [1621/2000], Avg Val Loss: 2.2501\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5695\n",
      "Epoch [1622/2000], Avg Train Loss: 3.5695\n",
      "Epoch [1622/2000], Avg Val Loss: 2.2502\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5647\n",
      "Epoch [1623/2000], Avg Train Loss: 3.5647\n",
      "Epoch [1623/2000], Avg Val Loss: 2.2500\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5426\n",
      "Epoch [1624/2000], Avg Train Loss: 3.5426\n",
      "Epoch [1624/2000], Avg Val Loss: 2.2497\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5467\n",
      "Epoch [1625/2000], Avg Train Loss: 3.5467\n",
      "Epoch [1625/2000], Avg Val Loss: 2.2495\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5205\n",
      "Epoch [1626/2000], Avg Train Loss: 3.5205\n",
      "Epoch [1626/2000], Avg Val Loss: 2.2494\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5470\n",
      "Epoch [1627/2000], Avg Train Loss: 3.5470\n",
      "Epoch [1627/2000], Avg Val Loss: 2.2491\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5311\n",
      "Epoch [1628/2000], Avg Train Loss: 3.5311\n",
      "Epoch [1628/2000], Avg Val Loss: 2.2484\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5480\n",
      "Epoch [1629/2000], Avg Train Loss: 3.5480\n",
      "Epoch [1629/2000], Avg Val Loss: 2.2477\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5424\n",
      "Epoch [1630/2000], Avg Train Loss: 3.5424\n",
      "Epoch [1630/2000], Avg Val Loss: 2.2470\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5548\n",
      "Epoch [1631/2000], Avg Train Loss: 3.5548\n",
      "Epoch [1631/2000], Avg Val Loss: 2.2464\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5794\n",
      "Epoch [1632/2000], Avg Train Loss: 3.5794\n",
      "Epoch [1632/2000], Avg Val Loss: 2.2455\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5307\n",
      "Epoch [1633/2000], Avg Train Loss: 3.5307\n",
      "Epoch [1633/2000], Avg Val Loss: 2.2445\n",
      "Validation loss improved from 2.2455 to 2.2445. Saving model...\n",
      "\n",
      "LOG: Epoch [1634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5638\n",
      "Epoch [1634/2000], Avg Train Loss: 3.5638\n",
      "Epoch [1634/2000], Avg Val Loss: 2.2435\n",
      "Validation loss improved from 2.2445 to 2.2435. Saving model...\n",
      "\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5416\n",
      "Epoch [1635/2000], Avg Train Loss: 3.5416\n",
      "Epoch [1635/2000], Avg Val Loss: 2.2428\n",
      "Validation loss improved from 2.2435 to 2.2428. Saving model...\n",
      "\n",
      "LOG: Epoch [1636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5792\n",
      "Epoch [1636/2000], Avg Train Loss: 3.5792\n",
      "Epoch [1636/2000], Avg Val Loss: 2.2421\n",
      "Validation loss improved from 2.2428 to 2.2421. Saving model...\n",
      "\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5006\n",
      "Epoch [1637/2000], Avg Train Loss: 3.5006\n",
      "Epoch [1637/2000], Avg Val Loss: 2.2413\n",
      "Validation loss improved from 2.2421 to 2.2413. Saving model...\n",
      "\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5553\n",
      "Epoch [1638/2000], Avg Train Loss: 3.5553\n",
      "Epoch [1638/2000], Avg Val Loss: 2.2408\n",
      "Validation loss improved from 2.2413 to 2.2408. Saving model...\n",
      "\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5262\n",
      "Epoch [1639/2000], Avg Train Loss: 3.5262\n",
      "Epoch [1639/2000], Avg Val Loss: 2.2403\n",
      "Validation loss improved from 2.2408 to 2.2403. Saving model...\n",
      "\n",
      "LOG: Epoch [1640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5667\n",
      "Epoch [1640/2000], Avg Train Loss: 3.5667\n",
      "Epoch [1640/2000], Avg Val Loss: 2.2401\n",
      "Validation loss improved from 2.2403 to 2.2401. Saving model...\n",
      "\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5801\n",
      "Epoch [1641/2000], Avg Train Loss: 3.5801\n",
      "Epoch [1641/2000], Avg Val Loss: 2.2400\n",
      "Validation loss improved from 2.2401 to 2.2400. Saving model...\n",
      "\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5615\n",
      "Epoch [1642/2000], Avg Train Loss: 3.5615\n",
      "Epoch [1642/2000], Avg Val Loss: 2.2399\n",
      "Validation loss improved from 2.2400 to 2.2399. Saving model...\n",
      "\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5030\n",
      "Epoch [1643/2000], Avg Train Loss: 3.5030\n",
      "Epoch [1643/2000], Avg Val Loss: 2.2397\n",
      "Validation loss improved from 2.2399 to 2.2397. Saving model...\n",
      "\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5665\n",
      "Epoch [1644/2000], Avg Train Loss: 3.5665\n",
      "Epoch [1644/2000], Avg Val Loss: 2.2394\n",
      "Validation loss improved from 2.2397 to 2.2394. Saving model...\n",
      "\n",
      "LOG: Epoch [1645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5772\n",
      "Epoch [1645/2000], Avg Train Loss: 3.5772\n",
      "Epoch [1645/2000], Avg Val Loss: 2.2396\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5341\n",
      "Epoch [1646/2000], Avg Train Loss: 3.5341\n",
      "Epoch [1646/2000], Avg Val Loss: 2.2396\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5415\n",
      "Epoch [1647/2000], Avg Train Loss: 3.5415\n",
      "Epoch [1647/2000], Avg Val Loss: 2.2395\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5264\n",
      "Epoch [1648/2000], Avg Train Loss: 3.5264\n",
      "Epoch [1648/2000], Avg Val Loss: 2.2393\n",
      "Validation loss improved from 2.2394 to 2.2393. Saving model...\n",
      "\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5580\n",
      "Epoch [1649/2000], Avg Train Loss: 3.5580\n",
      "Epoch [1649/2000], Avg Val Loss: 2.2395\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5410\n",
      "Epoch [1650/2000], Avg Train Loss: 3.5410\n",
      "Epoch [1650/2000], Avg Val Loss: 2.2398\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5410\n",
      "Epoch [1651/2000], Avg Train Loss: 3.5410\n",
      "Epoch [1651/2000], Avg Val Loss: 2.2402\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5482\n",
      "Epoch [1652/2000], Avg Train Loss: 3.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1652/2000], Avg Val Loss: 2.2405\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5477\n",
      "Epoch [1653/2000], Avg Train Loss: 3.5477\n",
      "Epoch [1653/2000], Avg Val Loss: 2.2406\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5405\n",
      "Epoch [1654/2000], Avg Train Loss: 3.5405\n",
      "Epoch [1654/2000], Avg Val Loss: 2.2408\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5666\n",
      "Epoch [1655/2000], Avg Train Loss: 3.5666\n",
      "Epoch [1655/2000], Avg Val Loss: 2.2409\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5877\n",
      "Epoch [1656/2000], Avg Train Loss: 3.5877\n",
      "Epoch [1656/2000], Avg Val Loss: 2.2411\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5407\n",
      "Epoch [1657/2000], Avg Train Loss: 3.5407\n",
      "Epoch [1657/2000], Avg Val Loss: 2.2413\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5121\n",
      "Epoch [1658/2000], Avg Train Loss: 3.5121\n",
      "Epoch [1658/2000], Avg Val Loss: 2.2415\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5499\n",
      "Epoch [1659/2000], Avg Train Loss: 3.5499\n",
      "Epoch [1659/2000], Avg Val Loss: 2.2416\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5093\n",
      "Epoch [1660/2000], Avg Train Loss: 3.5093\n",
      "Epoch [1660/2000], Avg Val Loss: 2.2420\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5355\n",
      "Epoch [1661/2000], Avg Train Loss: 3.5355\n",
      "Epoch [1661/2000], Avg Val Loss: 2.2424\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5220\n",
      "Epoch [1662/2000], Avg Train Loss: 3.5220\n",
      "Epoch [1662/2000], Avg Val Loss: 2.2429\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5291\n",
      "Epoch [1663/2000], Avg Train Loss: 3.5291\n",
      "Epoch [1663/2000], Avg Val Loss: 2.2431\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5399\n",
      "Epoch [1664/2000], Avg Train Loss: 3.5399\n",
      "Epoch [1664/2000], Avg Val Loss: 2.2432\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5276\n",
      "Epoch [1665/2000], Avg Train Loss: 3.5276\n",
      "Epoch [1665/2000], Avg Val Loss: 2.2433\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5604\n",
      "Epoch [1666/2000], Avg Train Loss: 3.5604\n",
      "Epoch [1666/2000], Avg Val Loss: 2.2433\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5084\n",
      "Epoch [1667/2000], Avg Train Loss: 3.5084\n",
      "Epoch [1667/2000], Avg Val Loss: 2.2435\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5270\n",
      "Epoch [1668/2000], Avg Train Loss: 3.5270\n",
      "Epoch [1668/2000], Avg Val Loss: 2.2435\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5469\n",
      "Epoch [1669/2000], Avg Train Loss: 3.5469\n",
      "Epoch [1669/2000], Avg Val Loss: 2.2436\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5708\n",
      "Epoch [1670/2000], Avg Train Loss: 3.5708\n",
      "Epoch [1670/2000], Avg Val Loss: 2.2437\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5754\n",
      "Epoch [1671/2000], Avg Train Loss: 3.5754\n",
      "Epoch [1671/2000], Avg Val Loss: 2.2440\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5375\n",
      "Epoch [1672/2000], Avg Train Loss: 3.5375\n",
      "Epoch [1672/2000], Avg Val Loss: 2.2443\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5360\n",
      "Epoch [1673/2000], Avg Train Loss: 3.5360\n",
      "Epoch [1673/2000], Avg Val Loss: 2.2448\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5395\n",
      "Epoch [1674/2000], Avg Train Loss: 3.5395\n",
      "Epoch [1674/2000], Avg Val Loss: 2.2451\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5407\n",
      "Epoch [1675/2000], Avg Train Loss: 3.5407\n",
      "Epoch [1675/2000], Avg Val Loss: 2.2454\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5493\n",
      "Epoch [1676/2000], Avg Train Loss: 3.5493\n",
      "Epoch [1676/2000], Avg Val Loss: 2.2456\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5410\n",
      "Epoch [1677/2000], Avg Train Loss: 3.5410\n",
      "Epoch [1677/2000], Avg Val Loss: 2.2458\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5103\n",
      "Epoch [1678/2000], Avg Train Loss: 3.5103\n",
      "Epoch [1678/2000], Avg Val Loss: 2.2459\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5262\n",
      "Epoch [1679/2000], Avg Train Loss: 3.5262\n",
      "Epoch [1679/2000], Avg Val Loss: 2.2461\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5437\n",
      "Epoch [1680/2000], Avg Train Loss: 3.5437\n",
      "Epoch [1680/2000], Avg Val Loss: 2.2462\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5083\n",
      "Epoch [1681/2000], Avg Train Loss: 3.5083\n",
      "Epoch [1681/2000], Avg Val Loss: 2.2460\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5317\n",
      "Epoch [1682/2000], Avg Train Loss: 3.5317\n",
      "Epoch [1682/2000], Avg Val Loss: 2.2460\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5125\n",
      "Epoch [1683/2000], Avg Train Loss: 3.5125\n",
      "Epoch [1683/2000], Avg Val Loss: 2.2458\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5585\n",
      "Epoch [1684/2000], Avg Train Loss: 3.5585\n",
      "Epoch [1684/2000], Avg Val Loss: 2.2456\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [1685/2000], Avg Train Loss: 3.5435\n",
      "Epoch [1685/2000], Avg Val Loss: 2.2453\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5459\n",
      "Epoch [1686/2000], Avg Train Loss: 3.5459\n",
      "Epoch [1686/2000], Avg Val Loss: 2.2446\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5488\n",
      "Epoch [1687/2000], Avg Train Loss: 3.5488\n",
      "Epoch [1687/2000], Avg Val Loss: 2.2438\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5444\n",
      "Epoch [1688/2000], Avg Train Loss: 3.5444\n",
      "Epoch [1688/2000], Avg Val Loss: 2.2430\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5203\n",
      "Epoch [1689/2000], Avg Train Loss: 3.5203\n",
      "Epoch [1689/2000], Avg Val Loss: 2.2420\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5364\n",
      "Epoch [1690/2000], Avg Train Loss: 3.5364\n",
      "Epoch [1690/2000], Avg Val Loss: 2.2413\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5263\n",
      "Epoch [1691/2000], Avg Train Loss: 3.5263\n",
      "Epoch [1691/2000], Avg Val Loss: 2.2404\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5161\n",
      "Epoch [1692/2000], Avg Train Loss: 3.5161\n",
      "Epoch [1692/2000], Avg Val Loss: 2.2398\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5585\n",
      "Epoch [1693/2000], Avg Train Loss: 3.5585\n",
      "Epoch [1693/2000], Avg Val Loss: 2.2391\n",
      "Validation loss improved from 2.2393 to 2.2391. Saving model...\n",
      "\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5398\n",
      "Epoch [1694/2000], Avg Train Loss: 3.5398\n",
      "Epoch [1694/2000], Avg Val Loss: 2.2386\n",
      "Validation loss improved from 2.2391 to 2.2386. Saving model...\n",
      "\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5475\n",
      "Epoch [1695/2000], Avg Train Loss: 3.5475\n",
      "Epoch [1695/2000], Avg Val Loss: 2.2382\n",
      "Validation loss improved from 2.2386 to 2.2382. Saving model...\n",
      "\n",
      "LOG: Epoch [1696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5340\n",
      "Epoch [1696/2000], Avg Train Loss: 3.5340\n",
      "Epoch [1696/2000], Avg Val Loss: 2.2380\n",
      "Validation loss improved from 2.2382 to 2.2380. Saving model...\n",
      "\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5393\n",
      "Epoch [1697/2000], Avg Train Loss: 3.5393\n",
      "Epoch [1697/2000], Avg Val Loss: 2.2379\n",
      "Validation loss improved from 2.2380 to 2.2379. Saving model...\n",
      "\n",
      "LOG: Epoch [1698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5252\n",
      "Epoch [1698/2000], Avg Train Loss: 3.5252\n",
      "Epoch [1698/2000], Avg Val Loss: 2.2380\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5089\n",
      "Epoch [1699/2000], Avg Train Loss: 3.5089\n",
      "Epoch [1699/2000], Avg Val Loss: 2.2380\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5228\n",
      "Epoch [1700/2000], Avg Train Loss: 3.5228\n",
      "Epoch [1700/2000], Avg Val Loss: 2.2378\n",
      "Validation loss improved from 2.2379 to 2.2378. Saving model...\n",
      "\n",
      "LOG: Epoch [1701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5139\n",
      "Epoch [1701/2000], Avg Train Loss: 3.5139\n",
      "Epoch [1701/2000], Avg Val Loss: 2.2377\n",
      "Validation loss improved from 2.2378 to 2.2377. Saving model...\n",
      "\n",
      "LOG: Epoch [1702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5168\n",
      "Epoch [1702/2000], Avg Train Loss: 3.5168\n",
      "Epoch [1702/2000], Avg Val Loss: 2.2376\n",
      "Validation loss improved from 2.2377 to 2.2376. Saving model...\n",
      "\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5158\n",
      "Epoch [1703/2000], Avg Train Loss: 3.5158\n",
      "Epoch [1703/2000], Avg Val Loss: 2.2377\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5325\n",
      "Epoch [1704/2000], Avg Train Loss: 3.5325\n",
      "Epoch [1704/2000], Avg Val Loss: 2.2376\n",
      "Validation loss improved from 2.2376 to 2.2376. Saving model...\n",
      "\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5427\n",
      "Epoch [1705/2000], Avg Train Loss: 3.5427\n",
      "Epoch [1705/2000], Avg Val Loss: 2.2374\n",
      "Validation loss improved from 2.2376 to 2.2374. Saving model...\n",
      "\n",
      "LOG: Epoch [1706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5196\n",
      "Epoch [1706/2000], Avg Train Loss: 3.5196\n",
      "Epoch [1706/2000], Avg Val Loss: 2.2373\n",
      "Validation loss improved from 2.2374 to 2.2373. Saving model...\n",
      "\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5090\n",
      "Epoch [1707/2000], Avg Train Loss: 3.5090\n",
      "Epoch [1707/2000], Avg Val Loss: 2.2373\n",
      "Validation loss improved from 2.2373 to 2.2373. Saving model...\n",
      "\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5297\n",
      "Epoch [1708/2000], Avg Train Loss: 3.5297\n",
      "Epoch [1708/2000], Avg Val Loss: 2.2373\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5173\n",
      "Epoch [1709/2000], Avg Train Loss: 3.5173\n",
      "Epoch [1709/2000], Avg Val Loss: 2.2373\n",
      "Validation loss improved from 2.2373 to 2.2373. Saving model...\n",
      "\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5156\n",
      "Epoch [1710/2000], Avg Train Loss: 3.5156\n",
      "Epoch [1710/2000], Avg Val Loss: 2.2371\n",
      "Validation loss improved from 2.2373 to 2.2371. Saving model...\n",
      "\n",
      "LOG: Epoch [1711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5403\n",
      "Epoch [1711/2000], Avg Train Loss: 3.5403\n",
      "Epoch [1711/2000], Avg Val Loss: 2.2370\n",
      "Validation loss improved from 2.2371 to 2.2370. Saving model...\n",
      "\n",
      "LOG: Epoch [1712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5382\n",
      "Epoch [1712/2000], Avg Train Loss: 3.5382\n",
      "Epoch [1712/2000], Avg Val Loss: 2.2367\n",
      "Validation loss improved from 2.2370 to 2.2367. Saving model...\n",
      "\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5589\n",
      "Epoch [1713/2000], Avg Train Loss: 3.5589\n",
      "Epoch [1713/2000], Avg Val Loss: 2.2366\n",
      "Validation loss improved from 2.2367 to 2.2366. Saving model...\n",
      "\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5174\n",
      "Epoch [1714/2000], Avg Train Loss: 3.5174\n",
      "Epoch [1714/2000], Avg Val Loss: 2.2365\n",
      "Validation loss improved from 2.2366 to 2.2365. Saving model...\n",
      "\n",
      "LOG: Epoch [1715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5454\n",
      "Epoch [1715/2000], Avg Train Loss: 3.5454\n",
      "Epoch [1715/2000], Avg Val Loss: 2.2365\n",
      "Validation loss improved from 2.2365 to 2.2365. Saving model...\n",
      "\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5073\n",
      "Epoch [1716/2000], Avg Train Loss: 3.5073\n",
      "Epoch [1716/2000], Avg Val Loss: 2.2364\n",
      "Validation loss improved from 2.2365 to 2.2364. Saving model...\n",
      "\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5530\n",
      "Epoch [1717/2000], Avg Train Loss: 3.5530\n",
      "Epoch [1717/2000], Avg Val Loss: 2.2361\n",
      "Validation loss improved from 2.2364 to 2.2361. Saving model...\n",
      "\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5427\n",
      "Epoch [1718/2000], Avg Train Loss: 3.5427\n",
      "Epoch [1718/2000], Avg Val Loss: 2.2359\n",
      "Validation loss improved from 2.2361 to 2.2359. Saving model...\n",
      "\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5342\n",
      "Epoch [1719/2000], Avg Train Loss: 3.5342\n",
      "Epoch [1719/2000], Avg Val Loss: 2.2356\n",
      "Validation loss improved from 2.2359 to 2.2356. Saving model...\n",
      "\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5442\n",
      "Epoch [1720/2000], Avg Train Loss: 3.5442\n",
      "Epoch [1720/2000], Avg Val Loss: 2.2353\n",
      "Validation loss improved from 2.2356 to 2.2353. Saving model...\n",
      "\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5191\n",
      "Epoch [1721/2000], Avg Train Loss: 3.5191\n",
      "Epoch [1721/2000], Avg Val Loss: 2.2352\n",
      "Validation loss improved from 2.2353 to 2.2352. Saving model...\n",
      "\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5299\n",
      "Epoch [1722/2000], Avg Train Loss: 3.5299\n",
      "Epoch [1722/2000], Avg Val Loss: 2.2349\n",
      "Validation loss improved from 2.2352 to 2.2349. Saving model...\n",
      "\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5273\n",
      "Epoch [1723/2000], Avg Train Loss: 3.5273\n",
      "Epoch [1723/2000], Avg Val Loss: 2.2348\n",
      "Validation loss improved from 2.2349 to 2.2348. Saving model...\n",
      "\n",
      "LOG: Epoch [1724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5378\n",
      "Epoch [1724/2000], Avg Train Loss: 3.5378\n",
      "Epoch [1724/2000], Avg Val Loss: 2.2347\n",
      "Validation loss improved from 2.2348 to 2.2347. Saving model...\n",
      "\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5179\n",
      "Epoch [1725/2000], Avg Train Loss: 3.5179\n",
      "Epoch [1725/2000], Avg Val Loss: 2.2347\n",
      "Validation loss improved from 2.2347 to 2.2347. Saving model...\n",
      "\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5019\n",
      "Epoch [1726/2000], Avg Train Loss: 3.5019\n",
      "Epoch [1726/2000], Avg Val Loss: 2.2347\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5358\n",
      "Epoch [1727/2000], Avg Train Loss: 3.5358\n",
      "Epoch [1727/2000], Avg Val Loss: 2.2348\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4939\n",
      "Epoch [1728/2000], Avg Train Loss: 3.4939\n",
      "Epoch [1728/2000], Avg Val Loss: 2.2350\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5280\n",
      "Epoch [1729/2000], Avg Train Loss: 3.5280\n",
      "Epoch [1729/2000], Avg Val Loss: 2.2354\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5279\n",
      "Epoch [1730/2000], Avg Train Loss: 3.5279\n",
      "Epoch [1730/2000], Avg Val Loss: 2.2357\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4907\n",
      "Epoch [1731/2000], Avg Train Loss: 3.4907\n",
      "Epoch [1731/2000], Avg Val Loss: 2.2361\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5108\n",
      "Epoch [1732/2000], Avg Train Loss: 3.5108\n",
      "Epoch [1732/2000], Avg Val Loss: 2.2363\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5325\n",
      "Epoch [1733/2000], Avg Train Loss: 3.5325\n",
      "Epoch [1733/2000], Avg Val Loss: 2.2367\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5253\n",
      "Epoch [1734/2000], Avg Train Loss: 3.5253\n",
      "Epoch [1734/2000], Avg Val Loss: 2.2370\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5273\n",
      "Epoch [1735/2000], Avg Train Loss: 3.5273\n",
      "Epoch [1735/2000], Avg Val Loss: 2.2373\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5205\n",
      "Epoch [1736/2000], Avg Train Loss: 3.5205\n",
      "Epoch [1736/2000], Avg Val Loss: 2.2376\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5174\n",
      "Epoch [1737/2000], Avg Train Loss: 3.5174\n",
      "Epoch [1737/2000], Avg Val Loss: 2.2379\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5622\n",
      "Epoch [1738/2000], Avg Train Loss: 3.5622\n",
      "Epoch [1738/2000], Avg Val Loss: 2.2381\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5165\n",
      "Epoch [1739/2000], Avg Train Loss: 3.5165\n",
      "Epoch [1739/2000], Avg Val Loss: 2.2383\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5012\n",
      "Epoch [1740/2000], Avg Train Loss: 3.5012\n",
      "Epoch [1740/2000], Avg Val Loss: 2.2386\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5005\n",
      "Epoch [1741/2000], Avg Train Loss: 3.5005\n",
      "Epoch [1741/2000], Avg Val Loss: 2.2387\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5302\n",
      "Epoch [1742/2000], Avg Train Loss: 3.5302\n",
      "Epoch [1742/2000], Avg Val Loss: 2.2390\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5098\n",
      "Epoch [1743/2000], Avg Train Loss: 3.5098\n",
      "Epoch [1743/2000], Avg Val Loss: 2.2392\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5210\n",
      "Epoch [1744/2000], Avg Train Loss: 3.5210\n",
      "Epoch [1744/2000], Avg Val Loss: 2.2394\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5129\n",
      "Epoch [1745/2000], Avg Train Loss: 3.5129\n",
      "Epoch [1745/2000], Avg Val Loss: 2.2396\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5411\n",
      "Epoch [1746/2000], Avg Train Loss: 3.5411\n",
      "Epoch [1746/2000], Avg Val Loss: 2.2398\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5348\n",
      "Epoch [1747/2000], Avg Train Loss: 3.5348\n",
      "Epoch [1747/2000], Avg Val Loss: 2.2401\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5198\n",
      "Epoch [1748/2000], Avg Train Loss: 3.5198\n",
      "Epoch [1748/2000], Avg Val Loss: 2.2401\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4998\n",
      "Epoch [1749/2000], Avg Train Loss: 3.4998\n",
      "Epoch [1749/2000], Avg Val Loss: 2.2402\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5058\n",
      "Epoch [1750/2000], Avg Train Loss: 3.5058\n",
      "Epoch [1750/2000], Avg Val Loss: 2.2403\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5498\n",
      "Epoch [1751/2000], Avg Train Loss: 3.5498\n",
      "Epoch [1751/2000], Avg Val Loss: 2.2406\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5280\n",
      "Epoch [1752/2000], Avg Train Loss: 3.5280\n",
      "Epoch [1752/2000], Avg Val Loss: 2.2408\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5364\n",
      "Epoch [1753/2000], Avg Train Loss: 3.5364\n",
      "Epoch [1753/2000], Avg Val Loss: 2.2409\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5036\n",
      "Epoch [1754/2000], Avg Train Loss: 3.5036\n",
      "Epoch [1754/2000], Avg Val Loss: 2.2407\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5579\n",
      "Epoch [1755/2000], Avg Train Loss: 3.5579\n",
      "Epoch [1755/2000], Avg Val Loss: 2.2406\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4845\n",
      "Epoch [1756/2000], Avg Train Loss: 3.4845\n",
      "Epoch [1756/2000], Avg Val Loss: 2.2406\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5054\n",
      "Epoch [1757/2000], Avg Train Loss: 3.5054\n",
      "Epoch [1757/2000], Avg Val Loss: 2.2407\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5545\n",
      "Epoch [1758/2000], Avg Train Loss: 3.5545\n",
      "Epoch [1758/2000], Avg Val Loss: 2.2406\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5075\n",
      "Epoch [1759/2000], Avg Train Loss: 3.5075\n",
      "Epoch [1759/2000], Avg Val Loss: 2.2403\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5136\n",
      "Epoch [1760/2000], Avg Train Loss: 3.5136\n",
      "Epoch [1760/2000], Avg Val Loss: 2.2401\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5232\n",
      "Epoch [1761/2000], Avg Train Loss: 3.5232\n",
      "Epoch [1761/2000], Avg Val Loss: 2.2397\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5224\n",
      "Epoch [1762/2000], Avg Train Loss: 3.5224\n",
      "Epoch [1762/2000], Avg Val Loss: 2.2393\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5167\n",
      "Epoch [1763/2000], Avg Train Loss: 3.5167\n",
      "Epoch [1763/2000], Avg Val Loss: 2.2390\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5049\n",
      "Epoch [1764/2000], Avg Train Loss: 3.5049\n",
      "Epoch [1764/2000], Avg Val Loss: 2.2388\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5262\n",
      "Epoch [1765/2000], Avg Train Loss: 3.5262\n",
      "Epoch [1765/2000], Avg Val Loss: 2.2386\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5156\n",
      "Epoch [1766/2000], Avg Train Loss: 3.5156\n",
      "Epoch [1766/2000], Avg Val Loss: 2.2382\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4974\n",
      "Epoch [1767/2000], Avg Train Loss: 3.4974\n",
      "Epoch [1767/2000], Avg Val Loss: 2.2378\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5146\n",
      "Epoch [1768/2000], Avg Train Loss: 3.5146\n",
      "Epoch [1768/2000], Avg Val Loss: 2.2375\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5001\n",
      "Epoch [1769/2000], Avg Train Loss: 3.5001\n",
      "Epoch [1769/2000], Avg Val Loss: 2.2374\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5212\n",
      "Epoch [1770/2000], Avg Train Loss: 3.5212\n",
      "Epoch [1770/2000], Avg Val Loss: 2.2374\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4862\n",
      "Epoch [1771/2000], Avg Train Loss: 3.4862\n",
      "Epoch [1771/2000], Avg Val Loss: 2.2375\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5229\n",
      "Epoch [1772/2000], Avg Train Loss: 3.5229\n",
      "Epoch [1772/2000], Avg Val Loss: 2.2376\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5078\n",
      "Epoch [1773/2000], Avg Train Loss: 3.5078\n",
      "Epoch [1773/2000], Avg Val Loss: 2.2377\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5118\n",
      "Epoch [1774/2000], Avg Train Loss: 3.5118\n",
      "Epoch [1774/2000], Avg Val Loss: 2.2382\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4951\n",
      "Epoch [1775/2000], Avg Train Loss: 3.4951\n",
      "Epoch [1775/2000], Avg Val Loss: 2.2384\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4912\n",
      "Epoch [1776/2000], Avg Train Loss: 3.4912\n",
      "Epoch [1776/2000], Avg Val Loss: 2.2386\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5426\n",
      "Epoch [1777/2000], Avg Train Loss: 3.5426\n",
      "Epoch [1777/2000], Avg Val Loss: 2.2390\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5248\n",
      "Epoch [1778/2000], Avg Train Loss: 3.5248\n",
      "Epoch [1778/2000], Avg Val Loss: 2.2392\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5069\n",
      "Epoch [1779/2000], Avg Train Loss: 3.5069\n",
      "Epoch [1779/2000], Avg Val Loss: 2.2394\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5175\n",
      "Epoch [1780/2000], Avg Train Loss: 3.5175\n",
      "Epoch [1780/2000], Avg Val Loss: 2.2397\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4932\n",
      "Epoch [1781/2000], Avg Train Loss: 3.4932\n",
      "Epoch [1781/2000], Avg Val Loss: 2.2396\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5605\n",
      "Epoch [1782/2000], Avg Train Loss: 3.5605\n",
      "Epoch [1782/2000], Avg Val Loss: 2.2398\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5384\n",
      "Epoch [1783/2000], Avg Train Loss: 3.5384\n",
      "Epoch [1783/2000], Avg Val Loss: 2.2400\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5451\n",
      "Epoch [1784/2000], Avg Train Loss: 3.5451\n",
      "Epoch [1784/2000], Avg Val Loss: 2.2402\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4868\n",
      "Epoch [1785/2000], Avg Train Loss: 3.4868\n",
      "Epoch [1785/2000], Avg Val Loss: 2.2403\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5156\n",
      "Epoch [1786/2000], Avg Train Loss: 3.5156\n",
      "Epoch [1786/2000], Avg Val Loss: 2.2401\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5183\n",
      "Epoch [1787/2000], Avg Train Loss: 3.5183\n",
      "Epoch [1787/2000], Avg Val Loss: 2.2401\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5213\n",
      "Epoch [1788/2000], Avg Train Loss: 3.5213\n",
      "Epoch [1788/2000], Avg Val Loss: 2.2401\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4951\n",
      "Epoch [1789/2000], Avg Train Loss: 3.4951\n",
      "Epoch [1789/2000], Avg Val Loss: 2.2399\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5061\n",
      "Epoch [1790/2000], Avg Train Loss: 3.5061\n",
      "Epoch [1790/2000], Avg Val Loss: 2.2395\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5023\n",
      "Epoch [1791/2000], Avg Train Loss: 3.5023\n",
      "Epoch [1791/2000], Avg Val Loss: 2.2393\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4835\n",
      "Epoch [1792/2000], Avg Train Loss: 3.4835\n",
      "Epoch [1792/2000], Avg Val Loss: 2.2394\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5187\n",
      "Epoch [1793/2000], Avg Train Loss: 3.5187\n",
      "Epoch [1793/2000], Avg Val Loss: 2.2395\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4701\n",
      "Epoch [1794/2000], Avg Train Loss: 3.4701\n",
      "Epoch [1794/2000], Avg Val Loss: 2.2395\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4952\n",
      "Epoch [1795/2000], Avg Train Loss: 3.4952\n",
      "Epoch [1795/2000], Avg Val Loss: 2.2394\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5187\n",
      "Epoch [1796/2000], Avg Train Loss: 3.5187\n",
      "Epoch [1796/2000], Avg Val Loss: 2.2391\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5156\n",
      "Epoch [1797/2000], Avg Train Loss: 3.5156\n",
      "Epoch [1797/2000], Avg Val Loss: 2.2387\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4961\n",
      "Epoch [1798/2000], Avg Train Loss: 3.4961\n",
      "Epoch [1798/2000], Avg Val Loss: 2.2384\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5162\n",
      "Epoch [1799/2000], Avg Train Loss: 3.5162\n",
      "Epoch [1799/2000], Avg Val Loss: 2.2382\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5116\n",
      "Epoch [1800/2000], Avg Train Loss: 3.5116\n",
      "Epoch [1800/2000], Avg Val Loss: 2.2381\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5331\n",
      "Epoch [1801/2000], Avg Train Loss: 3.5331\n",
      "Epoch [1801/2000], Avg Val Loss: 2.2381\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5283\n",
      "Epoch [1802/2000], Avg Train Loss: 3.5283\n",
      "Epoch [1802/2000], Avg Val Loss: 2.2380\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4733\n",
      "Epoch [1803/2000], Avg Train Loss: 3.4733\n",
      "Epoch [1803/2000], Avg Val Loss: 2.2380\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4905\n",
      "Epoch [1804/2000], Avg Train Loss: 3.4905\n",
      "Epoch [1804/2000], Avg Val Loss: 2.2378\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5360\n",
      "Epoch [1805/2000], Avg Train Loss: 3.5360\n",
      "Epoch [1805/2000], Avg Val Loss: 2.2377\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5074\n",
      "Epoch [1806/2000], Avg Train Loss: 3.5074\n",
      "Epoch [1806/2000], Avg Val Loss: 2.2373\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4540\n",
      "Epoch [1807/2000], Avg Train Loss: 3.4540\n",
      "Epoch [1807/2000], Avg Val Loss: 2.2368\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4740\n",
      "Epoch [1808/2000], Avg Train Loss: 3.4740\n",
      "Epoch [1808/2000], Avg Val Loss: 2.2363\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4841\n",
      "Epoch [1809/2000], Avg Train Loss: 3.4841\n",
      "Epoch [1809/2000], Avg Val Loss: 2.2360\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4841\n",
      "Epoch [1810/2000], Avg Train Loss: 3.4841\n",
      "Epoch [1810/2000], Avg Val Loss: 2.2358\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5105\n",
      "Epoch [1811/2000], Avg Train Loss: 3.5105\n",
      "Epoch [1811/2000], Avg Val Loss: 2.2357\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5143\n",
      "Epoch [1812/2000], Avg Train Loss: 3.5143\n",
      "Epoch [1812/2000], Avg Val Loss: 2.2359\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5050\n",
      "Epoch [1813/2000], Avg Train Loss: 3.5050\n",
      "Epoch [1813/2000], Avg Val Loss: 2.2359\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4990\n",
      "Epoch [1814/2000], Avg Train Loss: 3.4990\n",
      "Epoch [1814/2000], Avg Val Loss: 2.2360\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5049\n",
      "Epoch [1815/2000], Avg Train Loss: 3.5049\n",
      "Epoch [1815/2000], Avg Val Loss: 2.2363\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5213\n",
      "Epoch [1816/2000], Avg Train Loss: 3.5213\n",
      "Epoch [1816/2000], Avg Val Loss: 2.2369\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4948\n",
      "Epoch [1817/2000], Avg Train Loss: 3.4948\n",
      "Epoch [1817/2000], Avg Val Loss: 2.2374\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4794\n",
      "Epoch [1818/2000], Avg Train Loss: 3.4794\n",
      "Epoch [1818/2000], Avg Val Loss: 2.2378\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4927\n",
      "Epoch [1819/2000], Avg Train Loss: 3.4927\n",
      "Epoch [1819/2000], Avg Val Loss: 2.2382\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5116\n",
      "Epoch [1820/2000], Avg Train Loss: 3.5116\n",
      "Epoch [1820/2000], Avg Val Loss: 2.2386\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4983\n",
      "Epoch [1821/2000], Avg Train Loss: 3.4983\n",
      "Epoch [1821/2000], Avg Val Loss: 2.2390\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5026\n",
      "Epoch [1822/2000], Avg Train Loss: 3.5026\n",
      "Epoch [1822/2000], Avg Val Loss: 2.2390\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5123\n",
      "Epoch [1823/2000], Avg Train Loss: 3.5123\n",
      "Epoch [1823/2000], Avg Val Loss: 2.2389\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5256\n",
      "Epoch [1824/2000], Avg Train Loss: 3.5256\n",
      "Epoch [1824/2000], Avg Val Loss: 2.2389\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4789\n",
      "Epoch [1825/2000], Avg Train Loss: 3.4789\n",
      "Epoch [1825/2000], Avg Val Loss: 2.2386\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1825. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:21.630729Z",
     "iopub.status.busy": "2025-05-09T02:06:21.629734Z",
     "iopub.status.idle": "2025-05-09T02:06:22.036882Z",
     "shell.execute_reply": "2025-05-09T02:06:22.036882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/210], Loss: 4.7845\n",
      "Test Batch [20/210], Loss: 4.9980\n",
      "Test Batch [30/210], Loss: 5.4272\n",
      "Test Batch [40/210], Loss: 5.4980\n",
      "Test Batch [50/210], Loss: 4.6673\n",
      "Test Batch [60/210], Loss: 4.7168\n",
      "Test Batch [70/210], Loss: 4.8821\n",
      "Test Batch [80/210], Loss: 5.0698\n",
      "Test Batch [90/210], Loss: 5.3908\n",
      "Test Batch [100/210], Loss: 5.3767\n",
      "Test Batch [110/210], Loss: 5.1101\n",
      "Test Batch [120/210], Loss: 4.5278\n",
      "Test Batch [130/210], Loss: 5.0010\n",
      "Test Batch [140/210], Loss: 4.9275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [150/210], Loss: 5.0098\n",
      "Test Batch [160/210], Loss: 5.0043\n",
      "Test Batch [170/210], Loss: 4.8645\n",
      "Test Batch [180/210], Loss: 4.9149\n",
      "Test Batch [190/210], Loss: 4.8102\n",
      "Test Batch [200/210], Loss: 4.9774\n",
      "Test Batch [210/210], Loss: 4.7281\n",
      "\n",
      "Test Loss: 4.9685\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:22.040271Z",
     "iopub.status.busy": "2025-05-09T02:06:22.039270Z",
     "iopub.status.idle": "2025-05-09T02:06:22.768941Z",
     "shell.execute_reply": "2025-05-09T02:06:22.768941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 10/210 for test dataset.\n",
      "  Processed batch 20/210 for test dataset.\n",
      "  Processed batch 30/210 for test dataset.\n",
      "  Processed batch 40/210 for test dataset.\n",
      "  Processed batch 50/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 60/210 for test dataset.\n",
      "  Processed batch 70/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 80/210 for test dataset.\n",
      "  Processed batch 90/210 for test dataset.\n",
      "  Processed batch 100/210 for test dataset.\n",
      "  Processed batch 110/210 for test dataset.\n",
      "  Processed batch 120/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 130/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 140/210 for test dataset.\n",
      "  Processed batch 150/210 for test dataset.\n",
      "  Processed batch 160/210 for test dataset.\n",
      "  Processed batch 170/210 for test dataset.\n",
      "  Processed batch 180/210 for test dataset.\n",
      "  Processed batch 190/210 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 200/210 for test dataset.\n",
      "  Processed batch 210/210 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:22.771946Z",
     "iopub.status.busy": "2025-05-09T02:06:22.770947Z",
     "iopub.status.idle": "2025-05-09T02:06:22.774958Z",
     "shell.execute_reply": "2025-05-09T02:06:22.774958Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:22.777331Z",
     "iopub.status.busy": "2025-05-09T02:06:22.777331Z",
     "iopub.status.idle": "2025-05-09T02:06:24.297472Z",
     "shell.execute_reply": "2025-05-09T02:06:24.297122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (320, 128)\n",
      "Train labels shape: (320,)\n",
      "Val reps shape: (80, 128)\n",
      "Val labels shape: (80,)\n",
      "Test reps shape: (53729, 128)\n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:24.299481Z",
     "iopub.status.busy": "2025-05-09T02:06:24.299481Z",
     "iopub.status.idle": "2025-05-09T02:06:24.431267Z",
     "shell.execute_reply": "2025-05-09T02:06:24.431267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 93.75%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.75      0.60      0.67         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      0.80      0.89         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       0.83      1.00      0.91         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.60      0.60      0.60         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.94      0.94      0.94        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 83.67%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1984\n",
      "           1       0.99      0.95      0.97      3701\n",
      "           2       0.94      0.96      0.95      1951\n",
      "           3       0.99      0.99      0.99      1369\n",
      "           4       0.97      1.00      0.98      2653\n",
      "           5       1.00      0.99      1.00      3934\n",
      "           6       0.97      0.94      0.95      3554\n",
      "           7       0.77      0.64      0.70     11246\n",
      "           8       0.99      0.93      0.96      6178\n",
      "           9       0.83      0.77      0.80      3253\n",
      "          10       0.51      0.83      0.63      1043\n",
      "          11       0.85      0.98      0.91      1902\n",
      "          12       0.75      0.99      0.85       891\n",
      "          13       0.77      0.94      0.85      1045\n",
      "          14       0.58      0.65      0.62      7243\n",
      "          15       0.76      0.89      0.82      1782\n",
      "\n",
      "    accuracy                           0.84     53729\n",
      "   macro avg       0.85      0.90      0.87     53729\n",
      "weighted avg       0.85      0.84      0.84     53729\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:24.434275Z",
     "iopub.status.busy": "2025-05-09T02:06:24.434275Z",
     "iopub.status.idle": "2025-05-09T02:06:24.438541Z",
     "shell.execute_reply": "2025-05-09T02:06:24.438541Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:24.440550Z",
     "iopub.status.busy": "2025-05-09T02:06:24.440550Z",
     "iopub.status.idle": "2025-05-09T02:06:24.504504Z",
     "shell.execute_reply": "2025-05-09T02:06:24.504504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (320, 128)\n",
      "Train labels shape: (320,)\n",
      "Val reps shape: (80, 128)\n",
      "Val labels shape: (80,)\n",
      "Test reps shape: (53729, 128)\n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:24.507509Z",
     "iopub.status.busy": "2025-05-09T02:06:24.507509Z",
     "iopub.status.idle": "2025-05-09T02:06:24.516650Z",
     "shell.execute_reply": "2025-05-09T02:06:24.516650Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:24.520659Z",
     "iopub.status.busy": "2025-05-09T02:06:24.519657Z",
     "iopub.status.idle": "2025-05-09T02:06:28.898468Z",
     "shell.execute_reply": "2025-05-09T02:06:28.898468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.8315  |  Val Loss: 2.8159\n",
      "Validation loss improved from inf to 2.8159.\n",
      "[Epoch 2/1000] Train Loss: 2.7970  |  Val Loss: 2.7828\n",
      "Validation loss improved from 2.8159 to 2.7828.\n",
      "[Epoch 3/1000] Train Loss: 2.7656  |  Val Loss: 2.7514\n",
      "Validation loss improved from 2.7828 to 2.7514.\n",
      "[Epoch 4/1000] Train Loss: 2.7370  |  Val Loss: 2.7232\n",
      "Validation loss improved from 2.7514 to 2.7232.\n",
      "[Epoch 5/1000] Train Loss: 2.7108  |  Val Loss: 2.6983\n",
      "Validation loss improved from 2.7232 to 2.6983.\n",
      "[Epoch 6/1000] Train Loss: 2.6866  |  Val Loss: 2.6747\n",
      "Validation loss improved from 2.6983 to 2.6747.\n",
      "[Epoch 7/1000] Train Loss: 2.6627  |  Val Loss: 2.6514\n",
      "Validation loss improved from 2.6747 to 2.6514.\n",
      "[Epoch 8/1000] Train Loss: 2.6402  |  Val Loss: 2.6277\n",
      "Validation loss improved from 2.6514 to 2.6277.\n",
      "[Epoch 9/1000] Train Loss: 2.6164  |  Val Loss: 2.6054\n",
      "Validation loss improved from 2.6277 to 2.6054.\n",
      "[Epoch 10/1000] Train Loss: 2.5946  |  Val Loss: 2.5838\n",
      "Validation loss improved from 2.6054 to 2.5838.\n",
      "[Epoch 11/1000] Train Loss: 2.5729  |  Val Loss: 2.5618\n",
      "Validation loss improved from 2.5838 to 2.5618.\n",
      "[Epoch 12/1000] Train Loss: 2.5509  |  Val Loss: 2.5401\n",
      "Validation loss improved from 2.5618 to 2.5401.\n",
      "[Epoch 13/1000] Train Loss: 2.5292  |  Val Loss: 2.5182\n",
      "Validation loss improved from 2.5401 to 2.5182.\n",
      "[Epoch 14/1000] Train Loss: 2.5072  |  Val Loss: 2.4962\n",
      "Validation loss improved from 2.5182 to 2.4962.\n",
      "[Epoch 15/1000] Train Loss: 2.4863  |  Val Loss: 2.4744\n",
      "Validation loss improved from 2.4962 to 2.4744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/1000] Train Loss: 2.4636  |  Val Loss: 2.4529\n",
      "Validation loss improved from 2.4744 to 2.4529.\n",
      "[Epoch 17/1000] Train Loss: 2.4414  |  Val Loss: 2.4291\n",
      "Validation loss improved from 2.4529 to 2.4291.\n",
      "[Epoch 18/1000] Train Loss: 2.4168  |  Val Loss: 2.4041\n",
      "Validation loss improved from 2.4291 to 2.4041.\n",
      "[Epoch 19/1000] Train Loss: 2.3907  |  Val Loss: 2.3785\n",
      "Validation loss improved from 2.4041 to 2.3785.\n",
      "[Epoch 20/1000] Train Loss: 2.3643  |  Val Loss: 2.3528\n",
      "Validation loss improved from 2.3785 to 2.3528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/1000] Train Loss: 2.3375  |  Val Loss: 2.3279\n",
      "Validation loss improved from 2.3528 to 2.3279.\n",
      "[Epoch 22/1000] Train Loss: 2.3129  |  Val Loss: 2.3019\n",
      "Validation loss improved from 2.3279 to 2.3019.\n",
      "[Epoch 23/1000] Train Loss: 2.2857  |  Val Loss: 2.2764\n",
      "Validation loss improved from 2.3019 to 2.2764.\n",
      "[Epoch 24/1000] Train Loss: 2.2592  |  Val Loss: 2.2517\n",
      "Validation loss improved from 2.2764 to 2.2517.\n",
      "[Epoch 25/1000] Train Loss: 2.2331  |  Val Loss: 2.2281\n",
      "Validation loss improved from 2.2517 to 2.2281.\n",
      "[Epoch 26/1000] Train Loss: 2.2088  |  Val Loss: 2.2050\n",
      "Validation loss improved from 2.2281 to 2.2050.\n",
      "[Epoch 27/1000] Train Loss: 2.1844  |  Val Loss: 2.1826\n",
      "Validation loss improved from 2.2050 to 2.1826.\n",
      "[Epoch 28/1000] Train Loss: 2.1604  |  Val Loss: 2.1611\n",
      "Validation loss improved from 2.1826 to 2.1611.\n",
      "[Epoch 29/1000] Train Loss: 2.1380  |  Val Loss: 2.1401\n",
      "Validation loss improved from 2.1611 to 2.1401.\n",
      "[Epoch 30/1000] Train Loss: 2.1147  |  Val Loss: 2.1198\n",
      "Validation loss improved from 2.1401 to 2.1198.\n",
      "[Epoch 31/1000] Train Loss: 2.0926  |  Val Loss: 2.0996\n",
      "Validation loss improved from 2.1198 to 2.0996.\n",
      "[Epoch 32/1000] Train Loss: 2.0704  |  Val Loss: 2.0798\n",
      "Validation loss improved from 2.0996 to 2.0798.\n",
      "[Epoch 33/1000] Train Loss: 2.0482  |  Val Loss: 2.0601\n",
      "Validation loss improved from 2.0798 to 2.0601.\n",
      "[Epoch 34/1000] Train Loss: 2.0266  |  Val Loss: 2.0402\n",
      "Validation loss improved from 2.0601 to 2.0402.\n",
      "[Epoch 35/1000] Train Loss: 2.0044  |  Val Loss: 2.0207\n",
      "Validation loss improved from 2.0402 to 2.0207.\n",
      "[Epoch 36/1000] Train Loss: 1.9820  |  Val Loss: 2.0009\n",
      "Validation loss improved from 2.0207 to 2.0009.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/1000] Train Loss: 1.9593  |  Val Loss: 1.9812\n",
      "Validation loss improved from 2.0009 to 1.9812.\n",
      "[Epoch 38/1000] Train Loss: 1.9371  |  Val Loss: 1.9613\n",
      "Validation loss improved from 1.9812 to 1.9613.\n",
      "[Epoch 39/1000] Train Loss: 1.9141  |  Val Loss: 1.9413\n",
      "Validation loss improved from 1.9613 to 1.9413.\n",
      "[Epoch 40/1000] Train Loss: 1.8920  |  Val Loss: 1.9209\n",
      "Validation loss improved from 1.9413 to 1.9209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/1000] Train Loss: 1.8687  |  Val Loss: 1.9009\n",
      "Validation loss improved from 1.9209 to 1.9009.\n",
      "[Epoch 42/1000] Train Loss: 1.8465  |  Val Loss: 1.8806\n",
      "Validation loss improved from 1.9009 to 1.8806.\n",
      "[Epoch 43/1000] Train Loss: 1.8244  |  Val Loss: 1.8601\n",
      "Validation loss improved from 1.8806 to 1.8601.\n",
      "[Epoch 44/1000] Train Loss: 1.8015  |  Val Loss: 1.8389\n",
      "Validation loss improved from 1.8601 to 1.8389.\n",
      "[Epoch 45/1000] Train Loss: 1.7785  |  Val Loss: 1.8171\n",
      "Validation loss improved from 1.8389 to 1.8171.\n",
      "[Epoch 46/1000] Train Loss: 1.7550  |  Val Loss: 1.7949\n",
      "Validation loss improved from 1.8171 to 1.7949.\n",
      "[Epoch 47/1000] Train Loss: 1.7310  |  Val Loss: 1.7725\n",
      "Validation loss improved from 1.7949 to 1.7725.\n",
      "[Epoch 48/1000] Train Loss: 1.7068  |  Val Loss: 1.7502\n",
      "Validation loss improved from 1.7725 to 1.7502.\n",
      "[Epoch 49/1000] Train Loss: 1.6833  |  Val Loss: 1.7279\n",
      "Validation loss improved from 1.7502 to 1.7279.\n",
      "[Epoch 50/1000] Train Loss: 1.6588  |  Val Loss: 1.7061\n",
      "Validation loss improved from 1.7279 to 1.7061.\n",
      "[Epoch 51/1000] Train Loss: 1.6356  |  Val Loss: 1.6850\n",
      "Validation loss improved from 1.7061 to 1.6850.\n",
      "[Epoch 52/1000] Train Loss: 1.6128  |  Val Loss: 1.6639\n",
      "Validation loss improved from 1.6850 to 1.6639.\n",
      "[Epoch 53/1000] Train Loss: 1.5902  |  Val Loss: 1.6431\n",
      "Validation loss improved from 1.6639 to 1.6431.\n",
      "[Epoch 54/1000] Train Loss: 1.5678  |  Val Loss: 1.6229\n",
      "Validation loss improved from 1.6431 to 1.6229.\n",
      "[Epoch 55/1000] Train Loss: 1.5465  |  Val Loss: 1.6027\n",
      "Validation loss improved from 1.6229 to 1.6027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/1000] Train Loss: 1.5245  |  Val Loss: 1.5826\n",
      "Validation loss improved from 1.6027 to 1.5826.\n",
      "[Epoch 57/1000] Train Loss: 1.5029  |  Val Loss: 1.5628\n",
      "Validation loss improved from 1.5826 to 1.5628.\n",
      "[Epoch 58/1000] Train Loss: 1.4818  |  Val Loss: 1.5431\n",
      "Validation loss improved from 1.5628 to 1.5431.\n",
      "[Epoch 59/1000] Train Loss: 1.4604  |  Val Loss: 1.5238\n",
      "Validation loss improved from 1.5431 to 1.5238.\n",
      "[Epoch 60/1000] Train Loss: 1.4393  |  Val Loss: 1.5047\n",
      "Validation loss improved from 1.5238 to 1.5047.\n",
      "[Epoch 61/1000] Train Loss: 1.4184  |  Val Loss: 1.4855\n",
      "Validation loss improved from 1.5047 to 1.4855.\n",
      "[Epoch 62/1000] Train Loss: 1.3976  |  Val Loss: 1.4665\n",
      "Validation loss improved from 1.4855 to 1.4665.\n",
      "[Epoch 63/1000] Train Loss: 1.3771  |  Val Loss: 1.4478\n",
      "Validation loss improved from 1.4665 to 1.4478.\n",
      "[Epoch 64/1000] Train Loss: 1.3565  |  Val Loss: 1.4292\n",
      "Validation loss improved from 1.4478 to 1.4292.\n",
      "[Epoch 65/1000] Train Loss: 1.3363  |  Val Loss: 1.4106\n",
      "Validation loss improved from 1.4292 to 1.4106.\n",
      "[Epoch 66/1000] Train Loss: 1.3163  |  Val Loss: 1.3921\n",
      "Validation loss improved from 1.4106 to 1.3921.\n",
      "[Epoch 67/1000] Train Loss: 1.2959  |  Val Loss: 1.3740\n",
      "Validation loss improved from 1.3921 to 1.3740.\n",
      "[Epoch 68/1000] Train Loss: 1.2759  |  Val Loss: 1.3559\n",
      "Validation loss improved from 1.3740 to 1.3559.\n",
      "[Epoch 69/1000] Train Loss: 1.2563  |  Val Loss: 1.3381\n",
      "Validation loss improved from 1.3559 to 1.3381.\n",
      "[Epoch 70/1000] Train Loss: 1.2363  |  Val Loss: 1.3203\n",
      "Validation loss improved from 1.3381 to 1.3203.\n",
      "[Epoch 71/1000] Train Loss: 1.2167  |  Val Loss: 1.3030\n",
      "Validation loss improved from 1.3203 to 1.3030.\n",
      "[Epoch 72/1000] Train Loss: 1.1973  |  Val Loss: 1.2855\n",
      "Validation loss improved from 1.3030 to 1.2855.\n",
      "[Epoch 73/1000] Train Loss: 1.1783  |  Val Loss: 1.2682\n",
      "Validation loss improved from 1.2855 to 1.2682.\n",
      "[Epoch 74/1000] Train Loss: 1.1595  |  Val Loss: 1.2512\n",
      "Validation loss improved from 1.2682 to 1.2512.\n",
      "[Epoch 75/1000] Train Loss: 1.1406  |  Val Loss: 1.2344\n",
      "Validation loss improved from 1.2512 to 1.2344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76/1000] Train Loss: 1.1218  |  Val Loss: 1.2179\n",
      "Validation loss improved from 1.2344 to 1.2179.\n",
      "[Epoch 77/1000] Train Loss: 1.1038  |  Val Loss: 1.2016\n",
      "Validation loss improved from 1.2179 to 1.2016.\n",
      "[Epoch 78/1000] Train Loss: 1.0857  |  Val Loss: 1.1853\n",
      "Validation loss improved from 1.2016 to 1.1853.\n",
      "[Epoch 79/1000] Train Loss: 1.0680  |  Val Loss: 1.1696\n",
      "Validation loss improved from 1.1853 to 1.1696.\n",
      "[Epoch 80/1000] Train Loss: 1.0506  |  Val Loss: 1.1539\n",
      "Validation loss improved from 1.1696 to 1.1539.\n",
      "[Epoch 81/1000] Train Loss: 1.0329  |  Val Loss: 1.1384\n",
      "Validation loss improved from 1.1539 to 1.1384.\n",
      "[Epoch 82/1000] Train Loss: 1.0161  |  Val Loss: 1.1232\n",
      "Validation loss improved from 1.1384 to 1.1232.\n",
      "[Epoch 83/1000] Train Loss: 0.9992  |  Val Loss: 1.1079\n",
      "Validation loss improved from 1.1232 to 1.1079.\n",
      "[Epoch 84/1000] Train Loss: 0.9827  |  Val Loss: 1.0933\n",
      "Validation loss improved from 1.1079 to 1.0933.\n",
      "[Epoch 85/1000] Train Loss: 0.9667  |  Val Loss: 1.0785\n",
      "Validation loss improved from 1.0933 to 1.0785.\n",
      "[Epoch 86/1000] Train Loss: 0.9504  |  Val Loss: 1.0641\n",
      "Validation loss improved from 1.0785 to 1.0641.\n",
      "[Epoch 87/1000] Train Loss: 0.9348  |  Val Loss: 1.0499\n",
      "Validation loss improved from 1.0641 to 1.0499.\n",
      "[Epoch 88/1000] Train Loss: 0.9192  |  Val Loss: 1.0363\n",
      "Validation loss improved from 1.0499 to 1.0363.\n",
      "[Epoch 89/1000] Train Loss: 0.9041  |  Val Loss: 1.0231\n",
      "Validation loss improved from 1.0363 to 1.0231.\n",
      "[Epoch 90/1000] Train Loss: 0.8896  |  Val Loss: 1.0098\n",
      "Validation loss improved from 1.0231 to 1.0098.\n",
      "[Epoch 91/1000] Train Loss: 0.8751  |  Val Loss: 0.9966\n",
      "Validation loss improved from 1.0098 to 0.9966.\n",
      "[Epoch 92/1000] Train Loss: 0.8603  |  Val Loss: 0.9836\n",
      "Validation loss improved from 0.9966 to 0.9836.\n",
      "[Epoch 93/1000] Train Loss: 0.8462  |  Val Loss: 0.9710\n",
      "Validation loss improved from 0.9836 to 0.9710.\n",
      "[Epoch 94/1000] Train Loss: 0.8327  |  Val Loss: 0.9589\n",
      "Validation loss improved from 0.9710 to 0.9589.\n",
      "[Epoch 95/1000] Train Loss: 0.8189  |  Val Loss: 0.9470\n",
      "Validation loss improved from 0.9589 to 0.9470.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/1000] Train Loss: 0.8058  |  Val Loss: 0.9352\n",
      "Validation loss improved from 0.9470 to 0.9352.\n",
      "[Epoch 97/1000] Train Loss: 0.7928  |  Val Loss: 0.9234\n",
      "Validation loss improved from 0.9352 to 0.9234.\n",
      "[Epoch 98/1000] Train Loss: 0.7798  |  Val Loss: 0.9122\n",
      "Validation loss improved from 0.9234 to 0.9122.\n",
      "[Epoch 99/1000] Train Loss: 0.7672  |  Val Loss: 0.9013\n",
      "Validation loss improved from 0.9122 to 0.9013.\n",
      "[Epoch 100/1000] Train Loss: 0.7548  |  Val Loss: 0.8905\n",
      "Validation loss improved from 0.9013 to 0.8905.\n",
      "[Epoch 101/1000] Train Loss: 0.7427  |  Val Loss: 0.8794\n",
      "Validation loss improved from 0.8905 to 0.8794.\n",
      "[Epoch 102/1000] Train Loss: 0.7308  |  Val Loss: 0.8693\n",
      "Validation loss improved from 0.8794 to 0.8693.\n",
      "[Epoch 103/1000] Train Loss: 0.7190  |  Val Loss: 0.8588\n",
      "Validation loss improved from 0.8693 to 0.8588.\n",
      "[Epoch 104/1000] Train Loss: 0.7076  |  Val Loss: 0.8490\n",
      "Validation loss improved from 0.8588 to 0.8490.\n",
      "[Epoch 105/1000] Train Loss: 0.6962  |  Val Loss: 0.8387\n",
      "Validation loss improved from 0.8490 to 0.8387.\n",
      "[Epoch 106/1000] Train Loss: 0.6849  |  Val Loss: 0.8292\n",
      "Validation loss improved from 0.8387 to 0.8292.\n",
      "[Epoch 107/1000] Train Loss: 0.6740  |  Val Loss: 0.8195\n",
      "Validation loss improved from 0.8292 to 0.8195.\n",
      "[Epoch 108/1000] Train Loss: 0.6632  |  Val Loss: 0.8097\n",
      "Validation loss improved from 0.8195 to 0.8097.\n",
      "[Epoch 109/1000] Train Loss: 0.6524  |  Val Loss: 0.8006\n",
      "Validation loss improved from 0.8097 to 0.8006.\n",
      "[Epoch 110/1000] Train Loss: 0.6420  |  Val Loss: 0.7916\n",
      "Validation loss improved from 0.8006 to 0.7916.\n",
      "[Epoch 111/1000] Train Loss: 0.6315  |  Val Loss: 0.7827\n",
      "Validation loss improved from 0.7916 to 0.7827.\n",
      "[Epoch 112/1000] Train Loss: 0.6214  |  Val Loss: 0.7737\n",
      "Validation loss improved from 0.7827 to 0.7737.\n",
      "[Epoch 113/1000] Train Loss: 0.6118  |  Val Loss: 0.7651\n",
      "Validation loss improved from 0.7737 to 0.7651.\n",
      "[Epoch 114/1000] Train Loss: 0.6022  |  Val Loss: 0.7562\n",
      "Validation loss improved from 0.7651 to 0.7562.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 115/1000] Train Loss: 0.5922  |  Val Loss: 0.7481\n",
      "Validation loss improved from 0.7562 to 0.7481.\n",
      "[Epoch 116/1000] Train Loss: 0.5831  |  Val Loss: 0.7401\n",
      "Validation loss improved from 0.7481 to 0.7401.\n",
      "[Epoch 117/1000] Train Loss: 0.5740  |  Val Loss: 0.7327\n",
      "Validation loss improved from 0.7401 to 0.7327.\n",
      "[Epoch 118/1000] Train Loss: 0.5646  |  Val Loss: 0.7256\n",
      "Validation loss improved from 0.7327 to 0.7256.\n",
      "[Epoch 119/1000] Train Loss: 0.5559  |  Val Loss: 0.7181\n",
      "Validation loss improved from 0.7256 to 0.7181.\n",
      "[Epoch 120/1000] Train Loss: 0.5470  |  Val Loss: 0.7109\n",
      "Validation loss improved from 0.7181 to 0.7109.\n",
      "[Epoch 121/1000] Train Loss: 0.5387  |  Val Loss: 0.7036\n",
      "Validation loss improved from 0.7109 to 0.7036.\n",
      "[Epoch 122/1000] Train Loss: 0.5302  |  Val Loss: 0.6975\n",
      "Validation loss improved from 0.7036 to 0.6975.\n",
      "[Epoch 123/1000] Train Loss: 0.5221  |  Val Loss: 0.6912\n",
      "Validation loss improved from 0.6975 to 0.6912.\n",
      "[Epoch 124/1000] Train Loss: 0.5146  |  Val Loss: 0.6845\n",
      "Validation loss improved from 0.6912 to 0.6845.\n",
      "[Epoch 125/1000] Train Loss: 0.5064  |  Val Loss: 0.6780\n",
      "Validation loss improved from 0.6845 to 0.6780.\n",
      "[Epoch 126/1000] Train Loss: 0.4986  |  Val Loss: 0.6717\n",
      "Validation loss improved from 0.6780 to 0.6717.\n",
      "[Epoch 127/1000] Train Loss: 0.4916  |  Val Loss: 0.6656\n",
      "Validation loss improved from 0.6717 to 0.6656.\n",
      "[Epoch 128/1000] Train Loss: 0.4839  |  Val Loss: 0.6595\n",
      "Validation loss improved from 0.6656 to 0.6595.\n",
      "[Epoch 129/1000] Train Loss: 0.4766  |  Val Loss: 0.6534\n",
      "Validation loss improved from 0.6595 to 0.6534.\n",
      "[Epoch 130/1000] Train Loss: 0.4696  |  Val Loss: 0.6472\n",
      "Validation loss improved from 0.6534 to 0.6472.\n",
      "[Epoch 131/1000] Train Loss: 0.4627  |  Val Loss: 0.6410\n",
      "Validation loss improved from 0.6472 to 0.6410.\n",
      "[Epoch 132/1000] Train Loss: 0.4557  |  Val Loss: 0.6353\n",
      "Validation loss improved from 0.6410 to 0.6353.\n",
      "[Epoch 133/1000] Train Loss: 0.4491  |  Val Loss: 0.6299\n",
      "Validation loss improved from 0.6353 to 0.6299.\n",
      "[Epoch 134/1000] Train Loss: 0.4423  |  Val Loss: 0.6245\n",
      "Validation loss improved from 0.6299 to 0.6245.\n",
      "[Epoch 135/1000] Train Loss: 0.4360  |  Val Loss: 0.6189\n",
      "Validation loss improved from 0.6245 to 0.6189.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 136/1000] Train Loss: 0.4297  |  Val Loss: 0.6135\n",
      "Validation loss improved from 0.6189 to 0.6135.\n",
      "[Epoch 137/1000] Train Loss: 0.4232  |  Val Loss: 0.6082\n",
      "Validation loss improved from 0.6135 to 0.6082.\n",
      "[Epoch 138/1000] Train Loss: 0.4171  |  Val Loss: 0.6031\n",
      "Validation loss improved from 0.6082 to 0.6031.\n",
      "[Epoch 139/1000] Train Loss: 0.4111  |  Val Loss: 0.5987\n",
      "Validation loss improved from 0.6031 to 0.5987.\n",
      "[Epoch 140/1000] Train Loss: 0.4049  |  Val Loss: 0.5935\n",
      "Validation loss improved from 0.5987 to 0.5935.\n",
      "[Epoch 141/1000] Train Loss: 0.3992  |  Val Loss: 0.5888\n",
      "Validation loss improved from 0.5935 to 0.5888.\n",
      "[Epoch 142/1000] Train Loss: 0.3932  |  Val Loss: 0.5839\n",
      "Validation loss improved from 0.5888 to 0.5839.\n",
      "[Epoch 143/1000] Train Loss: 0.3877  |  Val Loss: 0.5792\n",
      "Validation loss improved from 0.5839 to 0.5792.\n",
      "[Epoch 144/1000] Train Loss: 0.3821  |  Val Loss: 0.5743\n",
      "Validation loss improved from 0.5792 to 0.5743.\n",
      "[Epoch 145/1000] Train Loss: 0.3764  |  Val Loss: 0.5696\n",
      "Validation loss improved from 0.5743 to 0.5696.\n",
      "[Epoch 146/1000] Train Loss: 0.3711  |  Val Loss: 0.5652\n",
      "Validation loss improved from 0.5696 to 0.5652.\n",
      "[Epoch 147/1000] Train Loss: 0.3659  |  Val Loss: 0.5609\n",
      "Validation loss improved from 0.5652 to 0.5609.\n",
      "[Epoch 148/1000] Train Loss: 0.3605  |  Val Loss: 0.5566\n",
      "Validation loss improved from 0.5609 to 0.5566.\n",
      "[Epoch 149/1000] Train Loss: 0.3555  |  Val Loss: 0.5525\n",
      "Validation loss improved from 0.5566 to 0.5525.\n",
      "[Epoch 150/1000] Train Loss: 0.3502  |  Val Loss: 0.5487\n",
      "Validation loss improved from 0.5525 to 0.5487.\n",
      "[Epoch 151/1000] Train Loss: 0.3456  |  Val Loss: 0.5447\n",
      "Validation loss improved from 0.5487 to 0.5447.\n",
      "[Epoch 152/1000] Train Loss: 0.3407  |  Val Loss: 0.5409\n",
      "Validation loss improved from 0.5447 to 0.5409.\n",
      "[Epoch 153/1000] Train Loss: 0.3359  |  Val Loss: 0.5371\n",
      "Validation loss improved from 0.5409 to 0.5371.\n",
      "[Epoch 154/1000] Train Loss: 0.3312  |  Val Loss: 0.5326\n",
      "Validation loss improved from 0.5371 to 0.5326.\n",
      "[Epoch 155/1000] Train Loss: 0.3265  |  Val Loss: 0.5292\n",
      "Validation loss improved from 0.5326 to 0.5292.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 156/1000] Train Loss: 0.3218  |  Val Loss: 0.5256\n",
      "Validation loss improved from 0.5292 to 0.5256.\n",
      "[Epoch 157/1000] Train Loss: 0.3177  |  Val Loss: 0.5213\n",
      "Validation loss improved from 0.5256 to 0.5213.\n",
      "[Epoch 158/1000] Train Loss: 0.3131  |  Val Loss: 0.5184\n",
      "Validation loss improved from 0.5213 to 0.5184.\n",
      "[Epoch 159/1000] Train Loss: 0.3090  |  Val Loss: 0.5147\n",
      "Validation loss improved from 0.5184 to 0.5147.\n",
      "[Epoch 160/1000] Train Loss: 0.3045  |  Val Loss: 0.5110\n",
      "Validation loss improved from 0.5147 to 0.5110.\n",
      "[Epoch 161/1000] Train Loss: 0.3006  |  Val Loss: 0.5080\n",
      "Validation loss improved from 0.5110 to 0.5080.\n",
      "[Epoch 162/1000] Train Loss: 0.2967  |  Val Loss: 0.5050\n",
      "Validation loss improved from 0.5080 to 0.5050.\n",
      "[Epoch 163/1000] Train Loss: 0.2925  |  Val Loss: 0.5018\n",
      "Validation loss improved from 0.5050 to 0.5018.\n",
      "[Epoch 164/1000] Train Loss: 0.2885  |  Val Loss: 0.4990\n",
      "Validation loss improved from 0.5018 to 0.4990.\n",
      "[Epoch 165/1000] Train Loss: 0.2847  |  Val Loss: 0.4956\n",
      "Validation loss improved from 0.4990 to 0.4956.\n",
      "[Epoch 166/1000] Train Loss: 0.2810  |  Val Loss: 0.4923\n",
      "Validation loss improved from 0.4956 to 0.4923.\n",
      "[Epoch 167/1000] Train Loss: 0.2772  |  Val Loss: 0.4897\n",
      "Validation loss improved from 0.4923 to 0.4897.\n",
      "[Epoch 168/1000] Train Loss: 0.2739  |  Val Loss: 0.4868\n",
      "Validation loss improved from 0.4897 to 0.4868.\n",
      "[Epoch 169/1000] Train Loss: 0.2701  |  Val Loss: 0.4840\n",
      "Validation loss improved from 0.4868 to 0.4840.\n",
      "[Epoch 170/1000] Train Loss: 0.2665  |  Val Loss: 0.4815\n",
      "Validation loss improved from 0.4840 to 0.4815.\n",
      "[Epoch 171/1000] Train Loss: 0.2633  |  Val Loss: 0.4784\n",
      "Validation loss improved from 0.4815 to 0.4784.\n",
      "[Epoch 172/1000] Train Loss: 0.2598  |  Val Loss: 0.4758\n",
      "Validation loss improved from 0.4784 to 0.4758.\n",
      "[Epoch 173/1000] Train Loss: 0.2565  |  Val Loss: 0.4729\n",
      "Validation loss improved from 0.4758 to 0.4729.\n",
      "[Epoch 174/1000] Train Loss: 0.2533  |  Val Loss: 0.4708\n",
      "Validation loss improved from 0.4729 to 0.4708.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 175/1000] Train Loss: 0.2500  |  Val Loss: 0.4683\n",
      "Validation loss improved from 0.4708 to 0.4683.\n",
      "[Epoch 176/1000] Train Loss: 0.2470  |  Val Loss: 0.4658\n",
      "Validation loss improved from 0.4683 to 0.4658.\n",
      "[Epoch 177/1000] Train Loss: 0.2440  |  Val Loss: 0.4636\n",
      "Validation loss improved from 0.4658 to 0.4636.\n",
      "[Epoch 178/1000] Train Loss: 0.2410  |  Val Loss: 0.4611\n",
      "Validation loss improved from 0.4636 to 0.4611.\n",
      "[Epoch 179/1000] Train Loss: 0.2381  |  Val Loss: 0.4583\n",
      "Validation loss improved from 0.4611 to 0.4583.\n",
      "[Epoch 180/1000] Train Loss: 0.2351  |  Val Loss: 0.4565\n",
      "Validation loss improved from 0.4583 to 0.4565.\n",
      "[Epoch 181/1000] Train Loss: 0.2324  |  Val Loss: 0.4546\n",
      "Validation loss improved from 0.4565 to 0.4546.\n",
      "[Epoch 182/1000] Train Loss: 0.2295  |  Val Loss: 0.4527\n",
      "Validation loss improved from 0.4546 to 0.4527.\n",
      "[Epoch 183/1000] Train Loss: 0.2269  |  Val Loss: 0.4509\n",
      "Validation loss improved from 0.4527 to 0.4509.\n",
      "[Epoch 184/1000] Train Loss: 0.2242  |  Val Loss: 0.4484\n",
      "Validation loss improved from 0.4509 to 0.4484.\n",
      "[Epoch 185/1000] Train Loss: 0.2214  |  Val Loss: 0.4463\n",
      "Validation loss improved from 0.4484 to 0.4463.\n",
      "[Epoch 186/1000] Train Loss: 0.2191  |  Val Loss: 0.4440\n",
      "Validation loss improved from 0.4463 to 0.4440.\n",
      "[Epoch 187/1000] Train Loss: 0.2164  |  Val Loss: 0.4425\n",
      "Validation loss improved from 0.4440 to 0.4425.\n",
      "[Epoch 188/1000] Train Loss: 0.2139  |  Val Loss: 0.4402\n",
      "Validation loss improved from 0.4425 to 0.4402.\n",
      "[Epoch 189/1000] Train Loss: 0.2116  |  Val Loss: 0.4387\n",
      "Validation loss improved from 0.4402 to 0.4387.\n",
      "[Epoch 190/1000] Train Loss: 0.2095  |  Val Loss: 0.4371\n",
      "Validation loss improved from 0.4387 to 0.4371.\n",
      "[Epoch 191/1000] Train Loss: 0.2069  |  Val Loss: 0.4359\n",
      "Validation loss improved from 0.4371 to 0.4359.\n",
      "[Epoch 192/1000] Train Loss: 0.2045  |  Val Loss: 0.4345\n",
      "Validation loss improved from 0.4359 to 0.4345.\n",
      "[Epoch 193/1000] Train Loss: 0.2022  |  Val Loss: 0.4327\n",
      "Validation loss improved from 0.4345 to 0.4327.\n",
      "[Epoch 194/1000] Train Loss: 0.2000  |  Val Loss: 0.4307\n",
      "Validation loss improved from 0.4327 to 0.4307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 195/1000] Train Loss: 0.1978  |  Val Loss: 0.4290\n",
      "Validation loss improved from 0.4307 to 0.4290.\n",
      "[Epoch 196/1000] Train Loss: 0.1958  |  Val Loss: 0.4273\n",
      "Validation loss improved from 0.4290 to 0.4273.\n",
      "[Epoch 197/1000] Train Loss: 0.1938  |  Val Loss: 0.4256\n",
      "Validation loss improved from 0.4273 to 0.4256.\n",
      "[Epoch 198/1000] Train Loss: 0.1918  |  Val Loss: 0.4243\n",
      "Validation loss improved from 0.4256 to 0.4243.\n",
      "[Epoch 199/1000] Train Loss: 0.1899  |  Val Loss: 0.4238\n",
      "Validation loss improved from 0.4243 to 0.4238.\n",
      "[Epoch 200/1000] Train Loss: 0.1877  |  Val Loss: 0.4222\n",
      "Validation loss improved from 0.4238 to 0.4222.\n",
      "[Epoch 201/1000] Train Loss: 0.1859  |  Val Loss: 0.4205\n",
      "Validation loss improved from 0.4222 to 0.4205.\n",
      "[Epoch 202/1000] Train Loss: 0.1839  |  Val Loss: 0.4192\n",
      "Validation loss improved from 0.4205 to 0.4192.\n",
      "[Epoch 203/1000] Train Loss: 0.1820  |  Val Loss: 0.4177\n",
      "Validation loss improved from 0.4192 to 0.4177.\n",
      "[Epoch 204/1000] Train Loss: 0.1802  |  Val Loss: 0.4167\n",
      "Validation loss improved from 0.4177 to 0.4167.\n",
      "[Epoch 205/1000] Train Loss: 0.1785  |  Val Loss: 0.4151\n",
      "Validation loss improved from 0.4167 to 0.4151.\n",
      "[Epoch 206/1000] Train Loss: 0.1769  |  Val Loss: 0.4142\n",
      "Validation loss improved from 0.4151 to 0.4142.\n",
      "[Epoch 207/1000] Train Loss: 0.1750  |  Val Loss: 0.4126\n",
      "Validation loss improved from 0.4142 to 0.4126.\n",
      "[Epoch 208/1000] Train Loss: 0.1737  |  Val Loss: 0.4119\n",
      "Validation loss improved from 0.4126 to 0.4119.\n",
      "[Epoch 209/1000] Train Loss: 0.1716  |  Val Loss: 0.4112\n",
      "Validation loss improved from 0.4119 to 0.4112.\n",
      "[Epoch 210/1000] Train Loss: 0.1701  |  Val Loss: 0.4101\n",
      "Validation loss improved from 0.4112 to 0.4101.\n",
      "[Epoch 211/1000] Train Loss: 0.1685  |  Val Loss: 0.4093\n",
      "Validation loss improved from 0.4101 to 0.4093.\n",
      "[Epoch 212/1000] Train Loss: 0.1669  |  Val Loss: 0.4081\n",
      "Validation loss improved from 0.4093 to 0.4081.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 213/1000] Train Loss: 0.1653  |  Val Loss: 0.4066\n",
      "Validation loss improved from 0.4081 to 0.4066.\n",
      "[Epoch 214/1000] Train Loss: 0.1640  |  Val Loss: 0.4054\n",
      "Validation loss improved from 0.4066 to 0.4054.\n",
      "[Epoch 215/1000] Train Loss: 0.1624  |  Val Loss: 0.4051\n",
      "Validation loss improved from 0.4054 to 0.4051.\n",
      "[Epoch 216/1000] Train Loss: 0.1609  |  Val Loss: 0.4042\n",
      "Validation loss improved from 0.4051 to 0.4042.\n",
      "[Epoch 217/1000] Train Loss: 0.1595  |  Val Loss: 0.4034\n",
      "Validation loss improved from 0.4042 to 0.4034.\n",
      "[Epoch 218/1000] Train Loss: 0.1580  |  Val Loss: 0.4028\n",
      "Validation loss improved from 0.4034 to 0.4028.\n",
      "[Epoch 219/1000] Train Loss: 0.1566  |  Val Loss: 0.4017\n",
      "Validation loss improved from 0.4028 to 0.4017.\n",
      "[Epoch 220/1000] Train Loss: 0.1552  |  Val Loss: 0.4006\n",
      "Validation loss improved from 0.4017 to 0.4006.\n",
      "[Epoch 221/1000] Train Loss: 0.1539  |  Val Loss: 0.3999\n",
      "Validation loss improved from 0.4006 to 0.3999.\n",
      "[Epoch 222/1000] Train Loss: 0.1526  |  Val Loss: 0.3989\n",
      "Validation loss improved from 0.3999 to 0.3989.\n",
      "[Epoch 223/1000] Train Loss: 0.1513  |  Val Loss: 0.3982\n",
      "Validation loss improved from 0.3989 to 0.3982.\n",
      "[Epoch 224/1000] Train Loss: 0.1500  |  Val Loss: 0.3975\n",
      "Validation loss improved from 0.3982 to 0.3975.\n",
      "[Epoch 225/1000] Train Loss: 0.1488  |  Val Loss: 0.3969\n",
      "Validation loss improved from 0.3975 to 0.3969.\n",
      "[Epoch 226/1000] Train Loss: 0.1478  |  Val Loss: 0.3966\n",
      "Validation loss improved from 0.3969 to 0.3966.\n",
      "[Epoch 227/1000] Train Loss: 0.1464  |  Val Loss: 0.3958\n",
      "Validation loss improved from 0.3966 to 0.3958.\n",
      "[Epoch 228/1000] Train Loss: 0.1453  |  Val Loss: 0.3942\n",
      "Validation loss improved from 0.3958 to 0.3942.\n",
      "[Epoch 229/1000] Train Loss: 0.1442  |  Val Loss: 0.3933\n",
      "Validation loss improved from 0.3942 to 0.3933.\n",
      "[Epoch 230/1000] Train Loss: 0.1431  |  Val Loss: 0.3929\n",
      "Validation loss improved from 0.3933 to 0.3929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 231/1000] Train Loss: 0.1419  |  Val Loss: 0.3925\n",
      "Validation loss improved from 0.3929 to 0.3925.\n",
      "[Epoch 232/1000] Train Loss: 0.1407  |  Val Loss: 0.3928\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 233/1000] Train Loss: 0.1397  |  Val Loss: 0.3931\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 234/1000] Train Loss: 0.1387  |  Val Loss: 0.3922\n",
      "Validation loss improved from 0.3925 to 0.3922.\n",
      "[Epoch 235/1000] Train Loss: 0.1374  |  Val Loss: 0.3913\n",
      "Validation loss improved from 0.3922 to 0.3913.\n",
      "[Epoch 236/1000] Train Loss: 0.1366  |  Val Loss: 0.3904\n",
      "Validation loss improved from 0.3913 to 0.3904.\n",
      "[Epoch 237/1000] Train Loss: 0.1357  |  Val Loss: 0.3900\n",
      "Validation loss improved from 0.3904 to 0.3900.\n",
      "[Epoch 238/1000] Train Loss: 0.1345  |  Val Loss: 0.3894\n",
      "Validation loss improved from 0.3900 to 0.3894.\n",
      "[Epoch 239/1000] Train Loss: 0.1336  |  Val Loss: 0.3885\n",
      "Validation loss improved from 0.3894 to 0.3885.\n",
      "[Epoch 240/1000] Train Loss: 0.1325  |  Val Loss: 0.3882\n",
      "Validation loss improved from 0.3885 to 0.3882.\n",
      "[Epoch 241/1000] Train Loss: 0.1317  |  Val Loss: 0.3884\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 242/1000] Train Loss: 0.1308  |  Val Loss: 0.3883\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 243/1000] Train Loss: 0.1298  |  Val Loss: 0.3880\n",
      "Validation loss improved from 0.3882 to 0.3880.\n",
      "[Epoch 244/1000] Train Loss: 0.1289  |  Val Loss: 0.3880\n",
      "Validation loss improved from 0.3880 to 0.3880.\n",
      "[Epoch 245/1000] Train Loss: 0.1282  |  Val Loss: 0.3877\n",
      "Validation loss improved from 0.3880 to 0.3877.\n",
      "[Epoch 246/1000] Train Loss: 0.1275  |  Val Loss: 0.3869\n",
      "Validation loss improved from 0.3877 to 0.3869.\n",
      "[Epoch 247/1000] Train Loss: 0.1265  |  Val Loss: 0.3862\n",
      "Validation loss improved from 0.3869 to 0.3862.\n",
      "[Epoch 248/1000] Train Loss: 0.1257  |  Val Loss: 0.3859\n",
      "Validation loss improved from 0.3862 to 0.3859.\n",
      "[Epoch 249/1000] Train Loss: 0.1246  |  Val Loss: 0.3854\n",
      "Validation loss improved from 0.3859 to 0.3854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 250/1000] Train Loss: 0.1237  |  Val Loss: 0.3855\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 251/1000] Train Loss: 0.1229  |  Val Loss: 0.3857\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 252/1000] Train Loss: 0.1222  |  Val Loss: 0.3856\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 253/1000] Train Loss: 0.1221  |  Val Loss: 0.3854\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 254/1000] Train Loss: 0.1207  |  Val Loss: 0.3849\n",
      "Validation loss improved from 0.3854 to 0.3849.\n",
      "[Epoch 255/1000] Train Loss: 0.1199  |  Val Loss: 0.3846\n",
      "Validation loss improved from 0.3849 to 0.3846.\n",
      "[Epoch 256/1000] Train Loss: 0.1192  |  Val Loss: 0.3839\n",
      "Validation loss improved from 0.3846 to 0.3839.\n",
      "[Epoch 257/1000] Train Loss: 0.1185  |  Val Loss: 0.3833\n",
      "Validation loss improved from 0.3839 to 0.3833.\n",
      "[Epoch 258/1000] Train Loss: 0.1180  |  Val Loss: 0.3836\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 259/1000] Train Loss: 0.1169  |  Val Loss: 0.3834\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 260/1000] Train Loss: 0.1174  |  Val Loss: 0.3836\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 261/1000] Train Loss: 0.1158  |  Val Loss: 0.3827\n",
      "Validation loss improved from 0.3833 to 0.3827.\n",
      "[Epoch 262/1000] Train Loss: 0.1148  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 263/1000] Train Loss: 0.1144  |  Val Loss: 0.3837\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 264/1000] Train Loss: 0.1135  |  Val Loss: 0.3833\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 265/1000] Train Loss: 0.1130  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 266/1000] Train Loss: 0.1130  |  Val Loss: 0.3820\n",
      "Validation loss improved from 0.3827 to 0.3820.\n",
      "[Epoch 267/1000] Train Loss: 0.1117  |  Val Loss: 0.3823\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 268/1000] Train Loss: 0.1111  |  Val Loss: 0.3825\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 269/1000] Train Loss: 0.1107  |  Val Loss: 0.3826\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 270/1000] Train Loss: 0.1098  |  Val Loss: 0.3824\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 271/1000] Train Loss: 0.1093  |  Val Loss: 0.3819\n",
      "Validation loss improved from 0.3820 to 0.3819.\n",
      "[Epoch 272/1000] Train Loss: 0.1087  |  Val Loss: 0.3821\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 273/1000] Train Loss: 0.1080  |  Val Loss: 0.3819\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 274/1000] Train Loss: 0.1077  |  Val Loss: 0.3816\n",
      "Validation loss improved from 0.3819 to 0.3816.\n",
      "[Epoch 275/1000] Train Loss: 0.1071  |  Val Loss: 0.3811\n",
      "Validation loss improved from 0.3816 to 0.3811.\n",
      "[Epoch 276/1000] Train Loss: 0.1067  |  Val Loss: 0.3811\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 277/1000] Train Loss: 0.1058  |  Val Loss: 0.3814\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 278/1000] Train Loss: 0.1053  |  Val Loss: 0.3817\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 279/1000] Train Loss: 0.1048  |  Val Loss: 0.3820\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 280/1000] Train Loss: 0.1047  |  Val Loss: 0.3820\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 281/1000] Train Loss: 0.1039  |  Val Loss: 0.3820\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 282/1000] Train Loss: 0.1033  |  Val Loss: 0.3823\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 283/1000] Train Loss: 0.1027  |  Val Loss: 0.3820\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 284/1000] Train Loss: 0.1024  |  Val Loss: 0.3815\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 285/1000] Train Loss: 0.1019  |  Val Loss: 0.3808\n",
      "Validation loss improved from 0.3811 to 0.3808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 286/1000] Train Loss: 0.1016  |  Val Loss: 0.3813\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 287/1000] Train Loss: 0.1008  |  Val Loss: 0.3816\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 288/1000] Train Loss: 0.1004  |  Val Loss: 0.3817\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 289/1000] Train Loss: 0.0999  |  Val Loss: 0.3818\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 290/1000] Train Loss: 0.0997  |  Val Loss: 0.3816\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 291/1000] Train Loss: 0.0989  |  Val Loss: 0.3817\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 292/1000] Train Loss: 0.0986  |  Val Loss: 0.3816\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 293/1000] Train Loss: 0.0981  |  Val Loss: 0.3819\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 294/1000] Train Loss: 0.0977  |  Val Loss: 0.3822\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 295/1000] Train Loss: 0.0977  |  Val Loss: 0.3820\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 296/1000] Train Loss: 0.0968  |  Val Loss: 0.3823\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 297/1000] Train Loss: 0.0965  |  Val Loss: 0.3821\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 298/1000] Train Loss: 0.0961  |  Val Loss: 0.3824\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 299/1000] Train Loss: 0.0964  |  Val Loss: 0.3831\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 300/1000] Train Loss: 0.0960  |  Val Loss: 0.3824\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 301/1000] Train Loss: 0.0948  |  Val Loss: 0.3830\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 302/1000] Train Loss: 0.0944  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 303/1000] Train Loss: 0.0942  |  Val Loss: 0.3830\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 304/1000] Train Loss: 0.0936  |  Val Loss: 0.3824\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 305/1000] Train Loss: 0.0934  |  Val Loss: 0.3827\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 306/1000] Train Loss: 0.0928  |  Val Loss: 0.3829\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 307/1000] Train Loss: 0.0925  |  Val Loss: 0.3827\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 308/1000] Train Loss: 0.0925  |  Val Loss: 0.3833\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 309/1000] Train Loss: 0.0923  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 310/1000] Train Loss: 0.0915  |  Val Loss: 0.3835\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 311/1000] Train Loss: 0.0913  |  Val Loss: 0.3831\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 312/1000] Train Loss: 0.0913  |  Val Loss: 0.3840\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 313/1000] Train Loss: 0.0906  |  Val Loss: 0.3840\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 314/1000] Train Loss: 0.0903  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 315/1000] Train Loss: 0.0896  |  Val Loss: 0.3830\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 316/1000] Train Loss: 0.0895  |  Val Loss: 0.3835\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 317/1000] Train Loss: 0.0890  |  Val Loss: 0.3844\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 318/1000] Train Loss: 0.0887  |  Val Loss: 0.3845\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 319/1000] Train Loss: 0.0883  |  Val Loss: 0.3854\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 320/1000] Train Loss: 0.0881  |  Val Loss: 0.3846\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 321/1000] Train Loss: 0.0876  |  Val Loss: 0.3850\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 322/1000] Train Loss: 0.0874  |  Val Loss: 0.3847\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 323/1000] Train Loss: 0.0873  |  Val Loss: 0.3844\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 324/1000] Train Loss: 0.0869  |  Val Loss: 0.3847\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 325/1000] Train Loss: 0.0866  |  Val Loss: 0.3856\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 326/1000] Train Loss: 0.0861  |  Val Loss: 0.3856\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 327/1000] Train Loss: 0.0859  |  Val Loss: 0.3854\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 328/1000] Train Loss: 0.0854  |  Val Loss: 0.3854\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 329/1000] Train Loss: 0.0852  |  Val Loss: 0.3850\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 330/1000] Train Loss: 0.0857  |  Val Loss: 0.3843\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 331/1000] Train Loss: 0.0853  |  Val Loss: 0.3854\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 332/1000] Train Loss: 0.0845  |  Val Loss: 0.3860\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 333/1000] Train Loss: 0.0841  |  Val Loss: 0.3869\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 334/1000] Train Loss: 0.0838  |  Val Loss: 0.3860\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 335/1000] Train Loss: 0.0834  |  Val Loss: 0.3864\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 336/1000] Train Loss: 0.0831  |  Val Loss: 0.3867\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 337/1000] Train Loss: 0.0831  |  Val Loss: 0.3873\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 338/1000] Train Loss: 0.0827  |  Val Loss: 0.3872\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 339/1000] Train Loss: 0.0823  |  Val Loss: 0.3866\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 340/1000] Train Loss: 0.0819  |  Val Loss: 0.3867\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 341/1000] Train Loss: 0.0816  |  Val Loss: 0.3868\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 342/1000] Train Loss: 0.0816  |  Val Loss: 0.3873\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 343/1000] Train Loss: 0.0813  |  Val Loss: 0.3880\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 344/1000] Train Loss: 0.0809  |  Val Loss: 0.3878\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 345/1000] Train Loss: 0.0806  |  Val Loss: 0.3885\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 346/1000] Train Loss: 0.0806  |  Val Loss: 0.3884\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 347/1000] Train Loss: 0.0802  |  Val Loss: 0.3894\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 348/1000] Train Loss: 0.0800  |  Val Loss: 0.3887\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 349/1000] Train Loss: 0.0795  |  Val Loss: 0.3890\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 350/1000] Train Loss: 0.0796  |  Val Loss: 0.3889\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 351/1000] Train Loss: 0.0792  |  Val Loss: 0.3891\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 352/1000] Train Loss: 0.0790  |  Val Loss: 0.3896\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 353/1000] Train Loss: 0.0787  |  Val Loss: 0.3897\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 354/1000] Train Loss: 0.0798  |  Val Loss: 0.3910\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 355/1000] Train Loss: 0.0782  |  Val Loss: 0.3908\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 356/1000] Train Loss: 0.0782  |  Val Loss: 0.3913\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 357/1000] Train Loss: 0.0779  |  Val Loss: 0.3913\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 358/1000] Train Loss: 0.0776  |  Val Loss: 0.3908\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 359/1000] Train Loss: 0.0776  |  Val Loss: 0.3909\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 360/1000] Train Loss: 0.0772  |  Val Loss: 0.3920\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 361/1000] Train Loss: 0.0768  |  Val Loss: 0.3921\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 362/1000] Train Loss: 0.0766  |  Val Loss: 0.3920\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 363/1000] Train Loss: 0.0766  |  Val Loss: 0.3917\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 364/1000] Train Loss: 0.0763  |  Val Loss: 0.3923\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 365/1000] Train Loss: 0.0760  |  Val Loss: 0.3921\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 366/1000] Train Loss: 0.0758  |  Val Loss: 0.3927\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 367/1000] Train Loss: 0.0761  |  Val Loss: 0.3930\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 368/1000] Train Loss: 0.0755  |  Val Loss: 0.3935\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 369/1000] Train Loss: 0.0756  |  Val Loss: 0.3944\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 370/1000] Train Loss: 0.0752  |  Val Loss: 0.3943\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 371/1000] Train Loss: 0.0749  |  Val Loss: 0.3941\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 372/1000] Train Loss: 0.0748  |  Val Loss: 0.3949\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 373/1000] Train Loss: 0.0744  |  Val Loss: 0.3950\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 374/1000] Train Loss: 0.0742  |  Val Loss: 0.3950\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 375/1000] Train Loss: 0.0742  |  Val Loss: 0.3954\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 376/1000] Train Loss: 0.0739  |  Val Loss: 0.3957\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 377/1000] Train Loss: 0.0737  |  Val Loss: 0.3952\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 378/1000] Train Loss: 0.0734  |  Val Loss: 0.3952\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 379/1000] Train Loss: 0.0733  |  Val Loss: 0.3958\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 380/1000] Train Loss: 0.0731  |  Val Loss: 0.3960\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 381/1000] Train Loss: 0.0735  |  Val Loss: 0.3961\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 382/1000] Train Loss: 0.0731  |  Val Loss: 0.3962\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 383/1000] Train Loss: 0.0728  |  Val Loss: 0.3970\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 384/1000] Train Loss: 0.0727  |  Val Loss: 0.3973\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 385/1000] Train Loss: 0.0722  |  Val Loss: 0.3976\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 385 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:28.900677Z",
     "iopub.status.busy": "2025-05-09T02:06:28.900677Z",
     "iopub.status.idle": "2025-05-09T02:06:29.845838Z",
     "shell.execute_reply": "2025-05-09T02:06:29.845838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.6127 | Test Accuracy: 83.23%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:29.848845Z",
     "iopub.status.busy": "2025-05-09T02:06:29.847843Z",
     "iopub.status.idle": "2025-05-09T02:06:29.904999Z",
     "shell.execute_reply": "2025-05-09T02:06:29.904999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 320 samples with 64 features each\n",
      "LOG: Labels shape: (320,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 80 samples with 64 features each\n",
      "LOG: Labels shape: (80,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 53729 samples with 64 features each\n",
      "LOG: Labels shape: (53729,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (320, 64), \n",
      "Train labels shape: (320,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (80, 64), \n",
      "Val labels shape: (80,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (53729, 64), \n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:29.907003Z",
     "iopub.status.busy": "2025-05-09T02:06:29.907003Z",
     "iopub.status.idle": "2025-05-09T02:06:29.919398Z",
     "shell.execute_reply": "2025-05-09T02:06:29.919398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20, 14: 20, 15: 20}\n",
      "Training batch size: 320\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:29.922402Z",
     "iopub.status.busy": "2025-05-09T02:06:29.921402Z",
     "iopub.status.idle": "2025-05-09T02:06:29.925210Z",
     "shell.execute_reply": "2025-05-09T02:06:29.925210Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:29.927213Z",
     "iopub.status.busy": "2025-05-09T02:06:29.927213Z",
     "iopub.status.idle": "2025-05-09T02:06:29.934489Z",
     "shell.execute_reply": "2025-05-09T02:06:29.934489Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:06:29.937494Z",
     "iopub.status.busy": "2025-05-09T02:06:29.937494Z",
     "iopub.status.idle": "2025-05-09T02:15:00.836161Z",
     "shell.execute_reply": "2025-05-09T02:15:00.835155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4674\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2960\n",
      "    Batch [2/2], Val Loss: 0.3807\n",
      "Epoch [1/2000], Avg Train Loss: 0.4674, Avg Val Loss: 0.3383\n",
      "\n",
      "Validation loss improved from inf to 0.3383. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4669\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2968\n",
      "    Batch [2/2], Val Loss: 0.3789\n",
      "Epoch [2/2000], Avg Train Loss: 0.4669, Avg Val Loss: 0.3379\n",
      "\n",
      "Validation loss improved from 0.3383 to 0.3379. Saving model...\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4624\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2974\n",
      "    Batch [2/2], Val Loss: 0.3781\n",
      "Epoch [3/2000], Avg Train Loss: 0.4624, Avg Val Loss: 0.3378\n",
      "\n",
      "Validation loss improved from 0.3379 to 0.3378. Saving model...\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4642\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2987\n",
      "    Batch [2/2], Val Loss: 0.3772\n",
      "Epoch [4/2000], Avg Train Loss: 0.4642, Avg Val Loss: 0.3380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4623\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2999\n",
      "    Batch [2/2], Val Loss: 0.3767\n",
      "Epoch [5/2000], Avg Train Loss: 0.4623, Avg Val Loss: 0.3383\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [6/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4619\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3009\n",
      "    Batch [2/2], Val Loss: 0.3768\n",
      "Epoch [6/2000], Avg Train Loss: 0.4619, Avg Val Loss: 0.3389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4640\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3012\n",
      "    Batch [2/2], Val Loss: 0.3771\n",
      "Epoch [7/2000], Avg Train Loss: 0.4640, Avg Val Loss: 0.3391\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [8/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4605\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3010\n",
      "    Batch [2/2], Val Loss: 0.3770\n",
      "Epoch [8/2000], Avg Train Loss: 0.4605, Avg Val Loss: 0.3390\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4614\n",
      "LOG: Epoch [9/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3015\n",
      "    Batch [2/2], Val Loss: 0.3766\n",
      "Epoch [9/2000], Avg Train Loss: 0.4614, Avg Val Loss: 0.3391\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4589\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3024\n",
      "    Batch [2/2], Val Loss: 0.3759\n",
      "Epoch [10/2000], Avg Train Loss: 0.4589, Avg Val Loss: 0.3391\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4563\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3032\n",
      "    Batch [2/2], Val Loss: 0.3742\n",
      "Epoch [11/2000], Avg Train Loss: 0.4563, Avg Val Loss: 0.3387\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4575\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3037\n",
      "    Batch [2/2], Val Loss: 0.3738\n",
      "Epoch [12/2000], Avg Train Loss: 0.4575, Avg Val Loss: 0.3387\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [13/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4583\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3042\n",
      "    Batch [2/2], Val Loss: 0.3723\n",
      "Epoch [13/2000], Avg Train Loss: 0.4583, Avg Val Loss: 0.3382\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4541\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3044\n",
      "    Batch [2/2], Val Loss: 0.3694\n",
      "Epoch [14/2000], Avg Train Loss: 0.4541, Avg Val Loss: 0.3369\n",
      "\n",
      "Validation loss improved from 0.3378 to 0.3369. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4548\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3041\n",
      "    Batch [2/2], Val Loss: 0.3663\n",
      "Epoch [15/2000], Avg Train Loss: 0.4548, Avg Val Loss: 0.3352\n",
      "\n",
      "Validation loss improved from 0.3369 to 0.3352. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4540\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3038\n",
      "    Batch [2/2], Val Loss: 0.3633\n",
      "Epoch [16/2000], Avg Train Loss: 0.4540, Avg Val Loss: 0.3336\n",
      "\n",
      "Validation loss improved from 0.3352 to 0.3336. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4537\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3033\n",
      "    Batch [2/2], Val Loss: 0.3603\n",
      "Epoch [17/2000], Avg Train Loss: 0.4537, Avg Val Loss: 0.3318\n",
      "\n",
      "Validation loss improved from 0.3336 to 0.3318. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4518\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3023\n",
      "    Batch [2/2], Val Loss: 0.3576\n",
      "Epoch [18/2000], Avg Train Loss: 0.4518, Avg Val Loss: 0.3300\n",
      "\n",
      "Validation loss improved from 0.3318 to 0.3300. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4517\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3011\n",
      "    Batch [2/2], Val Loss: 0.3557\n",
      "Epoch [19/2000], Avg Train Loss: 0.4517, Avg Val Loss: 0.3284\n",
      "\n",
      "Validation loss improved from 0.3300 to 0.3284. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4511\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2998\n",
      "    Batch [2/2], Val Loss: 0.3540\n",
      "Epoch [20/2000], Avg Train Loss: 0.4511, Avg Val Loss: 0.3269\n",
      "\n",
      "Validation loss improved from 0.3284 to 0.3269. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4491\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2985\n",
      "    Batch [2/2], Val Loss: 0.3524\n",
      "Epoch [21/2000], Avg Train Loss: 0.4491, Avg Val Loss: 0.3254\n",
      "\n",
      "Validation loss improved from 0.3269 to 0.3254. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4494\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2974\n",
      "    Batch [2/2], Val Loss: 0.3509\n",
      "Epoch [22/2000], Avg Train Loss: 0.4494, Avg Val Loss: 0.3242\n",
      "\n",
      "Validation loss improved from 0.3254 to 0.3242. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4514\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2964\n",
      "    Batch [2/2], Val Loss: 0.3499\n",
      "Epoch [23/2000], Avg Train Loss: 0.4514, Avg Val Loss: 0.3232\n",
      "\n",
      "Validation loss improved from 0.3242 to 0.3232. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4468\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2954\n",
      "    Batch [2/2], Val Loss: 0.3489\n",
      "Epoch [24/2000], Avg Train Loss: 0.4468, Avg Val Loss: 0.3222\n",
      "\n",
      "Validation loss improved from 0.3232 to 0.3222. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4467\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2945\n",
      "    Batch [2/2], Val Loss: 0.3479\n",
      "Epoch [25/2000], Avg Train Loss: 0.4467, Avg Val Loss: 0.3212\n",
      "\n",
      "Validation loss improved from 0.3222 to 0.3212. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4462\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2935\n",
      "    Batch [2/2], Val Loss: 0.3471\n",
      "Epoch [26/2000], Avg Train Loss: 0.4462, Avg Val Loss: 0.3203\n",
      "\n",
      "Validation loss improved from 0.3212 to 0.3203. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4466\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2927\n",
      "    Batch [2/2], Val Loss: 0.3462\n",
      "Epoch [27/2000], Avg Train Loss: 0.4466, Avg Val Loss: 0.3195\n",
      "\n",
      "Validation loss improved from 0.3203 to 0.3195. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4421\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2919\n",
      "    Batch [2/2], Val Loss: 0.3453\n",
      "Epoch [28/2000], Avg Train Loss: 0.4421, Avg Val Loss: 0.3186\n",
      "\n",
      "Validation loss improved from 0.3195 to 0.3186. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4445\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2912\n",
      "    Batch [2/2], Val Loss: 0.3444\n",
      "Epoch [29/2000], Avg Train Loss: 0.4445, Avg Val Loss: 0.3178\n",
      "\n",
      "Validation loss improved from 0.3186 to 0.3178. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4456\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2905\n",
      "    Batch [2/2], Val Loss: 0.3435\n",
      "Epoch [30/2000], Avg Train Loss: 0.4456, Avg Val Loss: 0.3170\n",
      "\n",
      "Validation loss improved from 0.3178 to 0.3170. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4412\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2898\n",
      "    Batch [2/2], Val Loss: 0.3427\n",
      "Epoch [31/2000], Avg Train Loss: 0.4412, Avg Val Loss: 0.3163\n",
      "\n",
      "Validation loss improved from 0.3170 to 0.3163. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4418\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2892\n",
      "    Batch [2/2], Val Loss: 0.3417\n",
      "Epoch [32/2000], Avg Train Loss: 0.4418, Avg Val Loss: 0.3155\n",
      "\n",
      "Validation loss improved from 0.3163 to 0.3155. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4408\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2886\n",
      "    Batch [2/2], Val Loss: 0.3407\n",
      "Epoch [33/2000], Avg Train Loss: 0.4408, Avg Val Loss: 0.3147\n",
      "\n",
      "Validation loss improved from 0.3155 to 0.3147. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4410\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2880\n",
      "    Batch [2/2], Val Loss: 0.3397\n",
      "Epoch [34/2000], Avg Train Loss: 0.4410, Avg Val Loss: 0.3139\n",
      "\n",
      "Validation loss improved from 0.3147 to 0.3139. Saving model...\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4398\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2874\n",
      "    Batch [2/2], Val Loss: 0.3387\n",
      "Epoch [35/2000], Avg Train Loss: 0.4398, Avg Val Loss: 0.3131\n",
      "\n",
      "Validation loss improved from 0.3139 to 0.3131. Saving model...\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4401\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2868\n",
      "    Batch [2/2], Val Loss: 0.3377\n",
      "Epoch [36/2000], Avg Train Loss: 0.4401, Avg Val Loss: 0.3123\n",
      "\n",
      "Validation loss improved from 0.3131 to 0.3123. Saving model...\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4385\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2862\n",
      "    Batch [2/2], Val Loss: 0.3368\n",
      "Epoch [37/2000], Avg Train Loss: 0.4385, Avg Val Loss: 0.3115\n",
      "\n",
      "Validation loss improved from 0.3123 to 0.3115. Saving model...\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4378\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2856\n",
      "    Batch [2/2], Val Loss: 0.3357\n",
      "Epoch [38/2000], Avg Train Loss: 0.4378, Avg Val Loss: 0.3106\n",
      "\n",
      "Validation loss improved from 0.3115 to 0.3106. Saving model...\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4392\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2850\n",
      "    Batch [2/2], Val Loss: 0.3346\n",
      "Epoch [39/2000], Avg Train Loss: 0.4392, Avg Val Loss: 0.3098\n",
      "\n",
      "Validation loss improved from 0.3106 to 0.3098. Saving model...\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4364\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2844\n",
      "    Batch [2/2], Val Loss: 0.3335\n",
      "Epoch [40/2000], Avg Train Loss: 0.4364, Avg Val Loss: 0.3089\n",
      "\n",
      "Validation loss improved from 0.3098 to 0.3089. Saving model...\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4348\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2837\n",
      "    Batch [2/2], Val Loss: 0.3324\n",
      "Epoch [41/2000], Avg Train Loss: 0.4348, Avg Val Loss: 0.3081\n",
      "\n",
      "Validation loss improved from 0.3089 to 0.3081. Saving model...\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4349\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2831\n",
      "    Batch [2/2], Val Loss: 0.3312\n",
      "Epoch [42/2000], Avg Train Loss: 0.4349, Avg Val Loss: 0.3072\n",
      "\n",
      "Validation loss improved from 0.3081 to 0.3072. Saving model...\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4319\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2825\n",
      "    Batch [2/2], Val Loss: 0.3300\n",
      "Epoch [43/2000], Avg Train Loss: 0.4319, Avg Val Loss: 0.3063\n",
      "\n",
      "Validation loss improved from 0.3072 to 0.3063. Saving model...\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4365\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2819\n",
      "    Batch [2/2], Val Loss: 0.3289\n",
      "Epoch [44/2000], Avg Train Loss: 0.4365, Avg Val Loss: 0.3054\n",
      "\n",
      "Validation loss improved from 0.3063 to 0.3054. Saving model...\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4323\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2813\n",
      "    Batch [2/2], Val Loss: 0.3277\n",
      "Epoch [45/2000], Avg Train Loss: 0.4323, Avg Val Loss: 0.3045\n",
      "\n",
      "Validation loss improved from 0.3054 to 0.3045. Saving model...\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4368\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2807\n",
      "    Batch [2/2], Val Loss: 0.3265\n",
      "Epoch [46/2000], Avg Train Loss: 0.4368, Avg Val Loss: 0.3036\n",
      "\n",
      "Validation loss improved from 0.3045 to 0.3036. Saving model...\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4312\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2801\n",
      "    Batch [2/2], Val Loss: 0.3254\n",
      "Epoch [47/2000], Avg Train Loss: 0.4312, Avg Val Loss: 0.3027\n",
      "\n",
      "Validation loss improved from 0.3036 to 0.3027. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4304\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2796\n",
      "    Batch [2/2], Val Loss: 0.3241\n",
      "Epoch [48/2000], Avg Train Loss: 0.4304, Avg Val Loss: 0.3018\n",
      "\n",
      "Validation loss improved from 0.3027 to 0.3018. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4274\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2790\n",
      "    Batch [2/2], Val Loss: 0.3229\n",
      "Epoch [49/2000], Avg Train Loss: 0.4274, Avg Val Loss: 0.3009\n",
      "\n",
      "Validation loss improved from 0.3018 to 0.3009. Saving model...\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2785\n",
      "    Batch [2/2], Val Loss: 0.3216\n",
      "Epoch [50/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.3000\n",
      "\n",
      "Validation loss improved from 0.3009 to 0.3000. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2779\n",
      "    Batch [2/2], Val Loss: 0.3203\n",
      "Epoch [51/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2991\n",
      "\n",
      "Validation loss improved from 0.3000 to 0.2991. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2774\n",
      "    Batch [2/2], Val Loss: 0.3192\n",
      "Epoch [52/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2983\n",
      "\n",
      "Validation loss improved from 0.2991 to 0.2983. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4313\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2770\n",
      "    Batch [2/2], Val Loss: 0.3180\n",
      "Epoch [53/2000], Avg Train Loss: 0.4313, Avg Val Loss: 0.2975\n",
      "\n",
      "Validation loss improved from 0.2983 to 0.2975. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2765\n",
      "    Batch [2/2], Val Loss: 0.3168\n",
      "Epoch [54/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.2966\n",
      "\n",
      "Validation loss improved from 0.2975 to 0.2966. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2760\n",
      "    Batch [2/2], Val Loss: 0.3157\n",
      "Epoch [55/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.2958\n",
      "\n",
      "Validation loss improved from 0.2966 to 0.2958. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2755\n",
      "    Batch [2/2], Val Loss: 0.3145\n",
      "Epoch [56/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.2950\n",
      "\n",
      "Validation loss improved from 0.2958 to 0.2950. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4271\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2750\n",
      "    Batch [2/2], Val Loss: 0.3134\n",
      "Epoch [57/2000], Avg Train Loss: 0.4271, Avg Val Loss: 0.2942\n",
      "\n",
      "Validation loss improved from 0.2950 to 0.2942. Saving model...\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4251\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2744\n",
      "    Batch [2/2], Val Loss: 0.3122\n",
      "Epoch [58/2000], Avg Train Loss: 0.4251, Avg Val Loss: 0.2933\n",
      "\n",
      "Validation loss improved from 0.2942 to 0.2933. Saving model...\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2739\n",
      "    Batch [2/2], Val Loss: 0.3110\n",
      "Epoch [59/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2925\n",
      "\n",
      "Validation loss improved from 0.2933 to 0.2925. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2734\n",
      "    Batch [2/2], Val Loss: 0.3099\n",
      "Epoch [60/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2916\n",
      "\n",
      "Validation loss improved from 0.2925 to 0.2916. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2729\n",
      "    Batch [2/2], Val Loss: 0.3088\n",
      "Epoch [61/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2908\n",
      "\n",
      "Validation loss improved from 0.2916 to 0.2908. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4207\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2723\n",
      "    Batch [2/2], Val Loss: 0.3078\n",
      "Epoch [62/2000], Avg Train Loss: 0.4207, Avg Val Loss: 0.2901\n",
      "\n",
      "Validation loss improved from 0.2908 to 0.2901. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2718\n",
      "    Batch [2/2], Val Loss: 0.3068\n",
      "Epoch [63/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2893\n",
      "\n",
      "Validation loss improved from 0.2901 to 0.2893. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4215\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2713\n",
      "    Batch [2/2], Val Loss: 0.3057\n",
      "Epoch [64/2000], Avg Train Loss: 0.4215, Avg Val Loss: 0.2885\n",
      "\n",
      "Validation loss improved from 0.2893 to 0.2885. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4190\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2709\n",
      "    Batch [2/2], Val Loss: 0.3047\n",
      "Epoch [65/2000], Avg Train Loss: 0.4190, Avg Val Loss: 0.2878\n",
      "\n",
      "Validation loss improved from 0.2885 to 0.2878. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4191\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2704\n",
      "    Batch [2/2], Val Loss: 0.3038\n",
      "Epoch [66/2000], Avg Train Loss: 0.4191, Avg Val Loss: 0.2871\n",
      "\n",
      "Validation loss improved from 0.2878 to 0.2871. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2700\n",
      "    Batch [2/2], Val Loss: 0.3029\n",
      "Epoch [67/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2864\n",
      "\n",
      "Validation loss improved from 0.2871 to 0.2864. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4235\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2696\n",
      "    Batch [2/2], Val Loss: 0.3020\n",
      "Epoch [68/2000], Avg Train Loss: 0.4235, Avg Val Loss: 0.2858\n",
      "\n",
      "Validation loss improved from 0.2864 to 0.2858. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2692\n",
      "    Batch [2/2], Val Loss: 0.3011\n",
      "Epoch [69/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2852\n",
      "\n",
      "Validation loss improved from 0.2858 to 0.2852. Saving model...\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2688\n",
      "    Batch [2/2], Val Loss: 0.3003\n",
      "Epoch [70/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2845\n",
      "\n",
      "Validation loss improved from 0.2852 to 0.2845. Saving model...\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2684\n",
      "    Batch [2/2], Val Loss: 0.2994\n",
      "Epoch [71/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2839\n",
      "\n",
      "Validation loss improved from 0.2845 to 0.2839. Saving model...\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2679\n",
      "    Batch [2/2], Val Loss: 0.2986\n",
      "Epoch [72/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2833\n",
      "\n",
      "Validation loss improved from 0.2839 to 0.2833. Saving model...\n",
      "LOG: Epoch [73/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2676\n",
      "    Batch [2/2], Val Loss: 0.2977\n",
      "Epoch [73/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2826\n",
      "\n",
      "Validation loss improved from 0.2833 to 0.2826. Saving model...\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2672\n",
      "    Batch [2/2], Val Loss: 0.2969\n",
      "Epoch [74/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2820\n",
      "\n",
      "Validation loss improved from 0.2826 to 0.2820. Saving model...\n",
      "LOG: Epoch [75/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2668\n",
      "    Batch [2/2], Val Loss: 0.2960\n",
      "Epoch [75/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2814\n",
      "\n",
      "Validation loss improved from 0.2820 to 0.2814. Saving model...\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4158\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2664\n",
      "    Batch [2/2], Val Loss: 0.2951\n",
      "Epoch [76/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2808\n",
      "\n",
      "Validation loss improved from 0.2814 to 0.2808. Saving model...\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2660\n",
      "    Batch [2/2], Val Loss: 0.2943\n",
      "Epoch [77/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2801\n",
      "\n",
      "Validation loss improved from 0.2808 to 0.2801. Saving model...\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2656\n",
      "    Batch [2/2], Val Loss: 0.2934\n",
      "Epoch [78/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.2795\n",
      "\n",
      "Validation loss improved from 0.2801 to 0.2795. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2651\n",
      "    Batch [2/2], Val Loss: 0.2925\n",
      "Epoch [79/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2788\n",
      "\n",
      "Validation loss improved from 0.2795 to 0.2788. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2647\n",
      "    Batch [2/2], Val Loss: 0.2916\n",
      "Epoch [80/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2781\n",
      "\n",
      "Validation loss improved from 0.2788 to 0.2781. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2643\n",
      "    Batch [2/2], Val Loss: 0.2907\n",
      "Epoch [81/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2775\n",
      "\n",
      "Validation loss improved from 0.2781 to 0.2775. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2638\n",
      "    Batch [2/2], Val Loss: 0.2898\n",
      "Epoch [82/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2768\n",
      "\n",
      "Validation loss improved from 0.2775 to 0.2768. Saving model...\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2634\n",
      "    Batch [2/2], Val Loss: 0.2890\n",
      "Epoch [83/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2762\n",
      "\n",
      "Validation loss improved from 0.2768 to 0.2762. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2629\n",
      "    Batch [2/2], Val Loss: 0.2881\n",
      "Epoch [84/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2755\n",
      "\n",
      "Validation loss improved from 0.2762 to 0.2755. Saving model...\n",
      "LOG: Epoch [85/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2625\n",
      "    Batch [2/2], Val Loss: 0.2873\n",
      "Epoch [85/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2749\n",
      "\n",
      "Validation loss improved from 0.2755 to 0.2749. Saving model...\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2621\n",
      "    Batch [2/2], Val Loss: 0.2865\n",
      "Epoch [86/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2749 to 0.2743. Saving model...\n",
      "LOG: Epoch [87/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2617\n",
      "    Batch [2/2], Val Loss: 0.2856\n",
      "Epoch [87/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2736\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2736. Saving model...\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [88/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2612\n",
      "    Batch [2/2], Val Loss: 0.2848\n",
      "Epoch [88/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2730\n",
      "\n",
      "Validation loss improved from 0.2736 to 0.2730. Saving model...\n",
      "LOG: Epoch [89/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2608\n",
      "    Batch [2/2], Val Loss: 0.2840\n",
      "Epoch [89/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2730 to 0.2724. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2604\n",
      "    Batch [2/2], Val Loss: 0.2831\n",
      "Epoch [90/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2717. Saving model...\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2600\n",
      "    Batch [2/2], Val Loss: 0.2823\n",
      "Epoch [91/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2711. Saving model...\n",
      "LOG: Epoch [92/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2595\n",
      "    Batch [2/2], Val Loss: 0.2815\n",
      "Epoch [92/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2705. Saving model...\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2591\n",
      "    Batch [2/2], Val Loss: 0.2807\n",
      "Epoch [93/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2699\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2699. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2586\n",
      "    Batch [2/2], Val Loss: 0.2799\n",
      "Epoch [94/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2693\n",
      "\n",
      "Validation loss improved from 0.2699 to 0.2693. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2582\n",
      "    Batch [2/2], Val Loss: 0.2792\n",
      "Epoch [95/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2687\n",
      "\n",
      "Validation loss improved from 0.2693 to 0.2687. Saving model...\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2578\n",
      "    Batch [2/2], Val Loss: 0.2785\n",
      "Epoch [96/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2682\n",
      "\n",
      "Validation loss improved from 0.2687 to 0.2682. Saving model...\n",
      "LOG: Epoch [97/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2574\n",
      "    Batch [2/2], Val Loss: 0.2778\n",
      "Epoch [97/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2676\n",
      "\n",
      "Validation loss improved from 0.2682 to 0.2676. Saving model...\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2570\n",
      "    Batch [2/2], Val Loss: 0.2773\n",
      "Epoch [98/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2671\n",
      "\n",
      "Validation loss improved from 0.2676 to 0.2671. Saving model...\n",
      "LOG: Epoch [99/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2566\n",
      "    Batch [2/2], Val Loss: 0.2767\n",
      "Epoch [99/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2671 to 0.2666. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2562\n",
      "    Batch [2/2], Val Loss: 0.2761\n",
      "Epoch [100/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2661. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2558\n",
      "    Batch [2/2], Val Loss: 0.2755\n",
      "Epoch [101/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2656\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2656. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2554\n",
      "    Batch [2/2], Val Loss: 0.2749\n",
      "Epoch [102/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2651\n",
      "\n",
      "Validation loss improved from 0.2656 to 0.2651. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2551\n",
      "    Batch [2/2], Val Loss: 0.2742\n",
      "Epoch [103/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2651 to 0.2646. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2547\n",
      "    Batch [2/2], Val Loss: 0.2736\n",
      "Epoch [104/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2641\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2641. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2543\n",
      "    Batch [2/2], Val Loss: 0.2730\n",
      "Epoch [105/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2637\n",
      "\n",
      "Validation loss improved from 0.2641 to 0.2637. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2540\n",
      "    Batch [2/2], Val Loss: 0.2724\n",
      "Epoch [106/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2637 to 0.2632. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2536\n",
      "    Batch [2/2], Val Loss: 0.2718\n",
      "Epoch [107/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2627. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2533\n",
      "    Batch [2/2], Val Loss: 0.2712\n",
      "Epoch [108/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2622\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2622. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2529\n",
      "    Batch [2/2], Val Loss: 0.2707\n",
      "Epoch [109/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2618\n",
      "\n",
      "Validation loss improved from 0.2622 to 0.2618. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2525\n",
      "    Batch [2/2], Val Loss: 0.2702\n",
      "Epoch [110/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2618 to 0.2614. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2522\n",
      "    Batch [2/2], Val Loss: 0.2696\n",
      "Epoch [111/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2609\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2609. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2518\n",
      "    Batch [2/2], Val Loss: 0.2691\n",
      "Epoch [112/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2609 to 0.2605. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2515\n",
      "    Batch [2/2], Val Loss: 0.2686\n",
      "Epoch [113/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2601. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2512\n",
      "    Batch [2/2], Val Loss: 0.2681\n",
      "Epoch [114/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2597. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2508\n",
      "    Batch [2/2], Val Loss: 0.2676\n",
      "Epoch [115/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2592. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2505\n",
      "    Batch [2/2], Val Loss: 0.2670\n",
      "Epoch [116/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2588. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2502\n",
      "    Batch [2/2], Val Loss: 0.2663\n",
      "Epoch [117/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2583\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2583. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3851\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2499\n",
      "    Batch [2/2], Val Loss: 0.2657\n",
      "Epoch [118/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2583 to 0.2578. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3866\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2496\n",
      "    Batch [2/2], Val Loss: 0.2650\n",
      "Epoch [119/2000], Avg Train Loss: 0.3866, Avg Val Loss: 0.2573\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2573. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3842\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2493\n",
      "    Batch [2/2], Val Loss: 0.2643\n",
      "Epoch [120/2000], Avg Train Loss: 0.3842, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2573 to 0.2568. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2490\n",
      "    Batch [2/2], Val Loss: 0.2636\n",
      "Epoch [121/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2563. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2488\n",
      "    Batch [2/2], Val Loss: 0.2629\n",
      "Epoch [122/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2558. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3821\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2485\n",
      "    Batch [2/2], Val Loss: 0.2622\n",
      "Epoch [123/2000], Avg Train Loss: 0.3821, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2554. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2482\n",
      "    Batch [2/2], Val Loss: 0.2616\n",
      "Epoch [124/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2549. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2479\n",
      "    Batch [2/2], Val Loss: 0.2609\n",
      "Epoch [125/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2544. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3815\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2477\n",
      "    Batch [2/2], Val Loss: 0.2604\n",
      "Epoch [126/2000], Avg Train Loss: 0.3815, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2540. Saving model...\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3820\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2474\n",
      "    Batch [2/2], Val Loss: 0.2598\n",
      "Epoch [127/2000], Avg Train Loss: 0.3820, Avg Val Loss: 0.2536\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2536. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3818\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2471\n",
      "    Batch [2/2], Val Loss: 0.2592\n",
      "Epoch [128/2000], Avg Train Loss: 0.3818, Avg Val Loss: 0.2532\n",
      "\n",
      "Validation loss improved from 0.2536 to 0.2532. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3756\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2468\n",
      "    Batch [2/2], Val Loss: 0.2586\n",
      "Epoch [129/2000], Avg Train Loss: 0.3756, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2532 to 0.2527. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3796\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2466\n",
      "    Batch [2/2], Val Loss: 0.2581\n",
      "Epoch [130/2000], Avg Train Loss: 0.3796, Avg Val Loss: 0.2523\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2523. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3813\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2463\n",
      "    Batch [2/2], Val Loss: 0.2575\n",
      "Epoch [131/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2523 to 0.2519. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3757\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2460\n",
      "    Batch [2/2], Val Loss: 0.2570\n",
      "Epoch [132/2000], Avg Train Loss: 0.3757, Avg Val Loss: 0.2515\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2515. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3774\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2457\n",
      "    Batch [2/2], Val Loss: 0.2564\n",
      "Epoch [133/2000], Avg Train Loss: 0.3774, Avg Val Loss: 0.2511\n",
      "\n",
      "Validation loss improved from 0.2515 to 0.2511. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3766\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2455\n",
      "    Batch [2/2], Val Loss: 0.2558\n",
      "Epoch [134/2000], Avg Train Loss: 0.3766, Avg Val Loss: 0.2507\n",
      "\n",
      "Validation loss improved from 0.2511 to 0.2507. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3783\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2452\n",
      "    Batch [2/2], Val Loss: 0.2553\n",
      "Epoch [135/2000], Avg Train Loss: 0.3783, Avg Val Loss: 0.2503\n",
      "\n",
      "Validation loss improved from 0.2507 to 0.2503. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3814\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2450\n",
      "    Batch [2/2], Val Loss: 0.2547\n",
      "Epoch [136/2000], Avg Train Loss: 0.3814, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2503 to 0.2499. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3758\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2448\n",
      "    Batch [2/2], Val Loss: 0.2542\n",
      "Epoch [137/2000], Avg Train Loss: 0.3758, Avg Val Loss: 0.2495\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2495. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3725\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2445\n",
      "    Batch [2/2], Val Loss: 0.2536\n",
      "Epoch [138/2000], Avg Train Loss: 0.3725, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2495 to 0.2491. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3749\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2443\n",
      "    Batch [2/2], Val Loss: 0.2530\n",
      "Epoch [139/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2486\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2486. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3799\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2441\n",
      "    Batch [2/2], Val Loss: 0.2523\n",
      "Epoch [140/2000], Avg Train Loss: 0.3799, Avg Val Loss: 0.2482\n",
      "\n",
      "Validation loss improved from 0.2486 to 0.2482. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3709\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2439\n",
      "    Batch [2/2], Val Loss: 0.2515\n",
      "Epoch [141/2000], Avg Train Loss: 0.3709, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2482 to 0.2477. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3744\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2436\n",
      "    Batch [2/2], Val Loss: 0.2508\n",
      "Epoch [142/2000], Avg Train Loss: 0.3744, Avg Val Loss: 0.2472\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2472. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3721\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2434\n",
      "    Batch [2/2], Val Loss: 0.2501\n",
      "Epoch [143/2000], Avg Train Loss: 0.3721, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2472 to 0.2468. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3742\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2432\n",
      "    Batch [2/2], Val Loss: 0.2495\n",
      "Epoch [144/2000], Avg Train Loss: 0.3742, Avg Val Loss: 0.2463\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2463. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3707\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2430\n",
      "    Batch [2/2], Val Loss: 0.2488\n",
      "Epoch [145/2000], Avg Train Loss: 0.3707, Avg Val Loss: 0.2459\n",
      "\n",
      "Validation loss improved from 0.2463 to 0.2459. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3729\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2428\n",
      "    Batch [2/2], Val Loss: 0.2481\n",
      "Epoch [146/2000], Avg Train Loss: 0.3729, Avg Val Loss: 0.2455\n",
      "\n",
      "Validation loss improved from 0.2459 to 0.2455. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3670\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2426\n",
      "    Batch [2/2], Val Loss: 0.2475\n",
      "Epoch [147/2000], Avg Train Loss: 0.3670, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2455 to 0.2451. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3707\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2424\n",
      "    Batch [2/2], Val Loss: 0.2469\n",
      "Epoch [148/2000], Avg Train Loss: 0.3707, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2446. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3750\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2422\n",
      "    Batch [2/2], Val Loss: 0.2463\n",
      "Epoch [149/2000], Avg Train Loss: 0.3750, Avg Val Loss: 0.2442\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2442. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3666\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2420\n",
      "    Batch [2/2], Val Loss: 0.2457\n",
      "Epoch [150/2000], Avg Train Loss: 0.3666, Avg Val Loss: 0.2438\n",
      "\n",
      "Validation loss improved from 0.2442 to 0.2438. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3695\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2417\n",
      "    Batch [2/2], Val Loss: 0.2451\n",
      "Epoch [151/2000], Avg Train Loss: 0.3695, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2438 to 0.2434. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3695\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2415\n",
      "    Batch [2/2], Val Loss: 0.2444\n",
      "Epoch [152/2000], Avg Train Loss: 0.3695, Avg Val Loss: 0.2429\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2429. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3643\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2412\n",
      "    Batch [2/2], Val Loss: 0.2436\n",
      "Epoch [153/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2424\n",
      "\n",
      "Validation loss improved from 0.2429 to 0.2424. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3688\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2410\n",
      "    Batch [2/2], Val Loss: 0.2429\n",
      "Epoch [154/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2424 to 0.2420. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3636\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2408\n",
      "    Batch [2/2], Val Loss: 0.2423\n",
      "Epoch [155/2000], Avg Train Loss: 0.3636, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2416. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3700\n",
      "LOG: Epoch [156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2406\n",
      "    Batch [2/2], Val Loss: 0.2417\n",
      "Epoch [156/2000], Avg Train Loss: 0.3700, Avg Val Loss: 0.2412\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2412. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3688\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2404\n",
      "    Batch [2/2], Val Loss: 0.2412\n",
      "Epoch [157/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.2408\n",
      "\n",
      "Validation loss improved from 0.2412 to 0.2408. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3654\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2401\n",
      "    Batch [2/2], Val Loss: 0.2405\n",
      "Epoch [158/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.2403\n",
      "\n",
      "Validation loss improved from 0.2408 to 0.2403. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3643\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2399\n",
      "    Batch [2/2], Val Loss: 0.2399\n",
      "Epoch [159/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2399\n",
      "\n",
      "Validation loss improved from 0.2403 to 0.2399. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3658\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2397\n",
      "    Batch [2/2], Val Loss: 0.2394\n",
      "Epoch [160/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2395\n",
      "\n",
      "Validation loss improved from 0.2399 to 0.2395. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3660\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2395\n",
      "    Batch [2/2], Val Loss: 0.2389\n",
      "Epoch [161/2000], Avg Train Loss: 0.3660, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2395 to 0.2392. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3643\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2393\n",
      "    Batch [2/2], Val Loss: 0.2383\n",
      "Epoch [162/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2388. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3645\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2391\n",
      "    Batch [2/2], Val Loss: 0.2377\n",
      "Epoch [163/2000], Avg Train Loss: 0.3645, Avg Val Loss: 0.2384\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2384. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3619\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2389\n",
      "    Batch [2/2], Val Loss: 0.2372\n",
      "Epoch [164/2000], Avg Train Loss: 0.3619, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2384 to 0.2380. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3617\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2386\n",
      "    Batch [2/2], Val Loss: 0.2366\n",
      "Epoch [165/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.2376\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2376. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3616\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2384\n",
      "    Batch [2/2], Val Loss: 0.2361\n",
      "Epoch [166/2000], Avg Train Loss: 0.3616, Avg Val Loss: 0.2372\n",
      "\n",
      "Validation loss improved from 0.2376 to 0.2372. Saving model...\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3623\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2382\n",
      "    Batch [2/2], Val Loss: 0.2355\n",
      "Epoch [167/2000], Avg Train Loss: 0.3623, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2372 to 0.2369. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3587\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2380\n",
      "    Batch [2/2], Val Loss: 0.2349\n",
      "Epoch [168/2000], Avg Train Loss: 0.3587, Avg Val Loss: 0.2364\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2364. Saving model...\n",
      "LOG: Epoch [169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3589\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2378\n",
      "    Batch [2/2], Val Loss: 0.2343\n",
      "Epoch [169/2000], Avg Train Loss: 0.3589, Avg Val Loss: 0.2361\n",
      "\n",
      "Validation loss improved from 0.2364 to 0.2361. Saving model...\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3547\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2377\n",
      "    Batch [2/2], Val Loss: 0.2337\n",
      "Epoch [170/2000], Avg Train Loss: 0.3547, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2361 to 0.2357. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3578\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2375\n",
      "    Batch [2/2], Val Loss: 0.2331\n",
      "Epoch [171/2000], Avg Train Loss: 0.3578, Avg Val Loss: 0.2353\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2353. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3586\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2373\n",
      "    Batch [2/2], Val Loss: 0.2325\n",
      "Epoch [172/2000], Avg Train Loss: 0.3586, Avg Val Loss: 0.2349\n",
      "\n",
      "Validation loss improved from 0.2353 to 0.2349. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3578\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2371\n",
      "    Batch [2/2], Val Loss: 0.2320\n",
      "Epoch [173/2000], Avg Train Loss: 0.3578, Avg Val Loss: 0.2345\n",
      "\n",
      "Validation loss improved from 0.2349 to 0.2345. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3542\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2369\n",
      "    Batch [2/2], Val Loss: 0.2315\n",
      "Epoch [174/2000], Avg Train Loss: 0.3542, Avg Val Loss: 0.2342\n",
      "\n",
      "Validation loss improved from 0.2345 to 0.2342. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3534\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2367\n",
      "    Batch [2/2], Val Loss: 0.2310\n",
      "Epoch [175/2000], Avg Train Loss: 0.3534, Avg Val Loss: 0.2339\n",
      "\n",
      "Validation loss improved from 0.2342 to 0.2339. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3586\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2365\n",
      "    Batch [2/2], Val Loss: 0.2307\n",
      "Epoch [176/2000], Avg Train Loss: 0.3586, Avg Val Loss: 0.2336\n",
      "\n",
      "Validation loss improved from 0.2339 to 0.2336. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2363\n",
      "    Batch [2/2], Val Loss: 0.2302\n",
      "Epoch [177/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2336 to 0.2333. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3596\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2362\n",
      "    Batch [2/2], Val Loss: 0.2298\n",
      "Epoch [178/2000], Avg Train Loss: 0.3596, Avg Val Loss: 0.2330\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2330. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3543\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2360\n",
      "    Batch [2/2], Val Loss: 0.2293\n",
      "Epoch [179/2000], Avg Train Loss: 0.3543, Avg Val Loss: 0.2326\n",
      "\n",
      "Validation loss improved from 0.2330 to 0.2326. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2359\n",
      "    Batch [2/2], Val Loss: 0.2289\n",
      "Epoch [180/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2324\n",
      "\n",
      "Validation loss improved from 0.2326 to 0.2324. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2358\n",
      "    Batch [2/2], Val Loss: 0.2285\n",
      "Epoch [181/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2324 to 0.2321. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3537\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2356\n",
      "    Batch [2/2], Val Loss: 0.2282\n",
      "Epoch [182/2000], Avg Train Loss: 0.3537, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2319. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2354\n",
      "    Batch [2/2], Val Loss: 0.2278\n",
      "Epoch [183/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2316\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2316. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3531\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2352\n",
      "    Batch [2/2], Val Loss: 0.2273\n",
      "Epoch [184/2000], Avg Train Loss: 0.3531, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2316 to 0.2313. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3555\n",
      "LOG: Epoch [185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2350\n",
      "    Batch [2/2], Val Loss: 0.2268\n",
      "Epoch [185/2000], Avg Train Loss: 0.3555, Avg Val Loss: 0.2309\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2309. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3546\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2349\n",
      "    Batch [2/2], Val Loss: 0.2263\n",
      "Epoch [186/2000], Avg Train Loss: 0.3546, Avg Val Loss: 0.2306\n",
      "\n",
      "Validation loss improved from 0.2309 to 0.2306. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2347\n",
      "    Batch [2/2], Val Loss: 0.2258\n",
      "Epoch [187/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2306 to 0.2302. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2345\n",
      "    Batch [2/2], Val Loss: 0.2252\n",
      "Epoch [188/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2298\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2298. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2343\n",
      "    Batch [2/2], Val Loss: 0.2246\n",
      "Epoch [189/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2295\n",
      "\n",
      "Validation loss improved from 0.2298 to 0.2295. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2341\n",
      "    Batch [2/2], Val Loss: 0.2241\n",
      "Epoch [190/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2295 to 0.2291. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2339\n",
      "    Batch [2/2], Val Loss: 0.2236\n",
      "Epoch [191/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2287. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2337\n",
      "    Batch [2/2], Val Loss: 0.2231\n",
      "Epoch [192/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2284. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2336\n",
      "    Batch [2/2], Val Loss: 0.2227\n",
      "Epoch [193/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2281. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2334\n",
      "    Batch [2/2], Val Loss: 0.2223\n",
      "Epoch [194/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2278\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2278. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2333\n",
      "    Batch [2/2], Val Loss: 0.2219\n",
      "Epoch [195/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2278 to 0.2276. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2331\n",
      "    Batch [2/2], Val Loss: 0.2215\n",
      "Epoch [196/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2273. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2330\n",
      "    Batch [2/2], Val Loss: 0.2210\n",
      "Epoch [197/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2270\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2270. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2328\n",
      "    Batch [2/2], Val Loss: 0.2206\n",
      "Epoch [198/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2267\n",
      "\n",
      "Validation loss improved from 0.2270 to 0.2267. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2327\n",
      "    Batch [2/2], Val Loss: 0.2201\n",
      "Epoch [199/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2264\n",
      "\n",
      "Validation loss improved from 0.2267 to 0.2264. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2325\n",
      "    Batch [2/2], Val Loss: 0.2198\n",
      "Epoch [200/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2261\n",
      "\n",
      "Validation loss improved from 0.2264 to 0.2261. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2324\n",
      "    Batch [2/2], Val Loss: 0.2194\n",
      "Epoch [201/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2259\n",
      "\n",
      "Validation loss improved from 0.2261 to 0.2259. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2322\n",
      "    Batch [2/2], Val Loss: 0.2191\n",
      "Epoch [202/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2257\n",
      "\n",
      "Validation loss improved from 0.2259 to 0.2257. Saving model...\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2320\n",
      "    Batch [2/2], Val Loss: 0.2189\n",
      "Epoch [203/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2255\n",
      "\n",
      "Validation loss improved from 0.2257 to 0.2255. Saving model...\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2319\n",
      "    Batch [2/2], Val Loss: 0.2186\n",
      "Epoch [204/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2252\n",
      "\n",
      "Validation loss improved from 0.2255 to 0.2252. Saving model...\n",
      "LOG: Epoch [205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2317\n",
      "    Batch [2/2], Val Loss: 0.2184\n",
      "Epoch [205/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2251\n",
      "\n",
      "Validation loss improved from 0.2252 to 0.2251. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3397\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2316\n",
      "    Batch [2/2], Val Loss: 0.2182\n",
      "Epoch [206/2000], Avg Train Loss: 0.3397, Avg Val Loss: 0.2249\n",
      "\n",
      "Validation loss improved from 0.2251 to 0.2249. Saving model...\n",
      "LOG: Epoch [207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3361\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2315\n",
      "    Batch [2/2], Val Loss: 0.2179\n",
      "Epoch [207/2000], Avg Train Loss: 0.3361, Avg Val Loss: 0.2247\n",
      "\n",
      "Validation loss improved from 0.2249 to 0.2247. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3382\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2315\n",
      "    Batch [2/2], Val Loss: 0.2176\n",
      "Epoch [208/2000], Avg Train Loss: 0.3382, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2247 to 0.2245. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2313\n",
      "    Batch [2/2], Val Loss: 0.2173\n",
      "Epoch [209/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2243\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2243. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2312\n",
      "    Batch [2/2], Val Loss: 0.2169\n",
      "Epoch [210/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2241\n",
      "\n",
      "Validation loss improved from 0.2243 to 0.2241. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2311\n",
      "    Batch [2/2], Val Loss: 0.2166\n",
      "Epoch [211/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2239\n",
      "\n",
      "Validation loss improved from 0.2241 to 0.2239. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3371\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2310\n",
      "    Batch [2/2], Val Loss: 0.2163\n",
      "Epoch [212/2000], Avg Train Loss: 0.3371, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2239 to 0.2237. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2309\n",
      "    Batch [2/2], Val Loss: 0.2161\n",
      "Epoch [213/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2235\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2235. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3392\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2308\n",
      "    Batch [2/2], Val Loss: 0.2158\n",
      "Epoch [214/2000], Avg Train Loss: 0.3392, Avg Val Loss: 0.2233\n",
      "\n",
      "Validation loss improved from 0.2235 to 0.2233. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3382\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2308\n",
      "    Batch [2/2], Val Loss: 0.2156\n",
      "Epoch [215/2000], Avg Train Loss: 0.3382, Avg Val Loss: 0.2232\n",
      "\n",
      "Validation loss improved from 0.2233 to 0.2232. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2307\n",
      "    Batch [2/2], Val Loss: 0.2155\n",
      "Epoch [216/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2231\n",
      "\n",
      "Validation loss improved from 0.2232 to 0.2231. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2306\n",
      "    Batch [2/2], Val Loss: 0.2152\n",
      "Epoch [217/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2229\n",
      "\n",
      "Validation loss improved from 0.2231 to 0.2229. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2305\n",
      "    Batch [2/2], Val Loss: 0.2150\n",
      "Epoch [218/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2227\n",
      "\n",
      "Validation loss improved from 0.2229 to 0.2227. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3333\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2305\n",
      "    Batch [2/2], Val Loss: 0.2147\n",
      "Epoch [219/2000], Avg Train Loss: 0.3333, Avg Val Loss: 0.2226\n",
      "\n",
      "Validation loss improved from 0.2227 to 0.2226. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3347\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2304\n",
      "    Batch [2/2], Val Loss: 0.2144\n",
      "Epoch [220/2000], Avg Train Loss: 0.3347, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2226 to 0.2224. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3300\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2303\n",
      "    Batch [2/2], Val Loss: 0.2142\n",
      "Epoch [221/2000], Avg Train Loss: 0.3300, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2222. Saving model...\n",
      "LOG: Epoch [222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3310\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2301\n",
      "    Batch [2/2], Val Loss: 0.2139\n",
      "Epoch [222/2000], Avg Train Loss: 0.3310, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2220. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3363\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2300\n",
      "    Batch [2/2], Val Loss: 0.2136\n",
      "Epoch [223/2000], Avg Train Loss: 0.3363, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2218. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3362\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2298\n",
      "    Batch [2/2], Val Loss: 0.2132\n",
      "Epoch [224/2000], Avg Train Loss: 0.3362, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2215. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3316\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2297\n",
      "    Batch [2/2], Val Loss: 0.2129\n",
      "Epoch [225/2000], Avg Train Loss: 0.3316, Avg Val Loss: 0.2213\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2213. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3260\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2296\n",
      "    Batch [2/2], Val Loss: 0.2126\n",
      "Epoch [226/2000], Avg Train Loss: 0.3260, Avg Val Loss: 0.2211\n",
      "\n",
      "Validation loss improved from 0.2213 to 0.2211. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3331\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2295\n",
      "    Batch [2/2], Val Loss: 0.2124\n",
      "Epoch [227/2000], Avg Train Loss: 0.3331, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2211 to 0.2210. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3349\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2295\n",
      "    Batch [2/2], Val Loss: 0.2122\n",
      "Epoch [228/2000], Avg Train Loss: 0.3349, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2209. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3315\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2294\n",
      "    Batch [2/2], Val Loss: 0.2120\n",
      "Epoch [229/2000], Avg Train Loss: 0.3315, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2207. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3326\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2293\n",
      "    Batch [2/2], Val Loss: 0.2118\n",
      "Epoch [230/2000], Avg Train Loss: 0.3326, Avg Val Loss: 0.2206\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2206. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3301\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2292\n",
      "    Batch [2/2], Val Loss: 0.2116\n",
      "Epoch [231/2000], Avg Train Loss: 0.3301, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2206 to 0.2204. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3272\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2291\n",
      "    Batch [2/2], Val Loss: 0.2114\n",
      "Epoch [232/2000], Avg Train Loss: 0.3272, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2202. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3325\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2290\n",
      "    Batch [2/2], Val Loss: 0.2111\n",
      "Epoch [233/2000], Avg Train Loss: 0.3325, Avg Val Loss: 0.2201\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2201. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3357\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2289\n",
      "    Batch [2/2], Val Loss: 0.2110\n",
      "Epoch [234/2000], Avg Train Loss: 0.3357, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2201 to 0.2200. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3314\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2288\n",
      "    Batch [2/2], Val Loss: 0.2109\n",
      "Epoch [235/2000], Avg Train Loss: 0.3314, Avg Val Loss: 0.2198\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2198. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3333\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2287\n",
      "    Batch [2/2], Val Loss: 0.2107\n",
      "Epoch [236/2000], Avg Train Loss: 0.3333, Avg Val Loss: 0.2197\n",
      "\n",
      "Validation loss improved from 0.2198 to 0.2197. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3288\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2286\n",
      "    Batch [2/2], Val Loss: 0.2106\n",
      "Epoch [237/2000], Avg Train Loss: 0.3288, Avg Val Loss: 0.2196\n",
      "\n",
      "Validation loss improved from 0.2197 to 0.2196. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3273\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2285\n",
      "    Batch [2/2], Val Loss: 0.2105\n",
      "Epoch [238/2000], Avg Train Loss: 0.3273, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2196 to 0.2195. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3325\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2285\n",
      "    Batch [2/2], Val Loss: 0.2102\n",
      "Epoch [239/2000], Avg Train Loss: 0.3325, Avg Val Loss: 0.2194\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2194. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3293\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2284\n",
      "    Batch [2/2], Val Loss: 0.2100\n",
      "Epoch [240/2000], Avg Train Loss: 0.3293, Avg Val Loss: 0.2192\n",
      "\n",
      "Validation loss improved from 0.2194 to 0.2192. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3278\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2284\n",
      "    Batch [2/2], Val Loss: 0.2097\n",
      "Epoch [241/2000], Avg Train Loss: 0.3278, Avg Val Loss: 0.2190\n",
      "\n",
      "Validation loss improved from 0.2192 to 0.2190. Saving model...\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3302\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2283\n",
      "    Batch [2/2], Val Loss: 0.2094\n",
      "Epoch [242/2000], Avg Train Loss: 0.3302, Avg Val Loss: 0.2189\n",
      "\n",
      "Validation loss improved from 0.2190 to 0.2189. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3288\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2283\n",
      "    Batch [2/2], Val Loss: 0.2090\n",
      "Epoch [243/2000], Avg Train Loss: 0.3288, Avg Val Loss: 0.2186\n",
      "\n",
      "Validation loss improved from 0.2189 to 0.2186. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3275\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2282\n",
      "    Batch [2/2], Val Loss: 0.2086\n",
      "Epoch [244/2000], Avg Train Loss: 0.3275, Avg Val Loss: 0.2184\n",
      "\n",
      "Validation loss improved from 0.2186 to 0.2184. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3263\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2281\n",
      "    Batch [2/2], Val Loss: 0.2083\n",
      "Epoch [245/2000], Avg Train Loss: 0.3263, Avg Val Loss: 0.2182\n",
      "\n",
      "Validation loss improved from 0.2184 to 0.2182. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3321\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2280\n",
      "    Batch [2/2], Val Loss: 0.2080\n",
      "Epoch [246/2000], Avg Train Loss: 0.3321, Avg Val Loss: 0.2180\n",
      "\n",
      "Validation loss improved from 0.2182 to 0.2180. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3283\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2279\n",
      "    Batch [2/2], Val Loss: 0.2076\n",
      "Epoch [247/2000], Avg Train Loss: 0.3283, Avg Val Loss: 0.2178\n",
      "\n",
      "Validation loss improved from 0.2180 to 0.2178. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3256\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2278\n",
      "    Batch [2/2], Val Loss: 0.2073\n",
      "Epoch [248/2000], Avg Train Loss: 0.3256, Avg Val Loss: 0.2175\n",
      "\n",
      "Validation loss improved from 0.2178 to 0.2175. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3250\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2277\n",
      "    Batch [2/2], Val Loss: 0.2069\n",
      "Epoch [249/2000], Avg Train Loss: 0.3250, Avg Val Loss: 0.2173\n",
      "\n",
      "Validation loss improved from 0.2175 to 0.2173. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3234\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2275\n",
      "    Batch [2/2], Val Loss: 0.2065\n",
      "Epoch [250/2000], Avg Train Loss: 0.3234, Avg Val Loss: 0.2170\n",
      "\n",
      "Validation loss improved from 0.2173 to 0.2170. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3185\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2274\n",
      "    Batch [2/2], Val Loss: 0.2062\n",
      "Epoch [251/2000], Avg Train Loss: 0.3185, Avg Val Loss: 0.2168\n",
      "\n",
      "Validation loss improved from 0.2170 to 0.2168. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3228\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2272\n",
      "    Batch [2/2], Val Loss: 0.2060\n",
      "Epoch [252/2000], Avg Train Loss: 0.3228, Avg Val Loss: 0.2166\n",
      "\n",
      "Validation loss improved from 0.2168 to 0.2166. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3251\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2271\n",
      "    Batch [2/2], Val Loss: 0.2058\n",
      "Epoch [253/2000], Avg Train Loss: 0.3251, Avg Val Loss: 0.2164\n",
      "\n",
      "Validation loss improved from 0.2166 to 0.2164. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3223\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2269\n",
      "    Batch [2/2], Val Loss: 0.2055\n",
      "Epoch [254/2000], Avg Train Loss: 0.3223, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2164 to 0.2162. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3196\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2268\n",
      "    Batch [2/2], Val Loss: 0.2052\n",
      "Epoch [255/2000], Avg Train Loss: 0.3196, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2160. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3261\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2266\n",
      "    Batch [2/2], Val Loss: 0.2049\n",
      "Epoch [256/2000], Avg Train Loss: 0.3261, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2157. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3225\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2264\n",
      "    Batch [2/2], Val Loss: 0.2045\n",
      "Epoch [257/2000], Avg Train Loss: 0.3225, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2155. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3225\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2262\n",
      "    Batch [2/2], Val Loss: 0.2042\n",
      "Epoch [258/2000], Avg Train Loss: 0.3225, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2152. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3253\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2260\n",
      "    Batch [2/2], Val Loss: 0.2039\n",
      "Epoch [259/2000], Avg Train Loss: 0.3253, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2150. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3222\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2259\n",
      "    Batch [2/2], Val Loss: 0.2037\n",
      "Epoch [260/2000], Avg Train Loss: 0.3222, Avg Val Loss: 0.2148\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2148. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3220\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2258\n",
      "    Batch [2/2], Val Loss: 0.2036\n",
      "Epoch [261/2000], Avg Train Loss: 0.3220, Avg Val Loss: 0.2147\n",
      "\n",
      "Validation loss improved from 0.2148 to 0.2147. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3280\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2257\n",
      "    Batch [2/2], Val Loss: 0.2035\n",
      "Epoch [262/2000], Avg Train Loss: 0.3280, Avg Val Loss: 0.2146\n",
      "\n",
      "Validation loss improved from 0.2147 to 0.2146. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3175\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2257\n",
      "    Batch [2/2], Val Loss: 0.2033\n",
      "Epoch [263/2000], Avg Train Loss: 0.3175, Avg Val Loss: 0.2145\n",
      "\n",
      "Validation loss improved from 0.2146 to 0.2145. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3194\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2257\n",
      "    Batch [2/2], Val Loss: 0.2032\n",
      "Epoch [264/2000], Avg Train Loss: 0.3194, Avg Val Loss: 0.2144\n",
      "\n",
      "Validation loss improved from 0.2145 to 0.2144. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3144\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2256\n",
      "    Batch [2/2], Val Loss: 0.2030\n",
      "Epoch [265/2000], Avg Train Loss: 0.3144, Avg Val Loss: 0.2143\n",
      "\n",
      "Validation loss improved from 0.2144 to 0.2143. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3173\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2256\n",
      "    Batch [2/2], Val Loss: 0.2027\n",
      "Epoch [266/2000], Avg Train Loss: 0.3173, Avg Val Loss: 0.2141\n",
      "\n",
      "Validation loss improved from 0.2143 to 0.2141. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3200\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2255\n",
      "    Batch [2/2], Val Loss: 0.2025\n",
      "Epoch [267/2000], Avg Train Loss: 0.3200, Avg Val Loss: 0.2140\n",
      "\n",
      "Validation loss improved from 0.2141 to 0.2140. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3206\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2254\n",
      "    Batch [2/2], Val Loss: 0.2023\n",
      "Epoch [268/2000], Avg Train Loss: 0.3206, Avg Val Loss: 0.2138\n",
      "\n",
      "Validation loss improved from 0.2140 to 0.2138. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3180\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2254\n",
      "    Batch [2/2], Val Loss: 0.2021\n",
      "Epoch [269/2000], Avg Train Loss: 0.3180, Avg Val Loss: 0.2137\n",
      "\n",
      "Validation loss improved from 0.2138 to 0.2137. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3133\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2253\n",
      "    Batch [2/2], Val Loss: 0.2018\n",
      "Epoch [270/2000], Avg Train Loss: 0.3133, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2137 to 0.2135. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3110\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2252\n",
      "    Batch [2/2], Val Loss: 0.2015\n",
      "Epoch [271/2000], Avg Train Loss: 0.3110, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2134. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3163\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2251\n",
      "    Batch [2/2], Val Loss: 0.2012\n",
      "Epoch [272/2000], Avg Train Loss: 0.3163, Avg Val Loss: 0.2132\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2132. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3177\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2251\n",
      "    Batch [2/2], Val Loss: 0.2008\n",
      "Epoch [273/2000], Avg Train Loss: 0.3177, Avg Val Loss: 0.2130\n",
      "\n",
      "Validation loss improved from 0.2132 to 0.2130. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3174\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2251\n",
      "    Batch [2/2], Val Loss: 0.2007\n",
      "Epoch [274/2000], Avg Train Loss: 0.3174, Avg Val Loss: 0.2129\n",
      "\n",
      "Validation loss improved from 0.2130 to 0.2129. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3153\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2250\n",
      "    Batch [2/2], Val Loss: 0.2004\n",
      "Epoch [275/2000], Avg Train Loss: 0.3153, Avg Val Loss: 0.2127\n",
      "\n",
      "Validation loss improved from 0.2129 to 0.2127. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3161\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2250\n",
      "    Batch [2/2], Val Loss: 0.2002\n",
      "Epoch [276/2000], Avg Train Loss: 0.3161, Avg Val Loss: 0.2126\n",
      "\n",
      "Validation loss improved from 0.2127 to 0.2126. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3138\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2250\n",
      "    Batch [2/2], Val Loss: 0.2000\n",
      "Epoch [277/2000], Avg Train Loss: 0.3138, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2126 to 0.2125. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3123\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2249\n",
      "    Batch [2/2], Val Loss: 0.1999\n",
      "Epoch [278/2000], Avg Train Loss: 0.3123, Avg Val Loss: 0.2124\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2124. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3171\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2247\n",
      "    Batch [2/2], Val Loss: 0.1998\n",
      "Epoch [279/2000], Avg Train Loss: 0.3171, Avg Val Loss: 0.2123\n",
      "\n",
      "Validation loss improved from 0.2124 to 0.2123. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3156\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2246\n",
      "    Batch [2/2], Val Loss: 0.1997\n",
      "Epoch [280/2000], Avg Train Loss: 0.3156, Avg Val Loss: 0.2121\n",
      "\n",
      "Validation loss improved from 0.2123 to 0.2121. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3137\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2244\n",
      "    Batch [2/2], Val Loss: 0.1994\n",
      "Epoch [281/2000], Avg Train Loss: 0.3137, Avg Val Loss: 0.2119\n",
      "\n",
      "Validation loss improved from 0.2121 to 0.2119. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3125\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2243\n",
      "    Batch [2/2], Val Loss: 0.1992\n",
      "Epoch [282/2000], Avg Train Loss: 0.3125, Avg Val Loss: 0.2117\n",
      "\n",
      "Validation loss improved from 0.2119 to 0.2117. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3065\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2241\n",
      "    Batch [2/2], Val Loss: 0.1989\n",
      "Epoch [283/2000], Avg Train Loss: 0.3065, Avg Val Loss: 0.2115\n",
      "\n",
      "Validation loss improved from 0.2117 to 0.2115. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3104\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2239\n",
      "    Batch [2/2], Val Loss: 0.1987\n",
      "Epoch [284/2000], Avg Train Loss: 0.3104, Avg Val Loss: 0.2113\n",
      "\n",
      "Validation loss improved from 0.2115 to 0.2113. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3106\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2237\n",
      "    Batch [2/2], Val Loss: 0.1983\n",
      "Epoch [285/2000], Avg Train Loss: 0.3106, Avg Val Loss: 0.2110\n",
      "\n",
      "Validation loss improved from 0.2113 to 0.2110. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3152\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2236\n",
      "    Batch [2/2], Val Loss: 0.1979\n",
      "Epoch [286/2000], Avg Train Loss: 0.3152, Avg Val Loss: 0.2108\n",
      "\n",
      "Validation loss improved from 0.2110 to 0.2108. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3105\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2234\n",
      "    Batch [2/2], Val Loss: 0.1976\n",
      "Epoch [287/2000], Avg Train Loss: 0.3105, Avg Val Loss: 0.2105\n",
      "\n",
      "Validation loss improved from 0.2108 to 0.2105. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3112\n",
      "LOG: Epoch [288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2231\n",
      "    Batch [2/2], Val Loss: 0.1972\n",
      "Epoch [288/2000], Avg Train Loss: 0.3112, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2105 to 0.2102. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3072\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2229\n",
      "    Batch [2/2], Val Loss: 0.1968\n",
      "Epoch [289/2000], Avg Train Loss: 0.3072, Avg Val Loss: 0.2099\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2099. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3099\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2228\n",
      "    Batch [2/2], Val Loss: 0.1965\n",
      "Epoch [290/2000], Avg Train Loss: 0.3099, Avg Val Loss: 0.2096\n",
      "\n",
      "Validation loss improved from 0.2099 to 0.2096. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3105\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2226\n",
      "    Batch [2/2], Val Loss: 0.1961\n",
      "Epoch [291/2000], Avg Train Loss: 0.3105, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2096 to 0.2094. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3107\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2225\n",
      "    Batch [2/2], Val Loss: 0.1958\n",
      "Epoch [292/2000], Avg Train Loss: 0.3107, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2092. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3130\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2224\n",
      "    Batch [2/2], Val Loss: 0.1955\n",
      "Epoch [293/2000], Avg Train Loss: 0.3130, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2089. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3059\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2222\n",
      "    Batch [2/2], Val Loss: 0.1952\n",
      "Epoch [294/2000], Avg Train Loss: 0.3059, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2087. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3096\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2221\n",
      "    Batch [2/2], Val Loss: 0.1949\n",
      "Epoch [295/2000], Avg Train Loss: 0.3096, Avg Val Loss: 0.2085\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2085. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3040\n",
      "LOG: Epoch [296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2221\n",
      "    Batch [2/2], Val Loss: 0.1947\n",
      "Epoch [296/2000], Avg Train Loss: 0.3040, Avg Val Loss: 0.2084\n",
      "\n",
      "Validation loss improved from 0.2085 to 0.2084. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3110\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2219\n",
      "    Batch [2/2], Val Loss: 0.1947\n",
      "Epoch [297/2000], Avg Train Loss: 0.3110, Avg Val Loss: 0.2083\n",
      "\n",
      "Validation loss improved from 0.2084 to 0.2083. Saving model...\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3044\n",
      "LOG: Epoch [298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2218\n",
      "    Batch [2/2], Val Loss: 0.1946\n",
      "Epoch [298/2000], Avg Train Loss: 0.3044, Avg Val Loss: 0.2082\n",
      "\n",
      "Validation loss improved from 0.2083 to 0.2082. Saving model...\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3104\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2216\n",
      "    Batch [2/2], Val Loss: 0.1945\n",
      "Epoch [299/2000], Avg Train Loss: 0.3104, Avg Val Loss: 0.2081\n",
      "\n",
      "Validation loss improved from 0.2082 to 0.2081. Saving model...\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3082\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2215\n",
      "    Batch [2/2], Val Loss: 0.1945\n",
      "Epoch [300/2000], Avg Train Loss: 0.3082, Avg Val Loss: 0.2080\n",
      "\n",
      "Validation loss improved from 0.2081 to 0.2080. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3119\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2214\n",
      "    Batch [2/2], Val Loss: 0.1945\n",
      "Epoch [301/2000], Avg Train Loss: 0.3119, Avg Val Loss: 0.2080\n",
      "\n",
      "Validation loss improved from 0.2080 to 0.2080. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3069\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2213\n",
      "    Batch [2/2], Val Loss: 0.1945\n",
      "Epoch [302/2000], Avg Train Loss: 0.3069, Avg Val Loss: 0.2079\n",
      "\n",
      "Validation loss improved from 0.2080 to 0.2079. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3069\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2211\n",
      "    Batch [2/2], Val Loss: 0.1945\n",
      "Epoch [303/2000], Avg Train Loss: 0.3069, Avg Val Loss: 0.2078\n",
      "\n",
      "Validation loss improved from 0.2079 to 0.2078. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3061\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2210\n",
      "    Batch [2/2], Val Loss: 0.1944\n",
      "Epoch [304/2000], Avg Train Loss: 0.3061, Avg Val Loss: 0.2077\n",
      "\n",
      "Validation loss improved from 0.2078 to 0.2077. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3075\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2209\n",
      "    Batch [2/2], Val Loss: 0.1945\n",
      "Epoch [305/2000], Avg Train Loss: 0.3075, Avg Val Loss: 0.2077\n",
      "\n",
      "Validation loss improved from 0.2077 to 0.2077. Saving model...\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3092\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2207\n",
      "    Batch [2/2], Val Loss: 0.1944\n",
      "Epoch [306/2000], Avg Train Loss: 0.3092, Avg Val Loss: 0.2076\n",
      "\n",
      "Validation loss improved from 0.2077 to 0.2076. Saving model...\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3039\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2206\n",
      "    Batch [2/2], Val Loss: 0.1943\n",
      "Epoch [307/2000], Avg Train Loss: 0.3039, Avg Val Loss: 0.2075\n",
      "\n",
      "Validation loss improved from 0.2076 to 0.2075. Saving model...\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3043\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2205\n",
      "    Batch [2/2], Val Loss: 0.1941\n",
      "Epoch [308/2000], Avg Train Loss: 0.3043, Avg Val Loss: 0.2073\n",
      "\n",
      "Validation loss improved from 0.2075 to 0.2073. Saving model...\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3032\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2204\n",
      "    Batch [2/2], Val Loss: 0.1940\n",
      "Epoch [309/2000], Avg Train Loss: 0.3032, Avg Val Loss: 0.2072\n",
      "\n",
      "Validation loss improved from 0.2073 to 0.2072. Saving model...\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3051\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2203\n",
      "    Batch [2/2], Val Loss: 0.1937\n",
      "Epoch [310/2000], Avg Train Loss: 0.3051, Avg Val Loss: 0.2070\n",
      "\n",
      "Validation loss improved from 0.2072 to 0.2070. Saving model...\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3068\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2202\n",
      "    Batch [2/2], Val Loss: 0.1934\n",
      "Epoch [311/2000], Avg Train Loss: 0.3068, Avg Val Loss: 0.2068\n",
      "\n",
      "Validation loss improved from 0.2070 to 0.2068. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3061\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2202\n",
      "    Batch [2/2], Val Loss: 0.1930\n",
      "Epoch [312/2000], Avg Train Loss: 0.3061, Avg Val Loss: 0.2066\n",
      "\n",
      "Validation loss improved from 0.2068 to 0.2066. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3029\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2201\n",
      "    Batch [2/2], Val Loss: 0.1925\n",
      "Epoch [313/2000], Avg Train Loss: 0.3029, Avg Val Loss: 0.2063\n",
      "\n",
      "Validation loss improved from 0.2066 to 0.2063. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2967\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2201\n",
      "    Batch [2/2], Val Loss: 0.1920\n",
      "Epoch [314/2000], Avg Train Loss: 0.2967, Avg Val Loss: 0.2061\n",
      "\n",
      "Validation loss improved from 0.2063 to 0.2061. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3020\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2202\n",
      "    Batch [2/2], Val Loss: 0.1916\n",
      "Epoch [315/2000], Avg Train Loss: 0.3020, Avg Val Loss: 0.2059\n",
      "\n",
      "Validation loss improved from 0.2061 to 0.2059. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3035\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2202\n",
      "    Batch [2/2], Val Loss: 0.1911\n",
      "Epoch [316/2000], Avg Train Loss: 0.3035, Avg Val Loss: 0.2057\n",
      "\n",
      "Validation loss improved from 0.2059 to 0.2057. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3022\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2203\n",
      "    Batch [2/2], Val Loss: 0.1907\n",
      "Epoch [317/2000], Avg Train Loss: 0.3022, Avg Val Loss: 0.2055\n",
      "\n",
      "Validation loss improved from 0.2057 to 0.2055. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2968\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2202\n",
      "    Batch [2/2], Val Loss: 0.1903\n",
      "Epoch [318/2000], Avg Train Loss: 0.2968, Avg Val Loss: 0.2053\n",
      "\n",
      "Validation loss improved from 0.2055 to 0.2053. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2995\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2202\n",
      "    Batch [2/2], Val Loss: 0.1900\n",
      "Epoch [319/2000], Avg Train Loss: 0.2995, Avg Val Loss: 0.2051\n",
      "\n",
      "Validation loss improved from 0.2053 to 0.2051. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2972\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2201\n",
      "    Batch [2/2], Val Loss: 0.1898\n",
      "Epoch [320/2000], Avg Train Loss: 0.2972, Avg Val Loss: 0.2049\n",
      "\n",
      "Validation loss improved from 0.2051 to 0.2049. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2967\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2201\n",
      "    Batch [2/2], Val Loss: 0.1896\n",
      "Epoch [321/2000], Avg Train Loss: 0.2967, Avg Val Loss: 0.2049\n",
      "\n",
      "Validation loss improved from 0.2049 to 0.2049. Saving model...\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2993\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2200\n",
      "    Batch [2/2], Val Loss: 0.1896\n",
      "Epoch [322/2000], Avg Train Loss: 0.2993, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2049 to 0.2048. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2941\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2199\n",
      "    Batch [2/2], Val Loss: 0.1896\n",
      "Epoch [323/2000], Avg Train Loss: 0.2941, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2047. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3052\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2198\n",
      "    Batch [2/2], Val Loss: 0.1895\n",
      "Epoch [324/2000], Avg Train Loss: 0.3052, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2996\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2197\n",
      "    Batch [2/2], Val Loss: 0.1896\n",
      "Epoch [325/2000], Avg Train Loss: 0.2996, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2046. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2932\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2196\n",
      "    Batch [2/2], Val Loss: 0.1895\n",
      "Epoch [326/2000], Avg Train Loss: 0.2932, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3033\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2195\n",
      "    Batch [2/2], Val Loss: 0.1895\n",
      "Epoch [327/2000], Avg Train Loss: 0.3033, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2045. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2984\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2193\n",
      "    Batch [2/2], Val Loss: 0.1895\n",
      "Epoch [328/2000], Avg Train Loss: 0.2984, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2044. Saving model...\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2929\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2193\n",
      "    Batch [2/2], Val Loss: 0.1895\n",
      "Epoch [329/2000], Avg Train Loss: 0.2929, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3022\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2192\n",
      "    Batch [2/2], Val Loss: 0.1894\n",
      "Epoch [330/2000], Avg Train Loss: 0.3022, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2043. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2960\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2192\n",
      "    Batch [2/2], Val Loss: 0.1894\n",
      "Epoch [331/2000], Avg Train Loss: 0.2960, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2997\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2192\n",
      "    Batch [2/2], Val Loss: 0.1894\n",
      "Epoch [332/2000], Avg Train Loss: 0.2997, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2943\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2192\n",
      "    Batch [2/2], Val Loss: 0.1893\n",
      "Epoch [333/2000], Avg Train Loss: 0.2943, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2927\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2192\n",
      "    Batch [2/2], Val Loss: 0.1893\n",
      "Epoch [334/2000], Avg Train Loss: 0.2927, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3002\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2191\n",
      "    Batch [2/2], Val Loss: 0.1893\n",
      "Epoch [335/2000], Avg Train Loss: 0.3002, Avg Val Loss: 0.2042\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2042. Saving model...\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2945\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2191\n",
      "    Batch [2/2], Val Loss: 0.1893\n",
      "Epoch [336/2000], Avg Train Loss: 0.2945, Avg Val Loss: 0.2042\n",
      "\n",
      "Validation loss improved from 0.2042 to 0.2042. Saving model...\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2932\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2190\n",
      "    Batch [2/2], Val Loss: 0.1892\n",
      "Epoch [337/2000], Avg Train Loss: 0.2932, Avg Val Loss: 0.2041\n",
      "\n",
      "Validation loss improved from 0.2042 to 0.2041. Saving model...\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2965\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2189\n",
      "    Batch [2/2], Val Loss: 0.1890\n",
      "Epoch [338/2000], Avg Train Loss: 0.2965, Avg Val Loss: 0.2040\n",
      "\n",
      "Validation loss improved from 0.2041 to 0.2040. Saving model...\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2898\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2189\n",
      "    Batch [2/2], Val Loss: 0.1888\n",
      "Epoch [339/2000], Avg Train Loss: 0.2898, Avg Val Loss: 0.2038\n",
      "\n",
      "Validation loss improved from 0.2040 to 0.2038. Saving model...\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2989\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2189\n",
      "    Batch [2/2], Val Loss: 0.1886\n",
      "Epoch [340/2000], Avg Train Loss: 0.2989, Avg Val Loss: 0.2037\n",
      "\n",
      "Validation loss improved from 0.2038 to 0.2037. Saving model...\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2888\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2188\n",
      "    Batch [2/2], Val Loss: 0.1885\n",
      "Epoch [341/2000], Avg Train Loss: 0.2888, Avg Val Loss: 0.2037\n",
      "\n",
      "Validation loss improved from 0.2037 to 0.2037. Saving model...\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2917\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2188\n",
      "    Batch [2/2], Val Loss: 0.1883\n",
      "Epoch [342/2000], Avg Train Loss: 0.2917, Avg Val Loss: 0.2035\n",
      "\n",
      "Validation loss improved from 0.2037 to 0.2035. Saving model...\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2914\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2188\n",
      "    Batch [2/2], Val Loss: 0.1881\n",
      "Epoch [343/2000], Avg Train Loss: 0.2914, Avg Val Loss: 0.2035\n",
      "\n",
      "Validation loss improved from 0.2035 to 0.2035. Saving model...\n",
      "LOG: Epoch [344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2932\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2187\n",
      "    Batch [2/2], Val Loss: 0.1880\n",
      "Epoch [344/2000], Avg Train Loss: 0.2932, Avg Val Loss: 0.2034\n",
      "\n",
      "Validation loss improved from 0.2035 to 0.2034. Saving model...\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2969\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2187\n",
      "    Batch [2/2], Val Loss: 0.1879\n",
      "Epoch [345/2000], Avg Train Loss: 0.2969, Avg Val Loss: 0.2033\n",
      "\n",
      "Validation loss improved from 0.2034 to 0.2033. Saving model...\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2939\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2187\n",
      "    Batch [2/2], Val Loss: 0.1879\n",
      "Epoch [346/2000], Avg Train Loss: 0.2939, Avg Val Loss: 0.2033\n",
      "\n",
      "Validation loss improved from 0.2033 to 0.2033. Saving model...\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2929\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2186\n",
      "    Batch [2/2], Val Loss: 0.1878\n",
      "Epoch [347/2000], Avg Train Loss: 0.2929, Avg Val Loss: 0.2032\n",
      "\n",
      "Validation loss improved from 0.2033 to 0.2032. Saving model...\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2953\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2186\n",
      "    Batch [2/2], Val Loss: 0.1876\n",
      "Epoch [348/2000], Avg Train Loss: 0.2953, Avg Val Loss: 0.2031\n",
      "\n",
      "Validation loss improved from 0.2032 to 0.2031. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2896\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2185\n",
      "    Batch [2/2], Val Loss: 0.1875\n",
      "Epoch [349/2000], Avg Train Loss: 0.2896, Avg Val Loss: 0.2030\n",
      "\n",
      "Validation loss improved from 0.2031 to 0.2030. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2887\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2184\n",
      "    Batch [2/2], Val Loss: 0.1873\n",
      "Epoch [350/2000], Avg Train Loss: 0.2887, Avg Val Loss: 0.2029\n",
      "\n",
      "Validation loss improved from 0.2030 to 0.2029. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2938\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2183\n",
      "    Batch [2/2], Val Loss: 0.1872\n",
      "Epoch [351/2000], Avg Train Loss: 0.2938, Avg Val Loss: 0.2027\n",
      "\n",
      "Validation loss improved from 0.2029 to 0.2027. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2926\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2181\n",
      "    Batch [2/2], Val Loss: 0.1870\n",
      "Epoch [352/2000], Avg Train Loss: 0.2926, Avg Val Loss: 0.2026\n",
      "\n",
      "Validation loss improved from 0.2027 to 0.2026. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2873\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2180\n",
      "    Batch [2/2], Val Loss: 0.1868\n",
      "Epoch [353/2000], Avg Train Loss: 0.2873, Avg Val Loss: 0.2024\n",
      "\n",
      "Validation loss improved from 0.2026 to 0.2024. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2894\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2179\n",
      "    Batch [2/2], Val Loss: 0.1867\n",
      "Epoch [354/2000], Avg Train Loss: 0.2894, Avg Val Loss: 0.2023\n",
      "\n",
      "Validation loss improved from 0.2024 to 0.2023. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2877\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2177\n",
      "    Batch [2/2], Val Loss: 0.1864\n",
      "Epoch [355/2000], Avg Train Loss: 0.2877, Avg Val Loss: 0.2021\n",
      "\n",
      "Validation loss improved from 0.2023 to 0.2021. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2883\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2175\n",
      "    Batch [2/2], Val Loss: 0.1862\n",
      "Epoch [356/2000], Avg Train Loss: 0.2883, Avg Val Loss: 0.2019\n",
      "\n",
      "Validation loss improved from 0.2021 to 0.2019. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2902\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2174\n",
      "    Batch [2/2], Val Loss: 0.1861\n",
      "Epoch [357/2000], Avg Train Loss: 0.2902, Avg Val Loss: 0.2017\n",
      "\n",
      "Validation loss improved from 0.2019 to 0.2017. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2867\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2172\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [358/2000], Avg Train Loss: 0.2867, Avg Val Loss: 0.2016\n",
      "\n",
      "Validation loss improved from 0.2017 to 0.2016. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2913\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2171\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [359/2000], Avg Train Loss: 0.2913, Avg Val Loss: 0.2014\n",
      "\n",
      "Validation loss improved from 0.2016 to 0.2014. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2878\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2169\n",
      "    Batch [2/2], Val Loss: 0.1856\n",
      "Epoch [360/2000], Avg Train Loss: 0.2878, Avg Val Loss: 0.2013\n",
      "\n",
      "Validation loss improved from 0.2014 to 0.2013. Saving model...\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2893\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2167\n",
      "    Batch [2/2], Val Loss: 0.1853\n",
      "Epoch [361/2000], Avg Train Loss: 0.2893, Avg Val Loss: 0.2010\n",
      "\n",
      "Validation loss improved from 0.2013 to 0.2010. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2914\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2165\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [362/2000], Avg Train Loss: 0.2914, Avg Val Loss: 0.2007\n",
      "\n",
      "Validation loss improved from 0.2010 to 0.2007. Saving model...\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2865\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2163\n",
      "    Batch [2/2], Val Loss: 0.1846\n",
      "Epoch [363/2000], Avg Train Loss: 0.2865, Avg Val Loss: 0.2005\n",
      "\n",
      "Validation loss improved from 0.2007 to 0.2005. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2910\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2162\n",
      "    Batch [2/2], Val Loss: 0.1842\n",
      "Epoch [364/2000], Avg Train Loss: 0.2910, Avg Val Loss: 0.2002\n",
      "\n",
      "Validation loss improved from 0.2005 to 0.2002. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2866\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2160\n",
      "    Batch [2/2], Val Loss: 0.1839\n",
      "Epoch [365/2000], Avg Train Loss: 0.2866, Avg Val Loss: 0.2000\n",
      "\n",
      "Validation loss improved from 0.2002 to 0.2000. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2872\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2159\n",
      "    Batch [2/2], Val Loss: 0.1835\n",
      "Epoch [366/2000], Avg Train Loss: 0.2872, Avg Val Loss: 0.1997\n",
      "\n",
      "Validation loss improved from 0.2000 to 0.1997. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2158\n",
      "    Batch [2/2], Val Loss: 0.1832\n",
      "Epoch [367/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.1995\n",
      "\n",
      "Validation loss improved from 0.1997 to 0.1995. Saving model...\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2915\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2158\n",
      "    Batch [2/2], Val Loss: 0.1828\n",
      "Epoch [368/2000], Avg Train Loss: 0.2915, Avg Val Loss: 0.1993\n",
      "\n",
      "Validation loss improved from 0.1995 to 0.1993. Saving model...\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2872\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2156\n",
      "    Batch [2/2], Val Loss: 0.1825\n",
      "Epoch [369/2000], Avg Train Loss: 0.2872, Avg Val Loss: 0.1991\n",
      "\n",
      "Validation loss improved from 0.1993 to 0.1991. Saving model...\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2155\n",
      "    Batch [2/2], Val Loss: 0.1822\n",
      "Epoch [370/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.1988\n",
      "\n",
      "Validation loss improved from 0.1991 to 0.1988. Saving model...\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2860\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2154\n",
      "    Batch [2/2], Val Loss: 0.1818\n",
      "Epoch [371/2000], Avg Train Loss: 0.2860, Avg Val Loss: 0.1986\n",
      "\n",
      "Validation loss improved from 0.1988 to 0.1986. Saving model...\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2154\n",
      "    Batch [2/2], Val Loss: 0.1816\n",
      "Epoch [372/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.1985\n",
      "\n",
      "Validation loss improved from 0.1986 to 0.1985. Saving model...\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2153\n",
      "    Batch [2/2], Val Loss: 0.1814\n",
      "Epoch [373/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.1983\n",
      "\n",
      "Validation loss improved from 0.1985 to 0.1983. Saving model...\n",
      "LOG: Epoch [374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2152\n",
      "    Batch [2/2], Val Loss: 0.1813\n",
      "Epoch [374/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.1982\n",
      "\n",
      "Validation loss improved from 0.1983 to 0.1982. Saving model...\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2151\n",
      "    Batch [2/2], Val Loss: 0.1812\n",
      "Epoch [375/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.1981\n",
      "\n",
      "Validation loss improved from 0.1982 to 0.1981. Saving model...\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2149\n",
      "    Batch [2/2], Val Loss: 0.1812\n",
      "Epoch [376/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.1981\n",
      "\n",
      "Validation loss improved from 0.1981 to 0.1981. Saving model...\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2147\n",
      "    Batch [2/2], Val Loss: 0.1812\n",
      "Epoch [377/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.1980\n",
      "\n",
      "Validation loss improved from 0.1981 to 0.1980. Saving model...\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2879\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2146\n",
      "    Batch [2/2], Val Loss: 0.1812\n",
      "Epoch [378/2000], Avg Train Loss: 0.2879, Avg Val Loss: 0.1979\n",
      "\n",
      "Validation loss improved from 0.1980 to 0.1979. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2872\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2144\n",
      "    Batch [2/2], Val Loss: 0.1811\n",
      "Epoch [379/2000], Avg Train Loss: 0.2872, Avg Val Loss: 0.1977\n",
      "\n",
      "Validation loss improved from 0.1979 to 0.1977. Saving model...\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2856\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2143\n",
      "    Batch [2/2], Val Loss: 0.1810\n",
      "Epoch [380/2000], Avg Train Loss: 0.2856, Avg Val Loss: 0.1977\n",
      "\n",
      "Validation loss improved from 0.1977 to 0.1977. Saving model...\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2846\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2142\n",
      "    Batch [2/2], Val Loss: 0.1809\n",
      "Epoch [381/2000], Avg Train Loss: 0.2846, Avg Val Loss: 0.1976\n",
      "\n",
      "Validation loss improved from 0.1977 to 0.1976. Saving model...\n",
      "LOG: Epoch [382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2141\n",
      "    Batch [2/2], Val Loss: 0.1808\n",
      "Epoch [382/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.1974\n",
      "\n",
      "Validation loss improved from 0.1976 to 0.1974. Saving model...\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1807\n",
      "Epoch [383/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.1974\n",
      "\n",
      "Validation loss improved from 0.1974 to 0.1974. Saving model...\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1805\n",
      "Epoch [384/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.1973\n",
      "\n",
      "Validation loss improved from 0.1974 to 0.1973. Saving model...\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1804\n",
      "Epoch [385/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.1972\n",
      "\n",
      "Validation loss improved from 0.1973 to 0.1972. Saving model...\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1805\n",
      "Epoch [386/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.1972\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1805\n",
      "Epoch [387/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.1972\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2872\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1805\n",
      "Epoch [388/2000], Avg Train Loss: 0.2872, Avg Val Loss: 0.1972\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1804\n",
      "Epoch [389/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.1972\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1803\n",
      "Epoch [390/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.1971\n",
      "\n",
      "Validation loss improved from 0.1972 to 0.1971. Saving model...\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1802\n",
      "Epoch [391/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.1971\n",
      "\n",
      "Validation loss improved from 0.1971 to 0.1971. Saving model...\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [392/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.1971\n",
      "\n",
      "Validation loss improved from 0.1971 to 0.1971. Saving model...\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [393/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.1970\n",
      "\n",
      "Validation loss improved from 0.1971 to 0.1970. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [394/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.1971\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2141\n",
      "    Batch [2/2], Val Loss: 0.1799\n",
      "Epoch [395/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.1970\n",
      "\n",
      "Validation loss improved from 0.1970 to 0.1970. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2141\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [396/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.1969\n",
      "\n",
      "Validation loss improved from 0.1970 to 0.1969. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2141\n",
      "    Batch [2/2], Val Loss: 0.1796\n",
      "Epoch [397/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.1969\n",
      "\n",
      "Validation loss improved from 0.1969 to 0.1969. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2142\n",
      "    Batch [2/2], Val Loss: 0.1794\n",
      "Epoch [398/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.1968\n",
      "\n",
      "Validation loss improved from 0.1969 to 0.1968. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2142\n",
      "    Batch [2/2], Val Loss: 0.1792\n",
      "Epoch [399/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.1967\n",
      "\n",
      "Validation loss improved from 0.1968 to 0.1967. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2142\n",
      "    Batch [2/2], Val Loss: 0.1791\n",
      "Epoch [400/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.1966\n",
      "\n",
      "Validation loss improved from 0.1967 to 0.1966. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2141\n",
      "    Batch [2/2], Val Loss: 0.1790\n",
      "Epoch [401/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.1965\n",
      "\n",
      "Validation loss improved from 0.1966 to 0.1965. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2140\n",
      "    Batch [2/2], Val Loss: 0.1789\n",
      "Epoch [402/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.1964\n",
      "\n",
      "Validation loss improved from 0.1965 to 0.1964. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2138\n",
      "    Batch [2/2], Val Loss: 0.1787\n",
      "Epoch [403/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.1963\n",
      "\n",
      "Validation loss improved from 0.1964 to 0.1963. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2728\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2136\n",
      "    Batch [2/2], Val Loss: 0.1786\n",
      "Epoch [404/2000], Avg Train Loss: 0.2728, Avg Val Loss: 0.1961\n",
      "\n",
      "Validation loss improved from 0.1963 to 0.1961. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2133\n",
      "    Batch [2/2], Val Loss: 0.1785\n",
      "Epoch [405/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.1959\n",
      "\n",
      "Validation loss improved from 0.1961 to 0.1959. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2131\n",
      "    Batch [2/2], Val Loss: 0.1783\n",
      "Epoch [406/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.1957\n",
      "\n",
      "Validation loss improved from 0.1959 to 0.1957. Saving model...\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2738\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2129\n",
      "    Batch [2/2], Val Loss: 0.1782\n",
      "Epoch [407/2000], Avg Train Loss: 0.2738, Avg Val Loss: 0.1955\n",
      "\n",
      "Validation loss improved from 0.1957 to 0.1955. Saving model...\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2127\n",
      "    Batch [2/2], Val Loss: 0.1781\n",
      "Epoch [408/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.1954\n",
      "\n",
      "Validation loss improved from 0.1955 to 0.1954. Saving model...\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2124\n",
      "    Batch [2/2], Val Loss: 0.1780\n",
      "Epoch [409/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.1952\n",
      "\n",
      "Validation loss improved from 0.1954 to 0.1952. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2122\n",
      "    Batch [2/2], Val Loss: 0.1778\n",
      "Epoch [410/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.1950\n",
      "\n",
      "Validation loss improved from 0.1952 to 0.1950. Saving model...\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2730\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2121\n",
      "    Batch [2/2], Val Loss: 0.1776\n",
      "Epoch [411/2000], Avg Train Loss: 0.2730, Avg Val Loss: 0.1948\n",
      "\n",
      "Validation loss improved from 0.1950 to 0.1948. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2718\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2119\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [412/2000], Avg Train Loss: 0.2718, Avg Val Loss: 0.1946\n",
      "\n",
      "Validation loss improved from 0.1948 to 0.1946. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2117\n",
      "    Batch [2/2], Val Loss: 0.1770\n",
      "Epoch [413/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.1944\n",
      "\n",
      "Validation loss improved from 0.1946 to 0.1944. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2684\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2115\n",
      "    Batch [2/2], Val Loss: 0.1767\n",
      "Epoch [414/2000], Avg Train Loss: 0.2684, Avg Val Loss: 0.1941\n",
      "\n",
      "Validation loss improved from 0.1944 to 0.1941. Saving model...\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2711\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2114\n",
      "    Batch [2/2], Val Loss: 0.1765\n",
      "Epoch [415/2000], Avg Train Loss: 0.2711, Avg Val Loss: 0.1939\n",
      "\n",
      "Validation loss improved from 0.1941 to 0.1939. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2697\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2113\n",
      "    Batch [2/2], Val Loss: 0.1761\n",
      "Epoch [416/2000], Avg Train Loss: 0.2697, Avg Val Loss: 0.1937\n",
      "\n",
      "Validation loss improved from 0.1939 to 0.1937. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2697\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2112\n",
      "    Batch [2/2], Val Loss: 0.1758\n",
      "Epoch [417/2000], Avg Train Loss: 0.2697, Avg Val Loss: 0.1935\n",
      "\n",
      "Validation loss improved from 0.1937 to 0.1935. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2713\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2112\n",
      "    Batch [2/2], Val Loss: 0.1755\n",
      "Epoch [418/2000], Avg Train Loss: 0.2713, Avg Val Loss: 0.1933\n",
      "\n",
      "Validation loss improved from 0.1935 to 0.1933. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2753\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2112\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [419/2000], Avg Train Loss: 0.2753, Avg Val Loss: 0.1932\n",
      "\n",
      "Validation loss improved from 0.1933 to 0.1932. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2712\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2112\n",
      "    Batch [2/2], Val Loss: 0.1751\n",
      "Epoch [420/2000], Avg Train Loss: 0.2712, Avg Val Loss: 0.1932\n",
      "\n",
      "Validation loss improved from 0.1932 to 0.1932. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2682\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2112\n",
      "    Batch [2/2], Val Loss: 0.1749\n",
      "Epoch [421/2000], Avg Train Loss: 0.2682, Avg Val Loss: 0.1930\n",
      "\n",
      "Validation loss improved from 0.1932 to 0.1930. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2731\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2111\n",
      "    Batch [2/2], Val Loss: 0.1747\n",
      "Epoch [422/2000], Avg Train Loss: 0.2731, Avg Val Loss: 0.1929\n",
      "\n",
      "Validation loss improved from 0.1930 to 0.1929. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2647\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2111\n",
      "    Batch [2/2], Val Loss: 0.1747\n",
      "Epoch [423/2000], Avg Train Loss: 0.2647, Avg Val Loss: 0.1929\n",
      "\n",
      "Validation loss improved from 0.1929 to 0.1929. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2724\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2110\n",
      "    Batch [2/2], Val Loss: 0.1746\n",
      "Epoch [424/2000], Avg Train Loss: 0.2724, Avg Val Loss: 0.1928\n",
      "\n",
      "Validation loss improved from 0.1929 to 0.1928. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2709\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2110\n",
      "    Batch [2/2], Val Loss: 0.1746\n",
      "Epoch [425/2000], Avg Train Loss: 0.2709, Avg Val Loss: 0.1928\n",
      "\n",
      "Validation loss improved from 0.1928 to 0.1928. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2716\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2110\n",
      "    Batch [2/2], Val Loss: 0.1747\n",
      "Epoch [426/2000], Avg Train Loss: 0.2716, Avg Val Loss: 0.1928\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2675\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2109\n",
      "    Batch [2/2], Val Loss: 0.1748\n",
      "Epoch [427/2000], Avg Train Loss: 0.2675, Avg Val Loss: 0.1929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2654\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2108\n",
      "    Batch [2/2], Val Loss: 0.1750\n",
      "Epoch [428/2000], Avg Train Loss: 0.2654, Avg Val Loss: 0.1929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2685\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2108\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [429/2000], Avg Train Loss: 0.2685, Avg Val Loss: 0.1930\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2720\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2107\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [430/2000], Avg Train Loss: 0.2720, Avg Val Loss: 0.1930\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2694\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2106\n",
      "    Batch [2/2], Val Loss: 0.1754\n",
      "Epoch [431/2000], Avg Train Loss: 0.2694, Avg Val Loss: 0.1930\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2698\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2105\n",
      "    Batch [2/2], Val Loss: 0.1754\n",
      "Epoch [432/2000], Avg Train Loss: 0.2698, Avg Val Loss: 0.1929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2675\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2104\n",
      "    Batch [2/2], Val Loss: 0.1754\n",
      "Epoch [433/2000], Avg Train Loss: 0.2675, Avg Val Loss: 0.1929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2652\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2103\n",
      "    Batch [2/2], Val Loss: 0.1754\n",
      "Epoch [434/2000], Avg Train Loss: 0.2652, Avg Val Loss: 0.1928\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2697\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2101\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [435/2000], Avg Train Loss: 0.2697, Avg Val Loss: 0.1927\n",
      "\n",
      "Validation loss improved from 0.1928 to 0.1927. Saving model...\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2675\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2099\n",
      "    Batch [2/2], Val Loss: 0.1751\n",
      "Epoch [436/2000], Avg Train Loss: 0.2675, Avg Val Loss: 0.1925\n",
      "\n",
      "Validation loss improved from 0.1927 to 0.1925. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2653\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2097\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [437/2000], Avg Train Loss: 0.2653, Avg Val Loss: 0.1925\n",
      "\n",
      "Validation loss improved from 0.1925 to 0.1925. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2700\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2095\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [438/2000], Avg Train Loss: 0.2700, Avg Val Loss: 0.1924\n",
      "\n",
      "Validation loss improved from 0.1925 to 0.1924. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2715\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2093\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [439/2000], Avg Train Loss: 0.2715, Avg Val Loss: 0.1922\n",
      "\n",
      "Validation loss improved from 0.1924 to 0.1922. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2696\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2090\n",
      "    Batch [2/2], Val Loss: 0.1750\n",
      "Epoch [440/2000], Avg Train Loss: 0.2696, Avg Val Loss: 0.1920\n",
      "\n",
      "Validation loss improved from 0.1922 to 0.1920. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2668\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2088\n",
      "    Batch [2/2], Val Loss: 0.1748\n",
      "Epoch [441/2000], Avg Train Loss: 0.2668, Avg Val Loss: 0.1918\n",
      "\n",
      "Validation loss improved from 0.1920 to 0.1918. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2616\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2085\n",
      "    Batch [2/2], Val Loss: 0.1745\n",
      "Epoch [442/2000], Avg Train Loss: 0.2616, Avg Val Loss: 0.1915\n",
      "\n",
      "Validation loss improved from 0.1918 to 0.1915. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2694\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2083\n",
      "    Batch [2/2], Val Loss: 0.1742\n",
      "Epoch [443/2000], Avg Train Loss: 0.2694, Avg Val Loss: 0.1913\n",
      "\n",
      "Validation loss improved from 0.1915 to 0.1913. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2686\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2081\n",
      "    Batch [2/2], Val Loss: 0.1740\n",
      "Epoch [444/2000], Avg Train Loss: 0.2686, Avg Val Loss: 0.1910\n",
      "\n",
      "Validation loss improved from 0.1913 to 0.1910. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2664\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2079\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [445/2000], Avg Train Loss: 0.2664, Avg Val Loss: 0.1908\n",
      "\n",
      "Validation loss improved from 0.1910 to 0.1908. Saving model...\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2673\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2078\n",
      "    Batch [2/2], Val Loss: 0.1732\n",
      "Epoch [446/2000], Avg Train Loss: 0.2673, Avg Val Loss: 0.1905\n",
      "\n",
      "Validation loss improved from 0.1908 to 0.1905. Saving model...\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2675\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2076\n",
      "    Batch [2/2], Val Loss: 0.1728\n",
      "Epoch [447/2000], Avg Train Loss: 0.2675, Avg Val Loss: 0.1902\n",
      "\n",
      "Validation loss improved from 0.1905 to 0.1902. Saving model...\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2657\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2075\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [448/2000], Avg Train Loss: 0.2657, Avg Val Loss: 0.1899\n",
      "\n",
      "Validation loss improved from 0.1902 to 0.1899. Saving model...\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2635\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2074\n",
      "    Batch [2/2], Val Loss: 0.1718\n",
      "Epoch [449/2000], Avg Train Loss: 0.2635, Avg Val Loss: 0.1896\n",
      "\n",
      "Validation loss improved from 0.1899 to 0.1896. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2622\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2073\n",
      "    Batch [2/2], Val Loss: 0.1714\n",
      "Epoch [450/2000], Avg Train Loss: 0.2622, Avg Val Loss: 0.1893\n",
      "\n",
      "Validation loss improved from 0.1896 to 0.1893. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2646\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2072\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [451/2000], Avg Train Loss: 0.2646, Avg Val Loss: 0.1891\n",
      "\n",
      "Validation loss improved from 0.1893 to 0.1891. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2666\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2072\n",
      "    Batch [2/2], Val Loss: 0.1707\n",
      "Epoch [452/2000], Avg Train Loss: 0.2666, Avg Val Loss: 0.1890\n",
      "\n",
      "Validation loss improved from 0.1891 to 0.1890. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2665\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2071\n",
      "    Batch [2/2], Val Loss: 0.1704\n",
      "Epoch [453/2000], Avg Train Loss: 0.2665, Avg Val Loss: 0.1888\n",
      "\n",
      "Validation loss improved from 0.1890 to 0.1888. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2677\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2071\n",
      "    Batch [2/2], Val Loss: 0.1702\n",
      "Epoch [454/2000], Avg Train Loss: 0.2677, Avg Val Loss: 0.1887\n",
      "\n",
      "Validation loss improved from 0.1888 to 0.1887. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2637\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2072\n",
      "    Batch [2/2], Val Loss: 0.1700\n",
      "Epoch [455/2000], Avg Train Loss: 0.2637, Avg Val Loss: 0.1886\n",
      "\n",
      "Validation loss improved from 0.1887 to 0.1886. Saving model...\n",
      "LOG: Epoch [456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2663\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2073\n",
      "    Batch [2/2], Val Loss: 0.1697\n",
      "Epoch [456/2000], Avg Train Loss: 0.2663, Avg Val Loss: 0.1885\n",
      "\n",
      "Validation loss improved from 0.1886 to 0.1885. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2603\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2074\n",
      "    Batch [2/2], Val Loss: 0.1695\n",
      "Epoch [457/2000], Avg Train Loss: 0.2603, Avg Val Loss: 0.1885\n",
      "\n",
      "Validation loss improved from 0.1885 to 0.1885. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2606\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2074\n",
      "    Batch [2/2], Val Loss: 0.1694\n",
      "Epoch [458/2000], Avg Train Loss: 0.2606, Avg Val Loss: 0.1884\n",
      "\n",
      "Validation loss improved from 0.1885 to 0.1884. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2631\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2074\n",
      "    Batch [2/2], Val Loss: 0.1693\n",
      "Epoch [459/2000], Avg Train Loss: 0.2631, Avg Val Loss: 0.1884\n",
      "\n",
      "Validation loss improved from 0.1884 to 0.1884. Saving model...\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2596\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2073\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [460/2000], Avg Train Loss: 0.2596, Avg Val Loss: 0.1883\n",
      "\n",
      "Validation loss improved from 0.1884 to 0.1883. Saving model...\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2608\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2073\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [461/2000], Avg Train Loss: 0.2608, Avg Val Loss: 0.1882\n",
      "\n",
      "Validation loss improved from 0.1883 to 0.1882. Saving model...\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2614\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2072\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [462/2000], Avg Train Loss: 0.2614, Avg Val Loss: 0.1882\n",
      "\n",
      "Validation loss improved from 0.1882 to 0.1882. Saving model...\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2660\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2071\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [463/2000], Avg Train Loss: 0.2660, Avg Val Loss: 0.1882\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2619\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2070\n",
      "    Batch [2/2], Val Loss: 0.1694\n",
      "Epoch [464/2000], Avg Train Loss: 0.2619, Avg Val Loss: 0.1882\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2599\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2069\n",
      "    Batch [2/2], Val Loss: 0.1696\n",
      "Epoch [465/2000], Avg Train Loss: 0.2599, Avg Val Loss: 0.1882\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2660\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2068\n",
      "    Batch [2/2], Val Loss: 0.1698\n",
      "Epoch [466/2000], Avg Train Loss: 0.2660, Avg Val Loss: 0.1883\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2620\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2067\n",
      "    Batch [2/2], Val Loss: 0.1700\n",
      "Epoch [467/2000], Avg Train Loss: 0.2620, Avg Val Loss: 0.1884\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2633\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2066\n",
      "    Batch [2/2], Val Loss: 0.1700\n",
      "Epoch [468/2000], Avg Train Loss: 0.2633, Avg Val Loss: 0.1883\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2605\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2064\n",
      "    Batch [2/2], Val Loss: 0.1699\n",
      "Epoch [469/2000], Avg Train Loss: 0.2605, Avg Val Loss: 0.1882\n",
      "\n",
      "Validation loss improved from 0.1882 to 0.1882. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2607\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2062\n",
      "    Batch [2/2], Val Loss: 0.1698\n",
      "Epoch [470/2000], Avg Train Loss: 0.2607, Avg Val Loss: 0.1880\n",
      "\n",
      "Validation loss improved from 0.1882 to 0.1880. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2531\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2061\n",
      "    Batch [2/2], Val Loss: 0.1698\n",
      "Epoch [471/2000], Avg Train Loss: 0.2531, Avg Val Loss: 0.1879\n",
      "\n",
      "Validation loss improved from 0.1880 to 0.1879. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2570\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2059\n",
      "    Batch [2/2], Val Loss: 0.1697\n",
      "Epoch [472/2000], Avg Train Loss: 0.2570, Avg Val Loss: 0.1878\n",
      "\n",
      "Validation loss improved from 0.1879 to 0.1878. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2578\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2057\n",
      "    Batch [2/2], Val Loss: 0.1694\n",
      "Epoch [473/2000], Avg Train Loss: 0.2578, Avg Val Loss: 0.1876\n",
      "\n",
      "Validation loss improved from 0.1878 to 0.1876. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2579\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2055\n",
      "    Batch [2/2], Val Loss: 0.1693\n",
      "Epoch [474/2000], Avg Train Loss: 0.2579, Avg Val Loss: 0.1874\n",
      "\n",
      "Validation loss improved from 0.1876 to 0.1874. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2628\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2054\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [475/2000], Avg Train Loss: 0.2628, Avg Val Loss: 0.1873\n",
      "\n",
      "Validation loss improved from 0.1874 to 0.1873. Saving model...\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2644\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2052\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [476/2000], Avg Train Loss: 0.2644, Avg Val Loss: 0.1872\n",
      "\n",
      "Validation loss improved from 0.1873 to 0.1872. Saving model...\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2580\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2051\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [477/2000], Avg Train Loss: 0.2580, Avg Val Loss: 0.1871\n",
      "\n",
      "Validation loss improved from 0.1872 to 0.1871. Saving model...\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2554\n",
      "LOG: Epoch [478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2050\n",
      "    Batch [2/2], Val Loss: 0.1688\n",
      "Epoch [478/2000], Avg Train Loss: 0.2554, Avg Val Loss: 0.1869\n",
      "\n",
      "Validation loss improved from 0.1871 to 0.1869. Saving model...\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2569\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2050\n",
      "    Batch [2/2], Val Loss: 0.1685\n",
      "Epoch [479/2000], Avg Train Loss: 0.2569, Avg Val Loss: 0.1868\n",
      "\n",
      "Validation loss improved from 0.1869 to 0.1868. Saving model...\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2541\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2049\n",
      "    Batch [2/2], Val Loss: 0.1683\n",
      "Epoch [480/2000], Avg Train Loss: 0.2541, Avg Val Loss: 0.1866\n",
      "\n",
      "Validation loss improved from 0.1868 to 0.1866. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2584\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2049\n",
      "    Batch [2/2], Val Loss: 0.1680\n",
      "Epoch [481/2000], Avg Train Loss: 0.2584, Avg Val Loss: 0.1865\n",
      "\n",
      "Validation loss improved from 0.1866 to 0.1865. Saving model...\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2572\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2049\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [482/2000], Avg Train Loss: 0.2572, Avg Val Loss: 0.1863\n",
      "\n",
      "Validation loss improved from 0.1865 to 0.1863. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2597\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2049\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [483/2000], Avg Train Loss: 0.2597, Avg Val Loss: 0.1864\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2566\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2050\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [484/2000], Avg Train Loss: 0.2566, Avg Val Loss: 0.1864\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2598\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2050\n",
      "    Batch [2/2], Val Loss: 0.1677\n",
      "Epoch [485/2000], Avg Train Loss: 0.2598, Avg Val Loss: 0.1864\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2569\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2051\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [486/2000], Avg Train Loss: 0.2569, Avg Val Loss: 0.1864\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2585\n",
      "LOG: Epoch [487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2052\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [487/2000], Avg Train Loss: 0.2585, Avg Val Loss: 0.1865\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2529\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2052\n",
      "    Batch [2/2], Val Loss: 0.1677\n",
      "Epoch [488/2000], Avg Train Loss: 0.2529, Avg Val Loss: 0.1864\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2529\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2052\n",
      "    Batch [2/2], Val Loss: 0.1676\n",
      "Epoch [489/2000], Avg Train Loss: 0.2529, Avg Val Loss: 0.1864\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2570\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2052\n",
      "    Batch [2/2], Val Loss: 0.1673\n",
      "Epoch [490/2000], Avg Train Loss: 0.2570, Avg Val Loss: 0.1863\n",
      "\n",
      "Validation loss improved from 0.1863 to 0.1863. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2538\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2051\n",
      "    Batch [2/2], Val Loss: 0.1671\n",
      "Epoch [491/2000], Avg Train Loss: 0.2538, Avg Val Loss: 0.1861\n",
      "\n",
      "Validation loss improved from 0.1863 to 0.1861. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2526\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2051\n",
      "    Batch [2/2], Val Loss: 0.1668\n",
      "Epoch [492/2000], Avg Train Loss: 0.2526, Avg Val Loss: 0.1859\n",
      "\n",
      "Validation loss improved from 0.1861 to 0.1859. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2563\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2050\n",
      "    Batch [2/2], Val Loss: 0.1664\n",
      "Epoch [493/2000], Avg Train Loss: 0.2563, Avg Val Loss: 0.1857\n",
      "\n",
      "Validation loss improved from 0.1859 to 0.1857. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2572\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2049\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [494/2000], Avg Train Loss: 0.2572, Avg Val Loss: 0.1855\n",
      "\n",
      "Validation loss improved from 0.1857 to 0.1855. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2555\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2049\n",
      "    Batch [2/2], Val Loss: 0.1659\n",
      "Epoch [495/2000], Avg Train Loss: 0.2555, Avg Val Loss: 0.1854\n",
      "\n",
      "Validation loss improved from 0.1855 to 0.1854. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2576\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2048\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [496/2000], Avg Train Loss: 0.2576, Avg Val Loss: 0.1852\n",
      "\n",
      "Validation loss improved from 0.1854 to 0.1852. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2519\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2046\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [497/2000], Avg Train Loss: 0.2519, Avg Val Loss: 0.1851\n",
      "\n",
      "Validation loss improved from 0.1852 to 0.1851. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2502\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2045\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [498/2000], Avg Train Loss: 0.2502, Avg Val Loss: 0.1851\n",
      "\n",
      "Validation loss improved from 0.1851 to 0.1851. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2510\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2045\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [499/2000], Avg Train Loss: 0.2510, Avg Val Loss: 0.1850\n",
      "\n",
      "Validation loss improved from 0.1851 to 0.1850. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2478\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2044\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [500/2000], Avg Train Loss: 0.2478, Avg Val Loss: 0.1849\n",
      "\n",
      "Validation loss improved from 0.1850 to 0.1849. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2480\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2043\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [501/2000], Avg Train Loss: 0.2480, Avg Val Loss: 0.1849\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2490\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2043\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [502/2000], Avg Train Loss: 0.2490, Avg Val Loss: 0.1849\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2521\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2043\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [503/2000], Avg Train Loss: 0.2521, Avg Val Loss: 0.1850\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2539\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2043\n",
      "    Batch [2/2], Val Loss: 0.1659\n",
      "Epoch [504/2000], Avg Train Loss: 0.2539, Avg Val Loss: 0.1851\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2508\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2043\n",
      "    Batch [2/2], Val Loss: 0.1660\n",
      "Epoch [505/2000], Avg Train Loss: 0.2508, Avg Val Loss: 0.1851\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2481\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2042\n",
      "    Batch [2/2], Val Loss: 0.1662\n",
      "Epoch [506/2000], Avg Train Loss: 0.2481, Avg Val Loss: 0.1852\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2551\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2042\n",
      "    Batch [2/2], Val Loss: 0.1662\n",
      "Epoch [507/2000], Avg Train Loss: 0.2551, Avg Val Loss: 0.1852\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2484\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2042\n",
      "    Batch [2/2], Val Loss: 0.1662\n",
      "Epoch [508/2000], Avg Train Loss: 0.2484, Avg Val Loss: 0.1852\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2510\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2040\n",
      "    Batch [2/2], Val Loss: 0.1662\n",
      "Epoch [509/2000], Avg Train Loss: 0.2510, Avg Val Loss: 0.1851\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2531\n",
      "LOG: Epoch [510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2038\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [510/2000], Avg Train Loss: 0.2531, Avg Val Loss: 0.1849\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2505\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2037\n",
      "    Batch [2/2], Val Loss: 0.1660\n",
      "Epoch [511/2000], Avg Train Loss: 0.2505, Avg Val Loss: 0.1848\n",
      "\n",
      "Validation loss improved from 0.1849 to 0.1848. Saving model...\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2464\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2036\n",
      "    Batch [2/2], Val Loss: 0.1660\n",
      "Epoch [512/2000], Avg Train Loss: 0.2464, Avg Val Loss: 0.1848\n",
      "\n",
      "Validation loss improved from 0.1848 to 0.1848. Saving model...\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2542\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2034\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [513/2000], Avg Train Loss: 0.2542, Avg Val Loss: 0.1847\n",
      "\n",
      "Validation loss improved from 0.1848 to 0.1847. Saving model...\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2486\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2033\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [514/2000], Avg Train Loss: 0.2486, Avg Val Loss: 0.1847\n",
      "\n",
      "Validation loss improved from 0.1847 to 0.1847. Saving model...\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2468\n",
      "LOG: Epoch [515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2031\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [515/2000], Avg Train Loss: 0.2468, Avg Val Loss: 0.1846\n",
      "\n",
      "Validation loss improved from 0.1847 to 0.1846. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2511\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2030\n",
      "    Batch [2/2], Val Loss: 0.1660\n",
      "Epoch [516/2000], Avg Train Loss: 0.2511, Avg Val Loss: 0.1845\n",
      "\n",
      "Validation loss improved from 0.1846 to 0.1845. Saving model...\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2440\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2029\n",
      "    Batch [2/2], Val Loss: 0.1659\n",
      "Epoch [517/2000], Avg Train Loss: 0.2440, Avg Val Loss: 0.1844\n",
      "\n",
      "Validation loss improved from 0.1845 to 0.1844. Saving model...\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2480\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2029\n",
      "    Batch [2/2], Val Loss: 0.1658\n",
      "Epoch [518/2000], Avg Train Loss: 0.2480, Avg Val Loss: 0.1843\n",
      "\n",
      "Validation loss improved from 0.1844 to 0.1843. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2492\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2028\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [519/2000], Avg Train Loss: 0.2492, Avg Val Loss: 0.1842\n",
      "\n",
      "Validation loss improved from 0.1843 to 0.1842. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2491\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2028\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [520/2000], Avg Train Loss: 0.2491, Avg Val Loss: 0.1841\n",
      "\n",
      "Validation loss improved from 0.1842 to 0.1841. Saving model...\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2447\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2027\n",
      "    Batch [2/2], Val Loss: 0.1653\n",
      "Epoch [521/2000], Avg Train Loss: 0.2447, Avg Val Loss: 0.1840\n",
      "\n",
      "Validation loss improved from 0.1841 to 0.1840. Saving model...\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2520\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2027\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [522/2000], Avg Train Loss: 0.2520, Avg Val Loss: 0.1839\n",
      "\n",
      "Validation loss improved from 0.1840 to 0.1839. Saving model...\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2448\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2028\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [523/2000], Avg Train Loss: 0.2448, Avg Val Loss: 0.1840\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2434\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2028\n",
      "    Batch [2/2], Val Loss: 0.1653\n",
      "Epoch [524/2000], Avg Train Loss: 0.2434, Avg Val Loss: 0.1840\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2468\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2027\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [525/2000], Avg Train Loss: 0.2468, Avg Val Loss: 0.1840\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2500\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2027\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [526/2000], Avg Train Loss: 0.2500, Avg Val Loss: 0.1840\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2414\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2026\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [527/2000], Avg Train Loss: 0.2414, Avg Val Loss: 0.1839\n",
      "\n",
      "Validation loss improved from 0.1839 to 0.1839. Saving model...\n",
      "LOG: Epoch [528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2484\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2026\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [528/2000], Avg Train Loss: 0.2484, Avg Val Loss: 0.1838\n",
      "\n",
      "Validation loss improved from 0.1839 to 0.1838. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2446\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2026\n",
      "    Batch [2/2], Val Loss: 0.1650\n",
      "Epoch [529/2000], Avg Train Loss: 0.2446, Avg Val Loss: 0.1838\n",
      "\n",
      "Validation loss improved from 0.1838 to 0.1838. Saving model...\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2506\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2026\n",
      "    Batch [2/2], Val Loss: 0.1649\n",
      "Epoch [530/2000], Avg Train Loss: 0.2506, Avg Val Loss: 0.1837\n",
      "\n",
      "Validation loss improved from 0.1838 to 0.1837. Saving model...\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2454\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2024\n",
      "    Batch [2/2], Val Loss: 0.1647\n",
      "Epoch [531/2000], Avg Train Loss: 0.2454, Avg Val Loss: 0.1836\n",
      "\n",
      "Validation loss improved from 0.1837 to 0.1836. Saving model...\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2457\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2024\n",
      "    Batch [2/2], Val Loss: 0.1646\n",
      "Epoch [532/2000], Avg Train Loss: 0.2457, Avg Val Loss: 0.1835\n",
      "\n",
      "Validation loss improved from 0.1836 to 0.1835. Saving model...\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2473\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2023\n",
      "    Batch [2/2], Val Loss: 0.1646\n",
      "Epoch [533/2000], Avg Train Loss: 0.2473, Avg Val Loss: 0.1834\n",
      "\n",
      "Validation loss improved from 0.1835 to 0.1834. Saving model...\n",
      "LOG: Epoch [534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2382\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2022\n",
      "    Batch [2/2], Val Loss: 0.1645\n",
      "Epoch [534/2000], Avg Train Loss: 0.2382, Avg Val Loss: 0.1834\n",
      "\n",
      "Validation loss improved from 0.1834 to 0.1834. Saving model...\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2428\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2021\n",
      "    Batch [2/2], Val Loss: 0.1644\n",
      "Epoch [535/2000], Avg Train Loss: 0.2428, Avg Val Loss: 0.1833\n",
      "\n",
      "Validation loss improved from 0.1834 to 0.1833. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2507\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2020\n",
      "    Batch [2/2], Val Loss: 0.1643\n",
      "Epoch [536/2000], Avg Train Loss: 0.2507, Avg Val Loss: 0.1832\n",
      "\n",
      "Validation loss improved from 0.1833 to 0.1832. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2431\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2019\n",
      "    Batch [2/2], Val Loss: 0.1642\n",
      "Epoch [537/2000], Avg Train Loss: 0.2431, Avg Val Loss: 0.1830\n",
      "\n",
      "Validation loss improved from 0.1832 to 0.1830. Saving model...\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2427\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2018\n",
      "    Batch [2/2], Val Loss: 0.1640\n",
      "Epoch [538/2000], Avg Train Loss: 0.2427, Avg Val Loss: 0.1829\n",
      "\n",
      "Validation loss improved from 0.1830 to 0.1829. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2396\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2018\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [539/2000], Avg Train Loss: 0.2396, Avg Val Loss: 0.1827\n",
      "\n",
      "Validation loss improved from 0.1829 to 0.1827. Saving model...\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2457\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2017\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [540/2000], Avg Train Loss: 0.2457, Avg Val Loss: 0.1826\n",
      "\n",
      "Validation loss improved from 0.1827 to 0.1826. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2441\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2017\n",
      "    Batch [2/2], Val Loss: 0.1633\n",
      "Epoch [541/2000], Avg Train Loss: 0.2441, Avg Val Loss: 0.1825\n",
      "\n",
      "Validation loss improved from 0.1826 to 0.1825. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2405\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2017\n",
      "    Batch [2/2], Val Loss: 0.1632\n",
      "Epoch [542/2000], Avg Train Loss: 0.2405, Avg Val Loss: 0.1824\n",
      "\n",
      "Validation loss improved from 0.1825 to 0.1824. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2397\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2016\n",
      "    Batch [2/2], Val Loss: 0.1630\n",
      "Epoch [543/2000], Avg Train Loss: 0.2397, Avg Val Loss: 0.1823\n",
      "\n",
      "Validation loss improved from 0.1824 to 0.1823. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2378\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2015\n",
      "    Batch [2/2], Val Loss: 0.1629\n",
      "Epoch [544/2000], Avg Train Loss: 0.2378, Avg Val Loss: 0.1822\n",
      "\n",
      "Validation loss improved from 0.1823 to 0.1822. Saving model...\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2431\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2013\n",
      "    Batch [2/2], Val Loss: 0.1626\n",
      "Epoch [545/2000], Avg Train Loss: 0.2431, Avg Val Loss: 0.1819\n",
      "\n",
      "Validation loss improved from 0.1822 to 0.1819. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2402\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2011\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [546/2000], Avg Train Loss: 0.2402, Avg Val Loss: 0.1817\n",
      "\n",
      "Validation loss improved from 0.1819 to 0.1817. Saving model...\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2491\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2010\n",
      "    Batch [2/2], Val Loss: 0.1622\n",
      "Epoch [547/2000], Avg Train Loss: 0.2491, Avg Val Loss: 0.1816\n",
      "\n",
      "Validation loss improved from 0.1817 to 0.1816. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2463\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2008\n",
      "    Batch [2/2], Val Loss: 0.1622\n",
      "Epoch [548/2000], Avg Train Loss: 0.2463, Avg Val Loss: 0.1815\n",
      "\n",
      "Validation loss improved from 0.1816 to 0.1815. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2443\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2007\n",
      "    Batch [2/2], Val Loss: 0.1622\n",
      "Epoch [549/2000], Avg Train Loss: 0.2443, Avg Val Loss: 0.1815\n",
      "\n",
      "Validation loss improved from 0.1815 to 0.1815. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2448\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2006\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [550/2000], Avg Train Loss: 0.2448, Avg Val Loss: 0.1815\n",
      "\n",
      "Validation loss improved from 0.1815 to 0.1815. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2450\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2005\n",
      "    Batch [2/2], Val Loss: 0.1624\n",
      "Epoch [551/2000], Avg Train Loss: 0.2450, Avg Val Loss: 0.1814\n",
      "\n",
      "Validation loss improved from 0.1815 to 0.1814. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2400\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2002\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [552/2000], Avg Train Loss: 0.2400, Avg Val Loss: 0.1813\n",
      "\n",
      "Validation loss improved from 0.1814 to 0.1813. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2429\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2001\n",
      "    Batch [2/2], Val Loss: 0.1624\n",
      "Epoch [553/2000], Avg Train Loss: 0.2429, Avg Val Loss: 0.1813\n",
      "\n",
      "Validation loss improved from 0.1813 to 0.1813. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2440\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2000\n",
      "    Batch [2/2], Val Loss: 0.1625\n",
      "Epoch [554/2000], Avg Train Loss: 0.2440, Avg Val Loss: 0.1813\n",
      "\n",
      "Validation loss improved from 0.1813 to 0.1813. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2379\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.2000\n",
      "    Batch [2/2], Val Loss: 0.1624\n",
      "Epoch [555/2000], Avg Train Loss: 0.2379, Avg Val Loss: 0.1812\n",
      "\n",
      "Validation loss improved from 0.1813 to 0.1812. Saving model...\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2420\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1999\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [556/2000], Avg Train Loss: 0.2420, Avg Val Loss: 0.1811\n",
      "\n",
      "Validation loss improved from 0.1812 to 0.1811. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2387\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1998\n",
      "    Batch [2/2], Val Loss: 0.1621\n",
      "Epoch [557/2000], Avg Train Loss: 0.2387, Avg Val Loss: 0.1810\n",
      "\n",
      "Validation loss improved from 0.1811 to 0.1810. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2455\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1998\n",
      "    Batch [2/2], Val Loss: 0.1619\n",
      "Epoch [558/2000], Avg Train Loss: 0.2455, Avg Val Loss: 0.1808\n",
      "\n",
      "Validation loss improved from 0.1810 to 0.1808. Saving model...\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2425\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1998\n",
      "    Batch [2/2], Val Loss: 0.1616\n",
      "Epoch [559/2000], Avg Train Loss: 0.2425, Avg Val Loss: 0.1807\n",
      "\n",
      "Validation loss improved from 0.1808 to 0.1807. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2404\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1997\n",
      "    Batch [2/2], Val Loss: 0.1615\n",
      "Epoch [560/2000], Avg Train Loss: 0.2404, Avg Val Loss: 0.1806\n",
      "\n",
      "Validation loss improved from 0.1807 to 0.1806. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2374\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1997\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [561/2000], Avg Train Loss: 0.2374, Avg Val Loss: 0.1805\n",
      "\n",
      "Validation loss improved from 0.1806 to 0.1805. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2385\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1995\n",
      "    Batch [2/2], Val Loss: 0.1610\n",
      "Epoch [562/2000], Avg Train Loss: 0.2385, Avg Val Loss: 0.1803\n",
      "\n",
      "Validation loss improved from 0.1805 to 0.1803. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2362\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1994\n",
      "    Batch [2/2], Val Loss: 0.1608\n",
      "Epoch [563/2000], Avg Train Loss: 0.2362, Avg Val Loss: 0.1801\n",
      "\n",
      "Validation loss improved from 0.1803 to 0.1801. Saving model...\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2350\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1994\n",
      "    Batch [2/2], Val Loss: 0.1607\n",
      "Epoch [564/2000], Avg Train Loss: 0.2350, Avg Val Loss: 0.1801\n",
      "\n",
      "Validation loss improved from 0.1801 to 0.1801. Saving model...\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2398\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1993\n",
      "    Batch [2/2], Val Loss: 0.1607\n",
      "Epoch [565/2000], Avg Train Loss: 0.2398, Avg Val Loss: 0.1800\n",
      "\n",
      "Validation loss improved from 0.1801 to 0.1800. Saving model...\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2420\n",
      "LOG: Epoch [566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1992\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [566/2000], Avg Train Loss: 0.2420, Avg Val Loss: 0.1799\n",
      "\n",
      "Validation loss improved from 0.1800 to 0.1799. Saving model...\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2387\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1992\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [567/2000], Avg Train Loss: 0.2387, Avg Val Loss: 0.1798\n",
      "\n",
      "Validation loss improved from 0.1799 to 0.1798. Saving model...\n",
      "LOG: Epoch [568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2350\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1992\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [568/2000], Avg Train Loss: 0.2350, Avg Val Loss: 0.1798\n",
      "\n",
      "Validation loss improved from 0.1798 to 0.1798. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2390\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1991\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [569/2000], Avg Train Loss: 0.2390, Avg Val Loss: 0.1798\n",
      "\n",
      "Validation loss improved from 0.1798 to 0.1798. Saving model...\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2413\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1990\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [570/2000], Avg Train Loss: 0.2413, Avg Val Loss: 0.1798\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2412\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1989\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [571/2000], Avg Train Loss: 0.2412, Avg Val Loss: 0.1797\n",
      "\n",
      "Validation loss improved from 0.1798 to 0.1797. Saving model...\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2383\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1988\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [572/2000], Avg Train Loss: 0.2383, Avg Val Loss: 0.1796\n",
      "\n",
      "Validation loss improved from 0.1797 to 0.1796. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2390\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1986\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [573/2000], Avg Train Loss: 0.2390, Avg Val Loss: 0.1795\n",
      "\n",
      "Validation loss improved from 0.1796 to 0.1795. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2401\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1985\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [574/2000], Avg Train Loss: 0.2401, Avg Val Loss: 0.1794\n",
      "\n",
      "Validation loss improved from 0.1795 to 0.1794. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2372\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1983\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [575/2000], Avg Train Loss: 0.2372, Avg Val Loss: 0.1793\n",
      "\n",
      "Validation loss improved from 0.1794 to 0.1793. Saving model...\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2346\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1980\n",
      "    Batch [2/2], Val Loss: 0.1600\n",
      "Epoch [576/2000], Avg Train Loss: 0.2346, Avg Val Loss: 0.1790\n",
      "\n",
      "Validation loss improved from 0.1793 to 0.1790. Saving model...\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2354\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1976\n",
      "    Batch [2/2], Val Loss: 0.1598\n",
      "Epoch [577/2000], Avg Train Loss: 0.2354, Avg Val Loss: 0.1787\n",
      "\n",
      "Validation loss improved from 0.1790 to 0.1787. Saving model...\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2344\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1973\n",
      "    Batch [2/2], Val Loss: 0.1596\n",
      "Epoch [578/2000], Avg Train Loss: 0.2344, Avg Val Loss: 0.1785\n",
      "\n",
      "Validation loss improved from 0.1787 to 0.1785. Saving model...\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2356\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1971\n",
      "    Batch [2/2], Val Loss: 0.1595\n",
      "Epoch [579/2000], Avg Train Loss: 0.2356, Avg Val Loss: 0.1783\n",
      "\n",
      "Validation loss improved from 0.1785 to 0.1783. Saving model...\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2442\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1969\n",
      "    Batch [2/2], Val Loss: 0.1594\n",
      "Epoch [580/2000], Avg Train Loss: 0.2442, Avg Val Loss: 0.1781\n",
      "\n",
      "Validation loss improved from 0.1783 to 0.1781. Saving model...\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2381\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1968\n",
      "    Batch [2/2], Val Loss: 0.1592\n",
      "Epoch [581/2000], Avg Train Loss: 0.2381, Avg Val Loss: 0.1780\n",
      "\n",
      "Validation loss improved from 0.1781 to 0.1780. Saving model...\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2369\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1967\n",
      "    Batch [2/2], Val Loss: 0.1589\n",
      "Epoch [582/2000], Avg Train Loss: 0.2369, Avg Val Loss: 0.1778\n",
      "\n",
      "Validation loss improved from 0.1780 to 0.1778. Saving model...\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2412\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1966\n",
      "    Batch [2/2], Val Loss: 0.1587\n",
      "Epoch [583/2000], Avg Train Loss: 0.2412, Avg Val Loss: 0.1777\n",
      "\n",
      "Validation loss improved from 0.1778 to 0.1777. Saving model...\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2346\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1965\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [584/2000], Avg Train Loss: 0.2346, Avg Val Loss: 0.1775\n",
      "\n",
      "Validation loss improved from 0.1777 to 0.1775. Saving model...\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2304\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1964\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [585/2000], Avg Train Loss: 0.2304, Avg Val Loss: 0.1773\n",
      "\n",
      "Validation loss improved from 0.1775 to 0.1773. Saving model...\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2345\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1963\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [586/2000], Avg Train Loss: 0.2345, Avg Val Loss: 0.1771\n",
      "\n",
      "Validation loss improved from 0.1773 to 0.1771. Saving model...\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2328\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1962\n",
      "    Batch [2/2], Val Loss: 0.1577\n",
      "Epoch [587/2000], Avg Train Loss: 0.2328, Avg Val Loss: 0.1770\n",
      "\n",
      "Validation loss improved from 0.1771 to 0.1770. Saving model...\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2352\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1962\n",
      "    Batch [2/2], Val Loss: 0.1576\n",
      "Epoch [588/2000], Avg Train Loss: 0.2352, Avg Val Loss: 0.1769\n",
      "\n",
      "Validation loss improved from 0.1770 to 0.1769. Saving model...\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2352\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1962\n",
      "    Batch [2/2], Val Loss: 0.1575\n",
      "Epoch [589/2000], Avg Train Loss: 0.2352, Avg Val Loss: 0.1768\n",
      "\n",
      "Validation loss improved from 0.1769 to 0.1768. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2358\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1961\n",
      "    Batch [2/2], Val Loss: 0.1573\n",
      "Epoch [590/2000], Avg Train Loss: 0.2358, Avg Val Loss: 0.1767\n",
      "\n",
      "Validation loss improved from 0.1768 to 0.1767. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2318\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1961\n",
      "    Batch [2/2], Val Loss: 0.1571\n",
      "Epoch [591/2000], Avg Train Loss: 0.2318, Avg Val Loss: 0.1766\n",
      "\n",
      "Validation loss improved from 0.1767 to 0.1766. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2394\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1962\n",
      "    Batch [2/2], Val Loss: 0.1569\n",
      "Epoch [592/2000], Avg Train Loss: 0.2394, Avg Val Loss: 0.1765\n",
      "\n",
      "Validation loss improved from 0.1766 to 0.1765. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2320\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1962\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [593/2000], Avg Train Loss: 0.2320, Avg Val Loss: 0.1764\n",
      "\n",
      "Validation loss improved from 0.1765 to 0.1764. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2320\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1961\n",
      "    Batch [2/2], Val Loss: 0.1563\n",
      "Epoch [594/2000], Avg Train Loss: 0.2320, Avg Val Loss: 0.1762\n",
      "\n",
      "Validation loss improved from 0.1764 to 0.1762. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2367\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1960\n",
      "    Batch [2/2], Val Loss: 0.1561\n",
      "Epoch [595/2000], Avg Train Loss: 0.2367, Avg Val Loss: 0.1761\n",
      "\n",
      "Validation loss improved from 0.1762 to 0.1761. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2334\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1959\n",
      "    Batch [2/2], Val Loss: 0.1558\n",
      "Epoch [596/2000], Avg Train Loss: 0.2334, Avg Val Loss: 0.1759\n",
      "\n",
      "Validation loss improved from 0.1761 to 0.1759. Saving model...\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2353\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1958\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [597/2000], Avg Train Loss: 0.2353, Avg Val Loss: 0.1757\n",
      "\n",
      "Validation loss improved from 0.1759 to 0.1757. Saving model...\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2305\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1957\n",
      "    Batch [2/2], Val Loss: 0.1555\n",
      "Epoch [598/2000], Avg Train Loss: 0.2305, Avg Val Loss: 0.1756\n",
      "\n",
      "Validation loss improved from 0.1757 to 0.1756. Saving model...\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2375\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1957\n",
      "    Batch [2/2], Val Loss: 0.1553\n",
      "Epoch [599/2000], Avg Train Loss: 0.2375, Avg Val Loss: 0.1755\n",
      "\n",
      "Validation loss improved from 0.1756 to 0.1755. Saving model...\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2304\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1956\n",
      "    Batch [2/2], Val Loss: 0.1552\n",
      "Epoch [600/2000], Avg Train Loss: 0.2304, Avg Val Loss: 0.1754\n",
      "\n",
      "Validation loss improved from 0.1755 to 0.1754. Saving model...\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2304\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1955\n",
      "    Batch [2/2], Val Loss: 0.1552\n",
      "Epoch [601/2000], Avg Train Loss: 0.2304, Avg Val Loss: 0.1754\n",
      "\n",
      "Validation loss improved from 0.1754 to 0.1754. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2343\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1954\n",
      "    Batch [2/2], Val Loss: 0.1554\n",
      "Epoch [602/2000], Avg Train Loss: 0.2343, Avg Val Loss: 0.1754\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2293\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1954\n",
      "    Batch [2/2], Val Loss: 0.1555\n",
      "Epoch [603/2000], Avg Train Loss: 0.2293, Avg Val Loss: 0.1754\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2292\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1953\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [604/2000], Avg Train Loss: 0.2292, Avg Val Loss: 0.1754\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2309\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1951\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [605/2000], Avg Train Loss: 0.2309, Avg Val Loss: 0.1754\n",
      "\n",
      "Validation loss improved from 0.1754 to 0.1754. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2285\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1950\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [606/2000], Avg Train Loss: 0.2285, Avg Val Loss: 0.1753\n",
      "\n",
      "Validation loss improved from 0.1754 to 0.1753. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2348\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1948\n",
      "    Batch [2/2], Val Loss: 0.1557\n",
      "Epoch [607/2000], Avg Train Loss: 0.2348, Avg Val Loss: 0.1753\n",
      "\n",
      "Validation loss improved from 0.1753 to 0.1753. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2300\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1947\n",
      "    Batch [2/2], Val Loss: 0.1557\n",
      "Epoch [608/2000], Avg Train Loss: 0.2300, Avg Val Loss: 0.1752\n",
      "\n",
      "Validation loss improved from 0.1753 to 0.1752. Saving model...\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2324\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1947\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [609/2000], Avg Train Loss: 0.2324, Avg Val Loss: 0.1752\n",
      "\n",
      "Validation loss improved from 0.1752 to 0.1752. Saving model...\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2328\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1946\n",
      "    Batch [2/2], Val Loss: 0.1555\n",
      "Epoch [610/2000], Avg Train Loss: 0.2328, Avg Val Loss: 0.1750\n",
      "\n",
      "Validation loss improved from 0.1752 to 0.1750. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2282\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1945\n",
      "    Batch [2/2], Val Loss: 0.1554\n",
      "Epoch [611/2000], Avg Train Loss: 0.2282, Avg Val Loss: 0.1750\n",
      "\n",
      "Validation loss improved from 0.1750 to 0.1750. Saving model...\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2277\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1945\n",
      "    Batch [2/2], Val Loss: 0.1554\n",
      "Epoch [612/2000], Avg Train Loss: 0.2277, Avg Val Loss: 0.1749\n",
      "\n",
      "Validation loss improved from 0.1750 to 0.1749. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2341\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1944\n",
      "    Batch [2/2], Val Loss: 0.1554\n",
      "Epoch [613/2000], Avg Train Loss: 0.2341, Avg Val Loss: 0.1749\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2239\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1944\n",
      "    Batch [2/2], Val Loss: 0.1555\n",
      "Epoch [614/2000], Avg Train Loss: 0.2239, Avg Val Loss: 0.1749\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2227\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1943\n",
      "    Batch [2/2], Val Loss: 0.1554\n",
      "Epoch [615/2000], Avg Train Loss: 0.2227, Avg Val Loss: 0.1749\n",
      "\n",
      "Validation loss improved from 0.1749 to 0.1749. Saving model...\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2316\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1942\n",
      "    Batch [2/2], Val Loss: 0.1553\n",
      "Epoch [616/2000], Avg Train Loss: 0.2316, Avg Val Loss: 0.1747\n",
      "\n",
      "Validation loss improved from 0.1749 to 0.1747. Saving model...\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2307\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1942\n",
      "    Batch [2/2], Val Loss: 0.1552\n",
      "Epoch [617/2000], Avg Train Loss: 0.2307, Avg Val Loss: 0.1747\n",
      "\n",
      "Validation loss improved from 0.1747 to 0.1747. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2262\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1940\n",
      "    Batch [2/2], Val Loss: 0.1550\n",
      "Epoch [618/2000], Avg Train Loss: 0.2262, Avg Val Loss: 0.1745\n",
      "\n",
      "Validation loss improved from 0.1747 to 0.1745. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2290\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1939\n",
      "    Batch [2/2], Val Loss: 0.1547\n",
      "Epoch [619/2000], Avg Train Loss: 0.2290, Avg Val Loss: 0.1743\n",
      "\n",
      "Validation loss improved from 0.1745 to 0.1743. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2311\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1936\n",
      "    Batch [2/2], Val Loss: 0.1543\n",
      "Epoch [620/2000], Avg Train Loss: 0.2311, Avg Val Loss: 0.1740\n",
      "\n",
      "Validation loss improved from 0.1743 to 0.1740. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2262\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1933\n",
      "    Batch [2/2], Val Loss: 0.1540\n",
      "Epoch [621/2000], Avg Train Loss: 0.2262, Avg Val Loss: 0.1737\n",
      "\n",
      "Validation loss improved from 0.1740 to 0.1737. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2292\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1931\n",
      "    Batch [2/2], Val Loss: 0.1539\n",
      "Epoch [622/2000], Avg Train Loss: 0.2292, Avg Val Loss: 0.1735\n",
      "\n",
      "Validation loss improved from 0.1737 to 0.1735. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2237\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1929\n",
      "    Batch [2/2], Val Loss: 0.1538\n",
      "Epoch [623/2000], Avg Train Loss: 0.2237, Avg Val Loss: 0.1734\n",
      "\n",
      "Validation loss improved from 0.1735 to 0.1734. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2266\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1929\n",
      "    Batch [2/2], Val Loss: 0.1537\n",
      "Epoch [624/2000], Avg Train Loss: 0.2266, Avg Val Loss: 0.1733\n",
      "\n",
      "Validation loss improved from 0.1734 to 0.1733. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2244\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1927\n",
      "    Batch [2/2], Val Loss: 0.1534\n",
      "Epoch [625/2000], Avg Train Loss: 0.2244, Avg Val Loss: 0.1730\n",
      "\n",
      "Validation loss improved from 0.1733 to 0.1730. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2242\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1925\n",
      "    Batch [2/2], Val Loss: 0.1532\n",
      "Epoch [626/2000], Avg Train Loss: 0.2242, Avg Val Loss: 0.1729\n",
      "\n",
      "Validation loss improved from 0.1730 to 0.1729. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2234\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1924\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [627/2000], Avg Train Loss: 0.2234, Avg Val Loss: 0.1728\n",
      "\n",
      "Validation loss improved from 0.1729 to 0.1728. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2231\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1923\n",
      "    Batch [2/2], Val Loss: 0.1530\n",
      "Epoch [628/2000], Avg Train Loss: 0.2231, Avg Val Loss: 0.1726\n",
      "\n",
      "Validation loss improved from 0.1728 to 0.1726. Saving model...\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2306\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1923\n",
      "    Batch [2/2], Val Loss: 0.1529\n",
      "Epoch [629/2000], Avg Train Loss: 0.2306, Avg Val Loss: 0.1726\n",
      "\n",
      "Validation loss improved from 0.1726 to 0.1726. Saving model...\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2285\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1922\n",
      "    Batch [2/2], Val Loss: 0.1528\n",
      "Epoch [630/2000], Avg Train Loss: 0.2285, Avg Val Loss: 0.1725\n",
      "\n",
      "Validation loss improved from 0.1726 to 0.1725. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2272\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1923\n",
      "    Batch [2/2], Val Loss: 0.1527\n",
      "Epoch [631/2000], Avg Train Loss: 0.2272, Avg Val Loss: 0.1725\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2282\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1924\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [632/2000], Avg Train Loss: 0.2282, Avg Val Loss: 0.1725\n",
      "\n",
      "Validation loss improved from 0.1725 to 0.1725. Saving model...\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2277\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1924\n",
      "    Batch [2/2], Val Loss: 0.1523\n",
      "Epoch [633/2000], Avg Train Loss: 0.2277, Avg Val Loss: 0.1724\n",
      "\n",
      "Validation loss improved from 0.1725 to 0.1724. Saving model...\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2313\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1925\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [634/2000], Avg Train Loss: 0.2313, Avg Val Loss: 0.1723\n",
      "\n",
      "Validation loss improved from 0.1724 to 0.1723. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2254\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1925\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [635/2000], Avg Train Loss: 0.2254, Avg Val Loss: 0.1723\n",
      "\n",
      "Validation loss improved from 0.1723 to 0.1723. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2198\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1926\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [636/2000], Avg Train Loss: 0.2198, Avg Val Loss: 0.1724\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2312\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1927\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [637/2000], Avg Train Loss: 0.2312, Avg Val Loss: 0.1724\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2298\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1928\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [638/2000], Avg Train Loss: 0.2298, Avg Val Loss: 0.1724\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2199\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1929\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [639/2000], Avg Train Loss: 0.2199, Avg Val Loss: 0.1726\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2277\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1929\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [640/2000], Avg Train Loss: 0.2277, Avg Val Loss: 0.1727\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2213\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1930\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [641/2000], Avg Train Loss: 0.2213, Avg Val Loss: 0.1727\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2262\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1929\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [642/2000], Avg Train Loss: 0.2262, Avg Val Loss: 0.1727\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2219\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1927\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [643/2000], Avg Train Loss: 0.2219, Avg Val Loss: 0.1726\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2246\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1924\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [644/2000], Avg Train Loss: 0.2246, Avg Val Loss: 0.1724\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2220\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1921\n",
      "    Batch [2/2], Val Loss: 0.1523\n",
      "Epoch [645/2000], Avg Train Loss: 0.2220, Avg Val Loss: 0.1722\n",
      "\n",
      "Validation loss improved from 0.1723 to 0.1722. Saving model...\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2224\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1919\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [646/2000], Avg Train Loss: 0.2224, Avg Val Loss: 0.1720\n",
      "\n",
      "Validation loss improved from 0.1722 to 0.1720. Saving model...\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2284\n",
      "LOG: Epoch [647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1916\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [647/2000], Avg Train Loss: 0.2284, Avg Val Loss: 0.1719\n",
      "\n",
      "Validation loss improved from 0.1720 to 0.1719. Saving model...\n",
      "LOG: Epoch [648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2256\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1914\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [648/2000], Avg Train Loss: 0.2256, Avg Val Loss: 0.1717\n",
      "\n",
      "Validation loss improved from 0.1719 to 0.1717. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2281\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1912\n",
      "    Batch [2/2], Val Loss: 0.1519\n",
      "Epoch [649/2000], Avg Train Loss: 0.2281, Avg Val Loss: 0.1716\n",
      "\n",
      "Validation loss improved from 0.1717 to 0.1716. Saving model...\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2270\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1911\n",
      "    Batch [2/2], Val Loss: 0.1519\n",
      "Epoch [650/2000], Avg Train Loss: 0.2270, Avg Val Loss: 0.1715\n",
      "\n",
      "Validation loss improved from 0.1716 to 0.1715. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2179\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1911\n",
      "    Batch [2/2], Val Loss: 0.1518\n",
      "Epoch [651/2000], Avg Train Loss: 0.2179, Avg Val Loss: 0.1715\n",
      "\n",
      "Validation loss improved from 0.1715 to 0.1715. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2230\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1911\n",
      "    Batch [2/2], Val Loss: 0.1518\n",
      "Epoch [652/2000], Avg Train Loss: 0.2230, Avg Val Loss: 0.1714\n",
      "\n",
      "Validation loss improved from 0.1715 to 0.1714. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2284\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1912\n",
      "    Batch [2/2], Val Loss: 0.1517\n",
      "Epoch [653/2000], Avg Train Loss: 0.2284, Avg Val Loss: 0.1715\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2253\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1914\n",
      "    Batch [2/2], Val Loss: 0.1516\n",
      "Epoch [654/2000], Avg Train Loss: 0.2253, Avg Val Loss: 0.1715\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2224\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1915\n",
      "    Batch [2/2], Val Loss: 0.1515\n",
      "Epoch [655/2000], Avg Train Loss: 0.2224, Avg Val Loss: 0.1715\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2232\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1916\n",
      "    Batch [2/2], Val Loss: 0.1514\n",
      "Epoch [656/2000], Avg Train Loss: 0.2232, Avg Val Loss: 0.1715\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2214\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1917\n",
      "    Batch [2/2], Val Loss: 0.1513\n",
      "Epoch [657/2000], Avg Train Loss: 0.2214, Avg Val Loss: 0.1715\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2265\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1916\n",
      "    Batch [2/2], Val Loss: 0.1511\n",
      "Epoch [658/2000], Avg Train Loss: 0.2265, Avg Val Loss: 0.1714\n",
      "\n",
      "Validation loss improved from 0.1714 to 0.1714. Saving model...\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2199\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1916\n",
      "    Batch [2/2], Val Loss: 0.1509\n",
      "Epoch [659/2000], Avg Train Loss: 0.2199, Avg Val Loss: 0.1712\n",
      "\n",
      "Validation loss improved from 0.1714 to 0.1712. Saving model...\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2201\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1915\n",
      "    Batch [2/2], Val Loss: 0.1506\n",
      "Epoch [660/2000], Avg Train Loss: 0.2201, Avg Val Loss: 0.1711\n",
      "\n",
      "Validation loss improved from 0.1712 to 0.1711. Saving model...\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2217\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1914\n",
      "    Batch [2/2], Val Loss: 0.1504\n",
      "Epoch [661/2000], Avg Train Loss: 0.2217, Avg Val Loss: 0.1709\n",
      "\n",
      "Validation loss improved from 0.1711 to 0.1709. Saving model...\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2164\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1913\n",
      "    Batch [2/2], Val Loss: 0.1501\n",
      "Epoch [662/2000], Avg Train Loss: 0.2164, Avg Val Loss: 0.1707\n",
      "\n",
      "Validation loss improved from 0.1709 to 0.1707. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2199\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1911\n",
      "    Batch [2/2], Val Loss: 0.1499\n",
      "Epoch [663/2000], Avg Train Loss: 0.2199, Avg Val Loss: 0.1705\n",
      "\n",
      "Validation loss improved from 0.1707 to 0.1705. Saving model...\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2229\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1909\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [664/2000], Avg Train Loss: 0.2229, Avg Val Loss: 0.1703\n",
      "\n",
      "Validation loss improved from 0.1705 to 0.1703. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2240\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1908\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [665/2000], Avg Train Loss: 0.2240, Avg Val Loss: 0.1701\n",
      "\n",
      "Validation loss improved from 0.1703 to 0.1701. Saving model...\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2235\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1906\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [666/2000], Avg Train Loss: 0.2235, Avg Val Loss: 0.1700\n",
      "\n",
      "Validation loss improved from 0.1701 to 0.1700. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2223\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1905\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [667/2000], Avg Train Loss: 0.2223, Avg Val Loss: 0.1699\n",
      "\n",
      "Validation loss improved from 0.1700 to 0.1699. Saving model...\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2172\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1904\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [668/2000], Avg Train Loss: 0.2172, Avg Val Loss: 0.1698\n",
      "\n",
      "Validation loss improved from 0.1699 to 0.1698. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2205\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1904\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [669/2000], Avg Train Loss: 0.2205, Avg Val Loss: 0.1699\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2218\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1904\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [670/2000], Avg Train Loss: 0.2218, Avg Val Loss: 0.1700\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2197\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1905\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [671/2000], Avg Train Loss: 0.2197, Avg Val Loss: 0.1700\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2253\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1905\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [672/2000], Avg Train Loss: 0.2253, Avg Val Loss: 0.1701\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2209\n",
      "LOG: Epoch [673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1904\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [673/2000], Avg Train Loss: 0.2209, Avg Val Loss: 0.1700\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2229\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1904\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [674/2000], Avg Train Loss: 0.2229, Avg Val Loss: 0.1700\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2190\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1902\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [675/2000], Avg Train Loss: 0.2190, Avg Val Loss: 0.1699\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2202\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1901\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [676/2000], Avg Train Loss: 0.2202, Avg Val Loss: 0.1699\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2217\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1899\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [677/2000], Avg Train Loss: 0.2217, Avg Val Loss: 0.1698\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2190\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1898\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [678/2000], Avg Train Loss: 0.2190, Avg Val Loss: 0.1698\n",
      "\n",
      "Validation loss improved from 0.1698 to 0.1698. Saving model...\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2204\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1897\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [679/2000], Avg Train Loss: 0.2204, Avg Val Loss: 0.1697\n",
      "\n",
      "Validation loss improved from 0.1698 to 0.1697. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2211\n",
      "LOG: Epoch [680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [680/2000], Avg Train Loss: 0.2211, Avg Val Loss: 0.1696\n",
      "\n",
      "Validation loss improved from 0.1697 to 0.1696. Saving model...\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2118\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [681/2000], Avg Train Loss: 0.2118, Avg Val Loss: 0.1695\n",
      "\n",
      "Validation loss improved from 0.1696 to 0.1695. Saving model...\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2219\n",
      "LOG: Epoch [682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [682/2000], Avg Train Loss: 0.2219, Avg Val Loss: 0.1694\n",
      "\n",
      "Validation loss improved from 0.1695 to 0.1694. Saving model...\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2204\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1893\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [683/2000], Avg Train Loss: 0.2204, Avg Val Loss: 0.1692\n",
      "\n",
      "Validation loss improved from 0.1694 to 0.1692. Saving model...\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2215\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1891\n",
      "    Batch [2/2], Val Loss: 0.1487\n",
      "Epoch [684/2000], Avg Train Loss: 0.2215, Avg Val Loss: 0.1689\n",
      "\n",
      "Validation loss improved from 0.1692 to 0.1689. Saving model...\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2247\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1889\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [685/2000], Avg Train Loss: 0.2247, Avg Val Loss: 0.1686\n",
      "\n",
      "Validation loss improved from 0.1689 to 0.1686. Saving model...\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2217\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1889\n",
      "    Batch [2/2], Val Loss: 0.1480\n",
      "Epoch [686/2000], Avg Train Loss: 0.2217, Avg Val Loss: 0.1685\n",
      "\n",
      "Validation loss improved from 0.1686 to 0.1685. Saving model...\n",
      "LOG: Epoch [687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2138\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1889\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [687/2000], Avg Train Loss: 0.2138, Avg Val Loss: 0.1683\n",
      "\n",
      "Validation loss improved from 0.1685 to 0.1683. Saving model...\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2184\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1891\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [688/2000], Avg Train Loss: 0.2184, Avg Val Loss: 0.1683\n",
      "\n",
      "Validation loss improved from 0.1683 to 0.1683. Saving model...\n",
      "LOG: Epoch [689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2191\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1892\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [689/2000], Avg Train Loss: 0.2191, Avg Val Loss: 0.1683\n",
      "\n",
      "Validation loss improved from 0.1683 to 0.1683. Saving model...\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2214\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1892\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [690/2000], Avg Train Loss: 0.2214, Avg Val Loss: 0.1681\n",
      "\n",
      "Validation loss improved from 0.1683 to 0.1681. Saving model...\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2200\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1893\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [691/2000], Avg Train Loss: 0.2200, Avg Val Loss: 0.1681\n",
      "\n",
      "Validation loss improved from 0.1681 to 0.1681. Saving model...\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2181\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [692/2000], Avg Train Loss: 0.2181, Avg Val Loss: 0.1682\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2176\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [693/2000], Avg Train Loss: 0.2176, Avg Val Loss: 0.1682\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2177\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [694/2000], Avg Train Loss: 0.2177, Avg Val Loss: 0.1682\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2129\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [695/2000], Avg Train Loss: 0.2129, Avg Val Loss: 0.1682\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2132\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [696/2000], Avg Train Loss: 0.2132, Avg Val Loss: 0.1683\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2140\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [697/2000], Avg Train Loss: 0.2140, Avg Val Loss: 0.1683\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2141\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1897\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [698/2000], Avg Train Loss: 0.2141, Avg Val Loss: 0.1684\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2121\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [699/2000], Avg Train Loss: 0.2121, Avg Val Loss: 0.1683\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2140\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [700/2000], Avg Train Loss: 0.2140, Avg Val Loss: 0.1681\n",
      "\n",
      "Validation loss improved from 0.1681 to 0.1681. Saving model...\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2139\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1464\n",
      "Epoch [701/2000], Avg Train Loss: 0.2139, Avg Val Loss: 0.1679\n",
      "\n",
      "Validation loss improved from 0.1681 to 0.1679. Saving model...\n",
      "LOG: Epoch [702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2177\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [702/2000], Avg Train Loss: 0.2177, Avg Val Loss: 0.1679\n",
      "\n",
      "Validation loss improved from 0.1679 to 0.1679. Saving model...\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2132\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1462\n",
      "Epoch [703/2000], Avg Train Loss: 0.2132, Avg Val Loss: 0.1678\n",
      "\n",
      "Validation loss improved from 0.1679 to 0.1678. Saving model...\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2155\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1460\n",
      "Epoch [704/2000], Avg Train Loss: 0.2155, Avg Val Loss: 0.1677\n",
      "\n",
      "Validation loss improved from 0.1678 to 0.1677. Saving model...\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2108\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1459\n",
      "Epoch [705/2000], Avg Train Loss: 0.2108, Avg Val Loss: 0.1677\n",
      "\n",
      "Validation loss improved from 0.1677 to 0.1677. Saving model...\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2123\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1457\n",
      "Epoch [706/2000], Avg Train Loss: 0.2123, Avg Val Loss: 0.1676\n",
      "\n",
      "Validation loss improved from 0.1677 to 0.1676. Saving model...\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2077\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [707/2000], Avg Train Loss: 0.2077, Avg Val Loss: 0.1675\n",
      "\n",
      "Validation loss improved from 0.1676 to 0.1675. Saving model...\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2127\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [708/2000], Avg Train Loss: 0.2127, Avg Val Loss: 0.1675\n",
      "\n",
      "Validation loss improved from 0.1675 to 0.1675. Saving model...\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2144\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [709/2000], Avg Train Loss: 0.2144, Avg Val Loss: 0.1674\n",
      "\n",
      "Validation loss improved from 0.1675 to 0.1674. Saving model...\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2139\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [710/2000], Avg Train Loss: 0.2139, Avg Val Loss: 0.1673\n",
      "\n",
      "Validation loss improved from 0.1674 to 0.1673. Saving model...\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2145\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1446\n",
      "Epoch [711/2000], Avg Train Loss: 0.2145, Avg Val Loss: 0.1671\n",
      "\n",
      "Validation loss improved from 0.1673 to 0.1671. Saving model...\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2166\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1444\n",
      "Epoch [712/2000], Avg Train Loss: 0.2166, Avg Val Loss: 0.1670\n",
      "\n",
      "Validation loss improved from 0.1671 to 0.1670. Saving model...\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2077\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [713/2000], Avg Train Loss: 0.2077, Avg Val Loss: 0.1670\n",
      "\n",
      "Validation loss improved from 0.1670 to 0.1670. Saving model...\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2083\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [714/2000], Avg Train Loss: 0.2083, Avg Val Loss: 0.1669\n",
      "\n",
      "Validation loss improved from 0.1670 to 0.1669. Saving model...\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2089\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [715/2000], Avg Train Loss: 0.2089, Avg Val Loss: 0.1668\n",
      "\n",
      "Validation loss improved from 0.1669 to 0.1668. Saving model...\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2143\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1896\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [716/2000], Avg Train Loss: 0.2143, Avg Val Loss: 0.1669\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2175\n",
      "LOG: Epoch [717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1895\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [717/2000], Avg Train Loss: 0.2175, Avg Val Loss: 0.1668\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2112\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1894\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [718/2000], Avg Train Loss: 0.2112, Avg Val Loss: 0.1669\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2062\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1893\n",
      "    Batch [2/2], Val Loss: 0.1444\n",
      "Epoch [719/2000], Avg Train Loss: 0.2062, Avg Val Loss: 0.1668\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2079\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1891\n",
      "    Batch [2/2], Val Loss: 0.1444\n",
      "Epoch [720/2000], Avg Train Loss: 0.2079, Avg Val Loss: 0.1668\n",
      "\n",
      "Validation loss improved from 0.1668 to 0.1668. Saving model...\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2129\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1889\n",
      "    Batch [2/2], Val Loss: 0.1445\n",
      "Epoch [721/2000], Avg Train Loss: 0.2129, Avg Val Loss: 0.1667\n",
      "\n",
      "Validation loss improved from 0.1668 to 0.1667. Saving model...\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2181\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1889\n",
      "    Batch [2/2], Val Loss: 0.1446\n",
      "Epoch [722/2000], Avg Train Loss: 0.2181, Avg Val Loss: 0.1667\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2125\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1887\n",
      "    Batch [2/2], Val Loss: 0.1446\n",
      "Epoch [723/2000], Avg Train Loss: 0.2125, Avg Val Loss: 0.1667\n",
      "\n",
      "Validation loss improved from 0.1667 to 0.1667. Saving model...\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2115\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1887\n",
      "    Batch [2/2], Val Loss: 0.1447\n",
      "Epoch [724/2000], Avg Train Loss: 0.2115, Avg Val Loss: 0.1667\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2154\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1886\n",
      "    Batch [2/2], Val Loss: 0.1448\n",
      "Epoch [725/2000], Avg Train Loss: 0.2154, Avg Val Loss: 0.1667\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2076\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1884\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [726/2000], Avg Train Loss: 0.2076, Avg Val Loss: 0.1667\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2079\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1882\n",
      "    Batch [2/2], Val Loss: 0.1450\n",
      "Epoch [727/2000], Avg Train Loss: 0.2079, Avg Val Loss: 0.1666\n",
      "\n",
      "Validation loss improved from 0.1667 to 0.1666. Saving model...\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2065\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1879\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [728/2000], Avg Train Loss: 0.2065, Avg Val Loss: 0.1664\n",
      "\n",
      "Validation loss improved from 0.1666 to 0.1664. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2141\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1878\n",
      "    Batch [2/2], Val Loss: 0.1447\n",
      "Epoch [729/2000], Avg Train Loss: 0.2141, Avg Val Loss: 0.1662\n",
      "\n",
      "Validation loss improved from 0.1664 to 0.1662. Saving model...\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2124\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1875\n",
      "    Batch [2/2], Val Loss: 0.1446\n",
      "Epoch [730/2000], Avg Train Loss: 0.2124, Avg Val Loss: 0.1661\n",
      "\n",
      "Validation loss improved from 0.1662 to 0.1661. Saving model...\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2109\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1873\n",
      "    Batch [2/2], Val Loss: 0.1445\n",
      "Epoch [731/2000], Avg Train Loss: 0.2109, Avg Val Loss: 0.1659\n",
      "\n",
      "Validation loss improved from 0.1661 to 0.1659. Saving model...\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2044\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1872\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [732/2000], Avg Train Loss: 0.2044, Avg Val Loss: 0.1658\n",
      "\n",
      "Validation loss improved from 0.1659 to 0.1658. Saving model...\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2073\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1870\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [733/2000], Avg Train Loss: 0.2073, Avg Val Loss: 0.1656\n",
      "\n",
      "Validation loss improved from 0.1658 to 0.1656. Saving model...\n",
      "LOG: Epoch [734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2062\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1869\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [734/2000], Avg Train Loss: 0.2062, Avg Val Loss: 0.1654\n",
      "\n",
      "Validation loss improved from 0.1656 to 0.1654. Saving model...\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2090\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1868\n",
      "    Batch [2/2], Val Loss: 0.1437\n",
      "Epoch [735/2000], Avg Train Loss: 0.2090, Avg Val Loss: 0.1652\n",
      "\n",
      "Validation loss improved from 0.1654 to 0.1652. Saving model...\n",
      "LOG: Epoch [736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2024\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1866\n",
      "    Batch [2/2], Val Loss: 0.1435\n",
      "Epoch [736/2000], Avg Train Loss: 0.2024, Avg Val Loss: 0.1651\n",
      "\n",
      "Validation loss improved from 0.1652 to 0.1651. Saving model...\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2092\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1865\n",
      "    Batch [2/2], Val Loss: 0.1432\n",
      "Epoch [737/2000], Avg Train Loss: 0.2092, Avg Val Loss: 0.1649\n",
      "\n",
      "Validation loss improved from 0.1651 to 0.1649. Saving model...\n",
      "LOG: Epoch [738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2150\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1865\n",
      "    Batch [2/2], Val Loss: 0.1426\n",
      "Epoch [738/2000], Avg Train Loss: 0.2150, Avg Val Loss: 0.1646\n",
      "\n",
      "Validation loss improved from 0.1649 to 0.1646. Saving model...\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2056\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1865\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [739/2000], Avg Train Loss: 0.2056, Avg Val Loss: 0.1643\n",
      "\n",
      "Validation loss improved from 0.1646 to 0.1643. Saving model...\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2085\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1866\n",
      "    Batch [2/2], Val Loss: 0.1416\n",
      "Epoch [740/2000], Avg Train Loss: 0.2085, Avg Val Loss: 0.1641\n",
      "\n",
      "Validation loss improved from 0.1643 to 0.1641. Saving model...\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2120\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1867\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [741/2000], Avg Train Loss: 0.2120, Avg Val Loss: 0.1641\n",
      "\n",
      "Validation loss improved from 0.1641 to 0.1641. Saving model...\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2068\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1869\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [742/2000], Avg Train Loss: 0.2068, Avg Val Loss: 0.1640\n",
      "\n",
      "Validation loss improved from 0.1641 to 0.1640. Saving model...\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2084\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1870\n",
      "    Batch [2/2], Val Loss: 0.1410\n",
      "Epoch [743/2000], Avg Train Loss: 0.2084, Avg Val Loss: 0.1640\n",
      "\n",
      "Validation loss improved from 0.1640 to 0.1640. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2110\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1871\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [744/2000], Avg Train Loss: 0.2110, Avg Val Loss: 0.1639\n",
      "\n",
      "Validation loss improved from 0.1640 to 0.1639. Saving model...\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2073\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1872\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [745/2000], Avg Train Loss: 0.2073, Avg Val Loss: 0.1639\n",
      "\n",
      "Validation loss improved from 0.1639 to 0.1639. Saving model...\n",
      "LOG: Epoch [746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2054\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1873\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [746/2000], Avg Train Loss: 0.2054, Avg Val Loss: 0.1639\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2123\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1874\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [747/2000], Avg Train Loss: 0.2123, Avg Val Loss: 0.1640\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2116\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1876\n",
      "    Batch [2/2], Val Loss: 0.1409\n",
      "Epoch [748/2000], Avg Train Loss: 0.2116, Avg Val Loss: 0.1643\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2040\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1877\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [749/2000], Avg Train Loss: 0.2040, Avg Val Loss: 0.1644\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2020\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1879\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [750/2000], Avg Train Loss: 0.2020, Avg Val Loss: 0.1646\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2056\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1879\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [751/2000], Avg Train Loss: 0.2056, Avg Val Loss: 0.1646\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2034\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1879\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [752/2000], Avg Train Loss: 0.2034, Avg Val Loss: 0.1645\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2099\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1878\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [753/2000], Avg Train Loss: 0.2099, Avg Val Loss: 0.1644\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2058\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1877\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [754/2000], Avg Train Loss: 0.2058, Avg Val Loss: 0.1644\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2057\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1876\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [755/2000], Avg Train Loss: 0.2057, Avg Val Loss: 0.1644\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2082\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1874\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [756/2000], Avg Train Loss: 0.2082, Avg Val Loss: 0.1643\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2065\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1872\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [757/2000], Avg Train Loss: 0.2065, Avg Val Loss: 0.1642\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2004\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1872\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [758/2000], Avg Train Loss: 0.2004, Avg Val Loss: 0.1643\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1985\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1871\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [759/2000], Avg Train Loss: 0.1985, Avg Val Loss: 0.1644\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2060\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1871\n",
      "    Batch [2/2], Val Loss: 0.1419\n",
      "Epoch [760/2000], Avg Train Loss: 0.2060, Avg Val Loss: 0.1645\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2030\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1870\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [761/2000], Avg Train Loss: 0.2030, Avg Val Loss: 0.1645\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2063\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1868\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [762/2000], Avg Train Loss: 0.2063, Avg Val Loss: 0.1645\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2072\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1867\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [763/2000], Avg Train Loss: 0.2072, Avg Val Loss: 0.1644\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2062\n",
      "LOG: Epoch [764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1867\n",
      "    Batch [2/2], Val Loss: 0.1420\n",
      "Epoch [764/2000], Avg Train Loss: 0.2062, Avg Val Loss: 0.1643\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2072\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1867\n",
      "    Batch [2/2], Val Loss: 0.1419\n",
      "Epoch [765/2000], Avg Train Loss: 0.2072, Avg Val Loss: 0.1643\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2055\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1867\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [766/2000], Avg Train Loss: 0.2055, Avg Val Loss: 0.1643\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2052\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1866\n",
      "    Batch [2/2], Val Loss: 0.1415\n",
      "Epoch [767/2000], Avg Train Loss: 0.2052, Avg Val Loss: 0.1640\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2013\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1865\n",
      "    Batch [2/2], Val Loss: 0.1413\n",
      "Epoch [768/2000], Avg Train Loss: 0.2013, Avg Val Loss: 0.1639\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2049\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1865\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [769/2000], Avg Train Loss: 0.2049, Avg Val Loss: 0.1638\n",
      "\n",
      "Validation loss improved from 0.1639 to 0.1638. Saving model...\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2018\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1864\n",
      "    Batch [2/2], Val Loss: 0.1410\n",
      "Epoch [770/2000], Avg Train Loss: 0.2018, Avg Val Loss: 0.1637\n",
      "\n",
      "Validation loss improved from 0.1638 to 0.1637. Saving model...\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2026\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1864\n",
      "    Batch [2/2], Val Loss: 0.1409\n",
      "Epoch [771/2000], Avg Train Loss: 0.2026, Avg Val Loss: 0.1637\n",
      "\n",
      "Validation loss improved from 0.1637 to 0.1637. Saving model...\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1864\n",
      "    Batch [2/2], Val Loss: 0.1409\n",
      "Epoch [772/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1636\n",
      "\n",
      "Validation loss improved from 0.1637 to 0.1636. Saving model...\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2030\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1863\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [773/2000], Avg Train Loss: 0.2030, Avg Val Loss: 0.1636\n",
      "\n",
      "Validation loss improved from 0.1636 to 0.1636. Saving model...\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2061\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1863\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [774/2000], Avg Train Loss: 0.2061, Avg Val Loss: 0.1636\n",
      "\n",
      "Validation loss improved from 0.1636 to 0.1636. Saving model...\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2046\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1863\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [775/2000], Avg Train Loss: 0.2046, Avg Val Loss: 0.1635\n",
      "\n",
      "Validation loss improved from 0.1636 to 0.1635. Saving model...\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2004\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1863\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [776/2000], Avg Train Loss: 0.2004, Avg Val Loss: 0.1634\n",
      "\n",
      "Validation loss improved from 0.1635 to 0.1634. Saving model...\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2016\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1864\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [777/2000], Avg Train Loss: 0.2016, Avg Val Loss: 0.1634\n",
      "\n",
      "Validation loss improved from 0.1634 to 0.1634. Saving model...\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2018\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1864\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [778/2000], Avg Train Loss: 0.2018, Avg Val Loss: 0.1633\n",
      "\n",
      "Validation loss improved from 0.1634 to 0.1633. Saving model...\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2003\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1865\n",
      "    Batch [2/2], Val Loss: 0.1400\n",
      "Epoch [779/2000], Avg Train Loss: 0.2003, Avg Val Loss: 0.1632\n",
      "\n",
      "Validation loss improved from 0.1633 to 0.1632. Saving model...\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2013\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1864\n",
      "    Batch [2/2], Val Loss: 0.1398\n",
      "Epoch [780/2000], Avg Train Loss: 0.2013, Avg Val Loss: 0.1631\n",
      "\n",
      "Validation loss improved from 0.1632 to 0.1631. Saving model...\n",
      "LOG: Epoch [781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1978\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1863\n",
      "    Batch [2/2], Val Loss: 0.1397\n",
      "Epoch [781/2000], Avg Train Loss: 0.1978, Avg Val Loss: 0.1630\n",
      "\n",
      "Validation loss improved from 0.1631 to 0.1630. Saving model...\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1863\n",
      "    Batch [2/2], Val Loss: 0.1395\n",
      "Epoch [782/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1629\n",
      "\n",
      "Validation loss improved from 0.1630 to 0.1629. Saving model...\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2024\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1862\n",
      "    Batch [2/2], Val Loss: 0.1394\n",
      "Epoch [783/2000], Avg Train Loss: 0.2024, Avg Val Loss: 0.1628\n",
      "\n",
      "Validation loss improved from 0.1629 to 0.1628. Saving model...\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2027\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1860\n",
      "    Batch [2/2], Val Loss: 0.1391\n",
      "Epoch [784/2000], Avg Train Loss: 0.2027, Avg Val Loss: 0.1626\n",
      "\n",
      "Validation loss improved from 0.1628 to 0.1626. Saving model...\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2006\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1858\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [785/2000], Avg Train Loss: 0.2006, Avg Val Loss: 0.1623\n",
      "\n",
      "Validation loss improved from 0.1626 to 0.1623. Saving model...\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1855\n",
      "    Batch [2/2], Val Loss: 0.1387\n",
      "Epoch [786/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1621\n",
      "\n",
      "Validation loss improved from 0.1623 to 0.1621. Saving model...\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2053\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1853\n",
      "    Batch [2/2], Val Loss: 0.1387\n",
      "Epoch [787/2000], Avg Train Loss: 0.2053, Avg Val Loss: 0.1620\n",
      "\n",
      "Validation loss improved from 0.1621 to 0.1620. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2023\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1851\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [788/2000], Avg Train Loss: 0.2023, Avg Val Loss: 0.1619\n",
      "\n",
      "Validation loss improved from 0.1620 to 0.1619. Saving model...\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2006\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1849\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [789/2000], Avg Train Loss: 0.2006, Avg Val Loss: 0.1617\n",
      "\n",
      "Validation loss improved from 0.1619 to 0.1617. Saving model...\n",
      "LOG: Epoch [790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1988\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1847\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [790/2000], Avg Train Loss: 0.1988, Avg Val Loss: 0.1616\n",
      "\n",
      "Validation loss improved from 0.1617 to 0.1616. Saving model...\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2004\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1845\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [791/2000], Avg Train Loss: 0.2004, Avg Val Loss: 0.1615\n",
      "\n",
      "Validation loss improved from 0.1616 to 0.1615. Saving model...\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1843\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [792/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1613\n",
      "\n",
      "Validation loss improved from 0.1615 to 0.1613. Saving model...\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2018\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1843\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [793/2000], Avg Train Loss: 0.2018, Avg Val Loss: 0.1613\n",
      "\n",
      "Validation loss improved from 0.1613 to 0.1613. Saving model...\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2005\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1842\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [794/2000], Avg Train Loss: 0.2005, Avg Val Loss: 0.1612\n",
      "\n",
      "Validation loss improved from 0.1613 to 0.1612. Saving model...\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1982\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1841\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [795/2000], Avg Train Loss: 0.1982, Avg Val Loss: 0.1612\n",
      "\n",
      "Validation loss improved from 0.1612 to 0.1612. Saving model...\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2024\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1841\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [796/2000], Avg Train Loss: 0.2024, Avg Val Loss: 0.1611\n",
      "\n",
      "Validation loss improved from 0.1612 to 0.1611. Saving model...\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1978\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1839\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [797/2000], Avg Train Loss: 0.1978, Avg Val Loss: 0.1610\n",
      "\n",
      "Validation loss improved from 0.1611 to 0.1610. Saving model...\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1989\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1837\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [798/2000], Avg Train Loss: 0.1989, Avg Val Loss: 0.1609\n",
      "\n",
      "Validation loss improved from 0.1610 to 0.1609. Saving model...\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1837\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [799/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1610\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [800/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1611\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1389\n",
      "Epoch [801/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1612\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2023\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1392\n",
      "Epoch [802/2000], Avg Train Loss: 0.2023, Avg Val Loss: 0.1613\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1394\n",
      "Epoch [803/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1614\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1396\n",
      "Epoch [804/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1616\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1398\n",
      "Epoch [805/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1617\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1838\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [806/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1619\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1838\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [807/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1620\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1988\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1838\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [808/2000], Avg Train Loss: 0.1988, Avg Val Loss: 0.1621\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1996\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1838\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [809/2000], Avg Train Loss: 0.1996, Avg Val Loss: 0.1622\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2011\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1839\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [810/2000], Avg Train Loss: 0.2011, Avg Val Loss: 0.1622\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1983\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1842\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [811/2000], Avg Train Loss: 0.1983, Avg Val Loss: 0.1622\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1995\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1844\n",
      "    Batch [2/2], Val Loss: 0.1400\n",
      "Epoch [812/2000], Avg Train Loss: 0.1995, Avg Val Loss: 0.1622\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1996\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1845\n",
      "    Batch [2/2], Val Loss: 0.1397\n",
      "Epoch [813/2000], Avg Train Loss: 0.1996, Avg Val Loss: 0.1621\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1991\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1846\n",
      "    Batch [2/2], Val Loss: 0.1396\n",
      "Epoch [814/2000], Avg Train Loss: 0.1991, Avg Val Loss: 0.1621\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1848\n",
      "    Batch [2/2], Val Loss: 0.1396\n",
      "Epoch [815/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1622\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2007\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1850\n",
      "    Batch [2/2], Val Loss: 0.1396\n",
      "Epoch [816/2000], Avg Train Loss: 0.2007, Avg Val Loss: 0.1623\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1851\n",
      "    Batch [2/2], Val Loss: 0.1395\n",
      "Epoch [817/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1623\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1852\n",
      "    Batch [2/2], Val Loss: 0.1395\n",
      "Epoch [818/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1623\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1852\n",
      "    Batch [2/2], Val Loss: 0.1394\n",
      "Epoch [819/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1623\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1963\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1851\n",
      "    Batch [2/2], Val Loss: 0.1393\n",
      "Epoch [820/2000], Avg Train Loss: 0.1963, Avg Val Loss: 0.1622\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1850\n",
      "    Batch [2/2], Val Loss: 0.1391\n",
      "Epoch [821/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1620\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1849\n",
      "    Batch [2/2], Val Loss: 0.1389\n",
      "Epoch [822/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1619\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1849\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [823/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1618\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1849\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [824/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1617\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1847\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [825/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.1616\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1846\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [826/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1615\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1977\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1845\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [827/2000], Avg Train Loss: 0.1977, Avg Val Loss: 0.1614\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1844\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [828/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1612\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1978\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1843\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [829/2000], Avg Train Loss: 0.1978, Avg Val Loss: 0.1611\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1842\n",
      "    Batch [2/2], Val Loss: 0.1379\n",
      "Epoch [830/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1611\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1989\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1841\n",
      "    Batch [2/2], Val Loss: 0.1378\n",
      "Epoch [831/2000], Avg Train Loss: 0.1989, Avg Val Loss: 0.1610\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1841\n",
      "    Batch [2/2], Val Loss: 0.1378\n",
      "Epoch [832/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1609\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1840\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [833/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1608\n",
      "\n",
      "Validation loss improved from 0.1609 to 0.1608. Saving model...\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1988\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1840\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [834/2000], Avg Train Loss: 0.1988, Avg Val Loss: 0.1608\n",
      "\n",
      "Validation loss improved from 0.1608 to 0.1608. Saving model...\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1839\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [835/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1608\n",
      "\n",
      "Validation loss improved from 0.1608 to 0.1608. Saving model...\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1839\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [836/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1607\n",
      "\n",
      "Validation loss improved from 0.1608 to 0.1607. Saving model...\n",
      "LOG: Epoch [837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1838\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [837/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1607\n",
      "\n",
      "Validation loss improved from 0.1607 to 0.1607. Saving model...\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1838\n",
      "    Batch [2/2], Val Loss: 0.1374\n",
      "Epoch [838/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1606\n",
      "\n",
      "Validation loss improved from 0.1607 to 0.1606. Saving model...\n",
      "LOG: Epoch [839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1837\n",
      "    Batch [2/2], Val Loss: 0.1374\n",
      "Epoch [839/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1606\n",
      "\n",
      "Validation loss improved from 0.1606 to 0.1606. Saving model...\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1837\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [840/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1605\n",
      "\n",
      "Validation loss improved from 0.1606 to 0.1605. Saving model...\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1837\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [841/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1605\n",
      "\n",
      "Validation loss improved from 0.1605 to 0.1605. Saving model...\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [842/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1605 to 0.1604. Saving model...\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [843/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [844/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [845/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2002\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [846/2000], Avg Train Loss: 0.2002, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [847/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [848/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1994\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [849/2000], Avg Train Loss: 0.1994, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1864\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [850/2000], Avg Train Loss: 0.1864, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1990\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [851/2000], Avg Train Loss: 0.1990, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [852/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [853/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [854/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2013\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [855/2000], Avg Train Loss: 0.2013, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [856/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [857/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [858/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1885\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [859/2000], Avg Train Loss: 0.1885, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [860/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [861/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [862/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [863/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1969\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [864/2000], Avg Train Loss: 0.1969, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [865/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1980\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [866/2000], Avg Train Loss: 0.1980, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1836\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [867/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [868/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [869/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1888\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [870/2000], Avg Train Loss: 0.1888, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [871/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1971\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [872/2000], Avg Train Loss: 0.1971, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1604. Saving model...\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [873/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1603. Saving model...\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [874/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [875/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [876/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [877/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [878/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1896\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [879/2000], Avg Train Loss: 0.1896, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [880/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [881/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [882/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [883/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1603\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1603. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1884\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [884/2000], Avg Train Loss: 0.1884, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [885/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2012\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [886/2000], Avg Train Loss: 0.2012, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [887/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [888/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [889/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [890/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1603 to 0.1602. Saving model...\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1978\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [891/2000], Avg Train Loss: 0.1978, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1602. Saving model...\n",
      "LOG: Epoch [892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [892/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1602. Saving model...\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1999\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [893/2000], Avg Train Loss: 0.1999, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1602. Saving model...\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [894/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1602. Saving model...\n",
      "LOG: Epoch [895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1980\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [895/2000], Avg Train Loss: 0.1980, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1602. Saving model...\n",
      "LOG: Epoch [896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1984\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [896/2000], Avg Train Loss: 0.1984, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1601. Saving model...\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2005\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1833\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [897/2000], Avg Train Loss: 0.2005, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1833\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [898/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [899/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [900/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [901/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [902/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [903/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [904/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2004\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [905/2000], Avg Train Loss: 0.2004, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [906/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [907/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1872\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [908/2000], Avg Train Loss: 0.1872, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [909/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [910/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1980\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [911/2000], Avg Train Loss: 0.1980, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [912/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [913/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [914/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [915/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [916/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [917/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [918/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [919/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [920/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [921/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1871\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [922/2000], Avg Train Loss: 0.1871, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [923/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [924/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1883\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [925/2000], Avg Train Loss: 0.1883, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [926/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [927/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1979\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1835\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [928/2000], Avg Train Loss: 0.1979, Avg Val Loss: 0.1602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [929/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [930/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [931/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [932/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [933/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1977\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [934/2000], Avg Train Loss: 0.1977, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1979\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [935/2000], Avg Train Loss: 0.1979, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [936/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [937/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [938/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [939/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [940/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [941/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [942/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [943/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1983\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [944/2000], Avg Train Loss: 0.1983, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [945/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1855\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [946/2000], Avg Train Loss: 0.1855, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [947/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [948/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [949/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [950/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [951/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [952/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1909\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [953/2000], Avg Train Loss: 0.1909, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [954/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [955/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [956/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [957/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2020\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [958/2000], Avg Train Loss: 0.2020, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [959/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [960/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [961/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [962/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1878\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [963/2000], Avg Train Loss: 0.1878, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [964/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [965/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [966/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [967/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1879\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [968/2000], Avg Train Loss: 0.1879, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [969/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [970/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [971/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [972/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [973/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1929\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [974/2000], Avg Train Loss: 0.1929, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [975/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [976/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [977/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [978/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [979/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [980/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [981/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [982/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1995\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [983/2000], Avg Train Loss: 0.1995, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [984/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [985/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [986/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [987/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [988/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [989/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [990/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [991/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1972\n",
      "LOG: Epoch [992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [992/2000], Avg Train Loss: 0.1972, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [993/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [994/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1895\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [995/2000], Avg Train Loss: 0.1895, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [996/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [997/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [998/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1897\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [999/2000], Avg Train Loss: 0.1897, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1000/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1001/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1001/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1002/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1002/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1003/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1004/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1004/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1005/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1006/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1006/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1007/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1007/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1007/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1008/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1008/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1009/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1979\n",
      "LOG: Epoch [1009/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1009/2000], Avg Train Loss: 0.1979, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1010/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1973\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1011/2000], Avg Train Loss: 0.1973, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1984\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1012/2000], Avg Train Loss: 0.1984, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1895\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1013/2000], Avg Train Loss: 0.1895, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1014/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1015/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1015/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1016/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1016/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1017/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1017/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1018/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1018/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1019/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1020/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1020/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1021/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1022/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1023/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1023/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1024/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1024/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1909\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1025/2000], Avg Train Loss: 0.1909, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1026/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1883\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1026/2000], Avg Train Loss: 0.1883, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1027/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1028/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1028/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1988\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1029/2000], Avg Train Loss: 0.1988, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1030/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1976\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1031/2000], Avg Train Loss: 0.1976, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1032/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1032/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1033/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1034/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1034/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1035/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1036/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1036/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1037/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1037/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1038/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1038/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1039/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1039/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1040/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1041/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1879\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1041/2000], Avg Train Loss: 0.1879, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1042/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1042/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1042/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1043/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1887\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1043/2000], Avg Train Loss: 0.1887, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1044/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1044/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1044/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1045/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1045/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1046/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1047/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1048/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1048/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1049/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1887\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1050/2000], Avg Train Loss: 0.1887, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [1051/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1051/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1052/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1052/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1053/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1054/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1054/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1997\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1055/2000], Avg Train Loss: 0.1997, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1056/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1056/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1057/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1058/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1058/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1889\n",
      "LOG: Epoch [1059/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1059/2000], Avg Train Loss: 0.1889, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1060/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1060/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1061/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1062/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1062/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1063/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1064/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1064/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1065/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1065/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1878\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1066/2000], Avg Train Loss: 0.1878, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1067/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1068/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1068/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1069/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1070/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1070/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1071/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1071/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1071/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1072/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1072/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1073/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1972\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1073/2000], Avg Train Loss: 0.1972, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1074/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1075/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1987\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1075/2000], Avg Train Loss: 0.1987, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1076/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1077/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1077/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1078/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1078/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1078/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1079/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1079/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1080/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1080/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1081/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1082/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2002\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1083/2000], Avg Train Loss: 0.2002, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1084/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1084/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1085/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1086/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1086/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1087/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1087/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1088/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1088/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1089/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1089/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1090/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1091/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1092/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1093/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1093/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1094/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1095/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1095/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1096/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1096/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1096/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1097/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1097/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1098/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1098/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1897\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1099/2000], Avg Train Loss: 0.1897, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1100/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1101/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1102/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1103/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1973\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1104/2000], Avg Train Loss: 0.1973, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [1105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1105/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1106/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1107/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1108/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1886\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1109/2000], Avg Train Loss: 0.1886, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1110/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1111/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1112/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1852\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1113/2000], Avg Train Loss: 0.1852, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1114/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1115/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1116/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1117/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1118/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1119/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1120/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1887\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1121/2000], Avg Train Loss: 0.1887, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1881\n",
      "LOG: Epoch [1122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1122/2000], Avg Train Loss: 0.1881, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1997\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1123/2000], Avg Train Loss: 0.1997, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1124/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1125/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1881\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1126/2000], Avg Train Loss: 0.1881, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2011\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1127/2000], Avg Train Loss: 0.2011, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1128/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1989\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1129/2000], Avg Train Loss: 0.1989, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1130/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1885\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1131/2000], Avg Train Loss: 0.1885, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1132/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1133/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1134/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1885\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1135/2000], Avg Train Loss: 0.1885, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1136/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1972\n",
      "LOG: Epoch [1137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1137/2000], Avg Train Loss: 0.1972, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1871\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1138/2000], Avg Train Loss: 0.1871, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1139/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1140/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1141/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1142/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1143/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1144/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1145/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1146/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1147/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1148/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1149/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1150/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1151/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1152/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1153/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1154/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1155/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1156/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1157/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1158/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1159/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1160/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1161/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1162/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1163/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1164/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1994\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1165/2000], Avg Train Loss: 0.1994, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [1166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1166/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1167/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1168/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1961\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1169/2000], Avg Train Loss: 0.1961, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1859\n",
      "LOG: Epoch [1170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1170/2000], Avg Train Loss: 0.1859, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1993\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1171/2000], Avg Train Loss: 0.1993, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1172/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1173/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1174/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1175/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1176/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1177/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1178/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1179/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1180/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1882\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1181/2000], Avg Train Loss: 0.1882, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1182/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1183/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1184/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1977\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1185/2000], Avg Train Loss: 0.1977, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1186/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1187/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1188/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1980\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1189/2000], Avg Train Loss: 0.1980, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1190/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1988\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1191/2000], Avg Train Loss: 0.1988, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1192/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1982\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1193/2000], Avg Train Loss: 0.1982, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1890\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1194/2000], Avg Train Loss: 0.1890, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1195/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1196/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1887\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1197/2000], Avg Train Loss: 0.1887, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1842\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1198/2000], Avg Train Loss: 0.1842, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1199/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1200/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1201/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1202/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1203/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1204/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1205/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [1206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1206/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1207/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [1208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1208/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1209/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1897\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1210/2000], Avg Train Loss: 0.1897, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1211/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1212/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [1213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1213/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1214/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1215/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2010\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1216/2000], Avg Train Loss: 0.2010, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1994\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1217/2000], Avg Train Loss: 0.1994, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1218/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1219/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [1220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1220/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1221/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1222/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1909\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1223/2000], Avg Train Loss: 0.1909, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1224/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1225/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1226/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1227/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1228/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1229/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1230/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1231/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [1232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1232/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1233/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1234/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1235/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1236/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1237/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1238/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1961\n",
      "LOG: Epoch [1239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1239/2000], Avg Train Loss: 0.1961, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1240/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1888\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1241/2000], Avg Train Loss: 0.1888, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1242/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1243/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1244/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1245/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1246/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1247/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1248/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1249/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1250/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1251/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1252/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1904\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1253/2000], Avg Train Loss: 0.1904, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1963\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1254/2000], Avg Train Loss: 0.1963, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1989\n",
      "LOG: Epoch [1255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1255/2000], Avg Train Loss: 0.1989, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1876\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1256/2000], Avg Train Loss: 0.1876, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1257/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1258/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1259/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1260/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1261/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1262/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1263/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [1264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1264/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1265/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1874\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1266/2000], Avg Train Loss: 0.1874, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1267/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1828\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1268/2000], Avg Train Loss: 0.1828, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [1269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1269/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1861\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1270/2000], Avg Train Loss: 0.1861, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1271/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1272/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1273/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1274/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1275/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1276/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1897\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1277/2000], Avg Train Loss: 0.1897, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1278/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1977\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1279/2000], Avg Train Loss: 0.1977, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1280/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1281/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1282/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1996\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1283/2000], Avg Train Loss: 0.1996, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1284/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1909\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1285/2000], Avg Train Loss: 0.1909, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1286/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [1287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1287/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1288/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2014\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1289/2000], Avg Train Loss: 0.2014, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1904\n",
      "LOG: Epoch [1290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1290/2000], Avg Train Loss: 0.1904, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1989\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1291/2000], Avg Train Loss: 0.1989, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1292/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1293/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1294/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1884\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1295/2000], Avg Train Loss: 0.1884, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1976\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1296/2000], Avg Train Loss: 0.1976, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1297/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1298/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [1299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1299/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1300/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1301/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1896\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1302/2000], Avg Train Loss: 0.1896, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1303/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1304/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1305/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1306/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1307/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1308/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1849\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1309/2000], Avg Train Loss: 0.1849, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1884\n",
      "LOG: Epoch [1310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1310/2000], Avg Train Loss: 0.1884, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1311/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1312/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1313/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1314/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1315/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1316/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1977\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1317/2000], Avg Train Loss: 0.1977, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1318/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1319/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1886\n",
      "LOG: Epoch [1320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1320/2000], Avg Train Loss: 0.1886, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1321/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1322/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1323/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1892\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1324/2000], Avg Train Loss: 0.1892, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1325/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1326/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1327/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1328/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1329/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1330/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1331/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1332/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1333/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1334/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1335/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1336/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1337/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1989\n",
      "LOG: Epoch [1338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1338/2000], Avg Train Loss: 0.1989, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1339/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1340/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1341/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1342/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1343/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2015\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1344/2000], Avg Train Loss: 0.2015, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1345/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1346/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1981\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1347/2000], Avg Train Loss: 0.1981, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1348/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1349/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1350/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1351/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [1352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1352/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1984\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1353/2000], Avg Train Loss: 0.1984, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1354/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1897\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1355/2000], Avg Train Loss: 0.1897, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1356/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1973\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1357/2000], Avg Train Loss: 0.1973, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1358/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2007\n",
      "LOG: Epoch [1359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1359/2000], Avg Train Loss: 0.2007, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1360/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1361/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1892\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1362/2000], Avg Train Loss: 0.1892, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1363/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1966\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1364/2000], Avg Train Loss: 0.1966, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1365/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1366/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1892\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1367/2000], Avg Train Loss: 0.1892, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [1368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1368/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1369/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1883\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1370/2000], Avg Train Loss: 0.1883, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1371/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1372/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1929\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1373/2000], Avg Train Loss: 0.1929, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1886\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1374/2000], Avg Train Loss: 0.1886, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1375/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1376/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1377/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1378/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1379/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1380/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [1381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1381/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1382/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1976\n",
      "LOG: Epoch [1383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1383/2000], Avg Train Loss: 0.1976, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1384/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1385/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1987\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1386/2000], Avg Train Loss: 0.1987, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1387/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1388/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1389/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [1390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1390/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1972\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1391/2000], Avg Train Loss: 0.1972, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1994\n",
      "LOG: Epoch [1392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1392/2000], Avg Train Loss: 0.1994, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1393/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1394/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1395/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1396/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1397/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1971\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1398/2000], Avg Train Loss: 0.1971, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1399/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1400/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1401/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1402/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1403/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1404/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1405/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [1406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1406/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1407/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1992\n",
      "LOG: Epoch [1408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1408/2000], Avg Train Loss: 0.1992, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2002\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1409/2000], Avg Train Loss: 0.2002, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [1410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1410/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1411/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1412/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1413/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1414/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1415/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1416/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1417/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1869\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1418/2000], Avg Train Loss: 0.1869, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1419/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1420/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1909\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1421/2000], Avg Train Loss: 0.1909, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1422/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [1423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1423/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1424/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1425/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1426/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [1427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1427/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1428/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1429/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1430/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1431/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1872\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1432/2000], Avg Train Loss: 0.1872, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1433/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1434/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1868\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1435/2000], Avg Train Loss: 0.1868, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1436/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1437/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [1438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1438/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1439/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1440/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1857\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1441/2000], Avg Train Loss: 0.1857, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1442/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1443/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1444/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1445/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1446/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1447/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2018\n",
      "LOG: Epoch [1448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1448/2000], Avg Train Loss: 0.2018, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1449/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1450/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1451/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1452/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [1453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1453/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1454/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1455/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1890\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1456/2000], Avg Train Loss: 0.1890, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1457/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1458/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1459/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1460/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1461/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1847\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1462/2000], Avg Train Loss: 0.1847, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1463/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [1464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1967\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1464/2000], Avg Train Loss: 0.1967, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1465/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [1466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1466/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1467/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [1468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1468/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1469/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [1470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1470/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "LOG: Epoch [1471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1471/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "LOG: Epoch [1472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1472/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [1473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1473/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "LOG: Epoch [1474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1474/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1475/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1942\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1476/2000], Avg Train Loss: 0.1942, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1886\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1477/2000], Avg Train Loss: 0.1886, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "LOG: Epoch [1478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1998\n",
      "LOG: Epoch [1478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1478/2000], Avg Train Loss: 0.1998, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "LOG: Epoch [1479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1479/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "LOG: Epoch [1480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [1480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1480/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "LOG: Epoch [1481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1481/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "LOG: Epoch [1482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1482/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "LOG: Epoch [1483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1981\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1483/2000], Avg Train Loss: 0.1981, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "LOG: Epoch [1484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1484/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "LOG: Epoch [1485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1485/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "LOG: Epoch [1486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1961\n",
      "LOG: Epoch [1486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1486/2000], Avg Train Loss: 0.1961, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "LOG: Epoch [1487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1487/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "LOG: Epoch [1488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1488/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1489/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "LOG: Epoch [1490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1490/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "LOG: Epoch [1491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [1491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1491/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1492/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1963\n",
      "LOG: Epoch [1493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1493/2000], Avg Train Loss: 0.1963, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1880\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1494/2000], Avg Train Loss: 0.1880, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1495/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1496/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1497/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1498/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1499/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1500/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1501/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1882\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1502/2000], Avg Train Loss: 0.1882, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1503/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1504/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [1505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1505/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1883\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1506/2000], Avg Train Loss: 0.1883, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1507/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1508/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1509/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1874\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1510/2000], Avg Train Loss: 0.1874, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1511/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1512/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1874\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1513/2000], Avg Train Loss: 0.1874, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1514/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1515/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1516/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1517/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1518/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1519/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1520/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1969\n",
      "LOG: Epoch [1521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1521/2000], Avg Train Loss: 0.1969, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2002\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1522/2000], Avg Train Loss: 0.2002, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1890\n",
      "LOG: Epoch [1523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1523/2000], Avg Train Loss: 0.1890, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1929\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1524/2000], Avg Train Loss: 0.1929, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1525/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1895\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1526/2000], Avg Train Loss: 0.1895, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1527/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1528/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [1529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1529/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1530/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1531/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1900\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1532/2000], Avg Train Loss: 0.1900, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1977\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1533/2000], Avg Train Loss: 0.1977, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1534/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1993\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1535/2000], Avg Train Loss: 0.1993, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1981\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1536/2000], Avg Train Loss: 0.1981, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [1537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1537/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1896\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1538/2000], Avg Train Loss: 0.1896, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1539/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1540/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1902\n",
      "LOG: Epoch [1541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1541/2000], Avg Train Loss: 0.1902, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1542/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1543/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1544/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1545/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1973\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1546/2000], Avg Train Loss: 0.1973, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1985\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1547/2000], Avg Train Loss: 0.1985, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1548/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1549/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1550/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1551/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1552/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1982\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1553/2000], Avg Train Loss: 0.1982, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1554/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1555/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2035\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1556/2000], Avg Train Loss: 0.2035, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1557/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1558/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1988\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1559/2000], Avg Train Loss: 0.1988, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1560/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1561/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1562/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1563/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1564/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1565/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1566/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1567/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1568/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1569/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1889\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1570/2000], Avg Train Loss: 0.1889, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1571/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1572/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [1573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1573/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1574/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [1575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1575/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1576/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1577/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1578/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1579/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1580/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1581/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1582/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1583/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1584/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1585/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1995\n",
      "LOG: Epoch [1586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1586/2000], Avg Train Loss: 0.1995, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1971\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1587/2000], Avg Train Loss: 0.1971, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1588/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1589/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1590/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1985\n",
      "LOG: Epoch [1591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1591/2000], Avg Train Loss: 0.1985, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1892\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1592/2000], Avg Train Loss: 0.1892, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1593/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1594/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1595/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1596/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1597/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1598/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1599/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1995\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1600/2000], Avg Train Loss: 0.1995, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1601/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1894\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1602/2000], Avg Train Loss: 0.1894, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1943\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1603/2000], Avg Train Loss: 0.1943, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1604/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1605/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1606/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1607/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1608/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1609/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1955\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1610/2000], Avg Train Loss: 0.1955, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1908\n",
      "LOG: Epoch [1611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1611/2000], Avg Train Loss: 0.1908, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1612/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1941\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1613/2000], Avg Train Loss: 0.1941, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1881\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1614/2000], Avg Train Loss: 0.1881, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1963\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1615/2000], Avg Train Loss: 0.1963, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1616/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1601. Saving model...\n",
      "LOG: Epoch [1617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1617/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1618/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1619/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1620/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1969\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1621/2000], Avg Train Loss: 0.1969, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1622/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1994\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1623/2000], Avg Train Loss: 0.1994, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1964\n",
      "LOG: Epoch [1624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1624/2000], Avg Train Loss: 0.1964, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1928\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1625/2000], Avg Train Loss: 0.1928, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1626/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1627/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1628/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1971\n",
      "LOG: Epoch [1629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1629/2000], Avg Train Loss: 0.1971, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1630/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1631/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1951\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1632/2000], Avg Train Loss: 0.1951, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1633/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1634/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1635/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1636/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1973\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1637/2000], Avg Train Loss: 0.1973, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1638/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1855\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1639/2000], Avg Train Loss: 0.1855, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1936\n",
      "LOG: Epoch [1640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1640/2000], Avg Train Loss: 0.1936, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1641/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1909\n",
      "LOG: Epoch [1642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1642/2000], Avg Train Loss: 0.1909, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1643/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1904\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1644/2000], Avg Train Loss: 0.1904, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1991\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1645/2000], Avg Train Loss: 0.1991, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1646/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [1647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1647/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1887\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1648/2000], Avg Train Loss: 0.1887, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [1649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1649/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1913\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1650/2000], Avg Train Loss: 0.1913, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1651/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1652/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1653/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [1654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1654/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1655/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1924\n",
      "LOG: Epoch [1656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1656/2000], Avg Train Loss: 0.1924, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1657/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1658/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2001\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1659/2000], Avg Train Loss: 0.2001, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1660/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1661/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1944\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1662/2000], Avg Train Loss: 0.1944, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1917\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1663/2000], Avg Train Loss: 0.1917, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1664/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1665/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1666/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1667/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1668/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1669/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1922\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1670/2000], Avg Train Loss: 0.1922, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1843\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1671/2000], Avg Train Loss: 0.1843, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1954\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1672/2000], Avg Train Loss: 0.1954, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1673/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1674/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1953\n",
      "LOG: Epoch [1675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1675/2000], Avg Train Loss: 0.1953, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1676/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1677/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1990\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1678/2000], Avg Train Loss: 0.1990, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1679/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [1680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1680/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1962\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1681/2000], Avg Train Loss: 0.1962, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1682/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1683/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1684/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1685/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1907\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1686/2000], Avg Train Loss: 0.1907, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2005\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1687/2000], Avg Train Loss: 0.2005, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1911\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1688/2000], Avg Train Loss: 0.1911, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1689/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [1690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1690/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [1691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1691/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [1692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1692/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1896\n",
      "LOG: Epoch [1693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1693/2000], Avg Train Loss: 0.1896, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [1694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1694/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "LOG: Epoch [1695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1695/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1696/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "LOG: Epoch [1697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1697/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1939\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1698/2000], Avg Train Loss: 0.1939, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "LOG: Epoch [1699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1862\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1699/2000], Avg Train Loss: 0.1862, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "LOG: Epoch [1700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [1700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1700/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1876\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1701/2000], Avg Train Loss: 0.1876, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1893\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1702/2000], Avg Train Loss: 0.1893, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "LOG: Epoch [1703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1703/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1978\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1704/2000], Avg Train Loss: 0.1978, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "LOG: Epoch [1705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1969\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1705/2000], Avg Train Loss: 0.1969, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1958\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1706/2000], Avg Train Loss: 0.1958, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "LOG: Epoch [1707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1945\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1707/2000], Avg Train Loss: 0.1945, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "LOG: Epoch [1708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [1708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1708/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "LOG: Epoch [1709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1709/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "LOG: Epoch [1710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [1710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1710/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1711/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1927\n",
      "LOG: Epoch [1712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1712/2000], Avg Train Loss: 0.1927, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "LOG: Epoch [1713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1848\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1713/2000], Avg Train Loss: 0.1848, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "LOG: Epoch [1714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1919\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1714/2000], Avg Train Loss: 0.1919, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1906\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1715/2000], Avg Train Loss: 0.1906, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "LOG: Epoch [1716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1874\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.1834\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1716/2000], Avg Train Loss: 0.1874, Avg Val Loss: 0.1601\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 1716!!\n",
      "No improvement for 100 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:00.839160Z",
     "iopub.status.busy": "2025-05-09T02:15:00.838161Z",
     "iopub.status.idle": "2025-05-09T02:15:04.194932Z",
     "shell.execute_reply": "2025-05-09T02:15:04.194932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/840], Loss: 0.0450\n",
      "Test Batch [20/840], Loss: 0.1472\n",
      "Test Batch [30/840], Loss: 0.1263\n",
      "Test Batch [40/840], Loss: 0.5000\n",
      "Test Batch [50/840], Loss: 0.1225\n",
      "Test Batch [60/840], Loss: 0.0799\n",
      "Test Batch [70/840], Loss: 0.0943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [80/840], Loss: 0.5000\n",
      "Test Batch [90/840], Loss: 0.1213\n",
      "Test Batch [100/840], Loss: 0.1872\n",
      "Test Batch [110/840], Loss: 0.5000\n",
      "Test Batch [120/840], Loss: 0.1264\n",
      "Test Batch [130/840], Loss: 0.1308\n",
      "Test Batch [140/840], Loss: 0.1169\n",
      "Test Batch [150/840], Loss: 0.1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [160/840], Loss: 0.2112\n",
      "Test Batch [170/840], Loss: 0.0734\n",
      "Test Batch [180/840], Loss: 0.0836\n",
      "Test Batch [190/840], Loss: 0.0828\n",
      "Test Batch [200/840], Loss: 0.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [210/840], Loss: 0.0747\n",
      "Test Batch [220/840], Loss: 0.0827\n",
      "Test Batch [230/840], Loss: 0.0908\n",
      "Test Batch [240/840], Loss: 0.0872\n",
      "Test Batch [250/840], Loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [260/840], Loss: 0.2289\n",
      "Test Batch [270/840], Loss: 0.2753\n",
      "Test Batch [280/840], Loss: 0.2863\n",
      "Test Batch [290/840], Loss: 0.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [300/840], Loss: 0.2233\n",
      "Test Batch [310/840], Loss: 0.2319\n",
      "Test Batch [320/840], Loss: 0.1168\n",
      "Test Batch [330/840], Loss: 0.1989\n",
      "Test Batch [340/840], Loss: 0.1917\n",
      "Test Batch [350/840], Loss: 0.5000\n",
      "Test Batch [360/840], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [370/840], Loss: 0.5000\n",
      "Test Batch [380/840], Loss: 0.5000\n",
      "Test Batch [390/840], Loss: 0.5000\n",
      "Test Batch [400/840], Loss: 0.5000\n",
      "Test Batch [410/840], Loss: 0.5000\n",
      "Test Batch [420/840], Loss: 0.5000\n",
      "Test Batch [430/840], Loss: 0.0783\n",
      "Test Batch [440/840], Loss: 0.1077\n",
      "Test Batch [450/840], Loss: 0.1571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [460/840], Loss: 0.0601\n",
      "Test Batch [470/840], Loss: 0.0983\n",
      "Test Batch [480/840], Loss: 0.1216\n",
      "Test Batch [490/840], Loss: 0.5000\n",
      "Test Batch [500/840], Loss: 0.0696\n",
      "Test Batch [510/840], Loss: 0.0806\n",
      "Test Batch [520/840], Loss: 0.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [530/840], Loss: 0.1523\n",
      "Test Batch [540/840], Loss: 0.1264\n",
      "Test Batch [550/840], Loss: 0.1280\n",
      "Test Batch [560/840], Loss: 0.1277\n",
      "Test Batch [570/840], Loss: 0.1269\n",
      "Test Batch [580/840], Loss: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [590/840], Loss: 0.1044\n",
      "Test Batch [600/840], Loss: 0.5000\n",
      "Test Batch [610/840], Loss: 0.1252\n",
      "Test Batch [620/840], Loss: 0.0928\n",
      "Test Batch [630/840], Loss: 0.1350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [640/840], Loss: 0.0509\n",
      "Test Batch [650/840], Loss: 0.1829\n",
      "Test Batch [660/840], Loss: 0.3879\n",
      "Test Batch [670/840], Loss: 0.0821\n",
      "Test Batch [680/840], Loss: 0.0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [690/840], Loss: 0.2928\n",
      "Test Batch [700/840], Loss: 0.2545\n",
      "Test Batch [710/840], Loss: 0.0965\n",
      "Test Batch [720/840], Loss: 0.1144\n",
      "Test Batch [730/840], Loss: 0.0754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [740/840], Loss: 0.1661\n",
      "Test Batch [750/840], Loss: 0.0945\n",
      "Test Batch [760/840], Loss: 0.5000\n",
      "Test Batch [770/840], Loss: 0.1173\n",
      "Test Batch [780/840], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [790/840], Loss: 0.2138\n",
      "Test Batch [800/840], Loss: 0.0879\n",
      "Test Batch [810/840], Loss: 0.5000\n",
      "Test Batch [820/840], Loss: 0.1446\n",
      "Test Batch [830/840], Loss: 0.5000\n",
      "Test Batch [840/840], Loss: 0.1743\n",
      "\n",
      "Test Loss: 0.1992\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:04.197946Z",
     "iopub.status.busy": "2025-05-09T02:15:04.197946Z",
     "iopub.status.idle": "2025-05-09T02:15:10.328983Z",
     "shell.execute_reply": "2025-05-09T02:15:10.328983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/840 for test dataset.\n",
      "  Processed batch 20/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/840 for test dataset.\n",
      "  Processed batch 40/840 for test dataset.\n",
      "  Processed batch 50/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 60/840 for test dataset.\n",
      "  Processed batch 70/840 for test dataset.\n",
      "  Processed batch 80/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 90/840 for test dataset.\n",
      "  Processed batch 100/840 for test dataset.\n",
      "  Processed batch 110/840 for test dataset.\n",
      "  Processed batch 120/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 130/840 for test dataset.\n",
      "  Processed batch 140/840 for test dataset.\n",
      "  Processed batch 150/840 for test dataset.\n",
      "  Processed batch 160/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 170/840 for test dataset.\n",
      "  Processed batch 180/840 for test dataset.\n",
      "  Processed batch 190/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 200/840 for test dataset.\n",
      "  Processed batch 210/840 for test dataset.\n",
      "  Processed batch 220/840 for test dataset.\n",
      "  Processed batch 230/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 240/840 for test dataset.\n",
      "  Processed batch 250/840 for test dataset.\n",
      "  Processed batch 260/840 for test dataset.\n",
      "  Processed batch 270/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 280/840 for test dataset.\n",
      "  Processed batch 290/840 for test dataset.\n",
      "  Processed batch 300/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 310/840 for test dataset.\n",
      "  Processed batch 320/840 for test dataset.\n",
      "  Processed batch 330/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 340/840 for test dataset.\n",
      "  Processed batch 350/840 for test dataset.\n",
      "  Processed batch 360/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 370/840 for test dataset.\n",
      "  Processed batch 380/840 for test dataset.\n",
      "  Processed batch 390/840 for test dataset.\n",
      "  Processed batch 400/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 410/840 for test dataset.\n",
      "  Processed batch 420/840 for test dataset.\n",
      "  Processed batch 430/840 for test dataset.\n",
      "  Processed batch 440/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 450/840 for test dataset.\n",
      "  Processed batch 460/840 for test dataset.\n",
      "  Processed batch 470/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 480/840 for test dataset.\n",
      "  Processed batch 490/840 for test dataset.\n",
      "  Processed batch 500/840 for test dataset.\n",
      "  Processed batch 510/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 520/840 for test dataset.\n",
      "  Processed batch 530/840 for test dataset.\n",
      "  Processed batch 540/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 550/840 for test dataset.\n",
      "  Processed batch 560/840 for test dataset.\n",
      "  Processed batch 570/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 580/840 for test dataset.\n",
      "  Processed batch 590/840 for test dataset.\n",
      "  Processed batch 600/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 610/840 for test dataset.\n",
      "  Processed batch 620/840 for test dataset.\n",
      "  Processed batch 630/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 640/840 for test dataset.\n",
      "  Processed batch 650/840 for test dataset.\n",
      "  Processed batch 660/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 670/840 for test dataset.\n",
      "  Processed batch 680/840 for test dataset.\n",
      "  Processed batch 690/840 for test dataset.\n",
      "  Processed batch 700/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 710/840 for test dataset.\n",
      "  Processed batch 720/840 for test dataset.\n",
      "  Processed batch 730/840 for test dataset.\n",
      "  Processed batch 740/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 750/840 for test dataset.\n",
      "  Processed batch 760/840 for test dataset.\n",
      "  Processed batch 770/840 for test dataset.\n",
      "  Processed batch 780/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 790/840 for test dataset.\n",
      "  Processed batch 800/840 for test dataset.\n",
      "  Processed batch 810/840 for test dataset.\n",
      "  Processed batch 820/840 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 830/840 for test dataset.\n",
      "  Processed batch 840/840 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:10.331988Z",
     "iopub.status.busy": "2025-05-09T02:15:10.331988Z",
     "iopub.status.idle": "2025-05-09T02:15:10.336494Z",
     "shell.execute_reply": "2025-05-09T02:15:10.335990Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:10.338499Z",
     "iopub.status.busy": "2025-05-09T02:15:10.338499Z",
     "iopub.status.idle": "2025-05-09T02:15:17.176944Z",
     "shell.execute_reply": "2025-05-09T02:15:17.176944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (320, 128)\n",
      "Train labels shape: (320,)\n",
      "Val reps shape: (80, 128)\n",
      "Val labels shape: (80,)\n",
      "Test reps shape: (53729, 128)\n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:17.179948Z",
     "iopub.status.busy": "2025-05-09T02:15:17.179948Z",
     "iopub.status.idle": "2025-05-09T02:15:17.303686Z",
     "shell.execute_reply": "2025-05-09T02:15:17.303686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 90.00%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.50      0.60      0.55         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      0.40      0.57         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.71      1.00      0.83         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.50      0.40      0.44         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.90        80\n",
      "   macro avg       0.91      0.90      0.89        80\n",
      "weighted avg       0.91      0.90      0.89        80\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 83.99%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1984\n",
      "           1       1.00      0.97      0.98      3701\n",
      "           2       0.95      0.96      0.95      1951\n",
      "           3       1.00      0.99      0.99      1369\n",
      "           4       0.95      0.99      0.97      2653\n",
      "           5       1.00      0.99      1.00      3934\n",
      "           6       0.98      0.92      0.95      3554\n",
      "           7       0.74      0.69      0.71     11246\n",
      "           8       0.99      0.94      0.97      6178\n",
      "           9       0.87      0.77      0.81      3253\n",
      "          10       0.57      0.87      0.68      1043\n",
      "          11       0.85      0.98      0.91      1902\n",
      "          12       0.71      0.99      0.83       891\n",
      "          13       0.75      0.93      0.83      1045\n",
      "          14       0.59      0.60      0.60      7243\n",
      "          15       0.81      0.87      0.84      1782\n",
      "\n",
      "    accuracy                           0.84     53729\n",
      "   macro avg       0.86      0.90      0.88     53729\n",
      "weighted avg       0.84      0.84      0.84     53729\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:17.306897Z",
     "iopub.status.busy": "2025-05-09T02:15:17.305898Z",
     "iopub.status.idle": "2025-05-09T02:15:17.500895Z",
     "shell.execute_reply": "2025-05-09T02:15:17.500895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (320, 128)\n",
      "Train labels shape: (320,)\n",
      "Val reps shape: (80, 128)\n",
      "Val labels shape: (80,)\n",
      "Test reps shape: (53729, 128)\n",
      "Test labels shape: (53729,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:17.502900Z",
     "iopub.status.busy": "2025-05-09T02:15:17.502900Z",
     "iopub.status.idle": "2025-05-09T02:15:17.513402Z",
     "shell.execute_reply": "2025-05-09T02:15:17.512899Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:17.515407Z",
     "iopub.status.busy": "2025-05-09T02:15:17.515407Z",
     "iopub.status.idle": "2025-05-09T02:15:21.116667Z",
     "shell.execute_reply": "2025-05-09T02:15:21.116667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.8591  |  Val Loss: 2.8108\n",
      "Validation loss improved from inf to 2.8108.\n",
      "[Epoch 2/1000] Train Loss: 2.7879  |  Val Loss: 2.7480\n",
      "Validation loss improved from 2.8108 to 2.7480.\n",
      "[Epoch 3/1000] Train Loss: 2.7255  |  Val Loss: 2.6913\n",
      "Validation loss improved from 2.7480 to 2.6913.\n",
      "[Epoch 4/1000] Train Loss: 2.6671  |  Val Loss: 2.6411\n",
      "Validation loss improved from 2.6913 to 2.6411.\n",
      "[Epoch 5/1000] Train Loss: 2.6159  |  Val Loss: 2.5944\n",
      "Validation loss improved from 2.6411 to 2.5944.\n",
      "[Epoch 6/1000] Train Loss: 2.5683  |  Val Loss: 2.5508\n",
      "Validation loss improved from 2.5944 to 2.5508.\n",
      "[Epoch 7/1000] Train Loss: 2.5246  |  Val Loss: 2.5114\n",
      "Validation loss improved from 2.5508 to 2.5114.\n",
      "[Epoch 8/1000] Train Loss: 2.4843  |  Val Loss: 2.4744\n",
      "Validation loss improved from 2.5114 to 2.4744.\n",
      "[Epoch 9/1000] Train Loss: 2.4458  |  Val Loss: 2.4393\n",
      "Validation loss improved from 2.4744 to 2.4393.\n",
      "[Epoch 10/1000] Train Loss: 2.4100  |  Val Loss: 2.4061\n",
      "Validation loss improved from 2.4393 to 2.4061.\n",
      "[Epoch 11/1000] Train Loss: 2.3746  |  Val Loss: 2.3749\n",
      "Validation loss improved from 2.4061 to 2.3749.\n",
      "[Epoch 12/1000] Train Loss: 2.3416  |  Val Loss: 2.3449\n",
      "Validation loss improved from 2.3749 to 2.3449.\n",
      "[Epoch 13/1000] Train Loss: 2.3096  |  Val Loss: 2.3162\n",
      "Validation loss improved from 2.3449 to 2.3162.\n",
      "[Epoch 14/1000] Train Loss: 2.2792  |  Val Loss: 2.2883\n",
      "Validation loss improved from 2.3162 to 2.2883.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.2494  |  Val Loss: 2.2616\n",
      "Validation loss improved from 2.2883 to 2.2616.\n",
      "[Epoch 16/1000] Train Loss: 2.2213  |  Val Loss: 2.2359\n",
      "Validation loss improved from 2.2616 to 2.2359.\n",
      "[Epoch 17/1000] Train Loss: 2.1928  |  Val Loss: 2.2111\n",
      "Validation loss improved from 2.2359 to 2.2111.\n",
      "[Epoch 18/1000] Train Loss: 2.1664  |  Val Loss: 2.1865\n",
      "Validation loss improved from 2.2111 to 2.1865.\n",
      "[Epoch 19/1000] Train Loss: 2.1396  |  Val Loss: 2.1620\n",
      "Validation loss improved from 2.1865 to 2.1620.\n",
      "[Epoch 20/1000] Train Loss: 2.1128  |  Val Loss: 2.1382\n",
      "Validation loss improved from 2.1620 to 2.1382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/1000] Train Loss: 2.0869  |  Val Loss: 2.1146\n",
      "Validation loss improved from 2.1382 to 2.1146.\n",
      "[Epoch 22/1000] Train Loss: 2.0612  |  Val Loss: 2.0908\n",
      "Validation loss improved from 2.1146 to 2.0908.\n",
      "[Epoch 23/1000] Train Loss: 2.0357  |  Val Loss: 2.0672\n",
      "Validation loss improved from 2.0908 to 2.0672.\n",
      "[Epoch 24/1000] Train Loss: 2.0105  |  Val Loss: 2.0433\n",
      "Validation loss improved from 2.0672 to 2.0433.\n",
      "[Epoch 25/1000] Train Loss: 1.9844  |  Val Loss: 2.0195\n",
      "Validation loss improved from 2.0433 to 2.0195.\n",
      "[Epoch 26/1000] Train Loss: 1.9588  |  Val Loss: 1.9960\n",
      "Validation loss improved from 2.0195 to 1.9960.\n",
      "[Epoch 27/1000] Train Loss: 1.9324  |  Val Loss: 1.9724\n",
      "Validation loss improved from 1.9960 to 1.9724.\n",
      "[Epoch 28/1000] Train Loss: 1.9067  |  Val Loss: 1.9485\n",
      "Validation loss improved from 1.9724 to 1.9485.\n",
      "[Epoch 29/1000] Train Loss: 1.8803  |  Val Loss: 1.9243\n",
      "Validation loss improved from 1.9485 to 1.9243.\n",
      "[Epoch 30/1000] Train Loss: 1.8534  |  Val Loss: 1.8999\n",
      "Validation loss improved from 1.9243 to 1.8999.\n",
      "[Epoch 31/1000] Train Loss: 1.8267  |  Val Loss: 1.8755\n",
      "Validation loss improved from 1.8999 to 1.8755.\n",
      "[Epoch 32/1000] Train Loss: 1.8000  |  Val Loss: 1.8508\n",
      "Validation loss improved from 1.8755 to 1.8508.\n",
      "[Epoch 33/1000] Train Loss: 1.7731  |  Val Loss: 1.8263\n",
      "Validation loss improved from 1.8508 to 1.8263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 1.7464  |  Val Loss: 1.8020\n",
      "Validation loss improved from 1.8263 to 1.8020.\n",
      "[Epoch 35/1000] Train Loss: 1.7205  |  Val Loss: 1.7774\n",
      "Validation loss improved from 1.8020 to 1.7774.\n",
      "[Epoch 36/1000] Train Loss: 1.6935  |  Val Loss: 1.7528\n",
      "Validation loss improved from 1.7774 to 1.7528.\n",
      "[Epoch 37/1000] Train Loss: 1.6657  |  Val Loss: 1.7284\n",
      "Validation loss improved from 1.7528 to 1.7284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/1000] Train Loss: 1.6387  |  Val Loss: 1.7039\n",
      "Validation loss improved from 1.7284 to 1.7039.\n",
      "[Epoch 39/1000] Train Loss: 1.6118  |  Val Loss: 1.6790\n",
      "Validation loss improved from 1.7039 to 1.6790.\n",
      "[Epoch 40/1000] Train Loss: 1.5843  |  Val Loss: 1.6538\n",
      "Validation loss improved from 1.6790 to 1.6538.\n",
      "[Epoch 41/1000] Train Loss: 1.5567  |  Val Loss: 1.6286\n",
      "Validation loss improved from 1.6538 to 1.6286.\n",
      "[Epoch 42/1000] Train Loss: 1.5291  |  Val Loss: 1.6034\n",
      "Validation loss improved from 1.6286 to 1.6034.\n",
      "[Epoch 43/1000] Train Loss: 1.5020  |  Val Loss: 1.5779\n",
      "Validation loss improved from 1.6034 to 1.5779.\n",
      "[Epoch 44/1000] Train Loss: 1.4739  |  Val Loss: 1.5528\n",
      "Validation loss improved from 1.5779 to 1.5528.\n",
      "[Epoch 45/1000] Train Loss: 1.4465  |  Val Loss: 1.5273\n",
      "Validation loss improved from 1.5528 to 1.5273.\n",
      "[Epoch 46/1000] Train Loss: 1.4189  |  Val Loss: 1.5011\n",
      "Validation loss improved from 1.5273 to 1.5011.\n",
      "[Epoch 47/1000] Train Loss: 1.3901  |  Val Loss: 1.4755\n",
      "Validation loss improved from 1.5011 to 1.4755.\n",
      "[Epoch 48/1000] Train Loss: 1.3619  |  Val Loss: 1.4497\n",
      "Validation loss improved from 1.4755 to 1.4497.\n",
      "[Epoch 49/1000] Train Loss: 1.3338  |  Val Loss: 1.4242\n",
      "Validation loss improved from 1.4497 to 1.4242.\n",
      "[Epoch 50/1000] Train Loss: 1.3058  |  Val Loss: 1.3986\n",
      "Validation loss improved from 1.4242 to 1.3986.\n",
      "[Epoch 51/1000] Train Loss: 1.2779  |  Val Loss: 1.3733\n",
      "Validation loss improved from 1.3986 to 1.3733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/1000] Train Loss: 1.2496  |  Val Loss: 1.3480\n",
      "Validation loss improved from 1.3733 to 1.3480.\n",
      "[Epoch 53/1000] Train Loss: 1.2219  |  Val Loss: 1.3224\n",
      "Validation loss improved from 1.3480 to 1.3224.\n",
      "[Epoch 54/1000] Train Loss: 1.1935  |  Val Loss: 1.2971\n",
      "Validation loss improved from 1.3224 to 1.2971.\n",
      "[Epoch 55/1000] Train Loss: 1.1661  |  Val Loss: 1.2718\n",
      "Validation loss improved from 1.2971 to 1.2718.\n",
      "[Epoch 56/1000] Train Loss: 1.1387  |  Val Loss: 1.2469\n",
      "Validation loss improved from 1.2718 to 1.2469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] Train Loss: 1.1113  |  Val Loss: 1.2223\n",
      "Validation loss improved from 1.2469 to 1.2223.\n",
      "[Epoch 58/1000] Train Loss: 1.0847  |  Val Loss: 1.1990\n",
      "Validation loss improved from 1.2223 to 1.1990.\n",
      "[Epoch 59/1000] Train Loss: 1.0585  |  Val Loss: 1.1758\n",
      "Validation loss improved from 1.1990 to 1.1758.\n",
      "[Epoch 60/1000] Train Loss: 1.0333  |  Val Loss: 1.1526\n",
      "Validation loss improved from 1.1758 to 1.1526.\n",
      "[Epoch 61/1000] Train Loss: 1.0083  |  Val Loss: 1.1299\n",
      "Validation loss improved from 1.1526 to 1.1299.\n",
      "[Epoch 62/1000] Train Loss: 0.9832  |  Val Loss: 1.1076\n",
      "Validation loss improved from 1.1299 to 1.1076.\n",
      "[Epoch 63/1000] Train Loss: 0.9592  |  Val Loss: 1.0858\n",
      "Validation loss improved from 1.1076 to 1.0858.\n",
      "[Epoch 64/1000] Train Loss: 0.9352  |  Val Loss: 1.0643\n",
      "Validation loss improved from 1.0858 to 1.0643.\n",
      "[Epoch 65/1000] Train Loss: 0.9121  |  Val Loss: 1.0434\n",
      "Validation loss improved from 1.0643 to 1.0434.\n",
      "[Epoch 66/1000] Train Loss: 0.8890  |  Val Loss: 1.0228\n",
      "Validation loss improved from 1.0434 to 1.0228.\n",
      "[Epoch 67/1000] Train Loss: 0.8665  |  Val Loss: 1.0023\n",
      "Validation loss improved from 1.0228 to 1.0023.\n",
      "[Epoch 68/1000] Train Loss: 0.8447  |  Val Loss: 0.9824\n",
      "Validation loss improved from 1.0023 to 0.9824.\n",
      "[Epoch 69/1000] Train Loss: 0.8234  |  Val Loss: 0.9628\n",
      "Validation loss improved from 0.9824 to 0.9628.\n",
      "[Epoch 70/1000] Train Loss: 0.8021  |  Val Loss: 0.9438\n",
      "Validation loss improved from 0.9628 to 0.9438.\n",
      "[Epoch 71/1000] Train Loss: 0.7817  |  Val Loss: 0.9255\n",
      "Validation loss improved from 0.9438 to 0.9255.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72/1000] Train Loss: 0.7611  |  Val Loss: 0.9074\n",
      "Validation loss improved from 0.9255 to 0.9074.\n",
      "[Epoch 73/1000] Train Loss: 0.7416  |  Val Loss: 0.8897\n",
      "Validation loss improved from 0.9074 to 0.8897.\n",
      "[Epoch 74/1000] Train Loss: 0.7221  |  Val Loss: 0.8723\n",
      "Validation loss improved from 0.8897 to 0.8723.\n",
      "[Epoch 75/1000] Train Loss: 0.7028  |  Val Loss: 0.8552\n",
      "Validation loss improved from 0.8723 to 0.8552.\n",
      "[Epoch 76/1000] Train Loss: 0.6839  |  Val Loss: 0.8384\n",
      "Validation loss improved from 0.8552 to 0.8384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 0.6658  |  Val Loss: 0.8221\n",
      "Validation loss improved from 0.8384 to 0.8221.\n",
      "[Epoch 78/1000] Train Loss: 0.6480  |  Val Loss: 0.8060\n",
      "Validation loss improved from 0.8221 to 0.8060.\n",
      "[Epoch 79/1000] Train Loss: 0.6304  |  Val Loss: 0.7902\n",
      "Validation loss improved from 0.8060 to 0.7902.\n",
      "[Epoch 80/1000] Train Loss: 0.6128  |  Val Loss: 0.7748\n",
      "Validation loss improved from 0.7902 to 0.7748.\n",
      "[Epoch 81/1000] Train Loss: 0.5961  |  Val Loss: 0.7599\n",
      "Validation loss improved from 0.7748 to 0.7599.\n",
      "[Epoch 82/1000] Train Loss: 0.5801  |  Val Loss: 0.7453\n",
      "Validation loss improved from 0.7599 to 0.7453.\n",
      "[Epoch 83/1000] Train Loss: 0.5638  |  Val Loss: 0.7309\n",
      "Validation loss improved from 0.7453 to 0.7309.\n",
      "[Epoch 84/1000] Train Loss: 0.5481  |  Val Loss: 0.7170\n",
      "Validation loss improved from 0.7309 to 0.7170.\n",
      "[Epoch 85/1000] Train Loss: 0.5326  |  Val Loss: 0.7035\n",
      "Validation loss improved from 0.7170 to 0.7035.\n",
      "[Epoch 86/1000] Train Loss: 0.5178  |  Val Loss: 0.6904\n",
      "Validation loss improved from 0.7035 to 0.6904.\n",
      "[Epoch 87/1000] Train Loss: 0.5035  |  Val Loss: 0.6773\n",
      "Validation loss improved from 0.6904 to 0.6773.\n",
      "[Epoch 88/1000] Train Loss: 0.4890  |  Val Loss: 0.6642\n",
      "Validation loss improved from 0.6773 to 0.6642.\n",
      "[Epoch 89/1000] Train Loss: 0.4747  |  Val Loss: 0.6514\n",
      "Validation loss improved from 0.6642 to 0.6514.\n",
      "[Epoch 90/1000] Train Loss: 0.4610  |  Val Loss: 0.6392\n",
      "Validation loss improved from 0.6514 to 0.6392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 91/1000] Train Loss: 0.4478  |  Val Loss: 0.6271\n",
      "Validation loss improved from 0.6392 to 0.6271.\n",
      "[Epoch 92/1000] Train Loss: 0.4350  |  Val Loss: 0.6155\n",
      "Validation loss improved from 0.6271 to 0.6155.\n",
      "[Epoch 93/1000] Train Loss: 0.4220  |  Val Loss: 0.6043\n",
      "Validation loss improved from 0.6155 to 0.6043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94/1000] Train Loss: 0.4096  |  Val Loss: 0.5935\n",
      "Validation loss improved from 0.6043 to 0.5935.\n",
      "[Epoch 95/1000] Train Loss: 0.3978  |  Val Loss: 0.5826\n",
      "Validation loss improved from 0.5935 to 0.5826.\n",
      "[Epoch 96/1000] Train Loss: 0.3864  |  Val Loss: 0.5722\n",
      "Validation loss improved from 0.5826 to 0.5722.\n",
      "[Epoch 97/1000] Train Loss: 0.3751  |  Val Loss: 0.5621\n",
      "Validation loss improved from 0.5722 to 0.5621.\n",
      "[Epoch 98/1000] Train Loss: 0.3647  |  Val Loss: 0.5521\n",
      "Validation loss improved from 0.5621 to 0.5521.\n",
      "[Epoch 99/1000] Train Loss: 0.3538  |  Val Loss: 0.5429\n",
      "Validation loss improved from 0.5521 to 0.5429.\n",
      "[Epoch 100/1000] Train Loss: 0.3441  |  Val Loss: 0.5337\n",
      "Validation loss improved from 0.5429 to 0.5337.\n",
      "[Epoch 101/1000] Train Loss: 0.3341  |  Val Loss: 0.5250\n",
      "Validation loss improved from 0.5337 to 0.5250.\n",
      "[Epoch 102/1000] Train Loss: 0.3248  |  Val Loss: 0.5164\n",
      "Validation loss improved from 0.5250 to 0.5164.\n",
      "[Epoch 103/1000] Train Loss: 0.3160  |  Val Loss: 0.5085\n",
      "Validation loss improved from 0.5164 to 0.5085.\n",
      "[Epoch 104/1000] Train Loss: 0.3074  |  Val Loss: 0.5002\n",
      "Validation loss improved from 0.5085 to 0.5002.\n",
      "[Epoch 105/1000] Train Loss: 0.2986  |  Val Loss: 0.4922\n",
      "Validation loss improved from 0.5002 to 0.4922.\n",
      "[Epoch 106/1000] Train Loss: 0.2907  |  Val Loss: 0.4845\n",
      "Validation loss improved from 0.4922 to 0.4845.\n",
      "[Epoch 107/1000] Train Loss: 0.2828  |  Val Loss: 0.4771\n",
      "Validation loss improved from 0.4845 to 0.4771.\n",
      "[Epoch 108/1000] Train Loss: 0.2752  |  Val Loss: 0.4702\n",
      "Validation loss improved from 0.4771 to 0.4702.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 109/1000] Train Loss: 0.2681  |  Val Loss: 0.4636\n",
      "Validation loss improved from 0.4702 to 0.4636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 110/1000] Train Loss: 0.2610  |  Val Loss: 0.4572\n",
      "Validation loss improved from 0.4636 to 0.4572.\n",
      "[Epoch 111/1000] Train Loss: 0.2545  |  Val Loss: 0.4512\n",
      "Validation loss improved from 0.4572 to 0.4512.\n",
      "[Epoch 112/1000] Train Loss: 0.2477  |  Val Loss: 0.4451\n",
      "Validation loss improved from 0.4512 to 0.4451.\n",
      "[Epoch 113/1000] Train Loss: 0.2416  |  Val Loss: 0.4394\n",
      "Validation loss improved from 0.4451 to 0.4394.\n",
      "[Epoch 114/1000] Train Loss: 0.2355  |  Val Loss: 0.4335\n",
      "Validation loss improved from 0.4394 to 0.4335.\n",
      "[Epoch 115/1000] Train Loss: 0.2296  |  Val Loss: 0.4279\n",
      "Validation loss improved from 0.4335 to 0.4279.\n",
      "[Epoch 116/1000] Train Loss: 0.2239  |  Val Loss: 0.4225\n",
      "Validation loss improved from 0.4279 to 0.4225.\n",
      "[Epoch 117/1000] Train Loss: 0.2183  |  Val Loss: 0.4173\n",
      "Validation loss improved from 0.4225 to 0.4173.\n",
      "[Epoch 118/1000] Train Loss: 0.2130  |  Val Loss: 0.4127\n",
      "Validation loss improved from 0.4173 to 0.4127.\n",
      "[Epoch 119/1000] Train Loss: 0.2081  |  Val Loss: 0.4081\n",
      "Validation loss improved from 0.4127 to 0.4081.\n",
      "[Epoch 120/1000] Train Loss: 0.2030  |  Val Loss: 0.4039\n",
      "Validation loss improved from 0.4081 to 0.4039.\n",
      "[Epoch 121/1000] Train Loss: 0.1985  |  Val Loss: 0.3998\n",
      "Validation loss improved from 0.4039 to 0.3998.\n",
      "[Epoch 122/1000] Train Loss: 0.1939  |  Val Loss: 0.3957\n",
      "Validation loss improved from 0.3998 to 0.3957.\n",
      "[Epoch 123/1000] Train Loss: 0.1894  |  Val Loss: 0.3918\n",
      "Validation loss improved from 0.3957 to 0.3918.\n",
      "[Epoch 124/1000] Train Loss: 0.1853  |  Val Loss: 0.3880\n",
      "Validation loss improved from 0.3918 to 0.3880.\n",
      "[Epoch 125/1000] Train Loss: 0.1812  |  Val Loss: 0.3843\n",
      "Validation loss improved from 0.3880 to 0.3843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/1000] Train Loss: 0.1774  |  Val Loss: 0.3812\n",
      "Validation loss improved from 0.3843 to 0.3812.\n",
      "[Epoch 127/1000] Train Loss: 0.1736  |  Val Loss: 0.3779\n",
      "Validation loss improved from 0.3812 to 0.3779.\n",
      "[Epoch 128/1000] Train Loss: 0.1701  |  Val Loss: 0.3747\n",
      "Validation loss improved from 0.3779 to 0.3747.\n",
      "[Epoch 129/1000] Train Loss: 0.1665  |  Val Loss: 0.3714\n",
      "Validation loss improved from 0.3747 to 0.3714.\n",
      "[Epoch 130/1000] Train Loss: 0.1631  |  Val Loss: 0.3684\n",
      "Validation loss improved from 0.3714 to 0.3684.\n",
      "[Epoch 131/1000] Train Loss: 0.1598  |  Val Loss: 0.3654\n",
      "Validation loss improved from 0.3684 to 0.3654.\n",
      "[Epoch 132/1000] Train Loss: 0.1567  |  Val Loss: 0.3624\n",
      "Validation loss improved from 0.3654 to 0.3624.\n",
      "[Epoch 133/1000] Train Loss: 0.1537  |  Val Loss: 0.3598\n",
      "Validation loss improved from 0.3624 to 0.3598.\n",
      "[Epoch 134/1000] Train Loss: 0.1507  |  Val Loss: 0.3571\n",
      "Validation loss improved from 0.3598 to 0.3571.\n",
      "[Epoch 135/1000] Train Loss: 0.1479  |  Val Loss: 0.3546\n",
      "Validation loss improved from 0.3571 to 0.3546.\n",
      "[Epoch 136/1000] Train Loss: 0.1451  |  Val Loss: 0.3523\n",
      "Validation loss improved from 0.3546 to 0.3523.\n",
      "[Epoch 137/1000] Train Loss: 0.1424  |  Val Loss: 0.3500\n",
      "Validation loss improved from 0.3523 to 0.3500.\n",
      "[Epoch 138/1000] Train Loss: 0.1398  |  Val Loss: 0.3477\n",
      "Validation loss improved from 0.3500 to 0.3477.\n",
      "[Epoch 139/1000] Train Loss: 0.1374  |  Val Loss: 0.3456\n",
      "Validation loss improved from 0.3477 to 0.3456.\n",
      "[Epoch 140/1000] Train Loss: 0.1349  |  Val Loss: 0.3436\n",
      "Validation loss improved from 0.3456 to 0.3436.\n",
      "[Epoch 141/1000] Train Loss: 0.1325  |  Val Loss: 0.3417\n",
      "Validation loss improved from 0.3436 to 0.3417.\n",
      "[Epoch 142/1000] Train Loss: 0.1302  |  Val Loss: 0.3400\n",
      "Validation loss improved from 0.3417 to 0.3400.\n",
      "[Epoch 143/1000] Train Loss: 0.1280  |  Val Loss: 0.3382\n",
      "Validation loss improved from 0.3400 to 0.3382.\n",
      "[Epoch 144/1000] Train Loss: 0.1259  |  Val Loss: 0.3365\n",
      "Validation loss improved from 0.3382 to 0.3365.\n",
      "[Epoch 145/1000] Train Loss: 0.1239  |  Val Loss: 0.3347\n",
      "Validation loss improved from 0.3365 to 0.3347.\n",
      "[Epoch 146/1000] Train Loss: 0.1217  |  Val Loss: 0.3331\n",
      "Validation loss improved from 0.3347 to 0.3331.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 147/1000] Train Loss: 0.1198  |  Val Loss: 0.3314\n",
      "Validation loss improved from 0.3331 to 0.3314.\n",
      "[Epoch 148/1000] Train Loss: 0.1179  |  Val Loss: 0.3299\n",
      "Validation loss improved from 0.3314 to 0.3299.\n",
      "[Epoch 149/1000] Train Loss: 0.1160  |  Val Loss: 0.3285\n",
      "Validation loss improved from 0.3299 to 0.3285.\n",
      "[Epoch 150/1000] Train Loss: 0.1142  |  Val Loss: 0.3271\n",
      "Validation loss improved from 0.3285 to 0.3271.\n",
      "[Epoch 151/1000] Train Loss: 0.1125  |  Val Loss: 0.3256\n",
      "Validation loss improved from 0.3271 to 0.3256.\n",
      "[Epoch 152/1000] Train Loss: 0.1108  |  Val Loss: 0.3244\n",
      "Validation loss improved from 0.3256 to 0.3244.\n",
      "[Epoch 153/1000] Train Loss: 0.1092  |  Val Loss: 0.3232\n",
      "Validation loss improved from 0.3244 to 0.3232.\n",
      "[Epoch 154/1000] Train Loss: 0.1076  |  Val Loss: 0.3221\n",
      "Validation loss improved from 0.3232 to 0.3221.\n",
      "[Epoch 155/1000] Train Loss: 0.1061  |  Val Loss: 0.3211\n",
      "Validation loss improved from 0.3221 to 0.3211.\n",
      "[Epoch 156/1000] Train Loss: 0.1046  |  Val Loss: 0.3200\n",
      "Validation loss improved from 0.3211 to 0.3200.\n",
      "[Epoch 157/1000] Train Loss: 0.1030  |  Val Loss: 0.3188\n",
      "Validation loss improved from 0.3200 to 0.3188.\n",
      "[Epoch 158/1000] Train Loss: 0.1016  |  Val Loss: 0.3179\n",
      "Validation loss improved from 0.3188 to 0.3179.\n",
      "[Epoch 159/1000] Train Loss: 0.1003  |  Val Loss: 0.3169\n",
      "Validation loss improved from 0.3179 to 0.3169.\n",
      "[Epoch 160/1000] Train Loss: 0.0988  |  Val Loss: 0.3160\n",
      "Validation loss improved from 0.3169 to 0.3160.\n",
      "[Epoch 161/1000] Train Loss: 0.0976  |  Val Loss: 0.3153\n",
      "Validation loss improved from 0.3160 to 0.3153.\n",
      "[Epoch 162/1000] Train Loss: 0.0963  |  Val Loss: 0.3144\n",
      "Validation loss improved from 0.3153 to 0.3144.\n",
      "[Epoch 163/1000] Train Loss: 0.0950  |  Val Loss: 0.3136\n",
      "Validation loss improved from 0.3144 to 0.3136.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 164/1000] Train Loss: 0.0937  |  Val Loss: 0.3129\n",
      "Validation loss improved from 0.3136 to 0.3129.\n",
      "[Epoch 165/1000] Train Loss: 0.0926  |  Val Loss: 0.3122\n",
      "Validation loss improved from 0.3129 to 0.3122.\n",
      "[Epoch 166/1000] Train Loss: 0.0913  |  Val Loss: 0.3116\n",
      "Validation loss improved from 0.3122 to 0.3116.\n",
      "[Epoch 167/1000] Train Loss: 0.0903  |  Val Loss: 0.3110\n",
      "Validation loss improved from 0.3116 to 0.3110.\n",
      "[Epoch 168/1000] Train Loss: 0.0892  |  Val Loss: 0.3103\n",
      "Validation loss improved from 0.3110 to 0.3103.\n",
      "[Epoch 169/1000] Train Loss: 0.0881  |  Val Loss: 0.3096\n",
      "Validation loss improved from 0.3103 to 0.3096.\n",
      "[Epoch 170/1000] Train Loss: 0.0870  |  Val Loss: 0.3090\n",
      "Validation loss improved from 0.3096 to 0.3090.\n",
      "[Epoch 171/1000] Train Loss: 0.0860  |  Val Loss: 0.3083\n",
      "Validation loss improved from 0.3090 to 0.3083.\n",
      "[Epoch 172/1000] Train Loss: 0.0850  |  Val Loss: 0.3078\n",
      "Validation loss improved from 0.3083 to 0.3078.\n",
      "[Epoch 173/1000] Train Loss: 0.0841  |  Val Loss: 0.3074\n",
      "Validation loss improved from 0.3078 to 0.3074.\n",
      "[Epoch 174/1000] Train Loss: 0.0832  |  Val Loss: 0.3066\n",
      "Validation loss improved from 0.3074 to 0.3066.\n",
      "[Epoch 175/1000] Train Loss: 0.0821  |  Val Loss: 0.3061\n",
      "Validation loss improved from 0.3066 to 0.3061.\n",
      "[Epoch 176/1000] Train Loss: 0.0811  |  Val Loss: 0.3058\n",
      "Validation loss improved from 0.3061 to 0.3058.\n",
      "[Epoch 177/1000] Train Loss: 0.0802  |  Val Loss: 0.3055\n",
      "Validation loss improved from 0.3058 to 0.3055.\n",
      "[Epoch 178/1000] Train Loss: 0.0794  |  Val Loss: 0.3051\n",
      "Validation loss improved from 0.3055 to 0.3051.\n",
      "[Epoch 179/1000] Train Loss: 0.0786  |  Val Loss: 0.3048\n",
      "Validation loss improved from 0.3051 to 0.3048.\n",
      "[Epoch 180/1000] Train Loss: 0.0777  |  Val Loss: 0.3045\n",
      "Validation loss improved from 0.3048 to 0.3045.\n",
      "[Epoch 181/1000] Train Loss: 0.0768  |  Val Loss: 0.3041\n",
      "Validation loss improved from 0.3045 to 0.3041.\n",
      "[Epoch 182/1000] Train Loss: 0.0761  |  Val Loss: 0.3035\n",
      "Validation loss improved from 0.3041 to 0.3035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 183/1000] Train Loss: 0.0753  |  Val Loss: 0.3033\n",
      "Validation loss improved from 0.3035 to 0.3033.\n",
      "[Epoch 184/1000] Train Loss: 0.0745  |  Val Loss: 0.3030\n",
      "Validation loss improved from 0.3033 to 0.3030.\n",
      "[Epoch 185/1000] Train Loss: 0.0738  |  Val Loss: 0.3029\n",
      "Validation loss improved from 0.3030 to 0.3029.\n",
      "[Epoch 186/1000] Train Loss: 0.0730  |  Val Loss: 0.3026\n",
      "Validation loss improved from 0.3029 to 0.3026.\n",
      "[Epoch 187/1000] Train Loss: 0.0723  |  Val Loss: 0.3021\n",
      "Validation loss improved from 0.3026 to 0.3021.\n",
      "[Epoch 188/1000] Train Loss: 0.0716  |  Val Loss: 0.3019\n",
      "Validation loss improved from 0.3021 to 0.3019.\n",
      "[Epoch 189/1000] Train Loss: 0.0709  |  Val Loss: 0.3016\n",
      "Validation loss improved from 0.3019 to 0.3016.\n",
      "[Epoch 190/1000] Train Loss: 0.0703  |  Val Loss: 0.3015\n",
      "Validation loss improved from 0.3016 to 0.3015.\n",
      "[Epoch 191/1000] Train Loss: 0.0696  |  Val Loss: 0.3016\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 192/1000] Train Loss: 0.0689  |  Val Loss: 0.3016\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 193/1000] Train Loss: 0.0682  |  Val Loss: 0.3015\n",
      "Validation loss improved from 0.3015 to 0.3015.\n",
      "[Epoch 194/1000] Train Loss: 0.0676  |  Val Loss: 0.3012\n",
      "Validation loss improved from 0.3015 to 0.3012.\n",
      "[Epoch 195/1000] Train Loss: 0.0670  |  Val Loss: 0.3011\n",
      "Validation loss improved from 0.3012 to 0.3011.\n",
      "[Epoch 196/1000] Train Loss: 0.0664  |  Val Loss: 0.3009\n",
      "Validation loss improved from 0.3011 to 0.3009.\n",
      "[Epoch 197/1000] Train Loss: 0.0658  |  Val Loss: 0.3010\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 198/1000] Train Loss: 0.0652  |  Val Loss: 0.3007\n",
      "Validation loss improved from 0.3009 to 0.3007.\n",
      "[Epoch 199/1000] Train Loss: 0.0647  |  Val Loss: 0.3004\n",
      "Validation loss improved from 0.3007 to 0.3004.\n",
      "[Epoch 200/1000] Train Loss: 0.0640  |  Val Loss: 0.3005\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Train Loss: 0.0635  |  Val Loss: 0.3006\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 202/1000] Train Loss: 0.0630  |  Val Loss: 0.3009\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 203/1000] Train Loss: 0.0624  |  Val Loss: 0.3011\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 204/1000] Train Loss: 0.0619  |  Val Loss: 0.3009\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 205/1000] Train Loss: 0.0614  |  Val Loss: 0.3007\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 206/1000] Train Loss: 0.0609  |  Val Loss: 0.3007\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 207/1000] Train Loss: 0.0603  |  Val Loss: 0.3005\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 208/1000] Train Loss: 0.0598  |  Val Loss: 0.3004\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 209/1000] Train Loss: 0.0593  |  Val Loss: 0.3004\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 210/1000] Train Loss: 0.0589  |  Val Loss: 0.3006\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 211/1000] Train Loss: 0.0584  |  Val Loss: 0.3009\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 212/1000] Train Loss: 0.0580  |  Val Loss: 0.3007\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 213/1000] Train Loss: 0.0574  |  Val Loss: 0.3009\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 214/1000] Train Loss: 0.0571  |  Val Loss: 0.3011\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 215/1000] Train Loss: 0.0565  |  Val Loss: 0.3011\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 216/1000] Train Loss: 0.0562  |  Val Loss: 0.3013\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 217/1000] Train Loss: 0.0557  |  Val Loss: 0.3016\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 218/1000] Train Loss: 0.0553  |  Val Loss: 0.3017\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 219/1000] Train Loss: 0.0549  |  Val Loss: 0.3019\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 220/1000] Train Loss: 0.0544  |  Val Loss: 0.3018\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 221/1000] Train Loss: 0.0541  |  Val Loss: 0.3023\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 222/1000] Train Loss: 0.0536  |  Val Loss: 0.3024\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 223/1000] Train Loss: 0.0533  |  Val Loss: 0.3026\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 224/1000] Train Loss: 0.0529  |  Val Loss: 0.3030\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 225/1000] Train Loss: 0.0525  |  Val Loss: 0.3030\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 226/1000] Train Loss: 0.0521  |  Val Loss: 0.3032\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 227/1000] Train Loss: 0.0518  |  Val Loss: 0.3033\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 228/1000] Train Loss: 0.0514  |  Val Loss: 0.3034\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 229/1000] Train Loss: 0.0511  |  Val Loss: 0.3039\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 230/1000] Train Loss: 0.0507  |  Val Loss: 0.3041\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 231/1000] Train Loss: 0.0503  |  Val Loss: 0.3041\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 232/1000] Train Loss: 0.0500  |  Val Loss: 0.3044\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 233/1000] Train Loss: 0.0496  |  Val Loss: 0.3047\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 234/1000] Train Loss: 0.0492  |  Val Loss: 0.3051\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 235/1000] Train Loss: 0.0489  |  Val Loss: 0.3053\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 236/1000] Train Loss: 0.0487  |  Val Loss: 0.3057\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 237/1000] Train Loss: 0.0483  |  Val Loss: 0.3057\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 238/1000] Train Loss: 0.0479  |  Val Loss: 0.3058\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 239/1000] Train Loss: 0.0476  |  Val Loss: 0.3061\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 240/1000] Train Loss: 0.0475  |  Val Loss: 0.3062\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 241/1000] Train Loss: 0.0470  |  Val Loss: 0.3066\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 242/1000] Train Loss: 0.0467  |  Val Loss: 0.3067\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 243/1000] Train Loss: 0.0464  |  Val Loss: 0.3068\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 244/1000] Train Loss: 0.0462  |  Val Loss: 0.3070\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 245/1000] Train Loss: 0.0458  |  Val Loss: 0.3074\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 246/1000] Train Loss: 0.0456  |  Val Loss: 0.3081\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 247/1000] Train Loss: 0.0453  |  Val Loss: 0.3081\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 248/1000] Train Loss: 0.0449  |  Val Loss: 0.3084\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 249/1000] Train Loss: 0.0447  |  Val Loss: 0.3084\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 250/1000] Train Loss: 0.0444  |  Val Loss: 0.3091\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 251/1000] Train Loss: 0.0442  |  Val Loss: 0.3095\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 252/1000] Train Loss: 0.0440  |  Val Loss: 0.3101\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 253/1000] Train Loss: 0.0436  |  Val Loss: 0.3104\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 254/1000] Train Loss: 0.0435  |  Val Loss: 0.3105\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 255/1000] Train Loss: 0.0431  |  Val Loss: 0.3108\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 256/1000] Train Loss: 0.0428  |  Val Loss: 0.3111\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 257/1000] Train Loss: 0.0426  |  Val Loss: 0.3111\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 258/1000] Train Loss: 0.0424  |  Val Loss: 0.3111\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 259/1000] Train Loss: 0.0420  |  Val Loss: 0.3115\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 260/1000] Train Loss: 0.0418  |  Val Loss: 0.3119\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 261/1000] Train Loss: 0.0416  |  Val Loss: 0.3122\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 262/1000] Train Loss: 0.0413  |  Val Loss: 0.3127\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 263/1000] Train Loss: 0.0412  |  Val Loss: 0.3131\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 264/1000] Train Loss: 0.0409  |  Val Loss: 0.3133\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 265/1000] Train Loss: 0.0406  |  Val Loss: 0.3136\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 266/1000] Train Loss: 0.0404  |  Val Loss: 0.3140\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 267/1000] Train Loss: 0.0402  |  Val Loss: 0.3141\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 268/1000] Train Loss: 0.0399  |  Val Loss: 0.3146\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 269/1000] Train Loss: 0.0397  |  Val Loss: 0.3152\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 270/1000] Train Loss: 0.0395  |  Val Loss: 0.3158\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 271/1000] Train Loss: 0.0394  |  Val Loss: 0.3166\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 272/1000] Train Loss: 0.0391  |  Val Loss: 0.3167\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 273/1000] Train Loss: 0.0389  |  Val Loss: 0.3169\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 274/1000] Train Loss: 0.0387  |  Val Loss: 0.3169\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 275/1000] Train Loss: 0.0384  |  Val Loss: 0.3175\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 276/1000] Train Loss: 0.0382  |  Val Loss: 0.3181\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 277/1000] Train Loss: 0.0382  |  Val Loss: 0.3181\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 278/1000] Train Loss: 0.0379  |  Val Loss: 0.3186\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 279/1000] Train Loss: 0.0376  |  Val Loss: 0.3187\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 280/1000] Train Loss: 0.0374  |  Val Loss: 0.3187\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 281/1000] Train Loss: 0.0372  |  Val Loss: 0.3195\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 282/1000] Train Loss: 0.0370  |  Val Loss: 0.3199\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 283/1000] Train Loss: 0.0369  |  Val Loss: 0.3205\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 284/1000] Train Loss: 0.0366  |  Val Loss: 0.3208\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 285/1000] Train Loss: 0.0365  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 286/1000] Train Loss: 0.0362  |  Val Loss: 0.3218\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 287/1000] Train Loss: 0.0361  |  Val Loss: 0.3220\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 288/1000] Train Loss: 0.0360  |  Val Loss: 0.3226\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 289/1000] Train Loss: 0.0357  |  Val Loss: 0.3231\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 290/1000] Train Loss: 0.0356  |  Val Loss: 0.3235\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 291/1000] Train Loss: 0.0354  |  Val Loss: 0.3239\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 292/1000] Train Loss: 0.0352  |  Val Loss: 0.3239\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 293/1000] Train Loss: 0.0351  |  Val Loss: 0.3239\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 294/1000] Train Loss: 0.0348  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 295/1000] Train Loss: 0.0347  |  Val Loss: 0.3250\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 296/1000] Train Loss: 0.0345  |  Val Loss: 0.3256\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 297/1000] Train Loss: 0.0343  |  Val Loss: 0.3262\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 298/1000] Train Loss: 0.0342  |  Val Loss: 0.3262\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 299/1000] Train Loss: 0.0340  |  Val Loss: 0.3273\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 299 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:21.119671Z",
     "iopub.status.busy": "2025-05-09T02:15:21.119671Z",
     "iopub.status.idle": "2025-05-09T02:15:21.977829Z",
     "shell.execute_reply": "2025-05-09T02:15:21.977829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.7508 | Test Accuracy: 84.25%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:21.980835Z",
     "iopub.status.busy": "2025-05-09T02:15:21.980835Z",
     "iopub.status.idle": "2025-05-09T02:15:21.987350Z",
     "shell.execute_reply": "2025-05-09T02:15:21.986843Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:21.990360Z",
     "iopub.status.busy": "2025-05-09T02:15:21.989356Z",
     "iopub.status.idle": "2025-05-09T02:15:27.396640Z",
     "shell.execute_reply": "2025-05-09T02:15:27.396124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzddVhUWQMG8HfoEAEBBVTAFUVFRQULsBMLu7u7dWWtFQO7sVtZxda1O1HXdkXsAJVOpWO+P/yYdSSHmLmj7+957vPIjXPfOfeCZ86ce0YkFovFICIiIiIiwVFRdAAiIiIiIsocG+tERERERALFxjoRERERkUCxsU5EREREJFBsrBMRERERCRQb60REREREAsXGOhERERGRQLGxTkREREQkUGysExEREREJFBvrREQKcOXKFTRq1AhFixaFSCSCSCTC+/fv5Xb+P//8EyKRCH/++afczvkra9iwIUQiEa5cuaLoKESkZNhYJ8qElZWVpAGV3bJjxw7JMWKxGDdu3MCUKVNQp04dGBgYQENDA+bm5ujUqRMuX76c5fnS/yPPaSmohtW///6LcePGoWrVqjA0NISGhgZKlCiBZs2aYcWKFQgPD5fa/8qVK5IMZmZmiI+Pz7Tcjx8/SvbL7jWuXLkyy2yDBw/O12tNS0vDvn370KVLF1haWkJHRwe6urooV64cevfujRMnTkAsFuep7ILi6+uLFi1a4MqVKzA2NoaTkxOcnJygpaWl0FxCk/6GQiQSoUSJEkhJScly3/DwcGhoaGT6u5kfO3bswJ9//inXN1JERN9TU3QAIiErV64cihcvnuX2EiVKSP596dIlNG3aFACgoqICa2tr6Orq4tWrVzh8+DAOHz6MGTNmYO7cuVmWV7p0aVhYWGS5PbttuZGamooJEybA09MTaWlpUFNTg7W1NfT09BAcHIwLFy7gwoULmDNnDg4ePCh5Pd8LCgrC+vXrMXHixDznWLhwIYYOHQodHZ38vJwM3rx5g44dO+LJkycAAENDQ9jY2EAsFuPDhw/w8vKCl5cX7O3tcePGDYU1jrdu3YqkpCSMGTMGq1evVkgGY2Nj2NjYwNjYWCHnl1VISAjOnTuHVq1aZbp93759SE5OLvDz7tixA1evXkXDhg1hZWWV53IsLCxgY2NT4Pc8Ef0CxESUgaWlpRiAePv27bk+5vz582Jra2vxunXrxBEREZL1iYmJYjc3NzEAMQDx33//neHYBg0aiAGIZ8+eXQDps9a1a1cxALGenp541apV4ujoaKnt7969E0+bNk2so6MjXrFihWT95cuXxQDEqqqqYgDi4sWLi2NjYzOUHxAQIHmdP0p/jellLFmyJNOMgwYNylNdvH//XmxiYiIGIHZwcBBfvnxZnJqaKtmekpIivnz5srhZs2ZiAOLIyEiZyi9ILi4uYgDiU6dOKSyDMpg9e7YYgNjGxkYMQNy9e/cs961du7ZYJBKJy5UrJ/PvbnbS79vLly8XSHlERLLiMBiiAlKrVi34+flhxIgRMDQ0lKzX0NDAggUL4OLiAgDYvHmzQvJt2bIF+/fvh7a2Ni5fvoyxY8eiaNGiUvtYWVnBw8MDd+/ehbW1dYYyrKysULduXYSEhMDT0zNPOXr06AEAWLx4MWJjY/NURmZ69eqF0NBQNGjQANeuXUPDhg2hovLfnzhVVVU0bNgQ586dg6enJ1RVVQvs3LJKH0akra2tsAzKxMnJCVZWVjh27Bi+fPmSYfvr169x584dNGjQIN+fPhERCQ0b60QFpGjRolBTy3pkWbNmzQAAL1++lFckidTUVMyfPx8AMGvWLNjb22e7f6VKldCmTZtMt82ZMwfAt8b2169fZc7SokULODo6IjQ0FGvXrpX5+MxcunQJN2/ehLq6Onbt2pVjI3jkyJHQ09OTWpecnIw1a9agVq1aKFq0KHR1dWFnZ4f58+cjLi4uQxnv37+HSCSSDI3Ys2cPHBwcoKOjg2LFiqFLly54+/at1DH9+/eXesiwUaNGkjHW/fv3B/Bt2MX3P/8o/fmBhg0bZth248YNdOjQAaamplBXV0exYsVQsWJFDB48GLdv35baN6cHTH18fNCxY0eUKFECGhoaKFWqFPr27Qs/P79M9//+Acrnz5+jS5cuMDY2hra2Nuzt7bF///5Mj8sNkUiEXr16IT4+HocOHcqwfffu3QCA3r17Z1lGfHw89u7di+7du8PGxgZFihRBkSJFUK1aNcybNy/DG8f0er569SoA6Wv1/Zj4H++DzZs3o2bNmtDT05N6diOzB0yvX78OVVVV6Orq4sWLFxkyP3v2DNra2lBVVcX169dzVVdE9PNhY51IThISEgAopjf1zp07eP/+PdTU1DB06NB8ldWsWTM4OzsjLCwMa9asyVMZ6Q3+JUuW5KnB/6N9+/YBANq0aZOnntX4+Hi0bNkSY8eOxd27d1GqVClYW1vj6dOnmDFjBpycnDI8dPs9Nzc39OnTB2FhYShfvjzi4uJw8OBBST2lK1++PJycnCSfaFSuXFnycGn58uVlzv29Y8eOoUGDBjh69ChSUlJQtWpVlChRAgEBAdi6daukjnJj/fr1cHZ2xpEjRwAAdnZ2iI2Nxe7du1GjRg2cPHkyy2Pv37+PmjVr4uzZs7CysoKenh4ePHiAbt26Yc+ePXl+fX369AGATMvw8vKClpYWOnfunG2unj174tChQ4iLi0PFihVhbm4OX19fzJw5E/Xr15d6cFpfXz/La+Xk5CT1vEq6ESNGYOjQoQgODkaFChVgYGCQ7WuqV68eJk2ahLi4OPTu3VvqAdrk5GT06dMHCQkJmDJlCurVq5dtWUT0E1P0OBwiIcrLmPXspKWliatXry4GIB49enSG7YU9Zn3JkiViAOJq1arl6fj0Metly5YVi8Vi8cWLF8UAxMWKFRPHxMRI9svNmPXdu3eLxWKxuH79+mIA4vnz50vtl5cx67a2tmIA4pUrV+bh1YnFkyZNEgMQm5ubi+/fvy9Z/+rVK3GFChXEAMRdu3aVOubdu3diAGI1NTVx0aJFpcafBwYGiqtWrSoGIP79998znC+7cdDbt28XAxD369cv06zp16JBgwZS6ytXriwGIF63bp04JSVFsj4tLU18+fJl8fHjx6X2Tx8P/mM9P3z4UKympiYGIF68eLFk3H9CQoJ45MiRYgBifX198efPnzN9Terq6uLRo0eL4+PjJef//fffJfX7fbacpGccNGiQWCwWi2vWrClWUVERf/z4UbLPzZs3pa5PkyZNMv3dff/+vXj//v3iL1++SK0PDAwUd+7cWQxA/Oeff2bIkNOY9fT7QFVVVayrqys+duyYZFtcXFyO5SQmJkrulRkzZkjWpz/nYmdnJ05MTMy6kojop8eedaJsDBgwINupFKOionJVzubNm/Hw4UNoaGhg/PjxWe43Z86cbM/36NGjPL2OT58+AQDKlCmTp+N/1LhxYzRo0AARERFYtWpVnspI711ftmwZYmJi8pUnP68vJiYG69evBwB4enqiRo0akm3W1tbYtWsXAODAgQN48+ZNhuNTUlIwe/ZsyTMJAGBqaop58+YBAE6fPi1zprx49eoVDA0NMWLECKnx+OlDZtq2bZurcpYuXYqUlBS4urpiypQpknH/mpqaWLt2LWxtbREdHS2psx9VqlQJq1atksy0IxKJMHfuXJiamuLz58+SmXryonfv3khLS4OXl5dkXW6GwACApaUlunTpgiJFikitNzU1xa5du6ChoSFVrqxSU1Ph7u6Odu3aSdbl5lM0DQ0N7NmzB5qamvDw8MCtW7fg4+ODxYsXQ0tLC15eXtDQ0MhzLiJSfmysE2WjXLlyUh99/7hkN0Y93YMHDzBu3DgAwLx581C2bNks9y1dunS25/uxoZFb6Q/l6erq5un4zKQ3tpcvX47o6GiZj2/YsCEaNmyIiIiIbOddz438vL4bN24gLi4OFhYWcHV1zbC9Zs2aqFu3LsRiMc6fP59pGYMGDcr0OAAZxq0XltKlSyMqKirLjLl17tw5AMCYMWMybBOJRBg7dqzUfj8aOHCg1IO9AKCurg47OzsA+auPHj16QE1NTTIUJikpCfv374exsTFatmyZ4/FpaWk4duwYRo0aBRcXF9SrVw/Ozs5o1qwZRCIRXr16lenzCbnVt2/fPB1XpUoVzJs3D6mpqejTpw/69OmD1NRULFiwALa2tnnOQ0Q/B86zTpSNP/74I8sH/XLj3bt3aNOmDRISEtCzZ09Mnjw52/0HDhxYKN8omf4wZUHOvtKgQQM0btwYly5dwsqVKzF79myZy3B3d0f9+vWxYsUKjB07NscxvlnR09NDVFRUnl5f+gO/FSpUyPTLnADA1tYWt27dyvThYGNjY+jr62dYnz4/f0GMyc+NCRMmYNSoUWjevDns7e3RtGlTODs7o0GDBhkeps1KVFQUQkNDAXzrIc9MeuMxqwels3ozWhD1YWJigubNm+PUqVN4/Pgx3r17h4iICIwaNQrq6urZHhsVFYVWrVrh1q1b2e4XGRmZp7nQjY2N8zVn/cSJE3Hy5EnJA6iNGzfO9lM4Ivp1sGedqJAEBQWhWbNmCAwMROvWrSWzfChCyZIlAXx781CQ3N3dAQArVqzI9ZCg79WrVw9NmzZFVFQUVqxYkecc+Xl96Y3H3Hz5VWbTBmbVm/9j73JhGzlyJHbt2gU7Ozvcv38fixYtQtu2bVG8eHEMHTo0V59+fN+Qzqo+sqsLIOf6EOfz22O/f9A0vYc9fV12Jk6ciFu3bsHGxgaHDh3Cp0+fkJiYCLFYDLFYLLmH8vrFSvn91EpFRQUNGjSQ/Jw+cxARERvrRIUgIiICzZo1w5s3b9CgQQMcOHAgx56/wuTo6AgAePr0KSIiIgqsXCcnJzRr1gzR0dFYtmxZnspIH06zcuVKREZG5qmM9NeXPs2eLNKHFoWEhGS5T3BwMADkuoc6P9IbaFk1arP79KBPnz549OgRAgMDsW/fPgwaNAhqamrYvHlzjmO6AUgNs8qqPuRZF5lxdXVF0aJFsXv3bpw4cQLlypVD7dq1sz0mJSVFMnXksWPH0LFjR5ibm0vGgqekpCAoKKjQs2fn0aNH8PDwkLypmTp1qtRMQkT062JjnaiAff36Fa1atcLTp09Rs2ZN/P333wr/8pvatWvDysoKKSkp2LRpU4GWnd67vmrVqjy9EXB0dESLFi0QExOT5wZ/t27dAAAnTpyAv7+/TMemT5no5+eXZQPZ19dXat/ClN5Dmz4c5UevX7/OsQxTU1N069YNW7ZswZ07d6CiooITJ04gMDAw2+MMDAxgYmIC4Nsc35mRZ11kRltbGx07dkRwcDASExNz9SYkNDQUsbGxKFasGGxsbDJsf/r0KVJTUzM9Vh692wkJCejduzeSkpLg7u6Ozp07IygoCMOHDy/0cxOR8LGxTlSAEhMT4erqijt37sDW1hZnzpxRWA/k91RVVeHm5gYAmDt3Lh48eJDt/n5+fjhx4kSuyq5Tpw5cXFzw5csXLF26NE/50hv8q1evznY+86w0adIEdevWRXJyMvr16yeZ0z4rGzZskAzjcHZ2ho6ODgICAnDs2LEM+967dw+3bt2CSCSSfLFVYfrtt98AfOtp/X7ebeDbA5Lbt2+XqbxKlSpJxtR//vw5x/1btGgBAJnOoS8WiyXr0/dThKFDh6JJkyZo0qRJrobApL9ZjomJkZpLPd3ixYtzPDaz4wrKH3/8AV9fX9SpUwfTpk3Dhg0bYGpqikOHDklmIyKiXxcb60QFJDU1Fd27d8elS5dQtmxZnD9/HsWKFVN0LImhQ4eiU6dOiIuLQ6NGjbBmzZoM444DAgIwY8YMODg45KoHN136UJa//vorT9lq1aqFVq1a4cuXL/j777/zVIaXlxeMjIxw5coV1KtXD1euXEFaWppke1paGm7cuIGWLVtixIgRkp7UokWLYsSIEQCA0aNH4+HDh5Jj3rx5g379+gEAunbtmu1MPgXFzs4O5ubmCAwMxOzZsyW9/QkJCRg/fnymPd4xMTHo3r17htecmpqK1atXIzIyErq6upn2Kv9o0qRJUFNTw7Fjx7Bs2TJJeUlJSRg3bhyePn0KfX19SZ0pQt26dXHhwgVcuHAhV9N1GhgYwNbWFikpKZgwYQKSkpIAfKufRYsWwdvbO8vpEdPfPOVliFVuXL58GStXroSOjg527doFVVVVGBkZYdu2bQC+zcoj66dFRPRz4WwwRNlYsGABtmzZkuX2rl27Sqay279/P44ePQrg28NiXbp0yfQYMzMzHDhwINNt27Ztw4ULF7I8X/369bFgwYJcps9o3759GDduHNavX4+xY8di0qRJsLa2hp6eHkJCQvD+/XsAQLFixVC1atVcl1uzZk20adMm173xmXF3d8epU6eyHI6QkzJlyuDWrVvo2LEj7t27h0aNGqFYsWKwtLSEWCzGhw8fJGPia9euLTU0Kf3ThsuXL6NGjRqoVKkS1NXVJcMj7Ozs4OnpmefXJgtVVVUsWrQIffr0wYIFC7B582ZYWlri5cuXSEtLg4eHR4ZZhdLS0uDt7Q1vb2/o6urC2toa6urqeP/+PcLCwiASibBy5cpcTf1ZrVo1rF69GqNGjcLkyZOxZMkSWFhY4NWrV4iKioKmpia8vLxgampaWFVQKDw8PODq6oqNGzfiwIED+O233yT1M3PmTOzatQsfPnzIcFy3bt3g6emJRYsW4ciRIzA1NYVIJMK0adNyNV1kdqKjo9G/f3+IxWIsW7YM5cqVk2xzcXHB8OHDsWHDBvTr1w+XLl3iA6dEvyg21omy8erVK7x69SrL7Q4ODpJ/JyYm5uo4S0vLLMsLCAhAQEBAltvzMzUcAKipqcHT0xPDhg3D5s2bcfnyZXz8+BFxcXEwNDREkyZN0K5dO/Tt21fmaRTnzJmTr8a6vb092rVrh+PHj+e5jHLlyuHRo0fw9vbGoUOHcPfuXfj5+UEkEsHc3BytWrVC79690aJFC6mGj7a2Ns6ePYv169dj9+7d8PPzQ1paGipVqoRu3bphwoQJeZrOL6969+4NTU1NLFq0CL6+vnj79i2aNGmCefPmZfrgp56eHnbv3o1z587h7t27eP/+PZKSklC6dGm0bNkSkydPlsxznhsjRoxA1apVsXTpUty8eROPHj2CiYkJ2rRpAzc3tyyndRSytm3b4vTp03B3d8fDhw/x4sUL2NraYuXKlejVq1eWw03q1auHv/76CytXroSvr69kysr8TOmabvTo0fD390fLli0zHZ++bNkyXLx4EVeuXMHy5csxadKkfJ+TiJSPSJzfebSIiIiIiKhQcMw6EREREZFAsbFORERERCRQHLNOpGSCgoLQuXPnXO8/ffp0uLi4FGIiIiIiKixsrBMpmYSEBNy8eTPX+6d/4yQREREpHz5gSkREREQkUByzTkREREQkUGysExEREREJ1E87Zl27+mhFR8gg4p+1io4ghV+GR0RE9PPTElhrT0httPiHwmqbZYY960REREREAsXGOhERERGRQAnsgxEiIiIi+qmJ2FcsC9YWEREREZFAsbFORERERCRQHAZDRERERPLD6ehkwp51IiIiIiKBYmOdiIiIiEigOAyGiIiIiOSHs8HIhLVFRERERCRQ7FknIiIiIvnhA6YyYc86EREREZFAsbFORERERCRQHAZDRERERPLDB0xlwtoiIiIiIhKon76x7lSjLA6uHIa35+Yj/uFatG1YVWp78WJ62DSnN96em49wn+U4tnYkylqYSLZbmBVD/MO1mS4dm1aX7Hdg5TC8POWOyNsr8PbcfGyd2xdmJvp5ynz/3l2MHTUczRo5o1plG1y6eEFq+8Xz5zBi6CA0dK6NapVt8Py5X57Ok1/ee73g0rwxalavgu5dOuLB/XsKySHkTMyjfJmYR7nyCDET8yhfJuYhIfvpG+u62pr49+UnTFi4P9Pt+1cMRZlSxugyfiPq9FgI/8AInNowBjpaGgCAj8GRsGrqJrW4rz+Br3GJOHvTV1LOtbsv0fv3bbDr4I6eU7bgt9LG+GvJoDxljo+PQ3kbG0z7Y1aW26tVr46x4yfnqfyCcOb0KSxe6IEhQ0fA++BR1Khhj5HDhiDw82dmYh6lzcQ8ypVHiJmYR/kyMY8CiETCWZSASCwWixUdojBoVx+dYV38w7XoOmET/r7yBABgbVEc/x6bhRqd5sHvbRAAQEVFBP+LCzFj9VHsOHIr07Jv7f0dj54HYMScv7I8f+sGVbB/+RDo1x6PlJQ0AEDEP2tlfh3VKttg+SpPNG7SNMO2T58+onWLJth38CgqVKgoc9n5uUd7de+CipUqYcasOZJ17du6oFHjphg3YVLeC84HoWViHuXLxDzKlUeImZhH+TL9Cnm0BPaEonbtKYqOIBF/Z4miI+Top+9Zz46mxre7NyEpRbIuLU2MpOQUOFYrm+kx1SuWRrUKpbHzaOYNeQAwLKqD7i4OuP34naSh/jNJTkqC3zNf1HV0llpf19EJjx89ZCbmUcpMzKNceYSYiXmULxPzKIhIRTiLElCOlIXkxfsgfPgcjrlj2sFATxvqaqqYPKAZzEz0YWqc+Xjzfu3rwu9tIG4/fpdh27yxrgjzWYbPVxejtFkxdJmwqbBfgkJERkUiNTUVRkZGUuuNjIwRFhbKTMyjlJmYR7nyCDET8yhfJuYhZSD4xnpAQAAGDhyY7T6JiYmIiYmRWsRpqTmWnZKShh6Tt8DasjgCry1BxK3lqGdfDmdu+CI1LWOPuJamOrq5OGTZq75i1wXU6b4IrYevRWpqGrbM7ZO7F6mkRD+MoxGLxRnWyZvQMjFPzoSWiXmyJ7Q8gPAyMU/OhJaJeUjIBN9Yj4iIwM6dO7Pdx8PDA/r6+lJLSvD9XJX/0C8AdbovRIl6k1Gm+XS4jl4HI31dvP8UnmHfDk2rQUdLA14n/sm0rPCoWLz2D8GlO8/Rd9p2uNSrjNpVy+QqhzIxNDCEqqoqwsLCpNZHRITDyMiYmZhHKTMxj3LlEWIm5lG+TMyjIIp+qFTJHjBVeGP9+PHj2S6XL1/OsQw3NzdER0dLLWol7GXKEfM1AWGRX1HWwgQ1KlngxP8fQv1e//aOOHn1X4RFfs2xvPTrr6EusKc6CoC6hgYqVrLFbZ+bUutv+/jArlr1LI76tTIxj/JlYh7lyiPETMyjfJmYh5SBwluS7du3h0gkQnaT0uT00Y+mpiY0NTWlj1FRBQDoamugbOn/5k23KmmEquVLIjImDgFBkejYtDpCI78iICgClcuZY+mUzvj7yhNcvP1cqrzfShvDuUZZtB+zPsP5HWwt4VDZEj4P3yDqSxysShpj1ojWeOMfijtPMo5tz0lcXCz8/f0lP3/69BHPn/tBX18fZmbmiI6OQmBgIEJDQgAAH959O4exsTGMjU0yLbOg9ek3ANOnTUWlypVhZ1cdhw54IzAwEF26dZfL+ZUhE/MoXybmUa48QszEPMqXiXlI6BTeWDczM4Onpyfat2+f6fZHjx7B3l62XvLv1ahkiXNbxkl+Xjy5EwBg9/HbGDp7D0xNimLRpI4obqSHoLAYeJ24A49NZzKU08+1Lj6HROPCrecZtsUnJsO1sR1mDG8NXW0NBIVF45yPH/pO246k5JQM++fE9+lTDBnYV/LzssUeAIC2rh0wd/5CXLl8CbNnuEm2/z5lAgBg2IjRGDFqjMzny4uWLq0QHRWJTevXITQ0BNblysNzwyaYm5eUy/mVIRPzKF8m5lGuPELMxDzKl4l5FEBJZmERCoXPs96uXTtUq1YN7u7umW5//PgxqlevjrRMHvjMTmbzrCtaXuZZL0xKMlSLiIiI8kFw86w7/qHoCBLxPgsUHSFHCr98U6ZMQWxsbJbbra2tczVunYiIiIjoZ6Pwxnq9evWy3a6rq4sGDRrIKQ0RERERFSp+tC8TDhoiIiIiIhIohfesExEREdEvhA+YyoS1RUREREQkUGysExEREREJFIfBEBEREZH88AFTmbBnnYiIiIhIoNhYJyIiIiISKA6DISIiIiL54WwwMmFtEREREREJFBvrREREREQCxWEwRERERCQ/HAYjE9YWEREREZFAsWediIiIiORHhfOsy4I960REREREAsXGOhERERGRQP20w2Ai765VdIQMDGuOVnQEKUKsIyIiIvrJ8QFTmbC2iIiIiIgEio11IiIiIiKB+mmHwRARERGRAIk4G4ws2LNORERERCRQbKwTEREREQkUh8EQERERkfxwNhiZsLaIiIiIiASKPetEREREJD98wFQm7FknIiIiIhIoNtaJiIiIiASKw2CIiIiISH74gKlMWFtERERERALFxjoRERERkUBxGAwRERERyQ9ng5EJe9aJiIiIiASKjfVseO/1gkvzxqhZvQq6d+mIB/fv5bvMIV2c8Y+3G4KvL0Hw9SW4snMSmjtVktrHpkwJHFg5DEHXliDkxlJc3TkJpU0NJdvLlDKG97Ih8L/kgeDrS7Bn0UAUL6YnVcbUQS1wecdEhPssR+C1xfnOnZnCqJ+fLRPzKF8m5lGuPELMxDzKl0lRee7fu4sxI4ejaUNn2Nna4NLFC1LbxWIx1nuuQdOGzqhVoyoG9e+D169fySVboRKpCGdRAsqRUgHOnD6FxQs9MGToCHgfPIoaNewxctgQBH7+nK9yPwVHYeaaY3DqtQROvZbgyj8vcWDFUFT8zRTAt4b4xW0T8fJdEFoMWYVa3TzgsfkMEhKTAQA6Who4sW4UxGIxXIauQeMBK6ChropDq4ZB9N3HShrqqjh8/iE2H7yer7xZKaz6+ZkyMY/yZWIe5cojxEzMo3yZFJknPj4ONjY2mDZ9Vqbbt2/djN07t2Pa9Fnw8j4II2NjDB88ALGxXws9GwmHSCwWixUdojAkpOTv+F7du6BipUqYMWuOZF37ti5o1Lgpxk2YlKcyDWuOznT9pyuL8MfKo9h59BZ2LRyA5ORUDJq5K9N9m9SpgGNrR8KswVR8iU0AABjoaSPw2hK0Gr4Gl++8kNq/d9vaWDKlE8zqT81QVuTdtXl6HUDh1E9+CS0T8yhfJuZRrjxCzMQ8ypdJKHnsbG2wYrUnGjdpCuBbr3rThvXQq09fDBw8FACQlJSExvUdMW7iZHTp2j3XZWsJ7AlF7ZbLFR1BIv7MREVHyBF71jORnJQEv2e+qOvoLLW+rqMTHj96WGDnUVERoUsLe+hqa+DOk3cQiURo6WyLV/4hOO45Ch8ueuDarslo27Cq5BhNDTWIxWIkJv33biQhKQWpqWlwrFa2wLJlR171o8yZmEf5MjGPcuURYibmUb5MQsvzvU8fPyIsLBR1nf7LpqGhAXuHmnj8ULHZ8k0kEs6iBATRWI+Pj8eNGzfw7NmzDNsSEhKwa1fmvcyFJTIqEqmpqTAyMpJab2RkjLCw0HyXb2ttjtCbyxB9ZyVWT++GbpM24/nbIBQvVgR6ulqYPKAZzvs8Q9sRa3H88mPsWzYYzvbWAIB//n2P2PgkzB/nCm0tdehoacBjfHuoqqrA1LhovrPlRmHXz8+QiXmULxPzKFceIWZiHuXLJLQ830s/f+bZwhQRiRRE4Y31ly9fomLFiqhfvz6qVKmChg0bIjAwULI9OjoaAwYMyLaMxMRExMTESC2JiYn5zib64R2XWCzOsC4vXr4PRu3uHmjQbxk2H7iBze59UOE3U6iofLscJ678izVel/Hk5Scs3X4ep677Ykjnb++swyK/otfUrWhVvzLCbi5D8PUlKFpEGw+e+SM1LS3f2WRRWPWTH0LLxDw5E1om5sme0PIAwsvEPDkTWiah5fle5tkUFIYUQuGN9d9//x1VqlRBSEgIXrx4gaJFi8LJyQn+/v65LsPDwwP6+vpSy5JFHnnOZGhgCFVV1QzvXCMiwmFkZJznctMlp6TibUAYHjzzx6w1x/Hvy08Y1aMhwiK/Ijk5FX5vA6X2f/E2SGo2mIu3n8O23RxYNHFDqUbTMGjmLpgXN8CHT+H5zpYbhV0/P0Mm5lG+TMyjXHmEmIl5lC+T0PJ8z9jYBAAEmS3fFD0DDGeDkY2Pjw8WLFgAY2NjWFtb4/jx43BxcUG9evXw9u3bXJXh5uaG6OhoqWXK7255zqSuoYGKlWxx2+em1PrbPj6wq1Y9z+VmRQQRNDXUkJySivvPPqC8ZQmp7eUsi8M/MDLDceFRsYj+Go8GNcujeLEiOHH13wLPlhl5148yZmIe5cvEPMqVR4iZmEf5Mgktz/dKlioFY2MTqWzJSUm4f+8u7KorNhvJl8KfD46Pj4eamnQMT09PqKiooEGDBvjrr79yLENTUxOamppS6/I7G0yffgMwfdpUVKpcGXZ21XHogDcCAwPRpVvun77OzJzRbXHu5jMEBEVCT1cLXVrYo75DObQbtQ4AsGLnBexeNBA3HrzG1Xsv0dyxElrVr4wWQ1b9l61dHbx4F4TQyK+oXbUMlk7pjDVel/HqQ4hkn9KmhjAsqoPSZoZQVVFB1fIlAQBvAkIRG5+Ur9cAFF79/EyZmEf5MjGPcuURYibmUb5MiswTFxsrNZLg08ePeO7nB319fZiZm6NXn77YunkjLCytYGFpia2bNkJLSwutWrcp9GwkHApvrFeoUAH37t1DxYoVpdavWbMGYrEY7dq1U0iuli6tEB0ViU3r1yE0NATW5crDc8MmmJuXzFe5xY30sHVeX5gaF0X01wQ8ffUJ7Uatw6U7zwEAxy8/wZj5+zBlYHMsm9oZLz+EoMeULfB59N+nDOWtisN9TDsU09fBh88RWLz1LFbvuSR1npkjWqNPuzqSn+94f/ukofngVbh+P/9fqFBY9fMzZWIe5cvEPMqVR4iZmEf5Mikyj6/vUwwe0Ffy89LF34bwtnPtgLkLFmLAoCFITEzEgrlzEBMTjSpV7bB+8zbo6hYp9GyFioPuZaLwedY9PDxw/fp1nDp1KtPtI0eOxIYNG5Am48OT+e1ZLwxZzbOuKPmZZ52IiIiUg+DmWW+9WtERJOJPjlV0hBwpvLFeWNhYzxkb60RERD8/wTXW2win/RF/Qlhts8wo/AFTIiIiIiLKHBvrREREREQCJbAPRoiIiIjop6Yk85sLBWuLiIiIiEig2FgnIiIiIhIoDoMhIiIiIvnhPOsyYc86EREREZFAsbFORERERCRQHAZDRERERPLD2WBkwtoiIiIiIhIo9qwTERERkfzwAVOZsGediIiIiEig2FgnIiIiIhIoDoMhIiIiIvnhA6YyYW0REREREQkUG+tERERERALFYTByFHl3raIjSDGsNVbREaRE/rNa0RGICpxYrOgE0jgJAxEpHP8QyYQ960REREREAsWedSIiIiKSGxF71mXCnnUiIiIiIoFiY52IiIiISKA4DIaIiIiI5IbDYGTDnnUiIiIiIoFiY52IiIiISKA4DIaIiIiI5IejYGTCnnUiIiIiIoFiY52IiIiISKA4DIaIiIiI5IazwciGPetERERERALFnnUiIiIikhv2rMuGPetERERERALFxjoRERERkUCxsZ4N771ecGneGDWrV0H3Lh3x4P69nzKPU42yOLhyKN6enYv4B6vRtmEVqe3Fi+lh05+98PbsXITfXIpja0egbGkTqX3WTO8G32OzEOGzFP4XF2D/8iEob1Vcap8DK4bg5ck/EXlrGd6enYutc/vAzLhogbyGdEK5Zi7NGsPO1ibDsmDuHIXkSSeU+hFyJqHkSUlJwdrVK9CqRWPUtq+K1i2bYOP6tUhLS1NIHgC4f+8uxowcjqYNnWFna4NLFy8oLMv3hHLNAGHWkZDqR4iZeM3kTyQSCWZRBmysZ+HM6VNYvNADQ4aOgPfBo6hRwx4jhw1B4OfPP10eXS0N/PvyEyYsOpDp9v3LB6NMKSN0mbAZdXouhn9gBE5tGAUdLQ3JPg/9AjB0jheqdVqAdqPWQSQCTniOhIrKf78I1+69Qu9pO2DXcR56TtmG30oZ468lg/KdP52QrpmX90FcvHJDsmzcsh0A0KxFS7lnSSek+hFqJiHl2b51Mw7u34dpf8zC4eOnMH7iFOzcvhV7vXbLPUu6+Pg42NjYYNr0WQrL8CMhXTNAeHUktPoRYiZeMxI6NtazsHvndnTo1AkdO3fBb2XLYqrbdJiamWK/996fLs85Hz/MWXcSxy49ybDN2sIEtauWwdgF+3H/mT9efQjBOI/90NXWRNeW9pL9th32wc0Hb+AfGIFHzz9izrqTKG1WDJbmRpJ91nhdwT//vod/YCRuP3mHpdvPo1YVS6ipFcxtKKRrVqxYMRibmEiWa1cuo3RpCzjUrCX3LOmEVD9CzSSkPE8eP0LDRk1Qv0FDlCxZCs2at0RdR2c8830q9yzpnOs1wOhxE9C0WXOFZfiRkK4ZILw6Elr9CDETrxkJHRvrmUhOSoLfM1/UdXSWWl/X0QmPHz38pfJoanybMCghKUWyLi1NjKTkFDhW+y3TY3S0NNC3XW28+xiGj0GRme5jWFQH3Vs54Pbjd0hJyf/H+kK7Zt9LTkrCyRPH0b5jJ4V95CbE+hFaJqHlqV7DHnfu3MaH9+8AAC+eP8fDB/fhXL+B3LMIldCumdAIsX6EmElIfpX6UfTQF2UbBiOIqRv9/Pxw+/Zt1K1bFxUqVMDz58+xatUqJCYmonfv3mjcuLFc80RGRSI1NRVGRkZS642MjBEWFirXLIrO8+J9MD58Dsfc0W0xev4+xMYnYVzvRjAz0YepifR486FdnDF/nCuK6Gji+bsgtB65DskpqVL7zBvbDsO71YOutibuPHmHjuM2FkhOoV2z7126dAFfvnxBu/YdFJZBiPUjtExCyzNg0BB8/fIF7du6QFVVFampqRg9dgJcWrWRexahEto1Exoh1o8QMwkJ64cyo/Ce9TNnzqBatWqYPHkyqlevjjNnzqB+/fp4/fo1/P390aJFC1y6dCnbMhITExETEyO1JCYm5jvbj++4xGKxQt+FKSJPSkoaekzZBmtLEwReXYQIn6Wo51AOZ274IjVVukd83+l7qNNjMZoOXoXX/qHYs2iApGc+3YpdF1Gnx2K0HuGJ1NQ0bHHvU6B5hXbNAODIoUNwcq6P4sVLKDQHIMz6EVomoeQ5e/oUTp44Do9Fy7B3/2HMnb8Qu3Zsw/FjR+SeReiEcs2ESoj1I8RMQsL6oe8pvLHu7u6OKVOmIDw8HNu3b0fPnj0xZMgQnD9/HhcuXMDUqVOxcOHCbMvw8PCAvr6+1LJkkUeeMxkaGEJVVRVhYWFS6yMiwmFkZJzncpU1z0O/ANTpsRgl6k9FmeYz4Tp6PYz0dfH+c4TUfjFfE/AmIBQ3H7xBzynbYGNVHK6NqkrtEx4Vi9f+obh05wX6uu2ESz1b1K5qle+Miq6jrHz+/Al3bvugY+fOCssACLN+hJZJaHlWLFuMAYOHomWr1ihX3gZt2rVH7779sG1LwXwa9TMQ2jUTGiHWjxAzCckvUz8iAS1KQOGNdV9fX/Tv3x8A0LVrV3z58gWdOnWSbO/RoweePMn44OP33NzcEB0dLbVM+d0tz5nUNTRQsZItbvvclFp/28cHdtWq57lcZc8T8zUBYVFfUba0CWpUssCJK/9mu78IImhoZD3SKr2TQEM9/6OxhFJHPzp25DCKFTNCvfoNFZYBEGb9CC2T0PIkJCRA5YeeNBUVVaSlieWeRaiEds2ERoj1I8RMQsL6ocwIYsx6OhUVFWhpacHAwECyTk9PD9HR0dkep6mpCU1NTal1CSlZ7JxLffoNwPRpU1GpcmXY2VXHoQPeCAwMRJdu3fNXsADz6GprSM2bblXSCFXLl0RkTBwCgiLRsWk1hEZ+RUBQJCpbm2PplI74+8oTXLz9XLJ/5+Y1cPH2c4RFfoV5cX1M6tcU8YnJOHvjGQDAwdYCDpUt4fPwLaK+xMGqpDFmjWiFNwGhuPPkfb5fAyC8a5aWloZjRw6jrWt7qKkp/ldNaPUjxExCylO/YSNs2bwBpmbmKGttjRd+ftizaztcO3TK+eBCEhcbC39/f8nPnz5+xHM/P+jr68PM3FwhmYR0zQDh1ZHQ6keImXjN5I9DemSj8BaElZUVXr9+DWtrawDArVu3YGFhIdkeEBAAMzMzuedq6dIK0VGR2LR+HUJDQ2Bdrjw8N2yCuXlJuWcp7Dw1Klng3Oaxkp8XT+oIANh9/A6G/ukFU+OiWDSxA4ob6SEoLAZeJ/6Bx+azkv0TE5PhVP03jO7ZAIZFdRAS/gU3HrxBowErEBr5FQAQn5gM18Z2mDGsFXS1NRAUFoNzPn7oO20HkpLz+c7q/4R2zW7f8kFg4Ge076i4xtX3hFY/QswkpDzT/pgBzzWr4DFvDiIiwmFiUhydunTDsBGj5J4lna/vUwwe0Ffy89LF34YbtnPtgLkLsh+uWFiEdM0A4dWR0OpHiJl4zUjoRGKxWKGfqW7YsAGlS5dG69atM90+ffp0BAcHY8uWLTKVm9+e9V+BYa2xOe8kR5H/rFZ0BKICp9i/sBmxQ4vo16Ol8K5ZaQa99ig6gkSUV29FR8iRwi/f8OHDs90+f/58OSUhIiIiosLGYTCyUfgDpkRERERElDk21omIiIiIBErhw2CIiIiI6NfBYTCyYc86EREREZFAsbFORERERCRQHAZDRERERHLDYTCyYc86EREREZFAsWediIiIiOSHHesyYc86EREREZFAsbFORERERCRQHAZDRERERHLDB0xlw551IiIiIiKBYmOdiIiIiEigOAyGiIiIiOSGw2Bkw551IiIiIiKBYs/6Lyzyn9WKjiDFsNZYRUeQEnFHWPUDAOyMUD68ZkRE0tizLhv2rBMRERERCRQb60REREREAsXGOhERERHJj0hASx6sW7cOZcqUgZaWFuzt7XH9+vVs9/fy8oKdnR10dHRgZmaGAQMGIDw8PNfnY2OdiIiIiCgXvL29MX78eEyfPh0PHz5EvXr14OLiAn9//0z3v3HjBvr27YtBgwbB19cXBw4cwN27dzF48OBcn5ONdSIiIiKiXFi+fDkGDRqEwYMHo2LFili5ciVKly6N9evXZ7r/7du3YWVlhbFjx6JMmTJwdnbGsGHDcO/evVyfk411IiIiIpIbkUgkmEUWSUlJuH//Ppo3by61vnnz5vDx8cn0GEdHR3z8+BGnTp2CWCxGcHAwDh48iNatW+f6vGysExEREdEvKTExETExMVJLYmJipvuGhYUhNTUVJUqUkFpfokQJBAUFZXqMo6MjvLy80K1bN2hoaMDU1BQGBgZYs2ZNrjOysU5EREREvyQPDw/o6+tLLR4eHtke82OPvFgszrKX/tmzZxg7dixmzZqF+/fv48yZM3j37h2GDx+e64z8UiQiIiIikhshfSmSm5sbJk6cKLVOU1Mz032NjY2hqqqaoRc9JCQkQ297Og8PDzg5OWHKlCkAgKpVq0JXVxf16tXDvHnzYGZmlmNG9qwTERER0S9JU1MTRYsWlVqyaqxraGjA3t4e58+fl1p//vx5ODo6ZnpMXFwcVFSkm9uqqqoAvvXI5wZ71omIiIhIboTUsy6riRMnok+fPnBwcEDdunWxadMm+Pv7S4a1uLm54dOnT9i1axcAoG3bthgyZAjWr1+PFi1aIDAwEOPHj0etWrVgbm6eq3OysU5ERERElAvdunVDeHg43N3dERgYiMqVK+PUqVOwtLQEAAQGBkrNud6/f398+fIFa9euxaRJk2BgYIDGjRtj0aJFuT6nSJzbPnglk5Ci6AQkK8NaYxUdQUrEndWKjpCBEndGEBGRgmgJrGvWbOghRUeQCNzUSdERciSwy0dEREREPzNlHgajCHzAlIiIiIhIoNhYz4b3Xi+4NG+MmtWroHuXjnhwP/dfDcs8eedUoywOrhyKt2fnIv7BarRtWEVq+/RhLnh0aDrCbi7B5ysLcXL9KNSsbCm1z9lNYxD/YLXUssujn9Q+1hYm2L98CAIuLkDwtcW4tG086juUy1Pm+/fuYuyo4WjWyBnVKtvg0sULUtvFYjHWe65Bs0bOqG1fFYP698Hr16/ydK78ENo9JMRMzJO1+/fuYszI4Wja0Bl2thnvc0URUh0xj3JmYh4SMjbWs3Dm9CksXuiBIUNHwPvgUdSoYY+Rw4Yg8PNn5inkPLpaGvj35SdMWHQg0+2vP4RgwqIDcOi6EE0GrsSHzxH423MkjA2KSO239fBNWDWbLllGz/eW2n5k9TCoqarAZfhaOPZagscvP+HwqqEoYaQnc+b4+DiUt7HBtD9mZbp9x7bN2LNrO6b9MQte+w7C2NgYI4YMQGzsV5nPlVdCu4eEmIl5shcfHwcbGxtMm575fa4IQqsj5lG+TMyjACIBLUqAjfUs7N65HR06dULHzl3wW9mymOo2HaZmptjvvZd5CjnPOR8/zFl3EscuPcl0u/eZ+7j8z0u8/xQOv7dB+H35EejraaNyeekpkOITkhEc/kWyxHxNkGwzMtCFtUVxLNtxHk9ffcabgFDMXH0cutqaqFg25y8o+JFzvQYYPXYCmjRrnmGbWCyG1+5dGDx0OJo0aw7rcuUxd8EixCck4PTJEzKfK6+Edg8JMRPzZM+5XgOMHjcBTTO5zxVFaHXEPMqXiXlI6ATZWFf0BDXJSUnwe+aLuo7OUuvrOjrh8aOHzCOgPOpqqhjU0RFRX+Lw78tPUtu6uTgg4OIC3D/gBo/xriii89+XHIRHxcLvbRB6tq4FHS0NqKqqYHAnJwSFxeDhs4ACzfjp40eEhYVK1ZeGhgYcHGrikZzqS0jXTKiZmEf5CK2OmEf5MjEPKQNBzgajqamJx48fo2LFigo5f2RUJFJTU2FkZCS13sjIGGFhocwjgDwu9Wyxy6M/dLTUERQWgzYj1iE8Klayfd/pe3j/KRzB4V9gW9YM7mPaokr5kmgzcp1knzYjPLF/xRCE3liMtDQxQiK+wHX0ekR/jS/QrOl1UuyH+ipmZCy3jzWFcM2Enol5lI/Q6oh5lC8T8ygGZ4ORjUIb6xMnTsx0fWpqKhYuXCi5WZcvX55tOYmJiUhMTJRaJ1bVzPLrYnPrx5tJLBYr9AZjnv9cvfsKtXssgrFBEQzoUBd7Fg1A/b7LEBr5bQz49iO3JPs+exOI1wGh8PGagmoVSuHR848AgJVuXREa8QVNB61CfGIy+revi8OrhsG5z1IEhcUUeObM66vAT5OHDIr9oym0TMyjfIRWR8yTM6FlYh4SMoUOg1m5ciUuX76Mhw8fSi1isRh+fn54+PAhHj16lGM5Hh4e0NfXl1qWLPLIcy5DA0OoqqoiLCxMan1ERDiMjIzzXC7zFJy4hCS8DQjDP/++xwj3vUhJTUW/9nWz3P+hXwCSklNgbWECAGhYqzxa1bNFX7eduPX4HR49/4jxCw8gPjEJvdvUKtCsxsbfzhn+Q31FRoSjmJzqSwjXTOiZmEf5CK2OmEf5MjGPYohEIsEsykChjfX58+cjOjoaM2fOxOXLlyWLqqoqduzYgcuXL+PSpUs5luPm5obo6GipZcrvbnnOpa6hgYqVbHHb56bU+ts+PrCrVj3P5TJP4RGJRNDUyPqDokplzaChrobA//eY62hpAADS0tKk9ktLE0OkUrC/vCVLlYKxsQlu3fqvvpKTk3Dv3l1Uk1N9CfGaCS0T8ygfodUR8yhfJuYhZaDQYTBubm5o2rQpevfujbZt28LDwwPq6uoyl6OpmXHIS0JK/rL16TcA06dNRaXKlWFnVx2HDngjMDAQXbp1z1/BzJMjXW0NlC1tIvnZqqQRqpYviciYOIRHxeL3wc1x8upTBIVFo5i+LoZ2qYeSxQ1w+Py3h2/KlDJGdxcHnL3hi7CoWFT8zRQLJ7bHQ78A3Hr0FgBw58k7RMbEYYt7byzYdAbxickY2NERViWNcOa6r8yZ4+Ji4e/vL/n506ePeP7cD/r6+jAzM0evPn2xdfNGWFpYwcLSEls2b4S2lhZcWrfJZ23lntDuISFmYp7sxcX+cJ9//Ijnfv+/z83Nszmy8AitjphH+TIxDwmdwh8wrVmzJu7fv49Ro0bBwcEBe/bsEcTHEi1dWiE6KhKb1q9DaGgIrMuVh+eGTTA3L8k8hZynRiULnNs8VvLz4kkdAQC7j9/BmAXesLEqgd5tasHIoAgiomNxz9cfTQetgt/bIABAcnIKGtUqj1E9GqCIjiY+BkfizHVfzN90Bmlp32YaCo+Khevo9fhzdBuc3jgG6mqq8HsbiC4TNuPfV7I/9On79CmGDOwr+XnZ4m/DsNq6dsDc+QvRf+AQJCQkYsG8OYiJiUaVqnZYv2kbdHWLZFVkgRPaPSTETMyTPV/fpxg84L/7fOn/7/N2rh0wd8FChWQSWh0xj/JlYh75E0I7T5mIxIqeJ/E7+/btw/jx4xEaGop///0XlSpVynNZ+e1ZJ/kzrDU2553kKOLOakVHyIB/34iISFZaCu+alVZ61DFFR5AI8HRVdIQcCeryde/eHc7Ozrh//z4sLS1zPoCIiIiI6CcmqMY6AJQqVQqlSpVSdAwiIiIiKgz8lFgmgvwGUyIiIiIiYmOdiIiIiEiwBDcMhoiIiIh+XpwNRjbsWSciIiIiEij2rBMRERGR3LBnXTbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbjgMRjbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbjgMRjbsWSciIiIiEij2rBMRERGR/LBjXSbsWSciIiIiEig21omIiIiIBIrDYEgwIv9ZregIUgzrTFB0hAwib69QdARScmlisaIjSBEJ7PNwPvdGVPj4gKls2LNORERERCRQbKwTEREREQkUh8EQERERkdxwGIxs2LNORERERCRQbKwTEREREQkUh8EQERERkdxwFIxs2LNORERERCRQ7FknIiIiIrnhA6ayYc86EREREZFAsbFORERERCRQHAZDRERERHLDUTCyYc86EREREZFAsbFORERERCRQHAZDRERERHLD2WBkw551IiIiIiKBYmM9G957veDSvDFqVq+C7l064sH9e8wj4DyFlWly/ya4sXMCQq564MM5d+xfOhDlLE0y7GdjVRwHlg9C0JUFCLnqgavbx6F0CQPJ9oEd6uLsxlEIvuKB+HsroF9EK0MZBnra2OreC0FXFiDoygJsde+V6X559atcM+bJv/379qJrh3Zwrm0P59r26NurG25cvybZLhaLscFzDZo1qoc69nYY3L8P3rx+VaiZ7t+7i7GjhqNZI2dUq2yDSxcvSLYlJydj5fIl6NyhLerUrIZmjZwxw20qQkKCCzVTZoR0D92/dxdjRg5H04bOsLOVrjNFElIdMQ8JHRvrWThz+hQWL/TAkKEj4H3wKGrUsMfIYUMQ+Pkz8wgwT2FmqlejLDYcuIEGA1ahzagNUFVVwYm1w6GjpSHZp0xJI1zcMhYv34egxTBP1Oq5FB5bziMhKUWyj46WOs77PMeS7Vn/Z7ljXh9ULW8O1zEb4TpmI6qWN8dW9975yp/uV7pmzJN/JUxLYMyESfDyPggv74OoVasOJowZJWmQ79i2BXt27cC0P2Ziz74DMDI2wfAhAxEb+7XQMsXHx6G8jQ2m/TErw7aEhAT4PXuGIcNGYN/+w1i2ci0+fHiP8aNHFFqezAjtHoqPj4ONjQ2mTc9YZ4oitDpiHvkTiYSzKAORWCwWKzpEYUhIyXmf7PTq3gUVK1XCjFlzJOvat3VBo8ZNMW7CpHymYx5lyGRYZ0Km640NdBFwYR6aDlmDmw/fAgB2LeiD5JQ0DJrllWO59ezL4tzG0TBt6IborwmS9TZWxfHooBvq91uBu77+AIBalS1xdcd4VO20AK8+hCLy9gqZX0e6X+GaMU/O0vLxJ7+BY22MnzQF7Tt2QvNG9dGzT18MGDQEAJCUlIQmDZwwbsIkdO7aPddlipC3/y2rVbbB8lWeaNykaZb7PP33CXr36ILT5y/DzMw8d3ny+Z+30O6h79nZ2mDF6uzrTB6EVke/Qh4tgT2hWGHaWUVHkHi+sIWiI+SIPeuZSE5Kgt8zX9R1dJZaX9fRCY8fPWQegeWRd6aiRbQBAJExcQC+PSjT0qkSXn0IwfE1w/DhnDuu7RiPtg0qy1Ru7apWiPoSL2moA8A/Tz8g6ks86lQtk6/Mv/o1Y578SU1NxZlTJxEfH4eq1arh08ePCAsLRV1HJ8k+GhoasHeoqbD7KTNfv36FSCSCnl5RuZxPSNdMqIRWR8yjGCoqIsEsykBg77WAyMhI7Ny5E69evYKZmRn69euH0qVLyzdDVCRSU1NhZGQktd7IyBhhYaFyzcI8wsu0aKIrbj58i2dvggAAxYsVgZ6uFib3b4I5609jxpq/0bxuRexbMgAthq/DjQdvclVuCaOiCI34kmF9aMQXlDDSy1fmX/2aMU/evHr5Av169UBSUiK0dXSwbNValC1rjUcPHwAAimXIZiSYj+oTExOxesVSuLRqgyJFisjlnEK4ZkIntDpiHlIGCm+sm5ub499//4WRkRHevXsHR0dHAECVKlVw/PhxLF26FLdv30aFChWyLCMxMRGJiYlS68SqmtDU1MxXth+nFhKLxQqdboh5clbYmVZM7YQq1uZoMni1ZJ3K/8s/cfUp1vx1FQDw5OVn1LazwpBOjrlurANAZgMURCJR5hvy4Fe8ZrJinv9YlSmDfYeO4EtMDC6eP4dZ06dhy47d2WQTxpRsycnJ+H3KBKSJxfhj5p9yP7/Q7iEhElodMQ8JmcKHwQQFBSE1NRUA8Mcff6BChQp48+YNzp07h9evX6NevXqYOXNmtmV4eHhAX19falmyyCPPmQwNDKGqqoqwsDCp9RER4TAyMs5zucyj3JmWT+mINvVt0WK4Jz6FREvWh0XFIjklFX7vpGedePEuGKVNDXNdfnB4DIoXy9iDbmxYBMGZ9LjL4le9ZsyTP+rqGrCwsIRt5SoYO2ESyttUwN49u2Bs/G02pPBMsv3Y2y5vycnJmDppPD5//IgNm7fJrVcdEMY1Ezqh1RHzKIaiHypVtgdMFd5Y/96dO3cwc+ZM6OjoAAA0NTUxY8YM3L59O9vj3NzcEB0dLbVM+d0tzznUNTRQsZItbvvclFp/28cHdtWq57lc5lHeTCumdoRroypoOWIdPnyOkNqWnJKK+77+KG9ZXGp9OQsT+AdK75udO0/ew0BPGw62FpJ1NW0tYKCnjdtP3uUr/694zZinEIjFSEpKQslSpWBsbILbt3wkm5KTk3D/3l3FZcN/DXV//w/YsGUHDAxy/2a5IAjymgmM0OqIeUgZKHwYDPDfxz2JiYkoUaKE1LYSJUogNDT7cVqamhmHvOR3Npg+/QZg+rSpqFS5MuzsquPQAW8EBgaiS7fcz3JQkJhHcZlW/t4J3Vrao8ukrfgalygZPx79NQEJickAgBW7L2O3R1/cePAGV++9RnPHCmhVzxYthnlKyilhpIcSRnooW+pb70hla3N8iUtAQFAUImPi8OJ9CM7e9IPn9K4Ys+AAAGDt9K44ec0Xrz7kf6zir3TNmCf/1qxcDqd69WFqaorY2FicPX0K9+7+A88NmyESidCzT19s3bwRFhaWsLC0xNbNG6GlpQWX1m0KLVNcXCz8/f97APvTp494/twP+vr6MDEpjikTx8Lv2TOs9tyItLRUyRhffX19qKtrZFVsgRLaPRQX+0OdffyI537f6szMPHcz5BQ0odUR85DQCaKx3qRJE6ipqSEmJgYvX76Era2tZJu/vz+MjeX/0U9Ll1aIjorEpvXrEBoaAuty5eG5YRPMzUvKPQvzKDbTsC7fnso/v2m01Pohf/6FPSfuAgCOX/kXYzwOYEr/plg2uQNefghFj993wOfxfz3igzs5YsbQlpKfL2wZk6GcATP3YNnkDvh77XAAwMlrTzFh8aF85U/3K10z5sm/8PBwzHCbirDQUBTR00O58jbw3LAZdf4/A0z/gYORmJAAj3nuiImJRuWqVbF+01bo6hbesBPfp08xZGBfyc/LFn8b7tjWtQOGjxyNK5cvAQC6dXaVOm7ztl2oWat2oeX6ntDuIV/fpxg84L86W/r/Omvn2gFzFyxUSCah1RHzyB/H38tG4fOsz5kzR+rnOnXqoEWL/+a8nDJlCj5+/Ii9e/fKVG5+e9aJsppnXZHyM886EZC/edYLQ17nWS8sbEPQz0ho86xXnnFe0REkns5rpugIOVL45Zs9e3a225csWSKnJEREREREwqLwxjoRERER/Tr4CZZsBDUbDBERERER/Yc960REREQkN3zAVDbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbjgMRjbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbjgKRjbsWSciIiIiEij2rBMRERGR3PABU9mwZ52IiIiISKDYWCciIiIiEigOgyEiIiIiueEoGNmwZ52IiIiISKDYWCciIiIiEigOgyHKQuTtFYqOkIFhrbGKjiAl8p/Vio5AMlIR2OfPYrGiExCRvHE2GNmwZ52IiIiISKDYWCciIiIiEigOgyEiIiIiueEoGNmwZ52IiIiISKDYs05EREREcsMHTGXDnnUiIiIiIoFiY52IiIiISKA4DIaIiIiI5IajYGTDnnUiIiIiIoFiY52IiIiISKA4DIaIiIiI5IazwciGPetERERERALFxjoRERERkUBxGAwRERERyQ1HwciGPetERERERALFxno2vPd6waV5Y9SsXgXdu3TEg/v3mEfAeYSYqTDyDOnsjH+8f0fwtcUIvrYYV3ZMQHPHipLtxYvpYdOfvfD27FyE31yKY2tHoGxpE6kyNNTVsHxqJwRcXICwm0twYMUQlCxuILXPgRVD8PLkn4i8tQxvz87F1rl9YGZcNN/5f/QrXLOfJc/9e3cxZuRwNG3oDDtbG1y6eEFu596/7y906dAWTrVrwKl2DfTt1Q03rl+VbBeLxVjvuQbNGjmjtn1VDOrfB69fv5Jbvu8J6ZoJMY8QMzGPfIlEIsEsyoCN9SycOX0Kixd6YMjQEfA+eBQ1athj5LAhCPz8mXkEmEeImQorz6eQKMxc/Tecei+BU+8luHL3JQ6sGIKKv5kCAPYvH4wypYzQZcJm1Om5GP6BETi1YRR0tDQkZSyZ3BHtGtmhr9sONBm4CkV0NHFo1VCoqPz3h+vavVfoPW0H7DrOQ88p2/BbKWP8tWRQvrL/6Fe5Zj9Lnvj4ONjY2GDa9FlyP3cJU1OMnTAZf3kfwl/eh1CzVh2MHzNK0iDfsW0z9uzajml/zILXvoMwNjbGiCEDEBv7Va45hXbNhJZHiJmYh4ROJBaLxYoOURgSUvJ3fK/uXVCxUiXMmDVHsq59Wxc0atwU4yZMymc65vkVMhVGHsNaYzNd/+myB/5YeQw3H77Bv0dnokbnBfB7GwQAUFERwf/CAsxYfRw7jt5C0SJaCLi4AINm7sbBcw8BAGbGRfHqtDvaj92AC7eeZ3qO1vUrY//ywdCvMxEpKWkAgMh/VufpdaT7Fa7Zz5Tne3a2Nlix2hONmzTNVzn5+R+ovmMtTJg0Be07dkazRvXQq09fDBg0FACQlJSExg0cMX7CZHTu2j3XZea3o01o10xoeYSY6VfIoyWwJxTrLrqm6AgSt36vr+gIOWLPeiaSk5Lg98wXdR2dpdbXdXTC40cPmUdgeYSYSV55VFRE6NK8BnS1NXHnyXtoanz7i5yQ9N+71bQ0MZKSU+BY7TcAQPWKpaGhribVKA8Mi4Hvm0DUsSuT6XkMi+qgeysH3H78TtJQz69f9Zopax4hSU1NxZlTJxEfH4eq1arj08ePCAsLlaorDQ0NODjUxCM51pXQrpnQ8ggxE/MohkgknEUZKPy91sOHD2FgYIAyZb41Evbs2YP169fD398flpaWGD16NLp3z32vSEGIjIpEamoqjIyMpNYbGRkjLCxUrlmYRzkzFXYeW2szXNkxEVoaavgan4huk7bg+bsgqKmp4MPncMwd3Raj5+9DbHwSxvVuBDMTfZiafBtvbmpUFIlJKYj6Ei9VZkj4F5Qwkh6TPm9sOwzvVu//bwbeoeO4jfnOnu5Xu2bKnkcIXr18gb69uiMpKRHaOjpYvsoTZcta49HDBwCAYj/UVTEjY7kOHRDaNRNaHiFmYh5SBgrvWR80aBDev38PANiyZQuGDh0KBwcHTJ8+HTVr1sSQIUOwbdu2bMtITExETEyM1JKYmJjvbD8+eCAWixX6MALz5ExomQorz8v3IajdYxEa9FuOzQduYrN7b1QoY4qUlDT0mLIN1pYmCLy6CBE+S1HPoRzO3PBFamr2PeIi0bd831ux6yLq9FiM1iM8kZqahi3uffKdPeN5f41rlldCy6NIVmXKwPvQUezy8kbXrj0wa/rvePPmtWR75nUl75TCu2ZCywMILxPzkJApvGf9xYsXKFu2LABg3bp1WLlyJYYOHSrZXrNmTcyfPx8DBw7MsgwPDw/MmTNHat30mbMxY9afecpkaGAIVVVVhIWFSa2PiAiHkZFxnsrMD+ZRvkyFnSc5JRVvA76V/cAvAPa2FhjVswHGzPfGQ78A1OmxGEWLaEFDTQ1hUV9xbedE3PcLAAAEhcdAU0MNBnraUr3rJsX0cPvJO6nzhEfFIjwqFq/9Q/HiXTBen3FH7apWuPPkfb5fw692zZQ9jxCoq2vAwsISAGBbuQp8ff/FX3t2YcDAIQCA8LAwmJgUl+wfGRGOYnKsK6FdM6HlEWIm5lEMvvGQjcJ71rW1tREa+u2jnU+fPqF27dpS22vXro13795ldqiEm5sboqOjpZYpv7vlOZO6hgYqVrLFbZ+bUutv+/jArlr1PJfLPL9OJnnnEYkATXXp994xXxMQFvUVZUuboEYlC5y48i8A4KFfAJKSU9CkTgXJvqbGRWFb1gy3H2f9u5b+t1VDvWDe4//q10zZ8giRWCxGUlISSpYqBWNjE9y69V9dJScn4d69u6gmx7oS2jUTWh4hZmIeUgYK71l3cXHB+vXrsWXLFjRo0AAHDx6EnZ2dZPv+/fthbW2dbRmamprQ1NSUWpff2WD69BuA6dOmolLlyrCzq45DB7wRGBiILt3kO36eeZQ3U2HlmTO6Dc7dfIaAoCjo6WqiS4saqG9fDu1GrwcAdGxaDaGRXxEQFInK1uZYOqUj/r7yBBdvf3ugNOZrAnYcvY2FE9ojPDoWkdFx8JjgiqevP+PSnRcAAAdbCzhUtoTPw7eI+hIHq5LGmDWiFd4EhBZIr3q6X+Wa/Sx54mJj4e/vL/n508ePeO7nB319fZiZmxfquVevXA7nevVRwtQUcbGxOHP6FO7d/QeeG7ZAJBKhV5++2Lp5IywtrGBhaYktmzdCW0sLLq3bFGquHwntmgktjxAzMY/8sWNdNgpvrC9atAhOTk5o0KABHBwcsGzZMly5cgUVK1bEixcvcPv2bRw5ckTuuVq6tEJ0VCQ2rV+H0NAQWJcrD88Nm2BuXlLuWZhHOTMVVp7ixfSwdW4fmBrrI/prPJ6++ox2o9dLGtqmxkWxaGIHFDfSQ1BYDLxO/AOPzWelypi67DBSU1OxZ+EAaGuq4/Ldlxg6exPS0r6NWY9PTIZrYzvMGNYKutoaCAqLwTkfP/SdtgNJyfl8J/ydX+Wa/Sx5fH2fYvCAvpKfly72AAC0c+2AuQsWFuq5I8LDMN1tKsJCQ1BETw/ly9vAc8MW1HV0AgD0HzgECQmJWDBvDmJiolGlqh3Wb9oGXd0ihZrrR0K7ZkLLI8RMzENCJ4h51qOiorBw4UL8/fffePv2LdLS0mBmZgYnJydMmDABDg4OMpeZ3551IiHKap51RcnvPOtEiv8fSBp7/OhnJLR51p2XXld0BIkbk+spOkKOBHH5DAwMsHDhQixcWLg9M0RERESkWHzAVDYKf8CUiIiIiIgyx8Y6EREREZFACWIYDBERERH9GjgMRjbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbjgKRjbsWSciIiIiEij2rBMRERGR3PABU9mwZ52IiIiISKDYWCciIiIiEigOgyEiIiIiueEoGNmwZ52IiIiISKDYWCciIiIiEigOgyEiIiIiueFsMLJhzzoRERERkUCxsU5EREREJFAcBkOkRCL/Wa3oCFIMa49TdAQpkXdWKToCyYifhtPPKE0sVnSEHwjrF42/97JhzzoRERERkUCxZ52IiIiI5EaFXesyYc86EREREZFAsbFORERERCRQHAZDRERERHLDUTCyYc86EREREZFAsbFORERERCRQHAZDRERERHIj4jgYmbBnnYiIiIhIoNhYJyIiIiISKA6DISIiIiK5UeEoGJmwZ52IiIiIKJfWrVuHMmXKQEtLC/b29rh+/Xq2+ycmJmL69OmwtLSEpqYmypYti23btuX6fOxZJyIiIiK5UeYHTL29vTF+/HisW7cOTk5O2LhxI1xcXPDs2TNYWFhkekzXrl0RHByMrVu3wtraGiEhIUhJScn1OdlYJyIiIiLKheXLl2PQoEEYPHgwAGDlypU4e/Ys1q9fDw8Pjwz7nzlzBlevXsXbt29RrFgxAICVlZVM5+QwmGx47/WCS/PGqFm9Crp36YgH9+8pLMv9e3cxZuRwNG3oDDtbG1y6eEFhWdIJqX6Elmnr5o3o2bUT6tasjob16mL8mJF4/+6tQrJ8rzDqZ0hnJ/yz73cEX12E4KuLcGX7eDR3rCjZvunPnoi/v0pqubpjglQZGuqqWD6lEwIuzkfYjcU4sHwwShbXl9rH2sIE+5cNRsDF+Qi+ugiXto5DfQfrfOf/Ee+h7AmlfgDWkTLmEdo1U3Se/fv2omuHdnCubQ/n2vbo26sbbly/Jtk+a/o0VK9cQWrp27Ob3PL9ChITExETEyO1JCYmZrpvUlIS7t+/j+bNm0utb968OXx8fDI95vjx43BwcMDixYtRsmRJlC9fHpMnT0Z8fHyuM7KxnoUzp09h8UIPDBk6At4Hj6JGDXuMHDYEgZ8/KyRPfHwcbGxsMG36LIWc/0dCqx+hZbp39x9069ELu/fux8bN25GSmorhQwYhLi5O7lnSFVb9fAqOwsw1f8Opz1I49VmKK3df4cDywaj4m6lkn7M3n8Gq+QzJ0n7sRqkylkzuiHaNqqKv2040GbQKRXQ0cWjlUKh89xTSkVXDoKamApdhnnDsvRSPX37C4ZVDUcJIL1/5v8d7KHtCqh+AdaSMeYR2zRSdp4RpCYyZMAle3gfh5X0QtWrVwYQxo/Dm9SvJPo7O9XD+ynXJsmb9xmxKVA4ikXAWDw8P6OvrSy2Z9ZADQFhYGFJTU1GiRAmp9SVKlEBQUFCmx7x9+xY3btzA06dPceTIEaxcuRIHDx7EqFGjcl9fYrFYnPvqVR4JuR8KlKle3bugYqVKmDFrjmRd+7YuaNS4KcZNmJTPdPljZ2uDFas90bhJU4VlEGL9CDFTuoiICDSqVxfbdu6BvUNNhWQojPoxrD0u0/WfLi3AH6uOY+ex29j0Z08Y6Gmj66Stme5btIgWAi7Mx6CZe3Dw/EMAgJlxUbw6NQftx23EhVvPYWSgi48XF6DpoFW4+ehbr1cRHU2EXl8Ml+GeuHL3JQAg8s6qPL2OdLyHsifk+gFYR8qQ50dCuGaFkSctH02rBo61MX7SFHTo1Bmzpk/Dly9fsGK1Z57LAwAddWGNEW+98R9FR5A43N8uQ0+6pqYmNDU1M+z7+fNnlCxZEj4+Pqhbt65k/fz587F79248f/48wzHNmzfH9evXERQUBH39b58YHz58GJ07d0ZsbCy0tbVzzMie9UwkJyXB75kv6jo6S62v6+iEx48eKiiVcAixfoSY6Xtfv3wBABTV189hz8Ihr/pRURGhS/Pq0NXWxJ0n7yTr69lb48P5eXhyeDo8Z3SDiWERybbqFUtDQ10NF27/90cuMCwGvm8CUadqGQBAeFQs/N4GoWebmtDR0oCqqgoGd3JEUFgMHvoFFEh23kPZE3r9AKwjoefJjKKv2Y8UmSc1NRVnTp1EfHwcqlarJll/7+4/aFzfEa6tW8B99kxEhIfLPdvPTFNTE0WLFpVaMmuoA4CxsTFUVVUz9KKHhIRk6G1PZ2ZmhpIlS0oa6gBQsWJFiMVifPz4MVcZ+YBpJiKjIpGamgojIyOp9UZGxggLC1VQKuEQYv0IMVM6sViMpYs9UL2GPcqVK6+QDIVdP7bWZriyfQK0NNTwNT4R3SZvxfN3wQCAczf9cPjCI/gHRsLKvBhmjWiF0xtGw7H3EiQlp8LUqCgSk1IQ9UV6/F5IxBepIS5tRq7D/uWDEXp9EdLSxAiJ+ALXMRsQ/TX34/6yw3soe0KuH4B1pAx5fiSEayaEPK9evkC/Xj2QlJQIbR0dLFu1FmXLfnsex8m5Ppo1bwkzc3N8+vQR69asxtBB/fHX/kPQ0NCQW8aCJoKwevpzS0NDA/b29jh//jw6dOggWX/+/Hm4urpmeoyTkxMOHDiAr1+/okiRbx1VL1++hIqKCkqVKpWr8yq8sT5mzBh07doV9erVy3MZiYmJGT7CEKtm/hGGLH6cWkgsFiv1dEMFTYj1I8RMHvPc8erlS+zY/ZdCcwCFVz8v34egdo/FMNDTRvsmdtg8pxeaD1mN5++CJUNbAODZm0A88AvAixOz4eJsi2OXn2SdFSJ8/0nyymldEBrxFU0Hr0Z8YjL6t6+LwyuHwrnvMgSFxeT7NUjOy3soW0KsH4B1lB2h5UknpGsGKC6PVZky2HfoCL7ExODi+XOYNX0atuzYjbJlrdHCpZVkP+ty5VHJtjJaNWuC61evoEmz5tmUSoVl4sSJ6NOnDxwcHFC3bl1s2rQJ/v7+GD58OADAzc0Nnz59wq5duwAAPXv2xNy5czFgwADMmTMHYWFhmDJlCgYOHJirITCAAIbBeHp6omHDhihfvjwWLVqU5QD97GT2cMCSRZk/HJAbhgaGUFVVRVhYmNT6iIhwGBkZ57ncn4UQ60eImQDAY/5cXLlyCZu370QJU9OcDygkhV0/ySmpePsxDA/8AjBr7Qn8+/ITRvVokOm+QWEx8A+MhLWFybefw2OgqaEGAz3pP1omxYogJOLbR9INa5ZHq3q26PvHDtx6/A6Pnn/E+IUHEJ+YjN5tauU7P8B7KCdCrR+AdaQseb4nlGsmhDzq6hqwsLCEbeUqGDthEsrbVMDePbsy3dfEpDjMzM3h7/9BrhkLmopIOIusunXrhpUrV8Ld3R3VqlXDtWvXcOrUKVhaWgIAAgMD4e/vL9m/SJEiOH/+PKKiouDg4IBevXqhbdu2WL16de7rS/aYBe/cuXNo1aoVli5dCgsLC7i6uuLEiRNIS0vL1fFubm6Ijo6WWqb87pbnPOoaGqhYyRa3fW5Krb/t4wO7atXzXO7PQoj1I7RMYrEYC+a54+KFc9i8bSdKlSot9wzfk3f9iEQiaGpk/sFdMX0dlCphgMD/94Y/9AtAUnIKmtSxkexjalwUtmXNcPv/4951tNQBAGlp0g9tpaWlFVgPIe+h7AmtfgDWkbLlAYR3zYSW5/+hkJSUlOmmqKhIBAcFwtjYRM6h6HsjR47E+/fvkZiYiPv376N+/fqSbTt27MCVK1ek9q9QoQLOnz+PuLg4BAQEYNmyZbnuVQcEMAwGAKpUqYImTZpgyZIlOHLkCLZt24b27dujRIkS6N+/PwYMGABr66znU87sqd38zgbTp98ATJ82FZUqV4adXXUcOuCNwMBAdOnWPX8F51FcbKzUO7VPHz/iuZ8f9PX1YWZuLvc8QqsfoWVaMHcOTp86gZVr1kFXRxdhod/GhxbR04OWlpbc8wCFVz9zRrXBuZvPEBAcBT1dTXRpXgP17a3RbswG6GprYMYwFxy9+BiBYTGwNC8G91FtEB4Vi+P/HwIT8zUBO47dxsLx7REeFYfImFh4jG+Pp68/49KdFwCAO/++R+SXOGyZ0xsLNp9BfGIyBnaoC6uSRjhzwzffdZOO91D2hFQ/AOtIGfMI7ZopOs+alcvhVK8+TE1NERsbi7OnT+He3X/guWEz4uJiscFzLZo0aw4TExN8/vQJa1atgIGhIRo3VdxscCR/Cp+6UUVFBUFBQShevLjUen9/f2zbtg07duxAQEAAUlNTZSo3v4114NsXSezYthWhoSGwLlceU353U9jUUnf/uYPBA/pmWN/OtQPmLliogETCqh+hZbKztcl0vfs8D7h26CjnNP8p6PoxrD0O62f2QKNa5WBqrI/or/F4+uozlu28iEt3XkBLUx37lw2CnU0pGOhpIygsBlfvvYL7+lP4GBwlKUdTQw0e41zRtaU9tLXUcfmflxi/8IDUPjUqlsafo1qjRkULqKupwu9tIBZsPotzPn6SffI7dSPAeygnQqkfgHWkjHmEds0KK09up278c+Z0/HPnFsJCQ1FETw/lyttgwMDBqOPohISEBEwcOwrPn/vhS8wXGJuYoGatWhg5ehxMzcxkyiO0qRtdNyv+SxTTHRvioOgIORJsYz2dWCzGhQsX0KxZM5nKLYjGOhFlL6t51hWlIBrrRET5lZ951gsDG+tZU4bGusLHrFtaWkJVVTXL7SKRSOaGOhERERHRz0DhY9bfvXuX805ERERE9FMQwMyhSkXhPetERERERJQ5NtaJiIiIiARK4cNgiIiIiOjXocJxMDJhzzoRERERkUCxZ52IiIiI5IYd67JhzzoRERERkUCxsU5EREREJFAcBkNEREREciPiOBiZsGediIiIiEig2FgnIiIiIhIoDoMhIiIiIrnhKBjZsGediIiIiEig2FgnIiIiIhIoDoMhIiIiIrlR4TgYmbBnnYiIiIhIoNizTkR5FnlnlaIjSGmy4rqiI2RwcUI9RUeQkpIqVnQEKWqq7GHLiVhYl0xwDwee9wtWdIQMmlUsoegIgiawW0jw2LNORERERCRQbKwTEREREQlUrobB+Pv7y1SohYVFnsIQERER0c9NJLSxVAKXq8a6lZWVTBWbmpqa50BERERERPRNrhrr27Zt47sgIiIiIiI5y1VjvX///oUcg4iIiIh+BSrs/5VJvh4wjY+Px6dPn5CSklJQeYiIiIiI6P/y1Fi/fPky6tatCz09PVhaWuLJkycAgFGjRuHw4cMFGpCIiIiI6Fclc2P90qVLaN68ORISEjB58mSkpaVJthkbG2PHjh0FmY+IiIiIfiIikUgwizKQubE+a9YstGrVCg8fPsS8efOkttnZ2eHRo0cFlY2IiIiI6JeWqwdMv/fw4UMcOHAAQMZ5Mk1MTBASElIwyYiIiIjop6MkHdqCIXPPupqaGpKTkzPdFhISAj09vXyHIiIiIiKiPDTWa9asid27d2e67eDBg6hbt26+QxERERERUR6GwUybNg0tWrRAhw4d0LdvX4hEIty5cwfbtm3DwYMHcfny5cLISUREREQ/AWV5sFMoZG6sN23aFDt37sT48eNx7NgxAN+mbDQwMMCOHTvg7Oxc4CGJiIiIiH5FMjfWAaB3797o1KkTbt68iZCQEBgbG8PJyQm6uroFnU+hvPd6Ycf2rQgLDUVZ63KYOu0P1LB3YB6B5lFkpvv37mLHtq3we/YUoaGhWLHaE42bNJVst7O1yfS4CZOmoP/AwYWeb+vmjbh4/hzevXsLTS0tVKtWHeMnToZVmd8K/dy5sXXzRqxeuRy9evfFVLfp+S7v4NCaMNPXyrD+0MPPWH7hDQY6WqBpBRMU19NEcloaXgR/xabrH/As8Itk3ynNrVHT0gDGuhqIS07D008xWHftHfwj4jOUq64qwube1VCueBH03/kAr0Ji8/0a5H3Ntm3ZiMsXz+P9u7fQ1NRC1WrVMXb8pCzPN999Fg4f3I9JU9zQs08/qfV3bt9CWGgItHV0YGdXHWMmTEaZfObev+8v7Pfei8+fPgEAylqXw7ARI+FcrwEAIDwsDCuXL8Utnxv48uULatg7YNr0mbC0tMrXeWWV098Cedq6eSPWrFqOnr37Yuq0/36v3r55g1UrluD+vbtIS0tDWetyWLxsJczMzOWSqbDua5+zR3Hr7FFEhAYBAExLl0HTzv1QsUYdAMC+tQtw78oZqWMsylXCWI8NGcoSi8XYMn8qXjy6g/5T56NyrXqSbdsWTsPn96/xNToK2rpFUK6qA1r3Hg79YsYyZ87pflnvuQZnTp9EUFAQ1NXVUamSLUaPm4CqVe1kPhcprzw11gFAW1sbTZsq5g+QPJw5fQqLF3pg+szZqFa9Bg7u34eRw4bgyPGTMDMv/D9ozKNcmeLj42BjYwPXDh0xafyYDNsvXrkh9fONG9fw58zpaNqsRaHmSnfv7j/o1qMXbKtUQWpKKtasXoHhQwbh8PGT0NHRkUuGrDz99wkOHvBG+fKZv6HJi8G7H0HluydyfjPWxaquVXD5RRgAICAyHssvvsHnqARoqqmgm0NJrOhSGd0230NU/LcH6F8EfcW5ZyEIjklEUS01DHKyxIouldFl012kiaXPN7JBGYR9TUK54gX2EuR+zR7cu4su3XvC1rYKUlNT4blmBUYNH4yDR05A+4fzXb50AU//fQKT4hlfcMVKtnBp1RamZmaIjo7GpvVrMWrYIPx9+gJUVVXznK94CVOMmzAZpS0sAAB/HzuKcaNHwfvQEZQta43xY0dBTU0NK9esQ5EiRbBr5w4MGzRA7vd4Tn8L5OXpv09w6GDG36sAf38M6NsT7Tt2wohRY1GkiB7evn0DTQ1NueQqzPta38gErXoPg7FpqW/nunIGOxb/gQlLtsK0dBkAgE212ug2aprkGDU19UzLun7iQJYzlljb1kCTjn2gZ2iEmPBQ/L1rHXYtnYkxC9bLnDmn+8XS0gpu02ehVKnSSEhMwJ5dOzBiyED8ffo8ihUrJvP5hEKFo2BkkqfGekxMDDw9PXH58mWEh4fDyMgIjRo1wogRI2BgYFDAERVj987t6NCpEzp27gIAmOo2HT4+N7Dfey/GTZjEPALLo+hMzvUaSHr4MmNsYiL185VLF1GzVm2UKl26UHOlW79pq9TP7vM80KheXfg984W9Q025ZMhMXGws3H6fgtlz5mHzRtn/o8tKeoM7XZ9axfAxMh4PA6IBAOf9QqW2r778Fm2rmqKsiS7u+0cBAI4/CZJsD4pJxKYb77Grvz3M9LXwKSpBsq1OGUPUsjLE9GN+qPtbwf3nKe9rtnbDFqmf/3T3QNOGjvB75osa350vJDgYixfMxdoNWzBu9LAM5XTs3E3yb/OSpTByzHh07+yKz58/oXRpizzna9iosdTPY8ZNwP59e/Hk8SOoqanhyeNHOHTsBKytywEAps+cjUb1HHHm1EnJ3wR5yOlvgTzExcXij2lTMOvPjL9Xa1evgHO9+pgwaapknbz+DgGFe1/bOjhJ/ezScwh8zh3Fh5e+ksa6mro6ihoaZVvO5/evcfWEN8Yt3AT3IR0ybK/ftqvk38VMTNG4Qy/sWDwdqSkpUFWTrVmV0/3Sqk1bqZ8nT3XDkUMH8erlC9Suwwk9fhUyzwbz7t07VK1aFdOnT8erV6+goaGBV69eYfr06bCzs8Pbt28LI6dcJSclwe+ZL+o6So+/r+vohMePHjKPwPIINVNWwsPCcP3aVXTo2FlhGb5++Tbco6i+vsIyAMCCee6oX78B6tR1LLRzqKmI0LxScZz8NzjL7a52pviSkILXoV8z3UdLXQWtK5viU1Q8gmMSJesNddTxe4tymHvyBRKSUwslfzp5X7OvXzOeLy0tDTP/mIo+/Qeh7P8bxdmJj4vD8aOHUbJkKZiamhZYttTUVJw+dRLx8XGws6uO5KQkAJDqHVZVVYW6ujoePrhfYOdVFgvmuaNeJr9XaWlpuH7tCiytrDBi6CA0ql8XvXt0waWLFxSUtPDu67TUVDy8cRFJCQmwLF9Zsv6N7yPMHtgOC8f0xIH1i/ElOlLquKTEBOxZOQcdBo3PsVEPAHFfYvDg+nlY2lSWuaEuq+SkJBw64A09PT2Utym4TyIVQdHfWqps32Aq8501btw4JCQk4ObNm1LTNPr4+KBjx44YP348jh8/XqAh5S0yKhKpqakwMpL+RTUyMkZYWGgWRzGPovIINVNWjh87Ah0dXTRp1lwh5xeLxVi62APVa9ijXLnyCskAAKdPnYSf3zP85X2wUM9Tv5wRimip4dRT6ca642/FMKdtBWipqyD8axLGH/gX0fEpUvt0qGaGkQ3KQEdDFe/D4zDhwFOkfDcGZrpLeRx9FIjnwV9hWrTwhhHI+5qJxWIsX7IQ1arbw/q78+3Ythmqaqro0atPtsfv3/cXVq9Yivj4OFiV+Q2em7ZBXV0j37levXyBPj27IykpETo6Olix2hNlra2RnJwMc/OSWL1yGWbOdoe2tjZ27dyBsLBQhIYK6/e/sJ05dRLP/Z7Ba1/G36uIiHDExcVh29bNGDVmPMZNnAyfG9cxafxobN62Cw41a8k1a2Hc14Ef3mDN9JFISUqChpY2+k+dB9PSVgCACtVro2rdRjA0KYGIkECc3bcVG/4cjwmLN0Pt//fn8R1rYGVTWWqMemZO7F6Pm2eOIDkxAZblbTHQbWGB5M/M1SuX8fvkiUhIiIexiQk2bN4GQ0PlHQJDspO5Z/3SpUuYP39+hvnUHR0dMW/ePFy6dEnmEGvWrEG/fv2wf/9+AMDu3btRqVIlVKhQAX/88QdSUlKyPT4xMRExMTFSS2JiYrbH5MaP77jEYrFC34UxT86EmOlHR48cQqs2baGpKZ8xoj/ymOeOVy9fYtGS5Qo5PwAEBQZi8cL5WLBwSaHXQ5sqprj9NgJhsUlS6x8ERKH/zgcY7vUYt99FYm7bijDQkR6/eu5ZCAbsfICRex/jY2Q83NtWgIbqt/upcw1z6GqqYvedgELND8j/mi1aMBevXr3AgkXLJOv8nj3FPq/dmDPXI8ffKZfWbfHX/sPYvG03LCwsMW3y+AL5m2xlVQb7Dx3F7r+80aVbD8z843e8ef0a6urqWLZyNT68f496jrVQ26Ea7t29A+d69aGqKvN/c0or/fdqvkfmv1dpaWkAgIaNmqBP3/6oUKEiBg4eivoNGuLg/n3yjlso97WJuQUmLtmKMQvWw7GFK/atXYCggPcAgGpOTVDJvi7MLH6DrYMTBk9fjLDAAPjdvwUA8L17A6//fQDX/jk/a9DItQcmLtmKoTOXQaSigr1r5kMsFud4XF7UrFUb+w8dxS6vfXByrocpk8YjPDy8UM5FwiRzz7qmpiZKZzG+zcLCQub/eOfOnYslS5agefPmGDduHN69e4clS5ZgwoQJUFFRwYoVK6Curo45c+ZkWYaHh0eG7dNnzsaMWX/KlCWdoYEhVFVVERYWJrU+IiIcRkayP+2dX8yjnJky8+D+Pbx/9w6Ll65UyPk95s/FlSuXsG3nHpQowGEJsnr2zBcR4eHo0bWjZF1qairu37uLfXu9cPfhv/l6GDFdiaKacLA0wB/HnmXYlpCchk9RCfgUlQDfwC/YN9gBbauUwO47HyX7xCalIjYpFR+jEuD72Q9nxtRF/XLGuPA8FPYW+rA1K4rLE6WHXm3pUx3nn4Vg3umX+c4PyP+aLfaYi2tXLmHzdunzPbx/HxER4Wjd4r+x46mpqVixbBH+8tqJE2f+66jR09ODnp4eLCytUMXODg2dauPyxfNo2apNvrKpa2jAwtISAGBbuQp8n/4Lrz27MOtPd1SyrYz9h4/hy5cvSE5ORrFixdCrexfY2lbOodSfx7NnvoiICEfPbtK/Vw/u34X3Xi/cuvttfH/ZsmWljivzW1m5DxcqrPtaTV0dxmbfHjAtbV0BAa+f48apA+g8bEqGfYsaGsPQuARCA7/9zr9++gDhwZ8xs19rqf12Lp2JMhWqYqT7ask63aIG0C1qABPz0iheyhLzhnXGh5e+sLIp+PtNR0cHFpaWsLC0RFW7amjr0hxHDx/EoCEZnxlRFsLqQhM+mRvrrq6uOHDgAJo3z/gR/oEDB9CmjWx/jHfs2IEdO3agY8eOePz4Mezt7bFz50706tULAFChQgVMnTo128a6m5sbJk6cKLVOrJr33jp1DQ1UrGSL2z430aRpM8n62z4+aNi4SZ7LZZ5fK1Nmjhw6iEq2trCpUEGu5xWLxfCYPxeXLp7H1h27UaqU/B4oy0ztOnVw8OjfUutmT3eD1W+/YcCgIQXSUAeA1pVLIDIuGbfeROS4rwiAeg69sCIRJD3rKy++xaYbHyTbTIpoYEWXKpj9tx98P3/Jqohck/c1E4vFWOwxF5cvXcCmrbtQslQpqe2t2rZDrR8eaBs9YjBatXFFO9eMD+FJlQ0xkpKTst0nr5nTx6un09PTAwB8+PAez3yfYtSYcQV+XqGqXacODh6R/r2aNcMNZcp8+73S0NBAJdsqeP/undQ+H96/h5l5SblkVMR9nZKcnOm22C/RiAoPlYxNb9S+F2o1kW7DLJvYH+36jUYlh2yeq/l/j3pW5yloYrEYSUkF//tEwpWrxvqDBw8k/+7ZsycGDRqELl26oGfPnjA1NUVQUBC8vLxw7949bN26NZuSMgoMDISDw7d5sO3s7KCiooJq1apJtteoUQOfP3/OtgxNTc0MPfoJ2Y+cyVGffgMwfdpUVKpcGXZ21XHogDcCAwPRpVv3/BXMPD9lprjYWPj7+0t+/vTxI577+UFfX18ybeTXr19x7twZTJrye6Hn+dGCuXNw+tQJrFyzDro6ugj7/zjeInp60NLKOB95YdPVLZJhjKq2jg4M9A0KbOyqCN8a66d9g5H63afTWuoq6FenNG68/jY0Rl9LDR2rm8NET1MytaO5vhaaVDDGP++jEBWXDGM9DfSuVQqJKWnwefftgbTgL4nAd23y+KRvD5h+ikpA6Nf8/0cq72u2cL47zpw+geWrPKGjqyt51qNIkW/nMzAwhIGBodQxampqMDYylsyR/fFjAM6dOYW6jk4wMCyG0JBg7Ni2BVqamnB2zt8MKatXLodzvfooYWqKuNhYnDl9Cvfu/oN1G7/NYnPu7GkYGhaDmZk5Xr16gcUeC9CocVM4Osn3i/py87egsOjqFpF6xgAAtLV1oG9gIFnff8AgTJ08ATUcaqJmrdrwuXEd165expbtuwo1W7rCvK9PeW1Cheq1YWBcHInxcXh08xLePHuEIdOXIDE+Duf2b0eVOg1Q1NAIESFBOP3XJujq6aNy7foAgKKGRpk+VGpoUgJGJb5dO/9Xz+D/2g9lKlSFdhE9RAR/xtl922BkWhJWNrYyZ87uftE3MMCWTRvQsFFjGJuYIDoqCt77/kJwcBCatWiZx1oiZZSrxrqDg4PUGEWxWIyAgAAcPnxYah0ANG/eHKmpuZ8VwdTUFM+ePYOFhQVevXqF1NRUPHv2DLa23256X19fFM9kLt/C1tKlFaKjIrFp/TqEhobAulx5eG7YBHM59T4wj3Jl8vV9isED+kp+XrrYAwDQzrUD5i749uDRmVMnAbEYLvkcCpAX+733AgAG9Zd+MNB9ngdcO3TM7BClV9PKAKb6WhlmgUlLE8OymA5cXEtAX1sdMQnJ8Av8ipF7H+NdeBwAICklDXal9NHVviT0tNQQEZuMxx+jMdzrMaLi5NN7Ju9rdnD/t/MNHdhXav3suQvQzjV359PU0MCjB/exd88uxMTEwMjICNXtHbBt114UM8p5Zo3shIeHYfq0qQgNDUERPT2UL2+DdRu3oK7jt+n6QkNDsXTxQoSHhcPExARt2rli2PCR+TpnXuTmb4EiNW7aDDNm/YmtWzZhscc8WFqVwdIVq1G9hny+0K4w7+uv0RHYu2Y+YiLDoaWjC3PLshgyfQnK29VEcmIiAv3f4t7Vs0iI+wo9AyNYV66OPhP/hJZ27ud3V9fQxL93ruGc93YkJSZAz7AYKlSrjd4TZkseUpVFdvfLjNlz8O7dWxw/dgRRkZEwMDCAbeUq2L7LSzJFqbJSEdizZEInEufiiYidO3fKVGi/fv1y3un/ZsyYgU2bNsHV1RUXL15E9+7d4eXlBTc3N4hEIsyfPx+dO3fG8uWyPYCS3551IlI+TVZcV3SEDC5OyH5WCXlLSS2ch+DySk2V/2nnpJCeW8wzobWzzvtlPi2rIjWrWELREaRoFe6skjIb7P1U0REktnQT/nMtubp8sjS+ZTVnzhxoa2vj9u3bGDZsGH7//XdUrVoVU6dORVxcHNq2bYu5c+cW2vmJiIiIiIRK4e+1VFVVMX36dKl13bt3R/fuihv7TERERESFQ2ifzghdnhrrERER+Ouvv+Dn54f4+HipbSKRSOaHTImIiIiIKCOZG+v+/v6oWbMm4uLiEBcXB2NjY0RERCA1NRWGhobQV/DXlxMRERGRcAntywqFTuavdps2bRpsbW0RHBwMsViM06dPIzY2FmvWrIGWlhZOnjxZGDmJiIiIiH45MjfWb926hREjRkjmQxWLxdDQ0MCoUaMwaNAgTJmS8VvCiIiIiIhIdjI31oODg2FmZgYVFRWoqqoiJiZGsq1Bgwa4ceNGgQYkIiIiop+HSCScRRnI3FgvUaIEIiK+fXW3lZUV7t27J9n2/v17qKkpfIIZIiIiIqKfgswt6zp16uDhw4do164dOnbsCHd3dyQmJkJDQwNLlixB48aNCyMnEREREdEvR+bG+uTJk/H+/XsAwKxZs+Dn54fZs2dDLBajfv36WLlyZQFHJCIiIqKfhYqyjD8RCJkb6/b29rC3twcA6Orq4vjx44iJiYFIJIKenl6BByQiIiIi+lXJPGY9M0WLFoWenh6uXbvGYTBERERERAWkQJ8GDQ0NxdWrVwuySCIiIiL6iXAUjGwKpGediIiIiIgKHudZJCIiIiK5EbFrXSbsWSciIiIiEig21omIiIiIBCpXw2CqVq2aq8JiYmLyFYaIKD8uTqin6AgZGNaZoOgIUiJvr1B0BClpYrGiI0gR4vzPAowkKM0qllB0BJIRe4plk6vGerFixXI1vsjIyAhlypTJdygiIiIiIsplY/3KlSuFHIOIiIiIiH7E2WCIiIiISG44G4xsOGyIiIiIiEig2LNORERERHKjwo51mbBnnYiIiIhIoNhYJyIiIiISKA6DISIiIiK54TAY2eS5sf78+XNcvXoVYWFhGDRoEExNTfH582cYGhpCW1u7IDMSEREREf2SZG6sp6amYujQodixYwfEYjFEIhFcXFxgamqKYcOGoXr16nB3dy+MrEREREREvxSZx6zPnz8ff/31F5YsWYKnT59C/N1XRbu4uODMmTMFGpCIiIiIfh4ikUgwizKQuWd9x44dmDlzJiZOnIjU1FSpbWXKlMG7d+8KLBwRERER0a9M5p71T58+oW7duplu09LSwpcvX/IdioiIiIiI8tBYL168ON6+fZvpthcvXqBUqVL5DkVEREREPycVkXAWZSBzY71Vq1aYP38+Pn36JFknEokQHR2N1atXo23btgUakIiIiIjoVyVzY93d3R0pKSmoVKkSOnXqBJFIhD/++AOVK1dGQkICZs6cWRg5FcJ7rxdcmjdGzepV0L1LRzy4f495/s+lWWPY2dpkWBbMnaOwTICw6khoee7fu4sxI4ejaUNn2Nna4NLFCwrL8j0h1VFh5jE30cc29174eGEewm8swm2vyaheQfqTyOlDW+Dt6T8RcWMRzm4chYq/mUq2WZgZIv7eikyXjk3sJPtVsymFE57DEXh5AT5emIe1f3SFrrZGnjLLcs+4/zkLdrY22LNrR57OlRutmjdG9coVMiwe877NQHbx/DmMHDoIjZzroHrlCnjx3K/QsmRHSPd0cHAw3H6fjPqOtVHb3g5dO7rime9TheVJJ6Q6Yh75E4mEsygDmRvrJUqUwN27d9GjRw/cv38fqqqqePz4MVxcXODj44NixYoVRk65O3P6FBYv9MCQoSPgffAoatSwx8hhQxD4+TPzAPDyPoiLV25Ilo1btgMAmrVoqZA8gPDqSGh54uPjYGNjg2nTZynk/JkRWh0VVh4DPW1c2joWySmpaD9uE6p3WYhpK48h6ku8ZJ9J/RpjbM+GmLD4EJz7rUBweAxOeg5HER1NAMDH4ChYtZgltbhvOI2vcYk46/OtUWpmXBQn1w3Hm4Aw1O+/Aq5jN6JSWVNs/rNnnnLn9p65dPECnj55DJPixfN0ntzas+8gzl+5LlnWb94GAGjWvMX/88bDrnoNjBk/qVBzZEdI93RMdDT69+4BNTV1eG7YjMPHT2LS1GnQ0ysq9yzfE1IdMQ8pA5H4+7kXfyIJKfk7vlf3LqhYqRJmzPqvp7h9Wxc0atwU4ybI/z8CoeX50WKP+bh29Qr+Pn1OYVMhCa2OhJbne3a2Nlix2hONmzRVaA6h1VFh5DGsMwFzR7dBXbsyaDpkTZb7vT0zB557r2LZzksAAA11VXw4Nxcz1vyNrYdvZXrMLa9JePT8I0bM9QYADOxQF7OGu6BMy9mSaXWrljfHnb+mwLb9fLz9GIbI2yvy9DqyumeCg4PRu0cXrN+0FWNGDEOvPn3Ru2//XJeblo//gpYsXIDrV6/g2KmzUn93Pn/6iNYtmmLfwSOwqVBRpjJV8vn3S0j39MrlS/Ho4QPs2P2XXM+bEyHV0a+SR0tg31c/9eQLRUeQWNzaRtERciRzz3pBCwwMxKxZs9C4cWNUrFgRlStXRtu2bbF169YMU0PKS3JSEvye+aKuo7PU+rqOTnj86OEvn+dHyUlJOHniONp37KSwhrrQ6khoeYRIaHVUmHla17fFA78AeC3shw/n3HHLaxIGtK8j2W5V0ghmxkVx4fZ//4ElJafi+oPXqFO1TKZlVq9QCtVsSmHnsTuSdZoaakhOTpH6/ov4xGQAgGO1zMvJj7S0NEyfNgX9BwyCtXW5Ai8/O8nJSTh14jhcO3QUzFzJQrunr16+BFvbypg8YSwa1quLrp3a49CB/XLP8T2h1RHzKIaKSCSYRRnI/F5r4MCB2W4XiUTYunVrrsq6d+8emjZtijJlykBbWxsvX75Er169kJSUhMmTJ2Pr1q04e/Ys9PT0ZI2ZL5FRkUhNTYWRkZHUeiMjY4SFhco1ixDz/OjSpQv48uUL2rXvoLAMQqsjoeURIqHVUWHmKVPSCEM6OWK11xUs3n4BDrYWWDa5AxKTU/DXyXswNfr2Ny4kXHrq25Dwr7AwM8y0zH6uteH3Ngi3n7yXrLty9xUWTXDFhD6NsHbvNehqa8B9VGsAgKlxwQ992L51M1TV1NCzd98CLzsnly9exJcvX9BWgX93fiS0e/rjxwDs996LPv0GYNDQ4Xj67xMs8pgHDQ0NtHVtL/c8gPDqiHlIGcjcWL906VKGXozw8HB8/foVBgYGMDAwyHVZ48ePx4QJEzB79mwAwJ49e7B27Vrcvn0bkZGRaNy4MWbMmIFVq1ZlW05iYiISExOl1olVNaGpqZnrLJn58XWKxWKF9uAILU+6I4cOwcm5PooXL6HoKIKrI6HlESKh1VFh5FFREeHBswDMXncKAPD4xSdU+s0UQzs54a+T/z049uOIEJEIyGykopamOrq1tMfCLeek1vu9DcKQ2X9h4QRXuI9qjdQ0Mdbtu4agsBikpRXsiMdnvk/htXsX9h08rJDrdfTwQTg51xPE350fCeWeTksTw7ZyZYwdPxEAULFiJbx5/Rr7vfcqrLGeTih1lI55SMhkHgbz/v17vHv3TmqJiYnBhQsXULx4cRw7dizXZT148AB9+vSR/NyzZ088ePAAwcHBMDQ0xOLFi3Hw4MEcy/Hw8IC+vr7UsmSRh6wvTcLQwBCqqqoICwuTWh8REQ4jI+M8l/uz5Pne58+fcOe2Dzp27qzQHEKrI6HlESKh1VFh5gkKi4Hfu2Cpdc/fBaO0qcG37f/vUS9hLP0pokmxIgiJ+JqhvA5N7KCjpQ6vk3czbPM++wBlWs5G2VZ/omST6Zi36SxMDIvg/afwfL2GHz24fw8REeFo2bQRalSthBpVK+Hz509YtmQRXJo1LtBz/ejb351baN+pS6GeR1ZCu6dNTEzwW9myUut+++03BAYq7kFFodUR8yiGioAWZVBgORs3bozRo0dj3LhxuT6mePHiCAwMlPwcHByMlJQUFC367ePacuXKISIiIsdy3NzcEB0dLbVM+d1N9hfxf+oaGqhYyRa3fW5Krb/t4wO7atXzXO7Pkud7x44cRrFiRqhXv6FCcwitjoSWR4iEVkeFmefW43cobyk9U0o5y+LwD4wEALz/FI7AsBg0qf3fg07qaqqoV8Mat5+8y1Bef9faOHnNF2FRsVmeMyTiK2Ljk9C5eTUkJCXj4p2CfaCrTTtXHDhyHN6HjkoWk+LF0W/AIKzftKVAz/Wj45K/Ow0K9TyyEto9Xa16Dbx/J33/fHj/HubmJeWeJZ3Q6oh5SBkU6PPBlSpVwrRp03K9f/v27TF8+HAsWbIEmpqamDt3Lho0aABtbW0A374RtWTJnP+oaGpmHPKS39lg+vQbgOnTpqJS5cqws6uOQwe8ERgYiC7duuev4J8kD/Dt4bJjRw6jrWt7qKkp/lFzodWR0PLExcbC399f8vOnjx/x3M8P+vr6MDM3V0gmodVRYeVZ89dVXN42DlMGNMWh849Q09YCAzvUwej5/z3s57n3KqYMaIrX/qF4HRCKqQOaIj4hCd5nHkiV9VspYzhX/w3tx23O9FzDuzrj9uP3+BqfiCa1y2PBuHaYueYEor8myJw7p3vGwEB6PL26mjqMjY1hVeY3mc+VW2lpaTh29AjaZPJ3Jzo6CkGBgQgJCQEASUPVyNgYxsYmhZbpe0K6p3v37Yd+vXtgy6YNaN7CBU//fYKDB/dj1p/ucs/yPSHVEfOQMijQFtbVq1dhbJz7j2nmzZuHwMBAtG3bFqmpqahbty727Nkj2S4SieDhkffhLPnR0qUVoqMisWn9OoSGhsC6XHl4btiksB4JoeUBgNu3fBAY+BntO3ZSWIbvCa2OhJbH1/cpBg/470HApYu//W61c+2AuQsWKiST0OqosPLcfxaAbpO3wX10a/wxuDnef47AlGVHse+7hviynZegpamOldM6w1BPG3effkCb0RvwNU76eZx+7Wrhc0i01Mwx33OwtcCMoS1RREcTL94HY/SCA9h7Km9fqCLEe+bOLR8EBX5G+w4dM2y7evkSZs/4Q/LztCnfxmoPGzEKw0eNkUs+Id3TlatUxfJVa7F65XJsXO+JkqVKYervf6B1m3Zyz/I9IdUR8ygGh9/LRuZ51t3dM74jT0xMxJMnT3D69GlMmTJF5gZ2QkICUlJSUKRIEZmOy7bMfPasExEVBMM6ExQdQUpe51kvLPmZZ70wKMtUbkSyENo869NPv1R0BIn5LuUVHSFHMl++P//8M8M6TU1NWFlZwd3dHVOmTJE5hJaWlszHEBEREZHy4Zti2cjcWE9LSyuMHERERERE9AOZZoOJj49Hz549cePGjcLKQ0RERERE/ydTY11bWxvHjh1j7zoRERER5YlIJJxFGcg8z3q1atXw9OnTwshCRERERETfkbmxvnDhQixevBhXr14tjDxERERERPR/uXrA9Nq1a6hRowaKFCmCkSNH4uvXr2jcuDEMDQ1hZmYG0XefI4hEIjx+/LjQAhMRERGR8lJRkuEnQpGrxnqjRo1w69Yt1KpVC0ZGRjJ98REREREREeVNrhrr339v0pUrVworCxERERERfUdg32lFRERERD8zfimSbHL9gKmIFUtEREREJFe57llv1KgRVFRybtuLRCJER0fnKxQRERER/ZzY/yubXDfWGzZsCBMTk8LMQkRERERE38l1Y33WrFmoVatWYWYhIiIiIqLv8AFTIiIiIpIbzrMuG5m/wZSIiIiIiOSDjXUiIiIiIoHK1TCYtLS0ws5BRPRTCvdZrugIUgybzVV0BClhZ2coOoI0AX48n/bdFxMKgUiIlSQwnO0ke7yHZMOedSIiIiIigeIDpkREREQkN3zAVDbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbjgMRjbsWSciIiIiEig21omIiIiIBIrDYIiIiIhIbkSciF4m7FknIiIiIhIoNtaJiIiIiASKw2CIiIiISG44G4xs2LNORERERCRQ7FknIiIiIrnh86WyYc86EREREZFAsbFORERERCRQgmisx8bGYvPmzRgwYABcXFzQqlUrDBgwAFu2bEFsbKzCcnnv9YJL88aoWb0KunfpiAf37yksi9DyrPdcAztbG6mlcX0nheVJJ5Q6cmnWOEP92NnaYMHcOQrJk04o9SPUTMHBwXD7fTLqO9ZGbXs7dO3oime+TxWSZeuWjahepQKWLFogtf7t2zcYN2YE6tV1gFPtGujbqxsCAz/LVPaQdvb4Z8tQBJ+YiuATU3Fl7QA0r1VWap/p/erj7YHxiDgzDWdX9EFFK5Msyzu6sAfiL89EWycbqfXWpYph/7yuCDg6CcEnpuLSmv6oX81SpqzfCwkOxvRpU9DIuTYca1ZD987tJdcnOTkZq5YvRdcObeFYqzqaN66HmX/8jtCQ4DyfLy9iY79iscd8tGzaCLVqVEXfXt3x9N8ncjn3/n170bVDOzjXtodzbXv07dUNN65fk2y/eP4cRg4dhEbOdVC9cgW8eO5X6Jnu37uLsaOGo1kjZ1SrbINLFy9k2OftmzcYN3o4nOvYw7FWdfTp2VXmezq3tm7eiJ7dOsGxVnU0ql8X48eOxPt3byXbk5OTsXL5EnTu0BZ1alZDs0bOmOE2FSFyvI/u37uLMSOHo2lDZ9jZZl5nyk5FJBLMogwU3lh/9uwZypcvj6lTpyIyMhIWFhYoVaoUIiMjMWXKFNjY2ODZs2dyz3Xm9CksXuiBIUNHwPvgUdSoYY+Rw4Yg8HPh/AFRtjwAUNa6HC5euSFZDh79W2FZAGHVkZf3Qam62bhlO/C/9u48rqb0AQP4c7WSJBUVo7IlRZStSHay7zsxGGYYxGQnDLKMfez7LmQwxj5ikH3fxq5EaU+blnvP749+3XGV0nbPiec7n/P5TO9573mfzrn3eu973/MGoEWr1mrPkk5K50eKmd7HxGBgv97Q1NTCyjXrceDwXxg3fiL09UuoPcuD+/dwYP9eVK6i2vl9/ToQ3w/oAyurCli/aRt89h/C0GE/QkdbJ0fHfxP2HtPWn0GD4RvQYPgGnL31Cvtm91R2yMf1csao7vXhsfw4Gg7fiHeR8fhrYV8UL6qd4Vg/d6sHQRAybecP717Q1CgCt7Hb4TxsA+48C8GBub1QxlAvR3mBtOszaEBvaGpqYsXq9dh/8Ag8fpkA/RJp1+fDhw/499FDDBn2E3b5+OK3JSsQEPAKY37+Kcdt5cWM6VNx6ZI/5sxbgP1//Akn5wYYNmQQ3r0r+M5eGdMy+NljHHb67MdOn/2oW7c+PH4egefPngIAEhMTYV/LAT+PGVfgWdIlJiagirU1Jk6enun+14GBGDSgDyytKmDD5u3Y63sYQ4f9lOPn9Je6cf0qevbui2279mLNus2Qp8rx4w+DkZiQACDtefTo4UMMHfYj9uw9gEVLf097Ho38sUDyZCYxMQHW1taYOCXzc0bfHpnwuXdZNWnSpAlMTU2xdetWaGur/kOQnJyMgQMHIjg4GH5+fjk67ofUvOXq26s7bKpVw9Tp/42EdmrvhiZNm2O0h/re6KSaZ/XKFfD7+zT2Hjik9rY/R2rn6GMLvOfgn3Nn8eexk6L95TYpnh8pZVq6+DfcvnUTW7bvytfjKhQ5e4tNSIhH7x5dMGmKFzasWw3rqjbwnDAZADDBcyy0NDUx23tBrvMYtZqdafmbQ79g8trT2Hr0Nl7sH4OV+69i0R5/AIC2lgYCDozF1HV/Y+OfN5WPqV6xDA7M7YmGwzfi1YGx6DF1L/68+DitnRJFEXToFzQftQUX770GABQvqo2woxPgNm47zt58BQAIPzH1i3IvX7IIt2/fxKatO7/4d31w/x769+6Ov06egZmZ+Rc9RiMPa8p9+PABznUdsHTFKjRybaws79GlIxq5NsbI0R65Oq4iD/9MuzrXw5hxnujctZuy7O2bILRt1Rx79v8B66o2OT6mDLk7RzXtrLF42Uo0bdZcWTbhFw9oampizryFuTpmXkVGRqJpIyds3LIDjrXrZFrn/r276Ne7O46d8vvi51F+vc3b21pjyXLVc5YbuhJbTmTp+ZdiR1Aa42IldoRsiT6yfuXKFUybNi1DRx0AtLW1MXnyZFy5ckWtmVKSk/Ho4QM4OTdUKXdyboA7t2+pNYsU86QLCAxA88YN4dayKcb/4oGg169FyyLVcwSkZfvryGF06tJVtI66FM+P1DKd8zsDW1s7/OIxCo1dnNCjayf47tur9hzec2bBxaUx6js5q5QrFApc+OcsyltY4qdhg9HU1Rn9+/SAXx6/Ii9SRIbuTWyhp6uFKw+CYGlWEmZG+jh9/b+pAckpcpy/E4D6tuWUZUV1NLF1amd4LD+Od1EZpytGvE/Eo1dh6NOyBorpakGjiAxD2jsgJDIOtx4H5zjnubNnUK2aHcaPHY1mrs7o3b0zDuzP+vrExcZCJpOp7dsRuTwVcrkcOjqqo8I6urq4devmZx5VUFnkOH70LyQmJqBGzZpqbftLKRQKnP/nLCwsLfHjD4PRpJET+vXurtZpH3FxsQAAAwODLOrEqfV59C0oIpPOVhiI3lk3NDTE06dPP7v/2bNnMDQ0VGMiICo6CnK5HEZGRirlRkbGCA8PU2sWKeYBgOo1amDO3PlYvW4jvGbORkR4OAb07YXo6ChR8kjxHKU7c+Y0YmNj0aFTZ9EySPH8SC1TUNBr7PXZjfIWlli9biO69+yF+d6z8eehg2rLcPzYX/j34UP8PGZshn2RkRFISEjA5k3r4dzABavXbkSTps0xzuNnXL92Ncdt2VqVRtjRCYg5ORnLx7ZBz+n78G9AOExLFQcAhEbFqdQPjYpHmf/vA4AFI1ri8oMgHLn45LNttPPcCfvKpgj7awKiT07Gz93qoeP4XYiJT8px3jdBr7F/7258Z2GBlWs2oGv3nlg4bw6OHD6Yaf2kpCQsX7oIrdu0Q/HixTOtk9/09IrDvmYtrFuzCqGh7yCXy3Hkz0O4d/cOwsJC1ZLh6ZPHcK7jgHoONTDn1xlYtOx3VKxYSS1t51T6c3rTxvVwbuiC1es2oWmzFhg3ZmSuntM5JQgCFi3wRi0HR1SqXCXTOklJSVi+5De4qfF5RPQp0b8YGTp0KNzd3TF16lS0aNECZcqUgUwmQ0hICE6dOoW5c+dizJgxWR4jKSkJSUmqb/6Chk6G0Y2c+nQUVBAE0UZGAWnlaejiqvz/ygBq2NdEu9YtcPjgQQwYOEiUTIC0zlG6P3x90aBhI5QuXUbUHIA0z49UMikUAmzt7DDq/x1lG5tqeP7sGfb67Eb7jp0KvP2QkGAsnDcXq9ZtzPS9S6FQAAAaN26KfgMGAgCsq9rgzp1b2L9vD2rXqZuj9p68Dke9IetQsrguOjWywfqJHdByzDbl/k9nXsgA5dz0ts5V0LiWJeoPXZ9lG0vHuCEsKh7NR29BYlIqBrathQPevdBw+EaERMZl+dhPKRQCqtna4ufRadenqk01vHj+DPt8dqNdh04qdVNSUjDJcywEQcCkqV45aiev5ngvgNe0yWjRpBE0NDRQ1aYa3Nq2w79quvfK0soKe3z/QOz79/j71ElMnzIRG7Zsl2SHXfmcbtIM/f//nK5a1QZ3bt/E/r05f07nlPecWXjy5Am2bMt86ltKSgomeHpAIQiYPG1GgWahwmXVqlVYuHAhgoODYWtri6VLl8LFxSXbx128eBGurq6ws7PD7du3v7g90TvrM2bMQNGiRbF48WKMHz9e+Y+0IAgwNTXFxIkTMX78+CyP4e3tjZkzVVfZmDLNC1Onz8hVJsOShtDQ0EB4eLhKeWRkBIyMjHN1zLyQWp7MFCtWDJWrVEFg4CtR2pfqOXr79g2uXPbH4mUrRMsASPP8SC2TiYkJKlRUXRGlQoUKOH3qhFraf/TgASIjI9C3Z1dlmVwux80b1+Gzeyf8r96CpqYmKnzS6apgVRG3bt3IcXspqQq8eJv2TdjNJ8FwrGqGEV3rYtHutHnqZUoVV+lQmxjqIfT/010a17JEBfNSCDmi+t68e2Y3XLwXiFYe29HYwRJt6leGWYeFiE1IBgCMWXoMzRyt0K9VDfz2/3a+lLGJSYbf3apCRfx9+qTq75WSgom/eODNmyCs3bhF7aOh35Uvj01bdyAhIQHx8XEwMSkNz3FjULZcuewfnA+0tLRRvnzaiju2dtXx4MF97N6xDVO9Zqml/ZwwNDSEpqYmKn7yurOqUBG3bub8OZ0T8+b+inN+Z7Bp6w6UMTXNsD8lJQXjx43B26AgrNu0laPq+ayQLMKSKR8fH4wZMwarVq1CgwYNsHbtWri5ueHhw4coX778Zx8XExODAQMGoFmzZjm+4Vz0aTAAMGHCBLx9+xbPnz/HhQsXcOHCBTx//hxv377NtqMOAJMmTUJMTIzK5jlhUq7zaGlrw6aaLS77X1Qpv+zvD/uatXJ93K8lT2aSk5Px4sVzGBt/fnm3giTVc3TojwMoVcoILo0ai5YBkOb5kVqmmrUc8Oql6k1PAa9ewdy8rFrar1u/PvYdOIw9+/5QbtVs7dCmbXvs2fcHtLW1Uc3WDgGvPskY8OqLb3rLikwmg46WJl4FRyM4IhbNav9305WWZhG42Fvg8oMgAMBvuy6izuC1qDdknXIDgPGrTuKH+WmrQhXT0QKQ8QZbhQKQ5WKiaM2atfDq09/9lervnt5RDwwMwJr1m1GypHqnUH6sWLFiMDEpjfcxMbh08QIaN2kmThBBQHJysjhtZ0NLSxvVbKtn+rozK6DXnSAI8J4zC3+fPol1m7aibLnvMtRJ76gHBgZgzYYtoj6PSHoWL16MwYMHY8iQIbCxscHSpUvx3XffYfXq1Vk+btiwYejTpw+cnJxy3KboI+sfs7KygpWV6l25r1+/hpeXFzZt2vTZx+noZJzyktfVYPq7D8KUieNRzc4O9va14LvPB8HBwejes1feDvyV5Fm0cD5cGzeBqZkZIiMjsX7NasTHxYk6L1tq50ihUODQHwfQvmMnaGqK/1KT2vmRWqZ+A9zh3q83Nqxbg5at3HD/3l3s378X02eoZ0RST694hnmzRYsWhUHJkspy90GDMeGXsXBwrI3adevB/8J5/HPOD+s3bcvskJ81c0gTnLzyDK9D30O/mA66N7VFI3sLdJiQNh1g5f6r8OzbEM+CIvEsKBLj+zVE4ocU+JxOW9P8XVR8pjeVvn73HgEh0QCAKw+CEBX3ARsmdcTcbeeRmJSC79vWgqVZSRy//Cynpwd9BwzEoP69sXH9GrRo5YYH9+7igO9eTJ2edn1SU1Mxfuxo/PvoIZatXAO5Qq6898HAwABaWhkXMSgIFy+cBwQBFlZWeB0YiCW/LYCFpRU6du5S4G2vWLoYDVwawdTUFPHx8Thx7CiuX7uKlWvSpivFxEQjJDgYoaFp8+fTO8lGxsYFNtCSkBCPwMBA5c9v3gTh338fwcDAAGZm5hg4aDDG/+IBh9p1UOej5/SGzTl7Tn+pubNn4tjRI1i6fBX09PSUz5HixfWhq6uL1NRUeI4dhUcPH2L5yrVQiPA8Soj/5JwFBeHfR/8/Z+Z5/2AuBUVyuaJQQchsKnVm/UogbWDyxo0bmDhxokp5y5Yt4e//+W8LN2/ejOfPn2PHjh2YPTvzFbmyIn4PIhuRkZHYunVrlp31gtDarQ1ioqOwbvUqhIWFolLlKli5Zp3aRtmknufduxBM9ByLqKhoGJYyRI0aNbF9117R8gDSO0eXL/kjOPgtOnXpmn1lNZDa+ZFaJrvqNbB42e9YvnQx1q5eibLlymH8hMlo266D2rN8TtNmLTBl+gxs2rAOC+bNgYWlFRYuXo5aDo45Ok5pQz1snNwJpqWKIyY+CfdfvEOHCbtw5kZa523RHn/o6mhi6Rg3GOoXxbVHb9DOcyfiEr98hDbifSI6jt+FGUOa4NiiftDS1MCjV2HoPtUH957nfM1xW7vq+G3pCvy+dDHWr1kF87Ll8Mv4SWjTrj0AIPRdCM6dPQMA6NWtk8pj123aitp16uW4zdyIi4vF8qWL8S4kBAYGJdGsRUv8PNoDWlpaBd52REQEpk4aj/CwMBTX10flKtZYuWY96jun/cG6c35n4DV1srL+RM+0+f/DfhyB4SN+LpBMD+7fx9DvByh/XrTAGwDQvmNn/DpnHpo2b4Gp02dg44Z1WOA9GxaWVvhtyXLUcqhdIHn2+ewGAAwZ1F+lfOZsb3Ts1AXv3oXgrF/a86hnt44qddZv2oY6dQv+efTgwX0MGfTfOfvt/+esQ8fO+HXuvAJv/1uT2VRqLy8vzJgxI0Pd8PBwyOVylCmjeg9amTJlEBISkunxnz59iokTJ+L8+fO5HrgTfZ31w4cPZ7n/xYsXGDduHORyeY6Om9eRdSKi/JDTddYL2ufWWRfLl66zri55WWe9oORlnfWCkNt11r8lUpuTLbV11ldefCV2BKUhtc2+eGT97du3KFu2LPz9/VWms8yZMwfbt2/Hv//+q1JfLpejfv36GDx4MIYPHw4g7V7NgwcPFq4bTDt16gSZTPbZv4AHZFwtgoiIiIgKJyl16z7XMc+MsbExNDQ0Moyih4aGZhhtB4DY2Fhcv34dt27dwsiRIwGkTZEVBAGampo4efIkmjZtmm27ot9gamZmBl9fXygUiky3mzfV+4ckiIiIiIg+pa2tDUdHR5w6dUql/NSpU3B2ds5Qv0SJErh37x5u376t3IYPHw5ra2vcvn0b9ep92bQq0UfWHR0dcfPmTXTq1CnT/dmNuhMRERERqcPYsWPRv39/1K5dG05OTli3bh0CAwOV01wmTZqEN2/eYNu2bShSpAjs7OxUHl+6dGno6upmKM+K6J11T09PxMdnXFUgXaVKleDn56fGRERERERUUCR4a8gX69mzJyIiIjBr1iwEBwfDzs4OR48ehYVF2t83CA4OVlnNJz+IfoNpQeENpkQkBbzBNGu8wTR7vMG08JHSnGxAejeYrrn0SuwISsOdLMWOkC3R56wTEREREVHmJPZZi4iIiIi+ZkWk9tWDxHFknYiIiIhIojiyTkRERERqw4H1nOHIOhERERGRRLGzTkREREQkUZwGQ0RERERqwxtMc4Yj60REREREEsXOOhERERGRRHEaDBERERGpDWfB5AxH1omIiIiIJIoj698wQRA7gSp+0qavUWR8stgRVESenCZ2BBXGfTaLHUFF6M6BYkfIQGrvjVLLQ4UPR4pzhueLiIiIiEii2FknIiIiIpIoToMhIiIiIrWRcS5VjnBknYiIiIhIothZJyIiIiKSKE6DISIiIiK14SSYnOHIOhERERGRRLGzTkREREQkUZwGQ0RERERqU4SrweQIR9aJiIiIiCSKI+tEREREpDYcV88ZjqwTEREREUkUO+tERERERBLFaTBEREREpDa8vzRnOLJORERERCRR7KxnwWf3Tri1bIo6taqjV/cuuHnjOvN85N27d5g84Re4NqiH+rXt0aNrRzx8cF/UTFI7R8xT+DKpK8/dW9cxZdxI9GjXDM3q18CFc2dU9guCgK3rV6FHu2Zwc62DsT9+j1cvnmU4zoN7dzBuxGC0bVwXHZo3wNgfv0fShw8FkhlQ3+teo4gM03s54MHKbgjf2R/3f++Gid3sVUbkShvoYu2Ihni2tifCdvTHwSktUNG0RIZj1a1igqNerRG6vR/ebOmDYzNaQ1dbI88Zb1y/htEjh6NlUxc4VK8Kv79Pq+yPCA+H15SJaNnUBc51amLE8CEIDHiV53azzTRiOFo0cUEtu4yZBEHAmpUr0KKJC+o72mPIwP54/uxpgWbKzLf6ui+seUhcku+sv3v3DrNmzVJ7u8ePHcWCed4Y+sOP8Nl/EA4Ojvhp2FAEv32r9ixSzPM+JgYD+/eGppYWfl+zHr6H/sI4z4nQ18/4D6W6SO0cMU/hy6TOPImJiahY2Ro/j5uU6f492zdj/+7t+HncJKzatAuGRsYYP2oYEuLjlXUe3LuDSWN+RO16zli5aRdWbdqFjt17QVakYN7a1fm6H9upOga3sMbYjZfhMOYPTN1xDWM6VMePbtWUdfaMbwbL0vroseBvOI8/hMCweByZ3grFdP6b4Vm3igkOTmmJv++8geukI2g08QjWHn8EhULIc8YPiYmoUqUqJkyelmGfIAgYO3oEgoKCsGT5KuzaewBmZuYYPvR7JCYk5Lntz0lMTEQV66qYmEkmANiyaQN2bNuCiZOnYceefTAyNsHwod8jPj6uwDJ96lt+3RfGPAVBJpNJZisMZIIg5P0dqwDduXMHDg4OkMvlOXrch9S8tdu3V3fYVKuGqdNnKss6tXdDk6bNMdpjXN4OLpE8ebnyy5b8htu3bmLztl25P8gn8vqa+Rau2deUR4qZCiJPeGxStnWa1a+BmfOXoqFrUwBpHb0e7ZqhS89+6D3gewBAcnIyurVpgqEjxqB95+4AgJGD+8KxrhMGDRv5xXmMiuvk4rdIUxCve+M+mzMt3z+xOUJjEvHT6ovKsp3jmiAxORVDVpxHJbMSuLO8K2p7/IFHQdEAgCJFZHi1oRem7biOrWfSRov95rTFmbtv8avPrS/KE7pzYK5+D4fqVbFo6e9o0qw5ACDg1Ut0bu+GfX/8iYqVKgMA5HI5mrs6Y5THL+jctfsXHzu374217Kpi8bL/MgmCgJZNGqFP/wEYNHgogLTnVTPXBhjtMQ7devT6ouPm9Q/afAuve6nl0ZXYHYq7b70RO4JS71plxY6QLdFH1u/evZvl9vjxY7VnSklOxqOHD+Dk3FCl3Mm5Ae7c/rI3/K85DwCc8zuDarZ2+GXsKDRp5ISe3TrBd/9eUbIA0jtHzFP4MkkpT/DbN4iMCEftek7KMm1tbdjXcsSDe7cBAFGREXj04B5KGpbCz0P7o6tbY3j8OAj3bt8ssFzqfN1f+vcdGtuZoZJZ2qh9dQtDOFctgxM3gwAAOlpp01g+pPw3kKNQCEhJVcDZpgwAwKSELupWKY2wmA/4e3ZbvFzfC8dnusGpaukCyfyx5ORkAIC2zn8fjjQ0NKClpY3bN28UePuZeRMUhPDwMDg5N1CWaWtrw7F2HbU9x6X0OmMeKixE/6xVs2ZNyGQyZDbAn16u7q8poqKjIJfLYWRkpFJuZGSM8PAwtWaRYh4ACAp6jX0+u9FvwCAMGToc9+/dxQLv2dDW0kb7jp3Unkdq54h5Cl8mKeWJiggHABiWUs1iWMoI70KCAQDBb9M6rVs3rMbwUeNQsbI1Th37E54/D8WGnQdQrrxFvudS5+t+0cF7KFFMG7eWdoFcIUCjiAwzd9/AvosvAQCP30QjIDQWM/s4YtQ6f8QnpWJUO1uYGhaDacliAADLMvoAgMk9amLKtmu4+yoSfVwr4a/prVFn7EE8D3mfr5k/ZmlVAWbm5vh96WJMmT4TRYsVxY6tWxAeHoYwkV5z6c/jUhme40Zqm2IhpdcZ84hH9JHiQkb0zrqRkRHmz5+PZs2aZbr/wYMHaN++fZbHSEpKQlKS6lfNgoYOdHRy/3UvgAwfEsT44PAxKeVRKARUs7XDqDFjAQBVbarh+bNn2Ld3tyid9XRSOkcA83wJqWWSUp7Ms/z///8/57pd525o3a4TAKCytQ1uXruC40cOYshPo/M9jzpf992crdDLpSIGLTuHR0HRqGFZCvMH1kVwVCJ2nnuGVLmAPov8sPrHBnizpS9S5Qr43XurHHkH/puusenUY2w/m3Zz7p1XV9G4uhkGNK0Mr10FN8KtpaWFhYuXY5bXVDRuWA8aGhqoW98JDRo2KrA2v1TG51XGMvVn4Ov+Y1LLQ+ISvbPu6OiIt2/fwsIi81Gg6OjoTEfdP+bt7Y2ZM2eqlE2Z5oWp02fkKpNhSUNoaGggPDxcpTwyMgJGRsa5OmZeSC0PAJiYmKBixYoqZVYVKuD06ROi5JHaOWKewpdJSnkM/99eZEQ4jIxNlOXRUZEo+f/R9lLGaXUsLFVfhxaWFRD6/9H3/KbO1/2c/nWw6OBd7PdPG0l/EBiF74yLY1zn6th5Lq3jfftFBJw8D6NEMS1oaxZB+PsknJ3bDjefp13DkOi0Gzn//f+c9nT/vonBd8Z6+Z75U9Vs7bBn/0HExsYiNSUFhqVKYUCfHrCpZlfgbWfG+P/PpYjwcJiY/DcVKDIyIsNoe0GR0uuMecTDDx45I/o3EcOGDYOlpeVn95cvXx6bN2d+A1K6SZMmISYmRmXznJD5CgtfQktbGzbVbHHZ/6JK+WV/f9jXrJXr434teQDAvpYDXr16qVIWEPAKZmbi3KghtXPEPIUvk5TymJmXRSkjY9y4eklZlpKSgju3bsC2ek0AgKlZWRiZlEZQ4CuVxwa9DkBpM7MCyaXO131RHQ0oPhmoUSgUmd7c+D4hBeHvk1DRtAQcKhrhr2uBadlC4/A2Mh6VzQ1U6lc2K4HAMPWtfqKvrw/DUqUQGPAKDx/cR+OmTdXW9sfKlisHY2MTXL7kryxLSUnGjevX1PYcl9LrjHmosBB9ZL1z585Z7jc0NIS7u3uWdXR0Mk55yetqMP3dB2HKxPGoZmcHe/ta8N3ng+DgYHTv+WV3y+c3qeXp198dA/v3xoZ1a9CytRvu37sL3/17Mc1L/ctsppPaOWKewpdJnXkSExLwJihQ+XPI2zd49uRf6JcwQBlTM3Tp2Q+7tm5Eue8sUPa78ti1dQN0dXXRrGUbAGkjUz37umPr+tWoULkKKlWuipNHDyMw4CW85i7K97yAel/3x268xvgu9ngdHo9Hr6Nhb1UKI9vbYfuZ/9YE71zfEuHvP+B1eBxsy5fCwkF18efVQPx997/510sP3ceUnrVwLyASd19Foq9rJVQpa4C+i/zynDEhIR6vA/+7hm/eBOHxv49QwsAAZmbmOHXiOAxLGcLU1BzPnj7Bwvlz0Lhpsww3D+an7DL16T8AG9evRfnyFihvYYGN69dCV1cXbm3bFVimT33Lr/vCmIfEJ/mlG1+/fg0vLy9s2rQpR4/La2cdSPujBFs2bURYWCgqVa4CzwmT4Fi7Tt4PLJE8eb3y/5z1w/JlixEY8Aply5ZDP/dB6NqtR66Plx/fin3t1+xryyPFTPmd53NLN96+cQ3jRgzOUN6yTQdMmD4bgiBg24bVOHJwP2Jj38PGtjpG/TIZVhUrq9TfvW0jDu3fg9j3MahQ2Ro/jPBA9ZoOn82Tl6Ubgfx/3X9u6cbiupqY3ssB7etawMRAF8GRCdh38SW8999GSqoCAPCjmw3GdKiO0iV1ERKViF3nnmGe7x3l/nTjOlXHD61sYFhcG/cCojB1xzVc+jc003ZzsnTj9WtX8MP3GQeT2nfohJlz5mH3zm3YtnkTIiIiYGxignbtO2Lo8B+hpaX9xW0AOXtvvH71CoZmlqljJ8yaMw+CIGDtqt/hu28v3r+PgV2NGpg0ZToqVa7yxW3kdelG4Ot/3Ustj9SWbtx3WzprxnevaS52hGxJvrMu1jrr3wKpXXlOYaOv0Zess65Oee2s57fPddbFktt11guS1N4b86OzTurFzvrnFYbOuuiX7/Dhw1nuf/HihZqSEBERERFJi+id9U6dOn12nfV0vGuYiIiI6OvAfl3OiL4ajJmZGXx9faFQKDLdbt4suL/GR0REREQkZaJ31h0dHbPskGc36k5ERERE9LUSfRqMp6cn4uPjP7u/UqVK8PPL+xJbRERERCQ+0UeKCxnRO+suLi5Z7tfT04Orq6ua0hARERERSYfonXUiIiIi+nbwBtOc4TcRREREREQSxc46EREREZFEcRoMEREREakNJ8HkDEfWiYiIiIgkip11IiIiIiKJ4jQYIiIiIlIbLgaTMxxZJyIiIiKSKI6sExEREZHaFOEtpjnCkXUiIiIiIoliZ52IiIiISKI4DeYbxhs8iAqesb6O2BEkLWL3ILEjqDCs7yF2hAwiLi0WOwJRvmL/I2c4sk5EREREJFHsrBMRERERSRSnwRARERGR2si4GkyOcGSdiIiIiEii2FknIiIiIpIoToMhIiIiIrXhajA5w5F1IiIiIiKJ4sg6EREREalNEd5gmiMcWSciIiIikih21omIiIiIJIrTYIiIiIhIbXiDac5wZJ2IiIiISKLYWSciIiIikihOgyEiIiIiteE0mJzhyDoRERERkUSxs54Fn9074dayKerUqo5e3bvg5o3rzPORd+/eYdKEX9DIuR7qOdqjR5eOePjgvqiZpHaOmKfwZZJKnr17dqFb5/ZwrusA57oO6N+nJy6cPydKlsxsXL8W9rbWWOA9R+woBXLNGtSqgP2Lh+DFsRlIvL4E7V3tVPbrFdXGkvFd8OwvL0RemI9b+yZiaFdn5f7yZoZIvL4k061LM3tlvZL6RbFxVl+EnJ2LkLNzsXFWXxgU18117hvXr2H0iOFo0cQFteyqwu/v0yr7I8LDMX3KRLRo4gKn2jUxYtgQBAS8ynV7uSWV1xnzUGEgmc56UFAQ4uLiMpSnpKTgn3/+UXue48eOYsE8bwz94Uf47D8IBwdH/DRsKILfvlV7FinmeR8Tg4H9ekNTUwsr16zHgcN/Ydz4idDXLyFKHkB654h5Cl8mKeUpXcYUoz1+wa69vti11xd169XH6JEj8OzZU7Vn+dT9e3exf58PqlSxFjtKgV0zvaLauPf0DTwW+Ga6f8HYTmjhVBWDpu9Aze7zsGLXOSz27IJ2/+/UB72LhmWr6SrbrDXHEJeQhBP+j5TH2TK7P2pUMUfHn9ei489rUaOKOTbO6pfr3ImJiahiXRUTJ0/LsE8QBHiMHoGgoCAsXb4Ku/cdgJm5OYYP+R6JCQm5bjOnpPQ6Yx5xyCT0X2Egemc9ODgYdevWhYWFBUqWLAl3d3eVTntkZCSaNGmi9lzbt25G565d0aVbd1SoWBHjJ02BqZkp9vrsVnsWKebZtHE9ypia4tc53qheowbKli2HevWd8F358qLkAaR3jpin8GWSUp7GTZrCpZErLC2tYGlphZ9He6BYsWK4e+e22rN8LCE+HpMmeMJr5myUMDAQNQtQcNfspP+/mLn6GA753ct0f70althx5BrO33iOwOAobPrjEu4+fQsHm+8AAAqFgHcRsSpbhybVsf/ULcQnJgMArC1Lo1UDG/z0qw+u3AvAlXsBGDF7L9o2skVlC5Nc5W7o0ggjRo1BsxYtM+wLDHiFe3fuYMo0L9hWrw5LqwqYNNULiQnxOHb0r1y1lxtSep0xDxUGonfWJ06cCA0NDVy5cgXHjx/Hw4cP0bhxY0RFRSnrCIKg1kwpycl49PABnJwbqpQ7OTfAndu31JpFinkA4JzfGdja2uEXj1Fo7OKEHl07wXffXlGyANI7R8xT+DJJLc/H5HI5jh39C4mJCbC3ryVqlrmzZ6FRI1fUd3LOvnIBE/Oa+d9+iXaN7GBukvaBpZFjJVQub4LTl/7NtH6tquVQ07octh66oiyrV8MS0bGJuPYgUFl29X4AomMTUb+GVb5nTk5O+5Cgra2jLNPQ0ICWljZu37qR7+1lRmqvM+YRRxGZdLbCQPTVYE6fPo0//vgDtWvXBgC4uLigZ8+eaNq0Kf7++28AgEzNtw1HRUdBLpfDyMhIpdzIyBjh4WFqzSLFPAAQFPQae312o7/7IAz+YTju37uL+d6zoa2tjfYdO6k9j9TOEfMUvkxSywMAT588Rv8+vZCcnIRixYphyfKVqFipkihZAODY0b/w6NFD7PLZL1qGj4l5zcYtPIBVU3vi+bEZSEmVQ6EQ8ONsH/jfeZlpffeO9fDoRQgu332lLCtjVAJhkbEZ6oZFxqKMkX6+Z7a0qgAzc3OsWLYYU6fPRNFiRbF96xaEh4chPEw9z3Gpvc6YhwoD0TvrMTExMDQ0VP6so6OD/fv3o3v37mjSpAl27NiR7TGSkpKQlJSkUiZo6EBHR+czj/gyn35IEARB7R8cPialPAqFAFs7O4waMxYAYGNTDc+fPcNen92idNbTSekcAczzJaSWSUp5LC2tsNf3IGJj3+P0qZOYNnkCNm7ZIUqHPSQ4GAvmzcGadZvy/N6a38S4ZiN6uaBudQt09diAwOBINHSoiGUTuiIk/D38rj5Rqauro4WerR0xb8PJDMfJ7HtjmUyW+Y480tLSwm9LlmPm9KlwbVAPGhoaqFffCQ1cGuV/Y9mQ0usMYB6SNtGnwVSoUAF3795VKdPU1MS+fftQoUIFtGvXLttjeHt7w8DAQGVbON8715kMSxpCQ0MD4eHhKuWRkREwMjLO9XG/ljwAYGJiggoVK6qUVahQAcHB4twAI7VzxDyFL5PU8gCAlrY2yltYwNauOkZ7jEMV66rYuWObKFkePnyAyIgI9O7RBQ41qsGhRjVcv3YVu3Zuh0ONapDL5WrPJNY109XRwswRbTFh8SEcPf8A958FY83eC9h/6jbG9GucoX7nZvYopquFnX9dUyl/F/EepUtlHEE3NiyOd5mMuOeHarZ28PE9iH8uXcNJv/NYuXYDYqKjUbZsuQJp71NSe50xjzjEvqmUN5jmkJubG9atW5ehPL3DXrNmzWznrE+aNAkxMTEqm+eESbnOpKWtDZtqtrjsf1Gl/LK/P+xrqn++qNTyAEDNWg549VL1696AV69gbl5WlDxSO0fMU/gySS1PZgRBQMr/5x2rW7369bH/4J/w8T2o3Gxt7dCmXXv4+B6EhoaG2jOJdc20NItAW0sTCkGhUi5XKFCkSMZ/Vgd2rIe//nmA8Oh4lfIrd1+hpH5R1Lb978b8OrblUVK/KC7fzXw6TX7R19dHqVKlEBDwCg8f3EfjJk0LtL10UnudMQ8VBqJPg5kzZw4SPrNklKamJg4cOICgoKAsj6Gjk3HKy4fUvOXq7z4IUyaORzU7O9jb14LvPh8EBweje89eeTvwV5Kn3wB3uPfrjQ3r1qBlK7e0pdz278X0GbNEyQNI7xwxT+HLJKU8y5cuRkOXRihjaoqE+HgcP3YU169dxaq1G9SeBQD09IqjcuUqKmVFixVDSYOSGcrVqaCumV5RbVT87r+RTMuyRqhRxRxRMQl4/S4a/9x4hrmjOyAxKQWBwVFwcaiIvm1qY8KSQyrHqVDOGA1rVUCn0esztPH4VShOXHyElVN64Oe5+wAAv0/pgb/+eYCnAbmbn5yQEI/Xgf/dsPrmTRAe//sIJQwMYGZmjlMnjsPQ0BCmZuZ4+vQJFs6bg8ZNm8GpQcMsjpq/pPQ6Yx4qDETvrGtqaqJEic+vzf327VvMnDkTmzZtUmMqoLVbG8RER2Hd6lUICwtFpcpVsHLNOtFGjqWWx656DSxe9juWL12MtatXomy5chg/YTLatusgSh5AeueIeQpfJinliYgIx5SJ4xEWFori+vqoUsUaq9ZugJNzA7VnkbKCumYO1b7DybUjlT8vGNsJALD9z6v4YeZuDJi8DbNGtMWWX/vBsEQxBIZEYcbqo1jv669yHPcOdfE2NAanLz/OtJ1B03Zg0S+d8efvwwEAf/1z/7Nru3+Jh/fvY+j37sqfFy2YBwBo37ETZs2Zh7CwUCxaMA8REREwNjFBuw4d8cPwH3PdXm5I6XXGPOLg9PuckQnqXhcxh+7cuQMHB4ccz4fM68g6ERF9ewzre4gdIYOIS4vFjqCiCHtahY6u6EOzqvweR4gdQamJtVH2lUQm+uU7fPhwlvtfvHihpiREREREVNAKy42dUiF6Z71Tp06QyWRZ3kTK5YqIiIiI6Fsk+mowZmZm8PX1hUKhyHS7efOm2BGJiIiIiEQhemfd0dExyw55dqPuRERERFR4FJFJZysMRJ8G4+npifj4+M/ur1SpEvz8/NSYiIiIiIhIGkTvrLu4uGS5X09PD66urmpKQ0REREQkHaJ31omIiIjo28HVYHJG9DnrRERERESUOXbWiYiIiIgkitNgiIiIiEht+OdzcoYj60REREREEsWRdSIiIiJSGw6s5wxH1omIiIiIJIqddSIiIiIiieI0GCIiIiJSmyK8wzRHOLJORERERCRR7KwTEREREUkUp8EQERH9X9TlJWJHyMCwzkixI6iIuva72BGokOMkmJzhyDoRERERkUSxs05EREREJFGcBkNERERE6sN5MDnCkXUiIiIiIoniyDoRERERqY2MQ+s5wpF1IiIiIiKJYmediIiIiEiiOA2GiIiIiNRGxlkwOcKRdSIiIiIiiWJnnYiIiIhIojgNhoiIiIjUhrNgcoYj60REREREEsXOOhERERGRRHEaDBERERGpD+fB5AhH1omIiIiIJIqd9Sz47N4Jt5ZNUadWdfTq3gU3b1xnnv/buH4t+vToCqc6tdDYxQljfv4Jr16+EC1POimdI+YpnJmYp3DlkWImdeXR0CgCr5/a4dGRGYi8tBgP/5yBST+0huyjRaz1impjyYTueHb8V0ReWoxbvlMxtHtDleNYlTOGz6KhCDzjjXfnF2LH/O9RupR+gWRO961es8KaJ7/JJPRfYSCJznpERAT8/PwQGRkJAAgPD8f8+fMxa9YsPHr0SJRMx48dxYJ53hj6w4/w2X8QDg6O+GnYUAS/fcs8AK5fu4qevfti++69WLt+M1LlcgwfOhgJCQmi5AGkd46Yp/BlYp7ClUeKmdSZZ9zAFhjSrSE85u1DzS6zMWXZQXgMaI6ferkq6yz4pStaOFfDoCnbULPLbKzY6YfF47ujXePqAIBiuto4smoEBEGA2w8r0HTQEmhracB32TCVTn9++pavWWHMQ+KTCYIgiBng6tWraNmyJd6/f4+SJUvi1KlT6N69OzQ1NSEIAt68eYMLFy7AwcEhR8f9kJq3XH17dYdNtWqYOn2msqxTezc0adocoz3G5e3gX0GeT0VGRqKJixM2bd0Bx9p1RMkgtXPEPIUvE/MUrjxSzFQQeQzrjMy03HfZcIRGvsePM3cpy3b/NgQJickYPG0bAOD6vsnYf/Im5q0/rqxzced4nLj4ALNW/YVm9avi0O8/wcx1PGLjPwAASuoXRfA/C9Fm+Ar4XXmcod2oa7/n6vdI9y1cM6nl0ZXYHYrXX74XO4JSbasSYkfIlugj61OmTEH37t0RExODyZMno1OnTmjWrBmePHmCp0+fok+fPvj111/VmiklORmPHj6Ak7PqV4VOzg1w5/YttWaRYp7MxMXGAgBKGBiI0r7UzhHzFL5MzFO48kgxk7rzXLr9HE3qWqNS+dIAgOpVysKpZgWcuPhAWcf/9gu0c60Oc5O09+ZGtSujskVpnPZP+9ZaRzttYCwp+b8Rrg/JqZDLFXCuWTHfM3/r16yw5SkoMpl0tsJA9M9aN27cwPLly6Gvr4/Ro0djwoQJGDp0qHL/iBEj0L59e7VmioqOglwuh5GRkUq5kZExwsPD1JpFink+JQgCflvgjVoOjqhcuYooGaR2jpin8GVinsKVR4qZ1J3nt82nUKJ4Udz5YyrkcgEaGjJ4rTyCvcdvKOuMm78Pq6b3wfOTc5CSIodCUODHWbvgfzvtHqOr914hPjEZc0Z3xPTfD0MGGeaM7ggNjSIwNc7/Ecdv/ZoVtjwkDaJ31pOTk1G0aFEAgJaWFooVKwZjY2PlfiMjI0RERGR5jKSkJCQlJamUCRo60NHRyVO2T+frCYJQYHP4voTU8qTznj0LT588wZbtu7KvXMCkdo6YJ3tSy8Q8WZNaHkB6mdSVp3srR/RuUwcDJ2/Fw+fBqGFdFgt/6YbgsBjs/PMKAGBE78aoW90SXUevQWBwJBo6VMKyST0REv4eflceIzwqDn3Hb8TyyT3xU29XKBQC9h6/gZsPAyFXKPI9c7pv9Zp9KanlIXGJ3ln/7rvv8OLFC1haWgIA9uzZAzMzM+X+4OBglc57Zry9vTFz5kyVsinTvDB1+oxcZTIsaQgNDQ2Eh4erlEdGRsDIKOssBUFqeT7mPedXnD17Bpu27kAZU1PRckjtHDFP4cvEPIUrjxQzqTvP3DGd8NvmU9h3Im0k/cGztyhvVgqeg1pg559XoKujhZk/t0fPsetx/ELa1Jj7T9+ihnU5jOnfTDkf/e/L/8K2w0wYldRDaqoCMXGJeHlqLgLeZD1Qlhvf+jUrbHkKCj925Izoc9Z79eqF0NBQ5c9t27ZVjrQDwOHDh1G3bt0sjzFp0iTExMSobJ4TJuU6k5a2Nmyq2eKy/0WV8sv+/rCvWSvXx/1a8gBpn/Lnzp6Fv0+fxPpNW1Gu3Hei5EgntXPEPIUvE/MUrjxSzKTuPEV1taEQVEe/5QoBRYqk/dOupakBbS1NKD5ZR0IuV6BIkYzdpYjoeMTEJcK1ThWULlUcR87dy/fM3/o1K2x5SBpEH1n38vLKcv+UKVOgoaGRZR0dnYxTXvK6Gkx/90GYMnE8qtnZwd6+Fnz3+SA4OBjde/bK24G/kjxzf52JY0ePYOmKVdArpofwsLS5dMX19aGrqytKJqmdI+YpfJmYp3DlkWImdeY5+s89TBjcCq+Do/DweTBqVi2HUf2aYNvBywCA2PgP+Of6U8wd0wmJH1IQGBwJF8dK6NuuLiYsPvBf5g718fhlCMKi4lCvhhV+8+yGFTv98DQg9HNN58m3fM0KY54CwaH1HBG9s56diIgIeHl5YdOmTWptt7VbG8RER2Hd6lUICwtFpcpVsHLNOpibl1VrDqnm2euzGwAweGB/lfJZs73RsXMXMSJJ7hwxT+HLxDyFK48UM6kzz9j5++D1Uzssm9wTJobFERwWg437L2LuumPKOgMmbsKsnztiy1x3GJYohsDgSMxYeQTr911Q1qliWRqzfu6AUgbFEPA2Egs2nsDyHWfyPW+6b/maFcY8JD7R11nPzp07d+Dg4AC5XJ6jx+V1ZJ2IiEgKPrfOuljyus46qZ/U1lm/GSCdddYdLKS/zrrol+/w4cNZ7n/xQvw/YU9ERERE+UPGeTA5InpnvVOnTpDJZMhqgJ/LFRERERHRt0j01WDMzMzg6+sLhUKR6Xbz5k2xIxIRERERiUL0zrqjo2OWHfLsRt2JiIiIqPCQyaSz5caqVatgZWUFXV1dODo64vz585+te+DAAbRo0QImJiYoUaIEnJyccOLEiRy1J3pn3dPTE87Ozp/dX6lSJfj5+akxERERERFRRj4+PhgzZgymTJmCW7duwcXFBW5ubggMDMy0/j///IMWLVrg6NGjuHHjBpo0aYL27dvj1q1bX9ym5FeDyS2uBkNERF8DrgZDeSW11WBuB8aKHUGpZnn9HNWvV68eHBwcsHr1amWZjY0NOnXqBG9v7y86hq2tLXr27Inp06d/UX3RR9aJiIiI6Nshk9CWE8nJybhx4wZatmypUt6yZUv4+/t/0TEUCgViY2NRqlSpL25XYp+1iIiIiIjUIykpCUlJSSplOjo60NHRyVA3PDwccrkcZcqUUSkvU6YMQkJCvqi9RYsWIT4+Hj169PjijBxZJyIiIiL1EXs4/aPN29sbBgYGKlt201k+XVJcEIQvWmZ89+7dmDFjBnx8fFC6dOls66fjyDoRERERfZMmTZqEsWPHqpRlNqoOAMbGxtDQ0Mgwih4aGpphtP1TPj4+GDx4MPbt24fmzZvnKCNH1omIiIjom6Sjo4MSJUqobJ/rrGtra8PR0RGnTp1SKT916lSWKxvu3r0bAwcOxK5du9C2bdscZ+TIOhERERGpjSzHt3ZKx9ixY9G/f3/Url0bTk5OWLduHQIDAzF8+HAAaSP1b968wbZt2wCkddQHDBiAZcuWoX79+spR+aJFi8LAwOCL2mRnnYiIiIjoC/Ts2RMRERGYNWsWgoODYWdnh6NHj8LCwgIAEBwcrLLm+tq1a5GamooRI0ZgxIgRynJ3d3ds2bLli9rkOutEREQSxnXWKa+kts763ddxYkdQqvFdcbEjZEtil4+IiIiIvmZfsHAKfYQ3mBIRERERSRQ760REREREEsVpMERE3xCFxG5TKsLvw7P17tJysSOoMHSdInYEFVHn5ogdgXKIr/qc4cg6EREREZFEcWSdiIiIiNSHQ+s5wpF1IiIiIiKJYmediIiIiEiiOA2GiIiIiNRGxnkwOcKRdSIiIiIiiWJnnYiIiIhIojgNhoiIiIjUhn9eIWc4sk5EREREJFHsrBMRERERSRSnwRARERGR2nAWTM5wZJ2IiIiISKI4sk5ERERE6sOh9RzhyDoRERERkUSxs54Fn9074dayKerUqo5e3bvg5o3rzCPhPFLMxDyFLxPz/OfG9WsYPWI4WjRxQS27qvD7+7TKfkEQsGblCrRo4oL6jvYYMrA/nj97qrZ86XjN0uzfuxu9u3VEY+faaOxcG9/374WLF/5R7p8xbRLq2NuobIP69cx1ew3sLbF/fn+8ODQBiRfnoL2LTYY6U75viheHJiDyzAycWDEYNlalVfZra2lgsUc7vP5rMsJPe2Hf/H4oa1JCpU5JfV1snNYNISemIeTENGyc1g0GxXVznTszfA6RlEm2s16hQgU8far+N/10x48dxYJ53hj6w4/w2X8QDg6O+GnYUAS/fcs8EswjxUzMU/gyMY+qxMREVLGuiomTp2W6f8umDdixbQsmTp6GHXv2wcjYBMOHfo/4+Di15APEP0dSylO6tClGjh6Lrbv2Yeuufahdtz5+GT1S5QOUUwMXHPv7H+W2dOXaXLenV1Qb954Fw2Pxn5nuH9fXBaN6NYDH4j/RcPAqvIuMw19LB6F4MW1lnYWj26JDo2oY4OWDZj+uQ/Gi2vBdOABFivw3T2KLV0/UqGyGjmO3oOPYLahR2Qwbp3XPde5P8TmkfjIJ/VcYyARBEMQMsHz58kzLx44di/Hjx8PU1BQAMGrUqBwd90Nq3nL17dUdNtWqYer0mcqyTu3d0KRpc4z2GJe3gzPPN5GJeQpfpm8hjyKXb/m17Kpi8bLf0aRZcwBpo+otmzRCn/4DMGjwUABAcnIymrk2wGiPcejWo9cXHbdIHv86yrdwzZJTFbnO08ylPkZ5/IKOXbphxrRJiIuNxW9Lf8/18QCgTLOMH94SL85Bj4k78Of5R8qyF4cmYuXei1i08zyAtFH0gD8nYerqE9h46BpK6Ong9V+TMfjX/dj/9z0AgJmxPp4eGI9Ov2zF6avPYG1hgtu7xqDR0NW49jAIAFDX9jucWzccNXovwdPAcESdm5On3+dbeA7pSuwOxX+DE8SOoFTVrJjYEbIl+sj6mDFjsHDhQixZskRlUygU2LZtG5YsWYKlS5eqNVNKcjIePXwAJ+eGKuVOzg1w5/YttWZhnsKZiXkKXybmyZk3QUEIDw+Dk3MDZZm2tjYca9dRWz6pnSMp5ZHL5Th57C8kJiagun1NZfmN61fRsnEDdG3fGrNnTkNkRESBtG9pbggzY32cvvpMWZacIsf5269Qv3p5AEAt67LQ1tLE6av/jfwHh8fiwYt3qF/dAgBQz648omMTlR11ALj64DWiYxNR3658nnNK6ZpJMQ9Jg+iftYYOHYqrV69i165dsLH5b76blpYWTp48iWrVqqk9U1R0FORyOYyMjFTKjYyMER4exjwSyyPFTMxT+DIxT86kZyiVIZ+R2r6ul9o5kkKeZ0+f4Pv+vZGcnISixYph4ZIVqFCxEgDAuYELmrdoBVMzc7x98wZrVi3Hj0MHYvseX2hra2dz5JwxLaUPAAiNUp0SFRoZh/KmJdPqGBVHUnIqomM/qNaJikOZUsUBAGWMiiMsKj7D8cOi4lHGqHiec0rhmkk5T0HJ4xdq3xzRO+tr167FwYMH0apVK4wfPx4jR47M8TGSkpKQlJSkUiZo6EBHRydP2WSfPJsEQchQpk7Mkz2pZWKe7EktE/PkTMZ8GcvUn+HbvWYWlpbYufcAYmNjceb0ScyYNglrN25DhYqV0LJ1G2W9SpWroJqtLdq3bo4L/5xF0+YtCyTPp7OuZLK085EVmUyGj2sIyFhfJgMyKc41PodIykSfBgMAnTp1wqVLl/DHH3/Azc0NISEhOXq8t7c3DAwMVLaF871zncewpCE0NDQQHh6uUh4ZGQEjI+NcH5d5vp1MzFP4MjFPzhgbmwAAIjLJ9+loe0GR2jmSQh4tLW18V94C1WztMHL0WFSuYo09O7dnWtfYpDTMzM3wOjAg33OERMYCgHKEPJ2JYXHlaHtIRBx0tDVRUl91ZReTknoIjUyr8y4iDqUNM46gG5fUw7vIvN/ILIVrJuU8BUUmoa0wkERnHQDKli2L06dPo1GjRqhVq1a2n7w/NmnSJMTExKhsnhMm5TqLlrY2bKrZ4rL/RZXyy/7+sK9ZK9fHZZ5vJxPzFL5MzJMzZcuVg7GxCS5f8leWpaQk48b1a2rLJ7VzJLU8QNrIdnJKcqb7oqOj8C4kBMYmJvne7qu3UQgOj0WzOpWUZVqaGnCpaYnL9wIBALcev0FySqpKHVMjfdhWKIPL99I+QFy5H4iS+kVR26acsk6dauVQUr8oLt8PzHNOqV0zqeUhaRB9GszHZDIZJk2ahJYtW+LChQswMzP7osfp6GSc8pLX1WD6uw/ClInjUc3ODvb2teC7zwfBwcHo3vPLVjjIb8xT+DIxT+HLxDyqEhLi8Trwvw7RmzdBePzvI5QwMICZmTn69B+AjevXonx5C5S3sMDG9Wuhq6sLt7bt1JIPEP8cSSnPyuVL4NzQBWXKmCEhIR4njx/FzetXsXzVOiQkxGPd6pVo2rwFjI1LI/jtG6xcsQQlSxqicdMWuWpPr6g2Kpb771sUS3ND1Khshqj3CXj9LgYr916E5wBXPAuKwLPX4Rg/oDESk1Lgc+oOAOB9fBK2HLmBeSPdEBGTgKj3ifAe6Yb7L97hzPXnAIDHAWE4cekJVk7ohJ8XHgIA/D6+E/668C+eBoZnDJULfA6R1Emqs57O0dERjo6OAIDXr1/Dy8sLmzZtUmuG1m5tEBMdhXWrVyEsLBSVKlfByjXrYG5eVq05mKfwZmKewpeJeVQ9vH8fQ793V/68aME8AED7jp0wa848DPx+CJI+fID37Fl4/z4GdjVqYPW6jdDTy/uNf19K7HMkpTyREeHwmjIB4WFhKF5cH5WqVMHyVetQz6kBPnz4gOdPn+Don4cQGxsLYxNjONaph7kLFkNPTy9X7TlULYuTvw9R/rxgVFsAwPajN/HDHF8s2nkeujpaWDquAwz1dXHtYRDajdmMuIT/RvrHLz8KuVyBHb/2RlEdTfhdf4Ef5myHQvHft+uDZu7FIo92+HPJQADAXxf+/eza7rnB55AICsv8E4kQfZ317Ny5cwcODg6Qy+U5elxeR9aJiL5GuV1nvaDkdZ31b0Fe1lkvCJmtsy6mvK6z/i2Q2jrrT95JZ531KmWkv8666Jfv8OHDWe5/8eKFmpIQEREREUmL6J31Tp06pS3TlMVoD5crIiIiIvo6yDgPJkdEXw3GzMwMvr6+UCgUmW43b94UOyIRERERkShE76w7Ojpm2SHPbtSdiIiIiOhrJfo0GE9PT8THZ/xTwukqVaoEPz8/NSYiIiIiooLC2c05I3pn3cXFJcv9enp6cHV1VVMaIiIiIiLpEL2zTkRERETfDg6s54zoc9aJiIiIiChz7KwTEREREUkUp8EQERERkfpwHkyOcGSdiIiIiEii2FknIiIiIpIoToMhIiIiIrWRcR5MjnBknYiIiIhIothZJyIiIiKSKE6DISIiIiK1kXEWTI5wZJ2IiIiISKJkgiAIYocoCB9SxU5AhZ0UXxkcjchacPQHsSNkYFZSV+wIKqT2vOZzOnsKhbQuWpEi0rpoZfpvFztCBu+29xc7ggpdic2jeBUunfdqS2NpvUdnhiPrREREREQSxc46EREREZFESeyLESIiIiL6qklrJpXkcWSdiIiIiEii2FknIiIiIpIoToMhIiIiIrWRcR5MjnBknYiIiIhIojiyTkRERERqw7+vkDMcWSciIiIikih21omIiIiIJIrTYIiIiIhIbTgLJmc4sk5EREREJFHsrBMRERERSRSnwRARERGR2nA1mJzhyDoRERERkUSxs54Fn9074dayKerUqo5e3bvg5o3rzCPhPGJm2rtnF7p3bo8G9RzQoJ4DBvTtiQvnzyn3T5syETXtrFW2/n16qCXbx77la5YQH481SxdgQJfW6NCkLjyGDcDjR/cBAKmpKdi4agmG9++Kjs3qoU+H5lj46xREhIWqHCM5ORmrFnujRxtXdGxWD17jRyEs9F2B5AWAG9ev4eefhqN544awt7XGmb9PF1hbn1q9ckWG52wz1wYqdV48f47RI4ejYX1HONethf59eiA4+K3aMqaT2vNazDzx8XFYOH8u3Fo2Rf3a9nDv1wsP7t9T7l+zagU6t3eDU91aaORcF8OGDMK9u3fUli9dQZ0jM8OiWDeiAV6u64HgLb1x3rstalqVUu5vX+c7HJjYDC/WdUfM7v6obmGY4RgDm1bGkWkt8HpjT8Ts7g+DYloZ6thblsLByc0RsKEnXq7rgWVD6kNPJ+eTFbJ7jUeEh2Pa5Ilo3rgh6jna48cfBiMg4FWO26HCTXKd9ZSUFBw8eBALFy7Ejh07EB8fL0qO48eOYsE8bwz94Uf47D8IBwdH/DRsKILfqv8fIuaRfqYypqYY5fELdvn4YpePL+rUrY8xP4/As2dPlXUaNHTB6bMXlNvvq9cVeK6PfevXbOm8Gbh57RI8p8/Bmu374VDXCZNGD0N42DskffiAZ4//RZ+BP+D3TT6YNncx3gQGYMaE0SrHWLtsAfz/OYOJM+dj0eot+JCYAC/PnyGXy/M9LwAkJibA2toaE6dML5DjZ6dipcoqz9l9f/yp3Pc6MBCDBvSBpVUFbNi8HXt9D2PosJ+go62j1oxSe16LnWeW1zRcvuSP2XPnY++Bw3ByboDhQwch9F3ah0oLC0tMmDwN+3wPY/O2nTAvWxY/DRuMyMhIteQDCu4cldTTxomZrZGSqkDX+X+j3i+HMXXHDcTEJyvrFNPRxOUnoZix+9Znj1NURwN/33mLxYfuZ7rf1LAoDk1pjhch79Fs2jF0nfc3qpYzwOofnXOcOavXuCAIGDNqBIKCXmPpilXw2f8HzMzLYtjgQUhISMhxW9Iik9AmfTJBEAQxAzg7O+Po0aMoWbIkwsLC0KxZMzx+/BgWFhZ4/fo1SpcuDX9/f5QtWzZHx/2QmrdcfXt1h021apg6faayrFN7NzRp2hyjPcbl7eDMUygy5fWV0ci5LjzGeaJz1+6YNmUiYmPfY+nyVXk6Zl7m+X0L1yw4+kOm5UlJH9C5hTO85i1FPedGyvKf3HugboNGGPjDyAyPefzoPkYP6YttvsdR2tQM8XGx6Nm2MTynzYFr89YAgIiwUPTv0gqzfvsdtes1yHAMADArqZvj3yMz9rbWWLJ8JZo2a56n43zp83r1yhXwO3Mae30PZbp/wi8e0NTUxJx5C/OUJ69zV6X2vC6IPArFl120Dx8+oGF9RyxZvhIujRory3t264RGjRpjxKgxGR4TFxcHF6faWLN+M+rVd/qidooUydtFy+9zVKb/dgDAjF61UM/aBG4zT2b7mPLGeri3ogsaTjyCewFRmdZpaFMGf01vifKD9yAmIUVZPrBpZUzpYY8qP+5Xvp6qWxjiwrx2qDXmIF68i8W77f1z/Ht8+hp/9eolOrZtDd9DR1CpUmUAgFwuRxMXZ4wZ+wu6dOv+xcfWldgdikFRydlXUpNyhtpiR8iW6CPrly9fRnJy2kWbMmUKNDQ0EBAQgCdPniAoKAjlypXD9OnqHVVKSU7Go4cP4OTcUKXcybkB7tz+/Kdx5hEnj9QyyeVyHD/6FxITE1CjZi1l+fVrV9GkkRM6tG2FmV5TERkRobZMUjo/YmSSp8qhkMuh/cmor7aODh7czbyt+Lg4yGQy6OnrAwCePn6I1NRUONT9b/TMyKQ0LCpUwqN76p9GoA6BgQFo0aQh2rRqigm/eCDo9WsAgEKhwPl/zsLC0hI//jAYTRo5oV/v7mqdpgNI73ktdh65PBXyTJ7nOjo6uHXrRob6KSnJOLDfB8X19VHFumqB5wMK9hy5OZbDrReR2Dq6EZ6t6Y7z3m3h3rRSno6ZGW2tIkhOVah88E1MTvt2rb61Sb61k/L/vtHH31ZpaGhAS0sLt25mvJ6FiUwmna0wEL2z/rFz585h9uzZMDU1BQAYGRlhzpw5OHPmjFpzREVHQS6Xw8jISKXcyMgY4eFhas3CPIUn09Mnj+FUpxbqOlTH7F+9sHjZSlSsmPYPRcOGjTB33m9Yv3ErxnlOwIP79zB0sLvyg2pBk8L5ETNTMT092NjZY9eWdYgIC4VcLsffJ47g8cN7iMykreSkJGxevQyNW7hBT694Wt6ICGhpaUG/RAmVuoaGpRAZGZ6veaWgeo0amD13Plat3YjpM2YjPDwc7v16ITo6CpGREUhISMCmjevh3NAFq9dtQtNmLTBuzEhcv3ZVbRml9rwWO4+eXnHUsK+J9WtXITT0HeRyOf768zDu37ur0v4/5/zgXNcB9RztsWP7VqxZtwmGhhnnbheEgjxHlqX1Mbh5FTwPeY8u805j0+knmO9eB71cKuTpuJ/650EIyhgUxah21aClUQQl9bTh1bMmAMDUsFi+tWNpVQHm5mWxfOkivI+JQUpyMjauX4fw8DCEhYnzvk3ikMQXI7L/f7SJjo6GlZWVyj4rKysEBwdn+fikpCQkJSWplAkaOtDRydvcSdknH7kEQchQpk7Mkz0xM1laWcHH9yBi37/H36dOYvqUCdiwZQcqVqyEVm5tlPUqVa6CarZ2cGvRFOfPnUWzFi3Vkg/4tq+Z57Q5WOLthb6dWqCIhgYqVamKxi3c8PzJvyr1UlNT4O01AQpBgZG/TMn2uIIAyArJvMecaOjiqvz/ygDs7WuinVsL/HnooPL53LhJM/QfMBAAULWqDe7cvon9e/egdp26as0qtee1mHlmey/AjGmT0aqZKzQ0NFDVphrc2rTDo0cPlXXq1KmHPfv/QHRUFA747sP4X8Zg+869KPVJB7ogFcQ5KlIEuPUiArN8bgMA7r6KQtVyJTG4eRXsOf8iT8f+2L9BMRi++iLm9q8Nr161IFcIWHv8X7yLToRcoci3drS0tLBo6XLMmDYFLs51oaGhgXr1ndDQpVH2D6aviiQ66wMHDoSOjg5SUlIQEBCAatWqKfcFBwejZMmSWT7e29sbM2fOVCmbMs0LU6fPyFUew5KG0NDQQHi46mhZZGQEjIyMc3XMvGCewpFJS0sb5ctbAABs7arjwYN72LVjG6Z5zcpQ18SkNMzMzREY+Eot2aRwfsTOZF7uOyxcuQkfEhMQHx8PI2MTzJ3miTJm/90Pk5qagrnTPBES/Abzl69XjqoDgKGREVJSUhD7/r3K6Hp0dCSqVbfP97xSU7RYMVSqXAWBAa9gaGgITU1NVKxYUaWOVYWKav16XmrPaynk+e678ti4ZQcSExIQFx8HE5PSmPCLB8qWLaesU7RYMZQvb4Hy5S1Qw74mOrRthT/+2I/BQ4YVeL6CPEchUYl4HBSjUvbkTQw61C2fp+NmZr//K+z3fwUTA10kfEiFAGBEWxsEhMblazvVbO2w98AhxMbGIiUlBaVKlULfXt1ha2uXr+2o29c3vFGwRJ8G4+7ujtKlS8PAwAAdO3ZEXJzqE93X1xc1a9bM8hiTJk1CTEyMyuY5YVKuM2lpa8Ommi0u+19UKb/s7w/7j+YgqwvzFM5MgiB8dppLdHQU3oUEw9i4tFqySPH8iJVJt2gxGBmbIPb9e9y4eglOLo0B/NdRf/M6EN5L16KEQUmVx1W2rgZNTU3cunZJWRYRHoaAF89g8w101pOTk/Hy5XMYm5hAS0sb1Wyr49XLlyp1Al69gpl5zhYDyAupPa+llKdosWIwMSmN9zEx8Pe/gMZNmn6+siAo50cXtII8R1eehKGSueo0tYpmJfA6PH870B8Li/mA+KRUdHGywIdkBfzuZT0TILf09fVRqlQpBAS8wsMH99G4abMCaYekSfSR9c2bN2e5f8aMGdDQ0Miyjo5OxikveV0Npr/7IEyZOB7V7Oxgb18Lvvt8EBwcjO49e+XtwMzzVWZavnQxGro0QhlTUyTEx+P4saO4fu0qVq7ZgISEeKxZ+TuatWgJYxMTvH3zBiuWLUFJQ0M0bZ63lT1y4lu/ZtevXAQEoFx5C7wNeo0NK5egXHkLtGzbEfLUVMye8guePXmEWQtWQKFQIDIibeRPv4QBtLS0oFdcH63adca63xdB36Ak9EuUwIbfF8OyQmXUql0/3/MCaWvDBwYGKn9+ExSEfx89goGBAczMzQukzXSLF85Ho8ZNYGZmhsjISKxfuxrxcXFo37EzAGDgoMEY/4sHHGrXQZ269eB/4Tz+OeeHDZu3FWiuT0nteS12Hv+L5yEIgKWlFV4HBmDJ4oWwtLRCh05dkJiQgA3r18C1cVMYm5ggJjoae3124927ELRo2Vot+YCCO0erjj7CyZmtMa6jHf64HACHikYY2LQyRm+4rKxjqKeNcsZ6MDUsCgCobJbWuX8XnYjQmLTVpEob6KJMyaKoYJp2c3m17wwR9yEFQeHxiPr/MpBDW1rj6pMwxH1IQZPqZvi1ryNm7L6lsmrMl8juNX7yxDEYGpaCmZk5nj59jAXec9GkaXM4N2iYxVHpayN6Zz07kZGR8PLywqZNm9Tabmu3NoiJjsK61asQFhaKSpWrYOWadTBX46gR8xSeTJER4ZgyaTzCw0LTVlaoYo2VazbAybkBPnz4gKdPn+DPPw8i9n0sTExMULtuPSz4bYnKNIuC9q1fs4S4OGxesxzhYe9QvIQBGro2w8BhP0NTUwshwW9w+cJZAMBPA1X/WNX8FRtg71AHADBslCc0NDQwd5onkpOSULN2Xcyc8mu2Awq59eDBfQwZNED5828LvAEAHTp2xq9z5xVIm+nevQvBpPFjERUVDcNShqhRoya27dqrvDZNm7fA1OkzsHHDOizwng0LSyv8tmQ5ajnULtBcn5La81rsPHGxcVixbDHevQuBgUFJNGveAiNGeUBLSwsKhQKvXr7En4dHIToqCgYlS8LWtjo2bd2Jiv9fGlAdCuoc3XwRgb6Lz8KrVy2M71IDAWFxmLT9GvZd/O8bIDfHclj943/LrG4enTb/23v/HczzvQsA+L55FUzq9t+3ZcdntAIA/Lj6Inb9kzb33bGiESZ3s4eeriaevI3BmA2X4XNB9ZumL5HdazwsLAy/LZiHiPAImJiYoF2Hjhg2/KcctyM1hWUVFqkQfZ317Ny5cwcODg45/qMjeR1ZJ5LiK4NvcFn73DrrYsqvddbzi9Se13xOZ+9L11lXl7yus57f0tdZl5LcrLNekKS2znpwjHTWWTczkP4666JfvsOHD2e5/8WL/LuDm4iIiIioMBG9s96pUyfIZDJkNcAv9tJyRERERJQ/vsblbguS6KvBmJmZwdfXFwqFItPt5s2bYkckIiIiIhKF6J11R0fHLDvk2Y26ExEREVEhIpPQVgiIPg3G09MT8fHxn91fqVIl+Pn5qTEREREREZE0iN5Zd3FxyXK/np4eXF1ds6xDRERERPQ1Er2zTkRERETfjkIy+0QyRJ+zTkREREREmWNnnYiIiIhIojgNhoiIiIjUhn8+J2c4sk5EREREJFHsrBMRERERSRSnwRARERGR2si4HkyOcGSdiIiIiEiiOLJOREREROrDgfUc4cg6EREREZFEsbNORERERCRRMkEQBLFDFIQPqWInoMJOiq8Mrk1LRGKT2nujFN8XDet7iB1BReL1JWJHUBEeJ51OmnFx6c8I58g6EREREZFEsbNORERERCRR0h/7JyIiIqKvhhSnLkkZR9aJiIiIiCSKI+tEREREpDb8C6Y5w5F1IiIiIiKJYmediIiIiEiiOA2GiIiIiNSGN5jmDEfWiYiIiIgkip11IiIiIiKJYmediIiIiEii2FknIiIiIpIodtaJiIiIiCSKq8EQERERkdpwNZic4cg6EREREZFEsbOeBZ/dO+HWsinq1KqOXt274OaN68wj0Tw3rl/Dzz8NR/PGDWFva40zf59We/ujRgxHiyYNUdNOtf2UlBQsXbwQ3Tq3R/06NdGiSUNMnTQeoaHv1JoR4DUrjJl4zbInpXPEPNmLj4/Dgnlz4NaiCeo51sCAvr1w/95dUTOl27h+LextrbHAe06+HK9BrQrYv3gIXhybgcTrS9De1U5lf+L1JZluHv2bKOucWDsiw/5tc/urHGff4sF4cmQ6oi4uwIvjM7FxVl+YGZfIl9+hIMgk9F9hIHpnPSgoCOHh4cqfz58/j759+8LFxQX9+vXDpUuXRMl1/NhRLJjnjaE//Aif/Qfh4OCIn4YNRfDbt8wjwTyJiQmwtrbGxCnTRWu/irU1Jk7O2P6HDx/w6OFDDB32I/bsPYBFS39HQMArjBn5o1oz8pplT2qZeM2yJ7VzxDzZmzl9Ki5f8sds7wXY98efcHJugOFDB+HdO/UPYHzs/r272L/PB1WqWOfbMfWKauPe0zfwWOCb6X7LVtNVth9m7oZCocAfZ1Q/vGw8cEml3sg5+1T2/3P9GfpN3Ar7rt7oM34zKpQ1wq75A/Pt9yBxid5Z79GjB65duwYAOHToEBo3boy4uDg0aNAACQkJcHV1xZEjR9Sea/vWzejctSu6dOuOChUrYvykKTA1M8Ven91qz8I82Wvo4oqRoz3QvEVL8dof5YFmmbSvr6+PtRs2o1XrNrC0qoAa9jUxYdJUPHz4AMHB6vsHk9cse1LLxGuWPamdI+bJ2ocPH/D36ZMYM9YTjrXroHx5C/w44meYly2HfT67RMkEAAnx8Zg0wRNeM2ejhIFBvh33pP+/mLn6GA753ct0/7uIWJWtvasdzl1/hldvIlTqJX5IVqn3Pv6Dyv4Vu87h6v0ABIZE4fLdV/ht69+oW90Cmhqid/MoH4h+Fe/fvw8bGxsAgLe3N+bOnYtDhw5h3rx5OHDgABYvXozp09U7ipOSnIxHDx/AybmhSrmTcwPcuX1LrVmY5+sUFxcHmUwGfX31fE3Ja1b48JplT2rniHmyJ5enQi6XQ0dHR6VcV1cXt27eFCUTAMydPQuNGrmivpOzaBlKlyqO1g2rYeuhKxn29XRzxOvTv+KGzwR4j+6A4sV0MjlCGsMSxdCrtSMu332FVLmiICPnmkwmna0wEH01mCJFiuD9+/cAgJcvX8LNzU1lv5ubGyZMmKDWTFHRUZDL5TAyMlIpNzIyRnh4mFqzMM/XJykpCcuX/Aa3Nu1QvHhxtbTJa1b48JplT2rniHmyp6dXHDXsa2HdmlWwqlABRkbGOH70CO7dvYPyFhaiZDp29C88evQQu3z2i9J+un7t6iI2/gMO+qlOgdlz7AZevY3Eu4j3sK1ohlkj2qJ6FXO0G7FGpd7sn9theI+G0Cuqgyt3X6GLx3p1xqcCJPrIuqurK3bvTvs6rlatWjh79qzKfj8/P5QtWzbLYyQlJeH9+/cqW1JSUp6zyT75yCUIQoYydWKewi8lJQUTPD2gEARMnjZD7e3zmhU+vGbZk9o5Yp6szfFeAEBAy6aNUNehOnbt3A63Nu2gUURD7VlCgoOxYN4czJ23MMNov7oN6FAXPsdvIik5VaV888HL8Lv6BA+fh2DfyVvoM2ELmtWzRk3rcir1lmzzQ/2+i9B2xGrIFQpsmNlXnfGpAIk+sj5v3jy4uLjg7du3aNiwIaZMmYJr167BxsYGjx8/ho+PD9asWZPlMby9vTFz5kyVsinTvDB1+oxcZTIsaQgNDQ2VG18BIDIyAkZGxrk6Zl4wz9chJSUF48eNwdugIKzbtFVto+oAr1lhxGuWPamdI+b5Mt+VL4+NW3YgMSEBcfFxMDEpjfHjxsC8bLnsH5zPHj58gMiICPTu0UVZJpfLceP6NezZvRPXbt2DhkbBf4hoULMCrC3LoP+kbdnWvfVvEJJTUlGpvDFuPw5SlkfExCMiJh7PAsPw+OU7PDs6A/WqW+DKvYCCjJ4rHG7IGdFH1m1sbHDlyhUkJydjwYIFiI+Px86dOzFjxgw8e/YMe/bswcCBA7M8xqRJkxATE6OyeU6YlOtMWtrasKlmi8v+F1XKL/v7w75mrVwfl3m+Xekd9cDAAKzZsAUlSxqqtX1es8KH1yx7UjtHzJMzRYsVg4lJabyPiYG//wU0btpM7Rnq1a+P/Qf/hI/vQeVma2uHNu3aw8f3oFo66gDg3rEebjx8jXtPs190oFpFU2hraSI4/P1n66R/c6KtLfqYLOUDSVzFihUrYvfu3RAEAaGhoVAoFDA2NoaWltYXPV5HRyfD11cfUj9T+Qv1dx+EKRPHo5qdHezta8F3nw+Cg4PRvWevvB2YeQpEQnw8AgMDlT+/CQrCv48ewcDAAGbm5gXffsIn7b8Jwr//prVvYlIanmNH4dHDh1i+ci0UCrlyvqiBgQG0tLQLPB/Aa1YYM/GaZU9q54h5sud/8TwEQYClpRUCAwOxZNECWFpaoWOnLtk/OJ/p6RVH5cpVVMqKFiuGkgYlM5Tn6vhFtVHxu/++xbAsa4QaVcwRFZOA1++iAQD6ejro0tweE5cezvB4q7JG6OXmiBMXHyE8Og42FUwxb0xH3Po3CJfuvAQA1LYtj9q25eF/+wWi3yfCsqwRpg93w/PXYbhy91WefwcSnyQ66+lkMhnKlCmjUvb69Wt4eXlh06ZNas3S2q0NYqKjsG71KoSFhaJS5SpYuWYdzM2znj/PPOLkefDgPoYMGqD8+bcF3gCADh0749e58wq+/fv3MfT7/9pf9P/223fsjOE/jcRZvzMAgJ7dOqo8bv2mbahTt16B5wN4zQpjJl6z7EntHDFP9mJjY7Fi6WK8excCA4OSaNaiJUaO8vjiAbrCxKHadzi5dqTy5wVjOwEAtv95FT/MTLtfr3tLB8hkMuw9nnE1nJRUOZrUqYwRvRqheDEdBL2LwvELjzBn/QkoFAIAIPFDCjo2qYGpP7SGXlFthIS/x8lL/2LA5G1ITpEX/C+ZG5wHkyMyQRAEsUNk5c6dO3BwcIBcnrMnXF5H1omk+MrgfYVEJDapvTdK8X3RsL6H2BFUJF5fInYEFbFJ0llSUl9H9Bnh2RJ9ZP3w4Yxf+3zsxYsXakpCRERERAVNxqH1HBG9s96pUyfIZDJkNcDPZcqIiIiI6Fsk+ti/mZkZfH19oVAoMt1uivgXzYiIiIiIxCR6Z93R0THLDnl2o+5EREREVHjIZNLZCgPRp8F4enoiPj7+s/srVaoEPz8/NSYiIiIiIpIG0TvrLi4uWe7X09ODq6urmtIQEREREUmH6J11IiIiIvp2FJLZJ5Ih+px1IiIiIiLKHDvrREREREQSxWkwRERERKQ+nAeTIxxZJyIiIiKSKI6sExEREZHayDi0niMcWSciIiIi+kKrVq2ClZUVdHV14ejoiPPnz2dZ/9y5c3B0dISuri4qVKiANWvW5Kg9dtaJiIiIiL6Aj48PxowZgylTpuDWrVtwcXGBm5sbAgMDM63/8uVLtGnTBi4uLrh16xYmT56MUaNGwdfX94vblAmCIOTXLyAlH1LFTkCFnRRfGYXlTyMT0ddLau+NUnxfNKzvIXYEFYnXl4gdQYWU+mi6OZwQXq9ePTg4OGD16tXKMhsbG3Tq1Ane3t4Z6k+YMAGHDx/Go0ePlGXDhw/HnTt3cOnSpS9qkyPrRERERETZSE5Oxo0bN9CyZUuV8pYtW8Lf3z/Tx1y6dClD/VatWuH69etISUn5onZ5gykRERERfZOSkpKQlJSkUqajowMdHZ0MdcPDwyGXy1GmTBmV8jJlyiAkJCTT44eEhGRaPzU1FeHh4TAzM8s+pECf9eHDB8HLy0v48OGD2FGUpJaJebIntUzMkzWp5REE6WVinuxJLRPzZE1qeQRBmpm+Rl5eXgIAlc3LyyvTum/evBEACP7+/irls2fPFqytrTN9TOXKlYW5c+eqlF24cEEAIAQHB39Rxq92znp+eP/+PQwMDBATE4MSJUqIHQeA9DIxT/aklol5ClceQHqZmCd7UsvEPIUrDyDNTF+jnIysJycno1ixYti3bx86d+6sLB89ejRu376Nc+fOZXhMo0aNUKtWLSxbtkxZ9scff6BHjx5ISEiAlpZWthk5Z52IiIiIvkk6OjooUaKEypZZRx0AtLW14ejoiFOnTqmUnzp1Cs7Ozpk+xsnJKUP9kydPonbt2l/UUQfYWSciIiIi+iJjx47Fhg0bsGnTJjx69AgeHh4IDAzE8OHDAQCTJk3CgAEDlPWHDx+OgIAAjB07Fo8ePcKmTZuwceNG/PLLL1/cJm8wJSIiIiL6Aj179kRERARmzZqF4OBg2NnZ4ejRo7CwsAAABAcHq6y5bmVlhaNHj8LDwwMrV66Eubk5li9fjq5du35xm+ysZ0FHRwdeXl6f/TpEDFLLxDzZk1om5sma1PIA0svEPNmTWibmyZrU8gDSzERpfvrpJ/z000+Z7tuyZUuGMldXV9y8eTPX7fEGUyIiIiIiieKcdSIiIiIiiWJnnYiIiIhIothZJyIiIiKSKHbWP+Off/5B+/btYW5uDplMhoMHD4qWxdvbG3Xq1IG+vj5Kly6NTp064fHjx6LlAYDVq1ejRo0ayjVJnZyccOzYMVEzfczb2xsymQxjxowRpf0ZM2ZAJpOpbKampqJkSffmzRv069cPRkZGKFasGGrWrIkbN26IlsfS0jLDOZLJZBgxYoQoeVJTUzF16lRYWVmhaNGiqFChAmbNmgWFQiFKHgCIjY3FmDFjYGFhgaJFi8LZ2RnXrl1TW/vZvQ8KgoAZM2bA3NwcRYsWRePGjfHgwQPR8hw4cACtWrWCsbExZDIZbt++XWBZssuTkpKCCRMmoHr16tDT04O5uTkGDBiAt2/fipYJSHtvqlq1KvT09GBoaIjmzZvjypUrouX52LBhwyCTybB06VLR8gwcODDDe1L9+vVFywMAjx49QocOHWBgYAB9fX3Ur19fZbUR+vqxs/4Z8fHxsLe3x++//y52FJw7dw4jRozA5cuXcerUKaSmpqJly5aIj48XLVO5cuUwb948XL9+HdevX0fTpk3RsWPHAv2H+ktdu3YN69atQ40aNUTNYWtri+DgYOV279490bJERUWhQYMG0NLSwrFjx/Dw4UMsWrQIJUuWFC3TtWvXVM5P+h+N6N69uyh55s+fjzVr1uD333/Ho0ePsGDBAixcuBArVqwQJQ8ADBkyBKdOncL27dtx7949tGzZEs2bN8ebN2/U0n5274MLFizA4sWL8fvvv+PatWswNTVFixYtEBsbK0qe+Ph4NGjQAPPmzSuQ9nOSJyEhATdv3sS0adNw8+ZNHDhwAE+ePEGHDh1EywQAVapUwe+//4579+7hwoULsLS0RMuWLREWFiZKnnQHDx7ElStXYG5uXiA5cpKndevWKu9NR48eFS3P8+fP0bBhQ1StWhVnz57FnTt3MG3aNOjq6hZYJpIggbIFQPjjjz/EjqEUGhoqABDOnTsndhQVhoaGwoYNG0TNEBsbK1SuXFk4deqU4OrqKowePVqUHF5eXoK9vb0obWdmwoQJQsOGDcWOkaXRo0cLFStWFBQKhSjtt23bVvj+++9Vyrp06SL069dPlDwJCQmChoaGcOTIEZVye3t7YcqUKWrP8+n7oEKhEExNTYV58+Ypyz58+CAYGBgIa9asUXuej718+VIAINy6davAc3xJnnRXr14VAAgBAQGSyRQTEyMAEE6fPi1anqCgIKFs2bLC/fv3BQsLC2HJkiUFnuVzedzd3YWOHTuqpf0vydOzZ0/R3oNIOjiyXgjFxMQAAEqVKiVykjRyuRx79uxBfHw8nJycRM0yYsQItG3bFs2bNxc1BwA8ffoU5ubmsLKyQq9evfDixQvRshw+fBi1a9dG9+7dUbp0adSqVQvr168XLc+nkpOTsWPHDnz//feQyWSiZGjYsCH+/vtvPHnyBABw584dXLhwAW3atBElT2pqKuRyeYYRtKJFi+LChQuiZPrYy5cvERISgpYtWyrLdHR04OrqCn9/fxGTSVdMTAxkMpmo32h9LDk5GevWrYOBgQHs7e1FyaBQKNC/f394enrC1tZWlAyfOnv2LEqXLo0qVapg6NChCA0NFSWHQqHAX3/9hSpVqqBVq1YoXbo06tWrJ+q0XBIHO+uFjCAIGDt2LBo2bAg7OztRs9y7dw/FixeHjo4Ohg8fjj/++APVqlUTLc+ePXtw8+ZNeHt7i5YhXb169bBt2zacOHEC69evR0hICJydnRERESFKnhcvXmD16tWoXLkyTpw4geHDh2PUqFHYtm2bKHk+dfDgQURHR2PgwIGiZZgwYQJ69+6NqlWrQktLC7Vq1cKYMWPQu3dvUfLo6+vDyckJv/76K96+fQu5XI4dO3bgypUrCA4OFiXTx0JCQgAAZcqUUSkvU6aMch/958OHD5g4cSL69OmDEiVKiJrlyJEjKF68OHR1dbFkyRKcOnUKxsbGomSZP38+NDU1MWrUKFHa/5Sbmxt27tyJM2fOYNGiRbh27RqaNm2KpKQktWcJDQ1FXFwc5s2bh9atW+PkyZPo3LkzunTpgnPnzqk9D4mHf8G0kBk5ciTu3r0riZE1a2tr3L59G9HR0fD19YW7uzvOnTsnSof99evXGD16NE6ePCmJuXxubm7K/69evTqcnJxQsWJFbN26FWPHjlV7HoVCgdq1a2Pu3LkAgFq1auHBgwdYvXo1BgwYoPY8n9q4cSPc3NwKfL5qVnx8fLBjxw7s2rULtra2uH37NsaMGQNzc3O4u7uLkmn79u34/vvvUbZsWWhoaMDBwQF9+vTJ01/Cy2+ffhMiCIJo345IVUpKCnr16gWFQoFVq1aJHQdNmjTB7du3ER4ejvXr16NHjx64cuUKSpcurdYcN27cwLJly3Dz5k3JPGd69uyp/H87OzvUrl0bFhYW+Ouvv9ClSxe1Zkm/ub1jx47w8PAAANSsWRP+/v5Ys2YNXF1d1ZqHxMOR9ULk559/xuHDh+Hn54dy5cqJHQfa2tqoVKkSateuDW9vb9jb22PZsmWiZLlx4wZCQ0Ph6OgITU1NaGpq4ty5c1i+fDk0NTUhl8tFyZVOT08P1atXx9OnT0Vp38zMLMOHKBsbG0msKBAQEIDTp09jyJAhoubw9PTExIkT0atXL1SvXh39+/eHh4eHqN/UVKxYEefOnUNcXBxev36Nq1evIiUlBVZWVqJlSpe+utGno+ihoaEZRtu/ZSkpKejRowdevnyJU6dOiT6qDqS9H1WqVAn169fHxo0boampiY0bN6o9x/nz5xEaGory5csr37cDAgIwbtw4WFpaqj1PZszMzGBhYSHKe7exsTE0NTUl+95N6sPOeiEgCAJGjhyJAwcO4MyZM5L4hzozgiCI8lUhADRr1gz37t3D7du3lVvt2rXRt29f3L59GxoaGqLkSpeUlIRHjx7BzMxMlPYbNGiQYbnPJ0+ewMLCQpQ8H9u8eTNKly6Ntm3bipojISEBRYqoviVqaGiIunRjOj09PZiZmSEqKgonTpxAx44dxY4EKysrmJqaKlfxAdLmQJ87dw7Ozs4iJpOO9I7606dPcfr0aRgZGYkdKVNivXf3798fd+/eVXnfNjc3h6enJ06cOKH2PJmJiIjA69evRXnv1tbWRp06dST73k3qw2kwnxEXF4dnz54pf3758iVu376NUqVKoXz58mrNMmLECOzatQuHDh2Cvr6+ciTLwMAARYsWVWuWdJMnT4abmxu+++47xMbGYs+ePTh79iyOHz8uSh59ff0Mc/j19PRgZGQkytz+X375Be3bt0f58uURGhqK2bNn4/3796JNp/Dw8ICzszPmzp2LHj164OrVq1i3bh3WrVsnSp50CoUCmzdvhru7OzQ1xX07at++PebMmYPy5cvD1tYWt27dwuLFi/H999+LlunEiRMQBAHW1tZ49uwZPD09YW1tjUGDBqml/ezeB8eMGYO5c+eicuXKqFy5MubOnYtixYqhT58+ouSJjIxEYGCgci3z9E6Oqalpgfydg6zymJubo1u3brh58yaOHDkCuVyufO8uVaoUtLW18z1PdpmMjIwwZ84cdOjQAWZmZoiIiMCqVasQFBRUYEumZnfNPv0Ao6WlBVNTU1hbW6s9T6lSpTBjxgx07doVZmZmePXqFSZPngxjY2N07txZ7XnKly8PT09P9OzZE40aNUKTJk1w/Phx/Pnnnzh79myB5CGJEnMpGinz8/MTAGTY3N3d1Z4lsxwAhM2bN6s9S7rvv/9esLCwELS1tQUTExOhWbNmwsmTJ0XLkxkxl27s2bOnYGZmJmhpaQnm5uZCly5dhAcPHoiSJd2ff/4p2NnZCTo6OkLVqlWFdevWiZpHEAThxIkTAgDh8ePHYkcR3r9/L4wePVooX768oKurK1SoUEGYMmWKkJSUJFomHx8foUKFCoK2trZgamoqjBgxQoiOjlZb+9m9DyoUCsHLy0swNTUVdHR0hEaNGgn37t0TLc/mzZsz3e/l5aX2POnLR2a2+fn5FUie7DIlJiYKnTt3FszNzQVtbW3BzMxM6NChg3D16lVR8mSmoJduzCpPQkKC0LJlS8HExETQ0tISypcvL7i7uwuBgYGi5Em3ceNGoVKlSoKurq5gb28vHDx4sMDykDTJBEEQ8qvjT0RERERE+Ydz1omIiIiIJIqddSIiIiIiiWJnnYiIiIhIothZJyIiIiKSKHbWiYiIiIgkip11IiIiIiKJYmediIiIiEii2FknIiIiIpIodtaJqEBt2bIFMplMuWlqaqJcuXIYNGgQ3rx5o5YMlpaWGDhwoPLns2fPQiaT5fhPdvv7+2PGjBmIjo7O13wAMHDgQFhaWmZbr3HjxrCzs8uXNtOvzfXr1/PleB8f89WrV/l2TCKibxk760SkFps3b8alS5dw6tQpDB06FLt374aLiwvi4+PVnsXBwQGXLl2Cg4NDjh7n7++PmTNnFkhnnYiIKDOaYgcgom+DnZ0dateuDQBo0qQJ5HI5fv31Vxw8eBB9+/bN9DEJCQkoVqxYvmcpUaIE6tevn+/HJSIiym8cWSciUaR3lgMCAgCkTQMpXrw47t27h5YtW0JfXx/NmjUDACQnJ2P27NmoWrUqdHR0YGJigkGDBiEsLEzlmCkpKRg/fjxMTU1RrFgxNGzYEFevXs3Q9uemwVy5cgXt27eHkZERdHV1UbFiRYwZMwYAMGPGDHh6egIArKyslNN6Pj6Gj48PnJycoKenh+LFi6NVq1a4detWhva3bNkCa2tr6OjowMbGBtu2bcvVOfyc69evo1evXrC0tETRokVhaWmJ3r17K8/1p6KiojBo0CCUKlUKenp6aN++PV68eJGh3unTp9GsWTOUKFECxYoVQ4MGDfD333/na3YiIlLFzjoRieLZs2cAABMTE2VZcnIyOnTogKZNm+LQoUOYOXMmFAoFOnbsiHnz5qFPnz7466+/MG/ePJw6dQqNGzdGYmKi8vFDhw7Fb7/9hgEDBuDQoUPo2rUrunTpgqioqGzznDhxAi4uLggMDMTixYtx7NgxTJ06Fe/evQMADBkyBD///DMA4MCBA7h06ZLKVJq5c+eid+/eqFatGvbu3Yvt27cjNjYWLi4uePjwobKdLVu2YNCgQbCxsYGvry+mTp2KX3/9FWfOnMn7Sf2/V69ewdraGkuXLsWJEycwf/58BAcHo06dOggPD89Qf/DgwShSpAh27dqFpUuX4urVq2jcuLHKdJ8dO3agZcuWKFGiBLZu3Yq9e/eiVKlSaNWqFTvsREQFSSAiKkCbN28WAAiXL18WUlJShNjYWOHIkSOCiYmJoK+vL4SEhAiCIAju7u4CAGHTpk0qj9+9e7cAQPD19VUpv3btmgBAWLVqlSAIgvDo0SMBgODh4aFSb+fOnQIAwd3dXVnm5+cnABD8/PyUZRUrVhQqVqwoJCYmfvZ3WbhwoQBAePnypUp5YGCgoKmpKfz8888q5bGxsYKpqanQo0cPQRAEQS6XC+bm5oKDg4OgUCiU9V69eiVoaWkJFhYWn207naurq2Bra5ttvY+lpqYKcXFxgp6enrBs2TJlefq16dy5s0r9ixcvCgCE2bNnC4IgCPHx8UKpUqWE9u3bq9STy+WCvb29ULdu3QzH/PQcERFR7nBknYjUon79+tDS0oK+vj7atWsHU1NTHDt2DGXKlFGp17VrV5Wfjxw5gpIlS6J9+/ZITU1VbjVr1oSpqalyGoqfnx8AZJj/3qNHD2hqZn17zpMnT/D8+XMMHjwYurq6Of7dTpw4gdTUVAwYMEAlo66uLlxdXZUZHz9+jLdv36JPnz6QyWTKx1tYWMDZ2TnH7X5OXFwcJkyYgEqVKkFTUxOampooXrw44uPj8ejRowz1Pz1nzs7OsLCwUJ5Tf39/REZGwt3dXeX3UygUaN26Na5duybKjcJERN8C3mBKRGqxbds22NjYQFNTE2XKlIGZmVmGOsWKFUOJEiVUyt69e4fo6Ghoa2tnetz0aR0REREAAFNTU5X9mpqaMDIyyjJb+tz3cuXKfdkv84n0qTJ16tTJdH+RIkWyzJhell/LHfbp0wd///03pk2bhjp16qBEiRKQyWRo06aNyrShj9vOrCw9b/rv161bt8+2GRkZCT09vXzJT0RE/2FnnYjUwsbGRrkazOd8PNqcztjYGEZGRjh+/Himj9HX1wcAZYc8JCQEZcuWVe5PTU1Vdjo/J33efFBQUJb1PsfY2BgAsH//flhYWHy23scZP5VZWW7ExMTgyJEj8PLywsSJE5XlSUlJiIyMzPQxn8tTqVIlAP/9fitWrPjsKjqffkNCRET5g511IpK0du3aYc+ePZDL5ahXr95n6zVu3BgAsHPnTjg6OirL9+7di9TU1CzbqFKlCipWrIhNmzZh7Nix0NHRybReevmno9OtWrWCpqYmnj9/nmEaz8esra1hZmaG3bt3Y+zYscoPJwEBAfD394e5uXmWOb+ETCaDIAgZfocNGzZALpdn+pidO3eq5Pb390dAQACGDBkCAGjQoAFKliyJhw8fYuTIkXnOSEREX46ddSKStF69emHnzp1o06YNRo8ejbp160JLSwtBQUHw8/NDx44d0blzZ9jY2KBfv35YunQptLS00Lx5c9y/fx+//fZbhqk1mVm5ciXat2+P+vXrw8PDA+XLl0dgYCBOnDiBnTt3AgCqV68OAFi2bBnc3d2hpaUFa2trWFpaYtasWZgyZQpevHiB1q1bw9DQEO/evcPVq1ehp6eHmTNnokiRIvj1118xZMgQdO7cGUOHDkV0dDRmzJiR6VSUz3n//j3279+fodzExASurq5o1KgRFi5cCGNjY1haWuLcuXPYuHEjSpYsmenxrl+/jiFDhqB79+54/fo1pkyZgrJly+Knn34CABQvXhwrVqyAu7s7IiMj0a1bN5QuXRphYWG4c+cOwsLCsHr16i/OT0REOSD2Ha5E9HVLXx3k6b0dawAAAY5JREFU2rVrWdZzd3cX9PT0Mt2XkpIi/Pbbb4K9vb2gq6srFC9eXKhataowbNgw4enTp8p6SUlJwrhx44TSpUsLurq6Qv369YVLly4JFhYW2a4GIwiCcOnSJcHNzU0wMDAQdHR0hIoVK2ZYXWbSpEmCubm5UKRIkQzHOHjwoNCkSROhRIkSgo6OjmBhYSF069ZNOH36tMoxNmzYIFSuXFnQ1tYWqlSpImzatElwd3f/4tVgAGS6ubq6CoIgCEFBQULXrl0FQ0NDQV9fX2jdurVw//79DOch/dqcPHlS6N+/v1CyZEmhaNGiQps2bVTOa7pz584Jbdu2FUqVKiVoaWkJZcuWFdq2bSvs27cvwzG5GgwRUf6QCYIgiPQ5gYiIiIiIssClG4mIiIiIJIqddSIiIiIiiWJnnYiIiIhIothZJyIiIiKSKHbWiYiIiIgkip11IiIiIiKJYmediIiIiEii2FknIiIiIpIodtaJiIiIiCSKnXUiIiIiIoliZ52IiIiISKLYWSciIiIikqj/AYO6Tpp2q0epAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 89.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 82.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 83.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 83.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 83.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 83.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 84.25%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T02:15:27.398654Z",
     "iopub.status.busy": "2025-05-09T02:15:27.398654Z",
     "iopub.status.idle": "2025-05-09T02:15:27.417237Z",
     "shell.execute_reply": "2025-05-09T02:15:27.416727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          89.27\n",
      "1    LRM (CAE)          82.46\n",
      "2    MLP (CAE)          83.26\n",
      "3     TSCL LRM          83.67\n",
      "4     TSCL MLP          83.23\n",
      "5  SCL_SDL LRM          83.99\n",
      "6  SCL_SDL MLP          84.25\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          89.27\n",
      "6  SCL_SDL MLP          84.25\n",
      "5  SCL_SDL LRM          83.99\n",
      "3     TSCL LRM          83.67\n",
      "2    MLP (CAE)          83.26\n",
      "4     TSCL MLP          83.23\n",
      "1    LRM (CAE)          82.46\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
