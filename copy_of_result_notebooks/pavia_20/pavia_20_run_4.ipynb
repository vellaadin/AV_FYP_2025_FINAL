{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:14.271190Z",
     "iopub.status.busy": "2025-05-08T17:15:14.271190Z",
     "iopub.status.idle": "2025-05-08T17:15:14.274682Z",
     "shell.execute_reply": "2025-05-08T17:15:14.274682Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:14.277688Z",
     "iopub.status.busy": "2025-05-08T17:15:14.276686Z",
     "iopub.status.idle": "2025-05-08T17:15:16.460465Z",
     "shell.execute_reply": "2025-05-08T17:15:16.460465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:16.462469Z",
     "iopub.status.busy": "2025-05-08T17:15:16.462469Z",
     "iopub.status.idle": "2025-05-08T17:15:20.118336Z",
     "shell.execute_reply": "2025-05-08T17:15:20.118336Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:20.121648Z",
     "iopub.status.busy": "2025-05-08T17:15:20.120652Z",
     "iopub.status.idle": "2025-05-08T17:15:20.140513Z",
     "shell.execute_reply": "2025-05-08T17:15:20.140513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:20.142709Z",
     "iopub.status.busy": "2025-05-08T17:15:20.142709Z",
     "iopub.status.idle": "2025-05-08T17:15:21.387038Z",
     "shell.execute_reply": "2025-05-08T17:15:21.386534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1096, 715)\n",
      "Hypercube shape: (1096, 715, 102)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Pavia_gt.mat'\n",
    "data_files = 'Pavia.mat'\n",
    "label_files = 'pavia_gt'\n",
    "hypercube_files = 'pavia'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:21.390044Z",
     "iopub.status.busy": "2025-05-08T17:15:21.390044Z",
     "iopub.status.idle": "2025-05-08T17:15:21.395611Z",
     "shell.execute_reply": "2025-05-08T17:15:21.395611Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:21.398626Z",
     "iopub.status.busy": "2025-05-08T17:15:21.397624Z",
     "iopub.status.idle": "2025-05-08T17:15:28.029169Z",
     "shell.execute_reply": "2025-05-08T17:15:28.029169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 148152\n",
      "Extracted windows shape: (148152, 5, 5, 102)\n",
      "Corresponding labels shape: (148152,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:28.033175Z",
     "iopub.status.busy": "2025-05-08T17:15:28.032175Z",
     "iopub.status.idle": "2025-05-08T17:15:28.043402Z",
     "shell.execute_reply": "2025-05-08T17:15:28.042427Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:28.045596Z",
     "iopub.status.busy": "2025-05-08T17:15:28.045596Z",
     "iopub.status.idle": "2025-05-08T17:15:33.692772Z",
     "shell.execute_reply": "2025-05-08T17:15:33.692772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 65971 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 7598 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 3090 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 2685 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 6584 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 9248 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 7287 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 42826 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 2863 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t180 samples\n",
      "\tshape (180, 5, 5, 102) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t45 samples\n",
      "\tshape (45, 5, 5, 102) --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- Test set created with: \n",
      "\t147927 samples\n",
      "\tshape (147927, 5, 5, 102) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(180, 5, 5, 102)\n",
      "(45, 5, 5, 102)\n",
      "(147927, 5, 5, 102)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:33.695777Z",
     "iopub.status.busy": "2025-05-08T17:15:33.695777Z",
     "iopub.status.idle": "2025-05-08T17:15:33.699130Z",
     "shell.execute_reply": "2025-05-08T17:15:33.699130Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:33.701140Z",
     "iopub.status.busy": "2025-05-08T17:15:33.701140Z",
     "iopub.status.idle": "2025-05-08T17:15:34.379506Z",
     "shell.execute_reply": "2025-05-08T17:15:34.379506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 180\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:34.382511Z",
     "iopub.status.busy": "2025-05-08T17:15:34.381514Z",
     "iopub.status.idle": "2025-05-08T17:15:34.386816Z",
     "shell.execute_reply": "2025-05-08T17:15:34.386816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:34.388821Z",
     "iopub.status.busy": "2025-05-08T17:15:34.388821Z",
     "iopub.status.idle": "2025-05-08T17:15:34.792808Z",
     "shell.execute_reply": "2025-05-08T17:15:34.792808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (118521, 5, 5, 102)\n",
      "Validation data shape: (29631, 5, 5, 102)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:34.795876Z",
     "iopub.status.busy": "2025-05-08T17:15:34.795876Z",
     "iopub.status.idle": "2025-05-08T17:15:34.800054Z",
     "shell.execute_reply": "2025-05-08T17:15:34.800054Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:34.803059Z",
     "iopub.status.busy": "2025-05-08T17:15:34.803059Z",
     "iopub.status.idle": "2025-05-08T17:15:35.102243Z",
     "shell.execute_reply": "2025-05-08T17:15:35.102243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:35.105249Z",
     "iopub.status.busy": "2025-05-08T17:15:35.105249Z",
     "iopub.status.idle": "2025-05-08T17:15:35.109750Z",
     "shell.execute_reply": "2025-05-08T17:15:35.109247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:35.112756Z",
     "iopub.status.busy": "2025-05-08T17:15:35.112756Z",
     "iopub.status.idle": "2025-05-08T17:15:35.120257Z",
     "shell.execute_reply": "2025-05-08T17:15:35.119754Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:15:35.123261Z",
     "iopub.status.busy": "2025-05-08T17:15:35.122261Z",
     "iopub.status.idle": "2025-05-08T17:19:03.518956Z",
     "shell.execute_reply": "2025-05-08T17:19:03.518956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/1852], Loss: 0.1564, PSNR: 2.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0860, PSNR: 8.5431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0501, PSNR: 7.5439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0245, PSNR: 12.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0153, PSNR: 13.7428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0121, PSNR: 15.5839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0087, PSNR: 15.6896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0079, PSNR: 17.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0087, PSNR: 17.1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0062, PSNR: 17.5813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.0322, PSNR: 13.7457\n",
      "\t[Val]   Batch [1/463] Loss: 0.0053, PSNR: 18.0097\n",
      "\t[Val]   Batch [10/463] Loss: 0.0049, PSNR: 19.1650\n",
      "\t[Val]   Batch [20/463] Loss: 0.0049, PSNR: 18.1806\n",
      "\t[Val]   Batch [30/463] Loss: 0.0060, PSNR: 18.7351\n",
      "\t[Val]   Batch [40/463] Loss: 0.0047, PSNR: 17.8778\n",
      "\t[Val]   Batch [50/463] Loss: 0.0050, PSNR: 18.0825\n",
      "\t[Val]   Batch [60/463] Loss: 0.0047, PSNR: 18.1289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0067, PSNR: 18.4639\n",
      "\t[Val]   Batch [80/463] Loss: 0.0059, PSNR: 20.3823\n",
      "\t[Val]   Batch [90/463] Loss: 0.0057, PSNR: 19.4723\n",
      "\t[Val]   Batch [100/463] Loss: 0.0058, PSNR: 19.1823\n",
      "\t[Val]   Batch [110/463] Loss: 0.0068, PSNR: 18.5848\n",
      "\t[Val]   Batch [120/463] Loss: 0.0046, PSNR: 18.1179\n",
      "\t[Val]   Batch [130/463] Loss: 0.0054, PSNR: 19.4932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0063, PSNR: 19.0529\n",
      "\t[Val]   Batch [150/463] Loss: 0.0072, PSNR: 19.0738\n",
      "\t[Val]   Batch [160/463] Loss: 0.0057, PSNR: 19.3458\n",
      "\t[Val]   Batch [170/463] Loss: 0.0074, PSNR: 18.2803\n",
      "\t[Val]   Batch [180/463] Loss: 0.0054, PSNR: 19.0733\n",
      "\t[Val]   Batch [190/463] Loss: 0.0059, PSNR: 19.4009\n",
      "\t[Val]   Batch [200/463] Loss: 0.0058, PSNR: 18.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0057, PSNR: 18.3877\n",
      "\t[Val]   Batch [220/463] Loss: 0.0056, PSNR: 19.6173\n",
      "\t[Val]   Batch [230/463] Loss: 0.0066, PSNR: 19.4349\n",
      "\t[Val]   Batch [240/463] Loss: 0.0050, PSNR: 18.2515\n",
      "\t[Val]   Batch [250/463] Loss: 0.0064, PSNR: 17.4252\n",
      "\t[Val]   Batch [260/463] Loss: 0.0056, PSNR: 18.4406\n",
      "\t[Val]   Batch [270/463] Loss: 0.0043, PSNR: 17.6409\n",
      "\t[Val]   Batch [280/463] Loss: 0.0053, PSNR: 20.3260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0058, PSNR: 17.3338\n",
      "\t[Val]   Batch [300/463] Loss: 0.0059, PSNR: 19.5784\n",
      "\t[Val]   Batch [310/463] Loss: 0.0054, PSNR: 19.4836\n",
      "\t[Val]   Batch [320/463] Loss: 0.0055, PSNR: 19.3422\n",
      "\t[Val]   Batch [330/463] Loss: 0.0064, PSNR: 18.7339\n",
      "\t[Val]   Batch [340/463] Loss: 0.0052, PSNR: 19.6787\n",
      "\t[Val]   Batch [350/463] Loss: 0.0069, PSNR: 19.5789\n",
      "\t[Val]   Batch [360/463] Loss: 0.0046, PSNR: 20.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0068, PSNR: 18.6651\n",
      "\t[Val]   Batch [380/463] Loss: 0.0066, PSNR: 18.8092\n",
      "\t[Val]   Batch [390/463] Loss: 0.0061, PSNR: 18.6346\n",
      "\t[Val]   Batch [400/463] Loss: 0.0054, PSNR: 17.6882\n",
      "\t[Val]   Batch [410/463] Loss: 0.0052, PSNR: 20.0120\n",
      "\t[Val]   Batch [420/463] Loss: 0.0054, PSNR: 18.7981\n",
      "\t[Val]   Batch [430/463] Loss: 0.0053, PSNR: 18.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0052, PSNR: 19.2073\n",
      "\t[Val]   Batch [450/463] Loss: 0.0040, PSNR: 16.6026\n",
      "\t[Val]   Batch [460/463] Loss: 0.0057, PSNR: 17.9495\n",
      "Epoch [1/50] Validation Loss: 0.0056, PSNR: 18.7741\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0072, PSNR: 18.6999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0059, PSNR: 18.9381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0042, PSNR: 18.7282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0047, PSNR: 19.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0045, PSNR: 20.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0038, PSNR: 22.0458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0033, PSNR: 21.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0038, PSNR: 20.8914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0037, PSNR: 21.4580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0031, PSNR: 21.4927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.0043, PSNR: 20.0867\n",
      "\t[Val]   Batch [1/463] Loss: 0.0026, PSNR: 21.1274\n",
      "\t[Val]   Batch [10/463] Loss: 0.0024, PSNR: 22.3581\n",
      "\t[Val]   Batch [20/463] Loss: 0.0023, PSNR: 21.4572\n",
      "\t[Val]   Batch [30/463] Loss: 0.0030, PSNR: 21.7144\n",
      "\t[Val]   Batch [40/463] Loss: 0.0023, PSNR: 21.0295\n",
      "\t[Val]   Batch [50/463] Loss: 0.0024, PSNR: 21.2083\n",
      "\t[Val]   Batch [60/463] Loss: 0.0023, PSNR: 21.3008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0035, PSNR: 21.3190\n",
      "\t[Val]   Batch [80/463] Loss: 0.0031, PSNR: 23.2253\n",
      "\t[Val]   Batch [90/463] Loss: 0.0028, PSNR: 22.5560\n",
      "\t[Val]   Batch [100/463] Loss: 0.0031, PSNR: 21.9645\n",
      "\t[Val]   Batch [110/463] Loss: 0.0035, PSNR: 21.4768\n",
      "\t[Val]   Batch [120/463] Loss: 0.0022, PSNR: 21.2888\n",
      "\t[Val]   Batch [130/463] Loss: 0.0026, PSNR: 22.6222\n",
      "\t[Val]   Batch [140/463] Loss: 0.0032, PSNR: 21.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0036, PSNR: 22.0412\n",
      "\t[Val]   Batch [160/463] Loss: 0.0030, PSNR: 22.1258\n",
      "\t[Val]   Batch [170/463] Loss: 0.0039, PSNR: 21.0758\n",
      "\t[Val]   Batch [180/463] Loss: 0.0029, PSNR: 21.7918\n",
      "\t[Val]   Batch [190/463] Loss: 0.0029, PSNR: 22.4698\n",
      "\t[Val]   Batch [200/463] Loss: 0.0030, PSNR: 21.7562\n",
      "\t[Val]   Batch [210/463] Loss: 0.0030, PSNR: 21.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0029, PSNR: 22.4820\n",
      "\t[Val]   Batch [230/463] Loss: 0.0033, PSNR: 22.4672\n",
      "\t[Val]   Batch [240/463] Loss: 0.0025, PSNR: 21.3194\n",
      "\t[Val]   Batch [250/463] Loss: 0.0033, PSNR: 20.3133\n",
      "\t[Val]   Batch [260/463] Loss: 0.0029, PSNR: 21.3788\n",
      "\t[Val]   Batch [270/463] Loss: 0.0020, PSNR: 20.9604\n",
      "\t[Val]   Batch [280/463] Loss: 0.0026, PSNR: 23.3801\n",
      "\t[Val]   Batch [290/463] Loss: 0.0029, PSNR: 20.4265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0030, PSNR: 22.5549\n",
      "\t[Val]   Batch [310/463] Loss: 0.0029, PSNR: 22.2446\n",
      "\t[Val]   Batch [320/463] Loss: 0.0028, PSNR: 22.2894\n",
      "\t[Val]   Batch [330/463] Loss: 0.0031, PSNR: 21.8343\n",
      "\t[Val]   Batch [340/463] Loss: 0.0026, PSNR: 22.6799\n",
      "\t[Val]   Batch [350/463] Loss: 0.0037, PSNR: 22.2482\n",
      "\t[Val]   Batch [360/463] Loss: 0.0024, PSNR: 23.3324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0034, PSNR: 21.6957\n",
      "\t[Val]   Batch [380/463] Loss: 0.0032, PSNR: 21.9828\n",
      "\t[Val]   Batch [390/463] Loss: 0.0030, PSNR: 21.7641\n",
      "\t[Val]   Batch [400/463] Loss: 0.0027, PSNR: 20.6133\n",
      "\t[Val]   Batch [410/463] Loss: 0.0025, PSNR: 23.1951\n",
      "\t[Val]   Batch [420/463] Loss: 0.0026, PSNR: 21.9192\n",
      "\t[Val]   Batch [430/463] Loss: 0.0027, PSNR: 21.1229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0027, PSNR: 22.1141\n",
      "\t[Val]   Batch [450/463] Loss: 0.0020, PSNR: 19.7239\n",
      "\t[Val]   Batch [460/463] Loss: 0.0028, PSNR: 21.0719\n",
      "Epoch [2/50] Validation Loss: 0.0028, PSNR: 21.7946\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0029, PSNR: 21.7614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0033, PSNR: 22.0818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0030, PSNR: 20.9772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0028, PSNR: 22.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0024, PSNR: 23.1672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0020, PSNR: 24.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0022, PSNR: 22.7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0020, PSNR: 22.5280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0018, PSNR: 24.4858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0022, PSNR: 22.4133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.0023, PSNR: 22.7403\n",
      "\t[Val]   Batch [1/463] Loss: 0.0015, PSNR: 23.3362\n",
      "\t[Val]   Batch [10/463] Loss: 0.0014, PSNR: 24.5011\n",
      "\t[Val]   Batch [20/463] Loss: 0.0014, PSNR: 23.6818\n",
      "\t[Val]   Batch [30/463] Loss: 0.0017, PSNR: 24.2691\n",
      "\t[Val]   Batch [40/463] Loss: 0.0015, PSNR: 22.8918\n",
      "\t[Val]   Batch [50/463] Loss: 0.0015, PSNR: 23.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [60/463] Loss: 0.0014, PSNR: 23.2445\n",
      "\t[Val]   Batch [70/463] Loss: 0.0019, PSNR: 23.8410\n",
      "\t[Val]   Batch [80/463] Loss: 0.0017, PSNR: 25.7374\n",
      "\t[Val]   Batch [90/463] Loss: 0.0017, PSNR: 24.8178\n",
      "\t[Val]   Batch [100/463] Loss: 0.0018, PSNR: 24.3655\n",
      "\t[Val]   Batch [110/463] Loss: 0.0019, PSNR: 24.0229\n",
      "\t[Val]   Batch [120/463] Loss: 0.0014, PSNR: 23.1414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [130/463] Loss: 0.0015, PSNR: 25.1139\n",
      "\t[Val]   Batch [140/463] Loss: 0.0018, PSNR: 24.4129\n",
      "\t[Val]   Batch [150/463] Loss: 0.0019, PSNR: 24.8339\n",
      "\t[Val]   Batch [160/463] Loss: 0.0019, PSNR: 24.0914\n",
      "\t[Val]   Batch [170/463] Loss: 0.0023, PSNR: 23.4096\n",
      "\t[Val]   Batch [180/463] Loss: 0.0018, PSNR: 23.9378\n",
      "\t[Val]   Batch [190/463] Loss: 0.0017, PSNR: 24.8659\n",
      "\t[Val]   Batch [200/463] Loss: 0.0017, PSNR: 24.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0019, PSNR: 23.1206\n",
      "\t[Val]   Batch [220/463] Loss: 0.0018, PSNR: 24.5841\n",
      "\t[Val]   Batch [230/463] Loss: 0.0017, PSNR: 25.4433\n",
      "\t[Val]   Batch [240/463] Loss: 0.0015, PSNR: 23.5319\n",
      "\t[Val]   Batch [250/463] Loss: 0.0020, PSNR: 22.4351\n",
      "\t[Val]   Batch [260/463] Loss: 0.0018, PSNR: 23.4624\n",
      "\t[Val]   Batch [270/463] Loss: 0.0013, PSNR: 22.8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0016, PSNR: 25.5452\n",
      "\t[Val]   Batch [290/463] Loss: 0.0017, PSNR: 22.7077\n",
      "\t[Val]   Batch [300/463] Loss: 0.0018, PSNR: 24.6510\n",
      "\t[Val]   Batch [310/463] Loss: 0.0019, PSNR: 24.0757\n",
      "\t[Val]   Batch [320/463] Loss: 0.0016, PSNR: 24.5549\n",
      "\t[Val]   Batch [330/463] Loss: 0.0017, PSNR: 24.4011\n",
      "\t[Val]   Batch [340/463] Loss: 0.0016, PSNR: 24.8719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [350/463] Loss: 0.0022, PSNR: 24.5863\n",
      "\t[Val]   Batch [360/463] Loss: 0.0017, PSNR: 24.7417\n",
      "\t[Val]   Batch [370/463] Loss: 0.0019, PSNR: 24.2690\n",
      "\t[Val]   Batch [380/463] Loss: 0.0017, PSNR: 24.8080\n",
      "\t[Val]   Batch [390/463] Loss: 0.0016, PSNR: 24.4189\n",
      "\t[Val]   Batch [400/463] Loss: 0.0017, PSNR: 22.5690\n",
      "\t[Val]   Batch [410/463] Loss: 0.0015, PSNR: 25.3961\n",
      "\t[Val]   Batch [420/463] Loss: 0.0016, PSNR: 24.2124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0018, PSNR: 22.9967\n",
      "\t[Val]   Batch [440/463] Loss: 0.0017, PSNR: 24.1565\n",
      "\t[Val]   Batch [450/463] Loss: 0.0014, PSNR: 21.2763\n",
      "\t[Val]   Batch [460/463] Loss: 0.0017, PSNR: 23.2689\n",
      "Epoch [3/50] Validation Loss: 0.0017, PSNR: 24.0533\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0017, PSNR: 23.5586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0019, PSNR: 22.9984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0018, PSNR: 23.6489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0016, PSNR: 24.7010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0015, PSNR: 23.8576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0018, PSNR: 23.4751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0016, PSNR: 24.5055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0014, PSNR: 24.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0012, PSNR: 25.1433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0016, PSNR: 25.6569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.0016, PSNR: 24.4980\n",
      "\t[Val]   Batch [1/463] Loss: 0.0011, PSNR: 24.9253\n",
      "\t[Val]   Batch [10/463] Loss: 0.0010, PSNR: 26.2240\n",
      "\t[Val]   Batch [20/463] Loss: 0.0009, PSNR: 25.4442\n",
      "\t[Val]   Batch [30/463] Loss: 0.0011, PSNR: 26.0168\n",
      "\t[Val]   Batch [40/463] Loss: 0.0010, PSNR: 24.4031\n",
      "\t[Val]   Batch [50/463] Loss: 0.0011, PSNR: 24.8067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [60/463] Loss: 0.0010, PSNR: 24.8039\n",
      "\t[Val]   Batch [70/463] Loss: 0.0013, PSNR: 25.5926\n",
      "\t[Val]   Batch [80/463] Loss: 0.0011, PSNR: 27.7469\n",
      "\t[Val]   Batch [90/463] Loss: 0.0011, PSNR: 26.5913\n",
      "\t[Val]   Batch [100/463] Loss: 0.0012, PSNR: 26.0950\n",
      "\t[Val]   Batch [110/463] Loss: 0.0013, PSNR: 25.8920\n",
      "\t[Val]   Batch [120/463] Loss: 0.0010, PSNR: 24.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [130/463] Loss: 0.0010, PSNR: 26.8987\n",
      "\t[Val]   Batch [140/463] Loss: 0.0012, PSNR: 26.1688\n",
      "\t[Val]   Batch [150/463] Loss: 0.0012, PSNR: 26.8431\n",
      "\t[Val]   Batch [160/463] Loss: 0.0014, PSNR: 25.6168\n",
      "\t[Val]   Batch [170/463] Loss: 0.0016, PSNR: 25.0066\n",
      "\t[Val]   Batch [180/463] Loss: 0.0012, PSNR: 25.5440\n",
      "\t[Val]   Batch [190/463] Loss: 0.0011, PSNR: 26.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [200/463] Loss: 0.0011, PSNR: 26.1763\n",
      "\t[Val]   Batch [210/463] Loss: 0.0013, PSNR: 24.6507\n",
      "\t[Val]   Batch [220/463] Loss: 0.0012, PSNR: 26.1532\n",
      "\t[Val]   Batch [230/463] Loss: 0.0010, PSNR: 27.5320\n",
      "\t[Val]   Batch [240/463] Loss: 0.0010, PSNR: 25.2364\n",
      "\t[Val]   Batch [250/463] Loss: 0.0014, PSNR: 24.0257\n",
      "\t[Val]   Batch [260/463] Loss: 0.0013, PSNR: 24.9579\n",
      "\t[Val]   Batch [270/463] Loss: 0.0009, PSNR: 24.4980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0011, PSNR: 27.1996\n",
      "\t[Val]   Batch [290/463] Loss: 0.0011, PSNR: 24.4317\n",
      "\t[Val]   Batch [300/463] Loss: 0.0013, PSNR: 26.1621\n",
      "\t[Val]   Batch [310/463] Loss: 0.0013, PSNR: 25.6162\n",
      "\t[Val]   Batch [320/463] Loss: 0.0011, PSNR: 26.3112\n",
      "\t[Val]   Batch [330/463] Loss: 0.0011, PSNR: 26.3424\n",
      "\t[Val]   Batch [340/463] Loss: 0.0011, PSNR: 26.5761\n",
      "\t[Val]   Batch [350/463] Loss: 0.0015, PSNR: 26.2923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0013, PSNR: 25.8761\n",
      "\t[Val]   Batch [370/463] Loss: 0.0012, PSNR: 26.1180\n",
      "\t[Val]   Batch [380/463] Loss: 0.0010, PSNR: 26.9183\n",
      "\t[Val]   Batch [390/463] Loss: 0.0010, PSNR: 26.3934\n",
      "\t[Val]   Batch [400/463] Loss: 0.0012, PSNR: 24.0600\n",
      "\t[Val]   Batch [410/463] Loss: 0.0010, PSNR: 27.1635\n",
      "\t[Val]   Batch [420/463] Loss: 0.0010, PSNR: 25.9371\n",
      "\t[Val]   Batch [430/463] Loss: 0.0013, PSNR: 24.4103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0012, PSNR: 25.7236\n",
      "\t[Val]   Batch [450/463] Loss: 0.0010, PSNR: 22.7448\n",
      "\t[Val]   Batch [460/463] Loss: 0.0011, PSNR: 24.9229\n",
      "Epoch [4/50] Validation Loss: 0.0011, PSNR: 25.7764\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0013, PSNR: 25.6091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0010, PSNR: 25.4177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0018, PSNR: 24.3808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0011, PSNR: 25.5917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0011, PSNR: 26.8894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0011, PSNR: 24.4158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0013, PSNR: 26.2210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0011, PSNR: 25.2404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0011, PSNR: 26.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0010, PSNR: 26.5828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.0012, PSNR: 25.5904\n",
      "\t[Val]   Batch [1/463] Loss: 0.0008, PSNR: 26.0218\n",
      "\t[Val]   Batch [10/463] Loss: 0.0007, PSNR: 27.4353\n",
      "\t[Val]   Batch [20/463] Loss: 0.0007, PSNR: 26.6451\n",
      "\t[Val]   Batch [30/463] Loss: 0.0009, PSNR: 27.0638\n",
      "\t[Val]   Batch [40/463] Loss: 0.0008, PSNR: 25.4753\n",
      "\t[Val]   Batch [50/463] Loss: 0.0008, PSNR: 26.0468\n",
      "\t[Val]   Batch [60/463] Loss: 0.0008, PSNR: 25.8806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0010, PSNR: 26.6712\n",
      "\t[Val]   Batch [80/463] Loss: 0.0008, PSNR: 29.1251\n",
      "\t[Val]   Batch [90/463] Loss: 0.0008, PSNR: 27.7815\n",
      "\t[Val]   Batch [100/463] Loss: 0.0009, PSNR: 27.2924\n",
      "\t[Val]   Batch [110/463] Loss: 0.0009, PSNR: 27.1384\n",
      "\t[Val]   Batch [120/463] Loss: 0.0007, PSNR: 25.9850\n",
      "\t[Val]   Batch [130/463] Loss: 0.0007, PSNR: 28.0831\n",
      "\t[Val]   Batch [140/463] Loss: 0.0009, PSNR: 27.3075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0009, PSNR: 28.0700\n",
      "\t[Val]   Batch [160/463] Loss: 0.0011, PSNR: 26.6630\n",
      "\t[Val]   Batch [170/463] Loss: 0.0013, PSNR: 25.9903\n",
      "\t[Val]   Batch [180/463] Loss: 0.0009, PSNR: 26.6930\n",
      "\t[Val]   Batch [190/463] Loss: 0.0008, PSNR: 27.7972\n",
      "\t[Val]   Batch [200/463] Loss: 0.0008, PSNR: 27.5033\n",
      "\t[Val]   Batch [210/463] Loss: 0.0010, PSNR: 25.7221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0010, PSNR: 27.2240\n",
      "\t[Val]   Batch [230/463] Loss: 0.0008, PSNR: 28.7757\n",
      "\t[Val]   Batch [240/463] Loss: 0.0008, PSNR: 26.4551\n",
      "\t[Val]   Batch [250/463] Loss: 0.0011, PSNR: 25.0804\n",
      "\t[Val]   Batch [260/463] Loss: 0.0010, PSNR: 25.9844\n",
      "\t[Val]   Batch [270/463] Loss: 0.0006, PSNR: 25.8417\n",
      "\t[Val]   Batch [280/463] Loss: 0.0008, PSNR: 28.3879\n",
      "\t[Val]   Batch [290/463] Loss: 0.0009, PSNR: 25.5711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0010, PSNR: 27.1411\n",
      "\t[Val]   Batch [310/463] Loss: 0.0010, PSNR: 26.7942\n",
      "\t[Val]   Batch [320/463] Loss: 0.0008, PSNR: 27.5519\n",
      "\t[Val]   Batch [330/463] Loss: 0.0008, PSNR: 27.4983\n",
      "\t[Val]   Batch [340/463] Loss: 0.0008, PSNR: 27.7797\n",
      "\t[Val]   Batch [350/463] Loss: 0.0011, PSNR: 27.3651\n",
      "\t[Val]   Batch [360/463] Loss: 0.0011, PSNR: 26.7925\n",
      "\t[Val]   Batch [370/463] Loss: 0.0009, PSNR: 27.2386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [380/463] Loss: 0.0008, PSNR: 28.1917\n",
      "\t[Val]   Batch [390/463] Loss: 0.0008, PSNR: 27.6072\n",
      "\t[Val]   Batch [400/463] Loss: 0.0010, PSNR: 25.1412\n",
      "\t[Val]   Batch [410/463] Loss: 0.0008, PSNR: 28.3302\n",
      "\t[Val]   Batch [420/463] Loss: 0.0008, PSNR: 27.0682\n",
      "\t[Val]   Batch [430/463] Loss: 0.0010, PSNR: 25.4592\n",
      "\t[Val]   Batch [440/463] Loss: 0.0009, PSNR: 26.8288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [450/463] Loss: 0.0007, PSNR: 23.9491\n",
      "\t[Val]   Batch [460/463] Loss: 0.0009, PSNR: 25.9799\n",
      "Epoch [5/50] Validation Loss: 0.0009, PSNR: 26.9520\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0009, PSNR: 25.5541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0011, PSNR: 27.5990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0009, PSNR: 26.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0009, PSNR: 26.5966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0009, PSNR: 25.8343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0011, PSNR: 26.7964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0009, PSNR: 26.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0008, PSNR: 27.6081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0011, PSNR: 25.4798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0009, PSNR: 26.3735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.0010, PSNR: 26.3978\n",
      "\t[Val]   Batch [1/463] Loss: 0.0007, PSNR: 26.7797\n",
      "\t[Val]   Batch [10/463] Loss: 0.0006, PSNR: 28.2485\n",
      "\t[Val]   Batch [20/463] Loss: 0.0006, PSNR: 27.4711\n",
      "\t[Val]   Batch [30/463] Loss: 0.0007, PSNR: 27.8387\n",
      "\t[Val]   Batch [40/463] Loss: 0.0007, PSNR: 26.2608\n",
      "\t[Val]   Batch [50/463] Loss: 0.0006, PSNR: 26.9153\n",
      "\t[Val]   Batch [60/463] Loss: 0.0007, PSNR: 26.6746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0008, PSNR: 27.4665\n",
      "\t[Val]   Batch [80/463] Loss: 0.0006, PSNR: 30.0897\n",
      "\t[Val]   Batch [90/463] Loss: 0.0007, PSNR: 28.6213\n",
      "\t[Val]   Batch [100/463] Loss: 0.0007, PSNR: 28.1024\n",
      "\t[Val]   Batch [110/463] Loss: 0.0008, PSNR: 27.9917\n",
      "\t[Val]   Batch [120/463] Loss: 0.0006, PSNR: 26.8188\n",
      "\t[Val]   Batch [130/463] Loss: 0.0006, PSNR: 28.8671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0008, PSNR: 28.1547\n",
      "\t[Val]   Batch [150/463] Loss: 0.0007, PSNR: 28.9135\n",
      "\t[Val]   Batch [160/463] Loss: 0.0009, PSNR: 27.4257\n",
      "\t[Val]   Batch [170/463] Loss: 0.0010, PSNR: 26.7773\n",
      "\t[Val]   Batch [180/463] Loss: 0.0008, PSNR: 27.5027\n",
      "\t[Val]   Batch [190/463] Loss: 0.0007, PSNR: 28.5732\n",
      "\t[Val]   Batch [200/463] Loss: 0.0006, PSNR: 28.4025\n",
      "\t[Val]   Batch [210/463] Loss: 0.0009, PSNR: 26.5316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0008, PSNR: 27.9830\n",
      "\t[Val]   Batch [230/463] Loss: 0.0006, PSNR: 29.6626\n",
      "\t[Val]   Batch [240/463] Loss: 0.0006, PSNR: 27.3040\n",
      "\t[Val]   Batch [250/463] Loss: 0.0009, PSNR: 25.8880\n",
      "\t[Val]   Batch [260/463] Loss: 0.0008, PSNR: 26.7249\n",
      "\t[Val]   Batch [270/463] Loss: 0.0005, PSNR: 26.7964\n",
      "\t[Val]   Batch [280/463] Loss: 0.0007, PSNR: 29.2054\n",
      "\t[Val]   Batch [290/463] Loss: 0.0007, PSNR: 26.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0009, PSNR: 27.8489\n",
      "\t[Val]   Batch [310/463] Loss: 0.0008, PSNR: 27.6027\n",
      "\t[Val]   Batch [320/463] Loss: 0.0007, PSNR: 28.5069\n",
      "\t[Val]   Batch [330/463] Loss: 0.0007, PSNR: 28.3360\n",
      "\t[Val]   Batch [340/463] Loss: 0.0007, PSNR: 28.6461\n",
      "\t[Val]   Batch [350/463] Loss: 0.0010, PSNR: 28.1576\n",
      "\t[Val]   Batch [360/463] Loss: 0.0010, PSNR: 27.3551\n",
      "\t[Val]   Batch [370/463] Loss: 0.0008, PSNR: 28.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [380/463] Loss: 0.0006, PSNR: 29.1168\n",
      "\t[Val]   Batch [390/463] Loss: 0.0006, PSNR: 28.4765\n",
      "\t[Val]   Batch [400/463] Loss: 0.0008, PSNR: 25.8626\n",
      "\t[Val]   Batch [410/463] Loss: 0.0006, PSNR: 29.1350\n",
      "\t[Val]   Batch [420/463] Loss: 0.0007, PSNR: 27.8823\n",
      "\t[Val]   Batch [430/463] Loss: 0.0008, PSNR: 26.2158\n",
      "\t[Val]   Batch [440/463] Loss: 0.0008, PSNR: 27.6169\n",
      "\t[Val]   Batch [450/463] Loss: 0.0006, PSNR: 24.7830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [460/463] Loss: 0.0007, PSNR: 26.8018\n",
      "Epoch [6/50] Validation Loss: 0.0007, PSNR: 27.7843\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0012, PSNR: 25.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0010, PSNR: 27.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0008, PSNR: 27.2231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0008, PSNR: 27.7187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0010, PSNR: 25.5821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0009, PSNR: 28.4048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0011, PSNR: 26.3794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0009, PSNR: 27.0804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0008, PSNR: 28.5248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0008, PSNR: 26.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0009, PSNR: 27.0432\n",
      "\t[Val]   Batch [1/463] Loss: 0.0006, PSNR: 27.5122\n",
      "\t[Val]   Batch [10/463] Loss: 0.0005, PSNR: 29.0200\n",
      "\t[Val]   Batch [20/463] Loss: 0.0005, PSNR: 28.2566\n",
      "\t[Val]   Batch [30/463] Loss: 0.0006, PSNR: 28.5846\n",
      "\t[Val]   Batch [40/463] Loss: 0.0006, PSNR: 26.9787\n",
      "\t[Val]   Batch [50/463] Loss: 0.0005, PSNR: 27.7869\n",
      "\t[Val]   Batch [60/463] Loss: 0.0006, PSNR: 27.4033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0007, PSNR: 28.2478\n",
      "\t[Val]   Batch [80/463] Loss: 0.0005, PSNR: 30.9612\n",
      "\t[Val]   Batch [90/463] Loss: 0.0006, PSNR: 29.3872\n",
      "\t[Val]   Batch [100/463] Loss: 0.0006, PSNR: 28.9380\n",
      "\t[Val]   Batch [110/463] Loss: 0.0006, PSNR: 28.8551\n",
      "\t[Val]   Batch [120/463] Loss: 0.0005, PSNR: 27.5994\n",
      "\t[Val]   Batch [130/463] Loss: 0.0005, PSNR: 29.6315\n",
      "\t[Val]   Batch [140/463] Loss: 0.0007, PSNR: 28.9023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0006, PSNR: 29.7988\n",
      "\t[Val]   Batch [160/463] Loss: 0.0008, PSNR: 28.1871\n",
      "\t[Val]   Batch [170/463] Loss: 0.0009, PSNR: 27.5159\n",
      "\t[Val]   Batch [180/463] Loss: 0.0006, PSNR: 28.3214\n",
      "\t[Val]   Batch [190/463] Loss: 0.0006, PSNR: 29.3197\n",
      "\t[Val]   Batch [200/463] Loss: 0.0005, PSNR: 29.2222\n",
      "\t[Val]   Batch [210/463] Loss: 0.0007, PSNR: 27.3354\n",
      "\t[Val]   Batch [220/463] Loss: 0.0007, PSNR: 28.7346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [230/463] Loss: 0.0005, PSNR: 30.4449\n",
      "\t[Val]   Batch [240/463] Loss: 0.0005, PSNR: 28.0637\n",
      "\t[Val]   Batch [250/463] Loss: 0.0008, PSNR: 26.6557\n",
      "\t[Val]   Batch [260/463] Loss: 0.0007, PSNR: 27.5261\n",
      "\t[Val]   Batch [270/463] Loss: 0.0004, PSNR: 27.6853\n",
      "\t[Val]   Batch [280/463] Loss: 0.0006, PSNR: 30.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0006, PSNR: 27.1797\n",
      "\t[Val]   Batch [300/463] Loss: 0.0008, PSNR: 28.5060\n",
      "\t[Val]   Batch [310/463] Loss: 0.0007, PSNR: 28.3948\n",
      "\t[Val]   Batch [320/463] Loss: 0.0005, PSNR: 29.3573\n",
      "\t[Val]   Batch [330/463] Loss: 0.0006, PSNR: 29.1311\n",
      "\t[Val]   Batch [340/463] Loss: 0.0006, PSNR: 29.4542\n",
      "\t[Val]   Batch [350/463] Loss: 0.0008, PSNR: 28.9018\n",
      "\t[Val]   Batch [360/463] Loss: 0.0008, PSNR: 27.9068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0006, PSNR: 28.9217\n",
      "\t[Val]   Batch [380/463] Loss: 0.0005, PSNR: 29.9821\n",
      "\t[Val]   Batch [390/463] Loss: 0.0005, PSNR: 29.2862\n",
      "\t[Val]   Batch [400/463] Loss: 0.0007, PSNR: 26.6093\n",
      "\t[Val]   Batch [410/463] Loss: 0.0005, PSNR: 29.8859\n",
      "\t[Val]   Batch [420/463] Loss: 0.0006, PSNR: 28.6474\n",
      "\t[Val]   Batch [430/463] Loss: 0.0007, PSNR: 26.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0006, PSNR: 28.3215\n",
      "\t[Val]   Batch [450/463] Loss: 0.0005, PSNR: 25.6003\n",
      "\t[Val]   Batch [460/463] Loss: 0.0006, PSNR: 27.5678\n",
      "Epoch [7/50] Validation Loss: 0.0006, PSNR: 28.5817\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0007, PSNR: 28.7345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0007, PSNR: 29.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0008, PSNR: 26.5985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0006, PSNR: 26.6089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0007, PSNR: 28.2145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0007, PSNR: 26.3363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0007, PSNR: 27.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0008, PSNR: 27.0532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0007, PSNR: 26.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0008, PSNR: 28.1502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0008, PSNR: 27.5809\n",
      "\t[Val]   Batch [1/463] Loss: 0.0005, PSNR: 28.1264\n",
      "\t[Val]   Batch [10/463] Loss: 0.0004, PSNR: 29.7715\n",
      "\t[Val]   Batch [20/463] Loss: 0.0004, PSNR: 28.9962\n",
      "\t[Val]   Batch [30/463] Loss: 0.0005, PSNR: 29.3153\n",
      "\t[Val]   Batch [40/463] Loss: 0.0005, PSNR: 27.6329\n",
      "\t[Val]   Batch [50/463] Loss: 0.0005, PSNR: 28.4885\n",
      "\t[Val]   Batch [60/463] Loss: 0.0005, PSNR: 27.9447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0006, PSNR: 28.9967\n",
      "\t[Val]   Batch [80/463] Loss: 0.0004, PSNR: 31.7639\n",
      "\t[Val]   Batch [90/463] Loss: 0.0005, PSNR: 30.1739\n",
      "\t[Val]   Batch [100/463] Loss: 0.0005, PSNR: 29.6272\n",
      "\t[Val]   Batch [110/463] Loss: 0.0005, PSNR: 29.6139\n",
      "\t[Val]   Batch [120/463] Loss: 0.0004, PSNR: 28.2103\n",
      "\t[Val]   Batch [130/463] Loss: 0.0004, PSNR: 30.3165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0006, PSNR: 29.5960\n",
      "\t[Val]   Batch [150/463] Loss: 0.0005, PSNR: 30.6618\n",
      "\t[Val]   Batch [160/463] Loss: 0.0006, PSNR: 28.9238\n",
      "\t[Val]   Batch [170/463] Loss: 0.0007, PSNR: 28.2424\n",
      "\t[Val]   Batch [180/463] Loss: 0.0005, PSNR: 29.0573\n",
      "\t[Val]   Batch [190/463] Loss: 0.0005, PSNR: 30.0046\n",
      "\t[Val]   Batch [200/463] Loss: 0.0004, PSNR: 29.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0006, PSNR: 28.0990\n",
      "\t[Val]   Batch [220/463] Loss: 0.0006, PSNR: 29.3566\n",
      "\t[Val]   Batch [230/463] Loss: 0.0004, PSNR: 31.2287\n",
      "\t[Val]   Batch [240/463] Loss: 0.0004, PSNR: 28.7903\n",
      "\t[Val]   Batch [250/463] Loss: 0.0007, PSNR: 27.3747\n",
      "\t[Val]   Batch [260/463] Loss: 0.0006, PSNR: 28.2433\n",
      "\t[Val]   Batch [270/463] Loss: 0.0004, PSNR: 28.4159\n",
      "\t[Val]   Batch [280/463] Loss: 0.0005, PSNR: 30.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0005, PSNR: 27.9574\n",
      "\t[Val]   Batch [300/463] Loss: 0.0006, PSNR: 29.2790\n",
      "\t[Val]   Batch [310/463] Loss: 0.0006, PSNR: 29.0913\n",
      "\t[Val]   Batch [320/463] Loss: 0.0005, PSNR: 30.0858\n",
      "\t[Val]   Batch [330/463] Loss: 0.0005, PSNR: 29.9001\n",
      "\t[Val]   Batch [340/463] Loss: 0.0005, PSNR: 30.1520\n",
      "\t[Val]   Batch [350/463] Loss: 0.0007, PSNR: 29.6828\n",
      "\t[Val]   Batch [360/463] Loss: 0.0008, PSNR: 28.2919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0005, PSNR: 29.6983\n",
      "\t[Val]   Batch [380/463] Loss: 0.0004, PSNR: 30.8138\n",
      "\t[Val]   Batch [390/463] Loss: 0.0004, PSNR: 30.0593\n",
      "\t[Val]   Batch [400/463] Loss: 0.0006, PSNR: 27.2311\n",
      "\t[Val]   Batch [410/463] Loss: 0.0005, PSNR: 30.5419\n",
      "\t[Val]   Batch [420/463] Loss: 0.0005, PSNR: 29.3617\n",
      "\t[Val]   Batch [430/463] Loss: 0.0006, PSNR: 27.6475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0006, PSNR: 28.8728\n",
      "\t[Val]   Batch [450/463] Loss: 0.0004, PSNR: 26.2166\n",
      "\t[Val]   Batch [460/463] Loss: 0.0005, PSNR: 28.3013\n",
      "Epoch [8/50] Validation Loss: 0.0005, PSNR: 29.2963\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0006, PSNR: 26.4238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0007, PSNR: 27.8417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0006, PSNR: 28.3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0007, PSNR: 26.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0009, PSNR: 28.1037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0009, PSNR: 27.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0008, PSNR: 31.1986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0006, PSNR: 28.2753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0007, PSNR: 26.7450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0006, PSNR: 26.3405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0007, PSNR: 28.0705\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 28.7526\n",
      "\t[Val]   Batch [10/463] Loss: 0.0004, PSNR: 30.3846\n",
      "\t[Val]   Batch [20/463] Loss: 0.0004, PSNR: 29.6660\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 29.9538\n",
      "\t[Val]   Batch [40/463] Loss: 0.0004, PSNR: 28.1859\n",
      "\t[Val]   Batch [50/463] Loss: 0.0004, PSNR: 29.1956\n",
      "\t[Val]   Batch [60/463] Loss: 0.0004, PSNR: 28.5898\n",
      "\t[Val]   Batch [70/463] Loss: 0.0005, PSNR: 29.6992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [80/463] Loss: 0.0004, PSNR: 32.4986\n",
      "\t[Val]   Batch [90/463] Loss: 0.0004, PSNR: 30.8240\n",
      "\t[Val]   Batch [100/463] Loss: 0.0004, PSNR: 30.3095\n",
      "\t[Val]   Batch [110/463] Loss: 0.0005, PSNR: 30.3013\n",
      "\t[Val]   Batch [120/463] Loss: 0.0004, PSNR: 28.8223\n",
      "\t[Val]   Batch [130/463] Loss: 0.0004, PSNR: 30.9693\n",
      "\t[Val]   Batch [140/463] Loss: 0.0005, PSNR: 30.2177\n",
      "\t[Val]   Batch [150/463] Loss: 0.0004, PSNR: 31.4209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [160/463] Loss: 0.0005, PSNR: 29.5728\n",
      "\t[Val]   Batch [170/463] Loss: 0.0006, PSNR: 28.9116\n",
      "\t[Val]   Batch [180/463] Loss: 0.0005, PSNR: 29.7139\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 30.5464\n",
      "\t[Val]   Batch [200/463] Loss: 0.0004, PSNR: 30.6293\n",
      "\t[Val]   Batch [210/463] Loss: 0.0005, PSNR: 28.7799\n",
      "\t[Val]   Batch [220/463] Loss: 0.0005, PSNR: 29.9048\n",
      "\t[Val]   Batch [230/463] Loss: 0.0004, PSNR: 31.8976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [240/463] Loss: 0.0004, PSNR: 29.4329\n",
      "\t[Val]   Batch [250/463] Loss: 0.0006, PSNR: 28.0169\n",
      "\t[Val]   Batch [260/463] Loss: 0.0005, PSNR: 28.9593\n",
      "\t[Val]   Batch [270/463] Loss: 0.0003, PSNR: 29.0604\n",
      "\t[Val]   Batch [280/463] Loss: 0.0004, PSNR: 31.2899\n",
      "\t[Val]   Batch [290/463] Loss: 0.0004, PSNR: 28.6826\n",
      "\t[Val]   Batch [300/463] Loss: 0.0006, PSNR: 29.7794\n",
      "\t[Val]   Batch [310/463] Loss: 0.0005, PSNR: 29.6841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [320/463] Loss: 0.0004, PSNR: 30.7756\n",
      "\t[Val]   Batch [330/463] Loss: 0.0004, PSNR: 30.5862\n",
      "\t[Val]   Batch [340/463] Loss: 0.0004, PSNR: 30.7816\n",
      "\t[Val]   Batch [350/463] Loss: 0.0006, PSNR: 30.3448\n",
      "\t[Val]   Batch [360/463] Loss: 0.0007, PSNR: 28.7343\n",
      "\t[Val]   Batch [370/463] Loss: 0.0005, PSNR: 30.3572\n",
      "\t[Val]   Batch [380/463] Loss: 0.0004, PSNR: 31.5853\n",
      "\t[Val]   Batch [390/463] Loss: 0.0004, PSNR: 30.7146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [400/463] Loss: 0.0005, PSNR: 27.7809\n",
      "\t[Val]   Batch [410/463] Loss: 0.0004, PSNR: 31.1602\n",
      "\t[Val]   Batch [420/463] Loss: 0.0004, PSNR: 30.0157\n",
      "\t[Val]   Batch [430/463] Loss: 0.0005, PSNR: 28.2671\n",
      "\t[Val]   Batch [440/463] Loss: 0.0005, PSNR: 29.4725\n",
      "\t[Val]   Batch [450/463] Loss: 0.0004, PSNR: 26.8454\n",
      "\t[Val]   Batch [460/463] Loss: 0.0004, PSNR: 28.9811\n",
      "Epoch [9/50] Validation Loss: 0.0004, PSNR: 29.9578\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0006, PSNR: 27.4558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0005, PSNR: 28.1367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0010, PSNR: 27.6735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0005, PSNR: 28.5609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0006, PSNR: 28.9946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0006, PSNR: 28.5226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0005, PSNR: 30.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0006, PSNR: 28.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0006, PSNR: 29.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0006, PSNR: 28.4761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0006, PSNR: 28.5235\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 29.1202\n",
      "\t[Val]   Batch [10/463] Loss: 0.0003, PSNR: 30.8306\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 30.0914\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 30.3569\n",
      "\t[Val]   Batch [40/463] Loss: 0.0004, PSNR: 28.6060\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 29.7155\n",
      "\t[Val]   Batch [60/463] Loss: 0.0004, PSNR: 29.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0005, PSNR: 30.1651\n",
      "\t[Val]   Batch [80/463] Loss: 0.0003, PSNR: 32.9345\n",
      "\t[Val]   Batch [90/463] Loss: 0.0004, PSNR: 31.2441\n",
      "\t[Val]   Batch [100/463] Loss: 0.0004, PSNR: 30.7797\n",
      "\t[Val]   Batch [110/463] Loss: 0.0004, PSNR: 30.7374\n",
      "\t[Val]   Batch [120/463] Loss: 0.0004, PSNR: 29.2284\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 31.3855\n",
      "\t[Val]   Batch [140/463] Loss: 0.0004, PSNR: 30.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0004, PSNR: 31.9260\n",
      "\t[Val]   Batch [160/463] Loss: 0.0005, PSNR: 30.0891\n",
      "\t[Val]   Batch [170/463] Loss: 0.0006, PSNR: 29.3732\n",
      "\t[Val]   Batch [180/463] Loss: 0.0004, PSNR: 30.1708\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 30.9774\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 31.0837\n",
      "\t[Val]   Batch [210/463] Loss: 0.0005, PSNR: 29.2936\n",
      "\t[Val]   Batch [220/463] Loss: 0.0005, PSNR: 30.3069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 32.2756\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 29.9078\n",
      "\t[Val]   Batch [250/463] Loss: 0.0005, PSNR: 28.5117\n",
      "\t[Val]   Batch [260/463] Loss: 0.0004, PSNR: 29.5139\n",
      "\t[Val]   Batch [270/463] Loss: 0.0003, PSNR: 29.5021\n",
      "\t[Val]   Batch [280/463] Loss: 0.0004, PSNR: 31.7034\n",
      "\t[Val]   Batch [290/463] Loss: 0.0004, PSNR: 29.1525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0005, PSNR: 30.1063\n",
      "\t[Val]   Batch [310/463] Loss: 0.0005, PSNR: 30.1400\n",
      "\t[Val]   Batch [320/463] Loss: 0.0004, PSNR: 31.2568\n",
      "\t[Val]   Batch [330/463] Loss: 0.0004, PSNR: 31.0371\n",
      "\t[Val]   Batch [340/463] Loss: 0.0004, PSNR: 31.2415\n",
      "\t[Val]   Batch [350/463] Loss: 0.0005, PSNR: 30.7980\n",
      "\t[Val]   Batch [360/463] Loss: 0.0007, PSNR: 28.9899\n",
      "\t[Val]   Batch [370/463] Loss: 0.0004, PSNR: 30.8072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [380/463] Loss: 0.0003, PSNR: 32.0249\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 31.1227\n",
      "\t[Val]   Batch [400/463] Loss: 0.0005, PSNR: 28.1875\n",
      "\t[Val]   Batch [410/463] Loss: 0.0004, PSNR: 31.5689\n",
      "\t[Val]   Batch [420/463] Loss: 0.0004, PSNR: 30.4543\n",
      "\t[Val]   Batch [430/463] Loss: 0.0005, PSNR: 28.6894\n",
      "\t[Val]   Batch [440/463] Loss: 0.0005, PSNR: 29.8593\n",
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 27.2636\n",
      "\t[Val]   Batch [460/463] Loss: 0.0004, PSNR: 29.4668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Validation Loss: 0.0004, PSNR: 30.3979\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0008, PSNR: 28.8263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0007, PSNR: 27.3271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0007, PSNR: 26.1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0007, PSNR: 27.9748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0006, PSNR: 28.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0005, PSNR: 27.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0006, PSNR: 28.2758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0007, PSNR: 27.1098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0004, PSNR: 29.3286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0006, PSNR: 29.5091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0006, PSNR: 28.8833\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 29.5255\n",
      "\t[Val]   Batch [10/463] Loss: 0.0003, PSNR: 31.2772\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 30.4900\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 30.7759\n",
      "\t[Val]   Batch [40/463] Loss: 0.0004, PSNR: 29.0121\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 30.1703\n",
      "\t[Val]   Batch [60/463] Loss: 0.0003, PSNR: 29.4794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0004, PSNR: 30.6691\n",
      "\t[Val]   Batch [80/463] Loss: 0.0003, PSNR: 33.3775\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 31.6549\n",
      "\t[Val]   Batch [100/463] Loss: 0.0004, PSNR: 31.2363\n",
      "\t[Val]   Batch [110/463] Loss: 0.0004, PSNR: 31.2164\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 29.6221\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 31.7963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0004, PSNR: 31.0492\n",
      "\t[Val]   Batch [150/463] Loss: 0.0003, PSNR: 32.3878\n",
      "\t[Val]   Batch [160/463] Loss: 0.0004, PSNR: 30.5957\n",
      "\t[Val]   Batch [170/463] Loss: 0.0005, PSNR: 29.8116\n",
      "\t[Val]   Batch [180/463] Loss: 0.0004, PSNR: 30.5824\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 31.3752\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 31.5423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0004, PSNR: 29.8107\n",
      "\t[Val]   Batch [220/463] Loss: 0.0004, PSNR: 30.6789\n",
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 32.7039\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 30.3373\n",
      "\t[Val]   Batch [250/463] Loss: 0.0004, PSNR: 28.9912\n",
      "\t[Val]   Batch [260/463] Loss: 0.0004, PSNR: 30.0399\n",
      "\t[Val]   Batch [270/463] Loss: 0.0003, PSNR: 29.9471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 32.1146\n",
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 29.6153\n",
      "\t[Val]   Batch [300/463] Loss: 0.0005, PSNR: 30.5752\n",
      "\t[Val]   Batch [310/463] Loss: 0.0004, PSNR: 30.5618\n",
      "\t[Val]   Batch [320/463] Loss: 0.0003, PSNR: 31.7061\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 31.4398\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 31.6996\n",
      "\t[Val]   Batch [350/463] Loss: 0.0005, PSNR: 31.2574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0006, PSNR: 29.2519\n",
      "\t[Val]   Batch [370/463] Loss: 0.0004, PSNR: 31.2223\n",
      "\t[Val]   Batch [380/463] Loss: 0.0003, PSNR: 32.5011\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 31.5445\n",
      "\t[Val]   Batch [400/463] Loss: 0.0004, PSNR: 28.5865\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 31.9483\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 30.8513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0004, PSNR: 29.1068\n",
      "\t[Val]   Batch [440/463] Loss: 0.0004, PSNR: 30.2584\n",
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 27.7310\n",
      "\t[Val]   Batch [460/463] Loss: 0.0004, PSNR: 29.9482\n",
      "Epoch [11/50] Validation Loss: 0.0004, PSNR: 30.8403\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0005, PSNR: 28.7974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0006, PSNR: 29.0948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0005, PSNR: 29.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0006, PSNR: 28.0791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0005, PSNR: 30.3233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0005, PSNR: 27.5446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0004, PSNR: 28.6660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0005, PSNR: 28.5501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0004, PSNR: 30.5287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0005, PSNR: 29.1346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0005, PSNR: 29.1575\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 29.6953\n",
      "\t[Val]   Batch [10/463] Loss: 0.0003, PSNR: 31.5316\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 30.7436\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 30.9471\n",
      "\t[Val]   Batch [40/463] Loss: 0.0003, PSNR: 29.2633\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 30.4294\n",
      "\t[Val]   Batch [60/463] Loss: 0.0003, PSNR: 29.7386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0004, PSNR: 30.9644\n",
      "\t[Val]   Batch [80/463] Loss: 0.0003, PSNR: 33.6538\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 31.9076\n",
      "\t[Val]   Batch [100/463] Loss: 0.0003, PSNR: 31.4685\n",
      "\t[Val]   Batch [110/463] Loss: 0.0003, PSNR: 31.4612\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 29.8329\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 32.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0004, PSNR: 31.2269\n",
      "\t[Val]   Batch [150/463] Loss: 0.0003, PSNR: 32.6966\n",
      "\t[Val]   Batch [160/463] Loss: 0.0004, PSNR: 30.9619\n",
      "\t[Val]   Batch [170/463] Loss: 0.0005, PSNR: 30.0352\n",
      "\t[Val]   Batch [180/463] Loss: 0.0004, PSNR: 30.8640\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 31.6008\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 31.8438\n",
      "\t[Val]   Batch [210/463] Loss: 0.0004, PSNR: 30.1272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0004, PSNR: 30.9310\n",
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 32.8688\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 30.5629\n",
      "\t[Val]   Batch [250/463] Loss: 0.0004, PSNR: 29.2237\n",
      "\t[Val]   Batch [260/463] Loss: 0.0004, PSNR: 30.3476\n",
      "\t[Val]   Batch [270/463] Loss: 0.0002, PSNR: 30.2200\n",
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 32.3524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 29.8050\n",
      "\t[Val]   Batch [300/463] Loss: 0.0005, PSNR: 30.6836\n",
      "\t[Val]   Batch [310/463] Loss: 0.0004, PSNR: 30.8870\n",
      "\t[Val]   Batch [320/463] Loss: 0.0003, PSNR: 31.9571\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 31.6623\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 31.9209\n",
      "\t[Val]   Batch [350/463] Loss: 0.0004, PSNR: 31.5542\n",
      "\t[Val]   Batch [360/463] Loss: 0.0006, PSNR: 29.4368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0004, PSNR: 31.4156\n",
      "\t[Val]   Batch [380/463] Loss: 0.0003, PSNR: 32.6687\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 31.7164\n",
      "\t[Val]   Batch [400/463] Loss: 0.0004, PSNR: 28.8118\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 32.1124\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 31.0592\n",
      "\t[Val]   Batch [430/463] Loss: 0.0004, PSNR: 29.3530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0004, PSNR: 30.4613\n",
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 28.0226\n",
      "\t[Val]   Batch [460/463] Loss: 0.0003, PSNR: 30.2007\n",
      "Epoch [12/50] Validation Loss: 0.0003, PSNR: 31.0744\n",
      "Early stopping triggered at epoch 12. No improvement for 3 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:03.521969Z",
     "iopub.status.busy": "2025-05-08T17:19:03.521969Z",
     "iopub.status.idle": "2025-05-08T17:19:06.913597Z",
     "shell.execute_reply": "2025-05-08T17:19:06.913597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 101/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 201/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 301/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 401/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 501/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:06.916602Z",
     "iopub.status.busy": "2025-05-08T17:19:06.916602Z",
     "iopub.status.idle": "2025-05-08T17:19:06.921781Z",
     "shell.execute_reply": "2025-05-08T17:19:06.921781Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:06.924792Z",
     "iopub.status.busy": "2025-05-08T17:19:06.923791Z",
     "iopub.status.idle": "2025-05-08T17:19:14.981353Z",
     "shell.execute_reply": "2025-05-08T17:19:14.981353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n",
      "Epoch [1/1000] completed, Average Training Loss: 2.2094\n",
      "    Validation Batch [1/1], Loss: 2.2024\n",
      "Validation Loss: 2.2024, Validation Accuracy: 11.11%\n",
      "Validation loss improved from inf to 2.2024. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.1474\n",
      "    Validation Batch [1/1], Loss: 2.2024\n",
      "Validation Loss: 2.2024, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.1191\n",
      "    Validation Batch [1/1], Loss: 2.2024\n",
      "Validation Loss: 2.2024, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.1005\n",
      "    Validation Batch [1/1], Loss: 2.2025\n",
      "Validation Loss: 2.2025, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.0717\n",
      "    Validation Batch [1/1], Loss: 2.2026\n",
      "Validation Loss: 2.2026, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.0655\n",
      "    Validation Batch [1/1], Loss: 2.2027\n",
      "Validation Loss: 2.2027, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.0455\n",
      "    Validation Batch [1/1], Loss: 2.2028\n",
      "Validation Loss: 2.2028, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.2027\n",
      "Validation Loss: 2.2027, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.0005\n",
      "    Validation Batch [1/1], Loss: 2.2027\n",
      "Validation Loss: 2.2027, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 1.9990\n",
      "    Validation Batch [1/1], Loss: 2.2029\n",
      "Validation Loss: 2.2029, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 1.9904\n",
      "    Validation Batch [1/1], Loss: 2.2030\n",
      "Validation Loss: 2.2030, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 1.9649\n",
      "    Validation Batch [1/1], Loss: 2.2030\n",
      "Validation Loss: 2.2030, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 1.9476\n",
      "    Validation Batch [1/1], Loss: 2.2031\n",
      "Validation Loss: 2.2031, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 1.9429\n",
      "    Validation Batch [1/1], Loss: 2.2031\n",
      "Validation Loss: 2.2031, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 1.9297\n",
      "    Validation Batch [1/1], Loss: 2.2031\n",
      "Validation Loss: 2.2031, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n",
      "Epoch [16/1000] completed, Average Training Loss: 1.9277\n",
      "    Validation Batch [1/1], Loss: 2.2030\n",
      "Validation Loss: 2.2030, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 1.9001\n",
      "    Validation Batch [1/1], Loss: 2.2028\n",
      "Validation Loss: 2.2028, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 1.8733\n",
      "    Validation Batch [1/1], Loss: 2.2026\n",
      "Validation Loss: 2.2026, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 1.8528\n",
      "    Validation Batch [1/1], Loss: 2.2025\n",
      "Validation Loss: 2.2025, Validation Accuracy: 11.11%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 1.8550\n",
      "    Validation Batch [1/1], Loss: 2.2023\n",
      "Validation Loss: 2.2023, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2024 to 2.2023. Saving model...\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 1.8439\n",
      "    Validation Batch [1/1], Loss: 2.2018\n",
      "Validation Loss: 2.2018, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2023 to 2.2018. Saving model...\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 1.8329\n",
      "    Validation Batch [1/1], Loss: 2.2012\n",
      "Validation Loss: 2.2012, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2018 to 2.2012. Saving model...\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 1.8188\n",
      "    Validation Batch [1/1], Loss: 2.2004\n",
      "Validation Loss: 2.2004, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2012 to 2.2004. Saving model...\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 1.8068\n",
      "    Validation Batch [1/1], Loss: 2.1991\n",
      "Validation Loss: 2.1991, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2004 to 2.1991. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 1.7950\n",
      "    Validation Batch [1/1], Loss: 2.1973\n",
      "Validation Loss: 2.1973, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1991 to 2.1973. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 1.7722\n",
      "    Validation Batch [1/1], Loss: 2.1954\n",
      "Validation Loss: 2.1954, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1973 to 2.1954. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 1.7660\n",
      "    Validation Batch [1/1], Loss: 2.1927\n",
      "Validation Loss: 2.1927, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1954 to 2.1927. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 1.7430\n",
      "    Validation Batch [1/1], Loss: 2.1899\n",
      "Validation Loss: 2.1899, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1927 to 2.1899. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 1.7687\n",
      "    Validation Batch [1/1], Loss: 2.1863\n",
      "Validation Loss: 2.1863, Validation Accuracy: 15.56%\n",
      "Validation loss improved from 2.1899 to 2.1863. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 1.7307\n",
      "    Validation Batch [1/1], Loss: 2.1818\n",
      "Validation Loss: 2.1818, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.1863 to 2.1818. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 1.7515\n",
      "    Validation Batch [1/1], Loss: 2.1761\n",
      "Validation Loss: 2.1761, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.1818 to 2.1761. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 1.7254\n",
      "    Validation Batch [1/1], Loss: 2.1692\n",
      "Validation Loss: 2.1692, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.1761 to 2.1692. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 1.7157\n",
      "    Validation Batch [1/1], Loss: 2.1608\n",
      "Validation Loss: 2.1608, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.1692 to 2.1608. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 1.7023\n",
      "    Validation Batch [1/1], Loss: 2.1509\n",
      "Validation Loss: 2.1509, Validation Accuracy: 22.22%\n",
      "Validation loss improved from 2.1608 to 2.1509. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 1.6973\n",
      "    Validation Batch [1/1], Loss: 2.1387\n",
      "Validation Loss: 2.1387, Validation Accuracy: 22.22%\n",
      "Validation loss improved from 2.1509 to 2.1387. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 1.6732\n",
      "    Validation Batch [1/1], Loss: 2.1253\n",
      "Validation Loss: 2.1253, Validation Accuracy: 22.22%\n",
      "Validation loss improved from 2.1387 to 2.1253. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/1000] completed, Average Training Loss: 1.6695\n",
      "    Validation Batch [1/1], Loss: 2.1106\n",
      "Validation Loss: 2.1106, Validation Accuracy: 26.67%\n",
      "Validation loss improved from 2.1253 to 2.1106. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 1.6375\n",
      "    Validation Batch [1/1], Loss: 2.0946\n",
      "Validation Loss: 2.0946, Validation Accuracy: 26.67%\n",
      "Validation loss improved from 2.1106 to 2.0946. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n",
      "Epoch [39/1000] completed, Average Training Loss: 1.6372\n",
      "    Validation Batch [1/1], Loss: 2.0786\n",
      "Validation Loss: 2.0786, Validation Accuracy: 28.89%\n",
      "Validation loss improved from 2.0946 to 2.0786. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 1.6194\n",
      "    Validation Batch [1/1], Loss: 2.0616\n",
      "Validation Loss: 2.0616, Validation Accuracy: 28.89%\n",
      "Validation loss improved from 2.0786 to 2.0616. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 1.6208\n",
      "    Validation Batch [1/1], Loss: 2.0427\n",
      "Validation Loss: 2.0427, Validation Accuracy: 31.11%\n",
      "Validation loss improved from 2.0616 to 2.0427. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 1.6073\n",
      "    Validation Batch [1/1], Loss: 2.0225\n",
      "Validation Loss: 2.0225, Validation Accuracy: 31.11%\n",
      "Validation loss improved from 2.0427 to 2.0225. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 1.5946\n",
      "    Validation Batch [1/1], Loss: 2.0017\n",
      "Validation Loss: 2.0017, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.0225 to 2.0017. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 1.5862\n",
      "    Validation Batch [1/1], Loss: 1.9830\n",
      "Validation Loss: 1.9830, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.0017 to 1.9830. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 1.5744\n",
      "    Validation Batch [1/1], Loss: 1.9622\n",
      "Validation Loss: 1.9622, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 1.9830 to 1.9622. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 1.5532\n",
      "    Validation Batch [1/1], Loss: 1.9363\n",
      "Validation Loss: 1.9363, Validation Accuracy: 44.44%\n",
      "Validation loss improved from 1.9622 to 1.9363. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 1.5599\n",
      "    Validation Batch [1/1], Loss: 1.9068\n",
      "Validation Loss: 1.9068, Validation Accuracy: 46.67%\n",
      "Validation loss improved from 1.9363 to 1.9068. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 1.5288\n",
      "    Validation Batch [1/1], Loss: 1.8828\n",
      "Validation Loss: 1.8828, Validation Accuracy: 48.89%\n",
      "Validation loss improved from 1.9068 to 1.8828. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 1.5585\n",
      "    Validation Batch [1/1], Loss: 1.8635\n",
      "Validation Loss: 1.8635, Validation Accuracy: 48.89%\n",
      "Validation loss improved from 1.8828 to 1.8635. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 1.5000\n",
      "    Validation Batch [1/1], Loss: 1.8438\n",
      "Validation Loss: 1.8438, Validation Accuracy: 51.11%\n",
      "Validation loss improved from 1.8635 to 1.8438. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 1.5185\n",
      "    Validation Batch [1/1], Loss: 1.8187\n",
      "Validation Loss: 1.8187, Validation Accuracy: 53.33%\n",
      "Validation loss improved from 1.8438 to 1.8187. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 1.5078\n",
      "    Validation Batch [1/1], Loss: 1.7921\n",
      "Validation Loss: 1.7921, Validation Accuracy: 55.56%\n",
      "Validation loss improved from 1.8187 to 1.7921. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 1.4986\n",
      "    Validation Batch [1/1], Loss: 1.7710\n",
      "Validation Loss: 1.7710, Validation Accuracy: 57.78%\n",
      "Validation loss improved from 1.7921 to 1.7710. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 1.4823\n",
      "    Validation Batch [1/1], Loss: 1.7440\n",
      "Validation Loss: 1.7440, Validation Accuracy: 57.78%\n",
      "Validation loss improved from 1.7710 to 1.7440. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 1.4806\n",
      "    Validation Batch [1/1], Loss: 1.7104\n",
      "Validation Loss: 1.7104, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.7440 to 1.7104. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 1.4737\n",
      "    Validation Batch [1/1], Loss: 1.6866\n",
      "Validation Loss: 1.6866, Validation Accuracy: 64.44%\n",
      "Validation loss improved from 1.7104 to 1.6866. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 1.4598\n",
      "    Validation Batch [1/1], Loss: 1.6771\n",
      "Validation Loss: 1.6771, Validation Accuracy: 62.22%\n",
      "Validation loss improved from 1.6866 to 1.6771. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.4600\n",
      "    Validation Batch [1/1], Loss: 1.6629\n",
      "Validation Loss: 1.6629, Validation Accuracy: 66.67%\n",
      "Validation loss improved from 1.6771 to 1.6629. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.4349\n",
      "    Validation Batch [1/1], Loss: 1.6418\n",
      "Validation Loss: 1.6418, Validation Accuracy: 66.67%\n",
      "Validation loss improved from 1.6629 to 1.6418. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 1.4477\n",
      "    Validation Batch [1/1], Loss: 1.6124\n",
      "Validation Loss: 1.6124, Validation Accuracy: 73.33%\n",
      "Validation loss improved from 1.6418 to 1.6124. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 1.4131\n",
      "    Validation Batch [1/1], Loss: 1.5890\n",
      "Validation Loss: 1.5890, Validation Accuracy: 82.22%\n",
      "Validation loss improved from 1.6124 to 1.5890. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.4389\n",
      "    Validation Batch [1/1], Loss: 1.5779\n",
      "Validation Loss: 1.5779, Validation Accuracy: 84.44%\n",
      "Validation loss improved from 1.5890 to 1.5779. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.3932\n",
      "    Validation Batch [1/1], Loss: 1.5655\n",
      "Validation Loss: 1.5655, Validation Accuracy: 84.44%\n",
      "Validation loss improved from 1.5779 to 1.5655. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.4092\n",
      "    Validation Batch [1/1], Loss: 1.5452\n",
      "Validation Loss: 1.5452, Validation Accuracy: 84.44%\n",
      "Validation loss improved from 1.5655 to 1.5452. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.3887\n",
      "    Validation Batch [1/1], Loss: 1.5137\n",
      "Validation Loss: 1.5137, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.5452 to 1.5137. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.3706\n",
      "    Validation Batch [1/1], Loss: 1.4923\n",
      "Validation Loss: 1.4923, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.5137 to 1.4923. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/1000] completed, Average Training Loss: 1.3883\n",
      "    Validation Batch [1/1], Loss: 1.4822\n",
      "Validation Loss: 1.4822, Validation Accuracy: 86.67%\n",
      "Validation loss improved from 1.4923 to 1.4822. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.3807\n",
      "    Validation Batch [1/1], Loss: 1.4700\n",
      "Validation Loss: 1.4700, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.4822 to 1.4700. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.3603\n",
      "    Validation Batch [1/1], Loss: 1.4534\n",
      "Validation Loss: 1.4534, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.4700 to 1.4534. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.3520\n",
      "    Validation Batch [1/1], Loss: 1.4299\n",
      "Validation Loss: 1.4299, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.4534 to 1.4299. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.3596\n",
      "    Validation Batch [1/1], Loss: 1.4149\n",
      "Validation Loss: 1.4149, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.4299 to 1.4149. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.3421\n",
      "    Validation Batch [1/1], Loss: 1.4148\n",
      "Validation Loss: 1.4148, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.4149 to 1.4148. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.3414\n",
      "    Validation Batch [1/1], Loss: 1.4096\n",
      "Validation Loss: 1.4096, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.4148 to 1.4096. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.3025\n",
      "    Validation Batch [1/1], Loss: 1.3961\n",
      "Validation Loss: 1.3961, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.4096 to 1.3961. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.3006\n",
      "    Validation Batch [1/1], Loss: 1.3752\n",
      "Validation Loss: 1.3752, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.3961 to 1.3752. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.3293\n",
      "    Validation Batch [1/1], Loss: 1.3502\n",
      "Validation Loss: 1.3502, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3752 to 1.3502. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.3053\n",
      "    Validation Batch [1/1], Loss: 1.3472\n",
      "Validation Loss: 1.3472, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3502 to 1.3472. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.2792\n",
      "    Validation Batch [1/1], Loss: 1.3484\n",
      "Validation Loss: 1.3484, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.2768\n",
      "    Validation Batch [1/1], Loss: 1.3401\n",
      "Validation Loss: 1.3401, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.3472 to 1.3401. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.2677\n",
      "    Validation Batch [1/1], Loss: 1.3283\n",
      "Validation Loss: 1.3283, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.3401 to 1.3283. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.2792\n",
      "    Validation Batch [1/1], Loss: 1.3097\n",
      "Validation Loss: 1.3097, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.3283 to 1.3097. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.2648\n",
      "    Validation Batch [1/1], Loss: 1.3085\n",
      "Validation Loss: 1.3085, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3097 to 1.3085. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.2408\n",
      "    Validation Batch [1/1], Loss: 1.2970\n",
      "Validation Loss: 1.2970, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3085 to 1.2970. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.2640\n",
      "    Validation Batch [1/1], Loss: 1.2880\n",
      "Validation Loss: 1.2880, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2970 to 1.2880. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.2396\n",
      "    Validation Batch [1/1], Loss: 1.2796\n",
      "Validation Loss: 1.2796, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2880 to 1.2796. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.2287\n",
      "    Validation Batch [1/1], Loss: 1.2689\n",
      "Validation Loss: 1.2689, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.2796 to 1.2689. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.2036\n",
      "    Validation Batch [1/1], Loss: 1.2563\n",
      "Validation Loss: 1.2563, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2689 to 1.2563. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.2239\n",
      "    Validation Batch [1/1], Loss: 1.2471\n",
      "Validation Loss: 1.2471, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2563 to 1.2471. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.1835\n",
      "    Validation Batch [1/1], Loss: 1.2434\n",
      "Validation Loss: 1.2434, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2471 to 1.2434. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.1985\n",
      "    Validation Batch [1/1], Loss: 1.2410\n",
      "Validation Loss: 1.2410, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.2434 to 1.2410. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.2027\n",
      "    Validation Batch [1/1], Loss: 1.2321\n",
      "Validation Loss: 1.2321, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2410 to 1.2321. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n",
      "Epoch [92/1000] completed, Average Training Loss: 1.1800\n",
      "    Validation Batch [1/1], Loss: 1.2188\n",
      "Validation Loss: 1.2188, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2321 to 1.2188. Saving model...\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.1862\n",
      "    Validation Batch [1/1], Loss: 1.2146\n",
      "Validation Loss: 1.2146, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2188 to 1.2146. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.1780\n",
      "    Validation Batch [1/1], Loss: 1.2115\n",
      "Validation Loss: 1.2115, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2146 to 1.2115. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.1524\n",
      "    Validation Batch [1/1], Loss: 1.2011\n",
      "Validation Loss: 1.2011, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2115 to 1.2011. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.1851\n",
      "Validation Loss: 1.1851, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2011 to 1.1851. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.1449\n",
      "    Validation Batch [1/1], Loss: 1.1848\n",
      "Validation Loss: 1.1848, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1851 to 1.1848. Saving model...\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.1497\n",
      "    Validation Batch [1/1], Loss: 1.1853\n",
      "Validation Loss: 1.1853, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.1182\n",
      "    Validation Batch [1/1], Loss: 1.1774\n",
      "Validation Loss: 1.1774, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1848 to 1.1774. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.1242\n",
      "    Validation Batch [1/1], Loss: 1.1611\n",
      "Validation Loss: 1.1611, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1774 to 1.1611. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.1261\n",
      "    Validation Batch [1/1], Loss: 1.1402\n",
      "Validation Loss: 1.1402, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.1611 to 1.1402. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.1176\n",
      "    Validation Batch [1/1], Loss: 1.1338\n",
      "Validation Loss: 1.1338, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.1402 to 1.1338. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.1194\n",
      "    Validation Batch [1/1], Loss: 1.1453\n",
      "Validation Loss: 1.1453, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.0670\n",
      "    Validation Batch [1/1], Loss: 1.1450\n",
      "Validation Loss: 1.1450, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.0755\n",
      "    Validation Batch [1/1], Loss: 1.1342\n",
      "Validation Loss: 1.1342, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.0477\n",
      "    Validation Batch [1/1], Loss: 1.1225\n",
      "Validation Loss: 1.1225, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1338 to 1.1225. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.0551\n",
      "    Validation Batch [1/1], Loss: 1.1135\n",
      "Validation Loss: 1.1135, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1225 to 1.1135. Saving model...\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.0423\n",
      "    Validation Batch [1/1], Loss: 1.1137\n",
      "Validation Loss: 1.1137, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.0487\n",
      "    Validation Batch [1/1], Loss: 1.1111\n",
      "Validation Loss: 1.1111, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.1135 to 1.1111. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.0604\n",
      "    Validation Batch [1/1], Loss: 1.0912\n",
      "Validation Loss: 1.0912, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1111 to 1.0912. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 0.9973\n",
      "    Validation Batch [1/1], Loss: 1.0797\n",
      "Validation Loss: 1.0797, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0912 to 1.0797. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 1.0636\n",
      "    Validation Batch [1/1], Loss: 1.0693\n",
      "Validation Loss: 1.0693, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0797 to 1.0693. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.0212\n",
      "    Validation Batch [1/1], Loss: 1.0732\n",
      "Validation Loss: 1.0732, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 1.0073\n",
      "    Validation Batch [1/1], Loss: 1.0707\n",
      "Validation Loss: 1.0707, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.0148\n",
      "    Validation Batch [1/1], Loss: 1.0628\n",
      "Validation Loss: 1.0628, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.0693 to 1.0628. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 1.0057\n",
      "    Validation Batch [1/1], Loss: 1.0506\n",
      "Validation Loss: 1.0506, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0628 to 1.0506. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 0.9747\n",
      "    Validation Batch [1/1], Loss: 1.0486\n",
      "Validation Loss: 1.0486, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0506 to 1.0486. Saving model...\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 0.9913\n",
      "    Validation Batch [1/1], Loss: 1.0449\n",
      "Validation Loss: 1.0449, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.0486 to 1.0449. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 0.9993\n",
      "    Validation Batch [1/1], Loss: 1.0310\n",
      "Validation Loss: 1.0310, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0449 to 1.0310. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 0.9454\n",
      "    Validation Batch [1/1], Loss: 1.0273\n",
      "Validation Loss: 1.0273, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0310 to 1.0273. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 0.9761\n",
      "    Validation Batch [1/1], Loss: 1.0182\n",
      "Validation Loss: 1.0182, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0273 to 1.0182. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 0.9564\n",
      "    Validation Batch [1/1], Loss: 1.0098\n",
      "Validation Loss: 1.0098, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0182 to 1.0098. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 0.9662\n",
      "    Validation Batch [1/1], Loss: 1.0214\n",
      "Validation Loss: 1.0214, Validation Accuracy: 88.89%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 0.9202\n",
      "    Validation Batch [1/1], Loss: 1.0035\n",
      "Validation Loss: 1.0035, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0098 to 1.0035. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/1000] completed, Average Training Loss: 0.9658\n",
      "    Validation Batch [1/1], Loss: 0.9883\n",
      "Validation Loss: 0.9883, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0035 to 0.9883. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 0.9211\n",
      "    Validation Batch [1/1], Loss: 0.9760\n",
      "Validation Loss: 0.9760, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.9883 to 0.9760. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 0.9065\n",
      "    Validation Batch [1/1], Loss: 0.9710\n",
      "Validation Loss: 0.9710, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9760 to 0.9710. Saving model...\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 0.9083\n",
      "    Validation Batch [1/1], Loss: 0.9756\n",
      "Validation Loss: 0.9756, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 0.8963\n",
      "    Validation Batch [1/1], Loss: 0.9673\n",
      "Validation Loss: 0.9673, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.9710 to 0.9673. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 0.9131\n",
      "    Validation Batch [1/1], Loss: 0.9621\n",
      "Validation Loss: 0.9621, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.9673 to 0.9621. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 0.9257\n",
      "    Validation Batch [1/1], Loss: 0.9392\n",
      "Validation Loss: 0.9392, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9621 to 0.9392. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 0.8454\n",
      "    Validation Batch [1/1], Loss: 0.9411\n",
      "Validation Loss: 0.9411, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 0.8671\n",
      "    Validation Batch [1/1], Loss: 0.9450\n",
      "Validation Loss: 0.9450, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 0.8797\n",
      "    Validation Batch [1/1], Loss: 0.9488\n",
      "Validation Loss: 0.9488, Validation Accuracy: 88.89%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 0.8646\n",
      "    Validation Batch [1/1], Loss: 0.9181\n",
      "Validation Loss: 0.9181, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9392 to 0.9181. Saving model...\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 0.8522\n",
      "    Validation Batch [1/1], Loss: 0.9157\n",
      "Validation Loss: 0.9157, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.9181 to 0.9157. Saving model...\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 0.8251\n",
      "    Validation Batch [1/1], Loss: 0.9208\n",
      "Validation Loss: 0.9208, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 0.8500\n",
      "    Validation Batch [1/1], Loss: 0.9123\n",
      "Validation Loss: 0.9123, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 0.9157 to 0.9123. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 0.8114\n",
      "    Validation Batch [1/1], Loss: 0.8856\n",
      "Validation Loss: 0.8856, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.9123 to 0.8856. Saving model...\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 0.8167\n",
      "    Validation Batch [1/1], Loss: 0.8758\n",
      "Validation Loss: 0.8758, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.8856 to 0.8758. Saving model...\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 0.8165\n",
      "    Validation Batch [1/1], Loss: 0.8846\n",
      "Validation Loss: 0.8846, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 0.8065\n",
      "    Validation Batch [1/1], Loss: 0.8907\n",
      "Validation Loss: 0.8907, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 0.7977\n",
      "    Validation Batch [1/1], Loss: 0.8651\n",
      "Validation Loss: 0.8651, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.8758 to 0.8651. Saving model...\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 0.7911\n",
      "    Validation Batch [1/1], Loss: 0.8453\n",
      "Validation Loss: 0.8453, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.8651 to 0.8453. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 0.7718\n",
      "    Validation Batch [1/1], Loss: 0.8462\n",
      "Validation Loss: 0.8462, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 0.7785\n",
      "    Validation Batch [1/1], Loss: 0.8500\n",
      "Validation Loss: 0.8500, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 0.8165\n",
      "    Validation Batch [1/1], Loss: 0.8330\n",
      "Validation Loss: 0.8330, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.8453 to 0.8330. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 0.7694\n",
      "    Validation Batch [1/1], Loss: 0.8295\n",
      "Validation Loss: 0.8295, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.8330 to 0.8295. Saving model...\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 0.7521\n",
      "    Validation Batch [1/1], Loss: 0.8460\n",
      "Validation Loss: 0.8460, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 0.7436\n",
      "    Validation Batch [1/1], Loss: 0.8304\n",
      "Validation Loss: 0.8304, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 0.7691\n",
      "    Validation Batch [1/1], Loss: 0.8130\n",
      "Validation Loss: 0.8130, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.8295 to 0.8130. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 0.7687\n",
      "    Validation Batch [1/1], Loss: 0.8045\n",
      "Validation Loss: 0.8045, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8130 to 0.8045. Saving model...\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 0.7464\n",
      "    Validation Batch [1/1], Loss: 0.8103\n",
      "Validation Loss: 0.8103, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/1000] completed, Average Training Loss: 0.7220\n",
      "    Validation Batch [1/1], Loss: 0.8074\n",
      "Validation Loss: 0.8074, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 0.7251\n",
      "    Validation Batch [1/1], Loss: 0.8010\n",
      "Validation Loss: 0.8010, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.8045 to 0.8010. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 0.7022\n",
      "    Validation Batch [1/1], Loss: 0.7797\n",
      "Validation Loss: 0.7797, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8010 to 0.7797. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 0.7209\n",
      "    Validation Batch [1/1], Loss: 0.7696\n",
      "Validation Loss: 0.7696, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7797 to 0.7696. Saving model...\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 0.7336\n",
      "    Validation Batch [1/1], Loss: 0.7732\n",
      "Validation Loss: 0.7732, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 0.6798\n",
      "    Validation Batch [1/1], Loss: 0.7936\n",
      "Validation Loss: 0.7936, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 0.7295\n",
      "    Validation Batch [1/1], Loss: 0.7867\n",
      "Validation Loss: 0.7867, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 0.6720\n",
      "    Validation Batch [1/1], Loss: 0.7548\n",
      "Validation Loss: 0.7548, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7696 to 0.7548. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 0.6808\n",
      "    Validation Batch [1/1], Loss: 0.7445\n",
      "Validation Loss: 0.7445, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7548 to 0.7445. Saving model...\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 0.6947\n",
      "    Validation Batch [1/1], Loss: 0.7705\n",
      "Validation Loss: 0.7705, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 0.6827\n",
      "    Validation Batch [1/1], Loss: 0.7632\n",
      "Validation Loss: 0.7632, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 0.6666\n",
      "    Validation Batch [1/1], Loss: 0.7302\n",
      "Validation Loss: 0.7302, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7445 to 0.7302. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 0.6456\n",
      "    Validation Batch [1/1], Loss: 0.7267\n",
      "Validation Loss: 0.7267, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.7302 to 0.7267. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 0.6377\n",
      "    Validation Batch [1/1], Loss: 0.7350\n",
      "Validation Loss: 0.7350, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 0.6126\n",
      "    Validation Batch [1/1], Loss: 0.7379\n",
      "Validation Loss: 0.7379, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 0.6443\n",
      "    Validation Batch [1/1], Loss: 0.7103\n",
      "Validation Loss: 0.7103, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.7267 to 0.7103. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 0.6521\n",
      "    Validation Batch [1/1], Loss: 0.6938\n",
      "Validation Loss: 0.6938, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7103 to 0.6938. Saving model...\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 0.6062\n",
      "    Validation Batch [1/1], Loss: 0.7016\n",
      "Validation Loss: 0.7016, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 0.5961\n",
      "    Validation Batch [1/1], Loss: 0.7282\n",
      "Validation Loss: 0.7282, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 0.6141\n",
      "    Validation Batch [1/1], Loss: 0.7174\n",
      "Validation Loss: 0.7174, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 0.6230\n",
      "    Validation Batch [1/1], Loss: 0.6841\n",
      "Validation Loss: 0.6841, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6938 to 0.6841. Saving model...\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.6092\n",
      "    Validation Batch [1/1], Loss: 0.6714\n",
      "Validation Loss: 0.6714, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6841 to 0.6714. Saving model...\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 0.6111\n",
      "    Validation Batch [1/1], Loss: 0.6859\n",
      "Validation Loss: 0.6859, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 0.5807\n",
      "    Validation Batch [1/1], Loss: 0.6723\n",
      "Validation Loss: 0.6723, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.5936\n",
      "    Validation Batch [1/1], Loss: 0.6592\n",
      "Validation Loss: 0.6592, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6714 to 0.6592. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.5976\n",
      "    Validation Batch [1/1], Loss: 0.6614\n",
      "Validation Loss: 0.6614, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.5752\n",
      "    Validation Batch [1/1], Loss: 0.6616\n",
      "Validation Loss: 0.6616, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.5265\n",
      "    Validation Batch [1/1], Loss: 0.6609\n",
      "Validation Loss: 0.6609, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.5607\n",
      "    Validation Batch [1/1], Loss: 0.6523\n",
      "Validation Loss: 0.6523, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.6592 to 0.6523. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/1000] completed, Average Training Loss: 0.5573\n",
      "    Validation Batch [1/1], Loss: 0.6453\n",
      "Validation Loss: 0.6453, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6523 to 0.6453. Saving model...\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.5327\n",
      "    Validation Batch [1/1], Loss: 0.6299\n",
      "Validation Loss: 0.6299, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6453 to 0.6299. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.5472\n",
      "    Validation Batch [1/1], Loss: 0.6211\n",
      "Validation Loss: 0.6211, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6299 to 0.6211. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.5355\n",
      "    Validation Batch [1/1], Loss: 0.6206\n",
      "Validation Loss: 0.6206, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.6211 to 0.6206. Saving model...\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.5285\n",
      "    Validation Batch [1/1], Loss: 0.6282\n",
      "Validation Loss: 0.6282, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.5285\n",
      "    Validation Batch [1/1], Loss: 0.6223\n",
      "Validation Loss: 0.6223, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.5250\n",
      "    Validation Batch [1/1], Loss: 0.6104\n",
      "Validation Loss: 0.6104, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.6206 to 0.6104. Saving model...\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.5085\n",
      "    Validation Batch [1/1], Loss: 0.6021\n",
      "Validation Loss: 0.6021, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.6104 to 0.6021. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.5039\n",
      "    Validation Batch [1/1], Loss: 0.6035\n",
      "Validation Loss: 0.6035, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.4919\n",
      "    Validation Batch [1/1], Loss: 0.5970\n",
      "Validation Loss: 0.5970, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.6021 to 0.5970. Saving model...\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.5046\n",
      "    Validation Batch [1/1], Loss: 0.5752\n",
      "Validation Loss: 0.5752, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5970 to 0.5752. Saving model...\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.4787\n",
      "    Validation Batch [1/1], Loss: 0.5712\n",
      "Validation Loss: 0.5712, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5752 to 0.5712. Saving model...\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.5141\n",
      "    Validation Batch [1/1], Loss: 0.5858\n",
      "Validation Loss: 0.5858, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.4903\n",
      "    Validation Batch [1/1], Loss: 0.5961\n",
      "Validation Loss: 0.5961, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.4800\n",
      "    Validation Batch [1/1], Loss: 0.5763\n",
      "Validation Loss: 0.5763, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.4598\n",
      "    Validation Batch [1/1], Loss: 0.5640\n",
      "Validation Loss: 0.5640, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.5712 to 0.5640. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.4535\n",
      "    Validation Batch [1/1], Loss: 0.5622\n",
      "Validation Loss: 0.5622, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5640 to 0.5622. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.4618\n",
      "    Validation Batch [1/1], Loss: 0.5590\n",
      "Validation Loss: 0.5590, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.5622 to 0.5590. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.4296\n",
      "    Validation Batch [1/1], Loss: 0.5613\n",
      "Validation Loss: 0.5613, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.4663\n",
      "    Validation Batch [1/1], Loss: 0.5612\n",
      "Validation Loss: 0.5612, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.4346\n",
      "    Validation Batch [1/1], Loss: 0.5418\n",
      "Validation Loss: 0.5418, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5590 to 0.5418. Saving model...\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.4510\n",
      "    Validation Batch [1/1], Loss: 0.5271\n",
      "Validation Loss: 0.5271, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.5418 to 0.5271. Saving model...\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.4397\n",
      "    Validation Batch [1/1], Loss: 0.5407\n",
      "Validation Loss: 0.5407, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.4559\n",
      "    Validation Batch [1/1], Loss: 0.5452\n",
      "Validation Loss: 0.5452, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.4220\n",
      "    Validation Batch [1/1], Loss: 0.5168\n",
      "Validation Loss: 0.5168, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.5271 to 0.5168. Saving model...\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.4101\n",
      "    Validation Batch [1/1], Loss: 0.5175\n",
      "Validation Loss: 0.5175, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.4258\n",
      "    Validation Batch [1/1], Loss: 0.5377\n",
      "Validation Loss: 0.5377, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.4336\n",
      "    Validation Batch [1/1], Loss: 0.5410\n",
      "Validation Loss: 0.5410, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.3937\n",
      "    Validation Batch [1/1], Loss: 0.5280\n",
      "Validation Loss: 0.5280, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.4008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.5059\n",
      "Validation Loss: 0.5059, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.5168 to 0.5059. Saving model...\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.4269\n",
      "    Validation Batch [1/1], Loss: 0.5214\n",
      "Validation Loss: 0.5214, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.3733\n",
      "    Validation Batch [1/1], Loss: 0.5319\n",
      "Validation Loss: 0.5319, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.3991\n",
      "    Validation Batch [1/1], Loss: 0.5029\n",
      "Validation Loss: 0.5029, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.5059 to 0.5029. Saving model...\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.4246\n",
      "    Validation Batch [1/1], Loss: 0.4878\n",
      "Validation Loss: 0.4878, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.5029 to 0.4878. Saving model...\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.3863\n",
      "    Validation Batch [1/1], Loss: 0.5068\n",
      "Validation Loss: 0.5068, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.3881\n",
      "    Validation Batch [1/1], Loss: 0.5001\n",
      "Validation Loss: 0.5001, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.3822\n",
      "    Validation Batch [1/1], Loss: 0.4925\n",
      "Validation Loss: 0.4925, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.3707\n",
      "    Validation Batch [1/1], Loss: 0.4745\n",
      "Validation Loss: 0.4745, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.4878 to 0.4745. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.3671\n",
      "    Validation Batch [1/1], Loss: 0.4753\n",
      "Validation Loss: 0.4753, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.3752\n",
      "    Validation Batch [1/1], Loss: 0.4623\n",
      "Validation Loss: 0.4623, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.4745 to 0.4623. Saving model...\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.3576\n",
      "    Validation Batch [1/1], Loss: 0.4708\n",
      "Validation Loss: 0.4708, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.3509\n",
      "    Validation Batch [1/1], Loss: 0.4860\n",
      "Validation Loss: 0.4860, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n",
      "Epoch [225/1000] completed, Average Training Loss: 0.3678\n",
      "    Validation Batch [1/1], Loss: 0.4614\n",
      "Validation Loss: 0.4614, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.4623 to 0.4614. Saving model...\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.3491\n",
      "    Validation Batch [1/1], Loss: 0.4497\n",
      "Validation Loss: 0.4497, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.4614 to 0.4497. Saving model...\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.3781\n",
      "    Validation Batch [1/1], Loss: 0.4512\n",
      "Validation Loss: 0.4512, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.3365\n",
      "    Validation Batch [1/1], Loss: 0.4573\n",
      "Validation Loss: 0.4573, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.3520\n",
      "    Validation Batch [1/1], Loss: 0.4638\n",
      "Validation Loss: 0.4638, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.3570\n",
      "    Validation Batch [1/1], Loss: 0.4521\n",
      "Validation Loss: 0.4521, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.3511\n",
      "    Validation Batch [1/1], Loss: 0.4417\n",
      "Validation Loss: 0.4417, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.4497 to 0.4417. Saving model...\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.3461\n",
      "    Validation Batch [1/1], Loss: 0.4239\n",
      "Validation Loss: 0.4239, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.4417 to 0.4239. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.3423\n",
      "    Validation Batch [1/1], Loss: 0.4362\n",
      "Validation Loss: 0.4362, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.3113\n",
      "    Validation Batch [1/1], Loss: 0.4745\n",
      "Validation Loss: 0.4745, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.3173\n",
      "    Validation Batch [1/1], Loss: 0.4611\n",
      "Validation Loss: 0.4611, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.2976\n",
      "    Validation Batch [1/1], Loss: 0.4421\n",
      "Validation Loss: 0.4421, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.2997\n",
      "    Validation Batch [1/1], Loss: 0.4305\n",
      "Validation Loss: 0.4305, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.3212\n",
      "    Validation Batch [1/1], Loss: 0.4127\n",
      "Validation Loss: 0.4127, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.4239 to 0.4127. Saving model...\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.2968\n",
      "    Validation Batch [1/1], Loss: 0.4330\n",
      "Validation Loss: 0.4330, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.2735\n",
      "    Validation Batch [1/1], Loss: 0.4709\n",
      "Validation Loss: 0.4709, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.3108\n",
      "    Validation Batch [1/1], Loss: 0.4239\n",
      "Validation Loss: 0.4239, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.2992\n",
      "    Validation Batch [1/1], Loss: 0.3904\n",
      "Validation Loss: 0.3904, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.4127 to 0.3904. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [243/1000] completed, Average Training Loss: 0.2886\n",
      "    Validation Batch [1/1], Loss: 0.3962\n",
      "Validation Loss: 0.3962, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.2990\n",
      "    Validation Batch [1/1], Loss: 0.4574\n",
      "Validation Loss: 0.4574, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.2779\n",
      "    Validation Batch [1/1], Loss: 0.4313\n",
      "Validation Loss: 0.4313, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.3066\n",
      "    Validation Batch [1/1], Loss: 0.3828\n",
      "Validation Loss: 0.3828, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3904 to 0.3828. Saving model...\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.2799\n",
      "    Validation Batch [1/1], Loss: 0.3805\n",
      "Validation Loss: 0.3805, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3828 to 0.3805. Saving model...\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.3062\n",
      "    Validation Batch [1/1], Loss: 0.4117\n",
      "Validation Loss: 0.4117, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.2890\n",
      "    Validation Batch [1/1], Loss: 0.4066\n",
      "Validation Loss: 0.4066, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.2813\n",
      "    Validation Batch [1/1], Loss: 0.4114\n",
      "Validation Loss: 0.4114, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.2905\n",
      "    Validation Batch [1/1], Loss: 0.4224\n",
      "Validation Loss: 0.4224, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.2908\n",
      "    Validation Batch [1/1], Loss: 0.4028\n",
      "Validation Loss: 0.4028, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.2641\n",
      "    Validation Batch [1/1], Loss: 0.3653\n",
      "Validation Loss: 0.3653, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3805 to 0.3653. Saving model...\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.2504\n",
      "    Validation Batch [1/1], Loss: 0.3612\n",
      "Validation Loss: 0.3612, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3653 to 0.3612. Saving model...\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.2701\n",
      "    Validation Batch [1/1], Loss: 0.3893\n",
      "Validation Loss: 0.3893, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.2635\n",
      "    Validation Batch [1/1], Loss: 0.4369\n",
      "Validation Loss: 0.4369, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.2476\n",
      "    Validation Batch [1/1], Loss: 0.4158\n",
      "Validation Loss: 0.4158, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.2658\n",
      "    Validation Batch [1/1], Loss: 0.3676\n",
      "Validation Loss: 0.3676, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.2529\n",
      "    Validation Batch [1/1], Loss: 0.3694\n",
      "Validation Loss: 0.3694, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.2730\n",
      "    Validation Batch [1/1], Loss: 0.3996\n",
      "Validation Loss: 0.3996, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.2259\n",
      "    Validation Batch [1/1], Loss: 0.4179\n",
      "Validation Loss: 0.4179, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.2322\n",
      "    Validation Batch [1/1], Loss: 0.3926\n",
      "Validation Loss: 0.3926, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.2156\n",
      "    Validation Batch [1/1], Loss: 0.3545\n",
      "Validation Loss: 0.3545, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.3612 to 0.3545. Saving model...\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.2431\n",
      "    Validation Batch [1/1], Loss: 0.3368\n",
      "Validation Loss: 0.3368, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3545 to 0.3368. Saving model...\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.2364\n",
      "    Validation Batch [1/1], Loss: 0.3415\n",
      "Validation Loss: 0.3415, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.2199\n",
      "    Validation Batch [1/1], Loss: 0.3636\n",
      "Validation Loss: 0.3636, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.2531\n",
      "    Validation Batch [1/1], Loss: 0.3930\n",
      "Validation Loss: 0.3930, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.2186\n",
      "    Validation Batch [1/1], Loss: 0.3907\n",
      "Validation Loss: 0.3907, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.2266\n",
      "    Validation Batch [1/1], Loss: 0.3627\n",
      "Validation Loss: 0.3627, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.2474\n",
      "    Validation Batch [1/1], Loss: 0.3334\n",
      "Validation Loss: 0.3334, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3368 to 0.3334. Saving model...\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.2088\n",
      "    Validation Batch [1/1], Loss: 0.3325\n",
      "Validation Loss: 0.3325, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3334 to 0.3325. Saving model...\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.2329\n",
      "    Validation Batch [1/1], Loss: 0.3611\n",
      "Validation Loss: 0.3611, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [273/1000] completed, Average Training Loss: 0.2243\n",
      "    Validation Batch [1/1], Loss: 0.3902\n",
      "Validation Loss: 0.3902, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.2306\n",
      "    Validation Batch [1/1], Loss: 0.3832\n",
      "Validation Loss: 0.3832, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.2283\n",
      "    Validation Batch [1/1], Loss: 0.3500\n",
      "Validation Loss: 0.3500, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.2063\n",
      "    Validation Batch [1/1], Loss: 0.3355\n",
      "Validation Loss: 0.3355, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.2530\n",
      "    Validation Batch [1/1], Loss: 0.3329\n",
      "Validation Loss: 0.3329, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.2254\n",
      "    Validation Batch [1/1], Loss: 0.3778\n",
      "Validation Loss: 0.3778, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.1931\n",
      "    Validation Batch [1/1], Loss: 0.4009\n",
      "Validation Loss: 0.4009, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.2020\n",
      "    Validation Batch [1/1], Loss: 0.3554\n",
      "Validation Loss: 0.3554, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.1893\n",
      "    Validation Batch [1/1], Loss: 0.3274\n",
      "Validation Loss: 0.3274, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.3325 to 0.3274. Saving model...\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.2060\n",
      "    Validation Batch [1/1], Loss: 0.3247\n",
      "Validation Loss: 0.3247, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3274 to 0.3247. Saving model...\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.2218\n",
      "    Validation Batch [1/1], Loss: 0.3466\n",
      "Validation Loss: 0.3466, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.2144\n",
      "    Validation Batch [1/1], Loss: 0.3580\n",
      "Validation Loss: 0.3580, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.2188\n",
      "    Validation Batch [1/1], Loss: 0.3410\n",
      "Validation Loss: 0.3410, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.1835\n",
      "    Validation Batch [1/1], Loss: 0.3175\n",
      "Validation Loss: 0.3175, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.3247 to 0.3175. Saving model...\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.1981\n",
      "    Validation Batch [1/1], Loss: 0.3295\n",
      "Validation Loss: 0.3295, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.1953\n",
      "    Validation Batch [1/1], Loss: 0.3265\n",
      "Validation Loss: 0.3265, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.1717\n",
      "    Validation Batch [1/1], Loss: 0.3152\n",
      "Validation Loss: 0.3152, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.3175 to 0.3152. Saving model...\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.1788\n",
      "    Validation Batch [1/1], Loss: 0.3198\n",
      "Validation Loss: 0.3198, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.1955\n",
      "    Validation Batch [1/1], Loss: 0.3244\n",
      "Validation Loss: 0.3244, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.1866\n",
      "    Validation Batch [1/1], Loss: 0.3358\n",
      "Validation Loss: 0.3358, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.1893\n",
      "    Validation Batch [1/1], Loss: 0.3196\n",
      "Validation Loss: 0.3196, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.1761\n",
      "    Validation Batch [1/1], Loss: 0.3027\n",
      "Validation Loss: 0.3027, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.3152 to 0.3027. Saving model...\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.1858\n",
      "    Validation Batch [1/1], Loss: 0.3169\n",
      "Validation Loss: 0.3169, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.1926\n",
      "    Validation Batch [1/1], Loss: 0.3362\n",
      "Validation Loss: 0.3362, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.1695\n",
      "    Validation Batch [1/1], Loss: 0.3521\n",
      "Validation Loss: 0.3521, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.1785\n",
      "    Validation Batch [1/1], Loss: 0.3491\n",
      "Validation Loss: 0.3491, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.1745\n",
      "    Validation Batch [1/1], Loss: 0.3409\n",
      "Validation Loss: 0.3409, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.1686\n",
      "    Validation Batch [1/1], Loss: 0.3372\n",
      "Validation Loss: 0.3372, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [301/1000] completed, Average Training Loss: 0.1502\n",
      "    Validation Batch [1/1], Loss: 0.3411\n",
      "Validation Loss: 0.3411, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.1582\n",
      "    Validation Batch [1/1], Loss: 0.3488\n",
      "Validation Loss: 0.3488, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.1574\n",
      "    Validation Batch [1/1], Loss: 0.3323\n",
      "Validation Loss: 0.3323, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.1683\n",
      "    Validation Batch [1/1], Loss: 0.3155\n",
      "Validation Loss: 0.3155, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.1647\n",
      "    Validation Batch [1/1], Loss: 0.3050\n",
      "Validation Loss: 0.3050, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.1564\n",
      "    Validation Batch [1/1], Loss: 0.3155\n",
      "Validation Loss: 0.3155, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.1355\n",
      "    Validation Batch [1/1], Loss: 0.3309\n",
      "Validation Loss: 0.3309, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.1629\n",
      "    Validation Batch [1/1], Loss: 0.3161\n",
      "Validation Loss: 0.3161, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.1647\n",
      "    Validation Batch [1/1], Loss: 0.2933\n",
      "Validation Loss: 0.2933, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.3027 to 0.2933. Saving model...\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.1500\n",
      "    Validation Batch [1/1], Loss: 0.2833\n",
      "Validation Loss: 0.2833, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2933 to 0.2833. Saving model...\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.1547\n",
      "    Validation Batch [1/1], Loss: 0.2935\n",
      "Validation Loss: 0.2935, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.1508\n",
      "    Validation Batch [1/1], Loss: 0.3108\n",
      "Validation Loss: 0.3108, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.1574\n",
      "    Validation Batch [1/1], Loss: 0.3023\n",
      "Validation Loss: 0.3023, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.1486\n",
      "    Validation Batch [1/1], Loss: 0.2901\n",
      "Validation Loss: 0.2901, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.1651\n",
      "    Validation Batch [1/1], Loss: 0.2887\n",
      "Validation Loss: 0.2887, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.1352\n",
      "    Validation Batch [1/1], Loss: 0.3148\n",
      "Validation Loss: 0.3148, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.1443\n",
      "    Validation Batch [1/1], Loss: 0.3381\n",
      "Validation Loss: 0.3381, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.1388\n",
      "    Validation Batch [1/1], Loss: 0.3074\n",
      "Validation Loss: 0.3074, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.1432\n",
      "    Validation Batch [1/1], Loss: 0.2848\n",
      "Validation Loss: 0.2848, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.1374\n",
      "    Validation Batch [1/1], Loss: 0.2851\n",
      "Validation Loss: 0.2851, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.1508\n",
      "    Validation Batch [1/1], Loss: 0.2933\n",
      "Validation Loss: 0.2933, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.1505\n",
      "    Validation Batch [1/1], Loss: 0.3245\n",
      "Validation Loss: 0.3245, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.1483\n",
      "    Validation Batch [1/1], Loss: 0.3305\n",
      "Validation Loss: 0.3305, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.1395\n",
      "    Validation Batch [1/1], Loss: 0.3148\n",
      "Validation Loss: 0.3148, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.1522\n",
      "    Validation Batch [1/1], Loss: 0.3043\n",
      "Validation Loss: 0.3043, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.1225\n",
      "    Validation Batch [1/1], Loss: 0.3060\n",
      "Validation Loss: 0.3060, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.1626\n",
      "    Validation Batch [1/1], Loss: 0.3041\n",
      "Validation Loss: 0.3041, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.1329\n",
      "    Validation Batch [1/1], Loss: 0.2980\n",
      "Validation Loss: 0.2980, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.1205\n",
      "    Validation Batch [1/1], Loss: 0.2857\n",
      "Validation Loss: 0.2857, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.1299\n",
      "    Validation Batch [1/1], Loss: 0.2878\n",
      "Validation Loss: 0.2878, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [331/1000] completed, Average Training Loss: 0.1351\n",
      "    Validation Batch [1/1], Loss: 0.2959\n",
      "Validation Loss: 0.2959, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.1367\n",
      "    Validation Batch [1/1], Loss: 0.2935\n",
      "Validation Loss: 0.2935, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.1287\n",
      "    Validation Batch [1/1], Loss: 0.2979\n",
      "Validation Loss: 0.2979, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.1255\n",
      "    Validation Batch [1/1], Loss: 0.3002\n",
      "Validation Loss: 0.3002, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.1256\n",
      "    Validation Batch [1/1], Loss: 0.2964\n",
      "Validation Loss: 0.2964, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.1348\n",
      "    Validation Batch [1/1], Loss: 0.2940\n",
      "Validation Loss: 0.2940, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.1191\n",
      "    Validation Batch [1/1], Loss: 0.2914\n",
      "Validation Loss: 0.2914, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.1318\n",
      "    Validation Batch [1/1], Loss: 0.2876\n",
      "Validation Loss: 0.2876, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.1087\n",
      "    Validation Batch [1/1], Loss: 0.2884\n",
      "Validation Loss: 0.2884, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.1319\n",
      "    Validation Batch [1/1], Loss: 0.2972\n",
      "Validation Loss: 0.2972, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.1315\n",
      "    Validation Batch [1/1], Loss: 0.3111\n",
      "Validation Loss: 0.3111, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.1246\n",
      "    Validation Batch [1/1], Loss: 0.3030\n",
      "Validation Loss: 0.3030, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.1236\n",
      "    Validation Batch [1/1], Loss: 0.2744\n",
      "Validation Loss: 0.2744, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.2833 to 0.2744. Saving model...\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.1049\n",
      "    Validation Batch [1/1], Loss: 0.2601\n",
      "Validation Loss: 0.2601, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2744 to 0.2601. Saving model...\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.1117\n",
      "    Validation Batch [1/1], Loss: 0.2564\n",
      "Validation Loss: 0.2564, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2601 to 0.2564. Saving model...\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.1284\n",
      "    Validation Batch [1/1], Loss: 0.2602\n",
      "Validation Loss: 0.2602, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.1110\n",
      "    Validation Batch [1/1], Loss: 0.2733\n",
      "Validation Loss: 0.2733, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.1360\n",
      "    Validation Batch [1/1], Loss: 0.3071\n",
      "Validation Loss: 0.3071, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.1196\n",
      "    Validation Batch [1/1], Loss: 0.2989\n",
      "Validation Loss: 0.2989, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.1168\n",
      "    Validation Batch [1/1], Loss: 0.2770\n",
      "Validation Loss: 0.2770, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.1161\n",
      "    Validation Batch [1/1], Loss: 0.2628\n",
      "Validation Loss: 0.2628, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.1045\n",
      "    Validation Batch [1/1], Loss: 0.2725\n",
      "Validation Loss: 0.2725, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.1096\n",
      "    Validation Batch [1/1], Loss: 0.2971\n",
      "Validation Loss: 0.2971, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.1131\n",
      "    Validation Batch [1/1], Loss: 0.2882\n",
      "Validation Loss: 0.2882, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.1107\n",
      "    Validation Batch [1/1], Loss: 0.2994\n",
      "Validation Loss: 0.2994, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.1169\n",
      "    Validation Batch [1/1], Loss: 0.3143\n",
      "Validation Loss: 0.3143, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.0979\n",
      "    Validation Batch [1/1], Loss: 0.2986\n",
      "Validation Loss: 0.2986, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.1218\n",
      "    Validation Batch [1/1], Loss: 0.2806\n",
      "Validation Loss: 0.2806, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.0934\n",
      "    Validation Batch [1/1], Loss: 0.2739\n",
      "Validation Loss: 0.2739, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1140\n",
      "    Validation Batch [1/1], Loss: 0.2736\n",
      "Validation Loss: 0.2736, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [361/1000] completed, Average Training Loss: 0.0995\n",
      "    Validation Batch [1/1], Loss: 0.2852\n",
      "Validation Loss: 0.2852, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.1047\n",
      "    Validation Batch [1/1], Loss: 0.3105\n",
      "Validation Loss: 0.3105, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.1152\n",
      "    Validation Batch [1/1], Loss: 0.2795\n",
      "Validation Loss: 0.2795, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.0963\n",
      "    Validation Batch [1/1], Loss: 0.2767\n",
      "Validation Loss: 0.2767, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.1050\n",
      "    Validation Batch [1/1], Loss: 0.2731\n",
      "Validation Loss: 0.2731, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.1023\n",
      "    Validation Batch [1/1], Loss: 0.2577\n",
      "Validation Loss: 0.2577, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.0939\n",
      "    Validation Batch [1/1], Loss: 0.2853\n",
      "Validation Loss: 0.2853, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.0970\n",
      "    Validation Batch [1/1], Loss: 0.3325\n",
      "Validation Loss: 0.3325, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.0936\n",
      "    Validation Batch [1/1], Loss: 0.3417\n",
      "Validation Loss: 0.3417, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.0952\n",
      "    Validation Batch [1/1], Loss: 0.3338\n",
      "Validation Loss: 0.3338, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.1132\n",
      "    Validation Batch [1/1], Loss: 0.2579\n",
      "Validation Loss: 0.2579, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.0986\n",
      "    Validation Batch [1/1], Loss: 0.2387\n",
      "Validation Loss: 0.2387, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.2564 to 0.2387. Saving model...\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.0929\n",
      "    Validation Batch [1/1], Loss: 0.2695\n",
      "Validation Loss: 0.2695, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.0945\n",
      "    Validation Batch [1/1], Loss: 0.3458\n",
      "Validation Loss: 0.3458, Validation Accuracy: 88.89%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.0808\n",
      "    Validation Batch [1/1], Loss: 0.3866\n",
      "Validation Loss: 0.3866, Validation Accuracy: 88.89%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.0929\n",
      "    Validation Batch [1/1], Loss: 0.2731\n",
      "Validation Loss: 0.2731, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.0867\n",
      "    Validation Batch [1/1], Loss: 0.2279\n",
      "Validation Loss: 0.2279, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.2387 to 0.2279. Saving model...\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.0966\n",
      "    Validation Batch [1/1], Loss: 0.2233\n",
      "Validation Loss: 0.2233, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.2279 to 0.2233. Saving model...\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.1047\n",
      "    Validation Batch [1/1], Loss: 0.2490\n",
      "Validation Loss: 0.2490, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.0918\n",
      "    Validation Batch [1/1], Loss: 0.3055\n",
      "Validation Loss: 0.3055, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.0815\n",
      "    Validation Batch [1/1], Loss: 0.2859\n",
      "Validation Loss: 0.2859, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.0793\n",
      "    Validation Batch [1/1], Loss: 0.2845\n",
      "Validation Loss: 0.2845, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.0811\n",
      "    Validation Batch [1/1], Loss: 0.2693\n",
      "Validation Loss: 0.2693, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.0953\n",
      "    Validation Batch [1/1], Loss: 0.2535\n",
      "Validation Loss: 0.2535, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.0796\n",
      "    Validation Batch [1/1], Loss: 0.2595\n",
      "Validation Loss: 0.2595, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.1096\n",
      "    Validation Batch [1/1], Loss: 0.2691\n",
      "Validation Loss: 0.2691, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.0925\n",
      "    Validation Batch [1/1], Loss: 0.2913\n",
      "Validation Loss: 0.2913, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.0839\n",
      "    Validation Batch [1/1], Loss: 0.3196\n",
      "Validation Loss: 0.3196, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.0776\n",
      "    Validation Batch [1/1], Loss: 0.3317\n",
      "Validation Loss: 0.3317, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.0759\n",
      "    Validation Batch [1/1], Loss: 0.3155\n",
      "Validation Loss: 0.3155, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.0954\n",
      "    Validation Batch [1/1], Loss: 0.2657\n",
      "Validation Loss: 0.2657, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [392/1000] completed, Average Training Loss: 0.0936\n",
      "    Validation Batch [1/1], Loss: 0.2472\n",
      "Validation Loss: 0.2472, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.0761\n",
      "    Validation Batch [1/1], Loss: 0.2377\n",
      "Validation Loss: 0.2377, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.0912\n",
      "    Validation Batch [1/1], Loss: 0.2571\n",
      "Validation Loss: 0.2571, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.0730\n",
      "    Validation Batch [1/1], Loss: 0.2921\n",
      "Validation Loss: 0.2921, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.0794\n",
      "    Validation Batch [1/1], Loss: 0.3082\n",
      "Validation Loss: 0.3082, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.0758\n",
      "    Validation Batch [1/1], Loss: 0.2806\n",
      "Validation Loss: 0.2806, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.0877\n",
      "    Validation Batch [1/1], Loss: 0.2402\n",
      "Validation Loss: 0.2402, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.0882\n",
      "    Validation Batch [1/1], Loss: 0.2258\n",
      "Validation Loss: 0.2258, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.2281\n",
      "Validation Loss: 0.2281, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.0861\n",
      "    Validation Batch [1/1], Loss: 0.2345\n",
      "Validation Loss: 0.2345, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.0847\n",
      "    Validation Batch [1/1], Loss: 0.2325\n",
      "Validation Loss: 0.2325, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.0651\n",
      "    Validation Batch [1/1], Loss: 0.2332\n",
      "Validation Loss: 0.2332, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.0861\n",
      "    Validation Batch [1/1], Loss: 0.2462\n",
      "Validation Loss: 0.2462, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.0805\n",
      "    Validation Batch [1/1], Loss: 0.2860\n",
      "Validation Loss: 0.2860, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.0807\n",
      "    Validation Batch [1/1], Loss: 0.3204\n",
      "Validation Loss: 0.3204, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.0903\n",
      "    Validation Batch [1/1], Loss: 0.3171\n",
      "Validation Loss: 0.3171, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.0717\n",
      "    Validation Batch [1/1], Loss: 0.2983\n",
      "Validation Loss: 0.2983, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.0728\n",
      "    Validation Batch [1/1], Loss: 0.2801\n",
      "Validation Loss: 0.2801, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.0721\n",
      "    Validation Batch [1/1], Loss: 0.2645\n",
      "Validation Loss: 0.2645, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.0767\n",
      "    Validation Batch [1/1], Loss: 0.2540\n",
      "Validation Loss: 0.2540, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.0906\n",
      "    Validation Batch [1/1], Loss: 0.2535\n",
      "Validation Loss: 0.2535, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.0719\n",
      "    Validation Batch [1/1], Loss: 0.2543\n",
      "Validation Loss: 0.2543, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.0753\n",
      "    Validation Batch [1/1], Loss: 0.2599\n",
      "Validation Loss: 0.2599, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.0685\n",
      "    Validation Batch [1/1], Loss: 0.2653\n",
      "Validation Loss: 0.2653, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.0645\n",
      "    Validation Batch [1/1], Loss: 0.2623\n",
      "Validation Loss: 0.2623, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.0862\n",
      "    Validation Batch [1/1], Loss: 0.2542\n",
      "Validation Loss: 0.2542, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.0678\n",
      "    Validation Batch [1/1], Loss: 0.2373\n",
      "Validation Loss: 0.2373, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.0723\n",
      "    Validation Batch [1/1], Loss: 0.2449\n",
      "Validation Loss: 0.2449, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.0659\n",
      "    Validation Batch [1/1], Loss: 0.2677\n",
      "Validation Loss: 0.2677, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.0774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.3043\n",
      "Validation Loss: 0.3043, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.0748\n",
      "    Validation Batch [1/1], Loss: 0.3122\n",
      "Validation Loss: 0.3122, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n",
      "Epoch [423/1000] completed, Average Training Loss: 0.0654\n",
      "    Validation Batch [1/1], Loss: 0.2991\n",
      "Validation Loss: 0.2991, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.0679\n",
      "    Validation Batch [1/1], Loss: 0.2852\n",
      "Validation Loss: 0.2852, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.0628\n",
      "    Validation Batch [1/1], Loss: 0.2607\n",
      "Validation Loss: 0.2607, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.0780\n",
      "    Validation Batch [1/1], Loss: 0.2410\n",
      "Validation Loss: 0.2410, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.0749\n",
      "    Validation Batch [1/1], Loss: 0.2379\n",
      "Validation Loss: 0.2379, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.0624\n",
      "    Validation Batch [1/1], Loss: 0.2576\n",
      "Validation Loss: 0.2576, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.0708\n",
      "    Validation Batch [1/1], Loss: 0.2908\n",
      "Validation Loss: 0.2908, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.0716\n",
      "    Validation Batch [1/1], Loss: 0.3056\n",
      "Validation Loss: 0.3056, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.0621\n",
      "    Validation Batch [1/1], Loss: 0.2973\n",
      "Validation Loss: 0.2973, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.0599\n",
      "    Validation Batch [1/1], Loss: 0.2611\n",
      "Validation Loss: 0.2611, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.0716\n",
      "    Validation Batch [1/1], Loss: 0.2388\n",
      "Validation Loss: 0.2388, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.0611\n",
      "    Validation Batch [1/1], Loss: 0.2407\n",
      "Validation Loss: 0.2407, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.0734\n",
      "    Validation Batch [1/1], Loss: 0.2406\n",
      "Validation Loss: 0.2406, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.0536\n",
      "    Validation Batch [1/1], Loss: 0.2473\n",
      "Validation Loss: 0.2473, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.0530\n",
      "    Validation Batch [1/1], Loss: 0.2539\n",
      "Validation Loss: 0.2539, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.0559\n",
      "    Validation Batch [1/1], Loss: 0.2572\n",
      "Validation Loss: 0.2572, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.0540\n",
      "    Validation Batch [1/1], Loss: 0.2548\n",
      "Validation Loss: 0.2548, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.0576\n",
      "    Validation Batch [1/1], Loss: 0.2407\n",
      "Validation Loss: 0.2407, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.0593\n",
      "    Validation Batch [1/1], Loss: 0.2349\n",
      "Validation Loss: 0.2349, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.0609\n",
      "    Validation Batch [1/1], Loss: 0.2302\n",
      "Validation Loss: 0.2302, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.0673\n",
      "    Validation Batch [1/1], Loss: 0.2236\n",
      "Validation Loss: 0.2236, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.0671\n",
      "    Validation Batch [1/1], Loss: 0.2228\n",
      "Validation Loss: 0.2228, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 0.2233 to 0.2228. Saving model...\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.0447\n",
      "    Validation Batch [1/1], Loss: 0.2434\n",
      "Validation Loss: 0.2434, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.0552\n",
      "    Validation Batch [1/1], Loss: 0.2787\n",
      "Validation Loss: 0.2787, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.0547\n",
      "    Validation Batch [1/1], Loss: 0.2926\n",
      "Validation Loss: 0.2926, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.0498\n",
      "    Validation Batch [1/1], Loss: 0.3038\n",
      "Validation Loss: 0.3038, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.0496\n",
      "    Validation Batch [1/1], Loss: 0.3039\n",
      "Validation Loss: 0.3039, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.0657\n",
      "    Validation Batch [1/1], Loss: 0.3037\n",
      "Validation Loss: 0.3037, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [451/1000] completed, Average Training Loss: 0.0522\n",
      "    Validation Batch [1/1], Loss: 0.2902\n",
      "Validation Loss: 0.2902, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.2787\n",
      "Validation Loss: 0.2787, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.0554\n",
      "    Validation Batch [1/1], Loss: 0.2744\n",
      "Validation Loss: 0.2744, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.0486\n",
      "    Validation Batch [1/1], Loss: 0.2670\n",
      "Validation Loss: 0.2670, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.2663\n",
      "Validation Loss: 0.2663, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.0567\n",
      "    Validation Batch [1/1], Loss: 0.2764\n",
      "Validation Loss: 0.2764, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.0548\n",
      "    Validation Batch [1/1], Loss: 0.2653\n",
      "Validation Loss: 0.2653, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0477\n",
      "    Validation Batch [1/1], Loss: 0.2553\n",
      "Validation Loss: 0.2553, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.0621\n",
      "    Validation Batch [1/1], Loss: 0.2490\n",
      "Validation Loss: 0.2490, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.0525\n",
      "    Validation Batch [1/1], Loss: 0.2434\n",
      "Validation Loss: 0.2434, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.2403\n",
      "Validation Loss: 0.2403, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.2547\n",
      "Validation Loss: 0.2547, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.0546\n",
      "    Validation Batch [1/1], Loss: 0.2502\n",
      "Validation Loss: 0.2502, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.0553\n",
      "    Validation Batch [1/1], Loss: 0.2395\n",
      "Validation Loss: 0.2395, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.2358\n",
      "Validation Loss: 0.2358, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.0531\n",
      "    Validation Batch [1/1], Loss: 0.2400\n",
      "Validation Loss: 0.2400, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.2498\n",
      "Validation Loss: 0.2498, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.0446\n",
      "    Validation Batch [1/1], Loss: 0.2509\n",
      "Validation Loss: 0.2509, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.2497\n",
      "Validation Loss: 0.2497, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n",
      "Epoch [470/1000] completed, Average Training Loss: 0.0520\n",
      "    Validation Batch [1/1], Loss: 0.2532\n",
      "Validation Loss: 0.2532, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.0534\n",
      "    Validation Batch [1/1], Loss: 0.2560\n",
      "Validation Loss: 0.2560, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0538\n",
      "    Validation Batch [1/1], Loss: 0.2662\n",
      "Validation Loss: 0.2662, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0506\n",
      "    Validation Batch [1/1], Loss: 0.2566\n",
      "Validation Loss: 0.2566, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0512\n",
      "    Validation Batch [1/1], Loss: 0.2374\n",
      "Validation Loss: 0.2374, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0480\n",
      "    Validation Batch [1/1], Loss: 0.2300\n",
      "Validation Loss: 0.2300, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0471\n",
      "    Validation Batch [1/1], Loss: 0.2161\n",
      "Validation Loss: 0.2161, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2228 to 0.2161. Saving model...\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0480\n",
      "    Validation Batch [1/1], Loss: 0.2079\n",
      "Validation Loss: 0.2079, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2161 to 0.2079. Saving model...\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0402\n",
      "    Validation Batch [1/1], Loss: 0.2195\n",
      "Validation Loss: 0.2195, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.2418\n",
      "Validation Loss: 0.2418, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2572\n",
      "Validation Loss: 0.2572, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.2550\n",
      "Validation Loss: 0.2550, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.0498\n",
      "    Validation Batch [1/1], Loss: 0.2439\n",
      "Validation Loss: 0.2439, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0508\n",
      "    Validation Batch [1/1], Loss: 0.2345\n",
      "Validation Loss: 0.2345, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.2240\n",
      "Validation Loss: 0.2240, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.2169\n",
      "Validation Loss: 0.2169, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0440\n",
      "    Validation Batch [1/1], Loss: 0.2071\n",
      "Validation Loss: 0.2071, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2079 to 0.2071. Saving model...\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0464\n",
      "    Validation Batch [1/1], Loss: 0.2101\n",
      "Validation Loss: 0.2101, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.2418\n",
      "Validation Loss: 0.2418, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0446\n",
      "    Validation Batch [1/1], Loss: 0.3030\n",
      "Validation Loss: 0.3030, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0525\n",
      "    Validation Batch [1/1], Loss: 0.3376\n",
      "Validation Loss: 0.3376, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0502\n",
      "    Validation Batch [1/1], Loss: 0.3214\n",
      "Validation Loss: 0.3214, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0492\n",
      "    Validation Batch [1/1], Loss: 0.2823\n",
      "Validation Loss: 0.2823, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.2352\n",
      "Validation Loss: 0.2352, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.2079\n",
      "Validation Loss: 0.2079, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.2097\n",
      "Validation Loss: 0.2097, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.2288\n",
      "Validation Loss: 0.2288, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.2606\n",
      "Validation Loss: 0.2606, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0446\n",
      "    Validation Batch [1/1], Loss: 0.2965\n",
      "Validation Loss: 0.2965, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0503\n",
      "    Validation Batch [1/1], Loss: 0.3001\n",
      "Validation Loss: 0.3001, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0483\n",
      "    Validation Batch [1/1], Loss: 0.2879\n",
      "Validation Loss: 0.2879, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.2642\n",
      "Validation Loss: 0.2642, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0514\n",
      "    Validation Batch [1/1], Loss: 0.2306\n",
      "Validation Loss: 0.2306, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.2088\n",
      "Validation Loss: 0.2088, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.1986\n",
      "Validation Loss: 0.1986, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.2071 to 0.1986. Saving model...\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.2053\n",
      "Validation Loss: 0.2053, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0417\n",
      "    Validation Batch [1/1], Loss: 0.2195\n",
      "Validation Loss: 0.2195, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.2420\n",
      "Validation Loss: 0.2420, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [508/1000] completed, Average Training Loss: 0.0449\n",
      "    Validation Batch [1/1], Loss: 0.2737\n",
      "Validation Loss: 0.2737, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.2710\n",
      "Validation Loss: 0.2710, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.2575\n",
      "Validation Loss: 0.2575, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0461\n",
      "    Validation Batch [1/1], Loss: 0.2311\n",
      "Validation Loss: 0.2311, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0376\n",
      "    Validation Batch [1/1], Loss: 0.2192\n",
      "Validation Loss: 0.2192, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.2164\n",
      "Validation Loss: 0.2164, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.2211\n",
      "Validation Loss: 0.2211, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.2297\n",
      "Validation Loss: 0.2297, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0370\n",
      "    Validation Batch [1/1], Loss: 0.2423\n",
      "Validation Loss: 0.2423, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.2639\n",
      "Validation Loss: 0.2639, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.2845\n",
      "Validation Loss: 0.2845, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n",
      "Epoch [519/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.3001\n",
      "Validation Loss: 0.3001, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0373\n",
      "    Validation Batch [1/1], Loss: 0.2893\n",
      "Validation Loss: 0.2893, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0502\n",
      "    Validation Batch [1/1], Loss: 0.2670\n",
      "Validation Loss: 0.2670, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.2586\n",
      "Validation Loss: 0.2586, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.2583\n",
      "Validation Loss: 0.2583, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.2628\n",
      "Validation Loss: 0.2628, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0471\n",
      "    Validation Batch [1/1], Loss: 0.2736\n",
      "Validation Loss: 0.2736, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.2748\n",
      "Validation Loss: 0.2748, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0432\n",
      "    Validation Batch [1/1], Loss: 0.2692\n",
      "Validation Loss: 0.2692, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.2584\n",
      "Validation Loss: 0.2584, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0430\n",
      "    Validation Batch [1/1], Loss: 0.2396\n",
      "Validation Loss: 0.2396, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0317\n",
      "    Validation Batch [1/1], Loss: 0.2244\n",
      "Validation Loss: 0.2244, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.2245\n",
      "Validation Loss: 0.2245, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.2169\n",
      "Validation Loss: 0.2169, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.2178\n",
      "Validation Loss: 0.2178, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0442\n",
      "    Validation Batch [1/1], Loss: 0.2242\n",
      "Validation Loss: 0.2242, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.2424\n",
      "Validation Loss: 0.2424, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [536/1000] completed, Average Training Loss: 0.0412\n",
      "    Validation Batch [1/1], Loss: 0.2505\n",
      "Validation Loss: 0.2505, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0405\n",
      "    Validation Batch [1/1], Loss: 0.2545\n",
      "Validation Loss: 0.2545, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.2505\n",
      "Validation Loss: 0.2505, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.2432\n",
      "Validation Loss: 0.2432, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.2314\n",
      "Validation Loss: 0.2314, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0414\n",
      "    Validation Batch [1/1], Loss: 0.2311\n",
      "Validation Loss: 0.2311, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0414\n",
      "    Validation Batch [1/1], Loss: 0.2440\n",
      "Validation Loss: 0.2440, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.2674\n",
      "Validation Loss: 0.2674, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0356\n",
      "    Validation Batch [1/1], Loss: 0.3034\n",
      "Validation Loss: 0.3034, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.2868\n",
      "Validation Loss: 0.2868, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.2610\n",
      "Validation Loss: 0.2610, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.2426\n",
      "Validation Loss: 0.2426, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0344\n",
      "    Validation Batch [1/1], Loss: 0.2348\n",
      "Validation Loss: 0.2348, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0441\n",
      "    Validation Batch [1/1], Loss: 0.2337\n",
      "Validation Loss: 0.2337, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.2504\n",
      "Validation Loss: 0.2504, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0332\n",
      "    Validation Batch [1/1], Loss: 0.2599\n",
      "Validation Loss: 0.2599, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0317\n",
      "    Validation Batch [1/1], Loss: 0.2708\n",
      "Validation Loss: 0.2708, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.2644\n",
      "Validation Loss: 0.2644, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.2478\n",
      "Validation Loss: 0.2478, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.2205\n",
      "Validation Loss: 0.2205, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0322\n",
      "    Validation Batch [1/1], Loss: 0.2296\n",
      "Validation Loss: 0.2296, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2398\n",
      "Validation Loss: 0.2398, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.2416\n",
      "Validation Loss: 0.2416, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0353\n",
      "    Validation Batch [1/1], Loss: 0.2445\n",
      "Validation Loss: 0.2445, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0388\n",
      "    Validation Batch [1/1], Loss: 0.2722\n",
      "Validation Loss: 0.2722, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0347\n",
      "    Validation Batch [1/1], Loss: 0.2851\n",
      "Validation Loss: 0.2851, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.2910\n",
      "Validation Loss: 0.2910, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.2772\n",
      "Validation Loss: 0.2772, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2597\n",
      "Validation Loss: 0.2597, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.2409\n",
      "Validation Loss: 0.2409, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [566/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.2274\n",
      "Validation Loss: 0.2274, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.2266\n",
      "Validation Loss: 0.2266, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.2404\n",
      "Validation Loss: 0.2404, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.2730\n",
      "Validation Loss: 0.2730, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0340\n",
      "    Validation Batch [1/1], Loss: 0.2956\n",
      "Validation Loss: 0.2956, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.3082\n",
      "Validation Loss: 0.3082, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0456\n",
      "    Validation Batch [1/1], Loss: 0.3031\n",
      "Validation Loss: 0.3031, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.2741\n",
      "Validation Loss: 0.2741, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.2323\n",
      "Validation Loss: 0.2323, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.1998\n",
      "Validation Loss: 0.1998, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0292\n",
      "    Validation Batch [1/1], Loss: 0.1964\n",
      "Validation Loss: 0.1964, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.1986 to 0.1964. Saving model...\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0281\n",
      "    Validation Batch [1/1], Loss: 0.1977\n",
      "Validation Loss: 0.1977, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.2149\n",
      "Validation Loss: 0.2149, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.2456\n",
      "Validation Loss: 0.2456, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.2780\n",
      "Validation Loss: 0.2780, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0374\n",
      "    Validation Batch [1/1], Loss: 0.2890\n",
      "Validation Loss: 0.2890, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.2781\n",
      "Validation Loss: 0.2781, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.2501\n",
      "Validation Loss: 0.2501, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0279\n",
      "    Validation Batch [1/1], Loss: 0.2213\n",
      "Validation Loss: 0.2213, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.2058\n",
      "Validation Loss: 0.2058, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.1996\n",
      "Validation Loss: 0.1996, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0260\n",
      "    Validation Batch [1/1], Loss: 0.2035\n",
      "Validation Loss: 0.2035, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0270\n",
      "    Validation Batch [1/1], Loss: 0.2135\n",
      "Validation Loss: 0.2135, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.2255\n",
      "Validation Loss: 0.2255, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.2403\n",
      "Validation Loss: 0.2403, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2492\n",
      "Validation Loss: 0.2492, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.2469\n",
      "Validation Loss: 0.2469, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.2322\n",
      "Validation Loss: 0.2322, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [594/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.2302\n",
      "Validation Loss: 0.2302, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0418\n",
      "    Validation Batch [1/1], Loss: 0.2271\n",
      "Validation Loss: 0.2271, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.2240\n",
      "Validation Loss: 0.2240, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.2315\n",
      "Validation Loss: 0.2315, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.2487\n",
      "Validation Loss: 0.2487, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0270\n",
      "    Validation Batch [1/1], Loss: 0.2383\n",
      "Validation Loss: 0.2383, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0322\n",
      "    Validation Batch [1/1], Loss: 0.2292\n",
      "Validation Loss: 0.2292, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.2290\n",
      "Validation Loss: 0.2290, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.2341\n",
      "Validation Loss: 0.2341, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.2509\n",
      "Validation Loss: 0.2509, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.2751\n",
      "Validation Loss: 0.2751, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.2992\n",
      "Validation Loss: 0.2992, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0270\n",
      "    Validation Batch [1/1], Loss: 0.3165\n",
      "Validation Loss: 0.3165, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.3219\n",
      "Validation Loss: 0.3219, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0287\n",
      "    Validation Batch [1/1], Loss: 0.3107\n",
      "Validation Loss: 0.3107, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.2981\n",
      "Validation Loss: 0.2981, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.2787\n",
      "Validation Loss: 0.2787, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.2661\n",
      "Validation Loss: 0.2661, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.2672\n",
      "Validation Loss: 0.2672, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.2730\n",
      "Validation Loss: 0.2730, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.2808\n",
      "Validation Loss: 0.2808, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0311\n",
      "    Validation Batch [1/1], Loss: 0.2935\n",
      "Validation Loss: 0.2935, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.2778\n",
      "Validation Loss: 0.2778, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0314\n",
      "    Validation Batch [1/1], Loss: 0.2621\n",
      "Validation Loss: 0.2621, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.2392\n",
      "Validation Loss: 0.2392, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.2261\n",
      "Validation Loss: 0.2261, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.2219\n",
      "Validation Loss: 0.2219, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.2291\n",
      "Validation Loss: 0.2291, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.2711\n",
      "Validation Loss: 0.2711, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0238\n",
      "    Validation Batch [1/1], Loss: 0.3092\n",
      "Validation Loss: 0.3092, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0260\n",
      "    Validation Batch [1/1], Loss: 0.2969\n",
      "Validation Loss: 0.2969, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [625/1000] completed, Average Training Loss: 0.0342\n",
      "    Validation Batch [1/1], Loss: 0.2596\n",
      "Validation Loss: 0.2596, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.2256\n",
      "Validation Loss: 0.2256, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.1959\n",
      "Validation Loss: 0.1959, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.1964 to 0.1959. Saving model...\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.1843\n",
      "Validation Loss: 0.1843, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.1959 to 0.1843. Saving model...\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.1827\n",
      "Validation Loss: 0.1827, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 0.1843 to 0.1827. Saving model...\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.1990\n",
      "Validation Loss: 0.1990, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.2193\n",
      "Validation Loss: 0.2193, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.2368\n",
      "Validation Loss: 0.2368, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0276\n",
      "    Validation Batch [1/1], Loss: 0.2485\n",
      "Validation Loss: 0.2485, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.2462\n",
      "Validation Loss: 0.2462, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0276\n",
      "    Validation Batch [1/1], Loss: 0.2360\n",
      "Validation Loss: 0.2360, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.2285\n",
      "Validation Loss: 0.2285, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.2220\n",
      "Validation Loss: 0.2220, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.2249\n",
      "Validation Loss: 0.2249, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.2264\n",
      "Validation Loss: 0.2264, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.2373\n",
      "Validation Loss: 0.2373, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.2227\n",
      "Validation Loss: 0.2227, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.2045\n",
      "Validation Loss: 0.2045, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.2011\n",
      "Validation Loss: 0.2011, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.2112\n",
      "Validation Loss: 0.2112, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.2398\n",
      "Validation Loss: 0.2398, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.2811\n",
      "Validation Loss: 0.2811, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.2507\n",
      "Validation Loss: 0.2507, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.2389\n",
      "Validation Loss: 0.2389, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.2397\n",
      "Validation Loss: 0.2397, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.2494\n",
      "Validation Loss: 0.2494, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.2473\n",
      "Validation Loss: 0.2473, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0198\n",
      "    Validation Batch [1/1], Loss: 0.2650\n",
      "Validation Loss: 0.2650, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.3060\n",
      "Validation Loss: 0.3060, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.3307\n",
      "Validation Loss: 0.3307, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [655/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.3427\n",
      "Validation Loss: 0.3427, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.3616\n",
      "Validation Loss: 0.3616, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.3372\n",
      "Validation Loss: 0.3372, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.3130\n",
      "Validation Loss: 0.3130, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.2837\n",
      "Validation Loss: 0.2837, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.2590\n",
      "Validation Loss: 0.2590, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.2379\n",
      "Validation Loss: 0.2379, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.2100\n",
      "Validation Loss: 0.2100, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.1957\n",
      "Validation Loss: 0.1957, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0171\n",
      "    Validation Batch [1/1], Loss: 0.1916\n",
      "Validation Loss: 0.1916, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.1929\n",
      "Validation Loss: 0.1929, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.2184\n",
      "Validation Loss: 0.2184, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.2549\n",
      "Validation Loss: 0.2549, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.2731\n",
      "Validation Loss: 0.2731, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.2666\n",
      "Validation Loss: 0.2666, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.2463\n",
      "Validation Loss: 0.2463, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.2277\n",
      "Validation Loss: 0.2277, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.2147\n",
      "Validation Loss: 0.2147, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.2202\n",
      "Validation Loss: 0.2202, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0165\n",
      "    Validation Batch [1/1], Loss: 0.2347\n",
      "Validation Loss: 0.2347, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.2454\n",
      "Validation Loss: 0.2454, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.2604\n",
      "Validation Loss: 0.2604, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.2638\n",
      "Validation Loss: 0.2638, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.2733\n",
      "Validation Loss: 0.2733, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.2781\n",
      "Validation Loss: 0.2781, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.2770\n",
      "Validation Loss: 0.2770, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.2743\n",
      "Validation Loss: 0.2743, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.2769\n",
      "Validation Loss: 0.2769, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [683/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.2799\n",
      "Validation Loss: 0.2799, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.2622\n",
      "Validation Loss: 0.2622, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.2418\n",
      "Validation Loss: 0.2418, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.2242\n",
      "Validation Loss: 0.2242, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.2126\n",
      "Validation Loss: 0.2126, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.2185\n",
      "Validation Loss: 0.2185, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.2317\n",
      "Validation Loss: 0.2317, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.2470\n",
      "Validation Loss: 0.2470, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0340\n",
      "    Validation Batch [1/1], Loss: 0.2438\n",
      "Validation Loss: 0.2438, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.2467\n",
      "Validation Loss: 0.2467, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.2553\n",
      "Validation Loss: 0.2553, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.2630\n",
      "Validation Loss: 0.2630, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.2698\n",
      "Validation Loss: 0.2698, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.2705\n",
      "Validation Loss: 0.2705, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.2664\n",
      "Validation Loss: 0.2664, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.2728\n",
      "Validation Loss: 0.2728, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0167\n",
      "    Validation Batch [1/1], Loss: 0.2722\n",
      "Validation Loss: 0.2722, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.2664\n",
      "Validation Loss: 0.2664, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.2678\n",
      "Validation Loss: 0.2678, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.2712\n",
      "Validation Loss: 0.2712, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.2633\n",
      "Validation Loss: 0.2633, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.2488\n",
      "Validation Loss: 0.2488, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.2341\n",
      "Validation Loss: 0.2341, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.2308\n",
      "Validation Loss: 0.2308, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.2252\n",
      "Validation Loss: 0.2252, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.2247\n",
      "Validation Loss: 0.2247, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.2299\n",
      "Validation Loss: 0.2299, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [710/1000] completed, Average Training Loss: 0.0165\n",
      "    Validation Batch [1/1], Loss: 0.2295\n",
      "Validation Loss: 0.2295, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0222\n",
      "    Validation Batch [1/1], Loss: 0.2223\n",
      "Validation Loss: 0.2223, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.2247\n",
      "Validation Loss: 0.2247, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0198\n",
      "    Validation Batch [1/1], Loss: 0.2461\n",
      "Validation Loss: 0.2461, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0169\n",
      "    Validation Batch [1/1], Loss: 0.2670\n",
      "Validation Loss: 0.2670, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0185\n",
      "    Validation Batch [1/1], Loss: 0.2857\n",
      "Validation Loss: 0.2857, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0203\n",
      "    Validation Batch [1/1], Loss: 0.3000\n",
      "Validation Loss: 0.3000, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0127\n",
      "    Validation Batch [1/1], Loss: 0.2987\n",
      "Validation Loss: 0.2987, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.3035\n",
      "Validation Loss: 0.3035, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.2957\n",
      "Validation Loss: 0.2957, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.2927\n",
      "Validation Loss: 0.2927, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.2924\n",
      "Validation Loss: 0.2924, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.2880\n",
      "Validation Loss: 0.2880, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.2861\n",
      "Validation Loss: 0.2861, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2856\n",
      "Validation Loss: 0.2856, Validation Accuracy: 91.11%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.2866\n",
      "Validation Loss: 0.2866, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0182\n",
      "    Validation Batch [1/1], Loss: 0.2963\n",
      "Validation Loss: 0.2963, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.3206\n",
      "Validation Loss: 0.3206, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.3334\n",
      "Validation Loss: 0.3334, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.3299\n",
      "Validation Loss: 0.3299, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 729. No improvement for 100 epochs.\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/578], Loss: 0.1584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.0780, Test Accuracy: 98.13%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:14.984573Z",
     "iopub.status.busy": "2025-05-08T17:19:14.983571Z",
     "iopub.status.idle": "2025-05-08T17:19:17.663263Z",
     "shell.execute_reply": "2025-05-08T17:19:17.663263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/578 for test dataset.\n",
      "  Processed batch 20/578 for test dataset.\n",
      "  Processed batch 30/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 40/578 for test dataset.\n",
      "  Processed batch 50/578 for test dataset.\n",
      "  Processed batch 60/578 for test dataset.\n",
      "  Processed batch 70/578 for test dataset.\n",
      "  Processed batch 80/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 90/578 for test dataset.\n",
      "  Processed batch 100/578 for test dataset.\n",
      "  Processed batch 110/578 for test dataset.\n",
      "  Processed batch 120/578 for test dataset.\n",
      "  Processed batch 130/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 140/578 for test dataset.\n",
      "  Processed batch 150/578 for test dataset.\n",
      "  Processed batch 160/578 for test dataset.\n",
      "  Processed batch 170/578 for test dataset.\n",
      "  Processed batch 180/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 190/578 for test dataset.\n",
      "  Processed batch 200/578 for test dataset.\n",
      "  Processed batch 210/578 for test dataset.\n",
      "  Processed batch 220/578 for test dataset.\n",
      "  Processed batch 230/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 240/578 for test dataset.\n",
      "  Processed batch 250/578 for test dataset.\n",
      "  Processed batch 260/578 for test dataset.\n",
      "  Processed batch 270/578 for test dataset.\n",
      "  Processed batch 280/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 290/578 for test dataset.\n",
      "  Processed batch 300/578 for test dataset.\n",
      "  Processed batch 310/578 for test dataset.\n",
      "  Processed batch 320/578 for test dataset.\n",
      "  Processed batch 330/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 340/578 for test dataset.\n",
      "  Processed batch 350/578 for test dataset.\n",
      "  Processed batch 360/578 for test dataset.\n",
      "  Processed batch 370/578 for test dataset.\n",
      "  Processed batch 380/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 390/578 for test dataset.\n",
      "  Processed batch 400/578 for test dataset.\n",
      "  Processed batch 410/578 for test dataset.\n",
      "  Processed batch 420/578 for test dataset.\n",
      "  Processed batch 430/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 440/578 for test dataset.\n",
      "  Processed batch 450/578 for test dataset.\n",
      "  Processed batch 460/578 for test dataset.\n",
      "  Processed batch 470/578 for test dataset.\n",
      "  Processed batch 480/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 490/578 for test dataset.\n",
      "  Processed batch 500/578 for test dataset.\n",
      "  Processed batch 510/578 for test dataset.\n",
      "  Processed batch 520/578 for test dataset.\n",
      "  Processed batch 530/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 540/578 for test dataset.\n",
      "  Processed batch 550/578 for test dataset.\n",
      "  Processed batch 560/578 for test dataset.\n",
      "  Processed batch 570/578 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:17.665269Z",
     "iopub.status.busy": "2025-05-08T17:19:17.665269Z",
     "iopub.status.idle": "2025-05-08T17:19:17.669267Z",
     "shell.execute_reply": "2025-05-08T17:19:17.669267Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:17.671420Z",
     "iopub.status.busy": "2025-05-08T17:19:17.671420Z",
     "iopub.status.idle": "2025-05-08T17:19:22.921856Z",
     "shell.execute_reply": "2025-05-08T17:19:22.921856Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:22.924864Z",
     "iopub.status.busy": "2025-05-08T17:19:22.924864Z",
     "iopub.status.idle": "2025-05-08T17:19:22.928886Z",
     "shell.execute_reply": "2025-05-08T17:19:22.928886Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:22.931127Z",
     "iopub.status.busy": "2025-05-08T17:19:22.931127Z",
     "iopub.status.idle": "2025-05-08T17:19:26.937216Z",
     "shell.execute_reply": "2025-05-08T17:19:26.937216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "\n",
      "LOG: Training features shape: (180, 64), Training labels shape: (180,)\n",
      "LOG: Validation features shape: (45, 64), Validation labels shape: (45,)\n",
      "LOG: Test features shape: (147927, 64), Test labels shape: (147927,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 93.33%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.80      0.80      0.80         5\n",
      "           4       0.80      0.80      0.80         5\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.83      1.00      0.91         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 96.54%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65946\n",
      "           1       0.95      0.91      0.93      7573\n",
      "           2       0.78      0.88      0.83      3065\n",
      "           3       0.66      0.88      0.76      2660\n",
      "           4       0.87      0.88      0.88      6559\n",
      "           5       0.88      0.93      0.90      9223\n",
      "           6       0.91      0.86      0.88      7262\n",
      "           7       1.00      0.98      0.99     42801\n",
      "           8       1.00      1.00      1.00      2838\n",
      "\n",
      "    accuracy                           0.97    147927\n",
      "   macro avg       0.89      0.92      0.91    147927\n",
      "weighted avg       0.97      0.97      0.97    147927\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:26.940221Z",
     "iopub.status.busy": "2025-05-08T17:19:26.939222Z",
     "iopub.status.idle": "2025-05-08T17:19:26.944231Z",
     "shell.execute_reply": "2025-05-08T17:19:26.944231Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:26.946507Z",
     "iopub.status.busy": "2025-05-08T17:19:26.946507Z",
     "iopub.status.idle": "2025-05-08T17:19:27.094445Z",
     "shell.execute_reply": "2025-05-08T17:19:27.094445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "Train reps shape: (180, 64)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 64)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 64)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:27.096449Z",
     "iopub.status.busy": "2025-05-08T17:19:27.096449Z",
     "iopub.status.idle": "2025-05-08T17:19:27.107049Z",
     "shell.execute_reply": "2025-05-08T17:19:27.107049Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:27.110058Z",
     "iopub.status.busy": "2025-05-08T17:19:27.110058Z",
     "iopub.status.idle": "2025-05-08T17:19:28.286289Z",
     "shell.execute_reply": "2025-05-08T17:19:28.286289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.1622  |  Val Loss: 2.0443\n",
      "Validation loss improved from inf to 2.0443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/1000] Train Loss: 1.9969  |  Val Loss: 1.9440\n",
      "Validation loss improved from 2.0443 to 1.9440.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/1000] Train Loss: 1.8926  |  Val Loss: 1.8376\n",
      "Validation loss improved from 1.9440 to 1.8376.\n",
      "[Epoch 4/1000] Train Loss: 1.7762  |  Val Loss: 1.7255\n",
      "Validation loss improved from 1.8376 to 1.7255.\n",
      "[Epoch 5/1000] Train Loss: 1.6587  |  Val Loss: 1.6225\n",
      "Validation loss improved from 1.7255 to 1.6225.\n",
      "[Epoch 6/1000] Train Loss: 1.5554  |  Val Loss: 1.5200\n",
      "Validation loss improved from 1.6225 to 1.5200.\n",
      "[Epoch 7/1000] Train Loss: 1.4581  |  Val Loss: 1.4159\n",
      "Validation loss improved from 1.5200 to 1.4159.\n",
      "[Epoch 8/1000] Train Loss: 1.3608  |  Val Loss: 1.3251\n",
      "Validation loss improved from 1.4159 to 1.3251.\n",
      "[Epoch 9/1000] Train Loss: 1.2723  |  Val Loss: 1.2386\n",
      "Validation loss improved from 1.3251 to 1.2386.\n",
      "[Epoch 10/1000] Train Loss: 1.1892  |  Val Loss: 1.1596\n",
      "Validation loss improved from 1.2386 to 1.1596.\n",
      "[Epoch 11/1000] Train Loss: 1.1124  |  Val Loss: 1.0870\n",
      "Validation loss improved from 1.1596 to 1.0870.\n",
      "[Epoch 12/1000] Train Loss: 1.0432  |  Val Loss: 1.0220\n",
      "Validation loss improved from 1.0870 to 1.0220.\n",
      "[Epoch 13/1000] Train Loss: 0.9807  |  Val Loss: 0.9645\n",
      "Validation loss improved from 1.0220 to 0.9645.\n",
      "[Epoch 14/1000] Train Loss: 0.9230  |  Val Loss: 0.9102\n",
      "Validation loss improved from 0.9645 to 0.9102.\n",
      "[Epoch 15/1000] Train Loss: 0.8648  |  Val Loss: 0.8588\n",
      "Validation loss improved from 0.9102 to 0.8588.\n",
      "[Epoch 16/1000] Train Loss: 0.8174  |  Val Loss: 0.8072\n",
      "Validation loss improved from 0.8588 to 0.8072.\n",
      "[Epoch 17/1000] Train Loss: 0.7691  |  Val Loss: 0.7591\n",
      "Validation loss improved from 0.8072 to 0.7591.\n",
      "[Epoch 18/1000] Train Loss: 0.7246  |  Val Loss: 0.7112\n",
      "Validation loss improved from 0.7591 to 0.7112.\n",
      "[Epoch 19/1000] Train Loss: 0.6796  |  Val Loss: 0.6712\n",
      "Validation loss improved from 0.7112 to 0.6712.\n",
      "[Epoch 20/1000] Train Loss: 0.6360  |  Val Loss: 0.6316\n",
      "Validation loss improved from 0.6712 to 0.6316.\n",
      "[Epoch 21/1000] Train Loss: 0.5975  |  Val Loss: 0.5889\n",
      "Validation loss improved from 0.6316 to 0.5889.\n",
      "[Epoch 22/1000] Train Loss: 0.5562  |  Val Loss: 0.5537\n",
      "Validation loss improved from 0.5889 to 0.5537.\n",
      "[Epoch 23/1000] Train Loss: 0.5160  |  Val Loss: 0.5129\n",
      "Validation loss improved from 0.5537 to 0.5129.\n",
      "[Epoch 24/1000] Train Loss: 0.4771  |  Val Loss: 0.4760\n",
      "Validation loss improved from 0.5129 to 0.4760.\n",
      "[Epoch 25/1000] Train Loss: 0.4427  |  Val Loss: 0.4398\n",
      "Validation loss improved from 0.4760 to 0.4398.\n",
      "[Epoch 26/1000] Train Loss: 0.4096  |  Val Loss: 0.4119\n",
      "Validation loss improved from 0.4398 to 0.4119.\n",
      "[Epoch 27/1000] Train Loss: 0.3777  |  Val Loss: 0.3819\n",
      "Validation loss improved from 0.4119 to 0.3819.\n",
      "[Epoch 28/1000] Train Loss: 0.3534  |  Val Loss: 0.3634\n",
      "Validation loss improved from 0.3819 to 0.3634.\n",
      "[Epoch 29/1000] Train Loss: 0.3317  |  Val Loss: 0.3500\n",
      "Validation loss improved from 0.3634 to 0.3500.\n",
      "[Epoch 30/1000] Train Loss: 0.3146  |  Val Loss: 0.3263\n",
      "Validation loss improved from 0.3500 to 0.3263.\n",
      "[Epoch 31/1000] Train Loss: 0.2931  |  Val Loss: 0.3081\n",
      "Validation loss improved from 0.3263 to 0.3081.\n",
      "[Epoch 32/1000] Train Loss: 0.2745  |  Val Loss: 0.2894\n",
      "Validation loss improved from 0.3081 to 0.2894.\n",
      "[Epoch 33/1000] Train Loss: 0.2631  |  Val Loss: 0.2890\n",
      "Validation loss improved from 0.2894 to 0.2890.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 0.2491  |  Val Loss: 0.2703\n",
      "Validation loss improved from 0.2890 to 0.2703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/1000] Train Loss: 0.2355  |  Val Loss: 0.2574\n",
      "Validation loss improved from 0.2703 to 0.2574.\n",
      "[Epoch 36/1000] Train Loss: 0.2280  |  Val Loss: 0.2619\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 37/1000] Train Loss: 0.2172  |  Val Loss: 0.2637\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 38/1000] Train Loss: 0.2105  |  Val Loss: 0.2404\n",
      "Validation loss improved from 0.2574 to 0.2404.\n",
      "[Epoch 39/1000] Train Loss: 0.2024  |  Val Loss: 0.2474\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 40/1000] Train Loss: 0.1939  |  Val Loss: 0.2371\n",
      "Validation loss improved from 0.2404 to 0.2371.\n",
      "[Epoch 41/1000] Train Loss: 0.1917  |  Val Loss: 0.2415\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 42/1000] Train Loss: 0.1807  |  Val Loss: 0.2254\n",
      "Validation loss improved from 0.2371 to 0.2254.\n",
      "[Epoch 43/1000] Train Loss: 0.1763  |  Val Loss: 0.2239\n",
      "Validation loss improved from 0.2254 to 0.2239.\n",
      "[Epoch 44/1000] Train Loss: 0.1714  |  Val Loss: 0.2336\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 45/1000] Train Loss: 0.1664  |  Val Loss: 0.2327\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 46/1000] Train Loss: 0.1636  |  Val Loss: 0.2263\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 47/1000] Train Loss: 0.1602  |  Val Loss: 0.2140\n",
      "Validation loss improved from 0.2239 to 0.2140.\n",
      "[Epoch 48/1000] Train Loss: 0.1635  |  Val Loss: 0.2412\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 49/1000] Train Loss: 0.1520  |  Val Loss: 0.2287\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 50/1000] Train Loss: 0.1482  |  Val Loss: 0.2223\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 51/1000] Train Loss: 0.1457  |  Val Loss: 0.2367\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 52/1000] Train Loss: 0.1540  |  Val Loss: 0.2317\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 53/1000] Train Loss: 0.1397  |  Val Loss: 0.2111\n",
      "Validation loss improved from 0.2140 to 0.2111.\n",
      "[Epoch 54/1000] Train Loss: 0.1404  |  Val Loss: 0.2438\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 55/1000] Train Loss: 0.1357  |  Val Loss: 0.2617\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 56/1000] Train Loss: 0.1347  |  Val Loss: 0.2340\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 57/1000] Train Loss: 0.1331  |  Val Loss: 0.2042\n",
      "Validation loss improved from 0.2111 to 0.2042.\n",
      "[Epoch 58/1000] Train Loss: 0.1316  |  Val Loss: 0.2424\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 59/1000] Train Loss: 0.1287  |  Val Loss: 0.2769\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 60/1000] Train Loss: 0.1295  |  Val Loss: 0.2176\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 61/1000] Train Loss: 0.1247  |  Val Loss: 0.2206\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 62/1000] Train Loss: 0.1210  |  Val Loss: 0.2555\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 63/1000] Train Loss: 0.1179  |  Val Loss: 0.2426\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 64/1000] Train Loss: 0.1138  |  Val Loss: 0.2454\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 65/1000] Train Loss: 0.1212  |  Val Loss: 0.2300\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 66/1000] Train Loss: 0.1119  |  Val Loss: 0.2427\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 67/1000] Train Loss: 0.1127  |  Val Loss: 0.2719\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] Train Loss: 0.1109  |  Val Loss: 0.2521\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 69/1000] Train Loss: 0.1068  |  Val Loss: 0.2266\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 70/1000] Train Loss: 0.1071  |  Val Loss: 0.2571\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 71/1000] Train Loss: 0.1036  |  Val Loss: 0.2696\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 72/1000] Train Loss: 0.1006  |  Val Loss: 0.2400\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 73/1000] Train Loss: 0.0991  |  Val Loss: 0.2503\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 74/1000] Train Loss: 0.0954  |  Val Loss: 0.2790\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 75/1000] Train Loss: 0.0990  |  Val Loss: 0.2701\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 76/1000] Train Loss: 0.0897  |  Val Loss: 0.2484\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 77/1000] Train Loss: 0.0929  |  Val Loss: 0.2477\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 78/1000] Train Loss: 0.0887  |  Val Loss: 0.2708\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 79/1000] Train Loss: 0.0893  |  Val Loss: 0.2662\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 80/1000] Train Loss: 0.0869  |  Val Loss: 0.2684\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 81/1000] Train Loss: 0.0835  |  Val Loss: 0.2649\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 82/1000] Train Loss: 0.0828  |  Val Loss: 0.2666\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 83/1000] Train Loss: 0.0806  |  Val Loss: 0.2754\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 84/1000] Train Loss: 0.0821  |  Val Loss: 0.2735\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 85/1000] Train Loss: 0.0805  |  Val Loss: 0.2850\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 86/1000] Train Loss: 0.0792  |  Val Loss: 0.2704\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 87/1000] Train Loss: 0.0775  |  Val Loss: 0.2766\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 88/1000] Train Loss: 0.0775  |  Val Loss: 0.2738\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 89/1000] Train Loss: 0.0767  |  Val Loss: 0.2951\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 90/1000] Train Loss: 0.0736  |  Val Loss: 0.2848\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 91/1000] Train Loss: 0.0785  |  Val Loss: 0.2741\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 92/1000] Train Loss: 0.0724  |  Val Loss: 0.2971\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 93/1000] Train Loss: 0.0790  |  Val Loss: 0.3079\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 94/1000] Train Loss: 0.0695  |  Val Loss: 0.2723\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 95/1000] Train Loss: 0.0696  |  Val Loss: 0.2947\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 96/1000] Train Loss: 0.0648  |  Val Loss: 0.2959\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 97/1000] Train Loss: 0.0634  |  Val Loss: 0.2883\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 98/1000] Train Loss: 0.0645  |  Val Loss: 0.3073\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 99/1000] Train Loss: 0.0610  |  Val Loss: 0.2948\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 100/1000] Train Loss: 0.0596  |  Val Loss: 0.3057\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 101/1000] Train Loss: 0.0590  |  Val Loss: 0.3001\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 102/1000] Train Loss: 0.0563  |  Val Loss: 0.3125\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 103/1000] Train Loss: 0.0573  |  Val Loss: 0.3171\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 104/1000] Train Loss: 0.0545  |  Val Loss: 0.3065\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 105/1000] Train Loss: 0.0568  |  Val Loss: 0.3118\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 106/1000] Train Loss: 0.0562  |  Val Loss: 0.3364\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 107/1000] Train Loss: 0.0533  |  Val Loss: 0.3232\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 108/1000] Train Loss: 0.0532  |  Val Loss: 0.3124\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 109/1000] Train Loss: 0.0532  |  Val Loss: 0.3151\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 110/1000] Train Loss: 0.0504  |  Val Loss: 0.3348\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 111/1000] Train Loss: 0.0486  |  Val Loss: 0.3480\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 112/1000] Train Loss: 0.0490  |  Val Loss: 0.3319\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 113/1000] Train Loss: 0.0502  |  Val Loss: 0.3259\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 114/1000] Train Loss: 0.0461  |  Val Loss: 0.3483\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 115/1000] Train Loss: 0.0468  |  Val Loss: 0.3467\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 116/1000] Train Loss: 0.0447  |  Val Loss: 0.3367\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 117/1000] Train Loss: 0.0437  |  Val Loss: 0.3365\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 118/1000] Train Loss: 0.0423  |  Val Loss: 0.3463\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 119/1000] Train Loss: 0.0436  |  Val Loss: 0.3464\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 120/1000] Train Loss: 0.0453  |  Val Loss: 0.3548\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 121/1000] Train Loss: 0.0402  |  Val Loss: 0.3324\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 122/1000] Train Loss: 0.0412  |  Val Loss: 0.3611\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 123/1000] Train Loss: 0.0438  |  Val Loss: 0.3865\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 124/1000] Train Loss: 0.0386  |  Val Loss: 0.3282\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 125/1000] Train Loss: 0.0404  |  Val Loss: 0.3506\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 126/1000] Train Loss: 0.0373  |  Val Loss: 0.3820\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 127/1000] Train Loss: 0.0375  |  Val Loss: 0.3556\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 128/1000] Train Loss: 0.0374  |  Val Loss: 0.3648\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 129/1000] Train Loss: 0.0342  |  Val Loss: 0.3889\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 130/1000] Train Loss: 0.0424  |  Val Loss: 0.3754\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 131/1000] Train Loss: 0.0335  |  Val Loss: 0.3636\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 132/1000] Train Loss: 0.0423  |  Val Loss: 0.3964\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 133/1000] Train Loss: 0.0322  |  Val Loss: 0.4039\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 134/1000] Train Loss: 0.0348  |  Val Loss: 0.3745\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 135/1000] Train Loss: 0.0353  |  Val Loss: 0.3702\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 136/1000] Train Loss: 0.0298  |  Val Loss: 0.4168\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 137/1000] Train Loss: 0.0325  |  Val Loss: 0.3996\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 138/1000] Train Loss: 0.0294  |  Val Loss: 0.3644\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 139/1000] Train Loss: 0.0293  |  Val Loss: 0.3897\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 140/1000] Train Loss: 0.0299  |  Val Loss: 0.4203\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 141/1000] Train Loss: 0.0302  |  Val Loss: 0.3813\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 142/1000] Train Loss: 0.0270  |  Val Loss: 0.4020\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 143/1000] Train Loss: 0.0251  |  Val Loss: 0.4111\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 144/1000] Train Loss: 0.0270  |  Val Loss: 0.3952\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 145/1000] Train Loss: 0.0257  |  Val Loss: 0.4063\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 146/1000] Train Loss: 0.0256  |  Val Loss: 0.3959\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 147/1000] Train Loss: 0.0239  |  Val Loss: 0.3950\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 148/1000] Train Loss: 0.0245  |  Val Loss: 0.4215\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 149/1000] Train Loss: 0.0230  |  Val Loss: 0.4146\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 150/1000] Train Loss: 0.0246  |  Val Loss: 0.4146\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 151/1000] Train Loss: 0.0215  |  Val Loss: 0.4347\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 152/1000] Train Loss: 0.0241  |  Val Loss: 0.4326\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 153/1000] Train Loss: 0.0222  |  Val Loss: 0.3945\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 154/1000] Train Loss: 0.0229  |  Val Loss: 0.4155\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 155/1000] Train Loss: 0.0203  |  Val Loss: 0.4437\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 156/1000] Train Loss: 0.0212  |  Val Loss: 0.4465\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 157/1000] Train Loss: 0.0198  |  Val Loss: 0.4168\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 157 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:28.289295Z",
     "iopub.status.busy": "2025-05-08T17:19:28.289295Z",
     "iopub.status.idle": "2025-05-08T17:19:30.643416Z",
     "shell.execute_reply": "2025-05-08T17:19:30.643416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.1349 | Test Accuracy: 96.68%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:30.646425Z",
     "iopub.status.busy": "2025-05-08T17:19:30.645425Z",
     "iopub.status.idle": "2025-05-08T17:19:30.804415Z",
     "shell.execute_reply": "2025-05-08T17:19:30.804415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (180, 64), \n",
      "Train labels shape: (180,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (45, 64), \n",
      "Val labels shape: (45,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (147927, 64), \n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:30.806420Z",
     "iopub.status.busy": "2025-05-08T17:19:30.806420Z",
     "iopub.status.idle": "2025-05-08T17:19:30.845220Z",
     "shell.execute_reply": "2025-05-08T17:19:30.845220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n",
      "Training batch size: 180\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:30.848226Z",
     "iopub.status.busy": "2025-05-08T17:19:30.848226Z",
     "iopub.status.idle": "2025-05-08T17:19:30.853224Z",
     "shell.execute_reply": "2025-05-08T17:19:30.853224Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:30.855570Z",
     "iopub.status.busy": "2025-05-08T17:19:30.855570Z",
     "iopub.status.idle": "2025-05-08T17:19:30.859002Z",
     "shell.execute_reply": "2025-05-08T17:19:30.859002Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:30.861005Z",
     "iopub.status.busy": "2025-05-08T17:19:30.861005Z",
     "iopub.status.idle": "2025-05-08T17:19:40.186858Z",
     "shell.execute_reply": "2025-05-08T17:19:40.186858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 8.5591\n",
      "Epoch [1/2000], Avg Train Loss: 8.5591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Avg Val Loss: 4.0750\n",
      "Validation loss improved from inf to 4.0750. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.5680\n",
      "Epoch [2/2000], Avg Train Loss: 8.5680\n",
      "Epoch [2/2000], Avg Val Loss: 4.0252\n",
      "Validation loss improved from 4.0750 to 4.0252. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.4894\n",
      "Epoch [3/2000], Avg Train Loss: 8.4894\n",
      "Epoch [3/2000], Avg Val Loss: 3.9771\n",
      "Validation loss improved from 4.0252 to 3.9771. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3201\n",
      "Epoch [4/2000], Avg Train Loss: 8.3201\n",
      "Epoch [4/2000], Avg Val Loss: 3.9303\n",
      "Validation loss improved from 3.9771 to 3.9303. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3097\n",
      "Epoch [5/2000], Avg Train Loss: 8.3097\n",
      "Epoch [5/2000], Avg Val Loss: 3.8846\n",
      "Validation loss improved from 3.9303 to 3.8846. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3453\n",
      "Epoch [6/2000], Avg Train Loss: 8.3453\n",
      "Epoch [6/2000], Avg Val Loss: 3.8402\n",
      "Validation loss improved from 3.8846 to 3.8402. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3158\n",
      "Epoch [7/2000], Avg Train Loss: 8.3158\n",
      "Epoch [7/2000], Avg Val Loss: 3.7971\n",
      "Validation loss improved from 3.8402 to 3.7971. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9523\n",
      "Epoch [8/2000], Avg Train Loss: 7.9523\n",
      "Epoch [8/2000], Avg Val Loss: 3.7551\n",
      "Validation loss improved from 3.7971 to 3.7551. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9939\n",
      "Epoch [9/2000], Avg Train Loss: 7.9939\n",
      "Epoch [9/2000], Avg Val Loss: 3.7143\n",
      "Validation loss improved from 3.7551 to 3.7143. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8935\n",
      "Epoch [10/2000], Avg Train Loss: 7.8935\n",
      "Epoch [10/2000], Avg Val Loss: 3.6748\n",
      "Validation loss improved from 3.7143 to 3.6748. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8445\n",
      "Epoch [11/2000], Avg Train Loss: 7.8445\n",
      "Epoch [11/2000], Avg Val Loss: 3.6364\n",
      "Validation loss improved from 3.6748 to 3.6364. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6721\n",
      "Epoch [12/2000], Avg Train Loss: 7.6721\n",
      "Epoch [12/2000], Avg Val Loss: 3.5990\n",
      "Validation loss improved from 3.6364 to 3.5990. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7223\n",
      "Epoch [13/2000], Avg Train Loss: 7.7223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/2000], Avg Val Loss: 3.5627\n",
      "Validation loss improved from 3.5990 to 3.5627. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6834\n",
      "Epoch [14/2000], Avg Train Loss: 7.6834\n",
      "Epoch [14/2000], Avg Val Loss: 3.5276\n",
      "Validation loss improved from 3.5627 to 3.5276. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5735\n",
      "Epoch [15/2000], Avg Train Loss: 7.5735\n",
      "Epoch [15/2000], Avg Val Loss: 3.4936\n",
      "Validation loss improved from 3.5276 to 3.4936. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5042\n",
      "Epoch [16/2000], Avg Train Loss: 7.5042\n",
      "Epoch [16/2000], Avg Val Loss: 3.4607\n",
      "Validation loss improved from 3.4936 to 3.4607. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4265\n",
      "Epoch [17/2000], Avg Train Loss: 7.4265\n",
      "Epoch [17/2000], Avg Val Loss: 3.4289\n",
      "Validation loss improved from 3.4607 to 3.4289. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4453\n",
      "Epoch [18/2000], Avg Train Loss: 7.4453\n",
      "Epoch [18/2000], Avg Val Loss: 3.3980\n",
      "Validation loss improved from 3.4289 to 3.3980. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3434\n",
      "Epoch [19/2000], Avg Train Loss: 7.3434\n",
      "Epoch [19/2000], Avg Val Loss: 3.3682\n",
      "Validation loss improved from 3.3980 to 3.3682. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2519\n",
      "Epoch [20/2000], Avg Train Loss: 7.2519\n",
      "Epoch [20/2000], Avg Val Loss: 3.3396\n",
      "Validation loss improved from 3.3682 to 3.3396. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0440\n",
      "Epoch [21/2000], Avg Train Loss: 7.0440\n",
      "Epoch [21/2000], Avg Val Loss: 3.3120\n",
      "Validation loss improved from 3.3396 to 3.3120. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0789\n",
      "Epoch [22/2000], Avg Train Loss: 7.0789\n",
      "Epoch [22/2000], Avg Val Loss: 3.2853\n",
      "Validation loss improved from 3.3120 to 3.2853. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1971\n",
      "Epoch [23/2000], Avg Train Loss: 7.1971\n",
      "Epoch [23/2000], Avg Val Loss: 3.2596\n",
      "Validation loss improved from 3.2853 to 3.2596. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8870\n",
      "Epoch [24/2000], Avg Train Loss: 6.8870\n",
      "Epoch [24/2000], Avg Val Loss: 3.2349\n",
      "Validation loss improved from 3.2596 to 3.2349. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8902\n",
      "Epoch [25/2000], Avg Train Loss: 6.8902\n",
      "Epoch [25/2000], Avg Val Loss: 3.2110\n",
      "Validation loss improved from 3.2349 to 3.2110. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8856\n",
      "Epoch [26/2000], Avg Train Loss: 6.8856\n",
      "Epoch [26/2000], Avg Val Loss: 3.1879\n",
      "Validation loss improved from 3.2110 to 3.1879. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9346\n",
      "Epoch [27/2000], Avg Train Loss: 6.9346\n",
      "Epoch [27/2000], Avg Val Loss: 3.1656\n",
      "Validation loss improved from 3.1879 to 3.1656. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6109\n",
      "Epoch [28/2000], Avg Train Loss: 6.6109\n",
      "Epoch [28/2000], Avg Val Loss: 3.1441\n",
      "Validation loss improved from 3.1656 to 3.1441. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6314\n",
      "Epoch [29/2000], Avg Train Loss: 6.6314\n",
      "Epoch [29/2000], Avg Val Loss: 3.1233\n",
      "Validation loss improved from 3.1441 to 3.1233. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6835\n",
      "Epoch [30/2000], Avg Train Loss: 6.6835\n",
      "Epoch [30/2000], Avg Val Loss: 3.1034\n",
      "Validation loss improved from 3.1233 to 3.1034. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5054\n",
      "Epoch [31/2000], Avg Train Loss: 6.5054\n",
      "Epoch [31/2000], Avg Val Loss: 3.0843\n",
      "Validation loss improved from 3.1034 to 3.0843. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6285\n",
      "Epoch [32/2000], Avg Train Loss: 6.6285\n",
      "Epoch [32/2000], Avg Val Loss: 3.0660\n",
      "Validation loss improved from 3.0843 to 3.0660. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4448\n",
      "Epoch [33/2000], Avg Train Loss: 6.4448\n",
      "Epoch [33/2000], Avg Val Loss: 3.0485\n",
      "Validation loss improved from 3.0660 to 3.0485. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4113\n",
      "Epoch [34/2000], Avg Train Loss: 6.4113\n",
      "Epoch [34/2000], Avg Val Loss: 3.0318\n",
      "Validation loss improved from 3.0485 to 3.0318. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3159\n",
      "Epoch [35/2000], Avg Train Loss: 6.3159\n",
      "Epoch [35/2000], Avg Val Loss: 3.0157\n",
      "Validation loss improved from 3.0318 to 3.0157. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3368\n",
      "Epoch [36/2000], Avg Train Loss: 6.3368\n",
      "Epoch [36/2000], Avg Val Loss: 3.0003\n",
      "Validation loss improved from 3.0157 to 3.0003. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3809\n",
      "Epoch [37/2000], Avg Train Loss: 6.3809\n",
      "Epoch [37/2000], Avg Val Loss: 2.9855\n",
      "Validation loss improved from 3.0003 to 2.9855. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3238\n",
      "Epoch [38/2000], Avg Train Loss: 6.3238\n",
      "Epoch [38/2000], Avg Val Loss: 2.9713\n",
      "Validation loss improved from 2.9855 to 2.9713. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3444\n",
      "Epoch [39/2000], Avg Train Loss: 6.3444\n",
      "Epoch [39/2000], Avg Val Loss: 2.9577\n",
      "Validation loss improved from 2.9713 to 2.9577. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1994\n",
      "Epoch [40/2000], Avg Train Loss: 6.1994\n",
      "Epoch [40/2000], Avg Val Loss: 2.9447\n",
      "Validation loss improved from 2.9577 to 2.9447. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2045\n",
      "Epoch [41/2000], Avg Train Loss: 6.2045\n",
      "Epoch [41/2000], Avg Val Loss: 2.9323\n",
      "Validation loss improved from 2.9447 to 2.9323. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9958\n",
      "Epoch [42/2000], Avg Train Loss: 5.9958\n",
      "Epoch [42/2000], Avg Val Loss: 2.9204\n",
      "Validation loss improved from 2.9323 to 2.9204. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.0773\n",
      "Epoch [43/2000], Avg Train Loss: 6.0773\n",
      "Epoch [43/2000], Avg Val Loss: 2.9090\n",
      "Validation loss improved from 2.9204 to 2.9090. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9741\n",
      "Epoch [44/2000], Avg Train Loss: 5.9741\n",
      "Epoch [44/2000], Avg Val Loss: 2.8981\n",
      "Validation loss improved from 2.9090 to 2.8981. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9859\n",
      "Epoch [45/2000], Avg Train Loss: 5.9859\n",
      "Epoch [45/2000], Avg Val Loss: 2.8876\n",
      "Validation loss improved from 2.8981 to 2.8876. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9881\n",
      "Epoch [46/2000], Avg Train Loss: 5.9881\n",
      "Epoch [46/2000], Avg Val Loss: 2.8775\n",
      "Validation loss improved from 2.8876 to 2.8775. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8147\n",
      "Epoch [47/2000], Avg Train Loss: 5.8147\n",
      "Epoch [47/2000], Avg Val Loss: 2.8680\n",
      "Validation loss improved from 2.8775 to 2.8680. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8071\n",
      "Epoch [48/2000], Avg Train Loss: 5.8071\n",
      "Epoch [48/2000], Avg Val Loss: 2.8588\n",
      "Validation loss improved from 2.8680 to 2.8588. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7326\n",
      "Epoch [49/2000], Avg Train Loss: 5.7326\n",
      "Epoch [49/2000], Avg Val Loss: 2.8501\n",
      "Validation loss improved from 2.8588 to 2.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7871\n",
      "Epoch [50/2000], Avg Train Loss: 5.7871\n",
      "Epoch [50/2000], Avg Val Loss: 2.8417\n",
      "Validation loss improved from 2.8501 to 2.8417. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6930\n",
      "Epoch [51/2000], Avg Train Loss: 5.6930\n",
      "Epoch [51/2000], Avg Val Loss: 2.8337\n",
      "Validation loss improved from 2.8417 to 2.8337. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6395\n",
      "Epoch [52/2000], Avg Train Loss: 5.6395\n",
      "Epoch [52/2000], Avg Val Loss: 2.8260\n",
      "Validation loss improved from 2.8337 to 2.8260. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6694\n",
      "Epoch [53/2000], Avg Train Loss: 5.6694\n",
      "Epoch [53/2000], Avg Val Loss: 2.8187\n",
      "Validation loss improved from 2.8260 to 2.8187. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5873\n",
      "Epoch [54/2000], Avg Train Loss: 5.5873\n",
      "Epoch [54/2000], Avg Val Loss: 2.8118\n",
      "Validation loss improved from 2.8187 to 2.8118. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6803\n",
      "Epoch [55/2000], Avg Train Loss: 5.6803\n",
      "Epoch [55/2000], Avg Val Loss: 2.8051\n",
      "Validation loss improved from 2.8118 to 2.8051. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6474\n",
      "Epoch [56/2000], Avg Train Loss: 5.6474\n",
      "Epoch [56/2000], Avg Val Loss: 2.7987\n",
      "Validation loss improved from 2.8051 to 2.7987. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.5903\n",
      "Epoch [57/2000], Avg Train Loss: 5.5903\n",
      "Epoch [57/2000], Avg Val Loss: 2.7926\n",
      "Validation loss improved from 2.7987 to 2.7926. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5848\n",
      "Epoch [58/2000], Avg Train Loss: 5.5848\n",
      "Epoch [58/2000], Avg Val Loss: 2.7868\n",
      "Validation loss improved from 2.7926 to 2.7868. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4493\n",
      "Epoch [59/2000], Avg Train Loss: 5.4493\n",
      "Epoch [59/2000], Avg Val Loss: 2.7812\n",
      "Validation loss improved from 2.7868 to 2.7812. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4390\n",
      "Epoch [60/2000], Avg Train Loss: 5.4390\n",
      "Epoch [60/2000], Avg Val Loss: 2.7758\n",
      "Validation loss improved from 2.7812 to 2.7758. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3891\n",
      "Epoch [61/2000], Avg Train Loss: 5.3891\n",
      "Epoch [61/2000], Avg Val Loss: 2.7707\n",
      "Validation loss improved from 2.7758 to 2.7707. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3396\n",
      "Epoch [62/2000], Avg Train Loss: 5.3396\n",
      "Epoch [62/2000], Avg Val Loss: 2.7658\n",
      "Validation loss improved from 2.7707 to 2.7658. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3888\n",
      "Epoch [63/2000], Avg Train Loss: 5.3888\n",
      "Epoch [63/2000], Avg Val Loss: 2.7611\n",
      "Validation loss improved from 2.7658 to 2.7611. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2682\n",
      "Epoch [64/2000], Avg Train Loss: 5.2682\n",
      "Epoch [64/2000], Avg Val Loss: 2.7565\n",
      "Validation loss improved from 2.7611 to 2.7565. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3309\n",
      "Epoch [65/2000], Avg Train Loss: 5.3309\n",
      "Epoch [65/2000], Avg Val Loss: 2.7522\n",
      "Validation loss improved from 2.7565 to 2.7522. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3292\n",
      "Epoch [66/2000], Avg Train Loss: 5.3292\n",
      "Epoch [66/2000], Avg Val Loss: 2.7481\n",
      "Validation loss improved from 2.7522 to 2.7481. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2577\n",
      "Epoch [67/2000], Avg Train Loss: 5.2577\n",
      "Epoch [67/2000], Avg Val Loss: 2.7442\n",
      "Validation loss improved from 2.7481 to 2.7442. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3088\n",
      "Epoch [68/2000], Avg Train Loss: 5.3088\n",
      "Epoch [68/2000], Avg Val Loss: 2.7405\n",
      "Validation loss improved from 2.7442 to 2.7405. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1908\n",
      "Epoch [69/2000], Avg Train Loss: 5.1908\n",
      "Epoch [69/2000], Avg Val Loss: 2.7369\n",
      "Validation loss improved from 2.7405 to 2.7369. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2408\n",
      "Epoch [70/2000], Avg Train Loss: 5.2408\n",
      "Epoch [70/2000], Avg Val Loss: 2.7335\n",
      "Validation loss improved from 2.7369 to 2.7335. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2563\n",
      "Epoch [71/2000], Avg Train Loss: 5.2563\n",
      "Epoch [71/2000], Avg Val Loss: 2.7302\n",
      "Validation loss improved from 2.7335 to 2.7302. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1887\n",
      "Epoch [72/2000], Avg Train Loss: 5.1887\n",
      "Epoch [72/2000], Avg Val Loss: 2.7270\n",
      "Validation loss improved from 2.7302 to 2.7270. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1589\n",
      "Epoch [73/2000], Avg Train Loss: 5.1589\n",
      "Epoch [73/2000], Avg Val Loss: 2.7239\n",
      "Validation loss improved from 2.7270 to 2.7239. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0640\n",
      "Epoch [74/2000], Avg Train Loss: 5.0640\n",
      "Epoch [74/2000], Avg Val Loss: 2.7210\n",
      "Validation loss improved from 2.7239 to 2.7210. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1349\n",
      "Epoch [75/2000], Avg Train Loss: 5.1349\n",
      "Epoch [75/2000], Avg Val Loss: 2.7181\n",
      "Validation loss improved from 2.7210 to 2.7181. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0335\n",
      "Epoch [76/2000], Avg Train Loss: 5.0335\n",
      "Epoch [76/2000], Avg Val Loss: 2.7154\n",
      "Validation loss improved from 2.7181 to 2.7154. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0456\n",
      "Epoch [77/2000], Avg Train Loss: 5.0456\n",
      "Epoch [77/2000], Avg Val Loss: 2.7127\n",
      "Validation loss improved from 2.7154 to 2.7127. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1177\n",
      "Epoch [78/2000], Avg Train Loss: 5.1177\n",
      "Epoch [78/2000], Avg Val Loss: 2.7102\n",
      "Validation loss improved from 2.7127 to 2.7102. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1146\n",
      "Epoch [79/2000], Avg Train Loss: 5.1146\n",
      "Epoch [79/2000], Avg Val Loss: 2.7077\n",
      "Validation loss improved from 2.7102 to 2.7077. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1506\n",
      "Epoch [80/2000], Avg Train Loss: 5.1506\n",
      "Epoch [80/2000], Avg Val Loss: 2.7052\n",
      "Validation loss improved from 2.7077 to 2.7052. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0758\n",
      "Epoch [81/2000], Avg Train Loss: 5.0758\n",
      "Epoch [81/2000], Avg Val Loss: 2.7029\n",
      "Validation loss improved from 2.7052 to 2.7029. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.9568\n",
      "Epoch [82/2000], Avg Train Loss: 4.9568\n",
      "Epoch [82/2000], Avg Val Loss: 2.7006\n",
      "Validation loss improved from 2.7029 to 2.7006. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0862\n",
      "Epoch [83/2000], Avg Train Loss: 5.0862\n",
      "Epoch [83/2000], Avg Val Loss: 2.6984\n",
      "Validation loss improved from 2.7006 to 2.6984. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1351\n",
      "Epoch [84/2000], Avg Train Loss: 5.1351\n",
      "Epoch [84/2000], Avg Val Loss: 2.6963\n",
      "Validation loss improved from 2.6984 to 2.6963. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9271\n",
      "Epoch [85/2000], Avg Train Loss: 4.9271\n",
      "Epoch [85/2000], Avg Val Loss: 2.6942\n",
      "Validation loss improved from 2.6963 to 2.6942. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9853\n",
      "Epoch [86/2000], Avg Train Loss: 4.9853\n",
      "Epoch [86/2000], Avg Val Loss: 2.6921\n",
      "Validation loss improved from 2.6942 to 2.6921. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9430\n",
      "Epoch [87/2000], Avg Train Loss: 4.9430\n",
      "Epoch [87/2000], Avg Val Loss: 2.6901\n",
      "Validation loss improved from 2.6921 to 2.6901. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8941\n",
      "Epoch [88/2000], Avg Train Loss: 4.8941\n",
      "Epoch [88/2000], Avg Val Loss: 2.6881\n",
      "Validation loss improved from 2.6901 to 2.6881. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9422\n",
      "Epoch [89/2000], Avg Train Loss: 4.9422\n",
      "Epoch [89/2000], Avg Val Loss: 2.6862\n",
      "Validation loss improved from 2.6881 to 2.6862. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8967\n",
      "Epoch [90/2000], Avg Train Loss: 4.8967\n",
      "Epoch [90/2000], Avg Val Loss: 2.6843\n",
      "Validation loss improved from 2.6862 to 2.6843. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8966\n",
      "Epoch [91/2000], Avg Train Loss: 4.8966\n",
      "Epoch [91/2000], Avg Val Loss: 2.6825\n",
      "Validation loss improved from 2.6843 to 2.6825. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8864\n",
      "Epoch [92/2000], Avg Train Loss: 4.8864\n",
      "Epoch [92/2000], Avg Val Loss: 2.6806\n",
      "Validation loss improved from 2.6825 to 2.6806. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9101\n",
      "Epoch [93/2000], Avg Train Loss: 4.9101\n",
      "Epoch [93/2000], Avg Val Loss: 2.6788\n",
      "Validation loss improved from 2.6806 to 2.6788. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8830\n",
      "Epoch [94/2000], Avg Train Loss: 4.8830\n",
      "Epoch [94/2000], Avg Val Loss: 2.6771\n",
      "Validation loss improved from 2.6788 to 2.6771. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9397\n",
      "Epoch [95/2000], Avg Train Loss: 4.9397\n",
      "Epoch [95/2000], Avg Val Loss: 2.6754\n",
      "Validation loss improved from 2.6771 to 2.6754. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9146\n",
      "Epoch [96/2000], Avg Train Loss: 4.9146\n",
      "Epoch [96/2000], Avg Val Loss: 2.6737\n",
      "Validation loss improved from 2.6754 to 2.6737. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8826\n",
      "Epoch [97/2000], Avg Train Loss: 4.8826\n",
      "Epoch [97/2000], Avg Val Loss: 2.6721\n",
      "Validation loss improved from 2.6737 to 2.6721. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8071\n",
      "Epoch [98/2000], Avg Train Loss: 4.8071\n",
      "Epoch [98/2000], Avg Val Loss: 2.6705\n",
      "Validation loss improved from 2.6721 to 2.6705. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7614\n",
      "Epoch [99/2000], Avg Train Loss: 4.7614\n",
      "Epoch [99/2000], Avg Val Loss: 2.6688\n",
      "Validation loss improved from 2.6705 to 2.6688. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7932\n",
      "Epoch [100/2000], Avg Train Loss: 4.7932\n",
      "Epoch [100/2000], Avg Val Loss: 2.6672\n",
      "Validation loss improved from 2.6688 to 2.6672. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7930\n",
      "Epoch [101/2000], Avg Train Loss: 4.7930\n",
      "Epoch [101/2000], Avg Val Loss: 2.6656\n",
      "Validation loss improved from 2.6672 to 2.6656. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8317\n",
      "Epoch [102/2000], Avg Train Loss: 4.8317\n",
      "Epoch [102/2000], Avg Val Loss: 2.6640\n",
      "Validation loss improved from 2.6656 to 2.6640. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7108\n",
      "Epoch [103/2000], Avg Train Loss: 4.7108\n",
      "Epoch [103/2000], Avg Val Loss: 2.6625\n",
      "Validation loss improved from 2.6640 to 2.6625. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6968\n",
      "Epoch [104/2000], Avg Train Loss: 4.6968\n",
      "Epoch [104/2000], Avg Val Loss: 2.6610\n",
      "Validation loss improved from 2.6625 to 2.6610. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7493\n",
      "Epoch [105/2000], Avg Train Loss: 4.7493\n",
      "Epoch [105/2000], Avg Val Loss: 2.6595\n",
      "Validation loss improved from 2.6610 to 2.6595. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7723\n",
      "Epoch [106/2000], Avg Train Loss: 4.7723\n",
      "Epoch [106/2000], Avg Val Loss: 2.6580\n",
      "Validation loss improved from 2.6595 to 2.6580. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7707\n",
      "Epoch [107/2000], Avg Train Loss: 4.7707\n",
      "Epoch [107/2000], Avg Val Loss: 2.6565\n",
      "Validation loss improved from 2.6580 to 2.6565. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7745\n",
      "Epoch [108/2000], Avg Train Loss: 4.7745\n",
      "Epoch [108/2000], Avg Val Loss: 2.6550\n",
      "Validation loss improved from 2.6565 to 2.6550. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6898\n",
      "Epoch [109/2000], Avg Train Loss: 4.6898\n",
      "Epoch [109/2000], Avg Val Loss: 2.6535\n",
      "Validation loss improved from 2.6550 to 2.6535. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7430\n",
      "Epoch [110/2000], Avg Train Loss: 4.7430\n",
      "Epoch [110/2000], Avg Val Loss: 2.6520\n",
      "Validation loss improved from 2.6535 to 2.6520. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7203\n",
      "Epoch [111/2000], Avg Train Loss: 4.7203\n",
      "Epoch [111/2000], Avg Val Loss: 2.6505\n",
      "Validation loss improved from 2.6520 to 2.6505. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6963\n",
      "Epoch [112/2000], Avg Train Loss: 4.6963\n",
      "Epoch [112/2000], Avg Val Loss: 2.6491\n",
      "Validation loss improved from 2.6505 to 2.6491. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6461\n",
      "Epoch [113/2000], Avg Train Loss: 4.6461\n",
      "Epoch [113/2000], Avg Val Loss: 2.6476\n",
      "Validation loss improved from 2.6491 to 2.6476. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7106\n",
      "Epoch [114/2000], Avg Train Loss: 4.7106\n",
      "Epoch [114/2000], Avg Val Loss: 2.6462\n",
      "Validation loss improved from 2.6476 to 2.6462. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7232\n",
      "Epoch [115/2000], Avg Train Loss: 4.7232\n",
      "Epoch [115/2000], Avg Val Loss: 2.6447\n",
      "Validation loss improved from 2.6462 to 2.6447. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6935\n",
      "Epoch [116/2000], Avg Train Loss: 4.6935\n",
      "Epoch [116/2000], Avg Val Loss: 2.6433\n",
      "Validation loss improved from 2.6447 to 2.6433. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5939\n",
      "Epoch [117/2000], Avg Train Loss: 4.5939\n",
      "Epoch [117/2000], Avg Val Loss: 2.6419\n",
      "Validation loss improved from 2.6433 to 2.6419. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7547\n",
      "Epoch [118/2000], Avg Train Loss: 4.7547\n",
      "Epoch [118/2000], Avg Val Loss: 2.6405\n",
      "Validation loss improved from 2.6419 to 2.6405. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7169\n",
      "Epoch [119/2000], Avg Train Loss: 4.7169\n",
      "Epoch [119/2000], Avg Val Loss: 2.6391\n",
      "Validation loss improved from 2.6405 to 2.6391. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5485\n",
      "Epoch [120/2000], Avg Train Loss: 4.5485\n",
      "Epoch [120/2000], Avg Val Loss: 2.6377\n",
      "Validation loss improved from 2.6391 to 2.6377. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6254\n",
      "Epoch [121/2000], Avg Train Loss: 4.6254\n",
      "Epoch [121/2000], Avg Val Loss: 2.6363\n",
      "Validation loss improved from 2.6377 to 2.6363. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6005\n",
      "Epoch [122/2000], Avg Train Loss: 4.6005\n",
      "Epoch [122/2000], Avg Val Loss: 2.6349\n",
      "Validation loss improved from 2.6363 to 2.6349. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6690\n",
      "Epoch [123/2000], Avg Train Loss: 4.6690\n",
      "Epoch [123/2000], Avg Val Loss: 2.6335\n",
      "Validation loss improved from 2.6349 to 2.6335. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6022\n",
      "Epoch [124/2000], Avg Train Loss: 4.6022\n",
      "Epoch [124/2000], Avg Val Loss: 2.6321\n",
      "Validation loss improved from 2.6335 to 2.6321. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6029\n",
      "Epoch [125/2000], Avg Train Loss: 4.6029\n",
      "Epoch [125/2000], Avg Val Loss: 2.6307\n",
      "Validation loss improved from 2.6321 to 2.6307. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5466\n",
      "Epoch [126/2000], Avg Train Loss: 4.5466\n",
      "Epoch [126/2000], Avg Val Loss: 2.6294\n",
      "Validation loss improved from 2.6307 to 2.6294. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6212\n",
      "Epoch [127/2000], Avg Train Loss: 4.6212\n",
      "Epoch [127/2000], Avg Val Loss: 2.6280\n",
      "Validation loss improved from 2.6294 to 2.6280. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5157\n",
      "Epoch [128/2000], Avg Train Loss: 4.5157\n",
      "Epoch [128/2000], Avg Val Loss: 2.6266\n",
      "Validation loss improved from 2.6280 to 2.6266. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6168\n",
      "Epoch [129/2000], Avg Train Loss: 4.6168\n",
      "Epoch [129/2000], Avg Val Loss: 2.6253\n",
      "Validation loss improved from 2.6266 to 2.6253. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5226\n",
      "Epoch [130/2000], Avg Train Loss: 4.5226\n",
      "Epoch [130/2000], Avg Val Loss: 2.6239\n",
      "Validation loss improved from 2.6253 to 2.6239. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5323\n",
      "Epoch [131/2000], Avg Train Loss: 4.5323\n",
      "Epoch [131/2000], Avg Val Loss: 2.6225\n",
      "Validation loss improved from 2.6239 to 2.6225. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5867\n",
      "Epoch [132/2000], Avg Train Loss: 4.5867\n",
      "Epoch [132/2000], Avg Val Loss: 2.6212\n",
      "Validation loss improved from 2.6225 to 2.6212. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5123\n",
      "Epoch [133/2000], Avg Train Loss: 4.5123\n",
      "Epoch [133/2000], Avg Val Loss: 2.6198\n",
      "Validation loss improved from 2.6212 to 2.6198. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5419\n",
      "Epoch [134/2000], Avg Train Loss: 4.5419\n",
      "Epoch [134/2000], Avg Val Loss: 2.6185\n",
      "Validation loss improved from 2.6198 to 2.6185. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5216\n",
      "Epoch [135/2000], Avg Train Loss: 4.5216\n",
      "Epoch [135/2000], Avg Val Loss: 2.6171\n",
      "Validation loss improved from 2.6185 to 2.6171. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5147\n",
      "Epoch [136/2000], Avg Train Loss: 4.5147\n",
      "Epoch [136/2000], Avg Val Loss: 2.6157\n",
      "Validation loss improved from 2.6171 to 2.6157. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5198\n",
      "Epoch [137/2000], Avg Train Loss: 4.5198\n",
      "Epoch [137/2000], Avg Val Loss: 2.6143\n",
      "Validation loss improved from 2.6157 to 2.6143. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4845\n",
      "Epoch [138/2000], Avg Train Loss: 4.4845\n",
      "Epoch [138/2000], Avg Val Loss: 2.6129\n",
      "Validation loss improved from 2.6143 to 2.6129. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5830\n",
      "Epoch [139/2000], Avg Train Loss: 4.5830\n",
      "Epoch [139/2000], Avg Val Loss: 2.6115\n",
      "Validation loss improved from 2.6129 to 2.6115. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5708\n",
      "Epoch [140/2000], Avg Train Loss: 4.5708\n",
      "Epoch [140/2000], Avg Val Loss: 2.6102\n",
      "Validation loss improved from 2.6115 to 2.6102. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5128\n",
      "Epoch [141/2000], Avg Train Loss: 4.5128\n",
      "Epoch [141/2000], Avg Val Loss: 2.6088\n",
      "Validation loss improved from 2.6102 to 2.6088. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5062\n",
      "Epoch [142/2000], Avg Train Loss: 4.5062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/2000], Avg Val Loss: 2.6074\n",
      "Validation loss improved from 2.6088 to 2.6074. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5227\n",
      "Epoch [143/2000], Avg Train Loss: 4.5227\n",
      "Epoch [143/2000], Avg Val Loss: 2.6060\n",
      "Validation loss improved from 2.6074 to 2.6060. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4932\n",
      "Epoch [144/2000], Avg Train Loss: 4.4932\n",
      "Epoch [144/2000], Avg Val Loss: 2.6047\n",
      "Validation loss improved from 2.6060 to 2.6047. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4521\n",
      "Epoch [145/2000], Avg Train Loss: 4.4521\n",
      "Epoch [145/2000], Avg Val Loss: 2.6033\n",
      "Validation loss improved from 2.6047 to 2.6033. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5499\n",
      "Epoch [146/2000], Avg Train Loss: 4.5499\n",
      "Epoch [146/2000], Avg Val Loss: 2.6020\n",
      "Validation loss improved from 2.6033 to 2.6020. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4908\n",
      "Epoch [147/2000], Avg Train Loss: 4.4908\n",
      "Epoch [147/2000], Avg Val Loss: 2.6006\n",
      "Validation loss improved from 2.6020 to 2.6006. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4959\n",
      "Epoch [148/2000], Avg Train Loss: 4.4959\n",
      "Epoch [148/2000], Avg Val Loss: 2.5992\n",
      "Validation loss improved from 2.6006 to 2.5992. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4996\n",
      "Epoch [149/2000], Avg Train Loss: 4.4996\n",
      "Epoch [149/2000], Avg Val Loss: 2.5978\n",
      "Validation loss improved from 2.5992 to 2.5978. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4656\n",
      "Epoch [150/2000], Avg Train Loss: 4.4656\n",
      "Epoch [150/2000], Avg Val Loss: 2.5965\n",
      "Validation loss improved from 2.5978 to 2.5965. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5464\n",
      "Epoch [151/2000], Avg Train Loss: 4.5464\n",
      "Epoch [151/2000], Avg Val Loss: 2.5951\n",
      "Validation loss improved from 2.5965 to 2.5951. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4637\n",
      "Epoch [152/2000], Avg Train Loss: 4.4637\n",
      "Epoch [152/2000], Avg Val Loss: 2.5938\n",
      "Validation loss improved from 2.5951 to 2.5938. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4546\n",
      "Epoch [153/2000], Avg Train Loss: 4.4546\n",
      "Epoch [153/2000], Avg Val Loss: 2.5924\n",
      "Validation loss improved from 2.5938 to 2.5924. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4991\n",
      "Epoch [154/2000], Avg Train Loss: 4.4991\n",
      "Epoch [154/2000], Avg Val Loss: 2.5911\n",
      "Validation loss improved from 2.5924 to 2.5911. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4634\n",
      "Epoch [155/2000], Avg Train Loss: 4.4634\n",
      "Epoch [155/2000], Avg Val Loss: 2.5897\n",
      "Validation loss improved from 2.5911 to 2.5897. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4454\n",
      "Epoch [156/2000], Avg Train Loss: 4.4454\n",
      "Epoch [156/2000], Avg Val Loss: 2.5884\n",
      "Validation loss improved from 2.5897 to 2.5884. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4525\n",
      "Epoch [157/2000], Avg Train Loss: 4.4525\n",
      "Epoch [157/2000], Avg Val Loss: 2.5871\n",
      "Validation loss improved from 2.5884 to 2.5871. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4409\n",
      "Epoch [158/2000], Avg Train Loss: 4.4409\n",
      "Epoch [158/2000], Avg Val Loss: 2.5858\n",
      "Validation loss improved from 2.5871 to 2.5858. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4873\n",
      "Epoch [159/2000], Avg Train Loss: 4.4873\n",
      "Epoch [159/2000], Avg Val Loss: 2.5845\n",
      "Validation loss improved from 2.5858 to 2.5845. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3787\n",
      "Epoch [160/2000], Avg Train Loss: 4.3787\n",
      "Epoch [160/2000], Avg Val Loss: 2.5831\n",
      "Validation loss improved from 2.5845 to 2.5831. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4319\n",
      "Epoch [161/2000], Avg Train Loss: 4.4319\n",
      "Epoch [161/2000], Avg Val Loss: 2.5818\n",
      "Validation loss improved from 2.5831 to 2.5818. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4475\n",
      "Epoch [162/2000], Avg Train Loss: 4.4475\n",
      "Epoch [162/2000], Avg Val Loss: 2.5805\n",
      "Validation loss improved from 2.5818 to 2.5805. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4336\n",
      "Epoch [163/2000], Avg Train Loss: 4.4336\n",
      "Epoch [163/2000], Avg Val Loss: 2.5793\n",
      "Validation loss improved from 2.5805 to 2.5793. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4995\n",
      "Epoch [164/2000], Avg Train Loss: 4.4995\n",
      "Epoch [164/2000], Avg Val Loss: 2.5780\n",
      "Validation loss improved from 2.5793 to 2.5780. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4284\n",
      "Epoch [165/2000], Avg Train Loss: 4.4284\n",
      "Epoch [165/2000], Avg Val Loss: 2.5768\n",
      "Validation loss improved from 2.5780 to 2.5768. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4453\n",
      "Epoch [166/2000], Avg Train Loss: 4.4453\n",
      "Epoch [166/2000], Avg Val Loss: 2.5755\n",
      "Validation loss improved from 2.5768 to 2.5755. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3770\n",
      "Epoch [167/2000], Avg Train Loss: 4.3770\n",
      "Epoch [167/2000], Avg Val Loss: 2.5743\n",
      "Validation loss improved from 2.5755 to 2.5743. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3791\n",
      "Epoch [168/2000], Avg Train Loss: 4.3791\n",
      "Epoch [168/2000], Avg Val Loss: 2.5730\n",
      "Validation loss improved from 2.5743 to 2.5730. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4468\n",
      "Epoch [169/2000], Avg Train Loss: 4.4468\n",
      "Epoch [169/2000], Avg Val Loss: 2.5717\n",
      "Validation loss improved from 2.5730 to 2.5717. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3891\n",
      "Epoch [170/2000], Avg Train Loss: 4.3891\n",
      "Epoch [170/2000], Avg Val Loss: 2.5705\n",
      "Validation loss improved from 2.5717 to 2.5705. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4247\n",
      "Epoch [171/2000], Avg Train Loss: 4.4247\n",
      "Epoch [171/2000], Avg Val Loss: 2.5692\n",
      "Validation loss improved from 2.5705 to 2.5692. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4363\n",
      "Epoch [172/2000], Avg Train Loss: 4.4363\n",
      "Epoch [172/2000], Avg Val Loss: 2.5679\n",
      "Validation loss improved from 2.5692 to 2.5679. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3971\n",
      "Epoch [173/2000], Avg Train Loss: 4.3971\n",
      "Epoch [173/2000], Avg Val Loss: 2.5667\n",
      "Validation loss improved from 2.5679 to 2.5667. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3065\n",
      "Epoch [174/2000], Avg Train Loss: 4.3065\n",
      "Epoch [174/2000], Avg Val Loss: 2.5654\n",
      "Validation loss improved from 2.5667 to 2.5654. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3782\n",
      "Epoch [175/2000], Avg Train Loss: 4.3782\n",
      "Epoch [175/2000], Avg Val Loss: 2.5641\n",
      "Validation loss improved from 2.5654 to 2.5641. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4024\n",
      "Epoch [176/2000], Avg Train Loss: 4.4024\n",
      "Epoch [176/2000], Avg Val Loss: 2.5629\n",
      "Validation loss improved from 2.5641 to 2.5629. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3765\n",
      "Epoch [177/2000], Avg Train Loss: 4.3765\n",
      "Epoch [177/2000], Avg Val Loss: 2.5616\n",
      "Validation loss improved from 2.5629 to 2.5616. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3706\n",
      "Epoch [178/2000], Avg Train Loss: 4.3706\n",
      "Epoch [178/2000], Avg Val Loss: 2.5603\n",
      "Validation loss improved from 2.5616 to 2.5603. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3632\n",
      "Epoch [179/2000], Avg Train Loss: 4.3632\n",
      "Epoch [179/2000], Avg Val Loss: 2.5591\n",
      "Validation loss improved from 2.5603 to 2.5591. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3746\n",
      "Epoch [180/2000], Avg Train Loss: 4.3746\n",
      "Epoch [180/2000], Avg Val Loss: 2.5578\n",
      "Validation loss improved from 2.5591 to 2.5578. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3475\n",
      "Epoch [181/2000], Avg Train Loss: 4.3475\n",
      "Epoch [181/2000], Avg Val Loss: 2.5565\n",
      "Validation loss improved from 2.5578 to 2.5565. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3570\n",
      "Epoch [182/2000], Avg Train Loss: 4.3570\n",
      "Epoch [182/2000], Avg Val Loss: 2.5552\n",
      "Validation loss improved from 2.5565 to 2.5552. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3451\n",
      "Epoch [183/2000], Avg Train Loss: 4.3451\n",
      "Epoch [183/2000], Avg Val Loss: 2.5539\n",
      "Validation loss improved from 2.5552 to 2.5539. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3555\n",
      "Epoch [184/2000], Avg Train Loss: 4.3555\n",
      "Epoch [184/2000], Avg Val Loss: 2.5527\n",
      "Validation loss improved from 2.5539 to 2.5527. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3313\n",
      "Epoch [185/2000], Avg Train Loss: 4.3313\n",
      "Epoch [185/2000], Avg Val Loss: 2.5514\n",
      "Validation loss improved from 2.5527 to 2.5514. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4170\n",
      "Epoch [186/2000], Avg Train Loss: 4.4170\n",
      "Epoch [186/2000], Avg Val Loss: 2.5501\n",
      "Validation loss improved from 2.5514 to 2.5501. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3491\n",
      "Epoch [187/2000], Avg Train Loss: 4.3491\n",
      "Epoch [187/2000], Avg Val Loss: 2.5489\n",
      "Validation loss improved from 2.5501 to 2.5489. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3403\n",
      "Epoch [188/2000], Avg Train Loss: 4.3403\n",
      "Epoch [188/2000], Avg Val Loss: 2.5476\n",
      "Validation loss improved from 2.5489 to 2.5476. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3364\n",
      "Epoch [189/2000], Avg Train Loss: 4.3364\n",
      "Epoch [189/2000], Avg Val Loss: 2.5464\n",
      "Validation loss improved from 2.5476 to 2.5464. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3296\n",
      "Epoch [190/2000], Avg Train Loss: 4.3296\n",
      "Epoch [190/2000], Avg Val Loss: 2.5451\n",
      "Validation loss improved from 2.5464 to 2.5451. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3103\n",
      "Epoch [191/2000], Avg Train Loss: 4.3103\n",
      "Epoch [191/2000], Avg Val Loss: 2.5439\n",
      "Validation loss improved from 2.5451 to 2.5439. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2681\n",
      "Epoch [192/2000], Avg Train Loss: 4.2681\n",
      "Epoch [192/2000], Avg Val Loss: 2.5426\n",
      "Validation loss improved from 2.5439 to 2.5426. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2984\n",
      "Epoch [193/2000], Avg Train Loss: 4.2984\n",
      "Epoch [193/2000], Avg Val Loss: 2.5414\n",
      "Validation loss improved from 2.5426 to 2.5414. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3291\n",
      "Epoch [194/2000], Avg Train Loss: 4.3291\n",
      "Epoch [194/2000], Avg Val Loss: 2.5402\n",
      "Validation loss improved from 2.5414 to 2.5402. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3068\n",
      "Epoch [195/2000], Avg Train Loss: 4.3068\n",
      "Epoch [195/2000], Avg Val Loss: 2.5389\n",
      "Validation loss improved from 2.5402 to 2.5389. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2781\n",
      "Epoch [196/2000], Avg Train Loss: 4.2781\n",
      "Epoch [196/2000], Avg Val Loss: 2.5376\n",
      "Validation loss improved from 2.5389 to 2.5376. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2529\n",
      "Epoch [197/2000], Avg Train Loss: 4.2529\n",
      "Epoch [197/2000], Avg Val Loss: 2.5363\n",
      "Validation loss improved from 2.5376 to 2.5363. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2965\n",
      "Epoch [198/2000], Avg Train Loss: 4.2965\n",
      "Epoch [198/2000], Avg Val Loss: 2.5350\n",
      "Validation loss improved from 2.5363 to 2.5350. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3092\n",
      "Epoch [199/2000], Avg Train Loss: 4.3092\n",
      "Epoch [199/2000], Avg Val Loss: 2.5338\n",
      "Validation loss improved from 2.5350 to 2.5338. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3127\n",
      "Epoch [200/2000], Avg Train Loss: 4.3127\n",
      "Epoch [200/2000], Avg Val Loss: 2.5325\n",
      "Validation loss improved from 2.5338 to 2.5325. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2931\n",
      "Epoch [201/2000], Avg Train Loss: 4.2931\n",
      "Epoch [201/2000], Avg Val Loss: 2.5312\n",
      "Validation loss improved from 2.5325 to 2.5312. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3152\n",
      "Epoch [202/2000], Avg Train Loss: 4.3152\n",
      "Epoch [202/2000], Avg Val Loss: 2.5299\n",
      "Validation loss improved from 2.5312 to 2.5299. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2761\n",
      "Epoch [203/2000], Avg Train Loss: 4.2761\n",
      "Epoch [203/2000], Avg Val Loss: 2.5287\n",
      "Validation loss improved from 2.5299 to 2.5287. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2560\n",
      "Epoch [204/2000], Avg Train Loss: 4.2560\n",
      "Epoch [204/2000], Avg Val Loss: 2.5274\n",
      "Validation loss improved from 2.5287 to 2.5274. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2847\n",
      "Epoch [205/2000], Avg Train Loss: 4.2847\n",
      "Epoch [205/2000], Avg Val Loss: 2.5261\n",
      "Validation loss improved from 2.5274 to 2.5261. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2770\n",
      "Epoch [206/2000], Avg Train Loss: 4.2770\n",
      "Epoch [206/2000], Avg Val Loss: 2.5249\n",
      "Validation loss improved from 2.5261 to 2.5249. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2766\n",
      "Epoch [207/2000], Avg Train Loss: 4.2766\n",
      "Epoch [207/2000], Avg Val Loss: 2.5236\n",
      "Validation loss improved from 2.5249 to 2.5236. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2727\n",
      "Epoch [208/2000], Avg Train Loss: 4.2727\n",
      "Epoch [208/2000], Avg Val Loss: 2.5224\n",
      "Validation loss improved from 2.5236 to 2.5224. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2247\n",
      "Epoch [209/2000], Avg Train Loss: 4.2247\n",
      "Epoch [209/2000], Avg Val Loss: 2.5211\n",
      "Validation loss improved from 2.5224 to 2.5211. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2910\n",
      "Epoch [210/2000], Avg Train Loss: 4.2910\n",
      "Epoch [210/2000], Avg Val Loss: 2.5199\n",
      "Validation loss improved from 2.5211 to 2.5199. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2174\n",
      "Epoch [211/2000], Avg Train Loss: 4.2174\n",
      "Epoch [211/2000], Avg Val Loss: 2.5187\n",
      "Validation loss improved from 2.5199 to 2.5187. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2351\n",
      "Epoch [212/2000], Avg Train Loss: 4.2351\n",
      "Epoch [212/2000], Avg Val Loss: 2.5175\n",
      "Validation loss improved from 2.5187 to 2.5175. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2972\n",
      "Epoch [213/2000], Avg Train Loss: 4.2972\n",
      "Epoch [213/2000], Avg Val Loss: 2.5163\n",
      "Validation loss improved from 2.5175 to 2.5163. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2791\n",
      "Epoch [214/2000], Avg Train Loss: 4.2791\n",
      "Epoch [214/2000], Avg Val Loss: 2.5151\n",
      "Validation loss improved from 2.5163 to 2.5151. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1801\n",
      "Epoch [215/2000], Avg Train Loss: 4.1801\n",
      "Epoch [215/2000], Avg Val Loss: 2.5139\n",
      "Validation loss improved from 2.5151 to 2.5139. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2351\n",
      "Epoch [216/2000], Avg Train Loss: 4.2351\n",
      "Epoch [216/2000], Avg Val Loss: 2.5127\n",
      "Validation loss improved from 2.5139 to 2.5127. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2439\n",
      "Epoch [217/2000], Avg Train Loss: 4.2439\n",
      "Epoch [217/2000], Avg Val Loss: 2.5116\n",
      "Validation loss improved from 2.5127 to 2.5116. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2381\n",
      "Epoch [218/2000], Avg Train Loss: 4.2381\n",
      "Epoch [218/2000], Avg Val Loss: 2.5104\n",
      "Validation loss improved from 2.5116 to 2.5104. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2509\n",
      "Epoch [219/2000], Avg Train Loss: 4.2509\n",
      "Epoch [219/2000], Avg Val Loss: 2.5092\n",
      "Validation loss improved from 2.5104 to 2.5092. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2543\n",
      "Epoch [220/2000], Avg Train Loss: 4.2543\n",
      "Epoch [220/2000], Avg Val Loss: 2.5081\n",
      "Validation loss improved from 2.5092 to 2.5081. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2383\n",
      "Epoch [221/2000], Avg Train Loss: 4.2383\n",
      "Epoch [221/2000], Avg Val Loss: 2.5069\n",
      "Validation loss improved from 2.5081 to 2.5069. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2337\n",
      "Epoch [222/2000], Avg Train Loss: 4.2337\n",
      "Epoch [222/2000], Avg Val Loss: 2.5058\n",
      "Validation loss improved from 2.5069 to 2.5058. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2754\n",
      "Epoch [223/2000], Avg Train Loss: 4.2754\n",
      "Epoch [223/2000], Avg Val Loss: 2.5046\n",
      "Validation loss improved from 2.5058 to 2.5046. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2352\n",
      "Epoch [224/2000], Avg Train Loss: 4.2352\n",
      "Epoch [224/2000], Avg Val Loss: 2.5035\n",
      "Validation loss improved from 2.5046 to 2.5035. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2114\n",
      "Epoch [225/2000], Avg Train Loss: 4.2114\n",
      "Epoch [225/2000], Avg Val Loss: 2.5023\n",
      "Validation loss improved from 2.5035 to 2.5023. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2418\n",
      "Epoch [226/2000], Avg Train Loss: 4.2418\n",
      "Epoch [226/2000], Avg Val Loss: 2.5012\n",
      "Validation loss improved from 2.5023 to 2.5012. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2052\n",
      "Epoch [227/2000], Avg Train Loss: 4.2052\n",
      "Epoch [227/2000], Avg Val Loss: 2.5001\n",
      "Validation loss improved from 2.5012 to 2.5001. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1951\n",
      "Epoch [228/2000], Avg Train Loss: 4.1951\n",
      "Epoch [228/2000], Avg Val Loss: 2.4990\n",
      "Validation loss improved from 2.5001 to 2.4990. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2277\n",
      "Epoch [229/2000], Avg Train Loss: 4.2277\n",
      "Epoch [229/2000], Avg Val Loss: 2.4978\n",
      "Validation loss improved from 2.4990 to 2.4978. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2499\n",
      "Epoch [230/2000], Avg Train Loss: 4.2499\n",
      "Epoch [230/2000], Avg Val Loss: 2.4967\n",
      "Validation loss improved from 2.4978 to 2.4967. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1890\n",
      "Epoch [231/2000], Avg Train Loss: 4.1890\n",
      "Epoch [231/2000], Avg Val Loss: 2.4956\n",
      "Validation loss improved from 2.4967 to 2.4956. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1620\n",
      "Epoch [232/2000], Avg Train Loss: 4.1620\n",
      "Epoch [232/2000], Avg Val Loss: 2.4945\n",
      "Validation loss improved from 2.4956 to 2.4945. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2329\n",
      "Epoch [233/2000], Avg Train Loss: 4.2329\n",
      "Epoch [233/2000], Avg Val Loss: 2.4934\n",
      "Validation loss improved from 2.4945 to 2.4934. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1964\n",
      "Epoch [234/2000], Avg Train Loss: 4.1964\n",
      "Epoch [234/2000], Avg Val Loss: 2.4923\n",
      "Validation loss improved from 2.4934 to 2.4923. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1972\n",
      "Epoch [235/2000], Avg Train Loss: 4.1972\n",
      "Epoch [235/2000], Avg Val Loss: 2.4912\n",
      "Validation loss improved from 2.4923 to 2.4912. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1530\n",
      "Epoch [236/2000], Avg Train Loss: 4.1530\n",
      "Epoch [236/2000], Avg Val Loss: 2.4901\n",
      "Validation loss improved from 2.4912 to 2.4901. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1883\n",
      "Epoch [237/2000], Avg Train Loss: 4.1883\n",
      "Epoch [237/2000], Avg Val Loss: 2.4890\n",
      "Validation loss improved from 2.4901 to 2.4890. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2498\n",
      "Epoch [238/2000], Avg Train Loss: 4.2498\n",
      "Epoch [238/2000], Avg Val Loss: 2.4879\n",
      "Validation loss improved from 2.4890 to 2.4879. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2033\n",
      "Epoch [239/2000], Avg Train Loss: 4.2033\n",
      "Epoch [239/2000], Avg Val Loss: 2.4868\n",
      "Validation loss improved from 2.4879 to 2.4868. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2099\n",
      "Epoch [240/2000], Avg Train Loss: 4.2099\n",
      "Epoch [240/2000], Avg Val Loss: 2.4858\n",
      "Validation loss improved from 2.4868 to 2.4858. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2010\n",
      "Epoch [241/2000], Avg Train Loss: 4.2010\n",
      "Epoch [241/2000], Avg Val Loss: 2.4847\n",
      "Validation loss improved from 2.4858 to 2.4847. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1848\n",
      "Epoch [242/2000], Avg Train Loss: 4.1848\n",
      "Epoch [242/2000], Avg Val Loss: 2.4836\n",
      "Validation loss improved from 2.4847 to 2.4836. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2073\n",
      "Epoch [243/2000], Avg Train Loss: 4.2073\n",
      "Epoch [243/2000], Avg Val Loss: 2.4826\n",
      "Validation loss improved from 2.4836 to 2.4826. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2116\n",
      "Epoch [244/2000], Avg Train Loss: 4.2116\n",
      "Epoch [244/2000], Avg Val Loss: 2.4816\n",
      "Validation loss improved from 2.4826 to 2.4816. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1416\n",
      "Epoch [245/2000], Avg Train Loss: 4.1416\n",
      "Epoch [245/2000], Avg Val Loss: 2.4806\n",
      "Validation loss improved from 2.4816 to 2.4806. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1887\n",
      "Epoch [246/2000], Avg Train Loss: 4.1887\n",
      "Epoch [246/2000], Avg Val Loss: 2.4795\n",
      "Validation loss improved from 2.4806 to 2.4795. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2050\n",
      "Epoch [247/2000], Avg Train Loss: 4.2050\n",
      "Epoch [247/2000], Avg Val Loss: 2.4785\n",
      "Validation loss improved from 2.4795 to 2.4785. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1938\n",
      "Epoch [248/2000], Avg Train Loss: 4.1938\n",
      "Epoch [248/2000], Avg Val Loss: 2.4775\n",
      "Validation loss improved from 2.4785 to 2.4775. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2097\n",
      "Epoch [249/2000], Avg Train Loss: 4.2097\n",
      "Epoch [249/2000], Avg Val Loss: 2.4765\n",
      "Validation loss improved from 2.4775 to 2.4765. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2316\n",
      "Epoch [250/2000], Avg Train Loss: 4.2316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/2000], Avg Val Loss: 2.4754\n",
      "Validation loss improved from 2.4765 to 2.4754. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1907\n",
      "Epoch [251/2000], Avg Train Loss: 4.1907\n",
      "Epoch [251/2000], Avg Val Loss: 2.4745\n",
      "Validation loss improved from 2.4754 to 2.4745. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1090\n",
      "Epoch [252/2000], Avg Train Loss: 4.1090\n",
      "Epoch [252/2000], Avg Val Loss: 2.4734\n",
      "Validation loss improved from 2.4745 to 2.4734. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1268\n",
      "Epoch [253/2000], Avg Train Loss: 4.1268\n",
      "Epoch [253/2000], Avg Val Loss: 2.4724\n",
      "Validation loss improved from 2.4734 to 2.4724. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1484\n",
      "Epoch [254/2000], Avg Train Loss: 4.1484\n",
      "Epoch [254/2000], Avg Val Loss: 2.4714\n",
      "Validation loss improved from 2.4724 to 2.4714. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1693\n",
      "Epoch [255/2000], Avg Train Loss: 4.1693\n",
      "Epoch [255/2000], Avg Val Loss: 2.4704\n",
      "Validation loss improved from 2.4714 to 2.4704. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1385\n",
      "Epoch [256/2000], Avg Train Loss: 4.1385\n",
      "Epoch [256/2000], Avg Val Loss: 2.4693\n",
      "Validation loss improved from 2.4704 to 2.4693. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1832\n",
      "Epoch [257/2000], Avg Train Loss: 4.1832\n",
      "Epoch [257/2000], Avg Val Loss: 2.4683\n",
      "Validation loss improved from 2.4693 to 2.4683. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1644\n",
      "Epoch [258/2000], Avg Train Loss: 4.1644\n",
      "Epoch [258/2000], Avg Val Loss: 2.4672\n",
      "Validation loss improved from 2.4683 to 2.4672. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1136\n",
      "Epoch [259/2000], Avg Train Loss: 4.1136\n",
      "Epoch [259/2000], Avg Val Loss: 2.4662\n",
      "Validation loss improved from 2.4672 to 2.4662. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1309\n",
      "Epoch [260/2000], Avg Train Loss: 4.1309\n",
      "Epoch [260/2000], Avg Val Loss: 2.4652\n",
      "Validation loss improved from 2.4662 to 2.4652. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1259\n",
      "Epoch [261/2000], Avg Train Loss: 4.1259\n",
      "Epoch [261/2000], Avg Val Loss: 2.4641\n",
      "Validation loss improved from 2.4652 to 2.4641. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1455\n",
      "Epoch [262/2000], Avg Train Loss: 4.1455\n",
      "Epoch [262/2000], Avg Val Loss: 2.4631\n",
      "Validation loss improved from 2.4641 to 2.4631. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1435\n",
      "Epoch [263/2000], Avg Train Loss: 4.1435\n",
      "Epoch [263/2000], Avg Val Loss: 2.4621\n",
      "Validation loss improved from 2.4631 to 2.4621. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0762\n",
      "Epoch [264/2000], Avg Train Loss: 4.0762\n",
      "Epoch [264/2000], Avg Val Loss: 2.4610\n",
      "Validation loss improved from 2.4621 to 2.4610. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1150\n",
      "Epoch [265/2000], Avg Train Loss: 4.1150\n",
      "Epoch [265/2000], Avg Val Loss: 2.4600\n",
      "Validation loss improved from 2.4610 to 2.4600. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0937\n",
      "Epoch [266/2000], Avg Train Loss: 4.0937\n",
      "Epoch [266/2000], Avg Val Loss: 2.4589\n",
      "Validation loss improved from 2.4600 to 2.4589. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0916\n",
      "Epoch [267/2000], Avg Train Loss: 4.0916\n",
      "Epoch [267/2000], Avg Val Loss: 2.4578\n",
      "Validation loss improved from 2.4589 to 2.4578. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1377\n",
      "Epoch [268/2000], Avg Train Loss: 4.1377\n",
      "Epoch [268/2000], Avg Val Loss: 2.4567\n",
      "Validation loss improved from 2.4578 to 2.4567. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0963\n",
      "Epoch [269/2000], Avg Train Loss: 4.0963\n",
      "Epoch [269/2000], Avg Val Loss: 2.4556\n",
      "Validation loss improved from 2.4567 to 2.4556. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1248\n",
      "Epoch [270/2000], Avg Train Loss: 4.1248\n",
      "Epoch [270/2000], Avg Val Loss: 2.4546\n",
      "Validation loss improved from 2.4556 to 2.4546. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0967\n",
      "Epoch [271/2000], Avg Train Loss: 4.0967\n",
      "Epoch [271/2000], Avg Val Loss: 2.4535\n",
      "Validation loss improved from 2.4546 to 2.4535. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0768\n",
      "Epoch [272/2000], Avg Train Loss: 4.0768\n",
      "Epoch [272/2000], Avg Val Loss: 2.4524\n",
      "Validation loss improved from 2.4535 to 2.4524. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1010\n",
      "Epoch [273/2000], Avg Train Loss: 4.1010\n",
      "Epoch [273/2000], Avg Val Loss: 2.4514\n",
      "Validation loss improved from 2.4524 to 2.4514. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0978\n",
      "Epoch [274/2000], Avg Train Loss: 4.0978\n",
      "Epoch [274/2000], Avg Val Loss: 2.4503\n",
      "Validation loss improved from 2.4514 to 2.4503. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1204\n",
      "Epoch [275/2000], Avg Train Loss: 4.1204\n",
      "Epoch [275/2000], Avg Val Loss: 2.4493\n",
      "Validation loss improved from 2.4503 to 2.4493. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1071\n",
      "Epoch [276/2000], Avg Train Loss: 4.1071\n",
      "Epoch [276/2000], Avg Val Loss: 2.4482\n",
      "Validation loss improved from 2.4493 to 2.4482. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1090\n",
      "Epoch [277/2000], Avg Train Loss: 4.1090\n",
      "Epoch [277/2000], Avg Val Loss: 2.4472\n",
      "Validation loss improved from 2.4482 to 2.4472. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1047\n",
      "Epoch [278/2000], Avg Train Loss: 4.1047\n",
      "Epoch [278/2000], Avg Val Loss: 2.4462\n",
      "Validation loss improved from 2.4472 to 2.4462. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0758\n",
      "Epoch [279/2000], Avg Train Loss: 4.0758\n",
      "Epoch [279/2000], Avg Val Loss: 2.4451\n",
      "Validation loss improved from 2.4462 to 2.4451. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0917\n",
      "Epoch [280/2000], Avg Train Loss: 4.0917\n",
      "Epoch [280/2000], Avg Val Loss: 2.4441\n",
      "Validation loss improved from 2.4451 to 2.4441. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0704\n",
      "Epoch [281/2000], Avg Train Loss: 4.0704\n",
      "Epoch [281/2000], Avg Val Loss: 2.4431\n",
      "Validation loss improved from 2.4441 to 2.4431. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1224\n",
      "Epoch [282/2000], Avg Train Loss: 4.1224\n",
      "Epoch [282/2000], Avg Val Loss: 2.4421\n",
      "Validation loss improved from 2.4431 to 2.4421. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1300\n",
      "Epoch [283/2000], Avg Train Loss: 4.1300\n",
      "Epoch [283/2000], Avg Val Loss: 2.4411\n",
      "Validation loss improved from 2.4421 to 2.4411. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1156\n",
      "Epoch [284/2000], Avg Train Loss: 4.1156\n",
      "Epoch [284/2000], Avg Val Loss: 2.4401\n",
      "Validation loss improved from 2.4411 to 2.4401. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0855\n",
      "Epoch [285/2000], Avg Train Loss: 4.0855\n",
      "Epoch [285/2000], Avg Val Loss: 2.4391\n",
      "Validation loss improved from 2.4401 to 2.4391. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1139\n",
      "Epoch [286/2000], Avg Train Loss: 4.1139\n",
      "Epoch [286/2000], Avg Val Loss: 2.4381\n",
      "Validation loss improved from 2.4391 to 2.4381. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0751\n",
      "Epoch [287/2000], Avg Train Loss: 4.0751\n",
      "Epoch [287/2000], Avg Val Loss: 2.4371\n",
      "Validation loss improved from 2.4381 to 2.4371. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0565\n",
      "Epoch [288/2000], Avg Train Loss: 4.0565\n",
      "Epoch [288/2000], Avg Val Loss: 2.4362\n",
      "Validation loss improved from 2.4371 to 2.4362. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0701\n",
      "Epoch [289/2000], Avg Train Loss: 4.0701\n",
      "Epoch [289/2000], Avg Val Loss: 2.4352\n",
      "Validation loss improved from 2.4362 to 2.4352. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0955\n",
      "Epoch [290/2000], Avg Train Loss: 4.0955\n",
      "Epoch [290/2000], Avg Val Loss: 2.4342\n",
      "Validation loss improved from 2.4352 to 2.4342. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0487\n",
      "Epoch [291/2000], Avg Train Loss: 4.0487\n",
      "Epoch [291/2000], Avg Val Loss: 2.4333\n",
      "Validation loss improved from 2.4342 to 2.4333. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0854\n",
      "Epoch [292/2000], Avg Train Loss: 4.0854\n",
      "Epoch [292/2000], Avg Val Loss: 2.4323\n",
      "Validation loss improved from 2.4333 to 2.4323. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0853\n",
      "Epoch [293/2000], Avg Train Loss: 4.0853\n",
      "Epoch [293/2000], Avg Val Loss: 2.4314\n",
      "Validation loss improved from 2.4323 to 2.4314. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0678\n",
      "Epoch [294/2000], Avg Train Loss: 4.0678\n",
      "Epoch [294/2000], Avg Val Loss: 2.4304\n",
      "Validation loss improved from 2.4314 to 2.4304. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0980\n",
      "Epoch [295/2000], Avg Train Loss: 4.0980\n",
      "Epoch [295/2000], Avg Val Loss: 2.4295\n",
      "Validation loss improved from 2.4304 to 2.4295. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0671\n",
      "Epoch [296/2000], Avg Train Loss: 4.0671\n",
      "Epoch [296/2000], Avg Val Loss: 2.4286\n",
      "Validation loss improved from 2.4295 to 2.4286. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0899\n",
      "Epoch [297/2000], Avg Train Loss: 4.0899\n",
      "Epoch [297/2000], Avg Val Loss: 2.4277\n",
      "Validation loss improved from 2.4286 to 2.4277. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0821\n",
      "Epoch [298/2000], Avg Train Loss: 4.0821\n",
      "Epoch [298/2000], Avg Val Loss: 2.4268\n",
      "Validation loss improved from 2.4277 to 2.4268. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0373\n",
      "Epoch [299/2000], Avg Train Loss: 4.0373\n",
      "Epoch [299/2000], Avg Val Loss: 2.4259\n",
      "Validation loss improved from 2.4268 to 2.4259. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0323\n",
      "Epoch [300/2000], Avg Train Loss: 4.0323\n",
      "Epoch [300/2000], Avg Val Loss: 2.4250\n",
      "Validation loss improved from 2.4259 to 2.4250. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0634\n",
      "Epoch [301/2000], Avg Train Loss: 4.0634\n",
      "Epoch [301/2000], Avg Val Loss: 2.4241\n",
      "Validation loss improved from 2.4250 to 2.4241. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0976\n",
      "Epoch [302/2000], Avg Train Loss: 4.0976\n",
      "Epoch [302/2000], Avg Val Loss: 2.4232\n",
      "Validation loss improved from 2.4241 to 2.4232. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0604\n",
      "Epoch [303/2000], Avg Train Loss: 4.0604\n",
      "Epoch [303/2000], Avg Val Loss: 2.4223\n",
      "Validation loss improved from 2.4232 to 2.4223. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0498\n",
      "Epoch [304/2000], Avg Train Loss: 4.0498\n",
      "Epoch [304/2000], Avg Val Loss: 2.4214\n",
      "Validation loss improved from 2.4223 to 2.4214. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0403\n",
      "Epoch [305/2000], Avg Train Loss: 4.0403\n",
      "Epoch [305/2000], Avg Val Loss: 2.4205\n",
      "Validation loss improved from 2.4214 to 2.4205. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0429\n",
      "Epoch [306/2000], Avg Train Loss: 4.0429\n",
      "Epoch [306/2000], Avg Val Loss: 2.4196\n",
      "Validation loss improved from 2.4205 to 2.4196. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0542\n",
      "Epoch [307/2000], Avg Train Loss: 4.0542\n",
      "Epoch [307/2000], Avg Val Loss: 2.4187\n",
      "Validation loss improved from 2.4196 to 2.4187. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0087\n",
      "Epoch [308/2000], Avg Train Loss: 4.0087\n",
      "Epoch [308/2000], Avg Val Loss: 2.4178\n",
      "Validation loss improved from 2.4187 to 2.4178. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0152\n",
      "Epoch [309/2000], Avg Train Loss: 4.0152\n",
      "Epoch [309/2000], Avg Val Loss: 2.4169\n",
      "Validation loss improved from 2.4178 to 2.4169. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0641\n",
      "Epoch [310/2000], Avg Train Loss: 4.0641\n",
      "Epoch [310/2000], Avg Val Loss: 2.4160\n",
      "Validation loss improved from 2.4169 to 2.4160. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0691\n",
      "Epoch [311/2000], Avg Train Loss: 4.0691\n",
      "Epoch [311/2000], Avg Val Loss: 2.4152\n",
      "Validation loss improved from 2.4160 to 2.4152. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0159\n",
      "Epoch [312/2000], Avg Train Loss: 4.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [312/2000], Avg Val Loss: 2.4143\n",
      "Validation loss improved from 2.4152 to 2.4143. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0185\n",
      "Epoch [313/2000], Avg Train Loss: 4.0185\n",
      "Epoch [313/2000], Avg Val Loss: 2.4134\n",
      "Validation loss improved from 2.4143 to 2.4134. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0954\n",
      "Epoch [314/2000], Avg Train Loss: 4.0954\n",
      "Epoch [314/2000], Avg Val Loss: 2.4125\n",
      "Validation loss improved from 2.4134 to 2.4125. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0244\n",
      "Epoch [315/2000], Avg Train Loss: 4.0244\n",
      "Epoch [315/2000], Avg Val Loss: 2.4117\n",
      "Validation loss improved from 2.4125 to 2.4117. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0268\n",
      "Epoch [316/2000], Avg Train Loss: 4.0268\n",
      "Epoch [316/2000], Avg Val Loss: 2.4108\n",
      "Validation loss improved from 2.4117 to 2.4108. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0454\n",
      "Epoch [317/2000], Avg Train Loss: 4.0454\n",
      "Epoch [317/2000], Avg Val Loss: 2.4100\n",
      "Validation loss improved from 2.4108 to 2.4100. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0175\n",
      "Epoch [318/2000], Avg Train Loss: 4.0175\n",
      "Epoch [318/2000], Avg Val Loss: 2.4092\n",
      "Validation loss improved from 2.4100 to 2.4092. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0286\n",
      "Epoch [319/2000], Avg Train Loss: 4.0286\n",
      "Epoch [319/2000], Avg Val Loss: 2.4084\n",
      "Validation loss improved from 2.4092 to 2.4084. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0164\n",
      "Epoch [320/2000], Avg Train Loss: 4.0164\n",
      "Epoch [320/2000], Avg Val Loss: 2.4075\n",
      "Validation loss improved from 2.4084 to 2.4075. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0483\n",
      "Epoch [321/2000], Avg Train Loss: 4.0483\n",
      "Epoch [321/2000], Avg Val Loss: 2.4067\n",
      "Validation loss improved from 2.4075 to 2.4067. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9767\n",
      "Epoch [322/2000], Avg Train Loss: 3.9767\n",
      "Epoch [322/2000], Avg Val Loss: 2.4058\n",
      "Validation loss improved from 2.4067 to 2.4058. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0443\n",
      "Epoch [323/2000], Avg Train Loss: 4.0443\n",
      "Epoch [323/2000], Avg Val Loss: 2.4050\n",
      "Validation loss improved from 2.4058 to 2.4050. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0256\n",
      "Epoch [324/2000], Avg Train Loss: 4.0256\n",
      "Epoch [324/2000], Avg Val Loss: 2.4042\n",
      "Validation loss improved from 2.4050 to 2.4042. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0180\n",
      "Epoch [325/2000], Avg Train Loss: 4.0180\n",
      "Epoch [325/2000], Avg Val Loss: 2.4034\n",
      "Validation loss improved from 2.4042 to 2.4034. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0048\n",
      "Epoch [326/2000], Avg Train Loss: 4.0048\n",
      "Epoch [326/2000], Avg Val Loss: 2.4026\n",
      "Validation loss improved from 2.4034 to 2.4026. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0298\n",
      "Epoch [327/2000], Avg Train Loss: 4.0298\n",
      "Epoch [327/2000], Avg Val Loss: 2.4018\n",
      "Validation loss improved from 2.4026 to 2.4018. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0524\n",
      "Epoch [328/2000], Avg Train Loss: 4.0524\n",
      "Epoch [328/2000], Avg Val Loss: 2.4010\n",
      "Validation loss improved from 2.4018 to 2.4010. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0531\n",
      "Epoch [329/2000], Avg Train Loss: 4.0531\n",
      "Epoch [329/2000], Avg Val Loss: 2.4002\n",
      "Validation loss improved from 2.4010 to 2.4002. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9733\n",
      "Epoch [330/2000], Avg Train Loss: 3.9733\n",
      "Epoch [330/2000], Avg Val Loss: 2.3994\n",
      "Validation loss improved from 2.4002 to 2.3994. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0055\n",
      "Epoch [331/2000], Avg Train Loss: 4.0055\n",
      "Epoch [331/2000], Avg Val Loss: 2.3986\n",
      "Validation loss improved from 2.3994 to 2.3986. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9704\n",
      "Epoch [332/2000], Avg Train Loss: 3.9704\n",
      "Epoch [332/2000], Avg Val Loss: 2.3978\n",
      "Validation loss improved from 2.3986 to 2.3978. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9855\n",
      "Epoch [333/2000], Avg Train Loss: 3.9855\n",
      "Epoch [333/2000], Avg Val Loss: 2.3970\n",
      "Validation loss improved from 2.3978 to 2.3970. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0666\n",
      "Epoch [334/2000], Avg Train Loss: 4.0666\n",
      "Epoch [334/2000], Avg Val Loss: 2.3962\n",
      "Validation loss improved from 2.3970 to 2.3962. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9999\n",
      "Epoch [335/2000], Avg Train Loss: 3.9999\n",
      "Epoch [335/2000], Avg Val Loss: 2.3954\n",
      "Validation loss improved from 2.3962 to 2.3954. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9650\n",
      "Epoch [336/2000], Avg Train Loss: 3.9650\n",
      "Epoch [336/2000], Avg Val Loss: 2.3946\n",
      "Validation loss improved from 2.3954 to 2.3946. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0081\n",
      "Epoch [337/2000], Avg Train Loss: 4.0081\n",
      "Epoch [337/2000], Avg Val Loss: 2.3938\n",
      "Validation loss improved from 2.3946 to 2.3938. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9870\n",
      "Epoch [338/2000], Avg Train Loss: 3.9870\n",
      "Epoch [338/2000], Avg Val Loss: 2.3930\n",
      "Validation loss improved from 2.3938 to 2.3930. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0017\n",
      "Epoch [339/2000], Avg Train Loss: 4.0017\n",
      "Epoch [339/2000], Avg Val Loss: 2.3922\n",
      "Validation loss improved from 2.3930 to 2.3922. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9971\n",
      "Epoch [340/2000], Avg Train Loss: 3.9971\n",
      "Epoch [340/2000], Avg Val Loss: 2.3914\n",
      "Validation loss improved from 2.3922 to 2.3914. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9873\n",
      "Epoch [341/2000], Avg Train Loss: 3.9873\n",
      "Epoch [341/2000], Avg Val Loss: 2.3906\n",
      "Validation loss improved from 2.3914 to 2.3906. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0066\n",
      "Epoch [342/2000], Avg Train Loss: 4.0066\n",
      "Epoch [342/2000], Avg Val Loss: 2.3898\n",
      "Validation loss improved from 2.3906 to 2.3898. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9991\n",
      "Epoch [343/2000], Avg Train Loss: 3.9991\n",
      "Epoch [343/2000], Avg Val Loss: 2.3890\n",
      "Validation loss improved from 2.3898 to 2.3890. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9512\n",
      "Epoch [344/2000], Avg Train Loss: 3.9512\n",
      "Epoch [344/2000], Avg Val Loss: 2.3882\n",
      "Validation loss improved from 2.3890 to 2.3882. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9662\n",
      "Epoch [345/2000], Avg Train Loss: 3.9662\n",
      "Epoch [345/2000], Avg Val Loss: 2.3874\n",
      "Validation loss improved from 2.3882 to 2.3874. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9488\n",
      "Epoch [346/2000], Avg Train Loss: 3.9488\n",
      "Epoch [346/2000], Avg Val Loss: 2.3866\n",
      "Validation loss improved from 2.3874 to 2.3866. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0105\n",
      "Epoch [347/2000], Avg Train Loss: 4.0105\n",
      "Epoch [347/2000], Avg Val Loss: 2.3858\n",
      "Validation loss improved from 2.3866 to 2.3858. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9837\n",
      "Epoch [348/2000], Avg Train Loss: 3.9837\n",
      "Epoch [348/2000], Avg Val Loss: 2.3850\n",
      "Validation loss improved from 2.3858 to 2.3850. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9855\n",
      "Epoch [349/2000], Avg Train Loss: 3.9855\n",
      "Epoch [349/2000], Avg Val Loss: 2.3843\n",
      "Validation loss improved from 2.3850 to 2.3843. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9707\n",
      "Epoch [350/2000], Avg Train Loss: 3.9707\n",
      "Epoch [350/2000], Avg Val Loss: 2.3835\n",
      "Validation loss improved from 2.3843 to 2.3835. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0333\n",
      "Epoch [351/2000], Avg Train Loss: 4.0333\n",
      "Epoch [351/2000], Avg Val Loss: 2.3828\n",
      "Validation loss improved from 2.3835 to 2.3828. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9999\n",
      "Epoch [352/2000], Avg Train Loss: 3.9999\n",
      "Epoch [352/2000], Avg Val Loss: 2.3821\n",
      "Validation loss improved from 2.3828 to 2.3821. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9951\n",
      "Epoch [353/2000], Avg Train Loss: 3.9951\n",
      "Epoch [353/2000], Avg Val Loss: 2.3814\n",
      "Validation loss improved from 2.3821 to 2.3814. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9988\n",
      "Epoch [354/2000], Avg Train Loss: 3.9988\n",
      "Epoch [354/2000], Avg Val Loss: 2.3806\n",
      "Validation loss improved from 2.3814 to 2.3806. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9950\n",
      "Epoch [355/2000], Avg Train Loss: 3.9950\n",
      "Epoch [355/2000], Avg Val Loss: 2.3799\n",
      "Validation loss improved from 2.3806 to 2.3799. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9691\n",
      "Epoch [356/2000], Avg Train Loss: 3.9691\n",
      "Epoch [356/2000], Avg Val Loss: 2.3792\n",
      "Validation loss improved from 2.3799 to 2.3792. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0089\n",
      "Epoch [357/2000], Avg Train Loss: 4.0089\n",
      "Epoch [357/2000], Avg Val Loss: 2.3784\n",
      "Validation loss improved from 2.3792 to 2.3784. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0127\n",
      "Epoch [358/2000], Avg Train Loss: 4.0127\n",
      "Epoch [358/2000], Avg Val Loss: 2.3777\n",
      "Validation loss improved from 2.3784 to 2.3777. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9424\n",
      "Epoch [359/2000], Avg Train Loss: 3.9424\n",
      "Epoch [359/2000], Avg Val Loss: 2.3770\n",
      "Validation loss improved from 2.3777 to 2.3770. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9969\n",
      "Epoch [360/2000], Avg Train Loss: 3.9969\n",
      "Epoch [360/2000], Avg Val Loss: 2.3763\n",
      "Validation loss improved from 2.3770 to 2.3763. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9533\n",
      "Epoch [361/2000], Avg Train Loss: 3.9533\n",
      "Epoch [361/2000], Avg Val Loss: 2.3756\n",
      "Validation loss improved from 2.3763 to 2.3756. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9853\n",
      "Epoch [362/2000], Avg Train Loss: 3.9853\n",
      "Epoch [362/2000], Avg Val Loss: 2.3750\n",
      "Validation loss improved from 2.3756 to 2.3750. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9544\n",
      "Epoch [363/2000], Avg Train Loss: 3.9544\n",
      "Epoch [363/2000], Avg Val Loss: 2.3743\n",
      "Validation loss improved from 2.3750 to 2.3743. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9209\n",
      "Epoch [364/2000], Avg Train Loss: 3.9209\n",
      "Epoch [364/2000], Avg Val Loss: 2.3736\n",
      "Validation loss improved from 2.3743 to 2.3736. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9730\n",
      "Epoch [365/2000], Avg Train Loss: 3.9730\n",
      "Epoch [365/2000], Avg Val Loss: 2.3729\n",
      "Validation loss improved from 2.3736 to 2.3729. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9407\n",
      "Epoch [366/2000], Avg Train Loss: 3.9407\n",
      "Epoch [366/2000], Avg Val Loss: 2.3722\n",
      "Validation loss improved from 2.3729 to 2.3722. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9555\n",
      "Epoch [367/2000], Avg Train Loss: 3.9555\n",
      "Epoch [367/2000], Avg Val Loss: 2.3715\n",
      "Validation loss improved from 2.3722 to 2.3715. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9531\n",
      "Epoch [368/2000], Avg Train Loss: 3.9531\n",
      "Epoch [368/2000], Avg Val Loss: 2.3708\n",
      "Validation loss improved from 2.3715 to 2.3708. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9763\n",
      "Epoch [369/2000], Avg Train Loss: 3.9763\n",
      "Epoch [369/2000], Avg Val Loss: 2.3700\n",
      "Validation loss improved from 2.3708 to 2.3700. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9336\n",
      "Epoch [370/2000], Avg Train Loss: 3.9336\n",
      "Epoch [370/2000], Avg Val Loss: 2.3693\n",
      "Validation loss improved from 2.3700 to 2.3693. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9546\n",
      "Epoch [371/2000], Avg Train Loss: 3.9546\n",
      "Epoch [371/2000], Avg Val Loss: 2.3686\n",
      "Validation loss improved from 2.3693 to 2.3686. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9490\n",
      "Epoch [372/2000], Avg Train Loss: 3.9490\n",
      "Epoch [372/2000], Avg Val Loss: 2.3679\n",
      "Validation loss improved from 2.3686 to 2.3679. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9406\n",
      "Epoch [373/2000], Avg Train Loss: 3.9406\n",
      "Epoch [373/2000], Avg Val Loss: 2.3672\n",
      "Validation loss improved from 2.3679 to 2.3672. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9778\n",
      "Epoch [374/2000], Avg Train Loss: 3.9778\n",
      "Epoch [374/2000], Avg Val Loss: 2.3666\n",
      "Validation loss improved from 2.3672 to 2.3666. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9672\n",
      "Epoch [375/2000], Avg Train Loss: 3.9672\n",
      "Epoch [375/2000], Avg Val Loss: 2.3659\n",
      "Validation loss improved from 2.3666 to 2.3659. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9613\n",
      "Epoch [376/2000], Avg Train Loss: 3.9613\n",
      "Epoch [376/2000], Avg Val Loss: 2.3652\n",
      "Validation loss improved from 2.3659 to 2.3652. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9383\n",
      "Epoch [377/2000], Avg Train Loss: 3.9383\n",
      "Epoch [377/2000], Avg Val Loss: 2.3646\n",
      "Validation loss improved from 2.3652 to 2.3646. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9103\n",
      "Epoch [378/2000], Avg Train Loss: 3.9103\n",
      "Epoch [378/2000], Avg Val Loss: 2.3640\n",
      "Validation loss improved from 2.3646 to 2.3640. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9552\n",
      "Epoch [379/2000], Avg Train Loss: 3.9552\n",
      "Epoch [379/2000], Avg Val Loss: 2.3634\n",
      "Validation loss improved from 2.3640 to 2.3634. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9343\n",
      "Epoch [380/2000], Avg Train Loss: 3.9343\n",
      "Epoch [380/2000], Avg Val Loss: 2.3627\n",
      "Validation loss improved from 2.3634 to 2.3627. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9173\n",
      "Epoch [381/2000], Avg Train Loss: 3.9173\n",
      "Epoch [381/2000], Avg Val Loss: 2.3621\n",
      "Validation loss improved from 2.3627 to 2.3621. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9407\n",
      "Epoch [382/2000], Avg Train Loss: 3.9407\n",
      "Epoch [382/2000], Avg Val Loss: 2.3615\n",
      "Validation loss improved from 2.3621 to 2.3615. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9661\n",
      "Epoch [383/2000], Avg Train Loss: 3.9661\n",
      "Epoch [383/2000], Avg Val Loss: 2.3609\n",
      "Validation loss improved from 2.3615 to 2.3609. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9460\n",
      "Epoch [384/2000], Avg Train Loss: 3.9460\n",
      "Epoch [384/2000], Avg Val Loss: 2.3603\n",
      "Validation loss improved from 2.3609 to 2.3603. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9280\n",
      "Epoch [385/2000], Avg Train Loss: 3.9280\n",
      "Epoch [385/2000], Avg Val Loss: 2.3597\n",
      "Validation loss improved from 2.3603 to 2.3597. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9218\n",
      "Epoch [386/2000], Avg Train Loss: 3.9218\n",
      "Epoch [386/2000], Avg Val Loss: 2.3590\n",
      "Validation loss improved from 2.3597 to 2.3590. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9423\n",
      "Epoch [387/2000], Avg Train Loss: 3.9423\n",
      "Epoch [387/2000], Avg Val Loss: 2.3584\n",
      "Validation loss improved from 2.3590 to 2.3584. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9448\n",
      "Epoch [388/2000], Avg Train Loss: 3.9448\n",
      "Epoch [388/2000], Avg Val Loss: 2.3578\n",
      "Validation loss improved from 2.3584 to 2.3578. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9300\n",
      "Epoch [389/2000], Avg Train Loss: 3.9300\n",
      "Epoch [389/2000], Avg Val Loss: 2.3572\n",
      "Validation loss improved from 2.3578 to 2.3572. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9276\n",
      "Epoch [390/2000], Avg Train Loss: 3.9276\n",
      "Epoch [390/2000], Avg Val Loss: 2.3566\n",
      "Validation loss improved from 2.3572 to 2.3566. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9601\n",
      "Epoch [391/2000], Avg Train Loss: 3.9601\n",
      "Epoch [391/2000], Avg Val Loss: 2.3560\n",
      "Validation loss improved from 2.3566 to 2.3560. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9153\n",
      "Epoch [392/2000], Avg Train Loss: 3.9153\n",
      "Epoch [392/2000], Avg Val Loss: 2.3554\n",
      "Validation loss improved from 2.3560 to 2.3554. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9027\n",
      "Epoch [393/2000], Avg Train Loss: 3.9027\n",
      "Epoch [393/2000], Avg Val Loss: 2.3548\n",
      "Validation loss improved from 2.3554 to 2.3548. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9601\n",
      "Epoch [394/2000], Avg Train Loss: 3.9601\n",
      "Epoch [394/2000], Avg Val Loss: 2.3542\n",
      "Validation loss improved from 2.3548 to 2.3542. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8880\n",
      "Epoch [395/2000], Avg Train Loss: 3.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [395/2000], Avg Val Loss: 2.3535\n",
      "Validation loss improved from 2.3542 to 2.3535. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9337\n",
      "Epoch [396/2000], Avg Train Loss: 3.9337\n",
      "Epoch [396/2000], Avg Val Loss: 2.3529\n",
      "Validation loss improved from 2.3535 to 2.3529. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9110\n",
      "Epoch [397/2000], Avg Train Loss: 3.9110\n",
      "Epoch [397/2000], Avg Val Loss: 2.3523\n",
      "Validation loss improved from 2.3529 to 2.3523. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9093\n",
      "Epoch [398/2000], Avg Train Loss: 3.9093\n",
      "Epoch [398/2000], Avg Val Loss: 2.3516\n",
      "Validation loss improved from 2.3523 to 2.3516. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9199\n",
      "Epoch [399/2000], Avg Train Loss: 3.9199\n",
      "Epoch [399/2000], Avg Val Loss: 2.3510\n",
      "Validation loss improved from 2.3516 to 2.3510. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9368\n",
      "Epoch [400/2000], Avg Train Loss: 3.9368\n",
      "Epoch [400/2000], Avg Val Loss: 2.3504\n",
      "Validation loss improved from 2.3510 to 2.3504. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9357\n",
      "Epoch [401/2000], Avg Train Loss: 3.9357\n",
      "Epoch [401/2000], Avg Val Loss: 2.3498\n",
      "Validation loss improved from 2.3504 to 2.3498. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9608\n",
      "Epoch [402/2000], Avg Train Loss: 3.9608\n",
      "Epoch [402/2000], Avg Val Loss: 2.3492\n",
      "Validation loss improved from 2.3498 to 2.3492. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9432\n",
      "Epoch [403/2000], Avg Train Loss: 3.9432\n",
      "Epoch [403/2000], Avg Val Loss: 2.3486\n",
      "Validation loss improved from 2.3492 to 2.3486. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9212\n",
      "Epoch [404/2000], Avg Train Loss: 3.9212\n",
      "Epoch [404/2000], Avg Val Loss: 2.3480\n",
      "Validation loss improved from 2.3486 to 2.3480. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9307\n",
      "Epoch [405/2000], Avg Train Loss: 3.9307\n",
      "Epoch [405/2000], Avg Val Loss: 2.3475\n",
      "Validation loss improved from 2.3480 to 2.3475. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9054\n",
      "Epoch [406/2000], Avg Train Loss: 3.9054\n",
      "Epoch [406/2000], Avg Val Loss: 2.3469\n",
      "Validation loss improved from 2.3475 to 2.3469. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9358\n",
      "Epoch [407/2000], Avg Train Loss: 3.9358\n",
      "Epoch [407/2000], Avg Val Loss: 2.3464\n",
      "Validation loss improved from 2.3469 to 2.3464. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9192\n",
      "Epoch [408/2000], Avg Train Loss: 3.9192\n",
      "Epoch [408/2000], Avg Val Loss: 2.3458\n",
      "Validation loss improved from 2.3464 to 2.3458. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9362\n",
      "Epoch [409/2000], Avg Train Loss: 3.9362\n",
      "Epoch [409/2000], Avg Val Loss: 2.3453\n",
      "Validation loss improved from 2.3458 to 2.3453. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9207\n",
      "Epoch [410/2000], Avg Train Loss: 3.9207\n",
      "Epoch [410/2000], Avg Val Loss: 2.3447\n",
      "Validation loss improved from 2.3453 to 2.3447. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9177\n",
      "Epoch [411/2000], Avg Train Loss: 3.9177\n",
      "Epoch [411/2000], Avg Val Loss: 2.3442\n",
      "Validation loss improved from 2.3447 to 2.3442. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9062\n",
      "Epoch [412/2000], Avg Train Loss: 3.9062\n",
      "Epoch [412/2000], Avg Val Loss: 2.3436\n",
      "Validation loss improved from 2.3442 to 2.3436. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8837\n",
      "Epoch [413/2000], Avg Train Loss: 3.8837\n",
      "Epoch [413/2000], Avg Val Loss: 2.3430\n",
      "Validation loss improved from 2.3436 to 2.3430. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8984\n",
      "Epoch [414/2000], Avg Train Loss: 3.8984\n",
      "Epoch [414/2000], Avg Val Loss: 2.3425\n",
      "Validation loss improved from 2.3430 to 2.3425. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8881\n",
      "Epoch [415/2000], Avg Train Loss: 3.8881\n",
      "Epoch [415/2000], Avg Val Loss: 2.3420\n",
      "Validation loss improved from 2.3425 to 2.3420. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9272\n",
      "Epoch [416/2000], Avg Train Loss: 3.9272\n",
      "Epoch [416/2000], Avg Val Loss: 2.3414\n",
      "Validation loss improved from 2.3420 to 2.3414. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9452\n",
      "Epoch [417/2000], Avg Train Loss: 3.9452\n",
      "Epoch [417/2000], Avg Val Loss: 2.3408\n",
      "Validation loss improved from 2.3414 to 2.3408. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8572\n",
      "Epoch [418/2000], Avg Train Loss: 3.8572\n",
      "Epoch [418/2000], Avg Val Loss: 2.3403\n",
      "Validation loss improved from 2.3408 to 2.3403. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8985\n",
      "Epoch [419/2000], Avg Train Loss: 3.8985\n",
      "Epoch [419/2000], Avg Val Loss: 2.3398\n",
      "Validation loss improved from 2.3403 to 2.3398. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9098\n",
      "Epoch [420/2000], Avg Train Loss: 3.9098\n",
      "Epoch [420/2000], Avg Val Loss: 2.3392\n",
      "Validation loss improved from 2.3398 to 2.3392. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8620\n",
      "Epoch [421/2000], Avg Train Loss: 3.8620\n",
      "Epoch [421/2000], Avg Val Loss: 2.3387\n",
      "Validation loss improved from 2.3392 to 2.3387. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8829\n",
      "Epoch [422/2000], Avg Train Loss: 3.8829\n",
      "Epoch [422/2000], Avg Val Loss: 2.3381\n",
      "Validation loss improved from 2.3387 to 2.3381. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8671\n",
      "Epoch [423/2000], Avg Train Loss: 3.8671\n",
      "Epoch [423/2000], Avg Val Loss: 2.3376\n",
      "Validation loss improved from 2.3381 to 2.3376. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9045\n",
      "Epoch [424/2000], Avg Train Loss: 3.9045\n",
      "Epoch [424/2000], Avg Val Loss: 2.3370\n",
      "Validation loss improved from 2.3376 to 2.3370. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9192\n",
      "Epoch [425/2000], Avg Train Loss: 3.9192\n",
      "Epoch [425/2000], Avg Val Loss: 2.3365\n",
      "Validation loss improved from 2.3370 to 2.3365. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8711\n",
      "Epoch [426/2000], Avg Train Loss: 3.8711\n",
      "Epoch [426/2000], Avg Val Loss: 2.3359\n",
      "Validation loss improved from 2.3365 to 2.3359. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8980\n",
      "Epoch [427/2000], Avg Train Loss: 3.8980\n",
      "Epoch [427/2000], Avg Val Loss: 2.3354\n",
      "Validation loss improved from 2.3359 to 2.3354. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8919\n",
      "Epoch [428/2000], Avg Train Loss: 3.8919\n",
      "Epoch [428/2000], Avg Val Loss: 2.3348\n",
      "Validation loss improved from 2.3354 to 2.3348. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9081\n",
      "Epoch [429/2000], Avg Train Loss: 3.9081\n",
      "Epoch [429/2000], Avg Val Loss: 2.3342\n",
      "Validation loss improved from 2.3348 to 2.3342. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9298\n",
      "Epoch [430/2000], Avg Train Loss: 3.9298\n",
      "Epoch [430/2000], Avg Val Loss: 2.3336\n",
      "Validation loss improved from 2.3342 to 2.3336. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9182\n",
      "Epoch [431/2000], Avg Train Loss: 3.9182\n",
      "Epoch [431/2000], Avg Val Loss: 2.3330\n",
      "Validation loss improved from 2.3336 to 2.3330. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9257\n",
      "Epoch [432/2000], Avg Train Loss: 3.9257\n",
      "Epoch [432/2000], Avg Val Loss: 2.3324\n",
      "Validation loss improved from 2.3330 to 2.3324. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9078\n",
      "Epoch [433/2000], Avg Train Loss: 3.9078\n",
      "Epoch [433/2000], Avg Val Loss: 2.3319\n",
      "Validation loss improved from 2.3324 to 2.3319. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8555\n",
      "Epoch [434/2000], Avg Train Loss: 3.8555\n",
      "Epoch [434/2000], Avg Val Loss: 2.3313\n",
      "Validation loss improved from 2.3319 to 2.3313. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9254\n",
      "Epoch [435/2000], Avg Train Loss: 3.9254\n",
      "Epoch [435/2000], Avg Val Loss: 2.3307\n",
      "Validation loss improved from 2.3313 to 2.3307. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8732\n",
      "Epoch [436/2000], Avg Train Loss: 3.8732\n",
      "Epoch [436/2000], Avg Val Loss: 2.3301\n",
      "Validation loss improved from 2.3307 to 2.3301. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8975\n",
      "Epoch [437/2000], Avg Train Loss: 3.8975\n",
      "Epoch [437/2000], Avg Val Loss: 2.3296\n",
      "Validation loss improved from 2.3301 to 2.3296. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8692\n",
      "Epoch [438/2000], Avg Train Loss: 3.8692\n",
      "Epoch [438/2000], Avg Val Loss: 2.3291\n",
      "Validation loss improved from 2.3296 to 2.3291. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8828\n",
      "Epoch [439/2000], Avg Train Loss: 3.8828\n",
      "Epoch [439/2000], Avg Val Loss: 2.3285\n",
      "Validation loss improved from 2.3291 to 2.3285. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9042\n",
      "Epoch [440/2000], Avg Train Loss: 3.9042\n",
      "Epoch [440/2000], Avg Val Loss: 2.3280\n",
      "Validation loss improved from 2.3285 to 2.3280. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8944\n",
      "Epoch [441/2000], Avg Train Loss: 3.8944\n",
      "Epoch [441/2000], Avg Val Loss: 2.3275\n",
      "Validation loss improved from 2.3280 to 2.3275. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8971\n",
      "Epoch [442/2000], Avg Train Loss: 3.8971\n",
      "Epoch [442/2000], Avg Val Loss: 2.3269\n",
      "Validation loss improved from 2.3275 to 2.3269. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8635\n",
      "Epoch [443/2000], Avg Train Loss: 3.8635\n",
      "Epoch [443/2000], Avg Val Loss: 2.3264\n",
      "Validation loss improved from 2.3269 to 2.3264. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8617\n",
      "Epoch [444/2000], Avg Train Loss: 3.8617\n",
      "Epoch [444/2000], Avg Val Loss: 2.3259\n",
      "Validation loss improved from 2.3264 to 2.3259. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9017\n",
      "Epoch [445/2000], Avg Train Loss: 3.9017\n",
      "Epoch [445/2000], Avg Val Loss: 2.3253\n",
      "Validation loss improved from 2.3259 to 2.3253. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8607\n",
      "Epoch [446/2000], Avg Train Loss: 3.8607\n",
      "Epoch [446/2000], Avg Val Loss: 2.3247\n",
      "Validation loss improved from 2.3253 to 2.3247. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8584\n",
      "Epoch [447/2000], Avg Train Loss: 3.8584\n",
      "Epoch [447/2000], Avg Val Loss: 2.3241\n",
      "Validation loss improved from 2.3247 to 2.3241. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9031\n",
      "Epoch [448/2000], Avg Train Loss: 3.9031\n",
      "Epoch [448/2000], Avg Val Loss: 2.3236\n",
      "Validation loss improved from 2.3241 to 2.3236. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8768\n",
      "Epoch [449/2000], Avg Train Loss: 3.8768\n",
      "Epoch [449/2000], Avg Val Loss: 2.3230\n",
      "Validation loss improved from 2.3236 to 2.3230. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8468\n",
      "Epoch [450/2000], Avg Train Loss: 3.8468\n",
      "Epoch [450/2000], Avg Val Loss: 2.3225\n",
      "Validation loss improved from 2.3230 to 2.3225. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8795\n",
      "Epoch [451/2000], Avg Train Loss: 3.8795\n",
      "Epoch [451/2000], Avg Val Loss: 2.3219\n",
      "Validation loss improved from 2.3225 to 2.3219. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8796\n",
      "Epoch [452/2000], Avg Train Loss: 3.8796\n",
      "Epoch [452/2000], Avg Val Loss: 2.3213\n",
      "Validation loss improved from 2.3219 to 2.3213. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8781\n",
      "Epoch [453/2000], Avg Train Loss: 3.8781\n",
      "Epoch [453/2000], Avg Val Loss: 2.3207\n",
      "Validation loss improved from 2.3213 to 2.3207. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8714\n",
      "Epoch [454/2000], Avg Train Loss: 3.8714\n",
      "Epoch [454/2000], Avg Val Loss: 2.3201\n",
      "Validation loss improved from 2.3207 to 2.3201. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8498\n",
      "Epoch [455/2000], Avg Train Loss: 3.8498\n",
      "Epoch [455/2000], Avg Val Loss: 2.3195\n",
      "Validation loss improved from 2.3201 to 2.3195. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8564\n",
      "Epoch [456/2000], Avg Train Loss: 3.8564\n",
      "Epoch [456/2000], Avg Val Loss: 2.3190\n",
      "Validation loss improved from 2.3195 to 2.3190. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8608\n",
      "Epoch [457/2000], Avg Train Loss: 3.8608\n",
      "Epoch [457/2000], Avg Val Loss: 2.3184\n",
      "Validation loss improved from 2.3190 to 2.3184. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8399\n",
      "Epoch [458/2000], Avg Train Loss: 3.8399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [458/2000], Avg Val Loss: 2.3178\n",
      "Validation loss improved from 2.3184 to 2.3178. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8605\n",
      "Epoch [459/2000], Avg Train Loss: 3.8605\n",
      "Epoch [459/2000], Avg Val Loss: 2.3172\n",
      "Validation loss improved from 2.3178 to 2.3172. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8623\n",
      "Epoch [460/2000], Avg Train Loss: 3.8623\n",
      "Epoch [460/2000], Avg Val Loss: 2.3167\n",
      "Validation loss improved from 2.3172 to 2.3167. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8815\n",
      "Epoch [461/2000], Avg Train Loss: 3.8815\n",
      "Epoch [461/2000], Avg Val Loss: 2.3161\n",
      "Validation loss improved from 2.3167 to 2.3161. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8608\n",
      "Epoch [462/2000], Avg Train Loss: 3.8608\n",
      "Epoch [462/2000], Avg Val Loss: 2.3156\n",
      "Validation loss improved from 2.3161 to 2.3156. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8512\n",
      "Epoch [463/2000], Avg Train Loss: 3.8512\n",
      "Epoch [463/2000], Avg Val Loss: 2.3150\n",
      "Validation loss improved from 2.3156 to 2.3150. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8244\n",
      "Epoch [464/2000], Avg Train Loss: 3.8244\n",
      "Epoch [464/2000], Avg Val Loss: 2.3144\n",
      "Validation loss improved from 2.3150 to 2.3144. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8482\n",
      "Epoch [465/2000], Avg Train Loss: 3.8482\n",
      "Epoch [465/2000], Avg Val Loss: 2.3139\n",
      "Validation loss improved from 2.3144 to 2.3139. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8659\n",
      "Epoch [466/2000], Avg Train Loss: 3.8659\n",
      "Epoch [466/2000], Avg Val Loss: 2.3133\n",
      "Validation loss improved from 2.3139 to 2.3133. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8330\n",
      "Epoch [467/2000], Avg Train Loss: 3.8330\n",
      "Epoch [467/2000], Avg Val Loss: 2.3127\n",
      "Validation loss improved from 2.3133 to 2.3127. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8782\n",
      "Epoch [468/2000], Avg Train Loss: 3.8782\n",
      "Epoch [468/2000], Avg Val Loss: 2.3121\n",
      "Validation loss improved from 2.3127 to 2.3121. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8088\n",
      "Epoch [469/2000], Avg Train Loss: 3.8088\n",
      "Epoch [469/2000], Avg Val Loss: 2.3115\n",
      "Validation loss improved from 2.3121 to 2.3115. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8499\n",
      "Epoch [470/2000], Avg Train Loss: 3.8499\n",
      "Epoch [470/2000], Avg Val Loss: 2.3110\n",
      "Validation loss improved from 2.3115 to 2.3110. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8171\n",
      "Epoch [471/2000], Avg Train Loss: 3.8171\n",
      "Epoch [471/2000], Avg Val Loss: 2.3104\n",
      "Validation loss improved from 2.3110 to 2.3104. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8522\n",
      "Epoch [472/2000], Avg Train Loss: 3.8522\n",
      "Epoch [472/2000], Avg Val Loss: 2.3098\n",
      "Validation loss improved from 2.3104 to 2.3098. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8493\n",
      "Epoch [473/2000], Avg Train Loss: 3.8493\n",
      "Epoch [473/2000], Avg Val Loss: 2.3093\n",
      "Validation loss improved from 2.3098 to 2.3093. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8163\n",
      "Epoch [474/2000], Avg Train Loss: 3.8163\n",
      "Epoch [474/2000], Avg Val Loss: 2.3087\n",
      "Validation loss improved from 2.3093 to 2.3087. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8360\n",
      "Epoch [475/2000], Avg Train Loss: 3.8360\n",
      "Epoch [475/2000], Avg Val Loss: 2.3082\n",
      "Validation loss improved from 2.3087 to 2.3082. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8287\n",
      "Epoch [476/2000], Avg Train Loss: 3.8287\n",
      "Epoch [476/2000], Avg Val Loss: 2.3077\n",
      "Validation loss improved from 2.3082 to 2.3077. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8263\n",
      "Epoch [477/2000], Avg Train Loss: 3.8263\n",
      "Epoch [477/2000], Avg Val Loss: 2.3071\n",
      "Validation loss improved from 2.3077 to 2.3071. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8386\n",
      "Epoch [478/2000], Avg Train Loss: 3.8386\n",
      "Epoch [478/2000], Avg Val Loss: 2.3066\n",
      "Validation loss improved from 2.3071 to 2.3066. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8474\n",
      "Epoch [479/2000], Avg Train Loss: 3.8474\n",
      "Epoch [479/2000], Avg Val Loss: 2.3061\n",
      "Validation loss improved from 2.3066 to 2.3061. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8380\n",
      "Epoch [480/2000], Avg Train Loss: 3.8380\n",
      "Epoch [480/2000], Avg Val Loss: 2.3056\n",
      "Validation loss improved from 2.3061 to 2.3056. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7863\n",
      "Epoch [481/2000], Avg Train Loss: 3.7863\n",
      "Epoch [481/2000], Avg Val Loss: 2.3051\n",
      "Validation loss improved from 2.3056 to 2.3051. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8675\n",
      "Epoch [482/2000], Avg Train Loss: 3.8675\n",
      "Epoch [482/2000], Avg Val Loss: 2.3045\n",
      "Validation loss improved from 2.3051 to 2.3045. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8310\n",
      "Epoch [483/2000], Avg Train Loss: 3.8310\n",
      "Epoch [483/2000], Avg Val Loss: 2.3040\n",
      "Validation loss improved from 2.3045 to 2.3040. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8193\n",
      "Epoch [484/2000], Avg Train Loss: 3.8193\n",
      "Epoch [484/2000], Avg Val Loss: 2.3035\n",
      "Validation loss improved from 2.3040 to 2.3035. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8313\n",
      "Epoch [485/2000], Avg Train Loss: 3.8313\n",
      "Epoch [485/2000], Avg Val Loss: 2.3030\n",
      "Validation loss improved from 2.3035 to 2.3030. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8273\n",
      "Epoch [486/2000], Avg Train Loss: 3.8273\n",
      "Epoch [486/2000], Avg Val Loss: 2.3025\n",
      "Validation loss improved from 2.3030 to 2.3025. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8151\n",
      "Epoch [487/2000], Avg Train Loss: 3.8151\n",
      "Epoch [487/2000], Avg Val Loss: 2.3020\n",
      "Validation loss improved from 2.3025 to 2.3020. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7652\n",
      "Epoch [488/2000], Avg Train Loss: 3.7652\n",
      "Epoch [488/2000], Avg Val Loss: 2.3015\n",
      "Validation loss improved from 2.3020 to 2.3015. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8207\n",
      "Epoch [489/2000], Avg Train Loss: 3.8207\n",
      "Epoch [489/2000], Avg Val Loss: 2.3010\n",
      "Validation loss improved from 2.3015 to 2.3010. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8480\n",
      "Epoch [490/2000], Avg Train Loss: 3.8480\n",
      "Epoch [490/2000], Avg Val Loss: 2.3005\n",
      "Validation loss improved from 2.3010 to 2.3005. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8021\n",
      "Epoch [491/2000], Avg Train Loss: 3.8021\n",
      "Epoch [491/2000], Avg Val Loss: 2.2999\n",
      "Validation loss improved from 2.3005 to 2.2999. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8235\n",
      "Epoch [492/2000], Avg Train Loss: 3.8235\n",
      "Epoch [492/2000], Avg Val Loss: 2.2994\n",
      "Validation loss improved from 2.2999 to 2.2994. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8481\n",
      "Epoch [493/2000], Avg Train Loss: 3.8481\n",
      "Epoch [493/2000], Avg Val Loss: 2.2988\n",
      "Validation loss improved from 2.2994 to 2.2988. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7998\n",
      "Epoch [494/2000], Avg Train Loss: 3.7998\n",
      "Epoch [494/2000], Avg Val Loss: 2.2982\n",
      "Validation loss improved from 2.2988 to 2.2982. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8463\n",
      "Epoch [495/2000], Avg Train Loss: 3.8463\n",
      "Epoch [495/2000], Avg Val Loss: 2.2977\n",
      "Validation loss improved from 2.2982 to 2.2977. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8157\n",
      "Epoch [496/2000], Avg Train Loss: 3.8157\n",
      "Epoch [496/2000], Avg Val Loss: 2.2972\n",
      "Validation loss improved from 2.2977 to 2.2972. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8621\n",
      "Epoch [497/2000], Avg Train Loss: 3.8621\n",
      "Epoch [497/2000], Avg Val Loss: 2.2966\n",
      "Validation loss improved from 2.2972 to 2.2966. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8172\n",
      "Epoch [498/2000], Avg Train Loss: 3.8172\n",
      "Epoch [498/2000], Avg Val Loss: 2.2961\n",
      "Validation loss improved from 2.2966 to 2.2961. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7857\n",
      "Epoch [499/2000], Avg Train Loss: 3.7857\n",
      "Epoch [499/2000], Avg Val Loss: 2.2956\n",
      "Validation loss improved from 2.2961 to 2.2956. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8017\n",
      "Epoch [500/2000], Avg Train Loss: 3.8017\n",
      "Epoch [500/2000], Avg Val Loss: 2.2950\n",
      "Validation loss improved from 2.2956 to 2.2950. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8180\n",
      "Epoch [501/2000], Avg Train Loss: 3.8180\n",
      "Epoch [501/2000], Avg Val Loss: 2.2945\n",
      "Validation loss improved from 2.2950 to 2.2945. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8488\n",
      "Epoch [502/2000], Avg Train Loss: 3.8488\n",
      "Epoch [502/2000], Avg Val Loss: 2.2940\n",
      "Validation loss improved from 2.2945 to 2.2940. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8329\n",
      "Epoch [503/2000], Avg Train Loss: 3.8329\n",
      "Epoch [503/2000], Avg Val Loss: 2.2934\n",
      "Validation loss improved from 2.2940 to 2.2934. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8459\n",
      "Epoch [504/2000], Avg Train Loss: 3.8459\n",
      "Epoch [504/2000], Avg Val Loss: 2.2929\n",
      "Validation loss improved from 2.2934 to 2.2929. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8390\n",
      "Epoch [505/2000], Avg Train Loss: 3.8390\n",
      "Epoch [505/2000], Avg Val Loss: 2.2924\n",
      "Validation loss improved from 2.2929 to 2.2924. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8392\n",
      "Epoch [506/2000], Avg Train Loss: 3.8392\n",
      "Epoch [506/2000], Avg Val Loss: 2.2919\n",
      "Validation loss improved from 2.2924 to 2.2919. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7799\n",
      "Epoch [507/2000], Avg Train Loss: 3.7799\n",
      "Epoch [507/2000], Avg Val Loss: 2.2914\n",
      "Validation loss improved from 2.2919 to 2.2914. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7986\n",
      "Epoch [508/2000], Avg Train Loss: 3.7986\n",
      "Epoch [508/2000], Avg Val Loss: 2.2910\n",
      "Validation loss improved from 2.2914 to 2.2910. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8237\n",
      "Epoch [509/2000], Avg Train Loss: 3.8237\n",
      "Epoch [509/2000], Avg Val Loss: 2.2905\n",
      "Validation loss improved from 2.2910 to 2.2905. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8493\n",
      "Epoch [510/2000], Avg Train Loss: 3.8493\n",
      "Epoch [510/2000], Avg Val Loss: 2.2901\n",
      "Validation loss improved from 2.2905 to 2.2901. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8021\n",
      "Epoch [511/2000], Avg Train Loss: 3.8021\n",
      "Epoch [511/2000], Avg Val Loss: 2.2896\n",
      "Validation loss improved from 2.2901 to 2.2896. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8050\n",
      "Epoch [512/2000], Avg Train Loss: 3.8050\n",
      "Epoch [512/2000], Avg Val Loss: 2.2891\n",
      "Validation loss improved from 2.2896 to 2.2891. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8388\n",
      "Epoch [513/2000], Avg Train Loss: 3.8388\n",
      "Epoch [513/2000], Avg Val Loss: 2.2886\n",
      "Validation loss improved from 2.2891 to 2.2886. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8623\n",
      "Epoch [514/2000], Avg Train Loss: 3.8623\n",
      "Epoch [514/2000], Avg Val Loss: 2.2881\n",
      "Validation loss improved from 2.2886 to 2.2881. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8244\n",
      "Epoch [515/2000], Avg Train Loss: 3.8244\n",
      "Epoch [515/2000], Avg Val Loss: 2.2877\n",
      "Validation loss improved from 2.2881 to 2.2877. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7983\n",
      "Epoch [516/2000], Avg Train Loss: 3.7983\n",
      "Epoch [516/2000], Avg Val Loss: 2.2873\n",
      "Validation loss improved from 2.2877 to 2.2873. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8026\n",
      "Epoch [517/2000], Avg Train Loss: 3.8026\n",
      "Epoch [517/2000], Avg Val Loss: 2.2868\n",
      "Validation loss improved from 2.2873 to 2.2868. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8112\n",
      "Epoch [518/2000], Avg Train Loss: 3.8112\n",
      "Epoch [518/2000], Avg Val Loss: 2.2864\n",
      "Validation loss improved from 2.2868 to 2.2864. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8113\n",
      "Epoch [519/2000], Avg Train Loss: 3.8113\n",
      "Epoch [519/2000], Avg Val Loss: 2.2860\n",
      "Validation loss improved from 2.2864 to 2.2860. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7851\n",
      "Epoch [520/2000], Avg Train Loss: 3.7851\n",
      "Epoch [520/2000], Avg Val Loss: 2.2856\n",
      "Validation loss improved from 2.2860 to 2.2856. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8046\n",
      "Epoch [521/2000], Avg Train Loss: 3.8046\n",
      "Epoch [521/2000], Avg Val Loss: 2.2851\n",
      "Validation loss improved from 2.2856 to 2.2851. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8113\n",
      "Epoch [522/2000], Avg Train Loss: 3.8113\n",
      "Epoch [522/2000], Avg Val Loss: 2.2847\n",
      "Validation loss improved from 2.2851 to 2.2847. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7805\n",
      "Epoch [523/2000], Avg Train Loss: 3.7805\n",
      "Epoch [523/2000], Avg Val Loss: 2.2843\n",
      "Validation loss improved from 2.2847 to 2.2843. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8078\n",
      "Epoch [524/2000], Avg Train Loss: 3.8078\n",
      "Epoch [524/2000], Avg Val Loss: 2.2839\n",
      "Validation loss improved from 2.2843 to 2.2839. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7776\n",
      "Epoch [525/2000], Avg Train Loss: 3.7776\n",
      "Epoch [525/2000], Avg Val Loss: 2.2834\n",
      "Validation loss improved from 2.2839 to 2.2834. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7661\n",
      "Epoch [526/2000], Avg Train Loss: 3.7661\n",
      "Epoch [526/2000], Avg Val Loss: 2.2829\n",
      "Validation loss improved from 2.2834 to 2.2829. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8051\n",
      "Epoch [527/2000], Avg Train Loss: 3.8051\n",
      "Epoch [527/2000], Avg Val Loss: 2.2825\n",
      "Validation loss improved from 2.2829 to 2.2825. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7520\n",
      "Epoch [528/2000], Avg Train Loss: 3.7520\n",
      "Epoch [528/2000], Avg Val Loss: 2.2820\n",
      "Validation loss improved from 2.2825 to 2.2820. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8149\n",
      "Epoch [529/2000], Avg Train Loss: 3.8149\n",
      "Epoch [529/2000], Avg Val Loss: 2.2816\n",
      "Validation loss improved from 2.2820 to 2.2816. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8064\n",
      "Epoch [530/2000], Avg Train Loss: 3.8064\n",
      "Epoch [530/2000], Avg Val Loss: 2.2812\n",
      "Validation loss improved from 2.2816 to 2.2812. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7873\n",
      "Epoch [531/2000], Avg Train Loss: 3.7873\n",
      "Epoch [531/2000], Avg Val Loss: 2.2808\n",
      "Validation loss improved from 2.2812 to 2.2808. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7843\n",
      "Epoch [532/2000], Avg Train Loss: 3.7843\n",
      "Epoch [532/2000], Avg Val Loss: 2.2804\n",
      "Validation loss improved from 2.2808 to 2.2804. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7747\n",
      "Epoch [533/2000], Avg Train Loss: 3.7747\n",
      "Epoch [533/2000], Avg Val Loss: 2.2800\n",
      "Validation loss improved from 2.2804 to 2.2800. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7871\n",
      "Epoch [534/2000], Avg Train Loss: 3.7871\n",
      "Epoch [534/2000], Avg Val Loss: 2.2795\n",
      "Validation loss improved from 2.2800 to 2.2795. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8332\n",
      "Epoch [535/2000], Avg Train Loss: 3.8332\n",
      "Epoch [535/2000], Avg Val Loss: 2.2791\n",
      "Validation loss improved from 2.2795 to 2.2791. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7848\n",
      "Epoch [536/2000], Avg Train Loss: 3.7848\n",
      "Epoch [536/2000], Avg Val Loss: 2.2787\n",
      "Validation loss improved from 2.2791 to 2.2787. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8100\n",
      "Epoch [537/2000], Avg Train Loss: 3.8100\n",
      "Epoch [537/2000], Avg Val Loss: 2.2784\n",
      "Validation loss improved from 2.2787 to 2.2784. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8104\n",
      "Epoch [538/2000], Avg Train Loss: 3.8104\n",
      "Epoch [538/2000], Avg Val Loss: 2.2780\n",
      "Validation loss improved from 2.2784 to 2.2780. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7657\n",
      "Epoch [539/2000], Avg Train Loss: 3.7657\n",
      "Epoch [539/2000], Avg Val Loss: 2.2776\n",
      "Validation loss improved from 2.2780 to 2.2776. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7779\n",
      "Epoch [540/2000], Avg Train Loss: 3.7779\n",
      "Epoch [540/2000], Avg Val Loss: 2.2772\n",
      "Validation loss improved from 2.2776 to 2.2772. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7770\n",
      "Epoch [541/2000], Avg Train Loss: 3.7770\n",
      "Epoch [541/2000], Avg Val Loss: 2.2768\n",
      "Validation loss improved from 2.2772 to 2.2768. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7576\n",
      "Epoch [542/2000], Avg Train Loss: 3.7576\n",
      "Epoch [542/2000], Avg Val Loss: 2.2764\n",
      "Validation loss improved from 2.2768 to 2.2764. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7807\n",
      "Epoch [543/2000], Avg Train Loss: 3.7807\n",
      "Epoch [543/2000], Avg Val Loss: 2.2760\n",
      "Validation loss improved from 2.2764 to 2.2760. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7759\n",
      "Epoch [544/2000], Avg Train Loss: 3.7759\n",
      "Epoch [544/2000], Avg Val Loss: 2.2756\n",
      "Validation loss improved from 2.2760 to 2.2756. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7955\n",
      "Epoch [545/2000], Avg Train Loss: 3.7955\n",
      "Epoch [545/2000], Avg Val Loss: 2.2751\n",
      "Validation loss improved from 2.2756 to 2.2751. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7740\n",
      "Epoch [546/2000], Avg Train Loss: 3.7740\n",
      "Epoch [546/2000], Avg Val Loss: 2.2747\n",
      "Validation loss improved from 2.2751 to 2.2747. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7904\n",
      "Epoch [547/2000], Avg Train Loss: 3.7904\n",
      "Epoch [547/2000], Avg Val Loss: 2.2742\n",
      "Validation loss improved from 2.2747 to 2.2742. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7731\n",
      "Epoch [548/2000], Avg Train Loss: 3.7731\n",
      "Epoch [548/2000], Avg Val Loss: 2.2738\n",
      "Validation loss improved from 2.2742 to 2.2738. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7840\n",
      "Epoch [549/2000], Avg Train Loss: 3.7840\n",
      "Epoch [549/2000], Avg Val Loss: 2.2734\n",
      "Validation loss improved from 2.2738 to 2.2734. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7788\n",
      "Epoch [550/2000], Avg Train Loss: 3.7788\n",
      "Epoch [550/2000], Avg Val Loss: 2.2730\n",
      "Validation loss improved from 2.2734 to 2.2730. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8217\n",
      "Epoch [551/2000], Avg Train Loss: 3.8217\n",
      "Epoch [551/2000], Avg Val Loss: 2.2726\n",
      "Validation loss improved from 2.2730 to 2.2726. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7583\n",
      "Epoch [552/2000], Avg Train Loss: 3.7583\n",
      "Epoch [552/2000], Avg Val Loss: 2.2722\n",
      "Validation loss improved from 2.2726 to 2.2722. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7620\n",
      "Epoch [553/2000], Avg Train Loss: 3.7620\n",
      "Epoch [553/2000], Avg Val Loss: 2.2718\n",
      "Validation loss improved from 2.2722 to 2.2718. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7716\n",
      "Epoch [554/2000], Avg Train Loss: 3.7716\n",
      "Epoch [554/2000], Avg Val Loss: 2.2714\n",
      "Validation loss improved from 2.2718 to 2.2714. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7716\n",
      "Epoch [555/2000], Avg Train Loss: 3.7716\n",
      "Epoch [555/2000], Avg Val Loss: 2.2710\n",
      "Validation loss improved from 2.2714 to 2.2710. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7733\n",
      "Epoch [556/2000], Avg Train Loss: 3.7733\n",
      "Epoch [556/2000], Avg Val Loss: 2.2706\n",
      "Validation loss improved from 2.2710 to 2.2706. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7503\n",
      "Epoch [557/2000], Avg Train Loss: 3.7503\n",
      "Epoch [557/2000], Avg Val Loss: 2.2702\n",
      "Validation loss improved from 2.2706 to 2.2702. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7615\n",
      "Epoch [558/2000], Avg Train Loss: 3.7615\n",
      "Epoch [558/2000], Avg Val Loss: 2.2698\n",
      "Validation loss improved from 2.2702 to 2.2698. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7921\n",
      "Epoch [559/2000], Avg Train Loss: 3.7921\n",
      "Epoch [559/2000], Avg Val Loss: 2.2693\n",
      "Validation loss improved from 2.2698 to 2.2693. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7724\n",
      "Epoch [560/2000], Avg Train Loss: 3.7724\n",
      "Epoch [560/2000], Avg Val Loss: 2.2689\n",
      "Validation loss improved from 2.2693 to 2.2689. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7587\n",
      "Epoch [561/2000], Avg Train Loss: 3.7587\n",
      "Epoch [561/2000], Avg Val Loss: 2.2685\n",
      "Validation loss improved from 2.2689 to 2.2685. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7696\n",
      "Epoch [562/2000], Avg Train Loss: 3.7696\n",
      "Epoch [562/2000], Avg Val Loss: 2.2681\n",
      "Validation loss improved from 2.2685 to 2.2681. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7886\n",
      "Epoch [563/2000], Avg Train Loss: 3.7886\n",
      "Epoch [563/2000], Avg Val Loss: 2.2677\n",
      "Validation loss improved from 2.2681 to 2.2677. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7703\n",
      "Epoch [564/2000], Avg Train Loss: 3.7703\n",
      "Epoch [564/2000], Avg Val Loss: 2.2673\n",
      "Validation loss improved from 2.2677 to 2.2673. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7684\n",
      "Epoch [565/2000], Avg Train Loss: 3.7684\n",
      "Epoch [565/2000], Avg Val Loss: 2.2669\n",
      "Validation loss improved from 2.2673 to 2.2669. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7325\n",
      "Epoch [566/2000], Avg Train Loss: 3.7325\n",
      "Epoch [566/2000], Avg Val Loss: 2.2664\n",
      "Validation loss improved from 2.2669 to 2.2664. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7677\n",
      "Epoch [567/2000], Avg Train Loss: 3.7677\n",
      "Epoch [567/2000], Avg Val Loss: 2.2660\n",
      "Validation loss improved from 2.2664 to 2.2660. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7706\n",
      "Epoch [568/2000], Avg Train Loss: 3.7706\n",
      "Epoch [568/2000], Avg Val Loss: 2.2656\n",
      "Validation loss improved from 2.2660 to 2.2656. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7663\n",
      "Epoch [569/2000], Avg Train Loss: 3.7663\n",
      "Epoch [569/2000], Avg Val Loss: 2.2652\n",
      "Validation loss improved from 2.2656 to 2.2652. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7422\n",
      "Epoch [570/2000], Avg Train Loss: 3.7422\n",
      "Epoch [570/2000], Avg Val Loss: 2.2647\n",
      "Validation loss improved from 2.2652 to 2.2647. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7446\n",
      "Epoch [571/2000], Avg Train Loss: 3.7446\n",
      "Epoch [571/2000], Avg Val Loss: 2.2643\n",
      "Validation loss improved from 2.2647 to 2.2643. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7680\n",
      "Epoch [572/2000], Avg Train Loss: 3.7680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [572/2000], Avg Val Loss: 2.2639\n",
      "Validation loss improved from 2.2643 to 2.2639. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8001\n",
      "Epoch [573/2000], Avg Train Loss: 3.8001\n",
      "Epoch [573/2000], Avg Val Loss: 2.2635\n",
      "Validation loss improved from 2.2639 to 2.2635. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7658\n",
      "Epoch [574/2000], Avg Train Loss: 3.7658\n",
      "Epoch [574/2000], Avg Val Loss: 2.2630\n",
      "Validation loss improved from 2.2635 to 2.2630. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7559\n",
      "Epoch [575/2000], Avg Train Loss: 3.7559\n",
      "Epoch [575/2000], Avg Val Loss: 2.2626\n",
      "Validation loss improved from 2.2630 to 2.2626. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7390\n",
      "Epoch [576/2000], Avg Train Loss: 3.7390\n",
      "Epoch [576/2000], Avg Val Loss: 2.2621\n",
      "Validation loss improved from 2.2626 to 2.2621. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7443\n",
      "Epoch [577/2000], Avg Train Loss: 3.7443\n",
      "Epoch [577/2000], Avg Val Loss: 2.2617\n",
      "Validation loss improved from 2.2621 to 2.2617. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7276\n",
      "Epoch [578/2000], Avg Train Loss: 3.7276\n",
      "Epoch [578/2000], Avg Val Loss: 2.2613\n",
      "Validation loss improved from 2.2617 to 2.2613. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7573\n",
      "Epoch [579/2000], Avg Train Loss: 3.7573\n",
      "Epoch [579/2000], Avg Val Loss: 2.2609\n",
      "Validation loss improved from 2.2613 to 2.2609. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7897\n",
      "Epoch [580/2000], Avg Train Loss: 3.7897\n",
      "Epoch [580/2000], Avg Val Loss: 2.2604\n",
      "Validation loss improved from 2.2609 to 2.2604. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7775\n",
      "Epoch [581/2000], Avg Train Loss: 3.7775\n",
      "Epoch [581/2000], Avg Val Loss: 2.2600\n",
      "Validation loss improved from 2.2604 to 2.2600. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7911\n",
      "Epoch [582/2000], Avg Train Loss: 3.7911\n",
      "Epoch [582/2000], Avg Val Loss: 2.2595\n",
      "Validation loss improved from 2.2600 to 2.2595. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7375\n",
      "Epoch [583/2000], Avg Train Loss: 3.7375\n",
      "Epoch [583/2000], Avg Val Loss: 2.2590\n",
      "Validation loss improved from 2.2595 to 2.2590. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7558\n",
      "Epoch [584/2000], Avg Train Loss: 3.7558\n",
      "Epoch [584/2000], Avg Val Loss: 2.2586\n",
      "Validation loss improved from 2.2590 to 2.2586. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7824\n",
      "Epoch [585/2000], Avg Train Loss: 3.7824\n",
      "Epoch [585/2000], Avg Val Loss: 2.2581\n",
      "Validation loss improved from 2.2586 to 2.2581. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7404\n",
      "Epoch [586/2000], Avg Train Loss: 3.7404\n",
      "Epoch [586/2000], Avg Val Loss: 2.2577\n",
      "Validation loss improved from 2.2581 to 2.2577. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7322\n",
      "Epoch [587/2000], Avg Train Loss: 3.7322\n",
      "Epoch [587/2000], Avg Val Loss: 2.2572\n",
      "Validation loss improved from 2.2577 to 2.2572. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7136\n",
      "Epoch [588/2000], Avg Train Loss: 3.7136\n",
      "Epoch [588/2000], Avg Val Loss: 2.2568\n",
      "Validation loss improved from 2.2572 to 2.2568. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7778\n",
      "Epoch [589/2000], Avg Train Loss: 3.7778\n",
      "Epoch [589/2000], Avg Val Loss: 2.2563\n",
      "Validation loss improved from 2.2568 to 2.2563. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7230\n",
      "Epoch [590/2000], Avg Train Loss: 3.7230\n",
      "Epoch [590/2000], Avg Val Loss: 2.2559\n",
      "Validation loss improved from 2.2563 to 2.2559. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7416\n",
      "Epoch [591/2000], Avg Train Loss: 3.7416\n",
      "Epoch [591/2000], Avg Val Loss: 2.2554\n",
      "Validation loss improved from 2.2559 to 2.2554. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7105\n",
      "Epoch [592/2000], Avg Train Loss: 3.7105\n",
      "Epoch [592/2000], Avg Val Loss: 2.2549\n",
      "Validation loss improved from 2.2554 to 2.2549. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7309\n",
      "Epoch [593/2000], Avg Train Loss: 3.7309\n",
      "Epoch [593/2000], Avg Val Loss: 2.2544\n",
      "Validation loss improved from 2.2549 to 2.2544. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7299\n",
      "Epoch [594/2000], Avg Train Loss: 3.7299\n",
      "Epoch [594/2000], Avg Val Loss: 2.2539\n",
      "Validation loss improved from 2.2544 to 2.2539. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7499\n",
      "Epoch [595/2000], Avg Train Loss: 3.7499\n",
      "Epoch [595/2000], Avg Val Loss: 2.2534\n",
      "Validation loss improved from 2.2539 to 2.2534. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7427\n",
      "Epoch [596/2000], Avg Train Loss: 3.7427\n",
      "Epoch [596/2000], Avg Val Loss: 2.2529\n",
      "Validation loss improved from 2.2534 to 2.2529. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7636\n",
      "Epoch [597/2000], Avg Train Loss: 3.7636\n",
      "Epoch [597/2000], Avg Val Loss: 2.2524\n",
      "Validation loss improved from 2.2529 to 2.2524. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7502\n",
      "Epoch [598/2000], Avg Train Loss: 3.7502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [598/2000], Avg Val Loss: 2.2518\n",
      "Validation loss improved from 2.2524 to 2.2518. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7301\n",
      "Epoch [599/2000], Avg Train Loss: 3.7301\n",
      "Epoch [599/2000], Avg Val Loss: 2.2513\n",
      "Validation loss improved from 2.2518 to 2.2513. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7381\n",
      "Epoch [600/2000], Avg Train Loss: 3.7381\n",
      "Epoch [600/2000], Avg Val Loss: 2.2509\n",
      "Validation loss improved from 2.2513 to 2.2509. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7563\n",
      "Epoch [601/2000], Avg Train Loss: 3.7563\n",
      "Epoch [601/2000], Avg Val Loss: 2.2504\n",
      "Validation loss improved from 2.2509 to 2.2504. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7470\n",
      "Epoch [602/2000], Avg Train Loss: 3.7470\n",
      "Epoch [602/2000], Avg Val Loss: 2.2500\n",
      "Validation loss improved from 2.2504 to 2.2500. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7207\n",
      "Epoch [603/2000], Avg Train Loss: 3.7207\n",
      "Epoch [603/2000], Avg Val Loss: 2.2496\n",
      "Validation loss improved from 2.2500 to 2.2496. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7546\n",
      "Epoch [604/2000], Avg Train Loss: 3.7546\n",
      "Epoch [604/2000], Avg Val Loss: 2.2492\n",
      "Validation loss improved from 2.2496 to 2.2492. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7450\n",
      "Epoch [605/2000], Avg Train Loss: 3.7450\n",
      "Epoch [605/2000], Avg Val Loss: 2.2488\n",
      "Validation loss improved from 2.2492 to 2.2488. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7401\n",
      "Epoch [606/2000], Avg Train Loss: 3.7401\n",
      "Epoch [606/2000], Avg Val Loss: 2.2484\n",
      "Validation loss improved from 2.2488 to 2.2484. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7171\n",
      "Epoch [607/2000], Avg Train Loss: 3.7171\n",
      "Epoch [607/2000], Avg Val Loss: 2.2480\n",
      "Validation loss improved from 2.2484 to 2.2480. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7340\n",
      "Epoch [608/2000], Avg Train Loss: 3.7340\n",
      "Epoch [608/2000], Avg Val Loss: 2.2476\n",
      "Validation loss improved from 2.2480 to 2.2476. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7243\n",
      "Epoch [609/2000], Avg Train Loss: 3.7243\n",
      "Epoch [609/2000], Avg Val Loss: 2.2472\n",
      "Validation loss improved from 2.2476 to 2.2472. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7348\n",
      "Epoch [610/2000], Avg Train Loss: 3.7348\n",
      "Epoch [610/2000], Avg Val Loss: 2.2468\n",
      "Validation loss improved from 2.2472 to 2.2468. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7325\n",
      "Epoch [611/2000], Avg Train Loss: 3.7325\n",
      "Epoch [611/2000], Avg Val Loss: 2.2464\n",
      "Validation loss improved from 2.2468 to 2.2464. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7081\n",
      "Epoch [612/2000], Avg Train Loss: 3.7081\n",
      "Epoch [612/2000], Avg Val Loss: 2.2460\n",
      "Validation loss improved from 2.2464 to 2.2460. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7336\n",
      "Epoch [613/2000], Avg Train Loss: 3.7336\n",
      "Epoch [613/2000], Avg Val Loss: 2.2457\n",
      "Validation loss improved from 2.2460 to 2.2457. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7168\n",
      "Epoch [614/2000], Avg Train Loss: 3.7168\n",
      "Epoch [614/2000], Avg Val Loss: 2.2453\n",
      "Validation loss improved from 2.2457 to 2.2453. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7204\n",
      "Epoch [615/2000], Avg Train Loss: 3.7204\n",
      "Epoch [615/2000], Avg Val Loss: 2.2449\n",
      "Validation loss improved from 2.2453 to 2.2449. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7392\n",
      "Epoch [616/2000], Avg Train Loss: 3.7392\n",
      "Epoch [616/2000], Avg Val Loss: 2.2445\n",
      "Validation loss improved from 2.2449 to 2.2445. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7109\n",
      "Epoch [617/2000], Avg Train Loss: 3.7109\n",
      "Epoch [617/2000], Avg Val Loss: 2.2440\n",
      "Validation loss improved from 2.2445 to 2.2440. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7007\n",
      "Epoch [618/2000], Avg Train Loss: 3.7007\n",
      "Epoch [618/2000], Avg Val Loss: 2.2436\n",
      "Validation loss improved from 2.2440 to 2.2436. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7558\n",
      "Epoch [619/2000], Avg Train Loss: 3.7558\n",
      "Epoch [619/2000], Avg Val Loss: 2.2432\n",
      "Validation loss improved from 2.2436 to 2.2432. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6902\n",
      "Epoch [620/2000], Avg Train Loss: 3.6902\n",
      "Epoch [620/2000], Avg Val Loss: 2.2428\n",
      "Validation loss improved from 2.2432 to 2.2428. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6995\n",
      "Epoch [621/2000], Avg Train Loss: 3.6995\n",
      "Epoch [621/2000], Avg Val Loss: 2.2424\n",
      "Validation loss improved from 2.2428 to 2.2424. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7329\n",
      "Epoch [622/2000], Avg Train Loss: 3.7329\n",
      "Epoch [622/2000], Avg Val Loss: 2.2420\n",
      "Validation loss improved from 2.2424 to 2.2420. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7127\n",
      "Epoch [623/2000], Avg Train Loss: 3.7127\n",
      "Epoch [623/2000], Avg Val Loss: 2.2417\n",
      "Validation loss improved from 2.2420 to 2.2417. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7354\n",
      "Epoch [624/2000], Avg Train Loss: 3.7354\n",
      "Epoch [624/2000], Avg Val Loss: 2.2413\n",
      "Validation loss improved from 2.2417 to 2.2413. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7187\n",
      "Epoch [625/2000], Avg Train Loss: 3.7187\n",
      "Epoch [625/2000], Avg Val Loss: 2.2410\n",
      "Validation loss improved from 2.2413 to 2.2410. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7498\n",
      "Epoch [626/2000], Avg Train Loss: 3.7498\n",
      "Epoch [626/2000], Avg Val Loss: 2.2406\n",
      "Validation loss improved from 2.2410 to 2.2406. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7164\n",
      "Epoch [627/2000], Avg Train Loss: 3.7164\n",
      "Epoch [627/2000], Avg Val Loss: 2.2402\n",
      "Validation loss improved from 2.2406 to 2.2402. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6910\n",
      "Epoch [628/2000], Avg Train Loss: 3.6910\n",
      "Epoch [628/2000], Avg Val Loss: 2.2399\n",
      "Validation loss improved from 2.2402 to 2.2399. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7486\n",
      "Epoch [629/2000], Avg Train Loss: 3.7486\n",
      "Epoch [629/2000], Avg Val Loss: 2.2395\n",
      "Validation loss improved from 2.2399 to 2.2395. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6995\n",
      "Epoch [630/2000], Avg Train Loss: 3.6995\n",
      "Epoch [630/2000], Avg Val Loss: 2.2391\n",
      "Validation loss improved from 2.2395 to 2.2391. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7158\n",
      "Epoch [631/2000], Avg Train Loss: 3.7158\n",
      "Epoch [631/2000], Avg Val Loss: 2.2387\n",
      "Validation loss improved from 2.2391 to 2.2387. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6886\n",
      "Epoch [632/2000], Avg Train Loss: 3.6886\n",
      "Epoch [632/2000], Avg Val Loss: 2.2383\n",
      "Validation loss improved from 2.2387 to 2.2383. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6997\n",
      "Epoch [633/2000], Avg Train Loss: 3.6997\n",
      "Epoch [633/2000], Avg Val Loss: 2.2379\n",
      "Validation loss improved from 2.2383 to 2.2379. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7590\n",
      "Epoch [634/2000], Avg Train Loss: 3.7590\n",
      "Epoch [634/2000], Avg Val Loss: 2.2375\n",
      "Validation loss improved from 2.2379 to 2.2375. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7317\n",
      "Epoch [635/2000], Avg Train Loss: 3.7317\n",
      "Epoch [635/2000], Avg Val Loss: 2.2371\n",
      "Validation loss improved from 2.2375 to 2.2371. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7072\n",
      "Epoch [636/2000], Avg Train Loss: 3.7072\n",
      "Epoch [636/2000], Avg Val Loss: 2.2368\n",
      "Validation loss improved from 2.2371 to 2.2368. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7033\n",
      "Epoch [637/2000], Avg Train Loss: 3.7033\n",
      "Epoch [637/2000], Avg Val Loss: 2.2364\n",
      "Validation loss improved from 2.2368 to 2.2364. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7213\n",
      "Epoch [638/2000], Avg Train Loss: 3.7213\n",
      "Epoch [638/2000], Avg Val Loss: 2.2360\n",
      "Validation loss improved from 2.2364 to 2.2360. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6902\n",
      "Epoch [639/2000], Avg Train Loss: 3.6902\n",
      "Epoch [639/2000], Avg Val Loss: 2.2356\n",
      "Validation loss improved from 2.2360 to 2.2356. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7172\n",
      "Epoch [640/2000], Avg Train Loss: 3.7172\n",
      "Epoch [640/2000], Avg Val Loss: 2.2353\n",
      "Validation loss improved from 2.2356 to 2.2353. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7181\n",
      "Epoch [641/2000], Avg Train Loss: 3.7181\n",
      "Epoch [641/2000], Avg Val Loss: 2.2349\n",
      "Validation loss improved from 2.2353 to 2.2349. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7133\n",
      "Epoch [642/2000], Avg Train Loss: 3.7133\n",
      "Epoch [642/2000], Avg Val Loss: 2.2346\n",
      "Validation loss improved from 2.2349 to 2.2346. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7106\n",
      "Epoch [643/2000], Avg Train Loss: 3.7106\n",
      "Epoch [643/2000], Avg Val Loss: 2.2344\n",
      "Validation loss improved from 2.2346 to 2.2344. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7124\n",
      "Epoch [644/2000], Avg Train Loss: 3.7124\n",
      "Epoch [644/2000], Avg Val Loss: 2.2340\n",
      "Validation loss improved from 2.2344 to 2.2340. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7192\n",
      "Epoch [645/2000], Avg Train Loss: 3.7192\n",
      "Epoch [645/2000], Avg Val Loss: 2.2337\n",
      "Validation loss improved from 2.2340 to 2.2337. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7055\n",
      "Epoch [646/2000], Avg Train Loss: 3.7055\n",
      "Epoch [646/2000], Avg Val Loss: 2.2333\n",
      "Validation loss improved from 2.2337 to 2.2333. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7251\n",
      "Epoch [647/2000], Avg Train Loss: 3.7251\n",
      "Epoch [647/2000], Avg Val Loss: 2.2330\n",
      "Validation loss improved from 2.2333 to 2.2330. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7113\n",
      "Epoch [648/2000], Avg Train Loss: 3.7113\n",
      "Epoch [648/2000], Avg Val Loss: 2.2326\n",
      "Validation loss improved from 2.2330 to 2.2326. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6940\n",
      "Epoch [649/2000], Avg Train Loss: 3.6940\n",
      "Epoch [649/2000], Avg Val Loss: 2.2322\n",
      "Validation loss improved from 2.2326 to 2.2322. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7016\n",
      "Epoch [650/2000], Avg Train Loss: 3.7016\n",
      "Epoch [650/2000], Avg Val Loss: 2.2319\n",
      "Validation loss improved from 2.2322 to 2.2319. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7265\n",
      "Epoch [651/2000], Avg Train Loss: 3.7265\n",
      "Epoch [651/2000], Avg Val Loss: 2.2315\n",
      "Validation loss improved from 2.2319 to 2.2315. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7131\n",
      "Epoch [652/2000], Avg Train Loss: 3.7131\n",
      "Epoch [652/2000], Avg Val Loss: 2.2312\n",
      "Validation loss improved from 2.2315 to 2.2312. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7085\n",
      "Epoch [653/2000], Avg Train Loss: 3.7085\n",
      "Epoch [653/2000], Avg Val Loss: 2.2308\n",
      "Validation loss improved from 2.2312 to 2.2308. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6906\n",
      "Epoch [654/2000], Avg Train Loss: 3.6906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [654/2000], Avg Val Loss: 2.2304\n",
      "Validation loss improved from 2.2308 to 2.2304. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6915\n",
      "Epoch [655/2000], Avg Train Loss: 3.6915\n",
      "Epoch [655/2000], Avg Val Loss: 2.2300\n",
      "Validation loss improved from 2.2304 to 2.2300. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6799\n",
      "Epoch [656/2000], Avg Train Loss: 3.6799\n",
      "Epoch [656/2000], Avg Val Loss: 2.2297\n",
      "Validation loss improved from 2.2300 to 2.2297. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7169\n",
      "Epoch [657/2000], Avg Train Loss: 3.7169\n",
      "Epoch [657/2000], Avg Val Loss: 2.2293\n",
      "Validation loss improved from 2.2297 to 2.2293. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6924\n",
      "Epoch [658/2000], Avg Train Loss: 3.6924\n",
      "Epoch [658/2000], Avg Val Loss: 2.2289\n",
      "Validation loss improved from 2.2293 to 2.2289. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7725\n",
      "Epoch [659/2000], Avg Train Loss: 3.7725\n",
      "Epoch [659/2000], Avg Val Loss: 2.2286\n",
      "Validation loss improved from 2.2289 to 2.2286. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6810\n",
      "Epoch [660/2000], Avg Train Loss: 3.6810\n",
      "Epoch [660/2000], Avg Val Loss: 2.2282\n",
      "Validation loss improved from 2.2286 to 2.2282. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7162\n",
      "Epoch [661/2000], Avg Train Loss: 3.7162\n",
      "Epoch [661/2000], Avg Val Loss: 2.2279\n",
      "Validation loss improved from 2.2282 to 2.2279. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7418\n",
      "Epoch [662/2000], Avg Train Loss: 3.7418\n",
      "Epoch [662/2000], Avg Val Loss: 2.2276\n",
      "Validation loss improved from 2.2279 to 2.2276. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6905\n",
      "Epoch [663/2000], Avg Train Loss: 3.6905\n",
      "Epoch [663/2000], Avg Val Loss: 2.2273\n",
      "Validation loss improved from 2.2276 to 2.2273. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6953\n",
      "Epoch [664/2000], Avg Train Loss: 3.6953\n",
      "Epoch [664/2000], Avg Val Loss: 2.2270\n",
      "Validation loss improved from 2.2273 to 2.2270. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6856\n",
      "Epoch [665/2000], Avg Train Loss: 3.6856\n",
      "Epoch [665/2000], Avg Val Loss: 2.2267\n",
      "Validation loss improved from 2.2270 to 2.2267. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6754\n",
      "Epoch [666/2000], Avg Train Loss: 3.6754\n",
      "Epoch [666/2000], Avg Val Loss: 2.2264\n",
      "Validation loss improved from 2.2267 to 2.2264. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6911\n",
      "Epoch [667/2000], Avg Train Loss: 3.6911\n",
      "Epoch [667/2000], Avg Val Loss: 2.2260\n",
      "Validation loss improved from 2.2264 to 2.2260. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7228\n",
      "Epoch [668/2000], Avg Train Loss: 3.7228\n",
      "Epoch [668/2000], Avg Val Loss: 2.2257\n",
      "Validation loss improved from 2.2260 to 2.2257. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7345\n",
      "Epoch [669/2000], Avg Train Loss: 3.7345\n",
      "Epoch [669/2000], Avg Val Loss: 2.2254\n",
      "Validation loss improved from 2.2257 to 2.2254. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6638\n",
      "Epoch [670/2000], Avg Train Loss: 3.6638\n",
      "Epoch [670/2000], Avg Val Loss: 2.2250\n",
      "Validation loss improved from 2.2254 to 2.2250. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6922\n",
      "Epoch [671/2000], Avg Train Loss: 3.6922\n",
      "Epoch [671/2000], Avg Val Loss: 2.2247\n",
      "Validation loss improved from 2.2250 to 2.2247. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6905\n",
      "Epoch [672/2000], Avg Train Loss: 3.6905\n",
      "Epoch [672/2000], Avg Val Loss: 2.2244\n",
      "Validation loss improved from 2.2247 to 2.2244. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6712\n",
      "Epoch [673/2000], Avg Train Loss: 3.6712\n",
      "Epoch [673/2000], Avg Val Loss: 2.2241\n",
      "Validation loss improved from 2.2244 to 2.2241. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6684\n",
      "Epoch [674/2000], Avg Train Loss: 3.6684\n",
      "Epoch [674/2000], Avg Val Loss: 2.2238\n",
      "Validation loss improved from 2.2241 to 2.2238. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6540\n",
      "Epoch [675/2000], Avg Train Loss: 3.6540\n",
      "Epoch [675/2000], Avg Val Loss: 2.2234\n",
      "Validation loss improved from 2.2238 to 2.2234. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6809\n",
      "Epoch [676/2000], Avg Train Loss: 3.6809\n",
      "Epoch [676/2000], Avg Val Loss: 2.2231\n",
      "Validation loss improved from 2.2234 to 2.2231. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6840\n",
      "Epoch [677/2000], Avg Train Loss: 3.6840\n",
      "Epoch [677/2000], Avg Val Loss: 2.2227\n",
      "Validation loss improved from 2.2231 to 2.2227. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6801\n",
      "Epoch [678/2000], Avg Train Loss: 3.6801\n",
      "Epoch [678/2000], Avg Val Loss: 2.2224\n",
      "Validation loss improved from 2.2227 to 2.2224. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6782\n",
      "Epoch [679/2000], Avg Train Loss: 3.6782\n",
      "Epoch [679/2000], Avg Val Loss: 2.2221\n",
      "Validation loss improved from 2.2224 to 2.2221. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7417\n",
      "Epoch [680/2000], Avg Train Loss: 3.7417\n",
      "Epoch [680/2000], Avg Val Loss: 2.2219\n",
      "Validation loss improved from 2.2221 to 2.2219. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6681\n",
      "Epoch [681/2000], Avg Train Loss: 3.6681\n",
      "Epoch [681/2000], Avg Val Loss: 2.2216\n",
      "Validation loss improved from 2.2219 to 2.2216. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6440\n",
      "Epoch [682/2000], Avg Train Loss: 3.6440\n",
      "Epoch [682/2000], Avg Val Loss: 2.2213\n",
      "Validation loss improved from 2.2216 to 2.2213. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7188\n",
      "Epoch [683/2000], Avg Train Loss: 3.7188\n",
      "Epoch [683/2000], Avg Val Loss: 2.2210\n",
      "Validation loss improved from 2.2213 to 2.2210. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6572\n",
      "Epoch [684/2000], Avg Train Loss: 3.6572\n",
      "Epoch [684/2000], Avg Val Loss: 2.2207\n",
      "Validation loss improved from 2.2210 to 2.2207. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6553\n",
      "Epoch [685/2000], Avg Train Loss: 3.6553\n",
      "Epoch [685/2000], Avg Val Loss: 2.2205\n",
      "Validation loss improved from 2.2207 to 2.2205. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6978\n",
      "Epoch [686/2000], Avg Train Loss: 3.6978\n",
      "Epoch [686/2000], Avg Val Loss: 2.2202\n",
      "Validation loss improved from 2.2205 to 2.2202. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6889\n",
      "Epoch [687/2000], Avg Train Loss: 3.6889\n",
      "Epoch [687/2000], Avg Val Loss: 2.2199\n",
      "Validation loss improved from 2.2202 to 2.2199. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7029\n",
      "Epoch [688/2000], Avg Train Loss: 3.7029\n",
      "Epoch [688/2000], Avg Val Loss: 2.2196\n",
      "Validation loss improved from 2.2199 to 2.2196. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6802\n",
      "Epoch [689/2000], Avg Train Loss: 3.6802\n",
      "Epoch [689/2000], Avg Val Loss: 2.2193\n",
      "Validation loss improved from 2.2196 to 2.2193. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6753\n",
      "Epoch [690/2000], Avg Train Loss: 3.6753\n",
      "Epoch [690/2000], Avg Val Loss: 2.2191\n",
      "Validation loss improved from 2.2193 to 2.2191. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6851\n",
      "Epoch [691/2000], Avg Train Loss: 3.6851\n",
      "Epoch [691/2000], Avg Val Loss: 2.2189\n",
      "Validation loss improved from 2.2191 to 2.2189. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6686\n",
      "Epoch [692/2000], Avg Train Loss: 3.6686\n",
      "Epoch [692/2000], Avg Val Loss: 2.2187\n",
      "Validation loss improved from 2.2189 to 2.2187. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6985\n",
      "Epoch [693/2000], Avg Train Loss: 3.6985\n",
      "Epoch [693/2000], Avg Val Loss: 2.2184\n",
      "Validation loss improved from 2.2187 to 2.2184. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6693\n",
      "Epoch [694/2000], Avg Train Loss: 3.6693\n",
      "Epoch [694/2000], Avg Val Loss: 2.2182\n",
      "Validation loss improved from 2.2184 to 2.2182. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6938\n",
      "Epoch [695/2000], Avg Train Loss: 3.6938\n",
      "Epoch [695/2000], Avg Val Loss: 2.2179\n",
      "Validation loss improved from 2.2182 to 2.2179. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6883\n",
      "Epoch [696/2000], Avg Train Loss: 3.6883\n",
      "Epoch [696/2000], Avg Val Loss: 2.2176\n",
      "Validation loss improved from 2.2179 to 2.2176. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6665\n",
      "Epoch [697/2000], Avg Train Loss: 3.6665\n",
      "Epoch [697/2000], Avg Val Loss: 2.2174\n",
      "Validation loss improved from 2.2176 to 2.2174. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6805\n",
      "Epoch [698/2000], Avg Train Loss: 3.6805\n",
      "Epoch [698/2000], Avg Val Loss: 2.2171\n",
      "Validation loss improved from 2.2174 to 2.2171. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7045\n",
      "Epoch [699/2000], Avg Train Loss: 3.7045\n",
      "Epoch [699/2000], Avg Val Loss: 2.2168\n",
      "Validation loss improved from 2.2171 to 2.2168. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6533\n",
      "Epoch [700/2000], Avg Train Loss: 3.6533\n",
      "Epoch [700/2000], Avg Val Loss: 2.2165\n",
      "Validation loss improved from 2.2168 to 2.2165. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6549\n",
      "Epoch [701/2000], Avg Train Loss: 3.6549\n",
      "Epoch [701/2000], Avg Val Loss: 2.2163\n",
      "Validation loss improved from 2.2165 to 2.2163. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6530\n",
      "Epoch [702/2000], Avg Train Loss: 3.6530\n",
      "Epoch [702/2000], Avg Val Loss: 2.2160\n",
      "Validation loss improved from 2.2163 to 2.2160. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6947\n",
      "Epoch [703/2000], Avg Train Loss: 3.6947\n",
      "Epoch [703/2000], Avg Val Loss: 2.2157\n",
      "Validation loss improved from 2.2160 to 2.2157. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6383\n",
      "Epoch [704/2000], Avg Train Loss: 3.6383\n",
      "Epoch [704/2000], Avg Val Loss: 2.2154\n",
      "Validation loss improved from 2.2157 to 2.2154. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6979\n",
      "Epoch [705/2000], Avg Train Loss: 3.6979\n",
      "Epoch [705/2000], Avg Val Loss: 2.2151\n",
      "Validation loss improved from 2.2154 to 2.2151. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6496\n",
      "Epoch [706/2000], Avg Train Loss: 3.6496\n",
      "Epoch [706/2000], Avg Val Loss: 2.2148\n",
      "Validation loss improved from 2.2151 to 2.2148. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6913\n",
      "Epoch [707/2000], Avg Train Loss: 3.6913\n",
      "Epoch [707/2000], Avg Val Loss: 2.2146\n",
      "Validation loss improved from 2.2148 to 2.2146. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6383\n",
      "Epoch [708/2000], Avg Train Loss: 3.6383\n",
      "Epoch [708/2000], Avg Val Loss: 2.2143\n",
      "Validation loss improved from 2.2146 to 2.2143. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6450\n",
      "Epoch [709/2000], Avg Train Loss: 3.6450\n",
      "Epoch [709/2000], Avg Val Loss: 2.2140\n",
      "Validation loss improved from 2.2143 to 2.2140. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6642\n",
      "Epoch [710/2000], Avg Train Loss: 3.6642\n",
      "Epoch [710/2000], Avg Val Loss: 2.2137\n",
      "Validation loss improved from 2.2140 to 2.2137. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6688\n",
      "Epoch [711/2000], Avg Train Loss: 3.6688\n",
      "Epoch [711/2000], Avg Val Loss: 2.2134\n",
      "Validation loss improved from 2.2137 to 2.2134. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6954\n",
      "Epoch [712/2000], Avg Train Loss: 3.6954\n",
      "Epoch [712/2000], Avg Val Loss: 2.2131\n",
      "Validation loss improved from 2.2134 to 2.2131. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6926\n",
      "Epoch [713/2000], Avg Train Loss: 3.6926\n",
      "Epoch [713/2000], Avg Val Loss: 2.2127\n",
      "Validation loss improved from 2.2131 to 2.2127. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6347\n",
      "Epoch [714/2000], Avg Train Loss: 3.6347\n",
      "Epoch [714/2000], Avg Val Loss: 2.2123\n",
      "Validation loss improved from 2.2127 to 2.2123. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6478\n",
      "Epoch [715/2000], Avg Train Loss: 3.6478\n",
      "Epoch [715/2000], Avg Val Loss: 2.2119\n",
      "Validation loss improved from 2.2123 to 2.2119. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6514\n",
      "Epoch [716/2000], Avg Train Loss: 3.6514\n",
      "Epoch [716/2000], Avg Val Loss: 2.2116\n",
      "Validation loss improved from 2.2119 to 2.2116. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6681\n",
      "Epoch [717/2000], Avg Train Loss: 3.6681\n",
      "Epoch [717/2000], Avg Val Loss: 2.2112\n",
      "Validation loss improved from 2.2116 to 2.2112. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6481\n",
      "Epoch [718/2000], Avg Train Loss: 3.6481\n",
      "Epoch [718/2000], Avg Val Loss: 2.2109\n",
      "Validation loss improved from 2.2112 to 2.2109. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6418\n",
      "Epoch [719/2000], Avg Train Loss: 3.6418\n",
      "Epoch [719/2000], Avg Val Loss: 2.2105\n",
      "Validation loss improved from 2.2109 to 2.2105. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6689\n",
      "Epoch [720/2000], Avg Train Loss: 3.6689\n",
      "Epoch [720/2000], Avg Val Loss: 2.2101\n",
      "Validation loss improved from 2.2105 to 2.2101. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6634\n",
      "Epoch [721/2000], Avg Train Loss: 3.6634\n",
      "Epoch [721/2000], Avg Val Loss: 2.2097\n",
      "Validation loss improved from 2.2101 to 2.2097. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6558\n",
      "Epoch [722/2000], Avg Train Loss: 3.6558\n",
      "Epoch [722/2000], Avg Val Loss: 2.2093\n",
      "Validation loss improved from 2.2097 to 2.2093. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6924\n",
      "Epoch [723/2000], Avg Train Loss: 3.6924\n",
      "Epoch [723/2000], Avg Val Loss: 2.2088\n",
      "Validation loss improved from 2.2093 to 2.2088. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6407\n",
      "Epoch [724/2000], Avg Train Loss: 3.6407\n",
      "Epoch [724/2000], Avg Val Loss: 2.2084\n",
      "Validation loss improved from 2.2088 to 2.2084. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6877\n",
      "Epoch [725/2000], Avg Train Loss: 3.6877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [725/2000], Avg Val Loss: 2.2079\n",
      "Validation loss improved from 2.2084 to 2.2079. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6640\n",
      "Epoch [726/2000], Avg Train Loss: 3.6640\n",
      "Epoch [726/2000], Avg Val Loss: 2.2075\n",
      "Validation loss improved from 2.2079 to 2.2075. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6457\n",
      "Epoch [727/2000], Avg Train Loss: 3.6457\n",
      "Epoch [727/2000], Avg Val Loss: 2.2070\n",
      "Validation loss improved from 2.2075 to 2.2070. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6419\n",
      "Epoch [728/2000], Avg Train Loss: 3.6419\n",
      "Epoch [728/2000], Avg Val Loss: 2.2066\n",
      "Validation loss improved from 2.2070 to 2.2066. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6706\n",
      "Epoch [729/2000], Avg Train Loss: 3.6706\n",
      "Epoch [729/2000], Avg Val Loss: 2.2062\n",
      "Validation loss improved from 2.2066 to 2.2062. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7162\n",
      "Epoch [730/2000], Avg Train Loss: 3.7162\n",
      "Epoch [730/2000], Avg Val Loss: 2.2059\n",
      "Validation loss improved from 2.2062 to 2.2059. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6648\n",
      "Epoch [731/2000], Avg Train Loss: 3.6648\n",
      "Epoch [731/2000], Avg Val Loss: 2.2055\n",
      "Validation loss improved from 2.2059 to 2.2055. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6642\n",
      "Epoch [732/2000], Avg Train Loss: 3.6642\n",
      "Epoch [732/2000], Avg Val Loss: 2.2051\n",
      "Validation loss improved from 2.2055 to 2.2051. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6798\n",
      "Epoch [733/2000], Avg Train Loss: 3.6798\n",
      "Epoch [733/2000], Avg Val Loss: 2.2048\n",
      "Validation loss improved from 2.2051 to 2.2048. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6497\n",
      "Epoch [734/2000], Avg Train Loss: 3.6497\n",
      "Epoch [734/2000], Avg Val Loss: 2.2045\n",
      "Validation loss improved from 2.2048 to 2.2045. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6444\n",
      "Epoch [735/2000], Avg Train Loss: 3.6444\n",
      "Epoch [735/2000], Avg Val Loss: 2.2041\n",
      "Validation loss improved from 2.2045 to 2.2041. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6534\n",
      "Epoch [736/2000], Avg Train Loss: 3.6534\n",
      "Epoch [736/2000], Avg Val Loss: 2.2038\n",
      "Validation loss improved from 2.2041 to 2.2038. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6520\n",
      "Epoch [737/2000], Avg Train Loss: 3.6520\n",
      "Epoch [737/2000], Avg Val Loss: 2.2034\n",
      "Validation loss improved from 2.2038 to 2.2034. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6815\n",
      "Epoch [738/2000], Avg Train Loss: 3.6815\n",
      "Epoch [738/2000], Avg Val Loss: 2.2031\n",
      "Validation loss improved from 2.2034 to 2.2031. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6662\n",
      "Epoch [739/2000], Avg Train Loss: 3.6662\n",
      "Epoch [739/2000], Avg Val Loss: 2.2027\n",
      "Validation loss improved from 2.2031 to 2.2027. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6554\n",
      "Epoch [740/2000], Avg Train Loss: 3.6554\n",
      "Epoch [740/2000], Avg Val Loss: 2.2024\n",
      "Validation loss improved from 2.2027 to 2.2024. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6507\n",
      "Epoch [741/2000], Avg Train Loss: 3.6507\n",
      "Epoch [741/2000], Avg Val Loss: 2.2020\n",
      "Validation loss improved from 2.2024 to 2.2020. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6648\n",
      "Epoch [742/2000], Avg Train Loss: 3.6648\n",
      "Epoch [742/2000], Avg Val Loss: 2.2017\n",
      "Validation loss improved from 2.2020 to 2.2017. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6313\n",
      "Epoch [743/2000], Avg Train Loss: 3.6313\n",
      "Epoch [743/2000], Avg Val Loss: 2.2015\n",
      "Validation loss improved from 2.2017 to 2.2015. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6558\n",
      "Epoch [744/2000], Avg Train Loss: 3.6558\n",
      "Epoch [744/2000], Avg Val Loss: 2.2012\n",
      "Validation loss improved from 2.2015 to 2.2012. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6546\n",
      "Epoch [745/2000], Avg Train Loss: 3.6546\n",
      "Epoch [745/2000], Avg Val Loss: 2.2009\n",
      "Validation loss improved from 2.2012 to 2.2009. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6788\n",
      "Epoch [746/2000], Avg Train Loss: 3.6788\n",
      "Epoch [746/2000], Avg Val Loss: 2.2006\n",
      "Validation loss improved from 2.2009 to 2.2006. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6317\n",
      "Epoch [747/2000], Avg Train Loss: 3.6317\n",
      "Epoch [747/2000], Avg Val Loss: 2.2003\n",
      "Validation loss improved from 2.2006 to 2.2003. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6545\n",
      "Epoch [748/2000], Avg Train Loss: 3.6545\n",
      "Epoch [748/2000], Avg Val Loss: 2.2000\n",
      "Validation loss improved from 2.2003 to 2.2000. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6909\n",
      "Epoch [749/2000], Avg Train Loss: 3.6909\n",
      "Epoch [749/2000], Avg Val Loss: 2.1997\n",
      "Validation loss improved from 2.2000 to 2.1997. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6694\n",
      "Epoch [750/2000], Avg Train Loss: 3.6694\n",
      "Epoch [750/2000], Avg Val Loss: 2.1994\n",
      "Validation loss improved from 2.1997 to 2.1994. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6649\n",
      "Epoch [751/2000], Avg Train Loss: 3.6649\n",
      "Epoch [751/2000], Avg Val Loss: 2.1991\n",
      "Validation loss improved from 2.1994 to 2.1991. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6819\n",
      "Epoch [752/2000], Avg Train Loss: 3.6819\n",
      "Epoch [752/2000], Avg Val Loss: 2.1989\n",
      "Validation loss improved from 2.1991 to 2.1989. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6604\n",
      "Epoch [753/2000], Avg Train Loss: 3.6604\n",
      "Epoch [753/2000], Avg Val Loss: 2.1987\n",
      "Validation loss improved from 2.1989 to 2.1987. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6483\n",
      "Epoch [754/2000], Avg Train Loss: 3.6483\n",
      "Epoch [754/2000], Avg Val Loss: 2.1985\n",
      "Validation loss improved from 2.1987 to 2.1985. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6586\n",
      "Epoch [755/2000], Avg Train Loss: 3.6586\n",
      "Epoch [755/2000], Avg Val Loss: 2.1982\n",
      "Validation loss improved from 2.1985 to 2.1982. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6315\n",
      "Epoch [756/2000], Avg Train Loss: 3.6315\n",
      "Epoch [756/2000], Avg Val Loss: 2.1980\n",
      "Validation loss improved from 2.1982 to 2.1980. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6331\n",
      "Epoch [757/2000], Avg Train Loss: 3.6331\n",
      "Epoch [757/2000], Avg Val Loss: 2.1978\n",
      "Validation loss improved from 2.1980 to 2.1978. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6368\n",
      "Epoch [758/2000], Avg Train Loss: 3.6368\n",
      "Epoch [758/2000], Avg Val Loss: 2.1976\n",
      "Validation loss improved from 2.1978 to 2.1976. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6394\n",
      "Epoch [759/2000], Avg Train Loss: 3.6394\n",
      "Epoch [759/2000], Avg Val Loss: 2.1973\n",
      "Validation loss improved from 2.1976 to 2.1973. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6631\n",
      "Epoch [760/2000], Avg Train Loss: 3.6631\n",
      "Epoch [760/2000], Avg Val Loss: 2.1971\n",
      "Validation loss improved from 2.1973 to 2.1971. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6040\n",
      "Epoch [761/2000], Avg Train Loss: 3.6040\n",
      "Epoch [761/2000], Avg Val Loss: 2.1968\n",
      "Validation loss improved from 2.1971 to 2.1968. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6499\n",
      "Epoch [762/2000], Avg Train Loss: 3.6499\n",
      "Epoch [762/2000], Avg Val Loss: 2.1966\n",
      "Validation loss improved from 2.1968 to 2.1966. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6663\n",
      "Epoch [763/2000], Avg Train Loss: 3.6663\n",
      "Epoch [763/2000], Avg Val Loss: 2.1963\n",
      "Validation loss improved from 2.1966 to 2.1963. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6427\n",
      "Epoch [764/2000], Avg Train Loss: 3.6427\n",
      "Epoch [764/2000], Avg Val Loss: 2.1960\n",
      "Validation loss improved from 2.1963 to 2.1960. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6390\n",
      "Epoch [765/2000], Avg Train Loss: 3.6390\n",
      "Epoch [765/2000], Avg Val Loss: 2.1957\n",
      "Validation loss improved from 2.1960 to 2.1957. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6122\n",
      "Epoch [766/2000], Avg Train Loss: 3.6122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [766/2000], Avg Val Loss: 2.1954\n",
      "Validation loss improved from 2.1957 to 2.1954. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6658\n",
      "Epoch [767/2000], Avg Train Loss: 3.6658\n",
      "Epoch [767/2000], Avg Val Loss: 2.1951\n",
      "Validation loss improved from 2.1954 to 2.1951. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6443\n",
      "Epoch [768/2000], Avg Train Loss: 3.6443\n",
      "Epoch [768/2000], Avg Val Loss: 2.1949\n",
      "Validation loss improved from 2.1951 to 2.1949. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6424\n",
      "Epoch [769/2000], Avg Train Loss: 3.6424\n",
      "Epoch [769/2000], Avg Val Loss: 2.1947\n",
      "Validation loss improved from 2.1949 to 2.1947. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6510\n",
      "Epoch [770/2000], Avg Train Loss: 3.6510\n",
      "Epoch [770/2000], Avg Val Loss: 2.1944\n",
      "Validation loss improved from 2.1947 to 2.1944. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6726\n",
      "Epoch [771/2000], Avg Train Loss: 3.6726\n",
      "Epoch [771/2000], Avg Val Loss: 2.1942\n",
      "Validation loss improved from 2.1944 to 2.1942. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6356\n",
      "Epoch [772/2000], Avg Train Loss: 3.6356\n",
      "Epoch [772/2000], Avg Val Loss: 2.1939\n",
      "Validation loss improved from 2.1942 to 2.1939. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6667\n",
      "Epoch [773/2000], Avg Train Loss: 3.6667\n",
      "Epoch [773/2000], Avg Val Loss: 2.1937\n",
      "Validation loss improved from 2.1939 to 2.1937. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6865\n",
      "Epoch [774/2000], Avg Train Loss: 3.6865\n",
      "Epoch [774/2000], Avg Val Loss: 2.1934\n",
      "Validation loss improved from 2.1937 to 2.1934. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6374\n",
      "Epoch [775/2000], Avg Train Loss: 3.6374\n",
      "Epoch [775/2000], Avg Val Loss: 2.1932\n",
      "Validation loss improved from 2.1934 to 2.1932. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6374\n",
      "Epoch [776/2000], Avg Train Loss: 3.6374\n",
      "Epoch [776/2000], Avg Val Loss: 2.1929\n",
      "Validation loss improved from 2.1932 to 2.1929. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6427\n",
      "Epoch [777/2000], Avg Train Loss: 3.6427\n",
      "Epoch [777/2000], Avg Val Loss: 2.1927\n",
      "Validation loss improved from 2.1929 to 2.1927. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6331\n",
      "Epoch [778/2000], Avg Train Loss: 3.6331\n",
      "Epoch [778/2000], Avg Val Loss: 2.1925\n",
      "Validation loss improved from 2.1927 to 2.1925. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6267\n",
      "Epoch [779/2000], Avg Train Loss: 3.6267\n",
      "Epoch [779/2000], Avg Val Loss: 2.1922\n",
      "Validation loss improved from 2.1925 to 2.1922. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6369\n",
      "Epoch [780/2000], Avg Train Loss: 3.6369\n",
      "Epoch [780/2000], Avg Val Loss: 2.1919\n",
      "Validation loss improved from 2.1922 to 2.1919. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6226\n",
      "Epoch [781/2000], Avg Train Loss: 3.6226\n",
      "Epoch [781/2000], Avg Val Loss: 2.1916\n",
      "Validation loss improved from 2.1919 to 2.1916. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6227\n",
      "Epoch [782/2000], Avg Train Loss: 3.6227\n",
      "Epoch [782/2000], Avg Val Loss: 2.1912\n",
      "Validation loss improved from 2.1916 to 2.1912. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6077\n",
      "Epoch [783/2000], Avg Train Loss: 3.6077\n",
      "Epoch [783/2000], Avg Val Loss: 2.1909\n",
      "Validation loss improved from 2.1912 to 2.1909. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6241\n",
      "Epoch [784/2000], Avg Train Loss: 3.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [784/2000], Avg Val Loss: 2.1905\n",
      "Validation loss improved from 2.1909 to 2.1905. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6439\n",
      "Epoch [785/2000], Avg Train Loss: 3.6439\n",
      "Epoch [785/2000], Avg Val Loss: 2.1902\n",
      "Validation loss improved from 2.1905 to 2.1902. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6488\n",
      "Epoch [786/2000], Avg Train Loss: 3.6488\n",
      "Epoch [786/2000], Avg Val Loss: 2.1899\n",
      "Validation loss improved from 2.1902 to 2.1899. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5931\n",
      "Epoch [787/2000], Avg Train Loss: 3.5931\n",
      "Epoch [787/2000], Avg Val Loss: 2.1896\n",
      "Validation loss improved from 2.1899 to 2.1896. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6217\n",
      "Epoch [788/2000], Avg Train Loss: 3.6217\n",
      "Epoch [788/2000], Avg Val Loss: 2.1893\n",
      "Validation loss improved from 2.1896 to 2.1893. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6365\n",
      "Epoch [789/2000], Avg Train Loss: 3.6365\n",
      "Epoch [789/2000], Avg Val Loss: 2.1890\n",
      "Validation loss improved from 2.1893 to 2.1890. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6221\n",
      "Epoch [790/2000], Avg Train Loss: 3.6221\n",
      "Epoch [790/2000], Avg Val Loss: 2.1887\n",
      "Validation loss improved from 2.1890 to 2.1887. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6144\n",
      "Epoch [791/2000], Avg Train Loss: 3.6144\n",
      "Epoch [791/2000], Avg Val Loss: 2.1884\n",
      "Validation loss improved from 2.1887 to 2.1884. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6423\n",
      "Epoch [792/2000], Avg Train Loss: 3.6423\n",
      "Epoch [792/2000], Avg Val Loss: 2.1881\n",
      "Validation loss improved from 2.1884 to 2.1881. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6274\n",
      "Epoch [793/2000], Avg Train Loss: 3.6274\n",
      "Epoch [793/2000], Avg Val Loss: 2.1878\n",
      "Validation loss improved from 2.1881 to 2.1878. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6477\n",
      "Epoch [794/2000], Avg Train Loss: 3.6477\n",
      "Epoch [794/2000], Avg Val Loss: 2.1875\n",
      "Validation loss improved from 2.1878 to 2.1875. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6289\n",
      "Epoch [795/2000], Avg Train Loss: 3.6289\n",
      "Epoch [795/2000], Avg Val Loss: 2.1872\n",
      "Validation loss improved from 2.1875 to 2.1872. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6112\n",
      "Epoch [796/2000], Avg Train Loss: 3.6112\n",
      "Epoch [796/2000], Avg Val Loss: 2.1869\n",
      "Validation loss improved from 2.1872 to 2.1869. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6132\n",
      "Epoch [797/2000], Avg Train Loss: 3.6132\n",
      "Epoch [797/2000], Avg Val Loss: 2.1865\n",
      "Validation loss improved from 2.1869 to 2.1865. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6043\n",
      "Epoch [798/2000], Avg Train Loss: 3.6043\n",
      "Epoch [798/2000], Avg Val Loss: 2.1862\n",
      "Validation loss improved from 2.1865 to 2.1862. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6097\n",
      "Epoch [799/2000], Avg Train Loss: 3.6097\n",
      "Epoch [799/2000], Avg Val Loss: 2.1858\n",
      "Validation loss improved from 2.1862 to 2.1858. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6406\n",
      "Epoch [800/2000], Avg Train Loss: 3.6406\n",
      "Epoch [800/2000], Avg Val Loss: 2.1855\n",
      "Validation loss improved from 2.1858 to 2.1855. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5912\n",
      "Epoch [801/2000], Avg Train Loss: 3.5912\n",
      "Epoch [801/2000], Avg Val Loss: 2.1851\n",
      "Validation loss improved from 2.1855 to 2.1851. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6279\n",
      "Epoch [802/2000], Avg Train Loss: 3.6279\n",
      "Epoch [802/2000], Avg Val Loss: 2.1847\n",
      "Validation loss improved from 2.1851 to 2.1847. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6778\n",
      "Epoch [803/2000], Avg Train Loss: 3.6778\n",
      "Epoch [803/2000], Avg Val Loss: 2.1844\n",
      "Validation loss improved from 2.1847 to 2.1844. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6432\n",
      "Epoch [804/2000], Avg Train Loss: 3.6432\n",
      "Epoch [804/2000], Avg Val Loss: 2.1842\n",
      "Validation loss improved from 2.1844 to 2.1842. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6238\n",
      "Epoch [805/2000], Avg Train Loss: 3.6238\n",
      "Epoch [805/2000], Avg Val Loss: 2.1839\n",
      "Validation loss improved from 2.1842 to 2.1839. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6292\n",
      "Epoch [806/2000], Avg Train Loss: 3.6292\n",
      "Epoch [806/2000], Avg Val Loss: 2.1836\n",
      "Validation loss improved from 2.1839 to 2.1836. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5986\n",
      "Epoch [807/2000], Avg Train Loss: 3.5986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [807/2000], Avg Val Loss: 2.1834\n",
      "Validation loss improved from 2.1836 to 2.1834. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6264\n",
      "Epoch [808/2000], Avg Train Loss: 3.6264\n",
      "Epoch [808/2000], Avg Val Loss: 2.1831\n",
      "Validation loss improved from 2.1834 to 2.1831. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6294\n",
      "Epoch [809/2000], Avg Train Loss: 3.6294\n",
      "Epoch [809/2000], Avg Val Loss: 2.1829\n",
      "Validation loss improved from 2.1831 to 2.1829. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6689\n",
      "Epoch [810/2000], Avg Train Loss: 3.6689\n",
      "Epoch [810/2000], Avg Val Loss: 2.1826\n",
      "Validation loss improved from 2.1829 to 2.1826. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5893\n",
      "Epoch [811/2000], Avg Train Loss: 3.5893\n",
      "Epoch [811/2000], Avg Val Loss: 2.1824\n",
      "Validation loss improved from 2.1826 to 2.1824. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6252\n",
      "Epoch [812/2000], Avg Train Loss: 3.6252\n",
      "Epoch [812/2000], Avg Val Loss: 2.1822\n",
      "Validation loss improved from 2.1824 to 2.1822. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6169\n",
      "Epoch [813/2000], Avg Train Loss: 3.6169\n",
      "Epoch [813/2000], Avg Val Loss: 2.1819\n",
      "Validation loss improved from 2.1822 to 2.1819. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6006\n",
      "Epoch [814/2000], Avg Train Loss: 3.6006\n",
      "Epoch [814/2000], Avg Val Loss: 2.1817\n",
      "Validation loss improved from 2.1819 to 2.1817. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6336\n",
      "Epoch [815/2000], Avg Train Loss: 3.6336\n",
      "Epoch [815/2000], Avg Val Loss: 2.1815\n",
      "Validation loss improved from 2.1817 to 2.1815. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6521\n",
      "Epoch [816/2000], Avg Train Loss: 3.6521\n",
      "Epoch [816/2000], Avg Val Loss: 2.1813\n",
      "Validation loss improved from 2.1815 to 2.1813. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6193\n",
      "Epoch [817/2000], Avg Train Loss: 3.6193\n",
      "Epoch [817/2000], Avg Val Loss: 2.1811\n",
      "Validation loss improved from 2.1813 to 2.1811. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6069\n",
      "Epoch [818/2000], Avg Train Loss: 3.6069\n",
      "Epoch [818/2000], Avg Val Loss: 2.1809\n",
      "Validation loss improved from 2.1811 to 2.1809. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6044\n",
      "Epoch [819/2000], Avg Train Loss: 3.6044\n",
      "Epoch [819/2000], Avg Val Loss: 2.1806\n",
      "Validation loss improved from 2.1809 to 2.1806. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5992\n",
      "Epoch [820/2000], Avg Train Loss: 3.5992\n",
      "Epoch [820/2000], Avg Val Loss: 2.1804\n",
      "Validation loss improved from 2.1806 to 2.1804. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5936\n",
      "Epoch [821/2000], Avg Train Loss: 3.5936\n",
      "Epoch [821/2000], Avg Val Loss: 2.1801\n",
      "Validation loss improved from 2.1804 to 2.1801. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6070\n",
      "Epoch [822/2000], Avg Train Loss: 3.6070\n",
      "Epoch [822/2000], Avg Val Loss: 2.1798\n",
      "Validation loss improved from 2.1801 to 2.1798. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6212\n",
      "Epoch [823/2000], Avg Train Loss: 3.6212\n",
      "Epoch [823/2000], Avg Val Loss: 2.1796\n",
      "Validation loss improved from 2.1798 to 2.1796. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5958\n",
      "Epoch [824/2000], Avg Train Loss: 3.5958\n",
      "Epoch [824/2000], Avg Val Loss: 2.1793\n",
      "Validation loss improved from 2.1796 to 2.1793. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5891\n",
      "Epoch [825/2000], Avg Train Loss: 3.5891\n",
      "Epoch [825/2000], Avg Val Loss: 2.1790\n",
      "Validation loss improved from 2.1793 to 2.1790. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6566\n",
      "Epoch [826/2000], Avg Train Loss: 3.6566\n",
      "Epoch [826/2000], Avg Val Loss: 2.1787\n",
      "Validation loss improved from 2.1790 to 2.1787. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5771\n",
      "Epoch [827/2000], Avg Train Loss: 3.5771\n",
      "Epoch [827/2000], Avg Val Loss: 2.1783\n",
      "Validation loss improved from 2.1787 to 2.1783. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6015\n",
      "Epoch [828/2000], Avg Train Loss: 3.6015\n",
      "Epoch [828/2000], Avg Val Loss: 2.1780\n",
      "Validation loss improved from 2.1783 to 2.1780. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6422\n",
      "Epoch [829/2000], Avg Train Loss: 3.6422\n",
      "Epoch [829/2000], Avg Val Loss: 2.1776\n",
      "Validation loss improved from 2.1780 to 2.1776. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6132\n",
      "Epoch [830/2000], Avg Train Loss: 3.6132\n",
      "Epoch [830/2000], Avg Val Loss: 2.1772\n",
      "Validation loss improved from 2.1776 to 2.1772. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6109\n",
      "Epoch [831/2000], Avg Train Loss: 3.6109\n",
      "Epoch [831/2000], Avg Val Loss: 2.1769\n",
      "Validation loss improved from 2.1772 to 2.1769. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5972\n",
      "Epoch [832/2000], Avg Train Loss: 3.5972\n",
      "Epoch [832/2000], Avg Val Loss: 2.1765\n",
      "Validation loss improved from 2.1769 to 2.1765. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6159\n",
      "Epoch [833/2000], Avg Train Loss: 3.6159\n",
      "Epoch [833/2000], Avg Val Loss: 2.1761\n",
      "Validation loss improved from 2.1765 to 2.1761. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5946\n",
      "Epoch [834/2000], Avg Train Loss: 3.5946\n",
      "Epoch [834/2000], Avg Val Loss: 2.1757\n",
      "Validation loss improved from 2.1761 to 2.1757. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5938\n",
      "Epoch [835/2000], Avg Train Loss: 3.5938\n",
      "Epoch [835/2000], Avg Val Loss: 2.1754\n",
      "Validation loss improved from 2.1757 to 2.1754. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5881\n",
      "Epoch [836/2000], Avg Train Loss: 3.5881\n",
      "Epoch [836/2000], Avg Val Loss: 2.1750\n",
      "Validation loss improved from 2.1754 to 2.1750. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5822\n",
      "Epoch [837/2000], Avg Train Loss: 3.5822\n",
      "Epoch [837/2000], Avg Val Loss: 2.1747\n",
      "Validation loss improved from 2.1750 to 2.1747. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5980\n",
      "Epoch [838/2000], Avg Train Loss: 3.5980\n",
      "Epoch [838/2000], Avg Val Loss: 2.1744\n",
      "Validation loss improved from 2.1747 to 2.1744. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6190\n",
      "Epoch [839/2000], Avg Train Loss: 3.6190\n",
      "Epoch [839/2000], Avg Val Loss: 2.1741\n",
      "Validation loss improved from 2.1744 to 2.1741. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5999\n",
      "Epoch [840/2000], Avg Train Loss: 3.5999\n",
      "Epoch [840/2000], Avg Val Loss: 2.1738\n",
      "Validation loss improved from 2.1741 to 2.1738. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5817\n",
      "Epoch [841/2000], Avg Train Loss: 3.5817\n",
      "Epoch [841/2000], Avg Val Loss: 2.1735\n",
      "Validation loss improved from 2.1738 to 2.1735. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5904\n",
      "Epoch [842/2000], Avg Train Loss: 3.5904\n",
      "Epoch [842/2000], Avg Val Loss: 2.1732\n",
      "Validation loss improved from 2.1735 to 2.1732. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6519\n",
      "Epoch [843/2000], Avg Train Loss: 3.6519\n",
      "Epoch [843/2000], Avg Val Loss: 2.1730\n",
      "Validation loss improved from 2.1732 to 2.1730. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6122\n",
      "Epoch [844/2000], Avg Train Loss: 3.6122\n",
      "Epoch [844/2000], Avg Val Loss: 2.1727\n",
      "Validation loss improved from 2.1730 to 2.1727. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6333\n",
      "Epoch [845/2000], Avg Train Loss: 3.6333\n",
      "Epoch [845/2000], Avg Val Loss: 2.1725\n",
      "Validation loss improved from 2.1727 to 2.1725. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5903\n",
      "Epoch [846/2000], Avg Train Loss: 3.5903\n",
      "Epoch [846/2000], Avg Val Loss: 2.1723\n",
      "Validation loss improved from 2.1725 to 2.1723. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6193\n",
      "Epoch [847/2000], Avg Train Loss: 3.6193\n",
      "Epoch [847/2000], Avg Val Loss: 2.1720\n",
      "Validation loss improved from 2.1723 to 2.1720. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6186\n",
      "Epoch [848/2000], Avg Train Loss: 3.6186\n",
      "Epoch [848/2000], Avg Val Loss: 2.1718\n",
      "Validation loss improved from 2.1720 to 2.1718. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6123\n",
      "Epoch [849/2000], Avg Train Loss: 3.6123\n",
      "Epoch [849/2000], Avg Val Loss: 2.1716\n",
      "Validation loss improved from 2.1718 to 2.1716. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6265\n",
      "Epoch [850/2000], Avg Train Loss: 3.6265\n",
      "Epoch [850/2000], Avg Val Loss: 2.1713\n",
      "Validation loss improved from 2.1716 to 2.1713. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6100\n",
      "Epoch [851/2000], Avg Train Loss: 3.6100\n",
      "Epoch [851/2000], Avg Val Loss: 2.1711\n",
      "Validation loss improved from 2.1713 to 2.1711. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5759\n",
      "Epoch [852/2000], Avg Train Loss: 3.5759\n",
      "Epoch [852/2000], Avg Val Loss: 2.1709\n",
      "Validation loss improved from 2.1711 to 2.1709. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5991\n",
      "Epoch [853/2000], Avg Train Loss: 3.5991\n",
      "Epoch [853/2000], Avg Val Loss: 2.1707\n",
      "Validation loss improved from 2.1709 to 2.1707. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6083\n",
      "Epoch [854/2000], Avg Train Loss: 3.6083\n",
      "Epoch [854/2000], Avg Val Loss: 2.1704\n",
      "Validation loss improved from 2.1707 to 2.1704. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5690\n",
      "Epoch [855/2000], Avg Train Loss: 3.5690\n",
      "Epoch [855/2000], Avg Val Loss: 2.1702\n",
      "Validation loss improved from 2.1704 to 2.1702. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5751\n",
      "Epoch [856/2000], Avg Train Loss: 3.5751\n",
      "Epoch [856/2000], Avg Val Loss: 2.1699\n",
      "Validation loss improved from 2.1702 to 2.1699. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6069\n",
      "Epoch [857/2000], Avg Train Loss: 3.6069\n",
      "Epoch [857/2000], Avg Val Loss: 2.1697\n",
      "Validation loss improved from 2.1699 to 2.1697. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5887\n",
      "Epoch [858/2000], Avg Train Loss: 3.5887\n",
      "Epoch [858/2000], Avg Val Loss: 2.1694\n",
      "Validation loss improved from 2.1697 to 2.1694. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6184\n",
      "Epoch [859/2000], Avg Train Loss: 3.6184\n",
      "Epoch [859/2000], Avg Val Loss: 2.1691\n",
      "Validation loss improved from 2.1694 to 2.1691. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5888\n",
      "Epoch [860/2000], Avg Train Loss: 3.5888\n",
      "Epoch [860/2000], Avg Val Loss: 2.1688\n",
      "Validation loss improved from 2.1691 to 2.1688. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6022\n",
      "Epoch [861/2000], Avg Train Loss: 3.6022\n",
      "Epoch [861/2000], Avg Val Loss: 2.1685\n",
      "Validation loss improved from 2.1688 to 2.1685. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6040\n",
      "Epoch [862/2000], Avg Train Loss: 3.6040\n",
      "Epoch [862/2000], Avg Val Loss: 2.1683\n",
      "Validation loss improved from 2.1685 to 2.1683. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6176\n",
      "Epoch [863/2000], Avg Train Loss: 3.6176\n",
      "Epoch [863/2000], Avg Val Loss: 2.1681\n",
      "Validation loss improved from 2.1683 to 2.1681. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6167\n",
      "Epoch [864/2000], Avg Train Loss: 3.6167\n",
      "Epoch [864/2000], Avg Val Loss: 2.1679\n",
      "Validation loss improved from 2.1681 to 2.1679. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6370\n",
      "Epoch [865/2000], Avg Train Loss: 3.6370\n",
      "Epoch [865/2000], Avg Val Loss: 2.1677\n",
      "Validation loss improved from 2.1679 to 2.1677. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6345\n",
      "Epoch [866/2000], Avg Train Loss: 3.6345\n",
      "Epoch [866/2000], Avg Val Loss: 2.1674\n",
      "Validation loss improved from 2.1677 to 2.1674. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6288\n",
      "Epoch [867/2000], Avg Train Loss: 3.6288\n",
      "Epoch [867/2000], Avg Val Loss: 2.1672\n",
      "Validation loss improved from 2.1674 to 2.1672. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5988\n",
      "Epoch [868/2000], Avg Train Loss: 3.5988\n",
      "Epoch [868/2000], Avg Val Loss: 2.1670\n",
      "Validation loss improved from 2.1672 to 2.1670. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5756\n",
      "Epoch [869/2000], Avg Train Loss: 3.5756\n",
      "Epoch [869/2000], Avg Val Loss: 2.1669\n",
      "Validation loss improved from 2.1670 to 2.1669. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5965\n",
      "Epoch [870/2000], Avg Train Loss: 3.5965\n",
      "Epoch [870/2000], Avg Val Loss: 2.1667\n",
      "Validation loss improved from 2.1669 to 2.1667. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5765\n",
      "Epoch [871/2000], Avg Train Loss: 3.5765\n",
      "Epoch [871/2000], Avg Val Loss: 2.1665\n",
      "Validation loss improved from 2.1667 to 2.1665. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6141\n",
      "Epoch [872/2000], Avg Train Loss: 3.6141\n",
      "Epoch [872/2000], Avg Val Loss: 2.1663\n",
      "Validation loss improved from 2.1665 to 2.1663. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5908\n",
      "Epoch [873/2000], Avg Train Loss: 3.5908\n",
      "Epoch [873/2000], Avg Val Loss: 2.1661\n",
      "Validation loss improved from 2.1663 to 2.1661. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5710\n",
      "Epoch [874/2000], Avg Train Loss: 3.5710\n",
      "Epoch [874/2000], Avg Val Loss: 2.1659\n",
      "Validation loss improved from 2.1661 to 2.1659. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5702\n",
      "Epoch [875/2000], Avg Train Loss: 3.5702\n",
      "Epoch [875/2000], Avg Val Loss: 2.1656\n",
      "Validation loss improved from 2.1659 to 2.1656. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6075\n",
      "Epoch [876/2000], Avg Train Loss: 3.6075\n",
      "Epoch [876/2000], Avg Val Loss: 2.1654\n",
      "Validation loss improved from 2.1656 to 2.1654. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5840\n",
      "Epoch [877/2000], Avg Train Loss: 3.5840\n",
      "Epoch [877/2000], Avg Val Loss: 2.1651\n",
      "Validation loss improved from 2.1654 to 2.1651. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5786\n",
      "Epoch [878/2000], Avg Train Loss: 3.5786\n",
      "Epoch [878/2000], Avg Val Loss: 2.1649\n",
      "Validation loss improved from 2.1651 to 2.1649. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5869\n",
      "Epoch [879/2000], Avg Train Loss: 3.5869\n",
      "Epoch [879/2000], Avg Val Loss: 2.1646\n",
      "Validation loss improved from 2.1649 to 2.1646. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5765\n",
      "Epoch [880/2000], Avg Train Loss: 3.5765\n",
      "Epoch [880/2000], Avg Val Loss: 2.1644\n",
      "Validation loss improved from 2.1646 to 2.1644. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5799\n",
      "Epoch [881/2000], Avg Train Loss: 3.5799\n",
      "Epoch [881/2000], Avg Val Loss: 2.1642\n",
      "Validation loss improved from 2.1644 to 2.1642. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5840\n",
      "Epoch [882/2000], Avg Train Loss: 3.5840\n",
      "Epoch [882/2000], Avg Val Loss: 2.1640\n",
      "Validation loss improved from 2.1642 to 2.1640. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5786\n",
      "Epoch [883/2000], Avg Train Loss: 3.5786\n",
      "Epoch [883/2000], Avg Val Loss: 2.1638\n",
      "Validation loss improved from 2.1640 to 2.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5753\n",
      "Epoch [884/2000], Avg Train Loss: 3.5753\n",
      "Epoch [884/2000], Avg Val Loss: 2.1636\n",
      "Validation loss improved from 2.1638 to 2.1636. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6189\n",
      "Epoch [885/2000], Avg Train Loss: 3.6189\n",
      "Epoch [885/2000], Avg Val Loss: 2.1634\n",
      "Validation loss improved from 2.1636 to 2.1634. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5808\n",
      "Epoch [886/2000], Avg Train Loss: 3.5808\n",
      "Epoch [886/2000], Avg Val Loss: 2.1632\n",
      "Validation loss improved from 2.1634 to 2.1632. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5963\n",
      "Epoch [887/2000], Avg Train Loss: 3.5963\n",
      "Epoch [887/2000], Avg Val Loss: 2.1631\n",
      "Validation loss improved from 2.1632 to 2.1631. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5916\n",
      "Epoch [888/2000], Avg Train Loss: 3.5916\n",
      "Epoch [888/2000], Avg Val Loss: 2.1629\n",
      "Validation loss improved from 2.1631 to 2.1629. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6046\n",
      "Epoch [889/2000], Avg Train Loss: 3.6046\n",
      "Epoch [889/2000], Avg Val Loss: 2.1626\n",
      "Validation loss improved from 2.1629 to 2.1626. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5746\n",
      "Epoch [890/2000], Avg Train Loss: 3.5746\n",
      "Epoch [890/2000], Avg Val Loss: 2.1624\n",
      "Validation loss improved from 2.1626 to 2.1624. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5699\n",
      "Epoch [891/2000], Avg Train Loss: 3.5699\n",
      "Epoch [891/2000], Avg Val Loss: 2.1622\n",
      "Validation loss improved from 2.1624 to 2.1622. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6006\n",
      "Epoch [892/2000], Avg Train Loss: 3.6006\n",
      "Epoch [892/2000], Avg Val Loss: 2.1621\n",
      "Validation loss improved from 2.1622 to 2.1621. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5861\n",
      "Epoch [893/2000], Avg Train Loss: 3.5861\n",
      "Epoch [893/2000], Avg Val Loss: 2.1619\n",
      "Validation loss improved from 2.1621 to 2.1619. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6143\n",
      "Epoch [894/2000], Avg Train Loss: 3.6143\n",
      "Epoch [894/2000], Avg Val Loss: 2.1617\n",
      "Validation loss improved from 2.1619 to 2.1617. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5980\n",
      "Epoch [895/2000], Avg Train Loss: 3.5980\n",
      "Epoch [895/2000], Avg Val Loss: 2.1615\n",
      "Validation loss improved from 2.1617 to 2.1615. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5933\n",
      "Epoch [896/2000], Avg Train Loss: 3.5933\n",
      "Epoch [896/2000], Avg Val Loss: 2.1613\n",
      "Validation loss improved from 2.1615 to 2.1613. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5860\n",
      "Epoch [897/2000], Avg Train Loss: 3.5860\n",
      "Epoch [897/2000], Avg Val Loss: 2.1611\n",
      "Validation loss improved from 2.1613 to 2.1611. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5683\n",
      "Epoch [898/2000], Avg Train Loss: 3.5683\n",
      "Epoch [898/2000], Avg Val Loss: 2.1610\n",
      "Validation loss improved from 2.1611 to 2.1610. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5668\n",
      "Epoch [899/2000], Avg Train Loss: 3.5668\n",
      "Epoch [899/2000], Avg Val Loss: 2.1608\n",
      "Validation loss improved from 2.1610 to 2.1608. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5755\n",
      "Epoch [900/2000], Avg Train Loss: 3.5755\n",
      "Epoch [900/2000], Avg Val Loss: 2.1607\n",
      "Validation loss improved from 2.1608 to 2.1607. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5937\n",
      "Epoch [901/2000], Avg Train Loss: 3.5937\n",
      "Epoch [901/2000], Avg Val Loss: 2.1605\n",
      "Validation loss improved from 2.1607 to 2.1605. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5844\n",
      "Epoch [902/2000], Avg Train Loss: 3.5844\n",
      "Epoch [902/2000], Avg Val Loss: 2.1603\n",
      "Validation loss improved from 2.1605 to 2.1603. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5803\n",
      "Epoch [903/2000], Avg Train Loss: 3.5803\n",
      "Epoch [903/2000], Avg Val Loss: 2.1601\n",
      "Validation loss improved from 2.1603 to 2.1601. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5936\n",
      "Epoch [904/2000], Avg Train Loss: 3.5936\n",
      "Epoch [904/2000], Avg Val Loss: 2.1599\n",
      "Validation loss improved from 2.1601 to 2.1599. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6064\n",
      "Epoch [905/2000], Avg Train Loss: 3.6064\n",
      "Epoch [905/2000], Avg Val Loss: 2.1597\n",
      "Validation loss improved from 2.1599 to 2.1597. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5655\n",
      "Epoch [906/2000], Avg Train Loss: 3.5655\n",
      "Epoch [906/2000], Avg Val Loss: 2.1596\n",
      "Validation loss improved from 2.1597 to 2.1596. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5902\n",
      "Epoch [907/2000], Avg Train Loss: 3.5902\n",
      "Epoch [907/2000], Avg Val Loss: 2.1594\n",
      "Validation loss improved from 2.1596 to 2.1594. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5814\n",
      "Epoch [908/2000], Avg Train Loss: 3.5814\n",
      "Epoch [908/2000], Avg Val Loss: 2.1592\n",
      "Validation loss improved from 2.1594 to 2.1592. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5474\n",
      "Epoch [909/2000], Avg Train Loss: 3.5474\n",
      "Epoch [909/2000], Avg Val Loss: 2.1590\n",
      "Validation loss improved from 2.1592 to 2.1590. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5945\n",
      "Epoch [910/2000], Avg Train Loss: 3.5945\n",
      "Epoch [910/2000], Avg Val Loss: 2.1588\n",
      "Validation loss improved from 2.1590 to 2.1588. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6111\n",
      "Epoch [911/2000], Avg Train Loss: 3.6111\n",
      "Epoch [911/2000], Avg Val Loss: 2.1586\n",
      "Validation loss improved from 2.1588 to 2.1586. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5650\n",
      "Epoch [912/2000], Avg Train Loss: 3.5650\n",
      "Epoch [912/2000], Avg Val Loss: 2.1584\n",
      "Validation loss improved from 2.1586 to 2.1584. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5649\n",
      "Epoch [913/2000], Avg Train Loss: 3.5649\n",
      "Epoch [913/2000], Avg Val Loss: 2.1582\n",
      "Validation loss improved from 2.1584 to 2.1582. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5510\n",
      "Epoch [914/2000], Avg Train Loss: 3.5510\n",
      "Epoch [914/2000], Avg Val Loss: 2.1579\n",
      "Validation loss improved from 2.1582 to 2.1579. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5730\n",
      "Epoch [915/2000], Avg Train Loss: 3.5730\n",
      "Epoch [915/2000], Avg Val Loss: 2.1576\n",
      "Validation loss improved from 2.1579 to 2.1576. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5841\n",
      "Epoch [916/2000], Avg Train Loss: 3.5841\n",
      "Epoch [916/2000], Avg Val Loss: 2.1573\n",
      "Validation loss improved from 2.1576 to 2.1573. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5889\n",
      "Epoch [917/2000], Avg Train Loss: 3.5889\n",
      "Epoch [917/2000], Avg Val Loss: 2.1570\n",
      "Validation loss improved from 2.1573 to 2.1570. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5839\n",
      "Epoch [918/2000], Avg Train Loss: 3.5839\n",
      "Epoch [918/2000], Avg Val Loss: 2.1567\n",
      "Validation loss improved from 2.1570 to 2.1567. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5712\n",
      "Epoch [919/2000], Avg Train Loss: 3.5712\n",
      "Epoch [919/2000], Avg Val Loss: 2.1565\n",
      "Validation loss improved from 2.1567 to 2.1565. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5664\n",
      "Epoch [920/2000], Avg Train Loss: 3.5664\n",
      "Epoch [920/2000], Avg Val Loss: 2.1562\n",
      "Validation loss improved from 2.1565 to 2.1562. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5406\n",
      "Epoch [921/2000], Avg Train Loss: 3.5406\n",
      "Epoch [921/2000], Avg Val Loss: 2.1560\n",
      "Validation loss improved from 2.1562 to 2.1560. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5929\n",
      "Epoch [922/2000], Avg Train Loss: 3.5929\n",
      "Epoch [922/2000], Avg Val Loss: 2.1557\n",
      "Validation loss improved from 2.1560 to 2.1557. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6161\n",
      "Epoch [923/2000], Avg Train Loss: 3.6161\n",
      "Epoch [923/2000], Avg Val Loss: 2.1553\n",
      "Validation loss improved from 2.1557 to 2.1553. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5595\n",
      "Epoch [924/2000], Avg Train Loss: 3.5595\n",
      "Epoch [924/2000], Avg Val Loss: 2.1550\n",
      "Validation loss improved from 2.1553 to 2.1550. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6087\n",
      "Epoch [925/2000], Avg Train Loss: 3.6087\n",
      "Epoch [925/2000], Avg Val Loss: 2.1548\n",
      "Validation loss improved from 2.1550 to 2.1548. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5631\n",
      "Epoch [926/2000], Avg Train Loss: 3.5631\n",
      "Epoch [926/2000], Avg Val Loss: 2.1545\n",
      "Validation loss improved from 2.1548 to 2.1545. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5986\n",
      "Epoch [927/2000], Avg Train Loss: 3.5986\n",
      "Epoch [927/2000], Avg Val Loss: 2.1543\n",
      "Validation loss improved from 2.1545 to 2.1543. Saving model...\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5952\n",
      "Epoch [928/2000], Avg Train Loss: 3.5952\n",
      "Epoch [928/2000], Avg Val Loss: 2.1541\n",
      "Validation loss improved from 2.1543 to 2.1541. Saving model...\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6044\n",
      "Epoch [929/2000], Avg Train Loss: 3.6044\n",
      "Epoch [929/2000], Avg Val Loss: 2.1538\n",
      "Validation loss improved from 2.1541 to 2.1538. Saving model...\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5636\n",
      "Epoch [930/2000], Avg Train Loss: 3.5636\n",
      "Epoch [930/2000], Avg Val Loss: 2.1535\n",
      "Validation loss improved from 2.1538 to 2.1535. Saving model...\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6027\n",
      "Epoch [931/2000], Avg Train Loss: 3.6027\n",
      "Epoch [931/2000], Avg Val Loss: 2.1532\n",
      "Validation loss improved from 2.1535 to 2.1532. Saving model...\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5954\n",
      "Epoch [932/2000], Avg Train Loss: 3.5954\n",
      "Epoch [932/2000], Avg Val Loss: 2.1529\n",
      "Validation loss improved from 2.1532 to 2.1529. Saving model...\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5375\n",
      "Epoch [933/2000], Avg Train Loss: 3.5375\n",
      "Epoch [933/2000], Avg Val Loss: 2.1526\n",
      "Validation loss improved from 2.1529 to 2.1526. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5591\n",
      "Epoch [934/2000], Avg Train Loss: 3.5591\n",
      "Epoch [934/2000], Avg Val Loss: 2.1524\n",
      "Validation loss improved from 2.1526 to 2.1524. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5613\n",
      "Epoch [935/2000], Avg Train Loss: 3.5613\n",
      "Epoch [935/2000], Avg Val Loss: 2.1522\n",
      "Validation loss improved from 2.1524 to 2.1522. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5972\n",
      "Epoch [936/2000], Avg Train Loss: 3.5972\n",
      "Epoch [936/2000], Avg Val Loss: 2.1520\n",
      "Validation loss improved from 2.1522 to 2.1520. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5429\n",
      "Epoch [937/2000], Avg Train Loss: 3.5429\n",
      "Epoch [937/2000], Avg Val Loss: 2.1518\n",
      "Validation loss improved from 2.1520 to 2.1518. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5498\n",
      "Epoch [938/2000], Avg Train Loss: 3.5498\n",
      "Epoch [938/2000], Avg Val Loss: 2.1517\n",
      "Validation loss improved from 2.1518 to 2.1517. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5131\n",
      "Epoch [939/2000], Avg Train Loss: 3.5131\n",
      "Epoch [939/2000], Avg Val Loss: 2.1516\n",
      "Validation loss improved from 2.1517 to 2.1516. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5383\n",
      "Epoch [940/2000], Avg Train Loss: 3.5383\n",
      "Epoch [940/2000], Avg Val Loss: 2.1515\n",
      "Validation loss improved from 2.1516 to 2.1515. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5400\n",
      "Epoch [941/2000], Avg Train Loss: 3.5400\n",
      "Epoch [941/2000], Avg Val Loss: 2.1514\n",
      "Validation loss improved from 2.1515 to 2.1514. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6098\n",
      "Epoch [942/2000], Avg Train Loss: 3.6098\n",
      "Epoch [942/2000], Avg Val Loss: 2.1512\n",
      "Validation loss improved from 2.1514 to 2.1512. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [943/2000], Avg Train Loss: 3.5435\n",
      "Epoch [943/2000], Avg Val Loss: 2.1511\n",
      "Validation loss improved from 2.1512 to 2.1511. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5613\n",
      "Epoch [944/2000], Avg Train Loss: 3.5613\n",
      "Epoch [944/2000], Avg Val Loss: 2.1509\n",
      "Validation loss improved from 2.1511 to 2.1509. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5363\n",
      "Epoch [945/2000], Avg Train Loss: 3.5363\n",
      "Epoch [945/2000], Avg Val Loss: 2.1508\n",
      "Validation loss improved from 2.1509 to 2.1508. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5570\n",
      "Epoch [946/2000], Avg Train Loss: 3.5570\n",
      "Epoch [946/2000], Avg Val Loss: 2.1506\n",
      "Validation loss improved from 2.1508 to 2.1506. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5502\n",
      "Epoch [947/2000], Avg Train Loss: 3.5502\n",
      "Epoch [947/2000], Avg Val Loss: 2.1505\n",
      "Validation loss improved from 2.1506 to 2.1505. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5654\n",
      "Epoch [948/2000], Avg Train Loss: 3.5654\n",
      "Epoch [948/2000], Avg Val Loss: 2.1503\n",
      "Validation loss improved from 2.1505 to 2.1503. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5790\n",
      "Epoch [949/2000], Avg Train Loss: 3.5790\n",
      "Epoch [949/2000], Avg Val Loss: 2.1502\n",
      "Validation loss improved from 2.1503 to 2.1502. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5680\n",
      "Epoch [950/2000], Avg Train Loss: 3.5680\n",
      "Epoch [950/2000], Avg Val Loss: 2.1501\n",
      "Validation loss improved from 2.1502 to 2.1501. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5610\n",
      "Epoch [951/2000], Avg Train Loss: 3.5610\n",
      "Epoch [951/2000], Avg Val Loss: 2.1499\n",
      "Validation loss improved from 2.1501 to 2.1499. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5325\n",
      "Epoch [952/2000], Avg Train Loss: 3.5325\n",
      "Epoch [952/2000], Avg Val Loss: 2.1498\n",
      "Validation loss improved from 2.1499 to 2.1498. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5444\n",
      "Epoch [953/2000], Avg Train Loss: 3.5444\n",
      "Epoch [953/2000], Avg Val Loss: 2.1497\n",
      "Validation loss improved from 2.1498 to 2.1497. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5341\n",
      "Epoch [954/2000], Avg Train Loss: 3.5341\n",
      "Epoch [954/2000], Avg Val Loss: 2.1496\n",
      "Validation loss improved from 2.1497 to 2.1496. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [955/2000], Avg Train Loss: 3.5435\n",
      "Epoch [955/2000], Avg Val Loss: 2.1495\n",
      "Validation loss improved from 2.1496 to 2.1495. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5762\n",
      "Epoch [956/2000], Avg Train Loss: 3.5762\n",
      "Epoch [956/2000], Avg Val Loss: 2.1494\n",
      "Validation loss improved from 2.1495 to 2.1494. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5837\n",
      "Epoch [957/2000], Avg Train Loss: 3.5837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [957/2000], Avg Val Loss: 2.1493\n",
      "Validation loss improved from 2.1494 to 2.1493. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5534\n",
      "Epoch [958/2000], Avg Train Loss: 3.5534\n",
      "Epoch [958/2000], Avg Val Loss: 2.1492\n",
      "Validation loss improved from 2.1493 to 2.1492. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5842\n",
      "Epoch [959/2000], Avg Train Loss: 3.5842\n",
      "Epoch [959/2000], Avg Val Loss: 2.1491\n",
      "Validation loss improved from 2.1492 to 2.1491. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5727\n",
      "Epoch [960/2000], Avg Train Loss: 3.5727\n",
      "Epoch [960/2000], Avg Val Loss: 2.1491\n",
      "Validation loss improved from 2.1491 to 2.1491. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5766\n",
      "Epoch [961/2000], Avg Train Loss: 3.5766\n",
      "Epoch [961/2000], Avg Val Loss: 2.1491\n",
      "Validation loss improved from 2.1491 to 2.1491. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5624\n",
      "Epoch [962/2000], Avg Train Loss: 3.5624\n",
      "Epoch [962/2000], Avg Val Loss: 2.1490\n",
      "Validation loss improved from 2.1491 to 2.1490. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5463\n",
      "Epoch [963/2000], Avg Train Loss: 3.5463\n",
      "Epoch [963/2000], Avg Val Loss: 2.1489\n",
      "Validation loss improved from 2.1490 to 2.1489. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5637\n",
      "Epoch [964/2000], Avg Train Loss: 3.5637\n",
      "Epoch [964/2000], Avg Val Loss: 2.1488\n",
      "Validation loss improved from 2.1489 to 2.1488. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5473\n",
      "Epoch [965/2000], Avg Train Loss: 3.5473\n",
      "Epoch [965/2000], Avg Val Loss: 2.1487\n",
      "Validation loss improved from 2.1488 to 2.1487. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5409\n",
      "Epoch [966/2000], Avg Train Loss: 3.5409\n",
      "Epoch [966/2000], Avg Val Loss: 2.1486\n",
      "Validation loss improved from 2.1487 to 2.1486. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5545\n",
      "Epoch [967/2000], Avg Train Loss: 3.5545\n",
      "Epoch [967/2000], Avg Val Loss: 2.1485\n",
      "Validation loss improved from 2.1486 to 2.1485. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5480\n",
      "Epoch [968/2000], Avg Train Loss: 3.5480\n",
      "Epoch [968/2000], Avg Val Loss: 2.1483\n",
      "Validation loss improved from 2.1485 to 2.1483. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5599\n",
      "Epoch [969/2000], Avg Train Loss: 3.5599\n",
      "Epoch [969/2000], Avg Val Loss: 2.1481\n",
      "Validation loss improved from 2.1483 to 2.1481. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5874\n",
      "Epoch [970/2000], Avg Train Loss: 3.5874\n",
      "Epoch [970/2000], Avg Val Loss: 2.1480\n",
      "Validation loss improved from 2.1481 to 2.1480. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5495\n",
      "Epoch [971/2000], Avg Train Loss: 3.5495\n",
      "Epoch [971/2000], Avg Val Loss: 2.1479\n",
      "Validation loss improved from 2.1480 to 2.1479. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5121\n",
      "Epoch [972/2000], Avg Train Loss: 3.5121\n",
      "Epoch [972/2000], Avg Val Loss: 2.1478\n",
      "Validation loss improved from 2.1479 to 2.1478. Saving model...\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5450\n",
      "Epoch [973/2000], Avg Train Loss: 3.5450\n",
      "Epoch [973/2000], Avg Val Loss: 2.1476\n",
      "Validation loss improved from 2.1478 to 2.1476. Saving model...\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5441\n",
      "Epoch [974/2000], Avg Train Loss: 3.5441\n",
      "Epoch [974/2000], Avg Val Loss: 2.1474\n",
      "Validation loss improved from 2.1476 to 2.1474. Saving model...\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5080\n",
      "Epoch [975/2000], Avg Train Loss: 3.5080\n",
      "Epoch [975/2000], Avg Val Loss: 2.1471\n",
      "Validation loss improved from 2.1474 to 2.1471. Saving model...\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5650\n",
      "Epoch [976/2000], Avg Train Loss: 3.5650\n",
      "Epoch [976/2000], Avg Val Loss: 2.1468\n",
      "Validation loss improved from 2.1471 to 2.1468. Saving model...\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5389\n",
      "Epoch [977/2000], Avg Train Loss: 3.5389\n",
      "Epoch [977/2000], Avg Val Loss: 2.1466\n",
      "Validation loss improved from 2.1468 to 2.1466. Saving model...\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5407\n",
      "Epoch [978/2000], Avg Train Loss: 3.5407\n",
      "Epoch [978/2000], Avg Val Loss: 2.1463\n",
      "Validation loss improved from 2.1466 to 2.1463. Saving model...\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5351\n",
      "Epoch [979/2000], Avg Train Loss: 3.5351\n",
      "Epoch [979/2000], Avg Val Loss: 2.1461\n",
      "Validation loss improved from 2.1463 to 2.1461. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5362\n",
      "Epoch [980/2000], Avg Train Loss: 3.5362\n",
      "Epoch [980/2000], Avg Val Loss: 2.1460\n",
      "Validation loss improved from 2.1461 to 2.1460. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5349\n",
      "Epoch [981/2000], Avg Train Loss: 3.5349\n",
      "Epoch [981/2000], Avg Val Loss: 2.1458\n",
      "Validation loss improved from 2.1460 to 2.1458. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5654\n",
      "Epoch [982/2000], Avg Train Loss: 3.5654\n",
      "Epoch [982/2000], Avg Val Loss: 2.1456\n",
      "Validation loss improved from 2.1458 to 2.1456. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5684\n",
      "Epoch [983/2000], Avg Train Loss: 3.5684\n",
      "Epoch [983/2000], Avg Val Loss: 2.1454\n",
      "Validation loss improved from 2.1456 to 2.1454. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [984/2000], Avg Train Loss: 3.5321\n",
      "Epoch [984/2000], Avg Val Loss: 2.1452\n",
      "Validation loss improved from 2.1454 to 2.1452. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5768\n",
      "Epoch [985/2000], Avg Train Loss: 3.5768\n",
      "Epoch [985/2000], Avg Val Loss: 2.1450\n",
      "Validation loss improved from 2.1452 to 2.1450. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5399\n",
      "Epoch [986/2000], Avg Train Loss: 3.5399\n",
      "Epoch [986/2000], Avg Val Loss: 2.1449\n",
      "Validation loss improved from 2.1450 to 2.1449. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5641\n",
      "Epoch [987/2000], Avg Train Loss: 3.5641\n",
      "Epoch [987/2000], Avg Val Loss: 2.1447\n",
      "Validation loss improved from 2.1449 to 2.1447. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5295\n",
      "Epoch [988/2000], Avg Train Loss: 3.5295\n",
      "Epoch [988/2000], Avg Val Loss: 2.1445\n",
      "Validation loss improved from 2.1447 to 2.1445. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5767\n",
      "Epoch [989/2000], Avg Train Loss: 3.5767\n",
      "Epoch [989/2000], Avg Val Loss: 2.1443\n",
      "Validation loss improved from 2.1445 to 2.1443. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5244\n",
      "Epoch [990/2000], Avg Train Loss: 3.5244\n",
      "Epoch [990/2000], Avg Val Loss: 2.1442\n",
      "Validation loss improved from 2.1443 to 2.1442. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5492\n",
      "Epoch [991/2000], Avg Train Loss: 3.5492\n",
      "Epoch [991/2000], Avg Val Loss: 2.1440\n",
      "Validation loss improved from 2.1442 to 2.1440. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4967\n",
      "Epoch [992/2000], Avg Train Loss: 3.4967\n",
      "Epoch [992/2000], Avg Val Loss: 2.1437\n",
      "Validation loss improved from 2.1440 to 2.1437. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5485\n",
      "Epoch [993/2000], Avg Train Loss: 3.5485\n",
      "Epoch [993/2000], Avg Val Loss: 2.1436\n",
      "Validation loss improved from 2.1437 to 2.1436. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5067\n",
      "Epoch [994/2000], Avg Train Loss: 3.5067\n",
      "Epoch [994/2000], Avg Val Loss: 2.1434\n",
      "Validation loss improved from 2.1436 to 2.1434. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5560\n",
      "Epoch [995/2000], Avg Train Loss: 3.5560\n",
      "Epoch [995/2000], Avg Val Loss: 2.1432\n",
      "Validation loss improved from 2.1434 to 2.1432. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5591\n",
      "Epoch [996/2000], Avg Train Loss: 3.5591\n",
      "Epoch [996/2000], Avg Val Loss: 2.1431\n",
      "Validation loss improved from 2.1432 to 2.1431. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5791\n",
      "Epoch [997/2000], Avg Train Loss: 3.5791\n",
      "Epoch [997/2000], Avg Val Loss: 2.1429\n",
      "Validation loss improved from 2.1431 to 2.1429. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5300\n",
      "Epoch [998/2000], Avg Train Loss: 3.5300\n",
      "Epoch [998/2000], Avg Val Loss: 2.1427\n",
      "Validation loss improved from 2.1429 to 2.1427. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5371\n",
      "Epoch [999/2000], Avg Train Loss: 3.5371\n",
      "Epoch [999/2000], Avg Val Loss: 2.1426\n",
      "Validation loss improved from 2.1427 to 2.1426. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5384\n",
      "Epoch [1000/2000], Avg Train Loss: 3.5384\n",
      "Epoch [1000/2000], Avg Val Loss: 2.1425\n",
      "Validation loss improved from 2.1426 to 2.1425. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5327\n",
      "Epoch [1001/2000], Avg Train Loss: 3.5327\n",
      "Epoch [1001/2000], Avg Val Loss: 2.1424\n",
      "Validation loss improved from 2.1425 to 2.1424. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5227\n",
      "Epoch [1002/2000], Avg Train Loss: 3.5227\n",
      "Epoch [1002/2000], Avg Val Loss: 2.1422\n",
      "Validation loss improved from 2.1424 to 2.1422. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5348\n",
      "Epoch [1003/2000], Avg Train Loss: 3.5348\n",
      "Epoch [1003/2000], Avg Val Loss: 2.1420\n",
      "Validation loss improved from 2.1422 to 2.1420. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5201\n",
      "Epoch [1004/2000], Avg Train Loss: 3.5201\n",
      "Epoch [1004/2000], Avg Val Loss: 2.1418\n",
      "Validation loss improved from 2.1420 to 2.1418. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [1005/2000], Avg Train Loss: 3.5435\n",
      "Epoch [1005/2000], Avg Val Loss: 2.1416\n",
      "Validation loss improved from 2.1418 to 2.1416. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5464\n",
      "Epoch [1006/2000], Avg Train Loss: 3.5464\n",
      "Epoch [1006/2000], Avg Val Loss: 2.1414\n",
      "Validation loss improved from 2.1416 to 2.1414. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5667\n",
      "Epoch [1007/2000], Avg Train Loss: 3.5667\n",
      "Epoch [1007/2000], Avg Val Loss: 2.1412\n",
      "Validation loss improved from 2.1414 to 2.1412. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5560\n",
      "Epoch [1008/2000], Avg Train Loss: 3.5560\n",
      "Epoch [1008/2000], Avg Val Loss: 2.1410\n",
      "Validation loss improved from 2.1412 to 2.1410. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5336\n",
      "Epoch [1009/2000], Avg Train Loss: 3.5336\n",
      "Epoch [1009/2000], Avg Val Loss: 2.1409\n",
      "Validation loss improved from 2.1410 to 2.1409. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5352\n",
      "Epoch [1010/2000], Avg Train Loss: 3.5352\n",
      "Epoch [1010/2000], Avg Val Loss: 2.1407\n",
      "Validation loss improved from 2.1409 to 2.1407. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5382\n",
      "Epoch [1011/2000], Avg Train Loss: 3.5382\n",
      "Epoch [1011/2000], Avg Val Loss: 2.1405\n",
      "Validation loss improved from 2.1407 to 2.1405. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5447\n",
      "Epoch [1012/2000], Avg Train Loss: 3.5447\n",
      "Epoch [1012/2000], Avg Val Loss: 2.1403\n",
      "Validation loss improved from 2.1405 to 2.1403. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5010\n",
      "Epoch [1013/2000], Avg Train Loss: 3.5010\n",
      "Epoch [1013/2000], Avg Val Loss: 2.1401\n",
      "Validation loss improved from 2.1403 to 2.1401. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5202\n",
      "Epoch [1014/2000], Avg Train Loss: 3.5202\n",
      "Epoch [1014/2000], Avg Val Loss: 2.1400\n",
      "Validation loss improved from 2.1401 to 2.1400. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5334\n",
      "Epoch [1015/2000], Avg Train Loss: 3.5334\n",
      "Epoch [1015/2000], Avg Val Loss: 2.1399\n",
      "Validation loss improved from 2.1400 to 2.1399. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5290\n",
      "Epoch [1016/2000], Avg Train Loss: 3.5290\n",
      "Epoch [1016/2000], Avg Val Loss: 2.1398\n",
      "Validation loss improved from 2.1399 to 2.1398. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5164\n",
      "Epoch [1017/2000], Avg Train Loss: 3.5164\n",
      "Epoch [1017/2000], Avg Val Loss: 2.1398\n",
      "Validation loss improved from 2.1398 to 2.1398. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5072\n",
      "Epoch [1018/2000], Avg Train Loss: 3.5072\n",
      "Epoch [1018/2000], Avg Val Loss: 2.1396\n",
      "Validation loss improved from 2.1398 to 2.1396. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5380\n",
      "Epoch [1019/2000], Avg Train Loss: 3.5380\n",
      "Epoch [1019/2000], Avg Val Loss: 2.1396\n",
      "Validation loss improved from 2.1396 to 2.1396. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5416\n",
      "Epoch [1020/2000], Avg Train Loss: 3.5416\n",
      "Epoch [1020/2000], Avg Val Loss: 2.1394\n",
      "Validation loss improved from 2.1396 to 2.1394. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5485\n",
      "Epoch [1021/2000], Avg Train Loss: 3.5485\n",
      "Epoch [1021/2000], Avg Val Loss: 2.1393\n",
      "Validation loss improved from 2.1394 to 2.1393. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5345\n",
      "Epoch [1022/2000], Avg Train Loss: 3.5345\n",
      "Epoch [1022/2000], Avg Val Loss: 2.1391\n",
      "Validation loss improved from 2.1393 to 2.1391. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5343\n",
      "Epoch [1023/2000], Avg Train Loss: 3.5343\n",
      "Epoch [1023/2000], Avg Val Loss: 2.1390\n",
      "Validation loss improved from 2.1391 to 2.1390. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5203\n",
      "Epoch [1024/2000], Avg Train Loss: 3.5203\n",
      "Epoch [1024/2000], Avg Val Loss: 2.1388\n",
      "Validation loss improved from 2.1390 to 2.1388. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5032\n",
      "Epoch [1025/2000], Avg Train Loss: 3.5032\n",
      "Epoch [1025/2000], Avg Val Loss: 2.1387\n",
      "Validation loss improved from 2.1388 to 2.1387. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5303\n",
      "Epoch [1026/2000], Avg Train Loss: 3.5303\n",
      "Epoch [1026/2000], Avg Val Loss: 2.1386\n",
      "Validation loss improved from 2.1387 to 2.1386. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5347\n",
      "Epoch [1027/2000], Avg Train Loss: 3.5347\n",
      "Epoch [1027/2000], Avg Val Loss: 2.1386\n",
      "Validation loss improved from 2.1386 to 2.1386. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5609\n",
      "Epoch [1028/2000], Avg Train Loss: 3.5609\n",
      "Epoch [1028/2000], Avg Val Loss: 2.1385\n",
      "Validation loss improved from 2.1386 to 2.1385. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5357\n",
      "Epoch [1029/2000], Avg Train Loss: 3.5357\n",
      "Epoch [1029/2000], Avg Val Loss: 2.1384\n",
      "Validation loss improved from 2.1385 to 2.1384. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5123\n",
      "Epoch [1030/2000], Avg Train Loss: 3.5123\n",
      "Epoch [1030/2000], Avg Val Loss: 2.1383\n",
      "Validation loss improved from 2.1384 to 2.1383. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5322\n",
      "Epoch [1031/2000], Avg Train Loss: 3.5322\n",
      "Epoch [1031/2000], Avg Val Loss: 2.1381\n",
      "Validation loss improved from 2.1383 to 2.1381. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5403\n",
      "Epoch [1032/2000], Avg Train Loss: 3.5403\n",
      "Epoch [1032/2000], Avg Val Loss: 2.1380\n",
      "Validation loss improved from 2.1381 to 2.1380. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5429\n",
      "Epoch [1033/2000], Avg Train Loss: 3.5429\n",
      "Epoch [1033/2000], Avg Val Loss: 2.1378\n",
      "Validation loss improved from 2.1380 to 2.1378. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5297\n",
      "Epoch [1034/2000], Avg Train Loss: 3.5297\n",
      "Epoch [1034/2000], Avg Val Loss: 2.1376\n",
      "Validation loss improved from 2.1378 to 2.1376. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5300\n",
      "Epoch [1035/2000], Avg Train Loss: 3.5300\n",
      "Epoch [1035/2000], Avg Val Loss: 2.1374\n",
      "Validation loss improved from 2.1376 to 2.1374. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5298\n",
      "Epoch [1036/2000], Avg Train Loss: 3.5298\n",
      "Epoch [1036/2000], Avg Val Loss: 2.1372\n",
      "Validation loss improved from 2.1374 to 2.1372. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5288\n",
      "Epoch [1037/2000], Avg Train Loss: 3.5288\n",
      "Epoch [1037/2000], Avg Val Loss: 2.1369\n",
      "Validation loss improved from 2.1372 to 2.1369. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5281\n",
      "Epoch [1038/2000], Avg Train Loss: 3.5281\n",
      "Epoch [1038/2000], Avg Val Loss: 2.1366\n",
      "Validation loss improved from 2.1369 to 2.1366. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5167\n",
      "Epoch [1039/2000], Avg Train Loss: 3.5167\n",
      "Epoch [1039/2000], Avg Val Loss: 2.1364\n",
      "Validation loss improved from 2.1366 to 2.1364. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5238\n",
      "Epoch [1040/2000], Avg Train Loss: 3.5238\n",
      "Epoch [1040/2000], Avg Val Loss: 2.1362\n",
      "Validation loss improved from 2.1364 to 2.1362. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5578\n",
      "Epoch [1041/2000], Avg Train Loss: 3.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1041/2000], Avg Val Loss: 2.1360\n",
      "Validation loss improved from 2.1362 to 2.1360. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5565\n",
      "Epoch [1042/2000], Avg Train Loss: 3.5565\n",
      "Epoch [1042/2000], Avg Val Loss: 2.1358\n",
      "Validation loss improved from 2.1360 to 2.1358. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5299\n",
      "Epoch [1043/2000], Avg Train Loss: 3.5299\n",
      "Epoch [1043/2000], Avg Val Loss: 2.1355\n",
      "Validation loss improved from 2.1358 to 2.1355. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5182\n",
      "Epoch [1044/2000], Avg Train Loss: 3.5182\n",
      "Epoch [1044/2000], Avg Val Loss: 2.1353\n",
      "Validation loss improved from 2.1355 to 2.1353. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5392\n",
      "Epoch [1045/2000], Avg Train Loss: 3.5392\n",
      "Epoch [1045/2000], Avg Val Loss: 2.1351\n",
      "Validation loss improved from 2.1353 to 2.1351. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5519\n",
      "Epoch [1046/2000], Avg Train Loss: 3.5519\n",
      "Epoch [1046/2000], Avg Val Loss: 2.1349\n",
      "Validation loss improved from 2.1351 to 2.1349. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5382\n",
      "Epoch [1047/2000], Avg Train Loss: 3.5382\n",
      "Epoch [1047/2000], Avg Val Loss: 2.1347\n",
      "Validation loss improved from 2.1349 to 2.1347. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5139\n",
      "Epoch [1048/2000], Avg Train Loss: 3.5139\n",
      "Epoch [1048/2000], Avg Val Loss: 2.1345\n",
      "Validation loss improved from 2.1347 to 2.1345. Saving model...\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5459\n",
      "Epoch [1049/2000], Avg Train Loss: 3.5459\n",
      "Epoch [1049/2000], Avg Val Loss: 2.1344\n",
      "Validation loss improved from 2.1345 to 2.1344. Saving model...\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5377\n",
      "Epoch [1050/2000], Avg Train Loss: 3.5377\n",
      "Epoch [1050/2000], Avg Val Loss: 2.1342\n",
      "Validation loss improved from 2.1344 to 2.1342. Saving model...\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4835\n",
      "Epoch [1051/2000], Avg Train Loss: 3.4835\n",
      "Epoch [1051/2000], Avg Val Loss: 2.1341\n",
      "Validation loss improved from 2.1342 to 2.1341. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5751\n",
      "Epoch [1052/2000], Avg Train Loss: 3.5751\n",
      "Epoch [1052/2000], Avg Val Loss: 2.1339\n",
      "Validation loss improved from 2.1341 to 2.1339. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5130\n",
      "Epoch [1053/2000], Avg Train Loss: 3.5130\n",
      "Epoch [1053/2000], Avg Val Loss: 2.1337\n",
      "Validation loss improved from 2.1339 to 2.1337. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5442\n",
      "Epoch [1054/2000], Avg Train Loss: 3.5442\n",
      "Epoch [1054/2000], Avg Val Loss: 2.1334\n",
      "Validation loss improved from 2.1337 to 2.1334. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5024\n",
      "Epoch [1055/2000], Avg Train Loss: 3.5024\n",
      "Epoch [1055/2000], Avg Val Loss: 2.1331\n",
      "Validation loss improved from 2.1334 to 2.1331. Saving model...\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4944\n",
      "Epoch [1056/2000], Avg Train Loss: 3.4944\n",
      "Epoch [1056/2000], Avg Val Loss: 2.1328\n",
      "Validation loss improved from 2.1331 to 2.1328. Saving model...\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5376\n",
      "Epoch [1057/2000], Avg Train Loss: 3.5376\n",
      "Epoch [1057/2000], Avg Val Loss: 2.1326\n",
      "Validation loss improved from 2.1328 to 2.1326. Saving model...\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5326\n",
      "Epoch [1058/2000], Avg Train Loss: 3.5326\n",
      "Epoch [1058/2000], Avg Val Loss: 2.1323\n",
      "Validation loss improved from 2.1326 to 2.1323. Saving model...\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5335\n",
      "Epoch [1059/2000], Avg Train Loss: 3.5335\n",
      "Epoch [1059/2000], Avg Val Loss: 2.1320\n",
      "Validation loss improved from 2.1323 to 2.1320. Saving model...\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5390\n",
      "Epoch [1060/2000], Avg Train Loss: 3.5390\n",
      "Epoch [1060/2000], Avg Val Loss: 2.1318\n",
      "Validation loss improved from 2.1320 to 2.1318. Saving model...\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5420\n",
      "Epoch [1061/2000], Avg Train Loss: 3.5420\n",
      "Epoch [1061/2000], Avg Val Loss: 2.1315\n",
      "Validation loss improved from 2.1318 to 2.1315. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5599\n",
      "Epoch [1062/2000], Avg Train Loss: 3.5599\n",
      "Epoch [1062/2000], Avg Val Loss: 2.1312\n",
      "Validation loss improved from 2.1315 to 2.1312. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5183\n",
      "Epoch [1063/2000], Avg Train Loss: 3.5183\n",
      "Epoch [1063/2000], Avg Val Loss: 2.1309\n",
      "Validation loss improved from 2.1312 to 2.1309. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5095\n",
      "Epoch [1064/2000], Avg Train Loss: 3.5095\n",
      "Epoch [1064/2000], Avg Val Loss: 2.1307\n",
      "Validation loss improved from 2.1309 to 2.1307. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5267\n",
      "Epoch [1065/2000], Avg Train Loss: 3.5267\n",
      "Epoch [1065/2000], Avg Val Loss: 2.1305\n",
      "Validation loss improved from 2.1307 to 2.1305. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5105\n",
      "Epoch [1066/2000], Avg Train Loss: 3.5105\n",
      "Epoch [1066/2000], Avg Val Loss: 2.1303\n",
      "Validation loss improved from 2.1305 to 2.1303. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4991\n",
      "Epoch [1067/2000], Avg Train Loss: 3.4991\n",
      "Epoch [1067/2000], Avg Val Loss: 2.1301\n",
      "Validation loss improved from 2.1303 to 2.1301. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5067\n",
      "Epoch [1068/2000], Avg Train Loss: 3.5067\n",
      "Epoch [1068/2000], Avg Val Loss: 2.1299\n",
      "Validation loss improved from 2.1301 to 2.1299. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5269\n",
      "Epoch [1069/2000], Avg Train Loss: 3.5269\n",
      "Epoch [1069/2000], Avg Val Loss: 2.1297\n",
      "Validation loss improved from 2.1299 to 2.1297. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5349\n",
      "Epoch [1070/2000], Avg Train Loss: 3.5349\n",
      "Epoch [1070/2000], Avg Val Loss: 2.1295\n",
      "Validation loss improved from 2.1297 to 2.1295. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5357\n",
      "Epoch [1071/2000], Avg Train Loss: 3.5357\n",
      "Epoch [1071/2000], Avg Val Loss: 2.1294\n",
      "Validation loss improved from 2.1295 to 2.1294. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5141\n",
      "Epoch [1072/2000], Avg Train Loss: 3.5141\n",
      "Epoch [1072/2000], Avg Val Loss: 2.1293\n",
      "Validation loss improved from 2.1294 to 2.1293. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4927\n",
      "Epoch [1073/2000], Avg Train Loss: 3.4927\n",
      "Epoch [1073/2000], Avg Val Loss: 2.1293\n",
      "Validation loss improved from 2.1293 to 2.1293. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5042\n",
      "Epoch [1074/2000], Avg Train Loss: 3.5042\n",
      "Epoch [1074/2000], Avg Val Loss: 2.1292\n",
      "Validation loss improved from 2.1293 to 2.1292. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5259\n",
      "Epoch [1075/2000], Avg Train Loss: 3.5259\n",
      "Epoch [1075/2000], Avg Val Loss: 2.1292\n",
      "Validation loss improved from 2.1292 to 2.1292. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5227\n",
      "Epoch [1076/2000], Avg Train Loss: 3.5227\n",
      "Epoch [1076/2000], Avg Val Loss: 2.1292\n",
      "Validation loss improved from 2.1292 to 2.1292. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5047\n",
      "Epoch [1077/2000], Avg Train Loss: 3.5047\n",
      "Epoch [1077/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5351\n",
      "Epoch [1078/2000], Avg Train Loss: 3.5351\n",
      "Epoch [1078/2000], Avg Val Loss: 2.1292\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5345\n",
      "Epoch [1079/2000], Avg Train Loss: 3.5345\n",
      "Epoch [1079/2000], Avg Val Loss: 2.1292\n",
      "Validation loss improved from 2.1292 to 2.1292. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4957\n",
      "Epoch [1080/2000], Avg Train Loss: 3.4957\n",
      "Epoch [1080/2000], Avg Val Loss: 2.1291\n",
      "Validation loss improved from 2.1292 to 2.1291. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5168\n",
      "Epoch [1081/2000], Avg Train Loss: 3.5168\n",
      "Epoch [1081/2000], Avg Val Loss: 2.1291\n",
      "Validation loss improved from 2.1291 to 2.1291. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5059\n",
      "Epoch [1082/2000], Avg Train Loss: 3.5059\n",
      "Epoch [1082/2000], Avg Val Loss: 2.1291\n",
      "Validation loss improved from 2.1291 to 2.1291. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5383\n",
      "Epoch [1083/2000], Avg Train Loss: 3.5383\n",
      "Epoch [1083/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5201\n",
      "Epoch [1084/2000], Avg Train Loss: 3.5201\n",
      "Epoch [1084/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5441\n",
      "Epoch [1085/2000], Avg Train Loss: 3.5441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1085/2000], Avg Val Loss: 2.1290\n",
      "Validation loss improved from 2.1291 to 2.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4926\n",
      "Epoch [1086/2000], Avg Train Loss: 3.4926\n",
      "Epoch [1086/2000], Avg Val Loss: 2.1290\n",
      "Validation loss improved from 2.1290 to 2.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5165\n",
      "Epoch [1087/2000], Avg Train Loss: 3.5165\n",
      "Epoch [1087/2000], Avg Val Loss: 2.1290\n",
      "Validation loss improved from 2.1290 to 2.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4914\n",
      "Epoch [1088/2000], Avg Train Loss: 3.4914\n",
      "Epoch [1088/2000], Avg Val Loss: 2.1290\n",
      "Validation loss improved from 2.1290 to 2.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4979\n",
      "Epoch [1089/2000], Avg Train Loss: 3.4979\n",
      "Epoch [1089/2000], Avg Val Loss: 2.1290\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4695\n",
      "Epoch [1090/2000], Avg Train Loss: 3.4695\n",
      "Epoch [1090/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4858\n",
      "Epoch [1091/2000], Avg Train Loss: 3.4858\n",
      "Epoch [1091/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4885\n",
      "Epoch [1092/2000], Avg Train Loss: 3.4885\n",
      "Epoch [1092/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5143\n",
      "Epoch [1093/2000], Avg Train Loss: 3.5143\n",
      "Epoch [1093/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5177\n",
      "Epoch [1094/2000], Avg Train Loss: 3.5177\n",
      "Epoch [1094/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4987\n",
      "Epoch [1095/2000], Avg Train Loss: 3.4987\n",
      "Epoch [1095/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5325\n",
      "Epoch [1096/2000], Avg Train Loss: 3.5325\n",
      "Epoch [1096/2000], Avg Val Loss: 2.1291\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5556\n",
      "Epoch [1097/2000], Avg Train Loss: 3.5556\n",
      "Epoch [1097/2000], Avg Val Loss: 2.1290\n",
      "Validation loss improved from 2.1290 to 2.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4748\n",
      "Epoch [1098/2000], Avg Train Loss: 3.4748\n",
      "Epoch [1098/2000], Avg Val Loss: 2.1289\n",
      "Validation loss improved from 2.1290 to 2.1289. Saving model...\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5065\n",
      "Epoch [1099/2000], Avg Train Loss: 3.5065\n",
      "Epoch [1099/2000], Avg Val Loss: 2.1288\n",
      "Validation loss improved from 2.1289 to 2.1288. Saving model...\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4841\n",
      "Epoch [1100/2000], Avg Train Loss: 3.4841\n",
      "Epoch [1100/2000], Avg Val Loss: 2.1286\n",
      "Validation loss improved from 2.1288 to 2.1286. Saving model...\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5194\n",
      "Epoch [1101/2000], Avg Train Loss: 3.5194\n",
      "Epoch [1101/2000], Avg Val Loss: 2.1285\n",
      "Validation loss improved from 2.1286 to 2.1285. Saving model...\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5220\n",
      "Epoch [1102/2000], Avg Train Loss: 3.5220\n",
      "Epoch [1102/2000], Avg Val Loss: 2.1283\n",
      "Validation loss improved from 2.1285 to 2.1283. Saving model...\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5060\n",
      "Epoch [1103/2000], Avg Train Loss: 3.5060\n",
      "Epoch [1103/2000], Avg Val Loss: 2.1281\n",
      "Validation loss improved from 2.1283 to 2.1281. Saving model...\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5324\n",
      "Epoch [1104/2000], Avg Train Loss: 3.5324\n",
      "Epoch [1104/2000], Avg Val Loss: 2.1280\n",
      "Validation loss improved from 2.1281 to 2.1280. Saving model...\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5106\n",
      "Epoch [1105/2000], Avg Train Loss: 3.5106\n",
      "Epoch [1105/2000], Avg Val Loss: 2.1278\n",
      "Validation loss improved from 2.1280 to 2.1278. Saving model...\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5205\n",
      "Epoch [1106/2000], Avg Train Loss: 3.5205\n",
      "Epoch [1106/2000], Avg Val Loss: 2.1277\n",
      "Validation loss improved from 2.1278 to 2.1277. Saving model...\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5179\n",
      "Epoch [1107/2000], Avg Train Loss: 3.5179\n",
      "Epoch [1107/2000], Avg Val Loss: 2.1276\n",
      "Validation loss improved from 2.1277 to 2.1276. Saving model...\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4982\n",
      "Epoch [1108/2000], Avg Train Loss: 3.4982\n",
      "Epoch [1108/2000], Avg Val Loss: 2.1274\n",
      "Validation loss improved from 2.1276 to 2.1274. Saving model...\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5040\n",
      "Epoch [1109/2000], Avg Train Loss: 3.5040\n",
      "Epoch [1109/2000], Avg Val Loss: 2.1273\n",
      "Validation loss improved from 2.1274 to 2.1273. Saving model...\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5064\n",
      "Epoch [1110/2000], Avg Train Loss: 3.5064\n",
      "Epoch [1110/2000], Avg Val Loss: 2.1272\n",
      "Validation loss improved from 2.1273 to 2.1272. Saving model...\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4812\n",
      "Epoch [1111/2000], Avg Train Loss: 3.4812\n",
      "Epoch [1111/2000], Avg Val Loss: 2.1271\n",
      "Validation loss improved from 2.1272 to 2.1271. Saving model...\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5204\n",
      "Epoch [1112/2000], Avg Train Loss: 3.5204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1112/2000], Avg Val Loss: 2.1269\n",
      "Validation loss improved from 2.1271 to 2.1269. Saving model...\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5251\n",
      "Epoch [1113/2000], Avg Train Loss: 3.5251\n",
      "Epoch [1113/2000], Avg Val Loss: 2.1267\n",
      "Validation loss improved from 2.1269 to 2.1267. Saving model...\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4895\n",
      "Epoch [1114/2000], Avg Train Loss: 3.4895\n",
      "Epoch [1114/2000], Avg Val Loss: 2.1265\n",
      "Validation loss improved from 2.1267 to 2.1265. Saving model...\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4990\n",
      "Epoch [1115/2000], Avg Train Loss: 3.4990\n",
      "Epoch [1115/2000], Avg Val Loss: 2.1263\n",
      "Validation loss improved from 2.1265 to 2.1263. Saving model...\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5054\n",
      "Epoch [1116/2000], Avg Train Loss: 3.5054\n",
      "Epoch [1116/2000], Avg Val Loss: 2.1261\n",
      "Validation loss improved from 2.1263 to 2.1261. Saving model...\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4842\n",
      "Epoch [1117/2000], Avg Train Loss: 3.4842\n",
      "Epoch [1117/2000], Avg Val Loss: 2.1258\n",
      "Validation loss improved from 2.1261 to 2.1258. Saving model...\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4783\n",
      "Epoch [1118/2000], Avg Train Loss: 3.4783\n",
      "Epoch [1118/2000], Avg Val Loss: 2.1255\n",
      "Validation loss improved from 2.1258 to 2.1255. Saving model...\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5302\n",
      "Epoch [1119/2000], Avg Train Loss: 3.5302\n",
      "Epoch [1119/2000], Avg Val Loss: 2.1253\n",
      "Validation loss improved from 2.1255 to 2.1253. Saving model...\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5038\n",
      "Epoch [1120/2000], Avg Train Loss: 3.5038\n",
      "Epoch [1120/2000], Avg Val Loss: 2.1251\n",
      "Validation loss improved from 2.1253 to 2.1251. Saving model...\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5130\n",
      "Epoch [1121/2000], Avg Train Loss: 3.5130\n",
      "Epoch [1121/2000], Avg Val Loss: 2.1248\n",
      "Validation loss improved from 2.1251 to 2.1248. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4712\n",
      "Epoch [1122/2000], Avg Train Loss: 3.4712\n",
      "Epoch [1122/2000], Avg Val Loss: 2.1245\n",
      "Validation loss improved from 2.1248 to 2.1245. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5071\n",
      "Epoch [1123/2000], Avg Train Loss: 3.5071\n",
      "Epoch [1123/2000], Avg Val Loss: 2.1243\n",
      "Validation loss improved from 2.1245 to 2.1243. Saving model...\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5166\n",
      "Epoch [1124/2000], Avg Train Loss: 3.5166\n",
      "Epoch [1124/2000], Avg Val Loss: 2.1241\n",
      "Validation loss improved from 2.1243 to 2.1241. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4959\n",
      "Epoch [1125/2000], Avg Train Loss: 3.4959\n",
      "Epoch [1125/2000], Avg Val Loss: 2.1240\n",
      "Validation loss improved from 2.1241 to 2.1240. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5022\n",
      "Epoch [1126/2000], Avg Train Loss: 3.5022\n",
      "Epoch [1126/2000], Avg Val Loss: 2.1238\n",
      "Validation loss improved from 2.1240 to 2.1238. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5234\n",
      "Epoch [1127/2000], Avg Train Loss: 3.5234\n",
      "Epoch [1127/2000], Avg Val Loss: 2.1237\n",
      "Validation loss improved from 2.1238 to 2.1237. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5165\n",
      "Epoch [1128/2000], Avg Train Loss: 3.5165\n",
      "Epoch [1128/2000], Avg Val Loss: 2.1236\n",
      "Validation loss improved from 2.1237 to 2.1236. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5148\n",
      "Epoch [1129/2000], Avg Train Loss: 3.5148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1129/2000], Avg Val Loss: 2.1235\n",
      "Validation loss improved from 2.1236 to 2.1235. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5092\n",
      "Epoch [1130/2000], Avg Train Loss: 3.5092\n",
      "Epoch [1130/2000], Avg Val Loss: 2.1234\n",
      "Validation loss improved from 2.1235 to 2.1234. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4877\n",
      "Epoch [1131/2000], Avg Train Loss: 3.4877\n",
      "Epoch [1131/2000], Avg Val Loss: 2.1233\n",
      "Validation loss improved from 2.1234 to 2.1233. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5068\n",
      "Epoch [1132/2000], Avg Train Loss: 3.5068\n",
      "Epoch [1132/2000], Avg Val Loss: 2.1232\n",
      "Validation loss improved from 2.1233 to 2.1232. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4724\n",
      "Epoch [1133/2000], Avg Train Loss: 3.4724\n",
      "Epoch [1133/2000], Avg Val Loss: 2.1232\n",
      "Validation loss improved from 2.1232 to 2.1232. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4943\n",
      "Epoch [1134/2000], Avg Train Loss: 3.4943\n",
      "Epoch [1134/2000], Avg Val Loss: 2.1231\n",
      "Validation loss improved from 2.1232 to 2.1231. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4944\n",
      "Epoch [1135/2000], Avg Train Loss: 3.4944\n",
      "Epoch [1135/2000], Avg Val Loss: 2.1230\n",
      "Validation loss improved from 2.1231 to 2.1230. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5028\n",
      "Epoch [1136/2000], Avg Train Loss: 3.5028\n",
      "Epoch [1136/2000], Avg Val Loss: 2.1230\n",
      "Validation loss improved from 2.1230 to 2.1230. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5116\n",
      "Epoch [1137/2000], Avg Train Loss: 3.5116\n",
      "Epoch [1137/2000], Avg Val Loss: 2.1229\n",
      "Validation loss improved from 2.1230 to 2.1229. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4790\n",
      "Epoch [1138/2000], Avg Train Loss: 3.4790\n",
      "Epoch [1138/2000], Avg Val Loss: 2.1229\n",
      "Validation loss improved from 2.1229 to 2.1229. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4840\n",
      "Epoch [1139/2000], Avg Train Loss: 3.4840\n",
      "Epoch [1139/2000], Avg Val Loss: 2.1228\n",
      "Validation loss improved from 2.1229 to 2.1228. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4811\n",
      "Epoch [1140/2000], Avg Train Loss: 3.4811\n",
      "Epoch [1140/2000], Avg Val Loss: 2.1227\n",
      "Validation loss improved from 2.1228 to 2.1227. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5152\n",
      "Epoch [1141/2000], Avg Train Loss: 3.5152\n",
      "Epoch [1141/2000], Avg Val Loss: 2.1226\n",
      "Validation loss improved from 2.1227 to 2.1226. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4859\n",
      "Epoch [1142/2000], Avg Train Loss: 3.4859\n",
      "Epoch [1142/2000], Avg Val Loss: 2.1225\n",
      "Validation loss improved from 2.1226 to 2.1225. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4978\n",
      "Epoch [1143/2000], Avg Train Loss: 3.4978\n",
      "Epoch [1143/2000], Avg Val Loss: 2.1224\n",
      "Validation loss improved from 2.1225 to 2.1224. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4753\n",
      "Epoch [1144/2000], Avg Train Loss: 3.4753\n",
      "Epoch [1144/2000], Avg Val Loss: 2.1222\n",
      "Validation loss improved from 2.1224 to 2.1222. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4826\n",
      "Epoch [1145/2000], Avg Train Loss: 3.4826\n",
      "Epoch [1145/2000], Avg Val Loss: 2.1221\n",
      "Validation loss improved from 2.1222 to 2.1221. Saving model...\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4968\n",
      "Epoch [1146/2000], Avg Train Loss: 3.4968\n",
      "Epoch [1146/2000], Avg Val Loss: 2.1219\n",
      "Validation loss improved from 2.1221 to 2.1219. Saving model...\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5001\n",
      "Epoch [1147/2000], Avg Train Loss: 3.5001\n",
      "Epoch [1147/2000], Avg Val Loss: 2.1218\n",
      "Validation loss improved from 2.1219 to 2.1218. Saving model...\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5070\n",
      "Epoch [1148/2000], Avg Train Loss: 3.5070\n",
      "Epoch [1148/2000], Avg Val Loss: 2.1217\n",
      "Validation loss improved from 2.1218 to 2.1217. Saving model...\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5058\n",
      "Epoch [1149/2000], Avg Train Loss: 3.5058\n",
      "Epoch [1149/2000], Avg Val Loss: 2.1216\n",
      "Validation loss improved from 2.1217 to 2.1216. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5009\n",
      "Epoch [1150/2000], Avg Train Loss: 3.5009\n",
      "Epoch [1150/2000], Avg Val Loss: 2.1214\n",
      "Validation loss improved from 2.1216 to 2.1214. Saving model...\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5088\n",
      "Epoch [1151/2000], Avg Train Loss: 3.5088\n",
      "Epoch [1151/2000], Avg Val Loss: 2.1212\n",
      "Validation loss improved from 2.1214 to 2.1212. Saving model...\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4882\n",
      "Epoch [1152/2000], Avg Train Loss: 3.4882\n",
      "Epoch [1152/2000], Avg Val Loss: 2.1209\n",
      "Validation loss improved from 2.1212 to 2.1209. Saving model...\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4748\n",
      "Epoch [1153/2000], Avg Train Loss: 3.4748\n",
      "Epoch [1153/2000], Avg Val Loss: 2.1207\n",
      "Validation loss improved from 2.1209 to 2.1207. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5003\n",
      "Epoch [1154/2000], Avg Train Loss: 3.5003\n",
      "Epoch [1154/2000], Avg Val Loss: 2.1205\n",
      "Validation loss improved from 2.1207 to 2.1205. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4926\n",
      "Epoch [1155/2000], Avg Train Loss: 3.4926\n",
      "Epoch [1155/2000], Avg Val Loss: 2.1203\n",
      "Validation loss improved from 2.1205 to 2.1203. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4982\n",
      "Epoch [1156/2000], Avg Train Loss: 3.4982\n",
      "Epoch [1156/2000], Avg Val Loss: 2.1200\n",
      "Validation loss improved from 2.1203 to 2.1200. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5008\n",
      "Epoch [1157/2000], Avg Train Loss: 3.5008\n",
      "Epoch [1157/2000], Avg Val Loss: 2.1197\n",
      "Validation loss improved from 2.1200 to 2.1197. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4975\n",
      "Epoch [1158/2000], Avg Train Loss: 3.4975\n",
      "Epoch [1158/2000], Avg Val Loss: 2.1195\n",
      "Validation loss improved from 2.1197 to 2.1195. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5156\n",
      "Epoch [1159/2000], Avg Train Loss: 3.5156\n",
      "Epoch [1159/2000], Avg Val Loss: 2.1191\n",
      "Validation loss improved from 2.1195 to 2.1191. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4670\n",
      "Epoch [1160/2000], Avg Train Loss: 3.4670\n",
      "Epoch [1160/2000], Avg Val Loss: 2.1187\n",
      "Validation loss improved from 2.1191 to 2.1187. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4756\n",
      "Epoch [1161/2000], Avg Train Loss: 3.4756\n",
      "Epoch [1161/2000], Avg Val Loss: 2.1185\n",
      "Validation loss improved from 2.1187 to 2.1185. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4835\n",
      "Epoch [1162/2000], Avg Train Loss: 3.4835\n",
      "Epoch [1162/2000], Avg Val Loss: 2.1182\n",
      "Validation loss improved from 2.1185 to 2.1182. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4514\n",
      "Epoch [1163/2000], Avg Train Loss: 3.4514\n",
      "Epoch [1163/2000], Avg Val Loss: 2.1179\n",
      "Validation loss improved from 2.1182 to 2.1179. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4768\n",
      "Epoch [1164/2000], Avg Train Loss: 3.4768\n",
      "Epoch [1164/2000], Avg Val Loss: 2.1176\n",
      "Validation loss improved from 2.1179 to 2.1176. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4810\n",
      "Epoch [1165/2000], Avg Train Loss: 3.4810\n",
      "Epoch [1165/2000], Avg Val Loss: 2.1173\n",
      "Validation loss improved from 2.1176 to 2.1173. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4865\n",
      "Epoch [1166/2000], Avg Train Loss: 3.4865\n",
      "Epoch [1166/2000], Avg Val Loss: 2.1171\n",
      "Validation loss improved from 2.1173 to 2.1171. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5086\n",
      "Epoch [1167/2000], Avg Train Loss: 3.5086\n",
      "Epoch [1167/2000], Avg Val Loss: 2.1168\n",
      "Validation loss improved from 2.1171 to 2.1168. Saving model...\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4865\n",
      "Epoch [1168/2000], Avg Train Loss: 3.4865\n",
      "Epoch [1168/2000], Avg Val Loss: 2.1166\n",
      "Validation loss improved from 2.1168 to 2.1166. Saving model...\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4676\n",
      "Epoch [1169/2000], Avg Train Loss: 3.4676\n",
      "Epoch [1169/2000], Avg Val Loss: 2.1164\n",
      "Validation loss improved from 2.1166 to 2.1164. Saving model...\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4490\n",
      "Epoch [1170/2000], Avg Train Loss: 3.4490\n",
      "Epoch [1170/2000], Avg Val Loss: 2.1162\n",
      "Validation loss improved from 2.1164 to 2.1162. Saving model...\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4921\n",
      "Epoch [1171/2000], Avg Train Loss: 3.4921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1171/2000], Avg Val Loss: 2.1159\n",
      "Validation loss improved from 2.1162 to 2.1159. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4747\n",
      "Epoch [1172/2000], Avg Train Loss: 3.4747\n",
      "Epoch [1172/2000], Avg Val Loss: 2.1157\n",
      "Validation loss improved from 2.1159 to 2.1157. Saving model...\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5108\n",
      "Epoch [1173/2000], Avg Train Loss: 3.5108\n",
      "Epoch [1173/2000], Avg Val Loss: 2.1155\n",
      "Validation loss improved from 2.1157 to 2.1155. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4792\n",
      "Epoch [1174/2000], Avg Train Loss: 3.4792\n",
      "Epoch [1174/2000], Avg Val Loss: 2.1153\n",
      "Validation loss improved from 2.1155 to 2.1153. Saving model...\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5029\n",
      "Epoch [1175/2000], Avg Train Loss: 3.5029\n",
      "Epoch [1175/2000], Avg Val Loss: 2.1150\n",
      "Validation loss improved from 2.1153 to 2.1150. Saving model...\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4915\n",
      "Epoch [1176/2000], Avg Train Loss: 3.4915\n",
      "Epoch [1176/2000], Avg Val Loss: 2.1147\n",
      "Validation loss improved from 2.1150 to 2.1147. Saving model...\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4779\n",
      "Epoch [1177/2000], Avg Train Loss: 3.4779\n",
      "Epoch [1177/2000], Avg Val Loss: 2.1145\n",
      "Validation loss improved from 2.1147 to 2.1145. Saving model...\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5047\n",
      "Epoch [1178/2000], Avg Train Loss: 3.5047\n",
      "Epoch [1178/2000], Avg Val Loss: 2.1143\n",
      "Validation loss improved from 2.1145 to 2.1143. Saving model...\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5173\n",
      "Epoch [1179/2000], Avg Train Loss: 3.5173\n",
      "Epoch [1179/2000], Avg Val Loss: 2.1142\n",
      "Validation loss improved from 2.1143 to 2.1142. Saving model...\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4746\n",
      "Epoch [1180/2000], Avg Train Loss: 3.4746\n",
      "Epoch [1180/2000], Avg Val Loss: 2.1140\n",
      "Validation loss improved from 2.1142 to 2.1140. Saving model...\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4788\n",
      "Epoch [1181/2000], Avg Train Loss: 3.4788\n",
      "Epoch [1181/2000], Avg Val Loss: 2.1137\n",
      "Validation loss improved from 2.1140 to 2.1137. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4766\n",
      "Epoch [1182/2000], Avg Train Loss: 3.4766\n",
      "Epoch [1182/2000], Avg Val Loss: 2.1136\n",
      "Validation loss improved from 2.1137 to 2.1136. Saving model...\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4885\n",
      "Epoch [1183/2000], Avg Train Loss: 3.4885\n",
      "Epoch [1183/2000], Avg Val Loss: 2.1134\n",
      "Validation loss improved from 2.1136 to 2.1134. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4931\n",
      "Epoch [1184/2000], Avg Train Loss: 3.4931\n",
      "Epoch [1184/2000], Avg Val Loss: 2.1132\n",
      "Validation loss improved from 2.1134 to 2.1132. Saving model...\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4965\n",
      "Epoch [1185/2000], Avg Train Loss: 3.4965\n",
      "Epoch [1185/2000], Avg Val Loss: 2.1131\n",
      "Validation loss improved from 2.1132 to 2.1131. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4704\n",
      "Epoch [1186/2000], Avg Train Loss: 3.4704\n",
      "Epoch [1186/2000], Avg Val Loss: 2.1129\n",
      "Validation loss improved from 2.1131 to 2.1129. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4986\n",
      "Epoch [1187/2000], Avg Train Loss: 3.4986\n",
      "Epoch [1187/2000], Avg Val Loss: 2.1128\n",
      "Validation loss improved from 2.1129 to 2.1128. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4548\n",
      "Epoch [1188/2000], Avg Train Loss: 3.4548\n",
      "Epoch [1188/2000], Avg Val Loss: 2.1127\n",
      "Validation loss improved from 2.1128 to 2.1127. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5068\n",
      "Epoch [1189/2000], Avg Train Loss: 3.5068\n",
      "Epoch [1189/2000], Avg Val Loss: 2.1126\n",
      "Validation loss improved from 2.1127 to 2.1126. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4778\n",
      "Epoch [1190/2000], Avg Train Loss: 3.4778\n",
      "Epoch [1190/2000], Avg Val Loss: 2.1125\n",
      "Validation loss improved from 2.1126 to 2.1125. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4832\n",
      "Epoch [1191/2000], Avg Train Loss: 3.4832\n",
      "Epoch [1191/2000], Avg Val Loss: 2.1124\n",
      "Validation loss improved from 2.1125 to 2.1124. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4542\n",
      "Epoch [1192/2000], Avg Train Loss: 3.4542\n",
      "Epoch [1192/2000], Avg Val Loss: 2.1124\n",
      "Validation loss improved from 2.1124 to 2.1124. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4758\n",
      "Epoch [1193/2000], Avg Train Loss: 3.4758\n",
      "Epoch [1193/2000], Avg Val Loss: 2.1124\n",
      "Validation loss improved from 2.1124 to 2.1124. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4831\n",
      "Epoch [1194/2000], Avg Train Loss: 3.4831\n",
      "Epoch [1194/2000], Avg Val Loss: 2.1123\n",
      "Validation loss improved from 2.1124 to 2.1123. Saving model...\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4440\n",
      "Epoch [1195/2000], Avg Train Loss: 3.4440\n",
      "Epoch [1195/2000], Avg Val Loss: 2.1123\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4749\n",
      "Epoch [1196/2000], Avg Train Loss: 3.4749\n",
      "Epoch [1196/2000], Avg Val Loss: 2.1124\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4735\n",
      "Epoch [1197/2000], Avg Train Loss: 3.4735\n",
      "Epoch [1197/2000], Avg Val Loss: 2.1125\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4830\n",
      "Epoch [1198/2000], Avg Train Loss: 3.4830\n",
      "Epoch [1198/2000], Avg Val Loss: 2.1125\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4737\n",
      "Epoch [1199/2000], Avg Train Loss: 3.4737\n",
      "Epoch [1199/2000], Avg Val Loss: 2.1125\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4633\n",
      "Epoch [1200/2000], Avg Train Loss: 3.4633\n",
      "Epoch [1200/2000], Avg Val Loss: 2.1124\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4998\n",
      "Epoch [1201/2000], Avg Train Loss: 3.4998\n",
      "Epoch [1201/2000], Avg Val Loss: 2.1124\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4734\n",
      "Epoch [1202/2000], Avg Train Loss: 3.4734\n",
      "Epoch [1202/2000], Avg Val Loss: 2.1123\n",
      "Validation loss improved from 2.1123 to 2.1123. Saving model...\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4614\n",
      "Epoch [1203/2000], Avg Train Loss: 3.4614\n",
      "Epoch [1203/2000], Avg Val Loss: 2.1122\n",
      "Validation loss improved from 2.1123 to 2.1122. Saving model...\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4812\n",
      "Epoch [1204/2000], Avg Train Loss: 3.4812\n",
      "Epoch [1204/2000], Avg Val Loss: 2.1122\n",
      "Validation loss improved from 2.1122 to 2.1122. Saving model...\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4848\n",
      "Epoch [1205/2000], Avg Train Loss: 3.4848\n",
      "Epoch [1205/2000], Avg Val Loss: 2.1121\n",
      "Validation loss improved from 2.1122 to 2.1121. Saving model...\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4831\n",
      "Epoch [1206/2000], Avg Train Loss: 3.4831\n",
      "Epoch [1206/2000], Avg Val Loss: 2.1120\n",
      "Validation loss improved from 2.1121 to 2.1120. Saving model...\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4478\n",
      "Epoch [1207/2000], Avg Train Loss: 3.4478\n",
      "Epoch [1207/2000], Avg Val Loss: 2.1119\n",
      "Validation loss improved from 2.1120 to 2.1119. Saving model...\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4958\n",
      "Epoch [1208/2000], Avg Train Loss: 3.4958\n",
      "Epoch [1208/2000], Avg Val Loss: 2.1118\n",
      "Validation loss improved from 2.1119 to 2.1118. Saving model...\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4692\n",
      "Epoch [1209/2000], Avg Train Loss: 3.4692\n",
      "Epoch [1209/2000], Avg Val Loss: 2.1117\n",
      "Validation loss improved from 2.1118 to 2.1117. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4596\n",
      "Epoch [1210/2000], Avg Train Loss: 3.4596\n",
      "Epoch [1210/2000], Avg Val Loss: 2.1117\n",
      "Validation loss improved from 2.1117 to 2.1117. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4790\n",
      "Epoch [1211/2000], Avg Train Loss: 3.4790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1211/2000], Avg Val Loss: 2.1116\n",
      "Validation loss improved from 2.1117 to 2.1116. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4891\n",
      "Epoch [1212/2000], Avg Train Loss: 3.4891\n",
      "Epoch [1212/2000], Avg Val Loss: 2.1116\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4809\n",
      "Epoch [1213/2000], Avg Train Loss: 3.4809\n",
      "Epoch [1213/2000], Avg Val Loss: 2.1116\n",
      "Validation loss improved from 2.1116 to 2.1116. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4513\n",
      "Epoch [1214/2000], Avg Train Loss: 3.4513\n",
      "Epoch [1214/2000], Avg Val Loss: 2.1116\n",
      "Validation loss improved from 2.1116 to 2.1116. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4946\n",
      "Epoch [1215/2000], Avg Train Loss: 3.4946\n",
      "Epoch [1215/2000], Avg Val Loss: 2.1115\n",
      "Validation loss improved from 2.1116 to 2.1115. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4814\n",
      "Epoch [1216/2000], Avg Train Loss: 3.4814\n",
      "Epoch [1216/2000], Avg Val Loss: 2.1114\n",
      "Validation loss improved from 2.1115 to 2.1114. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5018\n",
      "Epoch [1217/2000], Avg Train Loss: 3.5018\n",
      "Epoch [1217/2000], Avg Val Loss: 2.1112\n",
      "Validation loss improved from 2.1114 to 2.1112. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4682\n",
      "Epoch [1218/2000], Avg Train Loss: 3.4682\n",
      "Epoch [1218/2000], Avg Val Loss: 2.1110\n",
      "Validation loss improved from 2.1112 to 2.1110. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4771\n",
      "Epoch [1219/2000], Avg Train Loss: 3.4771\n",
      "Epoch [1219/2000], Avg Val Loss: 2.1108\n",
      "Validation loss improved from 2.1110 to 2.1108. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4668\n",
      "Epoch [1220/2000], Avg Train Loss: 3.4668\n",
      "Epoch [1220/2000], Avg Val Loss: 2.1106\n",
      "Validation loss improved from 2.1108 to 2.1106. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4465\n",
      "Epoch [1221/2000], Avg Train Loss: 3.4465\n",
      "Epoch [1221/2000], Avg Val Loss: 2.1104\n",
      "Validation loss improved from 2.1106 to 2.1104. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4661\n",
      "Epoch [1222/2000], Avg Train Loss: 3.4661\n",
      "Epoch [1222/2000], Avg Val Loss: 2.1102\n",
      "Validation loss improved from 2.1104 to 2.1102. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4781\n",
      "Epoch [1223/2000], Avg Train Loss: 3.4781\n",
      "Epoch [1223/2000], Avg Val Loss: 2.1101\n",
      "Validation loss improved from 2.1102 to 2.1101. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4959\n",
      "Epoch [1224/2000], Avg Train Loss: 3.4959\n",
      "Epoch [1224/2000], Avg Val Loss: 2.1100\n",
      "Validation loss improved from 2.1101 to 2.1100. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4875\n",
      "Epoch [1225/2000], Avg Train Loss: 3.4875\n",
      "Epoch [1225/2000], Avg Val Loss: 2.1098\n",
      "Validation loss improved from 2.1100 to 2.1098. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4670\n",
      "Epoch [1226/2000], Avg Train Loss: 3.4670\n",
      "Epoch [1226/2000], Avg Val Loss: 2.1096\n",
      "Validation loss improved from 2.1098 to 2.1096. Saving model...\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4650\n",
      "Epoch [1227/2000], Avg Train Loss: 3.4650\n",
      "Epoch [1227/2000], Avg Val Loss: 2.1094\n",
      "Validation loss improved from 2.1096 to 2.1094. Saving model...\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4778\n",
      "Epoch [1228/2000], Avg Train Loss: 3.4778\n",
      "Epoch [1228/2000], Avg Val Loss: 2.1092\n",
      "Validation loss improved from 2.1094 to 2.1092. Saving model...\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4722\n",
      "Epoch [1229/2000], Avg Train Loss: 3.4722\n",
      "Epoch [1229/2000], Avg Val Loss: 2.1090\n",
      "Validation loss improved from 2.1092 to 2.1090. Saving model...\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4957\n",
      "Epoch [1230/2000], Avg Train Loss: 3.4957\n",
      "Epoch [1230/2000], Avg Val Loss: 2.1088\n",
      "Validation loss improved from 2.1090 to 2.1088. Saving model...\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4758\n",
      "Epoch [1231/2000], Avg Train Loss: 3.4758\n",
      "Epoch [1231/2000], Avg Val Loss: 2.1086\n",
      "Validation loss improved from 2.1088 to 2.1086. Saving model...\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4428\n",
      "Epoch [1232/2000], Avg Train Loss: 3.4428\n",
      "Epoch [1232/2000], Avg Val Loss: 2.1084\n",
      "Validation loss improved from 2.1086 to 2.1084. Saving model...\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4783\n",
      "Epoch [1233/2000], Avg Train Loss: 3.4783\n",
      "Epoch [1233/2000], Avg Val Loss: 2.1082\n",
      "Validation loss improved from 2.1084 to 2.1082. Saving model...\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4283\n",
      "Epoch [1234/2000], Avg Train Loss: 3.4283\n",
      "Epoch [1234/2000], Avg Val Loss: 2.1080\n",
      "Validation loss improved from 2.1082 to 2.1080. Saving model...\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4619\n",
      "Epoch [1235/2000], Avg Train Loss: 3.4619\n",
      "Epoch [1235/2000], Avg Val Loss: 2.1079\n",
      "Validation loss improved from 2.1080 to 2.1079. Saving model...\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4599\n",
      "Epoch [1236/2000], Avg Train Loss: 3.4599\n",
      "Epoch [1236/2000], Avg Val Loss: 2.1077\n",
      "Validation loss improved from 2.1079 to 2.1077. Saving model...\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4809\n",
      "Epoch [1237/2000], Avg Train Loss: 3.4809\n",
      "Epoch [1237/2000], Avg Val Loss: 2.1076\n",
      "Validation loss improved from 2.1077 to 2.1076. Saving model...\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4616\n",
      "Epoch [1238/2000], Avg Train Loss: 3.4616\n",
      "Epoch [1238/2000], Avg Val Loss: 2.1075\n",
      "Validation loss improved from 2.1076 to 2.1075. Saving model...\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4370\n",
      "Epoch [1239/2000], Avg Train Loss: 3.4370\n",
      "Epoch [1239/2000], Avg Val Loss: 2.1074\n",
      "Validation loss improved from 2.1075 to 2.1074. Saving model...\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4610\n",
      "Epoch [1240/2000], Avg Train Loss: 3.4610\n",
      "Epoch [1240/2000], Avg Val Loss: 2.1072\n",
      "Validation loss improved from 2.1074 to 2.1072. Saving model...\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4757\n",
      "Epoch [1241/2000], Avg Train Loss: 3.4757\n",
      "Epoch [1241/2000], Avg Val Loss: 2.1071\n",
      "Validation loss improved from 2.1072 to 2.1071. Saving model...\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4523\n",
      "Epoch [1242/2000], Avg Train Loss: 3.4523\n",
      "Epoch [1242/2000], Avg Val Loss: 2.1070\n",
      "Validation loss improved from 2.1071 to 2.1070. Saving model...\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4738\n",
      "Epoch [1243/2000], Avg Train Loss: 3.4738\n",
      "Epoch [1243/2000], Avg Val Loss: 2.1070\n",
      "Validation loss improved from 2.1070 to 2.1070. Saving model...\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4575\n",
      "Epoch [1244/2000], Avg Train Loss: 3.4575\n",
      "Epoch [1244/2000], Avg Val Loss: 2.1070\n",
      "Validation loss improved from 2.1070 to 2.1070. Saving model...\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4553\n",
      "Epoch [1245/2000], Avg Train Loss: 3.4553\n",
      "Epoch [1245/2000], Avg Val Loss: 2.1070\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4770\n",
      "Epoch [1246/2000], Avg Train Loss: 3.4770\n",
      "Epoch [1246/2000], Avg Val Loss: 2.1070\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4469\n",
      "Epoch [1247/2000], Avg Train Loss: 3.4469\n",
      "Epoch [1247/2000], Avg Val Loss: 2.1070\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4355\n",
      "Epoch [1248/2000], Avg Train Loss: 3.4355\n",
      "Epoch [1248/2000], Avg Val Loss: 2.1070\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4827\n",
      "Epoch [1249/2000], Avg Train Loss: 3.4827\n",
      "Epoch [1249/2000], Avg Val Loss: 2.1070\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4760\n",
      "Epoch [1250/2000], Avg Train Loss: 3.4760\n",
      "Epoch [1250/2000], Avg Val Loss: 2.1071\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4497\n",
      "Epoch [1251/2000], Avg Train Loss: 3.4497\n",
      "Epoch [1251/2000], Avg Val Loss: 2.1071\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4632\n",
      "Epoch [1252/2000], Avg Train Loss: 3.4632\n",
      "Epoch [1252/2000], Avg Val Loss: 2.1072\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4774\n",
      "Epoch [1253/2000], Avg Train Loss: 3.4774\n",
      "Epoch [1253/2000], Avg Val Loss: 2.1072\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4578\n",
      "Epoch [1254/2000], Avg Train Loss: 3.4578\n",
      "Epoch [1254/2000], Avg Val Loss: 2.1072\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4768\n",
      "Epoch [1255/2000], Avg Train Loss: 3.4768\n",
      "Epoch [1255/2000], Avg Val Loss: 2.1073\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4641\n",
      "Epoch [1256/2000], Avg Train Loss: 3.4641\n",
      "Epoch [1256/2000], Avg Val Loss: 2.1073\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4815\n",
      "Epoch [1257/2000], Avg Train Loss: 3.4815\n",
      "Epoch [1257/2000], Avg Val Loss: 2.1073\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4518\n",
      "Epoch [1258/2000], Avg Train Loss: 3.4518\n",
      "Epoch [1258/2000], Avg Val Loss: 2.1072\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4824\n",
      "Epoch [1259/2000], Avg Train Loss: 3.4824\n",
      "Epoch [1259/2000], Avg Val Loss: 2.1071\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4161\n",
      "Epoch [1260/2000], Avg Train Loss: 3.4161\n",
      "Epoch [1260/2000], Avg Val Loss: 2.1071\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4856\n",
      "Epoch [1261/2000], Avg Train Loss: 3.4856\n",
      "Epoch [1261/2000], Avg Val Loss: 2.1070\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4767\n",
      "Epoch [1262/2000], Avg Train Loss: 3.4767\n",
      "Epoch [1262/2000], Avg Val Loss: 2.1069\n",
      "Validation loss improved from 2.1070 to 2.1069. Saving model...\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4632\n",
      "Epoch [1263/2000], Avg Train Loss: 3.4632\n",
      "Epoch [1263/2000], Avg Val Loss: 2.1068\n",
      "Validation loss improved from 2.1069 to 2.1068. Saving model...\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4612\n",
      "Epoch [1264/2000], Avg Train Loss: 3.4612\n",
      "Epoch [1264/2000], Avg Val Loss: 2.1067\n",
      "Validation loss improved from 2.1068 to 2.1067. Saving model...\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4909\n",
      "Epoch [1265/2000], Avg Train Loss: 3.4909\n",
      "Epoch [1265/2000], Avg Val Loss: 2.1066\n",
      "Validation loss improved from 2.1067 to 2.1066. Saving model...\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4447\n",
      "Epoch [1266/2000], Avg Train Loss: 3.4447\n",
      "Epoch [1266/2000], Avg Val Loss: 2.1065\n",
      "Validation loss improved from 2.1066 to 2.1065. Saving model...\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4471\n",
      "Epoch [1267/2000], Avg Train Loss: 3.4471\n",
      "Epoch [1267/2000], Avg Val Loss: 2.1064\n",
      "Validation loss improved from 2.1065 to 2.1064. Saving model...\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4583\n",
      "Epoch [1268/2000], Avg Train Loss: 3.4583\n",
      "Epoch [1268/2000], Avg Val Loss: 2.1063\n",
      "Validation loss improved from 2.1064 to 2.1063. Saving model...\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4796\n",
      "Epoch [1269/2000], Avg Train Loss: 3.4796\n",
      "Epoch [1269/2000], Avg Val Loss: 2.1061\n",
      "Validation loss improved from 2.1063 to 2.1061. Saving model...\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4487\n",
      "Epoch [1270/2000], Avg Train Loss: 3.4487\n",
      "Epoch [1270/2000], Avg Val Loss: 2.1059\n",
      "Validation loss improved from 2.1061 to 2.1059. Saving model...\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4658\n",
      "Epoch [1271/2000], Avg Train Loss: 3.4658\n",
      "Epoch [1271/2000], Avg Val Loss: 2.1058\n",
      "Validation loss improved from 2.1059 to 2.1058. Saving model...\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4342\n",
      "Epoch [1272/2000], Avg Train Loss: 3.4342\n",
      "Epoch [1272/2000], Avg Val Loss: 2.1056\n",
      "Validation loss improved from 2.1058 to 2.1056. Saving model...\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4555\n",
      "Epoch [1273/2000], Avg Train Loss: 3.4555\n",
      "Epoch [1273/2000], Avg Val Loss: 2.1054\n",
      "Validation loss improved from 2.1056 to 2.1054. Saving model...\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4572\n",
      "Epoch [1274/2000], Avg Train Loss: 3.4572\n",
      "Epoch [1274/2000], Avg Val Loss: 2.1052\n",
      "Validation loss improved from 2.1054 to 2.1052. Saving model...\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4763\n",
      "Epoch [1275/2000], Avg Train Loss: 3.4763\n",
      "Epoch [1275/2000], Avg Val Loss: 2.1051\n",
      "Validation loss improved from 2.1052 to 2.1051. Saving model...\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4463\n",
      "Epoch [1276/2000], Avg Train Loss: 3.4463\n",
      "Epoch [1276/2000], Avg Val Loss: 2.1050\n",
      "Validation loss improved from 2.1051 to 2.1050. Saving model...\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4523\n",
      "Epoch [1277/2000], Avg Train Loss: 3.4523\n",
      "Epoch [1277/2000], Avg Val Loss: 2.1049\n",
      "Validation loss improved from 2.1050 to 2.1049. Saving model...\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4683\n",
      "Epoch [1278/2000], Avg Train Loss: 3.4683\n",
      "Epoch [1278/2000], Avg Val Loss: 2.1049\n",
      "Validation loss improved from 2.1049 to 2.1049. Saving model...\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4513\n",
      "Epoch [1279/2000], Avg Train Loss: 3.4513\n",
      "Epoch [1279/2000], Avg Val Loss: 2.1048\n",
      "Validation loss improved from 2.1049 to 2.1048. Saving model...\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4940\n",
      "Epoch [1280/2000], Avg Train Loss: 3.4940\n",
      "Epoch [1280/2000], Avg Val Loss: 2.1046\n",
      "Validation loss improved from 2.1048 to 2.1046. Saving model...\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4495\n",
      "Epoch [1281/2000], Avg Train Loss: 3.4495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1281/2000], Avg Val Loss: 2.1044\n",
      "Validation loss improved from 2.1046 to 2.1044. Saving model...\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4466\n",
      "Epoch [1282/2000], Avg Train Loss: 3.4466\n",
      "Epoch [1282/2000], Avg Val Loss: 2.1042\n",
      "Validation loss improved from 2.1044 to 2.1042. Saving model...\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4551\n",
      "Epoch [1283/2000], Avg Train Loss: 3.4551\n",
      "Epoch [1283/2000], Avg Val Loss: 2.1040\n",
      "Validation loss improved from 2.1042 to 2.1040. Saving model...\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4685\n",
      "Epoch [1284/2000], Avg Train Loss: 3.4685\n",
      "Epoch [1284/2000], Avg Val Loss: 2.1038\n",
      "Validation loss improved from 2.1040 to 2.1038. Saving model...\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4437\n",
      "Epoch [1285/2000], Avg Train Loss: 3.4437\n",
      "Epoch [1285/2000], Avg Val Loss: 2.1036\n",
      "Validation loss improved from 2.1038 to 2.1036. Saving model...\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4485\n",
      "Epoch [1286/2000], Avg Train Loss: 3.4485\n",
      "Epoch [1286/2000], Avg Val Loss: 2.1033\n",
      "Validation loss improved from 2.1036 to 2.1033. Saving model...\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4888\n",
      "Epoch [1287/2000], Avg Train Loss: 3.4888\n",
      "Epoch [1287/2000], Avg Val Loss: 2.1032\n",
      "Validation loss improved from 2.1033 to 2.1032. Saving model...\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5013\n",
      "Epoch [1288/2000], Avg Train Loss: 3.5013\n",
      "Epoch [1288/2000], Avg Val Loss: 2.1030\n",
      "Validation loss improved from 2.1032 to 2.1030. Saving model...\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4171\n",
      "Epoch [1289/2000], Avg Train Loss: 3.4171\n",
      "Epoch [1289/2000], Avg Val Loss: 2.1029\n",
      "Validation loss improved from 2.1030 to 2.1029. Saving model...\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4812\n",
      "Epoch [1290/2000], Avg Train Loss: 3.4812\n",
      "Epoch [1290/2000], Avg Val Loss: 2.1029\n",
      "Validation loss improved from 2.1029 to 2.1029. Saving model...\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4991\n",
      "Epoch [1291/2000], Avg Train Loss: 3.4991\n",
      "Epoch [1291/2000], Avg Val Loss: 2.1029\n",
      "Validation loss improved from 2.1029 to 2.1029. Saving model...\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4404\n",
      "Epoch [1292/2000], Avg Train Loss: 3.4404\n",
      "Epoch [1292/2000], Avg Val Loss: 2.1028\n",
      "Validation loss improved from 2.1029 to 2.1028. Saving model...\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4147\n",
      "Epoch [1293/2000], Avg Train Loss: 3.4147\n",
      "Epoch [1293/2000], Avg Val Loss: 2.1028\n",
      "Validation loss improved from 2.1028 to 2.1028. Saving model...\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4286\n",
      "Epoch [1294/2000], Avg Train Loss: 3.4286\n",
      "Epoch [1294/2000], Avg Val Loss: 2.1029\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4480\n",
      "Epoch [1295/2000], Avg Train Loss: 3.4480\n",
      "Epoch [1295/2000], Avg Val Loss: 2.1029\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4531\n",
      "Epoch [1296/2000], Avg Train Loss: 3.4531\n",
      "Epoch [1296/2000], Avg Val Loss: 2.1028\n",
      "Validation loss improved from 2.1028 to 2.1028. Saving model...\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4526\n",
      "Epoch [1297/2000], Avg Train Loss: 3.4526\n",
      "Epoch [1297/2000], Avg Val Loss: 2.1028\n",
      "Validation loss improved from 2.1028 to 2.1028. Saving model...\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4648\n",
      "Epoch [1298/2000], Avg Train Loss: 3.4648\n",
      "Epoch [1298/2000], Avg Val Loss: 2.1026\n",
      "Validation loss improved from 2.1028 to 2.1026. Saving model...\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4531\n",
      "Epoch [1299/2000], Avg Train Loss: 3.4531\n",
      "Epoch [1299/2000], Avg Val Loss: 2.1024\n",
      "Validation loss improved from 2.1026 to 2.1024. Saving model...\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4353\n",
      "Epoch [1300/2000], Avg Train Loss: 3.4353\n",
      "Epoch [1300/2000], Avg Val Loss: 2.1021\n",
      "Validation loss improved from 2.1024 to 2.1021. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4267\n",
      "Epoch [1301/2000], Avg Train Loss: 3.4267\n",
      "Epoch [1301/2000], Avg Val Loss: 2.1019\n",
      "Validation loss improved from 2.1021 to 2.1019. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4613\n",
      "Epoch [1302/2000], Avg Train Loss: 3.4613\n",
      "Epoch [1302/2000], Avg Val Loss: 2.1017\n",
      "Validation loss improved from 2.1019 to 2.1017. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4368\n",
      "Epoch [1303/2000], Avg Train Loss: 3.4368\n",
      "Epoch [1303/2000], Avg Val Loss: 2.1015\n",
      "Validation loss improved from 2.1017 to 2.1015. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4635\n",
      "Epoch [1304/2000], Avg Train Loss: 3.4635\n",
      "Epoch [1304/2000], Avg Val Loss: 2.1015\n",
      "Validation loss improved from 2.1015 to 2.1015. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4660\n",
      "Epoch [1305/2000], Avg Train Loss: 3.4660\n",
      "Epoch [1305/2000], Avg Val Loss: 2.1014\n",
      "Validation loss improved from 2.1015 to 2.1014. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4495\n",
      "Epoch [1306/2000], Avg Train Loss: 3.4495\n",
      "Epoch [1306/2000], Avg Val Loss: 2.1014\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4426\n",
      "Epoch [1307/2000], Avg Train Loss: 3.4426\n",
      "Epoch [1307/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4373\n",
      "Epoch [1308/2000], Avg Train Loss: 3.4373\n",
      "Epoch [1308/2000], Avg Val Loss: 2.1016\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4351\n",
      "Epoch [1309/2000], Avg Train Loss: 3.4351\n",
      "Epoch [1309/2000], Avg Val Loss: 2.1017\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4177\n",
      "Epoch [1310/2000], Avg Train Loss: 3.4177\n",
      "Epoch [1310/2000], Avg Val Loss: 2.1018\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4654\n",
      "Epoch [1311/2000], Avg Train Loss: 3.4654\n",
      "Epoch [1311/2000], Avg Val Loss: 2.1018\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4580\n",
      "Epoch [1312/2000], Avg Train Loss: 3.4580\n",
      "Epoch [1312/2000], Avg Val Loss: 2.1018\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4835\n",
      "Epoch [1313/2000], Avg Train Loss: 3.4835\n",
      "Epoch [1313/2000], Avg Val Loss: 2.1017\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4752\n",
      "Epoch [1314/2000], Avg Train Loss: 3.4752\n",
      "Epoch [1314/2000], Avg Val Loss: 2.1016\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4354\n",
      "Epoch [1315/2000], Avg Train Loss: 3.4354\n",
      "Epoch [1315/2000], Avg Val Loss: 2.1016\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4383\n",
      "Epoch [1316/2000], Avg Train Loss: 3.4383\n",
      "Epoch [1316/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4306\n",
      "Epoch [1317/2000], Avg Train Loss: 3.4306\n",
      "Epoch [1317/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4322\n",
      "Epoch [1318/2000], Avg Train Loss: 3.4322\n",
      "Epoch [1318/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4208\n",
      "Epoch [1319/2000], Avg Train Loss: 3.4208\n",
      "Epoch [1319/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4170\n",
      "Epoch [1320/2000], Avg Train Loss: 3.4170\n",
      "Epoch [1320/2000], Avg Val Loss: 2.1014\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4391\n",
      "Epoch [1321/2000], Avg Train Loss: 3.4391\n",
      "Epoch [1321/2000], Avg Val Loss: 2.1014\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3964\n",
      "Epoch [1322/2000], Avg Train Loss: 3.3964\n",
      "Epoch [1322/2000], Avg Val Loss: 2.1014\n",
      "Validation loss improved from 2.1014 to 2.1014. Saving model...\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4251\n",
      "Epoch [1323/2000], Avg Train Loss: 3.4251\n",
      "Epoch [1323/2000], Avg Val Loss: 2.1014\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4568\n",
      "Epoch [1324/2000], Avg Train Loss: 3.4568\n",
      "Epoch [1324/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4681\n",
      "Epoch [1325/2000], Avg Train Loss: 3.4681\n",
      "Epoch [1325/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4248\n",
      "Epoch [1326/2000], Avg Train Loss: 3.4248\n",
      "Epoch [1326/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4469\n",
      "Epoch [1327/2000], Avg Train Loss: 3.4469\n",
      "Epoch [1327/2000], Avg Val Loss: 2.1015\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4290\n",
      "Epoch [1328/2000], Avg Train Loss: 3.4290\n",
      "Epoch [1328/2000], Avg Val Loss: 2.1014\n",
      "Validation loss improved from 2.1014 to 2.1014. Saving model...\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4413\n",
      "Epoch [1329/2000], Avg Train Loss: 3.4413\n",
      "Epoch [1329/2000], Avg Val Loss: 2.1014\n",
      "Validation loss improved from 2.1014 to 2.1014. Saving model...\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4340\n",
      "Epoch [1330/2000], Avg Train Loss: 3.4340\n",
      "Epoch [1330/2000], Avg Val Loss: 2.1013\n",
      "Validation loss improved from 2.1014 to 2.1013. Saving model...\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4779\n",
      "Epoch [1331/2000], Avg Train Loss: 3.4779\n",
      "Epoch [1331/2000], Avg Val Loss: 2.1012\n",
      "Validation loss improved from 2.1013 to 2.1012. Saving model...\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4425\n",
      "Epoch [1332/2000], Avg Train Loss: 3.4425\n",
      "Epoch [1332/2000], Avg Val Loss: 2.1011\n",
      "Validation loss improved from 2.1012 to 2.1011. Saving model...\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4332\n",
      "Epoch [1333/2000], Avg Train Loss: 3.4332\n",
      "Epoch [1333/2000], Avg Val Loss: 2.1010\n",
      "Validation loss improved from 2.1011 to 2.1010. Saving model...\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4454\n",
      "Epoch [1334/2000], Avg Train Loss: 3.4454\n",
      "Epoch [1334/2000], Avg Val Loss: 2.1009\n",
      "Validation loss improved from 2.1010 to 2.1009. Saving model...\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4544\n",
      "Epoch [1335/2000], Avg Train Loss: 3.4544\n",
      "Epoch [1335/2000], Avg Val Loss: 2.1006\n",
      "Validation loss improved from 2.1009 to 2.1006. Saving model...\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4452\n",
      "Epoch [1336/2000], Avg Train Loss: 3.4452\n",
      "Epoch [1336/2000], Avg Val Loss: 2.1004\n",
      "Validation loss improved from 2.1006 to 2.1004. Saving model...\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4596\n",
      "Epoch [1337/2000], Avg Train Loss: 3.4596\n",
      "Epoch [1337/2000], Avg Val Loss: 2.1001\n",
      "Validation loss improved from 2.1004 to 2.1001. Saving model...\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4374\n",
      "Epoch [1338/2000], Avg Train Loss: 3.4374\n",
      "Epoch [1338/2000], Avg Val Loss: 2.0998\n",
      "Validation loss improved from 2.1001 to 2.0998. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4773\n",
      "Epoch [1339/2000], Avg Train Loss: 3.4773\n",
      "Epoch [1339/2000], Avg Val Loss: 2.0995\n",
      "Validation loss improved from 2.0998 to 2.0995. Saving model...\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4328\n",
      "Epoch [1340/2000], Avg Train Loss: 3.4328\n",
      "Epoch [1340/2000], Avg Val Loss: 2.0993\n",
      "Validation loss improved from 2.0995 to 2.0993. Saving model...\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4288\n",
      "Epoch [1341/2000], Avg Train Loss: 3.4288\n",
      "Epoch [1341/2000], Avg Val Loss: 2.0990\n",
      "Validation loss improved from 2.0993 to 2.0990. Saving model...\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4239\n",
      "Epoch [1342/2000], Avg Train Loss: 3.4239\n",
      "Epoch [1342/2000], Avg Val Loss: 2.0987\n",
      "Validation loss improved from 2.0990 to 2.0987. Saving model...\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4269\n",
      "Epoch [1343/2000], Avg Train Loss: 3.4269\n",
      "Epoch [1343/2000], Avg Val Loss: 2.0984\n",
      "Validation loss improved from 2.0987 to 2.0984. Saving model...\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4607\n",
      "Epoch [1344/2000], Avg Train Loss: 3.4607\n",
      "Epoch [1344/2000], Avg Val Loss: 2.0982\n",
      "Validation loss improved from 2.0984 to 2.0982. Saving model...\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4503\n",
      "Epoch [1345/2000], Avg Train Loss: 3.4503\n",
      "Epoch [1345/2000], Avg Val Loss: 2.0979\n",
      "Validation loss improved from 2.0982 to 2.0979. Saving model...\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4583\n",
      "Epoch [1346/2000], Avg Train Loss: 3.4583\n",
      "Epoch [1346/2000], Avg Val Loss: 2.0976\n",
      "Validation loss improved from 2.0979 to 2.0976. Saving model...\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4345\n",
      "Epoch [1347/2000], Avg Train Loss: 3.4345\n",
      "Epoch [1347/2000], Avg Val Loss: 2.0973\n",
      "Validation loss improved from 2.0976 to 2.0973. Saving model...\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4349\n",
      "Epoch [1348/2000], Avg Train Loss: 3.4349\n",
      "Epoch [1348/2000], Avg Val Loss: 2.0969\n",
      "Validation loss improved from 2.0973 to 2.0969. Saving model...\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4043\n",
      "Epoch [1349/2000], Avg Train Loss: 3.4043\n",
      "Epoch [1349/2000], Avg Val Loss: 2.0966\n",
      "Validation loss improved from 2.0969 to 2.0966. Saving model...\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4398\n",
      "Epoch [1350/2000], Avg Train Loss: 3.4398\n",
      "Epoch [1350/2000], Avg Val Loss: 2.0963\n",
      "Validation loss improved from 2.0966 to 2.0963. Saving model...\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4349\n",
      "Epoch [1351/2000], Avg Train Loss: 3.4349\n",
      "Epoch [1351/2000], Avg Val Loss: 2.0960\n",
      "Validation loss improved from 2.0963 to 2.0960. Saving model...\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4416\n",
      "Epoch [1352/2000], Avg Train Loss: 3.4416\n",
      "Epoch [1352/2000], Avg Val Loss: 2.0957\n",
      "Validation loss improved from 2.0960 to 2.0957. Saving model...\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4490\n",
      "Epoch [1353/2000], Avg Train Loss: 3.4490\n",
      "Epoch [1353/2000], Avg Val Loss: 2.0954\n",
      "Validation loss improved from 2.0957 to 2.0954. Saving model...\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4517\n",
      "Epoch [1354/2000], Avg Train Loss: 3.4517\n",
      "Epoch [1354/2000], Avg Val Loss: 2.0952\n",
      "Validation loss improved from 2.0954 to 2.0952. Saving model...\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4526\n",
      "Epoch [1355/2000], Avg Train Loss: 3.4526\n",
      "Epoch [1355/2000], Avg Val Loss: 2.0950\n",
      "Validation loss improved from 2.0952 to 2.0950. Saving model...\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4496\n",
      "Epoch [1356/2000], Avg Train Loss: 3.4496\n",
      "Epoch [1356/2000], Avg Val Loss: 2.0948\n",
      "Validation loss improved from 2.0950 to 2.0948. Saving model...\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4084\n",
      "Epoch [1357/2000], Avg Train Loss: 3.4084\n",
      "Epoch [1357/2000], Avg Val Loss: 2.0945\n",
      "Validation loss improved from 2.0948 to 2.0945. Saving model...\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4464\n",
      "Epoch [1358/2000], Avg Train Loss: 3.4464\n",
      "Epoch [1358/2000], Avg Val Loss: 2.0943\n",
      "Validation loss improved from 2.0945 to 2.0943. Saving model...\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4875\n",
      "Epoch [1359/2000], Avg Train Loss: 3.4875\n",
      "Epoch [1359/2000], Avg Val Loss: 2.0941\n",
      "Validation loss improved from 2.0943 to 2.0941. Saving model...\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4515\n",
      "Epoch [1360/2000], Avg Train Loss: 3.4515\n",
      "Epoch [1360/2000], Avg Val Loss: 2.0939\n",
      "Validation loss improved from 2.0941 to 2.0939. Saving model...\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4263\n",
      "Epoch [1361/2000], Avg Train Loss: 3.4263\n",
      "Epoch [1361/2000], Avg Val Loss: 2.0937\n",
      "Validation loss improved from 2.0939 to 2.0937. Saving model...\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4585\n",
      "Epoch [1362/2000], Avg Train Loss: 3.4585\n",
      "Epoch [1362/2000], Avg Val Loss: 2.0934\n",
      "Validation loss improved from 2.0937 to 2.0934. Saving model...\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4337\n",
      "Epoch [1363/2000], Avg Train Loss: 3.4337\n",
      "Epoch [1363/2000], Avg Val Loss: 2.0932\n",
      "Validation loss improved from 2.0934 to 2.0932. Saving model...\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4341\n",
      "Epoch [1364/2000], Avg Train Loss: 3.4341\n",
      "Epoch [1364/2000], Avg Val Loss: 2.0930\n",
      "Validation loss improved from 2.0932 to 2.0930. Saving model...\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4464\n",
      "Epoch [1365/2000], Avg Train Loss: 3.4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1365/2000], Avg Val Loss: 2.0927\n",
      "Validation loss improved from 2.0930 to 2.0927. Saving model...\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4152\n",
      "Epoch [1366/2000], Avg Train Loss: 3.4152\n",
      "Epoch [1366/2000], Avg Val Loss: 2.0924\n",
      "Validation loss improved from 2.0927 to 2.0924. Saving model...\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4158\n",
      "Epoch [1367/2000], Avg Train Loss: 3.4158\n",
      "Epoch [1367/2000], Avg Val Loss: 2.0922\n",
      "Validation loss improved from 2.0924 to 2.0922. Saving model...\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4027\n",
      "Epoch [1368/2000], Avg Train Loss: 3.4027\n",
      "Epoch [1368/2000], Avg Val Loss: 2.0920\n",
      "Validation loss improved from 2.0922 to 2.0920. Saving model...\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4595\n",
      "Epoch [1369/2000], Avg Train Loss: 3.4595\n",
      "Epoch [1369/2000], Avg Val Loss: 2.0917\n",
      "Validation loss improved from 2.0920 to 2.0917. Saving model...\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4429\n",
      "Epoch [1370/2000], Avg Train Loss: 3.4429\n",
      "Epoch [1370/2000], Avg Val Loss: 2.0914\n",
      "Validation loss improved from 2.0917 to 2.0914. Saving model...\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4057\n",
      "Epoch [1371/2000], Avg Train Loss: 3.4057\n",
      "Epoch [1371/2000], Avg Val Loss: 2.0912\n",
      "Validation loss improved from 2.0914 to 2.0912. Saving model...\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4527\n",
      "Epoch [1372/2000], Avg Train Loss: 3.4527\n",
      "Epoch [1372/2000], Avg Val Loss: 2.0910\n",
      "Validation loss improved from 2.0912 to 2.0910. Saving model...\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4477\n",
      "Epoch [1373/2000], Avg Train Loss: 3.4477\n",
      "Epoch [1373/2000], Avg Val Loss: 2.0909\n",
      "Validation loss improved from 2.0910 to 2.0909. Saving model...\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4139\n",
      "Epoch [1374/2000], Avg Train Loss: 3.4139\n",
      "Epoch [1374/2000], Avg Val Loss: 2.0908\n",
      "Validation loss improved from 2.0909 to 2.0908. Saving model...\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4380\n",
      "Epoch [1375/2000], Avg Train Loss: 3.4380\n",
      "Epoch [1375/2000], Avg Val Loss: 2.0907\n",
      "Validation loss improved from 2.0908 to 2.0907. Saving model...\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4141\n",
      "Epoch [1376/2000], Avg Train Loss: 3.4141\n",
      "Epoch [1376/2000], Avg Val Loss: 2.0906\n",
      "Validation loss improved from 2.0907 to 2.0906. Saving model...\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4305\n",
      "Epoch [1377/2000], Avg Train Loss: 3.4305\n",
      "Epoch [1377/2000], Avg Val Loss: 2.0906\n",
      "Validation loss improved from 2.0906 to 2.0906. Saving model...\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4442\n",
      "Epoch [1378/2000], Avg Train Loss: 3.4442\n",
      "Epoch [1378/2000], Avg Val Loss: 2.0905\n",
      "Validation loss improved from 2.0906 to 2.0905. Saving model...\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4405\n",
      "Epoch [1379/2000], Avg Train Loss: 3.4405\n",
      "Epoch [1379/2000], Avg Val Loss: 2.0904\n",
      "Validation loss improved from 2.0905 to 2.0904. Saving model...\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4119\n",
      "Epoch [1380/2000], Avg Train Loss: 3.4119\n",
      "Epoch [1380/2000], Avg Val Loss: 2.0905\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4305\n",
      "Epoch [1381/2000], Avg Train Loss: 3.4305\n",
      "Epoch [1381/2000], Avg Val Loss: 2.0906\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4193\n",
      "Epoch [1382/2000], Avg Train Loss: 3.4193\n",
      "Epoch [1382/2000], Avg Val Loss: 2.0908\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4228\n",
      "Epoch [1383/2000], Avg Train Loss: 3.4228\n",
      "Epoch [1383/2000], Avg Val Loss: 2.0909\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4364\n",
      "Epoch [1384/2000], Avg Train Loss: 3.4364\n",
      "Epoch [1384/2000], Avg Val Loss: 2.0910\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4501\n",
      "Epoch [1385/2000], Avg Train Loss: 3.4501\n",
      "Epoch [1385/2000], Avg Val Loss: 2.0911\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4365\n",
      "Epoch [1386/2000], Avg Train Loss: 3.4365\n",
      "Epoch [1386/2000], Avg Val Loss: 2.0912\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4501\n",
      "Epoch [1387/2000], Avg Train Loss: 3.4501\n",
      "Epoch [1387/2000], Avg Val Loss: 2.0912\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4292\n",
      "Epoch [1388/2000], Avg Train Loss: 3.4292\n",
      "Epoch [1388/2000], Avg Val Loss: 2.0912\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4610\n",
      "Epoch [1389/2000], Avg Train Loss: 3.4610\n",
      "Epoch [1389/2000], Avg Val Loss: 2.0912\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4555\n",
      "Epoch [1390/2000], Avg Train Loss: 3.4555\n",
      "Epoch [1390/2000], Avg Val Loss: 2.0912\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4370\n",
      "Epoch [1391/2000], Avg Train Loss: 3.4370\n",
      "Epoch [1391/2000], Avg Val Loss: 2.0912\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4156\n",
      "Epoch [1392/2000], Avg Train Loss: 3.4156\n",
      "Epoch [1392/2000], Avg Val Loss: 2.0911\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4352\n",
      "Epoch [1393/2000], Avg Train Loss: 3.4352\n",
      "Epoch [1393/2000], Avg Val Loss: 2.0911\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4506\n",
      "Epoch [1394/2000], Avg Train Loss: 3.4506\n",
      "Epoch [1394/2000], Avg Val Loss: 2.0911\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4115\n",
      "Epoch [1395/2000], Avg Train Loss: 3.4115\n",
      "Epoch [1395/2000], Avg Val Loss: 2.0910\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4171\n",
      "Epoch [1396/2000], Avg Train Loss: 3.4171\n",
      "Epoch [1396/2000], Avg Val Loss: 2.0910\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4470\n",
      "Epoch [1397/2000], Avg Train Loss: 3.4470\n",
      "Epoch [1397/2000], Avg Val Loss: 2.0909\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4156\n",
      "Epoch [1398/2000], Avg Train Loss: 3.4156\n",
      "Epoch [1398/2000], Avg Val Loss: 2.0908\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4278\n",
      "Epoch [1399/2000], Avg Train Loss: 3.4278\n",
      "Epoch [1399/2000], Avg Val Loss: 2.0907\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4365\n",
      "Epoch [1400/2000], Avg Train Loss: 3.4365\n",
      "Epoch [1400/2000], Avg Val Loss: 2.0905\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4002\n",
      "Epoch [1401/2000], Avg Train Loss: 3.4002\n",
      "Epoch [1401/2000], Avg Val Loss: 2.0903\n",
      "Validation loss improved from 2.0904 to 2.0903. Saving model...\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4485\n",
      "Epoch [1402/2000], Avg Train Loss: 3.4485\n",
      "Epoch [1402/2000], Avg Val Loss: 2.0900\n",
      "Validation loss improved from 2.0903 to 2.0900. Saving model...\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4402\n",
      "Epoch [1403/2000], Avg Train Loss: 3.4402\n",
      "Epoch [1403/2000], Avg Val Loss: 2.0897\n",
      "Validation loss improved from 2.0900 to 2.0897. Saving model...\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3988\n",
      "Epoch [1404/2000], Avg Train Loss: 3.3988\n",
      "Epoch [1404/2000], Avg Val Loss: 2.0894\n",
      "Validation loss improved from 2.0897 to 2.0894. Saving model...\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4417\n",
      "Epoch [1405/2000], Avg Train Loss: 3.4417\n",
      "Epoch [1405/2000], Avg Val Loss: 2.0891\n",
      "Validation loss improved from 2.0894 to 2.0891. Saving model...\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4217\n",
      "Epoch [1406/2000], Avg Train Loss: 3.4217\n",
      "Epoch [1406/2000], Avg Val Loss: 2.0889\n",
      "Validation loss improved from 2.0891 to 2.0889. Saving model...\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4109\n",
      "Epoch [1407/2000], Avg Train Loss: 3.4109\n",
      "Epoch [1407/2000], Avg Val Loss: 2.0888\n",
      "Validation loss improved from 2.0889 to 2.0888. Saving model...\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4224\n",
      "Epoch [1408/2000], Avg Train Loss: 3.4224\n",
      "Epoch [1408/2000], Avg Val Loss: 2.0886\n",
      "Validation loss improved from 2.0888 to 2.0886. Saving model...\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3991\n",
      "Epoch [1409/2000], Avg Train Loss: 3.3991\n",
      "Epoch [1409/2000], Avg Val Loss: 2.0885\n",
      "Validation loss improved from 2.0886 to 2.0885. Saving model...\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4414\n",
      "Epoch [1410/2000], Avg Train Loss: 3.4414\n",
      "Epoch [1410/2000], Avg Val Loss: 2.0883\n",
      "Validation loss improved from 2.0885 to 2.0883. Saving model...\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4043\n",
      "Epoch [1411/2000], Avg Train Loss: 3.4043\n",
      "Epoch [1411/2000], Avg Val Loss: 2.0882\n",
      "Validation loss improved from 2.0883 to 2.0882. Saving model...\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4379\n",
      "Epoch [1412/2000], Avg Train Loss: 3.4379\n",
      "Epoch [1412/2000], Avg Val Loss: 2.0879\n",
      "Validation loss improved from 2.0882 to 2.0879. Saving model...\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4127\n",
      "Epoch [1413/2000], Avg Train Loss: 3.4127\n",
      "Epoch [1413/2000], Avg Val Loss: 2.0879\n",
      "Validation loss improved from 2.0879 to 2.0879. Saving model...\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4084\n",
      "Epoch [1414/2000], Avg Train Loss: 3.4084\n",
      "Epoch [1414/2000], Avg Val Loss: 2.0878\n",
      "Validation loss improved from 2.0879 to 2.0878. Saving model...\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4284\n",
      "Epoch [1415/2000], Avg Train Loss: 3.4284\n",
      "Epoch [1415/2000], Avg Val Loss: 2.0877\n",
      "Validation loss improved from 2.0878 to 2.0877. Saving model...\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4332\n",
      "Epoch [1416/2000], Avg Train Loss: 3.4332\n",
      "Epoch [1416/2000], Avg Val Loss: 2.0876\n",
      "Validation loss improved from 2.0877 to 2.0876. Saving model...\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4359\n",
      "Epoch [1417/2000], Avg Train Loss: 3.4359\n",
      "Epoch [1417/2000], Avg Val Loss: 2.0875\n",
      "Validation loss improved from 2.0876 to 2.0875. Saving model...\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4509\n",
      "Epoch [1418/2000], Avg Train Loss: 3.4509\n",
      "Epoch [1418/2000], Avg Val Loss: 2.0874\n",
      "Validation loss improved from 2.0875 to 2.0874. Saving model...\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4387\n",
      "Epoch [1419/2000], Avg Train Loss: 3.4387\n",
      "Epoch [1419/2000], Avg Val Loss: 2.0874\n",
      "Validation loss improved from 2.0874 to 2.0874. Saving model...\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3889\n",
      "Epoch [1420/2000], Avg Train Loss: 3.3889\n",
      "Epoch [1420/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4323\n",
      "Epoch [1421/2000], Avg Train Loss: 3.4323\n",
      "Epoch [1421/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4144\n",
      "Epoch [1422/2000], Avg Train Loss: 3.4144\n",
      "Epoch [1422/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4093\n",
      "Epoch [1423/2000], Avg Train Loss: 3.4093\n",
      "Epoch [1423/2000], Avg Val Loss: 2.0874\n",
      "Validation loss improved from 2.0874 to 2.0874. Saving model...\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4312\n",
      "Epoch [1424/2000], Avg Train Loss: 3.4312\n",
      "Epoch [1424/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4436\n",
      "Epoch [1425/2000], Avg Train Loss: 3.4436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1425/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4081\n",
      "Epoch [1426/2000], Avg Train Loss: 3.4081\n",
      "Epoch [1426/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3956\n",
      "Epoch [1427/2000], Avg Train Loss: 3.3956\n",
      "Epoch [1427/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4064\n",
      "Epoch [1428/2000], Avg Train Loss: 3.4064\n",
      "Epoch [1428/2000], Avg Val Loss: 2.0875\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4451\n",
      "Epoch [1429/2000], Avg Train Loss: 3.4451\n",
      "Epoch [1429/2000], Avg Val Loss: 2.0876\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4359\n",
      "Epoch [1430/2000], Avg Train Loss: 3.4359\n",
      "Epoch [1430/2000], Avg Val Loss: 2.0876\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4270\n",
      "Epoch [1431/2000], Avg Train Loss: 3.4270\n",
      "Epoch [1431/2000], Avg Val Loss: 2.0875\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3966\n",
      "Epoch [1432/2000], Avg Train Loss: 3.3966\n",
      "Epoch [1432/2000], Avg Val Loss: 2.0874\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4143\n",
      "Epoch [1433/2000], Avg Train Loss: 3.4143\n",
      "Epoch [1433/2000], Avg Val Loss: 2.0873\n",
      "Validation loss improved from 2.0874 to 2.0873. Saving model...\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4197\n",
      "Epoch [1434/2000], Avg Train Loss: 3.4197\n",
      "Epoch [1434/2000], Avg Val Loss: 2.0871\n",
      "Validation loss improved from 2.0873 to 2.0871. Saving model...\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4288\n",
      "Epoch [1435/2000], Avg Train Loss: 3.4288\n",
      "Epoch [1435/2000], Avg Val Loss: 2.0869\n",
      "Validation loss improved from 2.0871 to 2.0869. Saving model...\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4118\n",
      "Epoch [1436/2000], Avg Train Loss: 3.4118\n",
      "Epoch [1436/2000], Avg Val Loss: 2.0867\n",
      "Validation loss improved from 2.0869 to 2.0867. Saving model...\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3868\n",
      "Epoch [1437/2000], Avg Train Loss: 3.3868\n",
      "Epoch [1437/2000], Avg Val Loss: 2.0865\n",
      "Validation loss improved from 2.0867 to 2.0865. Saving model...\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4040\n",
      "Epoch [1438/2000], Avg Train Loss: 3.4040\n",
      "Epoch [1438/2000], Avg Val Loss: 2.0863\n",
      "Validation loss improved from 2.0865 to 2.0863. Saving model...\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4119\n",
      "Epoch [1439/2000], Avg Train Loss: 3.4119\n",
      "Epoch [1439/2000], Avg Val Loss: 2.0862\n",
      "Validation loss improved from 2.0863 to 2.0862. Saving model...\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4083\n",
      "Epoch [1440/2000], Avg Train Loss: 3.4083\n",
      "Epoch [1440/2000], Avg Val Loss: 2.0861\n",
      "Validation loss improved from 2.0862 to 2.0861. Saving model...\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3871\n",
      "Epoch [1441/2000], Avg Train Loss: 3.3871\n",
      "Epoch [1441/2000], Avg Val Loss: 2.0860\n",
      "Validation loss improved from 2.0861 to 2.0860. Saving model...\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4074\n",
      "Epoch [1442/2000], Avg Train Loss: 3.4074\n",
      "Epoch [1442/2000], Avg Val Loss: 2.0858\n",
      "Validation loss improved from 2.0860 to 2.0858. Saving model...\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4091\n",
      "Epoch [1443/2000], Avg Train Loss: 3.4091\n",
      "Epoch [1443/2000], Avg Val Loss: 2.0857\n",
      "Validation loss improved from 2.0858 to 2.0857. Saving model...\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4186\n",
      "Epoch [1444/2000], Avg Train Loss: 3.4186\n",
      "Epoch [1444/2000], Avg Val Loss: 2.0856\n",
      "Validation loss improved from 2.0857 to 2.0856. Saving model...\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4281\n",
      "Epoch [1445/2000], Avg Train Loss: 3.4281\n",
      "Epoch [1445/2000], Avg Val Loss: 2.0854\n",
      "Validation loss improved from 2.0856 to 2.0854. Saving model...\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4017\n",
      "Epoch [1446/2000], Avg Train Loss: 3.4017\n",
      "Epoch [1446/2000], Avg Val Loss: 2.0852\n",
      "Validation loss improved from 2.0854 to 2.0852. Saving model...\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4110\n",
      "Epoch [1447/2000], Avg Train Loss: 3.4110\n",
      "Epoch [1447/2000], Avg Val Loss: 2.0851\n",
      "Validation loss improved from 2.0852 to 2.0851. Saving model...\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4179\n",
      "Epoch [1448/2000], Avg Train Loss: 3.4179\n",
      "Epoch [1448/2000], Avg Val Loss: 2.0850\n",
      "Validation loss improved from 2.0851 to 2.0850. Saving model...\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4505\n",
      "Epoch [1449/2000], Avg Train Loss: 3.4505\n",
      "Epoch [1449/2000], Avg Val Loss: 2.0849\n",
      "Validation loss improved from 2.0850 to 2.0849. Saving model...\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4470\n",
      "Epoch [1450/2000], Avg Train Loss: 3.4470\n",
      "Epoch [1450/2000], Avg Val Loss: 2.0848\n",
      "Validation loss improved from 2.0849 to 2.0848. Saving model...\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4401\n",
      "Epoch [1451/2000], Avg Train Loss: 3.4401\n",
      "Epoch [1451/2000], Avg Val Loss: 2.0847\n",
      "Validation loss improved from 2.0848 to 2.0847. Saving model...\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4036\n",
      "Epoch [1452/2000], Avg Train Loss: 3.4036\n",
      "Epoch [1452/2000], Avg Val Loss: 2.0848\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4075\n",
      "Epoch [1453/2000], Avg Train Loss: 3.4075\n",
      "Epoch [1453/2000], Avg Val Loss: 2.0848\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4082\n",
      "Epoch [1454/2000], Avg Train Loss: 3.4082\n",
      "Epoch [1454/2000], Avg Val Loss: 2.0849\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4224\n",
      "Epoch [1455/2000], Avg Train Loss: 3.4224\n",
      "Epoch [1455/2000], Avg Val Loss: 2.0849\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3957\n",
      "Epoch [1456/2000], Avg Train Loss: 3.3957\n",
      "Epoch [1456/2000], Avg Val Loss: 2.0849\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3911\n",
      "Epoch [1457/2000], Avg Train Loss: 3.3911\n",
      "Epoch [1457/2000], Avg Val Loss: 2.0849\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4317\n",
      "Epoch [1458/2000], Avg Train Loss: 3.4317\n",
      "Epoch [1458/2000], Avg Val Loss: 2.0849\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4347\n",
      "Epoch [1459/2000], Avg Train Loss: 3.4347\n",
      "Epoch [1459/2000], Avg Val Loss: 2.0850\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3825\n",
      "Epoch [1460/2000], Avg Train Loss: 3.3825\n",
      "Epoch [1460/2000], Avg Val Loss: 2.0851\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4135\n",
      "Epoch [1461/2000], Avg Train Loss: 3.4135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1461/2000], Avg Val Loss: 2.0851\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4289\n",
      "Epoch [1462/2000], Avg Train Loss: 3.4289\n",
      "Epoch [1462/2000], Avg Val Loss: 2.0851\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3933\n",
      "Epoch [1463/2000], Avg Train Loss: 3.3933\n",
      "Epoch [1463/2000], Avg Val Loss: 2.0850\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3908\n",
      "Epoch [1464/2000], Avg Train Loss: 3.3908\n",
      "Epoch [1464/2000], Avg Val Loss: 2.0850\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4499\n",
      "Epoch [1465/2000], Avg Train Loss: 3.4499\n",
      "Epoch [1465/2000], Avg Val Loss: 2.0849\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4028\n",
      "Epoch [1466/2000], Avg Train Loss: 3.4028\n",
      "Epoch [1466/2000], Avg Val Loss: 2.0848\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4365\n",
      "Epoch [1467/2000], Avg Train Loss: 3.4365\n",
      "Epoch [1467/2000], Avg Val Loss: 2.0846\n",
      "Validation loss improved from 2.0847 to 2.0846. Saving model...\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3926\n",
      "Epoch [1468/2000], Avg Train Loss: 3.3926\n",
      "Epoch [1468/2000], Avg Val Loss: 2.0846\n",
      "Validation loss improved from 2.0846 to 2.0846. Saving model...\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4319\n",
      "Epoch [1469/2000], Avg Train Loss: 3.4319\n",
      "Epoch [1469/2000], Avg Val Loss: 2.0844\n",
      "Validation loss improved from 2.0846 to 2.0844. Saving model...\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3954\n",
      "Epoch [1470/2000], Avg Train Loss: 3.3954\n",
      "Epoch [1470/2000], Avg Val Loss: 2.0844\n",
      "Validation loss improved from 2.0844 to 2.0844. Saving model...\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4202\n",
      "Epoch [1471/2000], Avg Train Loss: 3.4202\n",
      "Epoch [1471/2000], Avg Val Loss: 2.0843\n",
      "Validation loss improved from 2.0844 to 2.0843. Saving model...\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4265\n",
      "Epoch [1472/2000], Avg Train Loss: 3.4265\n",
      "Epoch [1472/2000], Avg Val Loss: 2.0842\n",
      "Validation loss improved from 2.0843 to 2.0842. Saving model...\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4272\n",
      "Epoch [1473/2000], Avg Train Loss: 3.4272\n",
      "Epoch [1473/2000], Avg Val Loss: 2.0841\n",
      "Validation loss improved from 2.0842 to 2.0841. Saving model...\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4049\n",
      "Epoch [1474/2000], Avg Train Loss: 3.4049\n",
      "Epoch [1474/2000], Avg Val Loss: 2.0840\n",
      "Validation loss improved from 2.0841 to 2.0840. Saving model...\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4119\n",
      "Epoch [1475/2000], Avg Train Loss: 3.4119\n",
      "Epoch [1475/2000], Avg Val Loss: 2.0840\n",
      "Validation loss improved from 2.0840 to 2.0840. Saving model...\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3826\n",
      "Epoch [1476/2000], Avg Train Loss: 3.3826\n",
      "Epoch [1476/2000], Avg Val Loss: 2.0841\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3922\n",
      "Epoch [1477/2000], Avg Train Loss: 3.3922\n",
      "Epoch [1477/2000], Avg Val Loss: 2.0841\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3899\n",
      "Epoch [1478/2000], Avg Train Loss: 3.3899\n",
      "Epoch [1478/2000], Avg Val Loss: 2.0841\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4341\n",
      "Epoch [1479/2000], Avg Train Loss: 3.4341\n",
      "Epoch [1479/2000], Avg Val Loss: 2.0841\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4035\n",
      "Epoch [1480/2000], Avg Train Loss: 3.4035\n",
      "Epoch [1480/2000], Avg Val Loss: 2.0840\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4126\n",
      "Epoch [1481/2000], Avg Train Loss: 3.4126\n",
      "Epoch [1481/2000], Avg Val Loss: 2.0840\n",
      "Validation loss improved from 2.0840 to 2.0840. Saving model...\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4123\n",
      "Epoch [1482/2000], Avg Train Loss: 3.4123\n",
      "Epoch [1482/2000], Avg Val Loss: 2.0839\n",
      "Validation loss improved from 2.0840 to 2.0839. Saving model...\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4113\n",
      "Epoch [1483/2000], Avg Train Loss: 3.4113\n",
      "Epoch [1483/2000], Avg Val Loss: 2.0837\n",
      "Validation loss improved from 2.0839 to 2.0837. Saving model...\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4121\n",
      "Epoch [1484/2000], Avg Train Loss: 3.4121\n",
      "Epoch [1484/2000], Avg Val Loss: 2.0836\n",
      "Validation loss improved from 2.0837 to 2.0836. Saving model...\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4440\n",
      "Epoch [1485/2000], Avg Train Loss: 3.4440\n",
      "Epoch [1485/2000], Avg Val Loss: 2.0833\n",
      "Validation loss improved from 2.0836 to 2.0833. Saving model...\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4314\n",
      "Epoch [1486/2000], Avg Train Loss: 3.4314\n",
      "Epoch [1486/2000], Avg Val Loss: 2.0830\n",
      "Validation loss improved from 2.0833 to 2.0830. Saving model...\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4434\n",
      "Epoch [1487/2000], Avg Train Loss: 3.4434\n",
      "Epoch [1487/2000], Avg Val Loss: 2.0829\n",
      "Validation loss improved from 2.0830 to 2.0829. Saving model...\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3723\n",
      "Epoch [1488/2000], Avg Train Loss: 3.3723\n",
      "Epoch [1488/2000], Avg Val Loss: 2.0827\n",
      "Validation loss improved from 2.0829 to 2.0827. Saving model...\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4008\n",
      "Epoch [1489/2000], Avg Train Loss: 3.4008\n",
      "Epoch [1489/2000], Avg Val Loss: 2.0825\n",
      "Validation loss improved from 2.0827 to 2.0825. Saving model...\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4380\n",
      "Epoch [1490/2000], Avg Train Loss: 3.4380\n",
      "Epoch [1490/2000], Avg Val Loss: 2.0823\n",
      "Validation loss improved from 2.0825 to 2.0823. Saving model...\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4094\n",
      "Epoch [1491/2000], Avg Train Loss: 3.4094\n",
      "Epoch [1491/2000], Avg Val Loss: 2.0822\n",
      "Validation loss improved from 2.0823 to 2.0822. Saving model...\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4357\n",
      "Epoch [1492/2000], Avg Train Loss: 3.4357\n",
      "Epoch [1492/2000], Avg Val Loss: 2.0821\n",
      "Validation loss improved from 2.0822 to 2.0821. Saving model...\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4165\n",
      "Epoch [1493/2000], Avg Train Loss: 3.4165\n",
      "Epoch [1493/2000], Avg Val Loss: 2.0819\n",
      "Validation loss improved from 2.0821 to 2.0819. Saving model...\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3956\n",
      "Epoch [1494/2000], Avg Train Loss: 3.3956\n",
      "Epoch [1494/2000], Avg Val Loss: 2.0819\n",
      "Validation loss improved from 2.0819 to 2.0819. Saving model...\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3804\n",
      "Epoch [1495/2000], Avg Train Loss: 3.3804\n",
      "Epoch [1495/2000], Avg Val Loss: 2.0819\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4098\n",
      "Epoch [1496/2000], Avg Train Loss: 3.4098\n",
      "Epoch [1496/2000], Avg Val Loss: 2.0820\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4133\n",
      "Epoch [1497/2000], Avg Train Loss: 3.4133\n",
      "Epoch [1497/2000], Avg Val Loss: 2.0820\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4343\n",
      "Epoch [1498/2000], Avg Train Loss: 3.4343\n",
      "Epoch [1498/2000], Avg Val Loss: 2.0819\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4052\n",
      "Epoch [1499/2000], Avg Train Loss: 3.4052\n",
      "Epoch [1499/2000], Avg Val Loss: 2.0818\n",
      "Validation loss improved from 2.0819 to 2.0818. Saving model...\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4032\n",
      "Epoch [1500/2000], Avg Train Loss: 3.4032\n",
      "Epoch [1500/2000], Avg Val Loss: 2.0816\n",
      "Validation loss improved from 2.0818 to 2.0816. Saving model...\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4388\n",
      "Epoch [1501/2000], Avg Train Loss: 3.4388\n",
      "Epoch [1501/2000], Avg Val Loss: 2.0813\n",
      "Validation loss improved from 2.0816 to 2.0813. Saving model...\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4179\n",
      "Epoch [1502/2000], Avg Train Loss: 3.4179\n",
      "Epoch [1502/2000], Avg Val Loss: 2.0810\n",
      "Validation loss improved from 2.0813 to 2.0810. Saving model...\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4054\n",
      "Epoch [1503/2000], Avg Train Loss: 3.4054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1503/2000], Avg Val Loss: 2.0808\n",
      "Validation loss improved from 2.0810 to 2.0808. Saving model...\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4025\n",
      "Epoch [1504/2000], Avg Train Loss: 3.4025\n",
      "Epoch [1504/2000], Avg Val Loss: 2.0805\n",
      "Validation loss improved from 2.0808 to 2.0805. Saving model...\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3780\n",
      "Epoch [1505/2000], Avg Train Loss: 3.3780\n",
      "Epoch [1505/2000], Avg Val Loss: 2.0803\n",
      "Validation loss improved from 2.0805 to 2.0803. Saving model...\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4049\n",
      "Epoch [1506/2000], Avg Train Loss: 3.4049\n",
      "Epoch [1506/2000], Avg Val Loss: 2.0801\n",
      "Validation loss improved from 2.0803 to 2.0801. Saving model...\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4128\n",
      "Epoch [1507/2000], Avg Train Loss: 3.4128\n",
      "Epoch [1507/2000], Avg Val Loss: 2.0799\n",
      "Validation loss improved from 2.0801 to 2.0799. Saving model...\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4386\n",
      "Epoch [1508/2000], Avg Train Loss: 3.4386\n",
      "Epoch [1508/2000], Avg Val Loss: 2.0799\n",
      "Validation loss improved from 2.0799 to 2.0799. Saving model...\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4173\n",
      "Epoch [1509/2000], Avg Train Loss: 3.4173\n",
      "Epoch [1509/2000], Avg Val Loss: 2.0798\n",
      "Validation loss improved from 2.0799 to 2.0798. Saving model...\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4390\n",
      "Epoch [1510/2000], Avg Train Loss: 3.4390\n",
      "Epoch [1510/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4058\n",
      "Epoch [1511/2000], Avg Train Loss: 3.4058\n",
      "Epoch [1511/2000], Avg Val Loss: 2.0800\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4402\n",
      "Epoch [1512/2000], Avg Train Loss: 3.4402\n",
      "Epoch [1512/2000], Avg Val Loss: 2.0800\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4231\n",
      "Epoch [1513/2000], Avg Train Loss: 3.4231\n",
      "Epoch [1513/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3744\n",
      "Epoch [1514/2000], Avg Train Loss: 3.3744\n",
      "Epoch [1514/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3922\n",
      "Epoch [1515/2000], Avg Train Loss: 3.3922\n",
      "Epoch [1515/2000], Avg Val Loss: 2.0798\n",
      "Validation loss improved from 2.0798 to 2.0798. Saving model...\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4001\n",
      "Epoch [1516/2000], Avg Train Loss: 3.4001\n",
      "Epoch [1516/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3933\n",
      "Epoch [1517/2000], Avg Train Loss: 3.3933\n",
      "Epoch [1517/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3890\n",
      "Epoch [1518/2000], Avg Train Loss: 3.3890\n",
      "Epoch [1518/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3681\n",
      "Epoch [1519/2000], Avg Train Loss: 3.3681\n",
      "Epoch [1519/2000], Avg Val Loss: 2.0799\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4033\n",
      "Epoch [1520/2000], Avg Train Loss: 3.4033\n",
      "Epoch [1520/2000], Avg Val Loss: 2.0798\n",
      "Validation loss improved from 2.0798 to 2.0798. Saving model...\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4210\n",
      "Epoch [1521/2000], Avg Train Loss: 3.4210\n",
      "Epoch [1521/2000], Avg Val Loss: 2.0796\n",
      "Validation loss improved from 2.0798 to 2.0796. Saving model...\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3786\n",
      "Epoch [1522/2000], Avg Train Loss: 3.3786\n",
      "Epoch [1522/2000], Avg Val Loss: 2.0792\n",
      "Validation loss improved from 2.0796 to 2.0792. Saving model...\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4089\n",
      "Epoch [1523/2000], Avg Train Loss: 3.4089\n",
      "Epoch [1523/2000], Avg Val Loss: 2.0789\n",
      "Validation loss improved from 2.0792 to 2.0789. Saving model...\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4151\n",
      "Epoch [1524/2000], Avg Train Loss: 3.4151\n",
      "Epoch [1524/2000], Avg Val Loss: 2.0785\n",
      "Validation loss improved from 2.0789 to 2.0785. Saving model...\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4044\n",
      "Epoch [1525/2000], Avg Train Loss: 3.4044\n",
      "Epoch [1525/2000], Avg Val Loss: 2.0782\n",
      "Validation loss improved from 2.0785 to 2.0782. Saving model...\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4148\n",
      "Epoch [1526/2000], Avg Train Loss: 3.4148\n",
      "Epoch [1526/2000], Avg Val Loss: 2.0779\n",
      "Validation loss improved from 2.0782 to 2.0779. Saving model...\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3784\n",
      "Epoch [1527/2000], Avg Train Loss: 3.3784\n",
      "Epoch [1527/2000], Avg Val Loss: 2.0778\n",
      "Validation loss improved from 2.0779 to 2.0778. Saving model...\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4051\n",
      "Epoch [1528/2000], Avg Train Loss: 3.4051\n",
      "Epoch [1528/2000], Avg Val Loss: 2.0776\n",
      "Validation loss improved from 2.0778 to 2.0776. Saving model...\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3337\n",
      "Epoch [1529/2000], Avg Train Loss: 3.3337\n",
      "Epoch [1529/2000], Avg Val Loss: 2.0775\n",
      "Validation loss improved from 2.0776 to 2.0775. Saving model...\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3901\n",
      "Epoch [1530/2000], Avg Train Loss: 3.3901\n",
      "Epoch [1530/2000], Avg Val Loss: 2.0774\n",
      "Validation loss improved from 2.0775 to 2.0774. Saving model...\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3848\n",
      "Epoch [1531/2000], Avg Train Loss: 3.3848\n",
      "Epoch [1531/2000], Avg Val Loss: 2.0774\n",
      "Validation loss improved from 2.0774 to 2.0774. Saving model...\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4000\n",
      "Epoch [1532/2000], Avg Train Loss: 3.4000\n",
      "Epoch [1532/2000], Avg Val Loss: 2.0771\n",
      "Validation loss improved from 2.0774 to 2.0771. Saving model...\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4016\n",
      "Epoch [1533/2000], Avg Train Loss: 3.4016\n",
      "Epoch [1533/2000], Avg Val Loss: 2.0768\n",
      "Validation loss improved from 2.0771 to 2.0768. Saving model...\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4196\n",
      "Epoch [1534/2000], Avg Train Loss: 3.4196\n",
      "Epoch [1534/2000], Avg Val Loss: 2.0765\n",
      "Validation loss improved from 2.0768 to 2.0765. Saving model...\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3988\n",
      "Epoch [1535/2000], Avg Train Loss: 3.3988\n",
      "Epoch [1535/2000], Avg Val Loss: 2.0763\n",
      "Validation loss improved from 2.0765 to 2.0763. Saving model...\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3867\n",
      "Epoch [1536/2000], Avg Train Loss: 3.3867\n",
      "Epoch [1536/2000], Avg Val Loss: 2.0760\n",
      "Validation loss improved from 2.0763 to 2.0760. Saving model...\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3947\n",
      "Epoch [1537/2000], Avg Train Loss: 3.3947\n",
      "Epoch [1537/2000], Avg Val Loss: 2.0758\n",
      "Validation loss improved from 2.0760 to 2.0758. Saving model...\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3855\n",
      "Epoch [1538/2000], Avg Train Loss: 3.3855\n",
      "Epoch [1538/2000], Avg Val Loss: 2.0756\n",
      "Validation loss improved from 2.0758 to 2.0756. Saving model...\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3982\n",
      "Epoch [1539/2000], Avg Train Loss: 3.3982\n",
      "Epoch [1539/2000], Avg Val Loss: 2.0755\n",
      "Validation loss improved from 2.0756 to 2.0755. Saving model...\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3934\n",
      "Epoch [1540/2000], Avg Train Loss: 3.3934\n",
      "Epoch [1540/2000], Avg Val Loss: 2.0754\n",
      "Validation loss improved from 2.0755 to 2.0754. Saving model...\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4312\n",
      "Epoch [1541/2000], Avg Train Loss: 3.4312\n",
      "Epoch [1541/2000], Avg Val Loss: 2.0753\n",
      "Validation loss improved from 2.0754 to 2.0753. Saving model...\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3966\n",
      "Epoch [1542/2000], Avg Train Loss: 3.3966\n",
      "Epoch [1542/2000], Avg Val Loss: 2.0753\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4296\n",
      "Epoch [1543/2000], Avg Train Loss: 3.4296\n",
      "Epoch [1543/2000], Avg Val Loss: 2.0755\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4084\n",
      "Epoch [1544/2000], Avg Train Loss: 3.4084\n",
      "Epoch [1544/2000], Avg Val Loss: 2.0757\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3816\n",
      "Epoch [1545/2000], Avg Train Loss: 3.3816\n",
      "Epoch [1545/2000], Avg Val Loss: 2.0759\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4146\n",
      "Epoch [1546/2000], Avg Train Loss: 3.4146\n",
      "Epoch [1546/2000], Avg Val Loss: 2.0759\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4053\n",
      "Epoch [1547/2000], Avg Train Loss: 3.4053\n",
      "Epoch [1547/2000], Avg Val Loss: 2.0759\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4125\n",
      "Epoch [1548/2000], Avg Train Loss: 3.4125\n",
      "Epoch [1548/2000], Avg Val Loss: 2.0759\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3910\n",
      "Epoch [1549/2000], Avg Train Loss: 3.3910\n",
      "Epoch [1549/2000], Avg Val Loss: 2.0758\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4112\n",
      "Epoch [1550/2000], Avg Train Loss: 3.4112\n",
      "Epoch [1550/2000], Avg Val Loss: 2.0758\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3752\n",
      "Epoch [1551/2000], Avg Train Loss: 3.3752\n",
      "Epoch [1551/2000], Avg Val Loss: 2.0757\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4069\n",
      "Epoch [1552/2000], Avg Train Loss: 3.4069\n",
      "Epoch [1552/2000], Avg Val Loss: 2.0755\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3965\n",
      "Epoch [1553/2000], Avg Train Loss: 3.3965\n",
      "Epoch [1553/2000], Avg Val Loss: 2.0754\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4206\n",
      "Epoch [1554/2000], Avg Train Loss: 3.4206\n",
      "Epoch [1554/2000], Avg Val Loss: 2.0753\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4237\n",
      "Epoch [1555/2000], Avg Train Loss: 3.4237\n",
      "Epoch [1555/2000], Avg Val Loss: 2.0753\n",
      "Validation loss improved from 2.0753 to 2.0753. Saving model...\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3642\n",
      "Epoch [1556/2000], Avg Train Loss: 3.3642\n",
      "Epoch [1556/2000], Avg Val Loss: 2.0752\n",
      "Validation loss improved from 2.0753 to 2.0752. Saving model...\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3673\n",
      "Epoch [1557/2000], Avg Train Loss: 3.3673\n",
      "Epoch [1557/2000], Avg Val Loss: 2.0752\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3763\n",
      "Epoch [1558/2000], Avg Train Loss: 3.3763\n",
      "Epoch [1558/2000], Avg Val Loss: 2.0751\n",
      "Validation loss improved from 2.0752 to 2.0751. Saving model...\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3690\n",
      "Epoch [1559/2000], Avg Train Loss: 3.3690\n",
      "Epoch [1559/2000], Avg Val Loss: 2.0750\n",
      "Validation loss improved from 2.0751 to 2.0750. Saving model...\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4021\n",
      "Epoch [1560/2000], Avg Train Loss: 3.4021\n",
      "Epoch [1560/2000], Avg Val Loss: 2.0749\n",
      "Validation loss improved from 2.0750 to 2.0749. Saving model...\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4001\n",
      "Epoch [1561/2000], Avg Train Loss: 3.4001\n",
      "Epoch [1561/2000], Avg Val Loss: 2.0750\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3739\n",
      "Epoch [1562/2000], Avg Train Loss: 3.3739\n",
      "Epoch [1562/2000], Avg Val Loss: 2.0749\n",
      "Validation loss improved from 2.0749 to 2.0749. Saving model...\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3917\n",
      "Epoch [1563/2000], Avg Train Loss: 3.3917\n",
      "Epoch [1563/2000], Avg Val Loss: 2.0747\n",
      "Validation loss improved from 2.0749 to 2.0747. Saving model...\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3925\n",
      "Epoch [1564/2000], Avg Train Loss: 3.3925\n",
      "Epoch [1564/2000], Avg Val Loss: 2.0745\n",
      "Validation loss improved from 2.0747 to 2.0745. Saving model...\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3546\n",
      "Epoch [1565/2000], Avg Train Loss: 3.3546\n",
      "Epoch [1565/2000], Avg Val Loss: 2.0743\n",
      "Validation loss improved from 2.0745 to 2.0743. Saving model...\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4034\n",
      "Epoch [1566/2000], Avg Train Loss: 3.4034\n",
      "Epoch [1566/2000], Avg Val Loss: 2.0739\n",
      "Validation loss improved from 2.0743 to 2.0739. Saving model...\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3892\n",
      "Epoch [1567/2000], Avg Train Loss: 3.3892\n",
      "Epoch [1567/2000], Avg Val Loss: 2.0736\n",
      "Validation loss improved from 2.0739 to 2.0736. Saving model...\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3698\n",
      "Epoch [1568/2000], Avg Train Loss: 3.3698\n",
      "Epoch [1568/2000], Avg Val Loss: 2.0735\n",
      "Validation loss improved from 2.0736 to 2.0735. Saving model...\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4258\n",
      "Epoch [1569/2000], Avg Train Loss: 3.4258\n",
      "Epoch [1569/2000], Avg Val Loss: 2.0732\n",
      "Validation loss improved from 2.0735 to 2.0732. Saving model...\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3666\n",
      "Epoch [1570/2000], Avg Train Loss: 3.3666\n",
      "Epoch [1570/2000], Avg Val Loss: 2.0730\n",
      "Validation loss improved from 2.0732 to 2.0730. Saving model...\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3597\n",
      "Epoch [1571/2000], Avg Train Loss: 3.3597\n",
      "Epoch [1571/2000], Avg Val Loss: 2.0728\n",
      "Validation loss improved from 2.0730 to 2.0728. Saving model...\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3735\n",
      "Epoch [1572/2000], Avg Train Loss: 3.3735\n",
      "Epoch [1572/2000], Avg Val Loss: 2.0727\n",
      "Validation loss improved from 2.0728 to 2.0727. Saving model...\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3937\n",
      "Epoch [1573/2000], Avg Train Loss: 3.3937\n",
      "Epoch [1573/2000], Avg Val Loss: 2.0726\n",
      "Validation loss improved from 2.0727 to 2.0726. Saving model...\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4087\n",
      "Epoch [1574/2000], Avg Train Loss: 3.4087\n",
      "Epoch [1574/2000], Avg Val Loss: 2.0725\n",
      "Validation loss improved from 2.0726 to 2.0725. Saving model...\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3886\n",
      "Epoch [1575/2000], Avg Train Loss: 3.3886\n",
      "Epoch [1575/2000], Avg Val Loss: 2.0723\n",
      "Validation loss improved from 2.0725 to 2.0723. Saving model...\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4046\n",
      "Epoch [1576/2000], Avg Train Loss: 3.4046\n",
      "Epoch [1576/2000], Avg Val Loss: 2.0722\n",
      "Validation loss improved from 2.0723 to 2.0722. Saving model...\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4109\n",
      "Epoch [1577/2000], Avg Train Loss: 3.4109\n",
      "Epoch [1577/2000], Avg Val Loss: 2.0721\n",
      "Validation loss improved from 2.0722 to 2.0721. Saving model...\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3384\n",
      "Epoch [1578/2000], Avg Train Loss: 3.3384\n",
      "Epoch [1578/2000], Avg Val Loss: 2.0721\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3871\n",
      "Epoch [1579/2000], Avg Train Loss: 3.3871\n",
      "Epoch [1579/2000], Avg Val Loss: 2.0722\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3822\n",
      "Epoch [1580/2000], Avg Train Loss: 3.3822\n",
      "Epoch [1580/2000], Avg Val Loss: 2.0724\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3723\n",
      "Epoch [1581/2000], Avg Train Loss: 3.3723\n",
      "Epoch [1581/2000], Avg Val Loss: 2.0726\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3989\n",
      "Epoch [1582/2000], Avg Train Loss: 3.3989\n",
      "Epoch [1582/2000], Avg Val Loss: 2.0727\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3839\n",
      "Epoch [1583/2000], Avg Train Loss: 3.3839\n",
      "Epoch [1583/2000], Avg Val Loss: 2.0727\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3713\n",
      "Epoch [1584/2000], Avg Train Loss: 3.3713\n",
      "Epoch [1584/2000], Avg Val Loss: 2.0727\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3747\n",
      "Epoch [1585/2000], Avg Train Loss: 3.3747\n",
      "Epoch [1585/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3747\n",
      "Epoch [1586/2000], Avg Train Loss: 3.3747\n",
      "Epoch [1586/2000], Avg Val Loss: 2.0730\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4026\n",
      "Epoch [1587/2000], Avg Train Loss: 3.4026\n",
      "Epoch [1587/2000], Avg Val Loss: 2.0731\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3418\n",
      "Epoch [1588/2000], Avg Train Loss: 3.3418\n",
      "Epoch [1588/2000], Avg Val Loss: 2.0732\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3835\n",
      "Epoch [1589/2000], Avg Train Loss: 3.3835\n",
      "Epoch [1589/2000], Avg Val Loss: 2.0732\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3600\n",
      "Epoch [1590/2000], Avg Train Loss: 3.3600\n",
      "Epoch [1590/2000], Avg Val Loss: 2.0731\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4401\n",
      "Epoch [1591/2000], Avg Train Loss: 3.4401\n",
      "Epoch [1591/2000], Avg Val Loss: 2.0731\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4010\n",
      "Epoch [1592/2000], Avg Train Loss: 3.4010\n",
      "Epoch [1592/2000], Avg Val Loss: 2.0731\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3520\n",
      "Epoch [1593/2000], Avg Train Loss: 3.3520\n",
      "Epoch [1593/2000], Avg Val Loss: 2.0730\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3815\n",
      "Epoch [1594/2000], Avg Train Loss: 3.3815\n",
      "Epoch [1594/2000], Avg Val Loss: 2.0729\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3438\n",
      "Epoch [1595/2000], Avg Train Loss: 3.3438\n",
      "Epoch [1595/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3684\n",
      "Epoch [1596/2000], Avg Train Loss: 3.3684\n",
      "Epoch [1596/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3558\n",
      "Epoch [1597/2000], Avg Train Loss: 3.3558\n",
      "Epoch [1597/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3571\n",
      "Epoch [1598/2000], Avg Train Loss: 3.3571\n",
      "Epoch [1598/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3901\n",
      "Epoch [1599/2000], Avg Train Loss: 3.3901\n",
      "Epoch [1599/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4080\n",
      "Epoch [1600/2000], Avg Train Loss: 3.4080\n",
      "Epoch [1600/2000], Avg Val Loss: 2.0729\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3832\n",
      "Epoch [1601/2000], Avg Train Loss: 3.3832\n",
      "Epoch [1601/2000], Avg Val Loss: 2.0730\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3774\n",
      "Epoch [1602/2000], Avg Train Loss: 3.3774\n",
      "Epoch [1602/2000], Avg Val Loss: 2.0731\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3572\n",
      "Epoch [1603/2000], Avg Train Loss: 3.3572\n",
      "Epoch [1603/2000], Avg Val Loss: 2.0731\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3952\n",
      "Epoch [1604/2000], Avg Train Loss: 3.3952\n",
      "Epoch [1604/2000], Avg Val Loss: 2.0730\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4029\n",
      "Epoch [1605/2000], Avg Train Loss: 3.4029\n",
      "Epoch [1605/2000], Avg Val Loss: 2.0728\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3726\n",
      "Epoch [1606/2000], Avg Train Loss: 3.3726\n",
      "Epoch [1606/2000], Avg Val Loss: 2.0726\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3431\n",
      "Epoch [1607/2000], Avg Train Loss: 3.3431\n",
      "Epoch [1607/2000], Avg Val Loss: 2.0724\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3789\n",
      "Epoch [1608/2000], Avg Train Loss: 3.3789\n",
      "Epoch [1608/2000], Avg Val Loss: 2.0723\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3500\n",
      "Epoch [1609/2000], Avg Train Loss: 3.3500\n",
      "Epoch [1609/2000], Avg Val Loss: 2.0721\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3943\n",
      "Epoch [1610/2000], Avg Train Loss: 3.3943\n",
      "Epoch [1610/2000], Avg Val Loss: 2.0717\n",
      "Validation loss improved from 2.0721 to 2.0717. Saving model...\n",
      "\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3969\n",
      "Epoch [1611/2000], Avg Train Loss: 3.3969\n",
      "Epoch [1611/2000], Avg Val Loss: 2.0712\n",
      "Validation loss improved from 2.0717 to 2.0712. Saving model...\n",
      "\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4132\n",
      "Epoch [1612/2000], Avg Train Loss: 3.4132\n",
      "Epoch [1612/2000], Avg Val Loss: 2.0708\n",
      "Validation loss improved from 2.0712 to 2.0708. Saving model...\n",
      "\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3814\n",
      "Epoch [1613/2000], Avg Train Loss: 3.3814\n",
      "Epoch [1613/2000], Avg Val Loss: 2.0703\n",
      "Validation loss improved from 2.0708 to 2.0703. Saving model...\n",
      "\n",
      "LOG: Epoch [1614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3952\n",
      "Epoch [1614/2000], Avg Train Loss: 3.3952\n",
      "Epoch [1614/2000], Avg Val Loss: 2.0699\n",
      "Validation loss improved from 2.0703 to 2.0699. Saving model...\n",
      "\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3886\n",
      "Epoch [1615/2000], Avg Train Loss: 3.3886\n",
      "Epoch [1615/2000], Avg Val Loss: 2.0695\n",
      "Validation loss improved from 2.0699 to 2.0695. Saving model...\n",
      "\n",
      "LOG: Epoch [1616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3680\n",
      "Epoch [1616/2000], Avg Train Loss: 3.3680\n",
      "Epoch [1616/2000], Avg Val Loss: 2.0692\n",
      "Validation loss improved from 2.0695 to 2.0692. Saving model...\n",
      "\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3579\n",
      "Epoch [1617/2000], Avg Train Loss: 3.3579\n",
      "Epoch [1617/2000], Avg Val Loss: 2.0690\n",
      "Validation loss improved from 2.0692 to 2.0690. Saving model...\n",
      "\n",
      "LOG: Epoch [1618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3820\n",
      "Epoch [1618/2000], Avg Train Loss: 3.3820\n",
      "Epoch [1618/2000], Avg Val Loss: 2.0689\n",
      "Validation loss improved from 2.0690 to 2.0689. Saving model...\n",
      "\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4231\n",
      "Epoch [1619/2000], Avg Train Loss: 3.4231\n",
      "Epoch [1619/2000], Avg Val Loss: 2.0688\n",
      "Validation loss improved from 2.0689 to 2.0688. Saving model...\n",
      "\n",
      "LOG: Epoch [1620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3785\n",
      "Epoch [1620/2000], Avg Train Loss: 3.3785\n",
      "Epoch [1620/2000], Avg Val Loss: 2.0688\n",
      "Validation loss improved from 2.0688 to 2.0688. Saving model...\n",
      "\n",
      "LOG: Epoch [1621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3618\n",
      "Epoch [1621/2000], Avg Train Loss: 3.3618\n",
      "Epoch [1621/2000], Avg Val Loss: 2.0687\n",
      "Validation loss improved from 2.0688 to 2.0687. Saving model...\n",
      "\n",
      "LOG: Epoch [1622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3694\n",
      "Epoch [1622/2000], Avg Train Loss: 3.3694\n",
      "Epoch [1622/2000], Avg Val Loss: 2.0688\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3593\n",
      "Epoch [1623/2000], Avg Train Loss: 3.3593\n",
      "Epoch [1623/2000], Avg Val Loss: 2.0688\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3592\n",
      "Epoch [1624/2000], Avg Train Loss: 3.3592\n",
      "Epoch [1624/2000], Avg Val Loss: 2.0690\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3578\n",
      "Epoch [1625/2000], Avg Train Loss: 3.3578\n",
      "Epoch [1625/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3759\n",
      "Epoch [1626/2000], Avg Train Loss: 3.3759\n",
      "Epoch [1626/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3843\n",
      "Epoch [1627/2000], Avg Train Loss: 3.3843\n",
      "Epoch [1627/2000], Avg Val Loss: 2.0693\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3608\n",
      "Epoch [1628/2000], Avg Train Loss: 3.3608\n",
      "Epoch [1628/2000], Avg Val Loss: 2.0692\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3571\n",
      "Epoch [1629/2000], Avg Train Loss: 3.3571\n",
      "Epoch [1629/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3768\n",
      "Epoch [1630/2000], Avg Train Loss: 3.3768\n",
      "Epoch [1630/2000], Avg Val Loss: 2.0690\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4050\n",
      "Epoch [1631/2000], Avg Train Loss: 3.4050\n",
      "Epoch [1631/2000], Avg Val Loss: 2.0687\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3791\n",
      "Epoch [1632/2000], Avg Train Loss: 3.3791\n",
      "Epoch [1632/2000], Avg Val Loss: 2.0686\n",
      "Validation loss improved from 2.0687 to 2.0686. Saving model...\n",
      "\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3679\n",
      "Epoch [1633/2000], Avg Train Loss: 3.3679\n",
      "Epoch [1633/2000], Avg Val Loss: 2.0685\n",
      "Validation loss improved from 2.0686 to 2.0685. Saving model...\n",
      "\n",
      "LOG: Epoch [1634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3791\n",
      "Epoch [1634/2000], Avg Train Loss: 3.3791\n",
      "Epoch [1634/2000], Avg Val Loss: 2.0685\n",
      "Validation loss improved from 2.0685 to 2.0685. Saving model...\n",
      "\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3747\n",
      "Epoch [1635/2000], Avg Train Loss: 3.3747\n",
      "Epoch [1635/2000], Avg Val Loss: 2.0684\n",
      "Validation loss improved from 2.0685 to 2.0684. Saving model...\n",
      "\n",
      "LOG: Epoch [1636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3795\n",
      "Epoch [1636/2000], Avg Train Loss: 3.3795\n",
      "Epoch [1636/2000], Avg Val Loss: 2.0684\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3495\n",
      "Epoch [1637/2000], Avg Train Loss: 3.3495\n",
      "Epoch [1637/2000], Avg Val Loss: 2.0686\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3759\n",
      "Epoch [1638/2000], Avg Train Loss: 3.3759\n",
      "Epoch [1638/2000], Avg Val Loss: 2.0688\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4008\n",
      "Epoch [1639/2000], Avg Train Loss: 3.4008\n",
      "Epoch [1639/2000], Avg Val Loss: 2.0689\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3608\n",
      "Epoch [1640/2000], Avg Train Loss: 3.3608\n",
      "Epoch [1640/2000], Avg Val Loss: 2.0690\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3755\n",
      "Epoch [1641/2000], Avg Train Loss: 3.3755\n",
      "Epoch [1641/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3936\n",
      "Epoch [1642/2000], Avg Train Loss: 3.3936\n",
      "Epoch [1642/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3550\n",
      "Epoch [1643/2000], Avg Train Loss: 3.3550\n",
      "Epoch [1643/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3654\n",
      "Epoch [1644/2000], Avg Train Loss: 3.3654\n",
      "Epoch [1644/2000], Avg Val Loss: 2.0691\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3511\n",
      "Epoch [1645/2000], Avg Train Loss: 3.3511\n",
      "Epoch [1645/2000], Avg Val Loss: 2.0692\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3552\n",
      "Epoch [1646/2000], Avg Train Loss: 3.3552\n",
      "Epoch [1646/2000], Avg Val Loss: 2.0692\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3886\n",
      "Epoch [1647/2000], Avg Train Loss: 3.3886\n",
      "Epoch [1647/2000], Avg Val Loss: 2.0692\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3666\n",
      "Epoch [1648/2000], Avg Train Loss: 3.3666\n",
      "Epoch [1648/2000], Avg Val Loss: 2.0692\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3441\n",
      "Epoch [1649/2000], Avg Train Loss: 3.3441\n",
      "Epoch [1649/2000], Avg Val Loss: 2.0693\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3488\n",
      "Epoch [1650/2000], Avg Train Loss: 3.3488\n",
      "Epoch [1650/2000], Avg Val Loss: 2.0692\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3658\n",
      "Epoch [1651/2000], Avg Train Loss: 3.3658\n",
      "Epoch [1651/2000], Avg Val Loss: 2.0690\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3662\n",
      "Epoch [1652/2000], Avg Train Loss: 3.3662\n",
      "Epoch [1652/2000], Avg Val Loss: 2.0688\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3561\n",
      "Epoch [1653/2000], Avg Train Loss: 3.3561\n",
      "Epoch [1653/2000], Avg Val Loss: 2.0685\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3781\n",
      "Epoch [1654/2000], Avg Train Loss: 3.3781\n",
      "Epoch [1654/2000], Avg Val Loss: 2.0682\n",
      "Validation loss improved from 2.0684 to 2.0682. Saving model...\n",
      "\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3526\n",
      "Epoch [1655/2000], Avg Train Loss: 3.3526\n",
      "Epoch [1655/2000], Avg Val Loss: 2.0679\n",
      "Validation loss improved from 2.0682 to 2.0679. Saving model...\n",
      "\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3994\n",
      "Epoch [1656/2000], Avg Train Loss: 3.3994\n",
      "Epoch [1656/2000], Avg Val Loss: 2.0677\n",
      "Validation loss improved from 2.0679 to 2.0677. Saving model...\n",
      "\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3473\n",
      "Epoch [1657/2000], Avg Train Loss: 3.3473\n",
      "Epoch [1657/2000], Avg Val Loss: 2.0674\n",
      "Validation loss improved from 2.0677 to 2.0674. Saving model...\n",
      "\n",
      "LOG: Epoch [1658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3527\n",
      "Epoch [1658/2000], Avg Train Loss: 3.3527\n",
      "Epoch [1658/2000], Avg Val Loss: 2.0671\n",
      "Validation loss improved from 2.0674 to 2.0671. Saving model...\n",
      "\n",
      "LOG: Epoch [1659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3962\n",
      "Epoch [1659/2000], Avg Train Loss: 3.3962\n",
      "Epoch [1659/2000], Avg Val Loss: 2.0668\n",
      "Validation loss improved from 2.0671 to 2.0668. Saving model...\n",
      "\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3843\n",
      "Epoch [1660/2000], Avg Train Loss: 3.3843\n",
      "Epoch [1660/2000], Avg Val Loss: 2.0665\n",
      "Validation loss improved from 2.0668 to 2.0665. Saving model...\n",
      "\n",
      "LOG: Epoch [1661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3915\n",
      "Epoch [1661/2000], Avg Train Loss: 3.3915\n",
      "Epoch [1661/2000], Avg Val Loss: 2.0663\n",
      "Validation loss improved from 2.0665 to 2.0663. Saving model...\n",
      "\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3617\n",
      "Epoch [1662/2000], Avg Train Loss: 3.3617\n",
      "Epoch [1662/2000], Avg Val Loss: 2.0661\n",
      "Validation loss improved from 2.0663 to 2.0661. Saving model...\n",
      "\n",
      "LOG: Epoch [1663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3502\n",
      "Epoch [1663/2000], Avg Train Loss: 3.3502\n",
      "Epoch [1663/2000], Avg Val Loss: 2.0660\n",
      "Validation loss improved from 2.0661 to 2.0660. Saving model...\n",
      "\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3664\n",
      "Epoch [1664/2000], Avg Train Loss: 3.3664\n",
      "Epoch [1664/2000], Avg Val Loss: 2.0660\n",
      "Validation loss improved from 2.0660 to 2.0660. Saving model...\n",
      "\n",
      "LOG: Epoch [1665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3760\n",
      "Epoch [1665/2000], Avg Train Loss: 3.3760\n",
      "Epoch [1665/2000], Avg Val Loss: 2.0659\n",
      "Validation loss improved from 2.0660 to 2.0659. Saving model...\n",
      "\n",
      "LOG: Epoch [1666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3716\n",
      "Epoch [1666/2000], Avg Train Loss: 3.3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1666/2000], Avg Val Loss: 2.0659\n",
      "Validation loss improved from 2.0659 to 2.0659. Saving model...\n",
      "\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3661\n",
      "Epoch [1667/2000], Avg Train Loss: 3.3661\n",
      "Epoch [1667/2000], Avg Val Loss: 2.0657\n",
      "Validation loss improved from 2.0659 to 2.0657. Saving model...\n",
      "\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3585\n",
      "Epoch [1668/2000], Avg Train Loss: 3.3585\n",
      "Epoch [1668/2000], Avg Val Loss: 2.0657\n",
      "Validation loss improved from 2.0657 to 2.0657. Saving model...\n",
      "\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3654\n",
      "Epoch [1669/2000], Avg Train Loss: 3.3654\n",
      "Epoch [1669/2000], Avg Val Loss: 2.0656\n",
      "Validation loss improved from 2.0657 to 2.0656. Saving model...\n",
      "\n",
      "LOG: Epoch [1670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3567\n",
      "Epoch [1670/2000], Avg Train Loss: 3.3567\n",
      "Epoch [1670/2000], Avg Val Loss: 2.0655\n",
      "Validation loss improved from 2.0656 to 2.0655. Saving model...\n",
      "\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3649\n",
      "Epoch [1671/2000], Avg Train Loss: 3.3649\n",
      "Epoch [1671/2000], Avg Val Loss: 2.0653\n",
      "Validation loss improved from 2.0655 to 2.0653. Saving model...\n",
      "\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3447\n",
      "Epoch [1672/2000], Avg Train Loss: 3.3447\n",
      "Epoch [1672/2000], Avg Val Loss: 2.0651\n",
      "Validation loss improved from 2.0653 to 2.0651. Saving model...\n",
      "\n",
      "LOG: Epoch [1673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3493\n",
      "Epoch [1673/2000], Avg Train Loss: 3.3493\n",
      "Epoch [1673/2000], Avg Val Loss: 2.0651\n",
      "Validation loss improved from 2.0651 to 2.0651. Saving model...\n",
      "\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3473\n",
      "Epoch [1674/2000], Avg Train Loss: 3.3473\n",
      "Epoch [1674/2000], Avg Val Loss: 2.0651\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3884\n",
      "Epoch [1675/2000], Avg Train Loss: 3.3884\n",
      "Epoch [1675/2000], Avg Val Loss: 2.0651\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3486\n",
      "Epoch [1676/2000], Avg Train Loss: 3.3486\n",
      "Epoch [1676/2000], Avg Val Loss: 2.0649\n",
      "Validation loss improved from 2.0651 to 2.0649. Saving model...\n",
      "\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3586\n",
      "Epoch [1677/2000], Avg Train Loss: 3.3586\n",
      "Epoch [1677/2000], Avg Val Loss: 2.0647\n",
      "Validation loss improved from 2.0649 to 2.0647. Saving model...\n",
      "\n",
      "LOG: Epoch [1678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3655\n",
      "Epoch [1678/2000], Avg Train Loss: 3.3655\n",
      "Epoch [1678/2000], Avg Val Loss: 2.0646\n",
      "Validation loss improved from 2.0647 to 2.0646. Saving model...\n",
      "\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3678\n",
      "Epoch [1679/2000], Avg Train Loss: 3.3678\n",
      "Epoch [1679/2000], Avg Val Loss: 2.0644\n",
      "Validation loss improved from 2.0646 to 2.0644. Saving model...\n",
      "\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3339\n",
      "Epoch [1680/2000], Avg Train Loss: 3.3339\n",
      "Epoch [1680/2000], Avg Val Loss: 2.0642\n",
      "Validation loss improved from 2.0644 to 2.0642. Saving model...\n",
      "\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3527\n",
      "Epoch [1681/2000], Avg Train Loss: 3.3527\n",
      "Epoch [1681/2000], Avg Val Loss: 2.0640\n",
      "Validation loss improved from 2.0642 to 2.0640. Saving model...\n",
      "\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3500\n",
      "Epoch [1682/2000], Avg Train Loss: 3.3500\n",
      "Epoch [1682/2000], Avg Val Loss: 2.0637\n",
      "Validation loss improved from 2.0640 to 2.0637. Saving model...\n",
      "\n",
      "LOG: Epoch [1683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3670\n",
      "Epoch [1683/2000], Avg Train Loss: 3.3670\n",
      "Epoch [1683/2000], Avg Val Loss: 2.0634\n",
      "Validation loss improved from 2.0637 to 2.0634. Saving model...\n",
      "\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3562\n",
      "Epoch [1684/2000], Avg Train Loss: 3.3562\n",
      "Epoch [1684/2000], Avg Val Loss: 2.0630\n",
      "Validation loss improved from 2.0634 to 2.0630. Saving model...\n",
      "\n",
      "LOG: Epoch [1685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3586\n",
      "Epoch [1685/2000], Avg Train Loss: 3.3586\n",
      "Epoch [1685/2000], Avg Val Loss: 2.0628\n",
      "Validation loss improved from 2.0630 to 2.0628. Saving model...\n",
      "\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3438\n",
      "Epoch [1686/2000], Avg Train Loss: 3.3438\n",
      "Epoch [1686/2000], Avg Val Loss: 2.0624\n",
      "Validation loss improved from 2.0628 to 2.0624. Saving model...\n",
      "\n",
      "LOG: Epoch [1687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3618\n",
      "Epoch [1687/2000], Avg Train Loss: 3.3618\n",
      "Epoch [1687/2000], Avg Val Loss: 2.0620\n",
      "Validation loss improved from 2.0624 to 2.0620. Saving model...\n",
      "\n",
      "LOG: Epoch [1688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3585\n",
      "Epoch [1688/2000], Avg Train Loss: 3.3585\n",
      "Epoch [1688/2000], Avg Val Loss: 2.0617\n",
      "Validation loss improved from 2.0620 to 2.0617. Saving model...\n",
      "\n",
      "LOG: Epoch [1689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3477\n",
      "Epoch [1689/2000], Avg Train Loss: 3.3477\n",
      "Epoch [1689/2000], Avg Val Loss: 2.0615\n",
      "Validation loss improved from 2.0617 to 2.0615. Saving model...\n",
      "\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3391\n",
      "Epoch [1690/2000], Avg Train Loss: 3.3391\n",
      "Epoch [1690/2000], Avg Val Loss: 2.0612\n",
      "Validation loss improved from 2.0615 to 2.0612. Saving model...\n",
      "\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3729\n",
      "Epoch [1691/2000], Avg Train Loss: 3.3729\n",
      "Epoch [1691/2000], Avg Val Loss: 2.0609\n",
      "Validation loss improved from 2.0612 to 2.0609. Saving model...\n",
      "\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3392\n",
      "Epoch [1692/2000], Avg Train Loss: 3.3392\n",
      "Epoch [1692/2000], Avg Val Loss: 2.0606\n",
      "Validation loss improved from 2.0609 to 2.0606. Saving model...\n",
      "\n",
      "LOG: Epoch [1693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3592\n",
      "Epoch [1693/2000], Avg Train Loss: 3.3592\n",
      "Epoch [1693/2000], Avg Val Loss: 2.0605\n",
      "Validation loss improved from 2.0606 to 2.0605. Saving model...\n",
      "\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3665\n",
      "Epoch [1694/2000], Avg Train Loss: 3.3665\n",
      "Epoch [1694/2000], Avg Val Loss: 2.0603\n",
      "Validation loss improved from 2.0605 to 2.0603. Saving model...\n",
      "\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3554\n",
      "Epoch [1695/2000], Avg Train Loss: 3.3554\n",
      "Epoch [1695/2000], Avg Val Loss: 2.0601\n",
      "Validation loss improved from 2.0603 to 2.0601. Saving model...\n",
      "\n",
      "LOG: Epoch [1696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3503\n",
      "Epoch [1696/2000], Avg Train Loss: 3.3503\n",
      "Epoch [1696/2000], Avg Val Loss: 2.0598\n",
      "Validation loss improved from 2.0601 to 2.0598. Saving model...\n",
      "\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3404\n",
      "Epoch [1697/2000], Avg Train Loss: 3.3404\n",
      "Epoch [1697/2000], Avg Val Loss: 2.0597\n",
      "Validation loss improved from 2.0598 to 2.0597. Saving model...\n",
      "\n",
      "LOG: Epoch [1698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3362\n",
      "Epoch [1698/2000], Avg Train Loss: 3.3362\n",
      "Epoch [1698/2000], Avg Val Loss: 2.0596\n",
      "Validation loss improved from 2.0597 to 2.0596. Saving model...\n",
      "\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3427\n",
      "Epoch [1699/2000], Avg Train Loss: 3.3427\n",
      "Epoch [1699/2000], Avg Val Loss: 2.0598\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3473\n",
      "Epoch [1700/2000], Avg Train Loss: 3.3473\n",
      "Epoch [1700/2000], Avg Val Loss: 2.0600\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3532\n",
      "Epoch [1701/2000], Avg Train Loss: 3.3532\n",
      "Epoch [1701/2000], Avg Val Loss: 2.0601\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3337\n",
      "Epoch [1702/2000], Avg Train Loss: 3.3337\n",
      "Epoch [1702/2000], Avg Val Loss: 2.0602\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3430\n",
      "Epoch [1703/2000], Avg Train Loss: 3.3430\n",
      "Epoch [1703/2000], Avg Val Loss: 2.0603\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3290\n",
      "Epoch [1704/2000], Avg Train Loss: 3.3290\n",
      "Epoch [1704/2000], Avg Val Loss: 2.0605\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3292\n",
      "Epoch [1705/2000], Avg Train Loss: 3.3292\n",
      "Epoch [1705/2000], Avg Val Loss: 2.0606\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3835\n",
      "Epoch [1706/2000], Avg Train Loss: 3.3835\n",
      "Epoch [1706/2000], Avg Val Loss: 2.0608\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3321\n",
      "Epoch [1707/2000], Avg Train Loss: 3.3321\n",
      "Epoch [1707/2000], Avg Val Loss: 2.0610\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3977\n",
      "Epoch [1708/2000], Avg Train Loss: 3.3977\n",
      "Epoch [1708/2000], Avg Val Loss: 2.0611\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3547\n",
      "Epoch [1709/2000], Avg Train Loss: 3.3547\n",
      "Epoch [1709/2000], Avg Val Loss: 2.0612\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3386\n",
      "Epoch [1710/2000], Avg Train Loss: 3.3386\n",
      "Epoch [1710/2000], Avg Val Loss: 2.0613\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3421\n",
      "Epoch [1711/2000], Avg Train Loss: 3.3421\n",
      "Epoch [1711/2000], Avg Val Loss: 2.0615\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3807\n",
      "Epoch [1712/2000], Avg Train Loss: 3.3807\n",
      "Epoch [1712/2000], Avg Val Loss: 2.0616\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3550\n",
      "Epoch [1713/2000], Avg Train Loss: 3.3550\n",
      "Epoch [1713/2000], Avg Val Loss: 2.0616\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3435\n",
      "Epoch [1714/2000], Avg Train Loss: 3.3435\n",
      "Epoch [1714/2000], Avg Val Loss: 2.0618\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3404\n",
      "Epoch [1715/2000], Avg Train Loss: 3.3404\n",
      "Epoch [1715/2000], Avg Val Loss: 2.0618\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3485\n",
      "Epoch [1716/2000], Avg Train Loss: 3.3485\n",
      "Epoch [1716/2000], Avg Val Loss: 2.0620\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3579\n",
      "Epoch [1717/2000], Avg Train Loss: 3.3579\n",
      "Epoch [1717/2000], Avg Val Loss: 2.0621\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3389\n",
      "Epoch [1718/2000], Avg Train Loss: 3.3389\n",
      "Epoch [1718/2000], Avg Val Loss: 2.0623\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3707\n",
      "Epoch [1719/2000], Avg Train Loss: 3.3707\n",
      "Epoch [1719/2000], Avg Val Loss: 2.0625\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3776\n",
      "Epoch [1720/2000], Avg Train Loss: 3.3776\n",
      "Epoch [1720/2000], Avg Val Loss: 2.0627\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3512\n",
      "Epoch [1721/2000], Avg Train Loss: 3.3512\n",
      "Epoch [1721/2000], Avg Val Loss: 2.0627\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3631\n",
      "Epoch [1722/2000], Avg Train Loss: 3.3631\n",
      "Epoch [1722/2000], Avg Val Loss: 2.0627\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3852\n",
      "Epoch [1723/2000], Avg Train Loss: 3.3852\n",
      "Epoch [1723/2000], Avg Val Loss: 2.0626\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3780\n",
      "Epoch [1724/2000], Avg Train Loss: 3.3780\n",
      "Epoch [1724/2000], Avg Val Loss: 2.0626\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3599\n",
      "Epoch [1725/2000], Avg Train Loss: 3.3599\n",
      "Epoch [1725/2000], Avg Val Loss: 2.0625\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3732\n",
      "Epoch [1726/2000], Avg Train Loss: 3.3732\n",
      "Epoch [1726/2000], Avg Val Loss: 2.0621\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3159\n",
      "Epoch [1727/2000], Avg Train Loss: 3.3159\n",
      "Epoch [1727/2000], Avg Val Loss: 2.0617\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3524\n",
      "Epoch [1728/2000], Avg Train Loss: 3.3524\n",
      "Epoch [1728/2000], Avg Val Loss: 2.0614\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3556\n",
      "Epoch [1729/2000], Avg Train Loss: 3.3556\n",
      "Epoch [1729/2000], Avg Val Loss: 2.0612\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3727\n",
      "Epoch [1730/2000], Avg Train Loss: 3.3727\n",
      "Epoch [1730/2000], Avg Val Loss: 2.0611\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3465\n",
      "Epoch [1731/2000], Avg Train Loss: 3.3465\n",
      "Epoch [1731/2000], Avg Val Loss: 2.0611\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3576\n",
      "Epoch [1732/2000], Avg Train Loss: 3.3576\n",
      "Epoch [1732/2000], Avg Val Loss: 2.0612\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3506\n",
      "Epoch [1733/2000], Avg Train Loss: 3.3506\n",
      "Epoch [1733/2000], Avg Val Loss: 2.0614\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3277\n",
      "Epoch [1734/2000], Avg Train Loss: 3.3277\n",
      "Epoch [1734/2000], Avg Val Loss: 2.0615\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3603\n",
      "Epoch [1735/2000], Avg Train Loss: 3.3603\n",
      "Epoch [1735/2000], Avg Val Loss: 2.0617\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3626\n",
      "Epoch [1736/2000], Avg Train Loss: 3.3626\n",
      "Epoch [1736/2000], Avg Val Loss: 2.0618\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3109\n",
      "Epoch [1737/2000], Avg Train Loss: 3.3109\n",
      "Epoch [1737/2000], Avg Val Loss: 2.0619\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3686\n",
      "Epoch [1738/2000], Avg Train Loss: 3.3686\n",
      "Epoch [1738/2000], Avg Val Loss: 2.0620\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3552\n",
      "Epoch [1739/2000], Avg Train Loss: 3.3552\n",
      "Epoch [1739/2000], Avg Val Loss: 2.0621\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3374\n",
      "Epoch [1740/2000], Avg Train Loss: 3.3374\n",
      "Epoch [1740/2000], Avg Val Loss: 2.0624\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3379\n",
      "Epoch [1741/2000], Avg Train Loss: 3.3379\n",
      "Epoch [1741/2000], Avg Val Loss: 2.0626\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3552\n",
      "Epoch [1742/2000], Avg Train Loss: 3.3552\n",
      "Epoch [1742/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3425\n",
      "Epoch [1743/2000], Avg Train Loss: 3.3425\n",
      "Epoch [1743/2000], Avg Val Loss: 2.0630\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3439\n",
      "Epoch [1744/2000], Avg Train Loss: 3.3439\n",
      "Epoch [1744/2000], Avg Val Loss: 2.0630\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3494\n",
      "Epoch [1745/2000], Avg Train Loss: 3.3494\n",
      "Epoch [1745/2000], Avg Val Loss: 2.0631\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3835\n",
      "Epoch [1746/2000], Avg Train Loss: 3.3835\n",
      "Epoch [1746/2000], Avg Val Loss: 2.0632\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3525\n",
      "Epoch [1747/2000], Avg Train Loss: 3.3525\n",
      "Epoch [1747/2000], Avg Val Loss: 2.0632\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3484\n",
      "Epoch [1748/2000], Avg Train Loss: 3.3484\n",
      "Epoch [1748/2000], Avg Val Loss: 2.0633\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3561\n",
      "Epoch [1749/2000], Avg Train Loss: 3.3561\n",
      "Epoch [1749/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3921\n",
      "Epoch [1750/2000], Avg Train Loss: 3.3921\n",
      "Epoch [1750/2000], Avg Val Loss: 2.0633\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3528\n",
      "Epoch [1751/2000], Avg Train Loss: 3.3528\n",
      "Epoch [1751/2000], Avg Val Loss: 2.0632\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3946\n",
      "Epoch [1752/2000], Avg Train Loss: 3.3946\n",
      "Epoch [1752/2000], Avg Val Loss: 2.0629\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3582\n",
      "Epoch [1753/2000], Avg Train Loss: 3.3582\n",
      "Epoch [1753/2000], Avg Val Loss: 2.0626\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3486\n",
      "Epoch [1754/2000], Avg Train Loss: 3.3486\n",
      "Epoch [1754/2000], Avg Val Loss: 2.0624\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3478\n",
      "Epoch [1755/2000], Avg Train Loss: 3.3478\n",
      "Epoch [1755/2000], Avg Val Loss: 2.0622\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3411\n",
      "Epoch [1756/2000], Avg Train Loss: 3.3411\n",
      "Epoch [1756/2000], Avg Val Loss: 2.0621\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3168\n",
      "Epoch [1757/2000], Avg Train Loss: 3.3168\n",
      "Epoch [1757/2000], Avg Val Loss: 2.0620\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3761\n",
      "Epoch [1758/2000], Avg Train Loss: 3.3761\n",
      "Epoch [1758/2000], Avg Val Loss: 2.0620\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3501\n",
      "Epoch [1759/2000], Avg Train Loss: 3.3501\n",
      "Epoch [1759/2000], Avg Val Loss: 2.0620\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3167\n",
      "Epoch [1760/2000], Avg Train Loss: 3.3167\n",
      "Epoch [1760/2000], Avg Val Loss: 2.0621\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3376\n",
      "Epoch [1761/2000], Avg Train Loss: 3.3376\n",
      "Epoch [1761/2000], Avg Val Loss: 2.0623\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3429\n",
      "Epoch [1762/2000], Avg Train Loss: 3.3429\n",
      "Epoch [1762/2000], Avg Val Loss: 2.0625\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3426\n",
      "Epoch [1763/2000], Avg Train Loss: 3.3426\n",
      "Epoch [1763/2000], Avg Val Loss: 2.0627\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3603\n",
      "Epoch [1764/2000], Avg Train Loss: 3.3603\n",
      "Epoch [1764/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3518\n",
      "Epoch [1765/2000], Avg Train Loss: 3.3518\n",
      "Epoch [1765/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3204\n",
      "Epoch [1766/2000], Avg Train Loss: 3.3204\n",
      "Epoch [1766/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3454\n",
      "Epoch [1767/2000], Avg Train Loss: 3.3454\n",
      "Epoch [1767/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3433\n",
      "Epoch [1768/2000], Avg Train Loss: 3.3433\n",
      "Epoch [1768/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3474\n",
      "Epoch [1769/2000], Avg Train Loss: 3.3474\n",
      "Epoch [1769/2000], Avg Val Loss: 2.0627\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3293\n",
      "Epoch [1770/2000], Avg Train Loss: 3.3293\n",
      "Epoch [1770/2000], Avg Val Loss: 2.0625\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3361\n",
      "Epoch [1771/2000], Avg Train Loss: 3.3361\n",
      "Epoch [1771/2000], Avg Val Loss: 2.0624\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3432\n",
      "Epoch [1772/2000], Avg Train Loss: 3.3432\n",
      "Epoch [1772/2000], Avg Val Loss: 2.0625\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3171\n",
      "Epoch [1773/2000], Avg Train Loss: 3.3171\n",
      "Epoch [1773/2000], Avg Val Loss: 2.0624\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3206\n",
      "Epoch [1774/2000], Avg Train Loss: 3.3206\n",
      "Epoch [1774/2000], Avg Val Loss: 2.0623\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3415\n",
      "Epoch [1775/2000], Avg Train Loss: 3.3415\n",
      "Epoch [1775/2000], Avg Val Loss: 2.0624\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3355\n",
      "Epoch [1776/2000], Avg Train Loss: 3.3355\n",
      "Epoch [1776/2000], Avg Val Loss: 2.0626\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3138\n",
      "Epoch [1777/2000], Avg Train Loss: 3.3138\n",
      "Epoch [1777/2000], Avg Val Loss: 2.0628\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3320\n",
      "Epoch [1778/2000], Avg Train Loss: 3.3320\n",
      "Epoch [1778/2000], Avg Val Loss: 2.0629\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3446\n",
      "Epoch [1779/2000], Avg Train Loss: 3.3446\n",
      "Epoch [1779/2000], Avg Val Loss: 2.0630\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3242\n",
      "Epoch [1780/2000], Avg Train Loss: 3.3242\n",
      "Epoch [1780/2000], Avg Val Loss: 2.0633\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3327\n",
      "Epoch [1781/2000], Avg Train Loss: 3.3327\n",
      "Epoch [1781/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3466\n",
      "Epoch [1782/2000], Avg Train Loss: 3.3466\n",
      "Epoch [1782/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3639\n",
      "Epoch [1783/2000], Avg Train Loss: 3.3639\n",
      "Epoch [1783/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3468\n",
      "Epoch [1784/2000], Avg Train Loss: 3.3468\n",
      "Epoch [1784/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3241\n",
      "Epoch [1785/2000], Avg Train Loss: 3.3241\n",
      "Epoch [1785/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3509\n",
      "Epoch [1786/2000], Avg Train Loss: 3.3509\n",
      "Epoch [1786/2000], Avg Val Loss: 2.0632\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3303\n",
      "Epoch [1787/2000], Avg Train Loss: 3.3303\n",
      "Epoch [1787/2000], Avg Val Loss: 2.0631\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3154\n",
      "Epoch [1788/2000], Avg Train Loss: 3.3154\n",
      "Epoch [1788/2000], Avg Val Loss: 2.0631\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3675\n",
      "Epoch [1789/2000], Avg Train Loss: 3.3675\n",
      "Epoch [1789/2000], Avg Val Loss: 2.0631\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3126\n",
      "Epoch [1790/2000], Avg Train Loss: 3.3126\n",
      "Epoch [1790/2000], Avg Val Loss: 2.0631\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3223\n",
      "Epoch [1791/2000], Avg Train Loss: 3.3223\n",
      "Epoch [1791/2000], Avg Val Loss: 2.0630\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3682\n",
      "Epoch [1792/2000], Avg Train Loss: 3.3682\n",
      "Epoch [1792/2000], Avg Val Loss: 2.0630\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3196\n",
      "Epoch [1793/2000], Avg Train Loss: 3.3196\n",
      "Epoch [1793/2000], Avg Val Loss: 2.0631\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3550\n",
      "Epoch [1794/2000], Avg Train Loss: 3.3550\n",
      "Epoch [1794/2000], Avg Val Loss: 2.0633\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3506\n",
      "Epoch [1795/2000], Avg Train Loss: 3.3506\n",
      "Epoch [1795/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3570\n",
      "Epoch [1796/2000], Avg Train Loss: 3.3570\n",
      "Epoch [1796/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3228\n",
      "Epoch [1797/2000], Avg Train Loss: 3.3228\n",
      "Epoch [1797/2000], Avg Val Loss: 2.0634\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3072\n",
      "Epoch [1798/2000], Avg Train Loss: 3.3072\n",
      "Epoch [1798/2000], Avg Val Loss: 2.0635\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1798. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:40.189864Z",
     "iopub.status.busy": "2025-05-08T17:19:40.189864Z",
     "iopub.status.idle": "2025-05-08T17:19:41.208369Z",
     "shell.execute_reply": "2025-05-08T17:19:41.207978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/578], Loss: 5.2721\n",
      "Test Batch [20/578], Loss: 5.2080\n",
      "Test Batch [30/578], Loss: 5.1571\n",
      "Test Batch [40/578], Loss: 5.0400\n",
      "Test Batch [50/578], Loss: 5.0709\n",
      "Test Batch [60/578], Loss: 5.1545\n",
      "Test Batch [70/578], Loss: 5.1526\n",
      "Test Batch [80/578], Loss: 5.1686\n",
      "Test Batch [90/578], Loss: 5.4141\n",
      "Test Batch [100/578], Loss: 5.3772\n",
      "Test Batch [110/578], Loss: 5.3348\n",
      "Test Batch [120/578], Loss: 5.2015\n",
      "Test Batch [130/578], Loss: 5.1929\n",
      "Test Batch [140/578], Loss: 5.1565\n",
      "Test Batch [150/578], Loss: 5.2562\n",
      "Test Batch [160/578], Loss: 5.1889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [170/578], Loss: 5.3103\n",
      "Test Batch [180/578], Loss: 5.3940\n",
      "Test Batch [190/578], Loss: 5.1320\n",
      "Test Batch [200/578], Loss: 5.0647\n",
      "Test Batch [210/578], Loss: 5.1700\n",
      "Test Batch [220/578], Loss: 5.0809\n",
      "Test Batch [230/578], Loss: 5.0518\n",
      "Test Batch [240/578], Loss: 4.9772\n",
      "Test Batch [250/578], Loss: 5.0981\n",
      "Test Batch [260/578], Loss: 5.0559\n",
      "Test Batch [270/578], Loss: 5.0642\n",
      "Test Batch [280/578], Loss: 5.4802\n",
      "Test Batch [290/578], Loss: 4.9712\n",
      "Test Batch [300/578], Loss: 4.9758\n",
      "Test Batch [310/578], Loss: 4.9096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [320/578], Loss: 5.0198\n",
      "Test Batch [330/578], Loss: 5.0327\n",
      "Test Batch [340/578], Loss: 4.9884\n",
      "Test Batch [350/578], Loss: 5.0096\n",
      "Test Batch [360/578], Loss: 5.0941\n",
      "Test Batch [370/578], Loss: 4.8598\n",
      "Test Batch [380/578], Loss: 5.2494\n",
      "Test Batch [390/578], Loss: 4.9651\n",
      "Test Batch [400/578], Loss: 5.1323\n",
      "Test Batch [410/578], Loss: 5.1501\n",
      "Test Batch [420/578], Loss: 5.1623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [430/578], Loss: 4.9257\n",
      "Test Batch [440/578], Loss: 4.9889\n",
      "Test Batch [450/578], Loss: 4.9212\n",
      "Test Batch [460/578], Loss: 5.1007\n",
      "Test Batch [470/578], Loss: 5.0254\n",
      "Test Batch [480/578], Loss: 5.2968\n",
      "Test Batch [490/578], Loss: 5.1766\n",
      "Test Batch [500/578], Loss: 5.0274\n",
      "Test Batch [510/578], Loss: 4.9274\n",
      "Test Batch [520/578], Loss: 5.0949\n",
      "Test Batch [530/578], Loss: 5.8674\n",
      "Test Batch [540/578], Loss: 5.2553\n",
      "Test Batch [550/578], Loss: 5.3356\n",
      "Test Batch [560/578], Loss: 5.3105\n",
      "Test Batch [570/578], Loss: 5.3106\n",
      "\n",
      "Test Loss: 5.1547\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:41.210378Z",
     "iopub.status.busy": "2025-05-08T17:19:41.210378Z",
     "iopub.status.idle": "2025-05-08T17:19:43.237267Z",
     "shell.execute_reply": "2025-05-08T17:19:43.237267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/578 for test dataset.\n",
      "  Processed batch 20/578 for test dataset.\n",
      "  Processed batch 30/578 for test dataset.\n",
      "  Processed batch 40/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 50/578 for test dataset.\n",
      "  Processed batch 60/578 for test dataset.\n",
      "  Processed batch 70/578 for test dataset.\n",
      "  Processed batch 80/578 for test dataset.\n",
      "  Processed batch 90/578 for test dataset.\n",
      "  Processed batch 100/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 110/578 for test dataset.\n",
      "  Processed batch 120/578 for test dataset.\n",
      "  Processed batch 130/578 for test dataset.\n",
      "  Processed batch 140/578 for test dataset.\n",
      "  Processed batch 150/578 for test dataset.\n",
      "  Processed batch 160/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 170/578 for test dataset.\n",
      "  Processed batch 180/578 for test dataset.\n",
      "  Processed batch 190/578 for test dataset.\n",
      "  Processed batch 200/578 for test dataset.\n",
      "  Processed batch 210/578 for test dataset.\n",
      "  Processed batch 220/578 for test dataset.\n",
      "  Processed batch 230/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 240/578 for test dataset.\n",
      "  Processed batch 250/578 for test dataset.\n",
      "  Processed batch 260/578 for test dataset.\n",
      "  Processed batch 270/578 for test dataset.\n",
      "  Processed batch 280/578 for test dataset.\n",
      "  Processed batch 290/578 for test dataset.\n",
      "  Processed batch 300/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 310/578 for test dataset.\n",
      "  Processed batch 320/578 for test dataset.\n",
      "  Processed batch 330/578 for test dataset.\n",
      "  Processed batch 340/578 for test dataset.\n",
      "  Processed batch 350/578 for test dataset.\n",
      "  Processed batch 360/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 370/578 for test dataset.\n",
      "  Processed batch 380/578 for test dataset.\n",
      "  Processed batch 390/578 for test dataset.\n",
      "  Processed batch 400/578 for test dataset.\n",
      "  Processed batch 410/578 for test dataset.\n",
      "  Processed batch 420/578 for test dataset.\n",
      "  Processed batch 430/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 440/578 for test dataset.\n",
      "  Processed batch 450/578 for test dataset.\n",
      "  Processed batch 460/578 for test dataset.\n",
      "  Processed batch 470/578 for test dataset.\n",
      "  Processed batch 480/578 for test dataset.\n",
      "  Processed batch 490/578 for test dataset.\n",
      "  Processed batch 500/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 510/578 for test dataset.\n",
      "  Processed batch 520/578 for test dataset.\n",
      "  Processed batch 530/578 for test dataset.\n",
      "  Processed batch 540/578 for test dataset.\n",
      "  Processed batch 550/578 for test dataset.\n",
      "  Processed batch 560/578 for test dataset.\n",
      "  Processed batch 570/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:43.240273Z",
     "iopub.status.busy": "2025-05-08T17:19:43.239272Z",
     "iopub.status.idle": "2025-05-08T17:19:43.243488Z",
     "shell.execute_reply": "2025-05-08T17:19:43.243488Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:43.246494Z",
     "iopub.status.busy": "2025-05-08T17:19:43.245493Z",
     "iopub.status.idle": "2025-05-08T17:19:47.757315Z",
     "shell.execute_reply": "2025-05-08T17:19:47.756710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:47.759323Z",
     "iopub.status.busy": "2025-05-08T17:19:47.759323Z",
     "iopub.status.idle": "2025-05-08T17:19:47.977591Z",
     "shell.execute_reply": "2025-05-08T17:19:47.977591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 95.56%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      0.80      0.89         5\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.83      1.00      0.91         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 96.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     65946\n",
      "           1       0.96      0.91      0.94      7573\n",
      "           2       0.80      0.88      0.84      3065\n",
      "           3       0.66      0.89      0.76      2660\n",
      "           4       0.93      0.89      0.91      6559\n",
      "           5       0.85      0.94      0.89      9223\n",
      "           6       0.92      0.86      0.89      7262\n",
      "           7       1.00      0.98      0.99     42801\n",
      "           8       0.99      1.00      0.99      2838\n",
      "\n",
      "    accuracy                           0.97    147927\n",
      "   macro avg       0.90      0.93      0.91    147927\n",
      "weighted avg       0.97      0.97      0.97    147927\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:47.979853Z",
     "iopub.status.busy": "2025-05-08T17:19:47.979853Z",
     "iopub.status.idle": "2025-05-08T17:19:47.984052Z",
     "shell.execute_reply": "2025-05-08T17:19:47.984052Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:47.986063Z",
     "iopub.status.busy": "2025-05-08T17:19:47.986063Z",
     "iopub.status.idle": "2025-05-08T17:19:48.193147Z",
     "shell.execute_reply": "2025-05-08T17:19:48.193147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:48.196153Z",
     "iopub.status.busy": "2025-05-08T17:19:48.195154Z",
     "iopub.status.idle": "2025-05-08T17:19:48.210160Z",
     "shell.execute_reply": "2025-05-08T17:19:48.210160Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:48.213166Z",
     "iopub.status.busy": "2025-05-08T17:19:48.213166Z",
     "iopub.status.idle": "2025-05-08T17:19:51.087791Z",
     "shell.execute_reply": "2025-05-08T17:19:51.087791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.2219  |  Val Loss: 2.1695\n",
      "Validation loss improved from inf to 2.1695.\n",
      "[Epoch 2/1000] Train Loss: 2.1833  |  Val Loss: 2.1338\n",
      "Validation loss improved from 2.1695 to 2.1338.\n",
      "[Epoch 3/1000] Train Loss: 2.1454  |  Val Loss: 2.0981\n",
      "Validation loss improved from 2.1338 to 2.0981.\n",
      "[Epoch 4/1000] Train Loss: 2.1078  |  Val Loss: 2.0636\n",
      "Validation loss improved from 2.0981 to 2.0636.\n",
      "[Epoch 5/1000] Train Loss: 2.0699  |  Val Loss: 2.0299\n",
      "Validation loss improved from 2.0636 to 2.0299.\n",
      "[Epoch 6/1000] Train Loss: 2.0336  |  Val Loss: 1.9973\n",
      "Validation loss improved from 2.0299 to 1.9973.\n",
      "[Epoch 7/1000] Train Loss: 2.0002  |  Val Loss: 1.9675\n",
      "Validation loss improved from 1.9973 to 1.9675.\n",
      "[Epoch 8/1000] Train Loss: 1.9702  |  Val Loss: 1.9385\n",
      "Validation loss improved from 1.9675 to 1.9385.\n",
      "[Epoch 9/1000] Train Loss: 1.9392  |  Val Loss: 1.9108\n",
      "Validation loss improved from 1.9385 to 1.9108.\n",
      "[Epoch 10/1000] Train Loss: 1.9088  |  Val Loss: 1.8847\n",
      "Validation loss improved from 1.9108 to 1.8847.\n",
      "[Epoch 11/1000] Train Loss: 1.8811  |  Val Loss: 1.8595\n",
      "Validation loss improved from 1.8847 to 1.8595.\n",
      "[Epoch 12/1000] Train Loss: 1.8543  |  Val Loss: 1.8347\n",
      "Validation loss improved from 1.8595 to 1.8347.\n",
      "[Epoch 13/1000] Train Loss: 1.8266  |  Val Loss: 1.8108\n",
      "Validation loss improved from 1.8347 to 1.8108.\n",
      "[Epoch 14/1000] Train Loss: 1.8008  |  Val Loss: 1.7867\n",
      "Validation loss improved from 1.8108 to 1.7867.\n",
      "[Epoch 15/1000] Train Loss: 1.7743  |  Val Loss: 1.7626\n",
      "Validation loss improved from 1.7867 to 1.7626.\n",
      "[Epoch 16/1000] Train Loss: 1.7486  |  Val Loss: 1.7396\n",
      "Validation loss improved from 1.7626 to 1.7396.\n",
      "[Epoch 17/1000] Train Loss: 1.7222  |  Val Loss: 1.7168\n",
      "Validation loss improved from 1.7396 to 1.7168.\n",
      "[Epoch 18/1000] Train Loss: 1.6972  |  Val Loss: 1.6941\n",
      "Validation loss improved from 1.7168 to 1.6941.\n",
      "[Epoch 19/1000] Train Loss: 1.6725  |  Val Loss: 1.6714\n",
      "Validation loss improved from 1.6941 to 1.6714.\n",
      "[Epoch 20/1000] Train Loss: 1.6490  |  Val Loss: 1.6479\n",
      "Validation loss improved from 1.6714 to 1.6479.\n",
      "[Epoch 21/1000] Train Loss: 1.6252  |  Val Loss: 1.6243\n",
      "Validation loss improved from 1.6479 to 1.6243.\n",
      "[Epoch 22/1000] Train Loss: 1.6012  |  Val Loss: 1.6011\n",
      "Validation loss improved from 1.6243 to 1.6011.\n",
      "[Epoch 23/1000] Train Loss: 1.5773  |  Val Loss: 1.5783\n",
      "Validation loss improved from 1.6011 to 1.5783.\n",
      "[Epoch 24/1000] Train Loss: 1.5547  |  Val Loss: 1.5551\n",
      "Validation loss improved from 1.5783 to 1.5551.\n",
      "[Epoch 25/1000] Train Loss: 1.5313  |  Val Loss: 1.5325\n",
      "Validation loss improved from 1.5551 to 1.5325.\n",
      "[Epoch 26/1000] Train Loss: 1.5096  |  Val Loss: 1.5100\n",
      "Validation loss improved from 1.5325 to 1.5100.\n",
      "[Epoch 27/1000] Train Loss: 1.4873  |  Val Loss: 1.4881\n",
      "Validation loss improved from 1.5100 to 1.4881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/1000] Train Loss: 1.4660  |  Val Loss: 1.4665\n",
      "Validation loss improved from 1.4881 to 1.4665.\n",
      "[Epoch 29/1000] Train Loss: 1.4440  |  Val Loss: 1.4453\n",
      "Validation loss improved from 1.4665 to 1.4453.\n",
      "[Epoch 30/1000] Train Loss: 1.4235  |  Val Loss: 1.4237\n",
      "Validation loss improved from 1.4453 to 1.4237.\n",
      "[Epoch 31/1000] Train Loss: 1.4019  |  Val Loss: 1.4024\n",
      "Validation loss improved from 1.4237 to 1.4024.\n",
      "[Epoch 32/1000] Train Loss: 1.3812  |  Val Loss: 1.3808\n",
      "Validation loss improved from 1.4024 to 1.3808.\n",
      "[Epoch 33/1000] Train Loss: 1.3597  |  Val Loss: 1.3595\n",
      "Validation loss improved from 1.3808 to 1.3595.\n",
      "[Epoch 34/1000] Train Loss: 1.3392  |  Val Loss: 1.3384\n",
      "Validation loss improved from 1.3595 to 1.3384.\n",
      "[Epoch 35/1000] Train Loss: 1.3180  |  Val Loss: 1.3178\n",
      "Validation loss improved from 1.3384 to 1.3178.\n",
      "[Epoch 36/1000] Train Loss: 1.2976  |  Val Loss: 1.2975\n",
      "Validation loss improved from 1.3178 to 1.2975.\n",
      "[Epoch 37/1000] Train Loss: 1.2774  |  Val Loss: 1.2776\n",
      "Validation loss improved from 1.2975 to 1.2776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/1000] Train Loss: 1.2576  |  Val Loss: 1.2580\n",
      "Validation loss improved from 1.2776 to 1.2580.\n",
      "[Epoch 39/1000] Train Loss: 1.2381  |  Val Loss: 1.2385\n",
      "Validation loss improved from 1.2580 to 1.2385.\n",
      "[Epoch 40/1000] Train Loss: 1.2187  |  Val Loss: 1.2195\n",
      "Validation loss improved from 1.2385 to 1.2195.\n",
      "[Epoch 41/1000] Train Loss: 1.1996  |  Val Loss: 1.2009\n",
      "Validation loss improved from 1.2195 to 1.2009.\n",
      "[Epoch 42/1000] Train Loss: 1.1809  |  Val Loss: 1.1827\n",
      "Validation loss improved from 1.2009 to 1.1827.\n",
      "[Epoch 43/1000] Train Loss: 1.1620  |  Val Loss: 1.1651\n",
      "Validation loss improved from 1.1827 to 1.1651.\n",
      "[Epoch 44/1000] Train Loss: 1.1441  |  Val Loss: 1.1474\n",
      "Validation loss improved from 1.1651 to 1.1474.\n",
      "[Epoch 45/1000] Train Loss: 1.1258  |  Val Loss: 1.1302\n",
      "Validation loss improved from 1.1474 to 1.1302.\n",
      "[Epoch 46/1000] Train Loss: 1.1085  |  Val Loss: 1.1132\n",
      "Validation loss improved from 1.1302 to 1.1132.\n",
      "[Epoch 47/1000] Train Loss: 1.0912  |  Val Loss: 1.0967\n",
      "Validation loss improved from 1.1132 to 1.0967.\n",
      "[Epoch 48/1000] Train Loss: 1.0748  |  Val Loss: 1.0805\n",
      "Validation loss improved from 1.0967 to 1.0805.\n",
      "[Epoch 49/1000] Train Loss: 1.0583  |  Val Loss: 1.0648\n",
      "Validation loss improved from 1.0805 to 1.0648.\n",
      "[Epoch 50/1000] Train Loss: 1.0423  |  Val Loss: 1.0495\n",
      "Validation loss improved from 1.0648 to 1.0495.\n",
      "[Epoch 51/1000] Train Loss: 1.0264  |  Val Loss: 1.0345\n",
      "Validation loss improved from 1.0495 to 1.0345.\n",
      "[Epoch 52/1000] Train Loss: 1.0111  |  Val Loss: 1.0201\n",
      "Validation loss improved from 1.0345 to 1.0201.\n",
      "[Epoch 53/1000] Train Loss: 0.9963  |  Val Loss: 1.0059\n",
      "Validation loss improved from 1.0201 to 1.0059.\n",
      "[Epoch 54/1000] Train Loss: 0.9815  |  Val Loss: 0.9923\n",
      "Validation loss improved from 1.0059 to 0.9923.\n",
      "[Epoch 55/1000] Train Loss: 0.9673  |  Val Loss: 0.9790\n",
      "Validation loss improved from 0.9923 to 0.9790.\n",
      "[Epoch 56/1000] Train Loss: 0.9531  |  Val Loss: 0.9658\n",
      "Validation loss improved from 0.9790 to 0.9658.\n",
      "[Epoch 57/1000] Train Loss: 0.9393  |  Val Loss: 0.9526\n",
      "Validation loss improved from 0.9658 to 0.9526.\n",
      "[Epoch 58/1000] Train Loss: 0.9257  |  Val Loss: 0.9399\n",
      "Validation loss improved from 0.9526 to 0.9399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/1000] Train Loss: 0.9123  |  Val Loss: 0.9274\n",
      "Validation loss improved from 0.9399 to 0.9274.\n",
      "[Epoch 60/1000] Train Loss: 0.8991  |  Val Loss: 0.9151\n",
      "Validation loss improved from 0.9274 to 0.9151.\n",
      "[Epoch 61/1000] Train Loss: 0.8860  |  Val Loss: 0.9028\n",
      "Validation loss improved from 0.9151 to 0.9028.\n",
      "[Epoch 62/1000] Train Loss: 0.8732  |  Val Loss: 0.8907\n",
      "Validation loss improved from 0.9028 to 0.8907.\n",
      "[Epoch 63/1000] Train Loss: 0.8608  |  Val Loss: 0.8789\n",
      "Validation loss improved from 0.8907 to 0.8789.\n",
      "[Epoch 64/1000] Train Loss: 0.8484  |  Val Loss: 0.8674\n",
      "Validation loss improved from 0.8789 to 0.8674.\n",
      "[Epoch 65/1000] Train Loss: 0.8366  |  Val Loss: 0.8562\n",
      "Validation loss improved from 0.8674 to 0.8562.\n",
      "[Epoch 66/1000] Train Loss: 0.8247  |  Val Loss: 0.8452\n",
      "Validation loss improved from 0.8562 to 0.8452.\n",
      "[Epoch 67/1000] Train Loss: 0.8133  |  Val Loss: 0.8344\n",
      "Validation loss improved from 0.8452 to 0.8344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] Train Loss: 0.8019  |  Val Loss: 0.8238\n",
      "Validation loss improved from 0.8344 to 0.8238.\n",
      "[Epoch 69/1000] Train Loss: 0.7909  |  Val Loss: 0.8135\n",
      "Validation loss improved from 0.8238 to 0.8135.\n",
      "[Epoch 70/1000] Train Loss: 0.7800  |  Val Loss: 0.8033\n",
      "Validation loss improved from 0.8135 to 0.8033.\n",
      "[Epoch 71/1000] Train Loss: 0.7692  |  Val Loss: 0.7932\n",
      "Validation loss improved from 0.8033 to 0.7932.\n",
      "[Epoch 72/1000] Train Loss: 0.7586  |  Val Loss: 0.7836\n",
      "Validation loss improved from 0.7932 to 0.7836.\n",
      "[Epoch 73/1000] Train Loss: 0.7484  |  Val Loss: 0.7737\n",
      "Validation loss improved from 0.7836 to 0.7737.\n",
      "[Epoch 74/1000] Train Loss: 0.7383  |  Val Loss: 0.7642\n",
      "Validation loss improved from 0.7737 to 0.7642.\n",
      "[Epoch 75/1000] Train Loss: 0.7279  |  Val Loss: 0.7545\n",
      "Validation loss improved from 0.7642 to 0.7545.\n",
      "[Epoch 76/1000] Train Loss: 0.7178  |  Val Loss: 0.7451\n",
      "Validation loss improved from 0.7545 to 0.7451.\n",
      "[Epoch 77/1000] Train Loss: 0.7078  |  Val Loss: 0.7355\n",
      "Validation loss improved from 0.7451 to 0.7355.\n",
      "[Epoch 78/1000] Train Loss: 0.6977  |  Val Loss: 0.7263\n",
      "Validation loss improved from 0.7355 to 0.7263.\n",
      "[Epoch 79/1000] Train Loss: 0.6880  |  Val Loss: 0.7171\n",
      "Validation loss improved from 0.7263 to 0.7171.\n",
      "[Epoch 80/1000] Train Loss: 0.6779  |  Val Loss: 0.7081\n",
      "Validation loss improved from 0.7171 to 0.7081.\n",
      "[Epoch 81/1000] Train Loss: 0.6684  |  Val Loss: 0.6993\n",
      "Validation loss improved from 0.7081 to 0.6993.\n",
      "[Epoch 82/1000] Train Loss: 0.6588  |  Val Loss: 0.6908\n",
      "Validation loss improved from 0.6993 to 0.6908.\n",
      "[Epoch 83/1000] Train Loss: 0.6496  |  Val Loss: 0.6824\n",
      "Validation loss improved from 0.6908 to 0.6824.\n",
      "[Epoch 84/1000] Train Loss: 0.6401  |  Val Loss: 0.6743\n",
      "Validation loss improved from 0.6824 to 0.6743.\n",
      "[Epoch 85/1000] Train Loss: 0.6315  |  Val Loss: 0.6662\n",
      "Validation loss improved from 0.6743 to 0.6662.\n",
      "[Epoch 86/1000] Train Loss: 0.6223  |  Val Loss: 0.6583\n",
      "Validation loss improved from 0.6662 to 0.6583.\n",
      "[Epoch 87/1000] Train Loss: 0.6135  |  Val Loss: 0.6503\n",
      "Validation loss improved from 0.6583 to 0.6503.\n",
      "[Epoch 88/1000] Train Loss: 0.6046  |  Val Loss: 0.6426\n",
      "Validation loss improved from 0.6503 to 0.6426.\n",
      "[Epoch 89/1000] Train Loss: 0.5960  |  Val Loss: 0.6350\n",
      "Validation loss improved from 0.6426 to 0.6350.\n",
      "[Epoch 90/1000] Train Loss: 0.5875  |  Val Loss: 0.6273\n",
      "Validation loss improved from 0.6350 to 0.6273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 91/1000] Train Loss: 0.5788  |  Val Loss: 0.6199\n",
      "Validation loss improved from 0.6273 to 0.6199.\n",
      "[Epoch 92/1000] Train Loss: 0.5704  |  Val Loss: 0.6124\n",
      "Validation loss improved from 0.6199 to 0.6124.\n",
      "[Epoch 93/1000] Train Loss: 0.5624  |  Val Loss: 0.6051\n",
      "Validation loss improved from 0.6124 to 0.6051.\n",
      "[Epoch 94/1000] Train Loss: 0.5540  |  Val Loss: 0.5979\n",
      "Validation loss improved from 0.6051 to 0.5979.\n",
      "[Epoch 95/1000] Train Loss: 0.5459  |  Val Loss: 0.5907\n",
      "Validation loss improved from 0.5979 to 0.5907.\n",
      "[Epoch 96/1000] Train Loss: 0.5378  |  Val Loss: 0.5836\n",
      "Validation loss improved from 0.5907 to 0.5836.\n",
      "[Epoch 97/1000] Train Loss: 0.5299  |  Val Loss: 0.5765\n",
      "Validation loss improved from 0.5836 to 0.5765.\n",
      "[Epoch 98/1000] Train Loss: 0.5220  |  Val Loss: 0.5695\n",
      "Validation loss improved from 0.5765 to 0.5695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 99/1000] Train Loss: 0.5143  |  Val Loss: 0.5626\n",
      "Validation loss improved from 0.5695 to 0.5626.\n",
      "[Epoch 100/1000] Train Loss: 0.5068  |  Val Loss: 0.5557\n",
      "Validation loss improved from 0.5626 to 0.5557.\n",
      "[Epoch 101/1000] Train Loss: 0.4992  |  Val Loss: 0.5486\n",
      "Validation loss improved from 0.5557 to 0.5486.\n",
      "[Epoch 102/1000] Train Loss: 0.4920  |  Val Loss: 0.5417\n",
      "Validation loss improved from 0.5486 to 0.5417.\n",
      "[Epoch 103/1000] Train Loss: 0.4845  |  Val Loss: 0.5352\n",
      "Validation loss improved from 0.5417 to 0.5352.\n",
      "[Epoch 104/1000] Train Loss: 0.4774  |  Val Loss: 0.5287\n",
      "Validation loss improved from 0.5352 to 0.5287.\n",
      "[Epoch 105/1000] Train Loss: 0.4701  |  Val Loss: 0.5223\n",
      "Validation loss improved from 0.5287 to 0.5223.\n",
      "[Epoch 106/1000] Train Loss: 0.4630  |  Val Loss: 0.5161\n",
      "Validation loss improved from 0.5223 to 0.5161.\n",
      "[Epoch 107/1000] Train Loss: 0.4563  |  Val Loss: 0.5098\n",
      "Validation loss improved from 0.5161 to 0.5098.\n",
      "[Epoch 108/1000] Train Loss: 0.4493  |  Val Loss: 0.5036\n",
      "Validation loss improved from 0.5098 to 0.5036.\n",
      "[Epoch 109/1000] Train Loss: 0.4427  |  Val Loss: 0.4973\n",
      "Validation loss improved from 0.5036 to 0.4973.\n",
      "[Epoch 110/1000] Train Loss: 0.4360  |  Val Loss: 0.4912\n",
      "Validation loss improved from 0.4973 to 0.4912.\n",
      "[Epoch 111/1000] Train Loss: 0.4295  |  Val Loss: 0.4851\n",
      "Validation loss improved from 0.4912 to 0.4851.\n",
      "[Epoch 112/1000] Train Loss: 0.4230  |  Val Loss: 0.4789\n",
      "Validation loss improved from 0.4851 to 0.4789.\n",
      "[Epoch 113/1000] Train Loss: 0.4166  |  Val Loss: 0.4728\n",
      "Validation loss improved from 0.4789 to 0.4728.\n",
      "[Epoch 114/1000] Train Loss: 0.4103  |  Val Loss: 0.4668\n",
      "Validation loss improved from 0.4728 to 0.4668.\n",
      "[Epoch 115/1000] Train Loss: 0.4038  |  Val Loss: 0.4609\n",
      "Validation loss improved from 0.4668 to 0.4609.\n",
      "[Epoch 116/1000] Train Loss: 0.3979  |  Val Loss: 0.4552\n",
      "Validation loss improved from 0.4609 to 0.4552.\n",
      "[Epoch 117/1000] Train Loss: 0.3920  |  Val Loss: 0.4495\n",
      "Validation loss improved from 0.4552 to 0.4495.\n",
      "[Epoch 118/1000] Train Loss: 0.3861  |  Val Loss: 0.4441\n",
      "Validation loss improved from 0.4495 to 0.4441.\n",
      "[Epoch 119/1000] Train Loss: 0.3800  |  Val Loss: 0.4386\n",
      "Validation loss improved from 0.4441 to 0.4386.\n",
      "[Epoch 120/1000] Train Loss: 0.3743  |  Val Loss: 0.4334\n",
      "Validation loss improved from 0.4386 to 0.4334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 121/1000] Train Loss: 0.3686  |  Val Loss: 0.4281\n",
      "Validation loss improved from 0.4334 to 0.4281.\n",
      "[Epoch 122/1000] Train Loss: 0.3630  |  Val Loss: 0.4230\n",
      "Validation loss improved from 0.4281 to 0.4230.\n",
      "[Epoch 123/1000] Train Loss: 0.3573  |  Val Loss: 0.4180\n",
      "Validation loss improved from 0.4230 to 0.4180.\n",
      "[Epoch 124/1000] Train Loss: 0.3520  |  Val Loss: 0.4130\n",
      "Validation loss improved from 0.4180 to 0.4130.\n",
      "[Epoch 125/1000] Train Loss: 0.3466  |  Val Loss: 0.4080\n",
      "Validation loss improved from 0.4130 to 0.4080.\n",
      "[Epoch 126/1000] Train Loss: 0.3412  |  Val Loss: 0.4031\n",
      "Validation loss improved from 0.4080 to 0.4031.\n",
      "[Epoch 127/1000] Train Loss: 0.3360  |  Val Loss: 0.3983\n",
      "Validation loss improved from 0.4031 to 0.3983.\n",
      "[Epoch 128/1000] Train Loss: 0.3308  |  Val Loss: 0.3935\n",
      "Validation loss improved from 0.3983 to 0.3935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/1000] Train Loss: 0.3257  |  Val Loss: 0.3887\n",
      "Validation loss improved from 0.3935 to 0.3887.\n",
      "[Epoch 130/1000] Train Loss: 0.3205  |  Val Loss: 0.3842\n",
      "Validation loss improved from 0.3887 to 0.3842.\n",
      "[Epoch 131/1000] Train Loss: 0.3151  |  Val Loss: 0.3799\n",
      "Validation loss improved from 0.3842 to 0.3799.\n",
      "[Epoch 132/1000] Train Loss: 0.3100  |  Val Loss: 0.3755\n",
      "Validation loss improved from 0.3799 to 0.3755.\n",
      "[Epoch 133/1000] Train Loss: 0.3048  |  Val Loss: 0.3714\n",
      "Validation loss improved from 0.3755 to 0.3714.\n",
      "[Epoch 134/1000] Train Loss: 0.3004  |  Val Loss: 0.3681\n",
      "Validation loss improved from 0.3714 to 0.3681.\n",
      "[Epoch 135/1000] Train Loss: 0.2955  |  Val Loss: 0.3645\n",
      "Validation loss improved from 0.3681 to 0.3645.\n",
      "[Epoch 136/1000] Train Loss: 0.2912  |  Val Loss: 0.3611\n",
      "Validation loss improved from 0.3645 to 0.3611.\n",
      "[Epoch 137/1000] Train Loss: 0.2871  |  Val Loss: 0.3578\n",
      "Validation loss improved from 0.3611 to 0.3578.\n",
      "[Epoch 138/1000] Train Loss: 0.2828  |  Val Loss: 0.3543\n",
      "Validation loss improved from 0.3578 to 0.3543.\n",
      "[Epoch 139/1000] Train Loss: 0.2791  |  Val Loss: 0.3512\n",
      "Validation loss improved from 0.3543 to 0.3512.\n",
      "[Epoch 140/1000] Train Loss: 0.2748  |  Val Loss: 0.3477\n",
      "Validation loss improved from 0.3512 to 0.3477.\n",
      "[Epoch 141/1000] Train Loss: 0.2710  |  Val Loss: 0.3443\n",
      "Validation loss improved from 0.3477 to 0.3443.\n",
      "[Epoch 142/1000] Train Loss: 0.2671  |  Val Loss: 0.3407\n",
      "Validation loss improved from 0.3443 to 0.3407.\n",
      "[Epoch 143/1000] Train Loss: 0.2635  |  Val Loss: 0.3373\n",
      "Validation loss improved from 0.3407 to 0.3373.\n",
      "[Epoch 144/1000] Train Loss: 0.2597  |  Val Loss: 0.3342\n",
      "Validation loss improved from 0.3373 to 0.3342.\n",
      "[Epoch 145/1000] Train Loss: 0.2559  |  Val Loss: 0.3310\n",
      "Validation loss improved from 0.3342 to 0.3310.\n",
      "[Epoch 146/1000] Train Loss: 0.2523  |  Val Loss: 0.3275\n",
      "Validation loss improved from 0.3310 to 0.3275.\n",
      "[Epoch 147/1000] Train Loss: 0.2489  |  Val Loss: 0.3242\n",
      "Validation loss improved from 0.3275 to 0.3242.\n",
      "[Epoch 148/1000] Train Loss: 0.2453  |  Val Loss: 0.3211\n",
      "Validation loss improved from 0.3242 to 0.3211.\n",
      "[Epoch 149/1000] Train Loss: 0.2419  |  Val Loss: 0.3179\n",
      "Validation loss improved from 0.3211 to 0.3179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/1000] Train Loss: 0.2386  |  Val Loss: 0.3150\n",
      "Validation loss improved from 0.3179 to 0.3150.\n",
      "[Epoch 151/1000] Train Loss: 0.2352  |  Val Loss: 0.3123\n",
      "Validation loss improved from 0.3150 to 0.3123.\n",
      "[Epoch 152/1000] Train Loss: 0.2323  |  Val Loss: 0.3097\n",
      "Validation loss improved from 0.3123 to 0.3097.\n",
      "[Epoch 153/1000] Train Loss: 0.2291  |  Val Loss: 0.3070\n",
      "Validation loss improved from 0.3097 to 0.3070.\n",
      "[Epoch 154/1000] Train Loss: 0.2260  |  Val Loss: 0.3046\n",
      "Validation loss improved from 0.3070 to 0.3046.\n",
      "[Epoch 155/1000] Train Loss: 0.2230  |  Val Loss: 0.3021\n",
      "Validation loss improved from 0.3046 to 0.3021.\n",
      "[Epoch 156/1000] Train Loss: 0.2200  |  Val Loss: 0.2996\n",
      "Validation loss improved from 0.3021 to 0.2996.\n",
      "[Epoch 157/1000] Train Loss: 0.2172  |  Val Loss: 0.2976\n",
      "Validation loss improved from 0.2996 to 0.2976.\n",
      "[Epoch 158/1000] Train Loss: 0.2143  |  Val Loss: 0.2956\n",
      "Validation loss improved from 0.2976 to 0.2956.\n",
      "[Epoch 159/1000] Train Loss: 0.2116  |  Val Loss: 0.2933\n",
      "Validation loss improved from 0.2956 to 0.2933.\n",
      "[Epoch 160/1000] Train Loss: 0.2089  |  Val Loss: 0.2912\n",
      "Validation loss improved from 0.2933 to 0.2912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 161/1000] Train Loss: 0.2060  |  Val Loss: 0.2890\n",
      "Validation loss improved from 0.2912 to 0.2890.\n",
      "[Epoch 162/1000] Train Loss: 0.2034  |  Val Loss: 0.2870\n",
      "Validation loss improved from 0.2890 to 0.2870.\n",
      "[Epoch 163/1000] Train Loss: 0.2010  |  Val Loss: 0.2849\n",
      "Validation loss improved from 0.2870 to 0.2849.\n",
      "[Epoch 164/1000] Train Loss: 0.1985  |  Val Loss: 0.2832\n",
      "Validation loss improved from 0.2849 to 0.2832.\n",
      "[Epoch 165/1000] Train Loss: 0.1957  |  Val Loss: 0.2811\n",
      "Validation loss improved from 0.2832 to 0.2811.\n",
      "[Epoch 166/1000] Train Loss: 0.1934  |  Val Loss: 0.2792\n",
      "Validation loss improved from 0.2811 to 0.2792.\n",
      "[Epoch 167/1000] Train Loss: 0.1910  |  Val Loss: 0.2774\n",
      "Validation loss improved from 0.2792 to 0.2774.\n",
      "[Epoch 168/1000] Train Loss: 0.1887  |  Val Loss: 0.2757\n",
      "Validation loss improved from 0.2774 to 0.2757.\n",
      "[Epoch 169/1000] Train Loss: 0.1862  |  Val Loss: 0.2740\n",
      "Validation loss improved from 0.2757 to 0.2740.\n",
      "[Epoch 170/1000] Train Loss: 0.1840  |  Val Loss: 0.2723\n",
      "Validation loss improved from 0.2740 to 0.2723.\n",
      "[Epoch 171/1000] Train Loss: 0.1819  |  Val Loss: 0.2708\n",
      "Validation loss improved from 0.2723 to 0.2708.\n",
      "[Epoch 172/1000] Train Loss: 0.1798  |  Val Loss: 0.2695\n",
      "Validation loss improved from 0.2708 to 0.2695.\n",
      "[Epoch 173/1000] Train Loss: 0.1774  |  Val Loss: 0.2677\n",
      "Validation loss improved from 0.2695 to 0.2677.\n",
      "[Epoch 174/1000] Train Loss: 0.1755  |  Val Loss: 0.2657\n",
      "Validation loss improved from 0.2677 to 0.2657.\n",
      "[Epoch 175/1000] Train Loss: 0.1733  |  Val Loss: 0.2640\n",
      "Validation loss improved from 0.2657 to 0.2640.\n",
      "[Epoch 176/1000] Train Loss: 0.1713  |  Val Loss: 0.2625\n",
      "Validation loss improved from 0.2640 to 0.2625.\n",
      "[Epoch 177/1000] Train Loss: 0.1694  |  Val Loss: 0.2612\n",
      "Validation loss improved from 0.2625 to 0.2612.\n",
      "[Epoch 178/1000] Train Loss: 0.1674  |  Val Loss: 0.2600\n",
      "Validation loss improved from 0.2612 to 0.2600.\n",
      "[Epoch 179/1000] Train Loss: 0.1654  |  Val Loss: 0.2587\n",
      "Validation loss improved from 0.2600 to 0.2587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 180/1000] Train Loss: 0.1636  |  Val Loss: 0.2573\n",
      "Validation loss improved from 0.2587 to 0.2573.\n",
      "[Epoch 181/1000] Train Loss: 0.1620  |  Val Loss: 0.2556\n",
      "Validation loss improved from 0.2573 to 0.2556.\n",
      "[Epoch 182/1000] Train Loss: 0.1599  |  Val Loss: 0.2544\n",
      "Validation loss improved from 0.2556 to 0.2544.\n",
      "[Epoch 183/1000] Train Loss: 0.1581  |  Val Loss: 0.2533\n",
      "Validation loss improved from 0.2544 to 0.2533.\n",
      "[Epoch 184/1000] Train Loss: 0.1565  |  Val Loss: 0.2525\n",
      "Validation loss improved from 0.2533 to 0.2525.\n",
      "[Epoch 185/1000] Train Loss: 0.1548  |  Val Loss: 0.2513\n",
      "Validation loss improved from 0.2525 to 0.2513.\n",
      "[Epoch 186/1000] Train Loss: 0.1530  |  Val Loss: 0.2503\n",
      "Validation loss improved from 0.2513 to 0.2503.\n",
      "[Epoch 187/1000] Train Loss: 0.1514  |  Val Loss: 0.2485\n",
      "Validation loss improved from 0.2503 to 0.2485.\n",
      "[Epoch 188/1000] Train Loss: 0.1496  |  Val Loss: 0.2471\n",
      "Validation loss improved from 0.2485 to 0.2471.\n",
      "[Epoch 189/1000] Train Loss: 0.1480  |  Val Loss: 0.2464\n",
      "Validation loss improved from 0.2471 to 0.2464.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 190/1000] Train Loss: 0.1465  |  Val Loss: 0.2448\n",
      "Validation loss improved from 0.2464 to 0.2448.\n",
      "[Epoch 191/1000] Train Loss: 0.1448  |  Val Loss: 0.2438\n",
      "Validation loss improved from 0.2448 to 0.2438.\n",
      "[Epoch 192/1000] Train Loss: 0.1434  |  Val Loss: 0.2429\n",
      "Validation loss improved from 0.2438 to 0.2429.\n",
      "[Epoch 193/1000] Train Loss: 0.1419  |  Val Loss: 0.2420\n",
      "Validation loss improved from 0.2429 to 0.2420.\n",
      "[Epoch 194/1000] Train Loss: 0.1403  |  Val Loss: 0.2407\n",
      "Validation loss improved from 0.2420 to 0.2407.\n",
      "[Epoch 195/1000] Train Loss: 0.1388  |  Val Loss: 0.2395\n",
      "Validation loss improved from 0.2407 to 0.2395.\n",
      "[Epoch 196/1000] Train Loss: 0.1374  |  Val Loss: 0.2381\n",
      "Validation loss improved from 0.2395 to 0.2381.\n",
      "[Epoch 197/1000] Train Loss: 0.1360  |  Val Loss: 0.2371\n",
      "Validation loss improved from 0.2381 to 0.2371.\n",
      "[Epoch 198/1000] Train Loss: 0.1347  |  Val Loss: 0.2364\n",
      "Validation loss improved from 0.2371 to 0.2364.\n",
      "[Epoch 199/1000] Train Loss: 0.1331  |  Val Loss: 0.2354\n",
      "Validation loss improved from 0.2364 to 0.2354.\n",
      "[Epoch 200/1000] Train Loss: 0.1319  |  Val Loss: 0.2342\n",
      "Validation loss improved from 0.2354 to 0.2342.\n",
      "[Epoch 201/1000] Train Loss: 0.1305  |  Val Loss: 0.2334\n",
      "Validation loss improved from 0.2342 to 0.2334.\n",
      "[Epoch 202/1000] Train Loss: 0.1291  |  Val Loss: 0.2327\n",
      "Validation loss improved from 0.2334 to 0.2327.\n",
      "[Epoch 203/1000] Train Loss: 0.1279  |  Val Loss: 0.2323\n",
      "Validation loss improved from 0.2327 to 0.2323.\n",
      "[Epoch 204/1000] Train Loss: 0.1265  |  Val Loss: 0.2314\n",
      "Validation loss improved from 0.2323 to 0.2314.\n",
      "[Epoch 205/1000] Train Loss: 0.1253  |  Val Loss: 0.2304\n",
      "Validation loss improved from 0.2314 to 0.2304.\n",
      "[Epoch 206/1000] Train Loss: 0.1241  |  Val Loss: 0.2294\n",
      "Validation loss improved from 0.2304 to 0.2294.\n",
      "[Epoch 207/1000] Train Loss: 0.1229  |  Val Loss: 0.2288\n",
      "Validation loss improved from 0.2294 to 0.2288.\n",
      "[Epoch 208/1000] Train Loss: 0.1218  |  Val Loss: 0.2282\n",
      "Validation loss improved from 0.2288 to 0.2282.\n",
      "[Epoch 209/1000] Train Loss: 0.1205  |  Val Loss: 0.2272\n",
      "Validation loss improved from 0.2282 to 0.2272.\n",
      "[Epoch 210/1000] Train Loss: 0.1194  |  Val Loss: 0.2262\n",
      "Validation loss improved from 0.2272 to 0.2262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 211/1000] Train Loss: 0.1182  |  Val Loss: 0.2254\n",
      "Validation loss improved from 0.2262 to 0.2254.\n",
      "[Epoch 212/1000] Train Loss: 0.1171  |  Val Loss: 0.2248\n",
      "Validation loss improved from 0.2254 to 0.2248.\n",
      "[Epoch 213/1000] Train Loss: 0.1159  |  Val Loss: 0.2242\n",
      "Validation loss improved from 0.2248 to 0.2242.\n",
      "[Epoch 214/1000] Train Loss: 0.1149  |  Val Loss: 0.2237\n",
      "Validation loss improved from 0.2242 to 0.2237.\n",
      "[Epoch 215/1000] Train Loss: 0.1138  |  Val Loss: 0.2233\n",
      "Validation loss improved from 0.2237 to 0.2233.\n",
      "[Epoch 216/1000] Train Loss: 0.1126  |  Val Loss: 0.2229\n",
      "Validation loss improved from 0.2233 to 0.2229.\n",
      "[Epoch 217/1000] Train Loss: 0.1116  |  Val Loss: 0.2226\n",
      "Validation loss improved from 0.2229 to 0.2226.\n",
      "[Epoch 218/1000] Train Loss: 0.1107  |  Val Loss: 0.2223\n",
      "Validation loss improved from 0.2226 to 0.2223.\n",
      "[Epoch 219/1000] Train Loss: 0.1095  |  Val Loss: 0.2215\n",
      "Validation loss improved from 0.2223 to 0.2215.\n",
      "[Epoch 220/1000] Train Loss: 0.1088  |  Val Loss: 0.2204\n",
      "Validation loss improved from 0.2215 to 0.2204.\n",
      "[Epoch 221/1000] Train Loss: 0.1075  |  Val Loss: 0.2198\n",
      "Validation loss improved from 0.2204 to 0.2198.\n",
      "[Epoch 222/1000] Train Loss: 0.1066  |  Val Loss: 0.2194\n",
      "Validation loss improved from 0.2198 to 0.2194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 223/1000] Train Loss: 0.1054  |  Val Loss: 0.2190\n",
      "Validation loss improved from 0.2194 to 0.2190.\n",
      "[Epoch 224/1000] Train Loss: 0.1046  |  Val Loss: 0.2187\n",
      "Validation loss improved from 0.2190 to 0.2187.\n",
      "[Epoch 225/1000] Train Loss: 0.1037  |  Val Loss: 0.2182\n",
      "Validation loss improved from 0.2187 to 0.2182.\n",
      "[Epoch 226/1000] Train Loss: 0.1027  |  Val Loss: 0.2174\n",
      "Validation loss improved from 0.2182 to 0.2174.\n",
      "[Epoch 227/1000] Train Loss: 0.1019  |  Val Loss: 0.2166\n",
      "Validation loss improved from 0.2174 to 0.2166.\n",
      "[Epoch 228/1000] Train Loss: 0.1008  |  Val Loss: 0.2161\n",
      "Validation loss improved from 0.2166 to 0.2161.\n",
      "[Epoch 229/1000] Train Loss: 0.0999  |  Val Loss: 0.2156\n",
      "Validation loss improved from 0.2161 to 0.2156.\n",
      "[Epoch 230/1000] Train Loss: 0.0992  |  Val Loss: 0.2153\n",
      "Validation loss improved from 0.2156 to 0.2153.\n",
      "[Epoch 231/1000] Train Loss: 0.0981  |  Val Loss: 0.2150\n",
      "Validation loss improved from 0.2153 to 0.2150.\n",
      "[Epoch 232/1000] Train Loss: 0.0972  |  Val Loss: 0.2144\n",
      "Validation loss improved from 0.2150 to 0.2144.\n",
      "[Epoch 233/1000] Train Loss: 0.0965  |  Val Loss: 0.2144\n",
      "Validation loss improved from 0.2144 to 0.2144.\n",
      "[Epoch 234/1000] Train Loss: 0.0955  |  Val Loss: 0.2137\n",
      "Validation loss improved from 0.2144 to 0.2137.\n",
      "[Epoch 235/1000] Train Loss: 0.0948  |  Val Loss: 0.2131\n",
      "Validation loss improved from 0.2137 to 0.2131.\n",
      "[Epoch 236/1000] Train Loss: 0.0939  |  Val Loss: 0.2126\n",
      "Validation loss improved from 0.2131 to 0.2126.\n",
      "[Epoch 237/1000] Train Loss: 0.0931  |  Val Loss: 0.2119\n",
      "Validation loss improved from 0.2126 to 0.2119.\n",
      "[Epoch 238/1000] Train Loss: 0.0922  |  Val Loss: 0.2118\n",
      "Validation loss improved from 0.2119 to 0.2118.\n",
      "[Epoch 239/1000] Train Loss: 0.0913  |  Val Loss: 0.2115\n",
      "Validation loss improved from 0.2118 to 0.2115.\n",
      "[Epoch 240/1000] Train Loss: 0.0906  |  Val Loss: 0.2111\n",
      "Validation loss improved from 0.2115 to 0.2111.\n",
      "[Epoch 241/1000] Train Loss: 0.0899  |  Val Loss: 0.2107\n",
      "Validation loss improved from 0.2111 to 0.2107.\n",
      "[Epoch 242/1000] Train Loss: 0.0891  |  Val Loss: 0.2104\n",
      "Validation loss improved from 0.2107 to 0.2104.\n",
      "[Epoch 243/1000] Train Loss: 0.0884  |  Val Loss: 0.2102\n",
      "Validation loss improved from 0.2104 to 0.2102.\n",
      "[Epoch 244/1000] Train Loss: 0.0875  |  Val Loss: 0.2098\n",
      "Validation loss improved from 0.2102 to 0.2098.\n",
      "[Epoch 245/1000] Train Loss: 0.0868  |  Val Loss: 0.2095\n",
      "Validation loss improved from 0.2098 to 0.2095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 246/1000] Train Loss: 0.0859  |  Val Loss: 0.2093\n",
      "Validation loss improved from 0.2095 to 0.2093.\n",
      "[Epoch 247/1000] Train Loss: 0.0852  |  Val Loss: 0.2091\n",
      "Validation loss improved from 0.2093 to 0.2091.\n",
      "[Epoch 248/1000] Train Loss: 0.0844  |  Val Loss: 0.2090\n",
      "Validation loss improved from 0.2091 to 0.2090.\n",
      "[Epoch 249/1000] Train Loss: 0.0837  |  Val Loss: 0.2092\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 250/1000] Train Loss: 0.0830  |  Val Loss: 0.2089\n",
      "Validation loss improved from 0.2090 to 0.2089.\n",
      "[Epoch 251/1000] Train Loss: 0.0822  |  Val Loss: 0.2085\n",
      "Validation loss improved from 0.2089 to 0.2085.\n",
      "[Epoch 252/1000] Train Loss: 0.0816  |  Val Loss: 0.2085\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 253/1000] Train Loss: 0.0808  |  Val Loss: 0.2079\n",
      "Validation loss improved from 0.2085 to 0.2079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 254/1000] Train Loss: 0.0801  |  Val Loss: 0.2076\n",
      "Validation loss improved from 0.2079 to 0.2076.\n",
      "[Epoch 255/1000] Train Loss: 0.0795  |  Val Loss: 0.2074\n",
      "Validation loss improved from 0.2076 to 0.2074.\n",
      "[Epoch 256/1000] Train Loss: 0.0788  |  Val Loss: 0.2070\n",
      "Validation loss improved from 0.2074 to 0.2070.\n",
      "[Epoch 257/1000] Train Loss: 0.0781  |  Val Loss: 0.2067\n",
      "Validation loss improved from 0.2070 to 0.2067.\n",
      "[Epoch 258/1000] Train Loss: 0.0775  |  Val Loss: 0.2067\n",
      "Validation loss improved from 0.2067 to 0.2067.\n",
      "[Epoch 259/1000] Train Loss: 0.0769  |  Val Loss: 0.2067\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 260/1000] Train Loss: 0.0762  |  Val Loss: 0.2062\n",
      "Validation loss improved from 0.2067 to 0.2062.\n",
      "[Epoch 261/1000] Train Loss: 0.0758  |  Val Loss: 0.2058\n",
      "Validation loss improved from 0.2062 to 0.2058.\n",
      "[Epoch 262/1000] Train Loss: 0.0750  |  Val Loss: 0.2060\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 263/1000] Train Loss: 0.0744  |  Val Loss: 0.2056\n",
      "Validation loss improved from 0.2058 to 0.2056.\n",
      "[Epoch 264/1000] Train Loss: 0.0737  |  Val Loss: 0.2054\n",
      "Validation loss improved from 0.2056 to 0.2054.\n",
      "[Epoch 265/1000] Train Loss: 0.0733  |  Val Loss: 0.2056\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 266/1000] Train Loss: 0.0727  |  Val Loss: 0.2056\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 267/1000] Train Loss: 0.0721  |  Val Loss: 0.2056\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 268/1000] Train Loss: 0.0715  |  Val Loss: 0.2052\n",
      "Validation loss improved from 0.2054 to 0.2052.\n",
      "[Epoch 269/1000] Train Loss: 0.0709  |  Val Loss: 0.2049\n",
      "Validation loss improved from 0.2052 to 0.2049.\n",
      "[Epoch 270/1000] Train Loss: 0.0703  |  Val Loss: 0.2044\n",
      "Validation loss improved from 0.2049 to 0.2044.\n",
      "[Epoch 271/1000] Train Loss: 0.0698  |  Val Loss: 0.2039\n",
      "Validation loss improved from 0.2044 to 0.2039.\n",
      "[Epoch 272/1000] Train Loss: 0.0694  |  Val Loss: 0.2031\n",
      "Validation loss improved from 0.2039 to 0.2031.\n",
      "[Epoch 273/1000] Train Loss: 0.0688  |  Val Loss: 0.2029\n",
      "Validation loss improved from 0.2031 to 0.2029.\n",
      "[Epoch 274/1000] Train Loss: 0.0684  |  Val Loss: 0.2031\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 275/1000] Train Loss: 0.0678  |  Val Loss: 0.2031\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 276/1000] Train Loss: 0.0672  |  Val Loss: 0.2035\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 277/1000] Train Loss: 0.0667  |  Val Loss: 0.2036\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 278/1000] Train Loss: 0.0662  |  Val Loss: 0.2039\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 279/1000] Train Loss: 0.0658  |  Val Loss: 0.2037\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 280/1000] Train Loss: 0.0651  |  Val Loss: 0.2039\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 281/1000] Train Loss: 0.0647  |  Val Loss: 0.2041\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 282/1000] Train Loss: 0.0643  |  Val Loss: 0.2040\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 283/1000] Train Loss: 0.0638  |  Val Loss: 0.2044\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 284/1000] Train Loss: 0.0633  |  Val Loss: 0.2042\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 285/1000] Train Loss: 0.0629  |  Val Loss: 0.2036\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 286/1000] Train Loss: 0.0625  |  Val Loss: 0.2034\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 287/1000] Train Loss: 0.0619  |  Val Loss: 0.2030\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 288/1000] Train Loss: 0.0615  |  Val Loss: 0.2027\n",
      "Validation loss improved from 0.2029 to 0.2027.\n",
      "[Epoch 289/1000] Train Loss: 0.0610  |  Val Loss: 0.2028\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 290/1000] Train Loss: 0.0606  |  Val Loss: 0.2028\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 291/1000] Train Loss: 0.0600  |  Val Loss: 0.2029\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 292/1000] Train Loss: 0.0596  |  Val Loss: 0.2033\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 293/1000] Train Loss: 0.0592  |  Val Loss: 0.2032\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 294/1000] Train Loss: 0.0587  |  Val Loss: 0.2036\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 295/1000] Train Loss: 0.0583  |  Val Loss: 0.2037\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 296/1000] Train Loss: 0.0578  |  Val Loss: 0.2037\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 297/1000] Train Loss: 0.0576  |  Val Loss: 0.2042\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 298/1000] Train Loss: 0.0570  |  Val Loss: 0.2039\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 299/1000] Train Loss: 0.0566  |  Val Loss: 0.2040\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 300/1000] Train Loss: 0.0561  |  Val Loss: 0.2037\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 301/1000] Train Loss: 0.0559  |  Val Loss: 0.2031\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 302/1000] Train Loss: 0.0555  |  Val Loss: 0.2026\n",
      "Validation loss improved from 0.2027 to 0.2026.\n",
      "[Epoch 303/1000] Train Loss: 0.0550  |  Val Loss: 0.2031\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 304/1000] Train Loss: 0.0546  |  Val Loss: 0.2032\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 305/1000] Train Loss: 0.0543  |  Val Loss: 0.2035\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 306/1000] Train Loss: 0.0539  |  Val Loss: 0.2036\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 307/1000] Train Loss: 0.0535  |  Val Loss: 0.2033\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 308/1000] Train Loss: 0.0531  |  Val Loss: 0.2033\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 309/1000] Train Loss: 0.0528  |  Val Loss: 0.2030\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 310/1000] Train Loss: 0.0524  |  Val Loss: 0.2030\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 311/1000] Train Loss: 0.0520  |  Val Loss: 0.2029\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 312/1000] Train Loss: 0.0517  |  Val Loss: 0.2030\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 313/1000] Train Loss: 0.0514  |  Val Loss: 0.2032\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 314/1000] Train Loss: 0.0510  |  Val Loss: 0.2032\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 315/1000] Train Loss: 0.0508  |  Val Loss: 0.2039\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 316/1000] Train Loss: 0.0505  |  Val Loss: 0.2043\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 317/1000] Train Loss: 0.0500  |  Val Loss: 0.2040\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 318/1000] Train Loss: 0.0497  |  Val Loss: 0.2036\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 319/1000] Train Loss: 0.0493  |  Val Loss: 0.2035\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 320/1000] Train Loss: 0.0490  |  Val Loss: 0.2035\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 321/1000] Train Loss: 0.0486  |  Val Loss: 0.2037\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 322/1000] Train Loss: 0.0484  |  Val Loss: 0.2046\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 323/1000] Train Loss: 0.0481  |  Val Loss: 0.2050\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 324/1000] Train Loss: 0.0478  |  Val Loss: 0.2053\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 325/1000] Train Loss: 0.0474  |  Val Loss: 0.2054\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 326/1000] Train Loss: 0.0473  |  Val Loss: 0.2054\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 327/1000] Train Loss: 0.0468  |  Val Loss: 0.2054\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 328/1000] Train Loss: 0.0465  |  Val Loss: 0.2052\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 329/1000] Train Loss: 0.0463  |  Val Loss: 0.2055\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 330/1000] Train Loss: 0.0459  |  Val Loss: 0.2050\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 331/1000] Train Loss: 0.0456  |  Val Loss: 0.2048\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 332/1000] Train Loss: 0.0455  |  Val Loss: 0.2049\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 333/1000] Train Loss: 0.0452  |  Val Loss: 0.2051\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 334/1000] Train Loss: 0.0449  |  Val Loss: 0.2051\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 335/1000] Train Loss: 0.0445  |  Val Loss: 0.2056\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 336/1000] Train Loss: 0.0443  |  Val Loss: 0.2059\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 337/1000] Train Loss: 0.0439  |  Val Loss: 0.2064\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 338/1000] Train Loss: 0.0437  |  Val Loss: 0.2069\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 339/1000] Train Loss: 0.0435  |  Val Loss: 0.2071\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 340/1000] Train Loss: 0.0432  |  Val Loss: 0.2071\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 341/1000] Train Loss: 0.0430  |  Val Loss: 0.2066\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 342/1000] Train Loss: 0.0426  |  Val Loss: 0.2066\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 343/1000] Train Loss: 0.0424  |  Val Loss: 0.2069\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 344/1000] Train Loss: 0.0423  |  Val Loss: 0.2076\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 345/1000] Train Loss: 0.0420  |  Val Loss: 0.2071\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 346/1000] Train Loss: 0.0417  |  Val Loss: 0.2077\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 347/1000] Train Loss: 0.0414  |  Val Loss: 0.2079\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 348/1000] Train Loss: 0.0413  |  Val Loss: 0.2076\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 349/1000] Train Loss: 0.0409  |  Val Loss: 0.2080\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 350/1000] Train Loss: 0.0408  |  Val Loss: 0.2080\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 351/1000] Train Loss: 0.0404  |  Val Loss: 0.2082\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 352/1000] Train Loss: 0.0402  |  Val Loss: 0.2085\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 353/1000] Train Loss: 0.0400  |  Val Loss: 0.2087\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 354/1000] Train Loss: 0.0397  |  Val Loss: 0.2087\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 355/1000] Train Loss: 0.0395  |  Val Loss: 0.2088\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 356/1000] Train Loss: 0.0393  |  Val Loss: 0.2090\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 357/1000] Train Loss: 0.0391  |  Val Loss: 0.2093\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 358/1000] Train Loss: 0.0388  |  Val Loss: 0.2096\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 359/1000] Train Loss: 0.0387  |  Val Loss: 0.2092\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 360/1000] Train Loss: 0.0385  |  Val Loss: 0.2094\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 361/1000] Train Loss: 0.0382  |  Val Loss: 0.2095\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 362/1000] Train Loss: 0.0380  |  Val Loss: 0.2093\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 363/1000] Train Loss: 0.0378  |  Val Loss: 0.2100\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 364/1000] Train Loss: 0.0376  |  Val Loss: 0.2104\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 365/1000] Train Loss: 0.0373  |  Val Loss: 0.2107\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 366/1000] Train Loss: 0.0371  |  Val Loss: 0.2110\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 367/1000] Train Loss: 0.0369  |  Val Loss: 0.2112\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 368/1000] Train Loss: 0.0367  |  Val Loss: 0.2122\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 369/1000] Train Loss: 0.0365  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 370/1000] Train Loss: 0.0364  |  Val Loss: 0.2126\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 371/1000] Train Loss: 0.0361  |  Val Loss: 0.2128\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 372/1000] Train Loss: 0.0360  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 373/1000] Train Loss: 0.0358  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 374/1000] Train Loss: 0.0355  |  Val Loss: 0.2127\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 375/1000] Train Loss: 0.0354  |  Val Loss: 0.2128\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 376/1000] Train Loss: 0.0352  |  Val Loss: 0.2123\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 377/1000] Train Loss: 0.0351  |  Val Loss: 0.2122\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 378/1000] Train Loss: 0.0348  |  Val Loss: 0.2123\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 379/1000] Train Loss: 0.0347  |  Val Loss: 0.2125\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 380/1000] Train Loss: 0.0345  |  Val Loss: 0.2133\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 381/1000] Train Loss: 0.0343  |  Val Loss: 0.2136\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 382/1000] Train Loss: 0.0341  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 383/1000] Train Loss: 0.0339  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 384/1000] Train Loss: 0.0337  |  Val Loss: 0.2144\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 385/1000] Train Loss: 0.0336  |  Val Loss: 0.2152\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 386/1000] Train Loss: 0.0334  |  Val Loss: 0.2156\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 387/1000] Train Loss: 0.0332  |  Val Loss: 0.2159\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 388/1000] Train Loss: 0.0330  |  Val Loss: 0.2164\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 389/1000] Train Loss: 0.0330  |  Val Loss: 0.2166\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 390/1000] Train Loss: 0.0327  |  Val Loss: 0.2165\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 391/1000] Train Loss: 0.0325  |  Val Loss: 0.2163\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 392/1000] Train Loss: 0.0325  |  Val Loss: 0.2162\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 393/1000] Train Loss: 0.0323  |  Val Loss: 0.2165\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 394/1000] Train Loss: 0.0321  |  Val Loss: 0.2161\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 395/1000] Train Loss: 0.0320  |  Val Loss: 0.2168\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 396/1000] Train Loss: 0.0317  |  Val Loss: 0.2169\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 397/1000] Train Loss: 0.0316  |  Val Loss: 0.2175\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 398/1000] Train Loss: 0.0314  |  Val Loss: 0.2179\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 399/1000] Train Loss: 0.0313  |  Val Loss: 0.2186\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 400/1000] Train Loss: 0.0310  |  Val Loss: 0.2189\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 401/1000] Train Loss: 0.0310  |  Val Loss: 0.2185\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 402/1000] Train Loss: 0.0309  |  Val Loss: 0.2189\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 402 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:51.090797Z",
     "iopub.status.busy": "2025-05-08T17:19:51.090797Z",
     "iopub.status.idle": "2025-05-08T17:19:53.262945Z",
     "shell.execute_reply": "2025-05-08T17:19:53.262945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.1331 | Test Accuracy: 96.64%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:53.265731Z",
     "iopub.status.busy": "2025-05-08T17:19:53.265731Z",
     "iopub.status.idle": "2025-05-08T17:19:53.450509Z",
     "shell.execute_reply": "2025-05-08T17:19:53.449771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (180, 64), \n",
      "Train labels shape: (180,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (45, 64), \n",
      "Val labels shape: (45,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (147927, 64), \n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:53.452838Z",
     "iopub.status.busy": "2025-05-08T17:19:53.451838Z",
     "iopub.status.idle": "2025-05-08T17:19:53.467770Z",
     "shell.execute_reply": "2025-05-08T17:19:53.467770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n",
      "Training batch size: 180\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:53.470778Z",
     "iopub.status.busy": "2025-05-08T17:19:53.469776Z",
     "iopub.status.idle": "2025-05-08T17:19:53.473785Z",
     "shell.execute_reply": "2025-05-08T17:19:53.473785Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:53.475971Z",
     "iopub.status.busy": "2025-05-08T17:19:53.475971Z",
     "iopub.status.idle": "2025-05-08T17:19:53.482136Z",
     "shell.execute_reply": "2025-05-08T17:19:53.482136Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:19:53.484139Z",
     "iopub.status.busy": "2025-05-08T17:19:53.484139Z",
     "iopub.status.idle": "2025-05-08T17:23:24.781619Z",
     "shell.execute_reply": "2025-05-08T17:23:24.781619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4591\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4109\n",
      "Epoch [1/2000], Avg Train Loss: 0.4591, Avg Val Loss: 0.4109\n",
      "\n",
      "Validation loss improved from inf to 0.4109. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4581\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4104\n",
      "Epoch [2/2000], Avg Train Loss: 0.4581, Avg Val Loss: 0.4104\n",
      "\n",
      "Validation loss improved from 0.4109 to 0.4104. Saving model...\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4586\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4097\n",
      "Epoch [3/2000], Avg Train Loss: 0.4586, Avg Val Loss: 0.4097\n",
      "\n",
      "Validation loss improved from 0.4104 to 0.4097. Saving model...\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4521\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4089\n",
      "Epoch [4/2000], Avg Train Loss: 0.4521, Avg Val Loss: 0.4089\n",
      "\n",
      "Validation loss improved from 0.4097 to 0.4089. Saving model...\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4534\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4083\n",
      "Epoch [5/2000], Avg Train Loss: 0.4534, Avg Val Loss: 0.4083\n",
      "\n",
      "Validation loss improved from 0.4089 to 0.4083. Saving model...\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4578\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4083\n",
      "Epoch [6/2000], Avg Train Loss: 0.4578, Avg Val Loss: 0.4083\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4520\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4083\n",
      "Epoch [7/2000], Avg Train Loss: 0.4520, Avg Val Loss: 0.4083\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4511\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4080\n",
      "Epoch [8/2000], Avg Train Loss: 0.4511, Avg Val Loss: 0.4080\n",
      "\n",
      "Validation loss improved from 0.4083 to 0.4080. Saving model...\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4525\n",
      "LOG: Epoch [9/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.4075\n",
      "Epoch [9/2000], Avg Train Loss: 0.4525, Avg Val Loss: 0.4075\n",
      "\n",
      "Validation loss improved from 0.4080 to 0.4075. Saving model...\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4496\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4066\n",
      "Epoch [10/2000], Avg Train Loss: 0.4496, Avg Val Loss: 0.4066\n",
      "\n",
      "Validation loss improved from 0.4075 to 0.4066. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4462\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4058\n",
      "Epoch [11/2000], Avg Train Loss: 0.4462, Avg Val Loss: 0.4058\n",
      "\n",
      "Validation loss improved from 0.4066 to 0.4058. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4507\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4050\n",
      "Epoch [12/2000], Avg Train Loss: 0.4507, Avg Val Loss: 0.4050\n",
      "\n",
      "Validation loss improved from 0.4058 to 0.4050. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4481\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4045\n",
      "Epoch [13/2000], Avg Train Loss: 0.4481, Avg Val Loss: 0.4045\n",
      "\n",
      "Validation loss improved from 0.4050 to 0.4045. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4467\n",
      "LOG: Epoch [14/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.4041\n",
      "Epoch [14/2000], Avg Train Loss: 0.4467, Avg Val Loss: 0.4041\n",
      "\n",
      "Validation loss improved from 0.4045 to 0.4041. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4486\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4037\n",
      "Epoch [15/2000], Avg Train Loss: 0.4486, Avg Val Loss: 0.4037\n",
      "\n",
      "Validation loss improved from 0.4041 to 0.4037. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4483\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4033\n",
      "Epoch [16/2000], Avg Train Loss: 0.4483, Avg Val Loss: 0.4033\n",
      "\n",
      "Validation loss improved from 0.4037 to 0.4033. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4423\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4028\n",
      "Epoch [17/2000], Avg Train Loss: 0.4423, Avg Val Loss: 0.4028\n",
      "\n",
      "Validation loss improved from 0.4033 to 0.4028. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4431\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4023\n",
      "Epoch [18/2000], Avg Train Loss: 0.4431, Avg Val Loss: 0.4023\n",
      "\n",
      "Validation loss improved from 0.4028 to 0.4023. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4388\n",
      "LOG: Epoch [19/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.4016\n",
      "Epoch [19/2000], Avg Train Loss: 0.4388, Avg Val Loss: 0.4016\n",
      "\n",
      "Validation loss improved from 0.4023 to 0.4016. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4402\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.4008\n",
      "Epoch [20/2000], Avg Train Loss: 0.4402, Avg Val Loss: 0.4008\n",
      "\n",
      "Validation loss improved from 0.4016 to 0.4008. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4375\n",
      "LOG: Epoch [21/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.4000\n",
      "Epoch [21/2000], Avg Train Loss: 0.4375, Avg Val Loss: 0.4000\n",
      "\n",
      "Validation loss improved from 0.4008 to 0.4000. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4389\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3992\n",
      "Epoch [22/2000], Avg Train Loss: 0.4389, Avg Val Loss: 0.3992\n",
      "\n",
      "Validation loss improved from 0.4000 to 0.3992. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4420\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3984\n",
      "Epoch [23/2000], Avg Train Loss: 0.4420, Avg Val Loss: 0.3984\n",
      "\n",
      "Validation loss improved from 0.3992 to 0.3984. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4376\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3976\n",
      "Epoch [24/2000], Avg Train Loss: 0.4376, Avg Val Loss: 0.3976\n",
      "\n",
      "Validation loss improved from 0.3984 to 0.3976. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4384\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3969\n",
      "Epoch [25/2000], Avg Train Loss: 0.4384, Avg Val Loss: 0.3969\n",
      "\n",
      "Validation loss improved from 0.3976 to 0.3969. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4386\n",
      "LOG: Epoch [26/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3961\n",
      "Epoch [26/2000], Avg Train Loss: 0.4386, Avg Val Loss: 0.3961\n",
      "\n",
      "Validation loss improved from 0.3969 to 0.3961. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3954\n",
      "Epoch [27/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.3954\n",
      "\n",
      "Validation loss improved from 0.3961 to 0.3954. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4401\n",
      "LOG: Epoch [28/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3946\n",
      "Epoch [28/2000], Avg Train Loss: 0.4401, Avg Val Loss: 0.3946\n",
      "\n",
      "Validation loss improved from 0.3954 to 0.3946. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3938\n",
      "Epoch [29/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.3938\n",
      "\n",
      "Validation loss improved from 0.3946 to 0.3938. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3930\n",
      "Epoch [30/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.3930\n",
      "\n",
      "Validation loss improved from 0.3938 to 0.3930. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4332\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3922\n",
      "Epoch [31/2000], Avg Train Loss: 0.4332, Avg Val Loss: 0.3922\n",
      "\n",
      "Validation loss improved from 0.3930 to 0.3922. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4319\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3913\n",
      "Epoch [32/2000], Avg Train Loss: 0.4319, Avg Val Loss: 0.3913\n",
      "\n",
      "Validation loss improved from 0.3922 to 0.3913. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3905\n",
      "Epoch [33/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.3905\n",
      "\n",
      "Validation loss improved from 0.3913 to 0.3905. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3897\n",
      "Epoch [34/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.3897\n",
      "\n",
      "Validation loss improved from 0.3905 to 0.3897. Saving model...\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4304\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3888\n",
      "Epoch [35/2000], Avg Train Loss: 0.4304, Avg Val Loss: 0.3888\n",
      "\n",
      "Validation loss improved from 0.3897 to 0.3888. Saving model...\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4216\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3880\n",
      "Epoch [36/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.3880\n",
      "\n",
      "Validation loss improved from 0.3888 to 0.3880. Saving model...\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4240\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3871\n",
      "Epoch [37/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.3871\n",
      "\n",
      "Validation loss improved from 0.3880 to 0.3871. Saving model...\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [38/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3863\n",
      "Epoch [38/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.3863\n",
      "\n",
      "Validation loss improved from 0.3871 to 0.3863. Saving model...\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3855\n",
      "Epoch [39/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.3855\n",
      "\n",
      "Validation loss improved from 0.3863 to 0.3855. Saving model...\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4224\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3847\n",
      "Epoch [40/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.3847\n",
      "\n",
      "Validation loss improved from 0.3855 to 0.3847. Saving model...\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3839\n",
      "Epoch [41/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.3839\n",
      "\n",
      "Validation loss improved from 0.3847 to 0.3839. Saving model...\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4208\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3831\n",
      "Epoch [42/2000], Avg Train Loss: 0.4208, Avg Val Loss: 0.3831\n",
      "\n",
      "Validation loss improved from 0.3839 to 0.3831. Saving model...\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3824\n",
      "Epoch [43/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.3824\n",
      "\n",
      "Validation loss improved from 0.3831 to 0.3824. Saving model...\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3816\n",
      "Epoch [44/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.3816\n",
      "\n",
      "Validation loss improved from 0.3824 to 0.3816. Saving model...\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4175\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3808\n",
      "Epoch [45/2000], Avg Train Loss: 0.4175, Avg Val Loss: 0.3808\n",
      "\n",
      "Validation loss improved from 0.3816 to 0.3808. Saving model...\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3800\n",
      "Epoch [46/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.3800\n",
      "\n",
      "Validation loss improved from 0.3808 to 0.3800. Saving model...\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [47/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3793\n",
      "Epoch [47/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.3793\n",
      "\n",
      "Validation loss improved from 0.3800 to 0.3793. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3785\n",
      "Epoch [48/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.3785\n",
      "\n",
      "Validation loss improved from 0.3793 to 0.3785. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3777\n",
      "Epoch [49/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.3777\n",
      "\n",
      "Validation loss improved from 0.3785 to 0.3777. Saving model...\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3770\n",
      "Epoch [50/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.3770\n",
      "\n",
      "Validation loss improved from 0.3777 to 0.3770. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3762\n",
      "Epoch [51/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.3762\n",
      "\n",
      "Validation loss improved from 0.3770 to 0.3762. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [52/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3754\n",
      "Epoch [52/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.3754\n",
      "\n",
      "Validation loss improved from 0.3762 to 0.3754. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3747\n",
      "Epoch [53/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.3747\n",
      "\n",
      "Validation loss improved from 0.3754 to 0.3747. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [54/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3739\n",
      "Epoch [54/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.3739\n",
      "\n",
      "Validation loss improved from 0.3747 to 0.3739. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3731\n",
      "Epoch [55/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.3731\n",
      "\n",
      "Validation loss improved from 0.3739 to 0.3731. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3724\n",
      "Epoch [56/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.3724\n",
      "\n",
      "Validation loss improved from 0.3731 to 0.3724. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3716\n",
      "Epoch [57/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.3716\n",
      "\n",
      "Validation loss improved from 0.3724 to 0.3716. Saving model...\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3708\n",
      "Epoch [58/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.3708\n",
      "\n",
      "Validation loss improved from 0.3716 to 0.3708. Saving model...\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3701\n",
      "Epoch [59/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.3701\n",
      "\n",
      "Validation loss improved from 0.3708 to 0.3701. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3694\n",
      "Epoch [60/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.3694\n",
      "\n",
      "Validation loss improved from 0.3701 to 0.3694. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [61/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3687\n",
      "Epoch [61/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.3687\n",
      "\n",
      "Validation loss improved from 0.3694 to 0.3687. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3681\n",
      "Epoch [62/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.3681\n",
      "\n",
      "Validation loss improved from 0.3687 to 0.3681. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [63/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3674\n",
      "Epoch [63/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.3674\n",
      "\n",
      "Validation loss improved from 0.3681 to 0.3674. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3667\n",
      "Epoch [64/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.3667\n",
      "\n",
      "Validation loss improved from 0.3674 to 0.3667. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3660\n",
      "Epoch [65/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.3660\n",
      "\n",
      "Validation loss improved from 0.3667 to 0.3660. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3653\n",
      "Epoch [66/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.3653\n",
      "\n",
      "Validation loss improved from 0.3660 to 0.3653. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [67/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3645\n",
      "Epoch [67/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.3645\n",
      "\n",
      "Validation loss improved from 0.3653 to 0.3645. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3638\n",
      "Epoch [68/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.3638\n",
      "\n",
      "Validation loss improved from 0.3645 to 0.3638. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3631\n",
      "Epoch [69/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.3631\n",
      "\n",
      "Validation loss improved from 0.3638 to 0.3631. Saving model...\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3624\n",
      "Epoch [70/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.3624\n",
      "\n",
      "Validation loss improved from 0.3631 to 0.3624. Saving model...\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3618\n",
      "Epoch [71/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.3618\n",
      "\n",
      "Validation loss improved from 0.3624 to 0.3618. Saving model...\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3611\n",
      "Epoch [72/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.3611\n",
      "\n",
      "Validation loss improved from 0.3618 to 0.3611. Saving model...\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3604\n",
      "Epoch [73/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.3604\n",
      "\n",
      "Validation loss improved from 0.3611 to 0.3604. Saving model...\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3974\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3597\n",
      "Epoch [74/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.3597\n",
      "\n",
      "Validation loss improved from 0.3604 to 0.3597. Saving model...\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3591\n",
      "Epoch [75/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.3591\n",
      "\n",
      "Validation loss improved from 0.3597 to 0.3591. Saving model...\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3585\n",
      "Epoch [76/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.3585\n",
      "\n",
      "Validation loss improved from 0.3591 to 0.3585. Saving model...\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3578\n",
      "Epoch [77/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.3578\n",
      "\n",
      "Validation loss improved from 0.3585 to 0.3578. Saving model...\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3572\n",
      "Epoch [78/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.3572\n",
      "\n",
      "Validation loss improved from 0.3578 to 0.3572. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3566\n",
      "Epoch [79/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.3566\n",
      "\n",
      "Validation loss improved from 0.3572 to 0.3566. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3560\n",
      "Epoch [80/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.3560\n",
      "\n",
      "Validation loss improved from 0.3566 to 0.3560. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3554\n",
      "Epoch [81/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.3554\n",
      "\n",
      "Validation loss improved from 0.3560 to 0.3554. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3548\n",
      "Epoch [82/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.3548\n",
      "\n",
      "Validation loss improved from 0.3554 to 0.3548. Saving model...\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [83/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3543\n",
      "Epoch [83/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.3543\n",
      "\n",
      "Validation loss improved from 0.3548 to 0.3543. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3537\n",
      "Epoch [84/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.3537\n",
      "\n",
      "Validation loss improved from 0.3543 to 0.3537. Saving model...\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3531\n",
      "Epoch [85/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.3531\n",
      "\n",
      "Validation loss improved from 0.3537 to 0.3531. Saving model...\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3525\n",
      "Epoch [86/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.3525\n",
      "\n",
      "Validation loss improved from 0.3531 to 0.3525. Saving model...\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3868\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3519\n",
      "Epoch [87/2000], Avg Train Loss: 0.3868, Avg Val Loss: 0.3519\n",
      "\n",
      "Validation loss improved from 0.3525 to 0.3519. Saving model...\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [88/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3513\n",
      "Epoch [88/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.3513\n",
      "\n",
      "Validation loss improved from 0.3519 to 0.3513. Saving model...\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3508\n",
      "Epoch [89/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.3508\n",
      "\n",
      "Validation loss improved from 0.3513 to 0.3508. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3866\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3502\n",
      "Epoch [90/2000], Avg Train Loss: 0.3866, Avg Val Loss: 0.3502\n",
      "\n",
      "Validation loss improved from 0.3508 to 0.3502. Saving model...\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3816\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3496\n",
      "Epoch [91/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.3496\n",
      "\n",
      "Validation loss improved from 0.3502 to 0.3496. Saving model...\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3836\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3490\n",
      "Epoch [92/2000], Avg Train Loss: 0.3836, Avg Val Loss: 0.3490\n",
      "\n",
      "Validation loss improved from 0.3496 to 0.3490. Saving model...\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3816\n",
      "LOG: Epoch [93/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3484\n",
      "Epoch [93/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.3484\n",
      "\n",
      "Validation loss improved from 0.3490 to 0.3484. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3825\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3478\n",
      "Epoch [94/2000], Avg Train Loss: 0.3825, Avg Val Loss: 0.3478\n",
      "\n",
      "Validation loss improved from 0.3484 to 0.3478. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3788\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3472\n",
      "Epoch [95/2000], Avg Train Loss: 0.3788, Avg Val Loss: 0.3472\n",
      "\n",
      "Validation loss improved from 0.3478 to 0.3472. Saving model...\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3781\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3466\n",
      "Epoch [96/2000], Avg Train Loss: 0.3781, Avg Val Loss: 0.3466\n",
      "\n",
      "Validation loss improved from 0.3472 to 0.3466. Saving model...\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3810\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3460\n",
      "Epoch [97/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.3460\n",
      "\n",
      "Validation loss improved from 0.3466 to 0.3460. Saving model...\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3813\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3454\n",
      "Epoch [98/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.3454\n",
      "\n",
      "Validation loss improved from 0.3460 to 0.3454. Saving model...\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3785\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3447\n",
      "Epoch [99/2000], Avg Train Loss: 0.3785, Avg Val Loss: 0.3447\n",
      "\n",
      "Validation loss improved from 0.3454 to 0.3447. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3810\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3441\n",
      "Epoch [100/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.3441\n",
      "\n",
      "Validation loss improved from 0.3447 to 0.3441. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3767\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3435\n",
      "Epoch [101/2000], Avg Train Loss: 0.3767, Avg Val Loss: 0.3435\n",
      "\n",
      "Validation loss improved from 0.3441 to 0.3435. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3817\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3429\n",
      "Epoch [102/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.3429\n",
      "\n",
      "Validation loss improved from 0.3435 to 0.3429. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3688\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3423\n",
      "Epoch [103/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.3423\n",
      "\n",
      "Validation loss improved from 0.3429 to 0.3423. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3758\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3417\n",
      "Epoch [104/2000], Avg Train Loss: 0.3758, Avg Val Loss: 0.3417\n",
      "\n",
      "Validation loss improved from 0.3423 to 0.3417. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3714\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3411\n",
      "Epoch [105/2000], Avg Train Loss: 0.3714, Avg Val Loss: 0.3411\n",
      "\n",
      "Validation loss improved from 0.3417 to 0.3411. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3745\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3405\n",
      "Epoch [106/2000], Avg Train Loss: 0.3745, Avg Val Loss: 0.3405\n",
      "\n",
      "Validation loss improved from 0.3411 to 0.3405. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3824\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3399\n",
      "Epoch [107/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.3399\n",
      "\n",
      "Validation loss improved from 0.3405 to 0.3399. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3718\n",
      "LOG: Epoch [108/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3393\n",
      "Epoch [108/2000], Avg Train Loss: 0.3718, Avg Val Loss: 0.3393\n",
      "\n",
      "Validation loss improved from 0.3399 to 0.3393. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3751\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3387\n",
      "Epoch [109/2000], Avg Train Loss: 0.3751, Avg Val Loss: 0.3387\n",
      "\n",
      "Validation loss improved from 0.3393 to 0.3387. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3730\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3380\n",
      "Epoch [110/2000], Avg Train Loss: 0.3730, Avg Val Loss: 0.3380\n",
      "\n",
      "Validation loss improved from 0.3387 to 0.3380. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3690\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3374\n",
      "Epoch [111/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.3374\n",
      "\n",
      "Validation loss improved from 0.3380 to 0.3374. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3706\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3368\n",
      "Epoch [112/2000], Avg Train Loss: 0.3706, Avg Val Loss: 0.3368\n",
      "\n",
      "Validation loss improved from 0.3374 to 0.3368. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3666\n",
      "LOG: Epoch [113/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3361\n",
      "Epoch [113/2000], Avg Train Loss: 0.3666, Avg Val Loss: 0.3361\n",
      "\n",
      "Validation loss improved from 0.3368 to 0.3361. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3746\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3355\n",
      "Epoch [114/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.3355\n",
      "\n",
      "Validation loss improved from 0.3361 to 0.3355. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3721\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3349\n",
      "Epoch [115/2000], Avg Train Loss: 0.3721, Avg Val Loss: 0.3349\n",
      "\n",
      "Validation loss improved from 0.3355 to 0.3349. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3667\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3343\n",
      "Epoch [116/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.3343\n",
      "\n",
      "Validation loss improved from 0.3349 to 0.3343. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3679\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3338\n",
      "Epoch [117/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.3338\n",
      "\n",
      "Validation loss improved from 0.3343 to 0.3338. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3682\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3332\n",
      "Epoch [118/2000], Avg Train Loss: 0.3682, Avg Val Loss: 0.3332\n",
      "\n",
      "Validation loss improved from 0.3338 to 0.3332. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3327\n",
      "Epoch [119/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.3327\n",
      "\n",
      "Validation loss improved from 0.3332 to 0.3327. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3654\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3321\n",
      "Epoch [120/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.3321\n",
      "\n",
      "Validation loss improved from 0.3327 to 0.3321. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3696\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3316\n",
      "Epoch [121/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.3316\n",
      "\n",
      "Validation loss improved from 0.3321 to 0.3316. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3595\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3310\n",
      "Epoch [122/2000], Avg Train Loss: 0.3595, Avg Val Loss: 0.3310\n",
      "\n",
      "Validation loss improved from 0.3316 to 0.3310. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3641\n",
      "LOG: Epoch [123/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3305\n",
      "Epoch [123/2000], Avg Train Loss: 0.3641, Avg Val Loss: 0.3305\n",
      "\n",
      "Validation loss improved from 0.3310 to 0.3305. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3637\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3299\n",
      "Epoch [124/2000], Avg Train Loss: 0.3637, Avg Val Loss: 0.3299\n",
      "\n",
      "Validation loss improved from 0.3305 to 0.3299. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3605\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3294\n",
      "Epoch [125/2000], Avg Train Loss: 0.3605, Avg Val Loss: 0.3294\n",
      "\n",
      "Validation loss improved from 0.3299 to 0.3294. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3613\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3288\n",
      "Epoch [126/2000], Avg Train Loss: 0.3613, Avg Val Loss: 0.3288\n",
      "\n",
      "Validation loss improved from 0.3294 to 0.3288. Saving model...\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3592\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3283\n",
      "Epoch [127/2000], Avg Train Loss: 0.3592, Avg Val Loss: 0.3283\n",
      "\n",
      "Validation loss improved from 0.3288 to 0.3283. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3575\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3277\n",
      "Epoch [128/2000], Avg Train Loss: 0.3575, Avg Val Loss: 0.3277\n",
      "\n",
      "Validation loss improved from 0.3283 to 0.3277. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3568\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3272\n",
      "Epoch [129/2000], Avg Train Loss: 0.3568, Avg Val Loss: 0.3272\n",
      "\n",
      "Validation loss improved from 0.3277 to 0.3272. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3584\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3267\n",
      "Epoch [130/2000], Avg Train Loss: 0.3584, Avg Val Loss: 0.3267\n",
      "\n",
      "Validation loss improved from 0.3272 to 0.3267. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3577\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3261\n",
      "Epoch [131/2000], Avg Train Loss: 0.3577, Avg Val Loss: 0.3261\n",
      "\n",
      "Validation loss improved from 0.3267 to 0.3261. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3602\n",
      "LOG: Epoch [132/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3256\n",
      "Epoch [132/2000], Avg Train Loss: 0.3602, Avg Val Loss: 0.3256\n",
      "\n",
      "Validation loss improved from 0.3261 to 0.3256. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3582\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3250\n",
      "Epoch [133/2000], Avg Train Loss: 0.3582, Avg Val Loss: 0.3250\n",
      "\n",
      "Validation loss improved from 0.3256 to 0.3250. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3617\n",
      "LOG: Epoch [134/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3245\n",
      "Epoch [134/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.3245\n",
      "\n",
      "Validation loss improved from 0.3250 to 0.3245. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3622\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3240\n",
      "Epoch [135/2000], Avg Train Loss: 0.3622, Avg Val Loss: 0.3240\n",
      "\n",
      "Validation loss improved from 0.3245 to 0.3240. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [136/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3235\n",
      "Epoch [136/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.3235\n",
      "\n",
      "Validation loss improved from 0.3240 to 0.3235. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3229\n",
      "Epoch [137/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.3229\n",
      "\n",
      "Validation loss improved from 0.3235 to 0.3229. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3578\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3224\n",
      "Epoch [138/2000], Avg Train Loss: 0.3578, Avg Val Loss: 0.3224\n",
      "\n",
      "Validation loss improved from 0.3229 to 0.3224. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3219\n",
      "Epoch [139/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.3219\n",
      "\n",
      "Validation loss improved from 0.3224 to 0.3219. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3555\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3214\n",
      "Epoch [140/2000], Avg Train Loss: 0.3555, Avg Val Loss: 0.3214\n",
      "\n",
      "Validation loss improved from 0.3219 to 0.3214. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3209\n",
      "Epoch [141/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.3209\n",
      "\n",
      "Validation loss improved from 0.3214 to 0.3209. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3526\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3204\n",
      "Epoch [142/2000], Avg Train Loss: 0.3526, Avg Val Loss: 0.3204\n",
      "\n",
      "Validation loss improved from 0.3209 to 0.3204. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [143/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3198\n",
      "Epoch [143/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.3198\n",
      "\n",
      "Validation loss improved from 0.3204 to 0.3198. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3193\n",
      "Epoch [144/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.3193\n",
      "\n",
      "Validation loss improved from 0.3198 to 0.3193. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [145/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3188\n",
      "Epoch [145/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.3188\n",
      "\n",
      "Validation loss improved from 0.3193 to 0.3188. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3182\n",
      "Epoch [146/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.3182\n",
      "\n",
      "Validation loss improved from 0.3188 to 0.3182. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3177\n",
      "Epoch [147/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.3177\n",
      "\n",
      "Validation loss improved from 0.3182 to 0.3177. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3171\n",
      "Epoch [148/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.3171\n",
      "\n",
      "Validation loss improved from 0.3177 to 0.3171. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3166\n",
      "Epoch [149/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.3166\n",
      "\n",
      "Validation loss improved from 0.3171 to 0.3166. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3160\n",
      "Epoch [150/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.3160\n",
      "\n",
      "Validation loss improved from 0.3166 to 0.3160. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3155\n",
      "Epoch [151/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.3155\n",
      "\n",
      "Validation loss improved from 0.3160 to 0.3155. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3149\n",
      "Epoch [152/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.3149\n",
      "\n",
      "Validation loss improved from 0.3155 to 0.3149. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3144\n",
      "Epoch [153/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.3144\n",
      "\n",
      "Validation loss improved from 0.3149 to 0.3144. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3138\n",
      "Epoch [154/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.3138\n",
      "\n",
      "Validation loss improved from 0.3144 to 0.3138. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3133\n",
      "Epoch [155/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.3133\n",
      "\n",
      "Validation loss improved from 0.3138 to 0.3133. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [156/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3128\n",
      "Epoch [156/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.3128\n",
      "\n",
      "Validation loss improved from 0.3133 to 0.3128. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3122\n",
      "Epoch [157/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.3122\n",
      "\n",
      "Validation loss improved from 0.3128 to 0.3122. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [158/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3117\n",
      "Epoch [158/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.3117\n",
      "\n",
      "Validation loss improved from 0.3122 to 0.3117. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3397\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3112\n",
      "Epoch [159/2000], Avg Train Loss: 0.3397, Avg Val Loss: 0.3112\n",
      "\n",
      "Validation loss improved from 0.3117 to 0.3112. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3411\n",
      "LOG: Epoch [160/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3107\n",
      "Epoch [160/2000], Avg Train Loss: 0.3411, Avg Val Loss: 0.3107\n",
      "\n",
      "Validation loss improved from 0.3112 to 0.3107. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3102\n",
      "Epoch [161/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.3102\n",
      "\n",
      "Validation loss improved from 0.3107 to 0.3102. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [162/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3097\n",
      "Epoch [162/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.3097\n",
      "\n",
      "Validation loss improved from 0.3102 to 0.3097. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3369\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3092\n",
      "Epoch [163/2000], Avg Train Loss: 0.3369, Avg Val Loss: 0.3092\n",
      "\n",
      "Validation loss improved from 0.3097 to 0.3092. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3337\n",
      "LOG: Epoch [164/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3087\n",
      "Epoch [164/2000], Avg Train Loss: 0.3337, Avg Val Loss: 0.3087\n",
      "\n",
      "Validation loss improved from 0.3092 to 0.3087. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3083\n",
      "Epoch [165/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.3083\n",
      "\n",
      "Validation loss improved from 0.3087 to 0.3083. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3394\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3078\n",
      "Epoch [166/2000], Avg Train Loss: 0.3394, Avg Val Loss: 0.3078\n",
      "\n",
      "Validation loss improved from 0.3083 to 0.3078. Saving model...\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3389\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3074\n",
      "Epoch [167/2000], Avg Train Loss: 0.3389, Avg Val Loss: 0.3074\n",
      "\n",
      "Validation loss improved from 0.3078 to 0.3074. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3398\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3070\n",
      "Epoch [168/2000], Avg Train Loss: 0.3398, Avg Val Loss: 0.3070\n",
      "\n",
      "Validation loss improved from 0.3074 to 0.3070. Saving model...\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [169/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3066\n",
      "Epoch [169/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.3066\n",
      "\n",
      "Validation loss improved from 0.3070 to 0.3066. Saving model...\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3356\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3062\n",
      "Epoch [170/2000], Avg Train Loss: 0.3356, Avg Val Loss: 0.3062\n",
      "\n",
      "Validation loss improved from 0.3066 to 0.3062. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3378\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3057\n",
      "Epoch [171/2000], Avg Train Loss: 0.3378, Avg Val Loss: 0.3057\n",
      "\n",
      "Validation loss improved from 0.3062 to 0.3057. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3338\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3053\n",
      "Epoch [172/2000], Avg Train Loss: 0.3338, Avg Val Loss: 0.3053\n",
      "\n",
      "Validation loss improved from 0.3057 to 0.3053. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3290\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3050\n",
      "Epoch [173/2000], Avg Train Loss: 0.3290, Avg Val Loss: 0.3050\n",
      "\n",
      "Validation loss improved from 0.3053 to 0.3050. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3338\n",
      "LOG: Epoch [174/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3046\n",
      "Epoch [174/2000], Avg Train Loss: 0.3338, Avg Val Loss: 0.3046\n",
      "\n",
      "Validation loss improved from 0.3050 to 0.3046. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3347\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3042\n",
      "Epoch [175/2000], Avg Train Loss: 0.3347, Avg Val Loss: 0.3042\n",
      "\n",
      "Validation loss improved from 0.3046 to 0.3042. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3311\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3038\n",
      "Epoch [176/2000], Avg Train Loss: 0.3311, Avg Val Loss: 0.3038\n",
      "\n",
      "Validation loss improved from 0.3042 to 0.3038. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3281\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3033\n",
      "Epoch [177/2000], Avg Train Loss: 0.3281, Avg Val Loss: 0.3033\n",
      "\n",
      "Validation loss improved from 0.3038 to 0.3033. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3334\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3029\n",
      "Epoch [178/2000], Avg Train Loss: 0.3334, Avg Val Loss: 0.3029\n",
      "\n",
      "Validation loss improved from 0.3033 to 0.3029. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3280\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3025\n",
      "Epoch [179/2000], Avg Train Loss: 0.3280, Avg Val Loss: 0.3025\n",
      "\n",
      "Validation loss improved from 0.3029 to 0.3025. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3298\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3021\n",
      "Epoch [180/2000], Avg Train Loss: 0.3298, Avg Val Loss: 0.3021\n",
      "\n",
      "Validation loss improved from 0.3025 to 0.3021. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3294\n",
      "LOG: Epoch [181/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3017\n",
      "Epoch [181/2000], Avg Train Loss: 0.3294, Avg Val Loss: 0.3017\n",
      "\n",
      "Validation loss improved from 0.3021 to 0.3017. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3302\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3013\n",
      "Epoch [182/2000], Avg Train Loss: 0.3302, Avg Val Loss: 0.3013\n",
      "\n",
      "Validation loss improved from 0.3017 to 0.3013. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3324\n",
      "LOG: Epoch [183/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3009\n",
      "Epoch [183/2000], Avg Train Loss: 0.3324, Avg Val Loss: 0.3009\n",
      "\n",
      "Validation loss improved from 0.3013 to 0.3009. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3214\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3004\n",
      "Epoch [184/2000], Avg Train Loss: 0.3214, Avg Val Loss: 0.3004\n",
      "\n",
      "Validation loss improved from 0.3009 to 0.3004. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3216\n",
      "LOG: Epoch [185/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3000\n",
      "Epoch [185/2000], Avg Train Loss: 0.3216, Avg Val Loss: 0.3000\n",
      "\n",
      "Validation loss improved from 0.3004 to 0.3000. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3332\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2996\n",
      "Epoch [186/2000], Avg Train Loss: 0.3332, Avg Val Loss: 0.2996\n",
      "\n",
      "Validation loss improved from 0.3000 to 0.2996. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3308\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2992\n",
      "Epoch [187/2000], Avg Train Loss: 0.3308, Avg Val Loss: 0.2992\n",
      "\n",
      "Validation loss improved from 0.2996 to 0.2992. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3297\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2987\n",
      "Epoch [188/2000], Avg Train Loss: 0.3297, Avg Val Loss: 0.2987\n",
      "\n",
      "Validation loss improved from 0.2992 to 0.2987. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3322\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2983\n",
      "Epoch [189/2000], Avg Train Loss: 0.3322, Avg Val Loss: 0.2983\n",
      "\n",
      "Validation loss improved from 0.2987 to 0.2983. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3260\n",
      "LOG: Epoch [190/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2979\n",
      "Epoch [190/2000], Avg Train Loss: 0.3260, Avg Val Loss: 0.2979\n",
      "\n",
      "Validation loss improved from 0.2983 to 0.2979. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3230\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2975\n",
      "Epoch [191/2000], Avg Train Loss: 0.3230, Avg Val Loss: 0.2975\n",
      "\n",
      "Validation loss improved from 0.2979 to 0.2975. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3226\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2970\n",
      "Epoch [192/2000], Avg Train Loss: 0.3226, Avg Val Loss: 0.2970\n",
      "\n",
      "Validation loss improved from 0.2975 to 0.2970. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3217\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2966\n",
      "Epoch [193/2000], Avg Train Loss: 0.3217, Avg Val Loss: 0.2966\n",
      "\n",
      "Validation loss improved from 0.2970 to 0.2966. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3252\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2962\n",
      "Epoch [194/2000], Avg Train Loss: 0.3252, Avg Val Loss: 0.2962\n",
      "\n",
      "Validation loss improved from 0.2966 to 0.2962. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3262\n",
      "LOG: Epoch [195/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2958\n",
      "Epoch [195/2000], Avg Train Loss: 0.3262, Avg Val Loss: 0.2958\n",
      "\n",
      "Validation loss improved from 0.2962 to 0.2958. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3198\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2954\n",
      "Epoch [196/2000], Avg Train Loss: 0.3198, Avg Val Loss: 0.2954\n",
      "\n",
      "Validation loss improved from 0.2958 to 0.2954. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3208\n",
      "LOG: Epoch [197/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2950\n",
      "Epoch [197/2000], Avg Train Loss: 0.3208, Avg Val Loss: 0.2950\n",
      "\n",
      "Validation loss improved from 0.2954 to 0.2950. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3175\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2946\n",
      "Epoch [198/2000], Avg Train Loss: 0.3175, Avg Val Loss: 0.2946\n",
      "\n",
      "Validation loss improved from 0.2950 to 0.2946. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3171\n",
      "LOG: Epoch [199/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2942\n",
      "Epoch [199/2000], Avg Train Loss: 0.3171, Avg Val Loss: 0.2942\n",
      "\n",
      "Validation loss improved from 0.2946 to 0.2942. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3166\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2938\n",
      "Epoch [200/2000], Avg Train Loss: 0.3166, Avg Val Loss: 0.2938\n",
      "\n",
      "Validation loss improved from 0.2942 to 0.2938. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3191\n",
      "LOG: Epoch [201/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2934\n",
      "Epoch [201/2000], Avg Train Loss: 0.3191, Avg Val Loss: 0.2934\n",
      "\n",
      "Validation loss improved from 0.2938 to 0.2934. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3184\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2929\n",
      "Epoch [202/2000], Avg Train Loss: 0.3184, Avg Val Loss: 0.2929\n",
      "\n",
      "Validation loss improved from 0.2934 to 0.2929. Saving model...\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3250\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2926\n",
      "Epoch [203/2000], Avg Train Loss: 0.3250, Avg Val Loss: 0.2926\n",
      "\n",
      "Validation loss improved from 0.2929 to 0.2926. Saving model...\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3221\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2922\n",
      "Epoch [204/2000], Avg Train Loss: 0.3221, Avg Val Loss: 0.2922\n",
      "\n",
      "Validation loss improved from 0.2926 to 0.2922. Saving model...\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3176\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2918\n",
      "Epoch [205/2000], Avg Train Loss: 0.3176, Avg Val Loss: 0.2918\n",
      "\n",
      "Validation loss improved from 0.2922 to 0.2918. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3186\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2915\n",
      "Epoch [206/2000], Avg Train Loss: 0.3186, Avg Val Loss: 0.2915\n",
      "\n",
      "Validation loss improved from 0.2918 to 0.2915. Saving model...\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3132\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2911\n",
      "Epoch [207/2000], Avg Train Loss: 0.3132, Avg Val Loss: 0.2911\n",
      "\n",
      "Validation loss improved from 0.2915 to 0.2911. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3206\n",
      "LOG: Epoch [208/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2908\n",
      "Epoch [208/2000], Avg Train Loss: 0.3206, Avg Val Loss: 0.2908\n",
      "\n",
      "Validation loss improved from 0.2911 to 0.2908. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3131\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2905\n",
      "Epoch [209/2000], Avg Train Loss: 0.3131, Avg Val Loss: 0.2905\n",
      "\n",
      "Validation loss improved from 0.2908 to 0.2905. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3183\n",
      "LOG: Epoch [210/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2902\n",
      "Epoch [210/2000], Avg Train Loss: 0.3183, Avg Val Loss: 0.2902\n",
      "\n",
      "Validation loss improved from 0.2905 to 0.2902. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3189\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2899\n",
      "Epoch [211/2000], Avg Train Loss: 0.3189, Avg Val Loss: 0.2899\n",
      "\n",
      "Validation loss improved from 0.2902 to 0.2899. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3162\n",
      "LOG: Epoch [212/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2897\n",
      "Epoch [212/2000], Avg Train Loss: 0.3162, Avg Val Loss: 0.2897\n",
      "\n",
      "Validation loss improved from 0.2899 to 0.2897. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3104\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2893\n",
      "Epoch [213/2000], Avg Train Loss: 0.3104, Avg Val Loss: 0.2893\n",
      "\n",
      "Validation loss improved from 0.2897 to 0.2893. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3130\n",
      "LOG: Epoch [214/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2890\n",
      "Epoch [214/2000], Avg Train Loss: 0.3130, Avg Val Loss: 0.2890\n",
      "\n",
      "Validation loss improved from 0.2893 to 0.2890. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3103\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2887\n",
      "Epoch [215/2000], Avg Train Loss: 0.3103, Avg Val Loss: 0.2887\n",
      "\n",
      "Validation loss improved from 0.2890 to 0.2887. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3090\n",
      "LOG: Epoch [216/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2883\n",
      "Epoch [216/2000], Avg Train Loss: 0.3090, Avg Val Loss: 0.2883\n",
      "\n",
      "Validation loss improved from 0.2887 to 0.2883. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3116\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2880\n",
      "Epoch [217/2000], Avg Train Loss: 0.3116, Avg Val Loss: 0.2880\n",
      "\n",
      "Validation loss improved from 0.2883 to 0.2880. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3164\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2877\n",
      "Epoch [218/2000], Avg Train Loss: 0.3164, Avg Val Loss: 0.2877\n",
      "\n",
      "Validation loss improved from 0.2880 to 0.2877. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3063\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2873\n",
      "Epoch [219/2000], Avg Train Loss: 0.3063, Avg Val Loss: 0.2873\n",
      "\n",
      "Validation loss improved from 0.2877 to 0.2873. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3077\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2870\n",
      "Epoch [220/2000], Avg Train Loss: 0.3077, Avg Val Loss: 0.2870\n",
      "\n",
      "Validation loss improved from 0.2873 to 0.2870. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3073\n",
      "LOG: Epoch [221/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2866\n",
      "Epoch [221/2000], Avg Train Loss: 0.3073, Avg Val Loss: 0.2866\n",
      "\n",
      "Validation loss improved from 0.2870 to 0.2866. Saving model...\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3074\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2863\n",
      "Epoch [222/2000], Avg Train Loss: 0.3074, Avg Val Loss: 0.2863\n",
      "\n",
      "Validation loss improved from 0.2866 to 0.2863. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3106\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2860\n",
      "Epoch [223/2000], Avg Train Loss: 0.3106, Avg Val Loss: 0.2860\n",
      "\n",
      "Validation loss improved from 0.2863 to 0.2860. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3029\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2856\n",
      "Epoch [224/2000], Avg Train Loss: 0.3029, Avg Val Loss: 0.2856\n",
      "\n",
      "Validation loss improved from 0.2860 to 0.2856. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3067\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2853\n",
      "Epoch [225/2000], Avg Train Loss: 0.3067, Avg Val Loss: 0.2853\n",
      "\n",
      "Validation loss improved from 0.2856 to 0.2853. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3032\n",
      "LOG: Epoch [226/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2849\n",
      "Epoch [226/2000], Avg Train Loss: 0.3032, Avg Val Loss: 0.2849\n",
      "\n",
      "Validation loss improved from 0.2853 to 0.2849. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3103\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2846\n",
      "Epoch [227/2000], Avg Train Loss: 0.3103, Avg Val Loss: 0.2846\n",
      "\n",
      "Validation loss improved from 0.2849 to 0.2846. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3069\n",
      "LOG: Epoch [228/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2843\n",
      "Epoch [228/2000], Avg Train Loss: 0.3069, Avg Val Loss: 0.2843\n",
      "\n",
      "Validation loss improved from 0.2846 to 0.2843. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3053\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2839\n",
      "Epoch [229/2000], Avg Train Loss: 0.3053, Avg Val Loss: 0.2839\n",
      "\n",
      "Validation loss improved from 0.2843 to 0.2839. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3120\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2836\n",
      "Epoch [230/2000], Avg Train Loss: 0.3120, Avg Val Loss: 0.2836\n",
      "\n",
      "Validation loss improved from 0.2839 to 0.2836. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2961\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2832\n",
      "Epoch [231/2000], Avg Train Loss: 0.2961, Avg Val Loss: 0.2832\n",
      "\n",
      "Validation loss improved from 0.2836 to 0.2832. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3059\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2829\n",
      "Epoch [232/2000], Avg Train Loss: 0.3059, Avg Val Loss: 0.2829\n",
      "\n",
      "Validation loss improved from 0.2832 to 0.2829. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3057\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2825\n",
      "Epoch [233/2000], Avg Train Loss: 0.3057, Avg Val Loss: 0.2825\n",
      "\n",
      "Validation loss improved from 0.2829 to 0.2825. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3043\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2822\n",
      "Epoch [234/2000], Avg Train Loss: 0.3043, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2825 to 0.2822. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2997\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2818\n",
      "Epoch [235/2000], Avg Train Loss: 0.2997, Avg Val Loss: 0.2818\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2818. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3039\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2814\n",
      "Epoch [236/2000], Avg Train Loss: 0.3039, Avg Val Loss: 0.2814\n",
      "\n",
      "Validation loss improved from 0.2818 to 0.2814. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3055\n",
      "LOG: Epoch [237/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2811\n",
      "Epoch [237/2000], Avg Train Loss: 0.3055, Avg Val Loss: 0.2811\n",
      "\n",
      "Validation loss improved from 0.2814 to 0.2811. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2980\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2808\n",
      "Epoch [238/2000], Avg Train Loss: 0.2980, Avg Val Loss: 0.2808\n",
      "\n",
      "Validation loss improved from 0.2811 to 0.2808. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3000\n",
      "LOG: Epoch [239/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2805\n",
      "Epoch [239/2000], Avg Train Loss: 0.3000, Avg Val Loss: 0.2805\n",
      "\n",
      "Validation loss improved from 0.2808 to 0.2805. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2981\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2802\n",
      "Epoch [240/2000], Avg Train Loss: 0.2981, Avg Val Loss: 0.2802\n",
      "\n",
      "Validation loss improved from 0.2805 to 0.2802. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2973\n",
      "LOG: Epoch [241/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2799\n",
      "Epoch [241/2000], Avg Train Loss: 0.2973, Avg Val Loss: 0.2799\n",
      "\n",
      "Validation loss improved from 0.2802 to 0.2799. Saving model...\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2972\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2796\n",
      "Epoch [242/2000], Avg Train Loss: 0.2972, Avg Val Loss: 0.2796\n",
      "\n",
      "Validation loss improved from 0.2799 to 0.2796. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2969\n",
      "LOG: Epoch [243/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2794\n",
      "Epoch [243/2000], Avg Train Loss: 0.2969, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2796 to 0.2794. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2995\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2791\n",
      "Epoch [244/2000], Avg Train Loss: 0.2995, Avg Val Loss: 0.2791\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2791. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2955\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2788\n",
      "Epoch [245/2000], Avg Train Loss: 0.2955, Avg Val Loss: 0.2788\n",
      "\n",
      "Validation loss improved from 0.2791 to 0.2788. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3046\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2785\n",
      "Epoch [246/2000], Avg Train Loss: 0.3046, Avg Val Loss: 0.2785\n",
      "\n",
      "Validation loss improved from 0.2788 to 0.2785. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2943\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2782\n",
      "Epoch [247/2000], Avg Train Loss: 0.2943, Avg Val Loss: 0.2782\n",
      "\n",
      "Validation loss improved from 0.2785 to 0.2782. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2934\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2780\n",
      "Epoch [248/2000], Avg Train Loss: 0.2934, Avg Val Loss: 0.2780\n",
      "\n",
      "Validation loss improved from 0.2782 to 0.2780. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2893\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2777\n",
      "Epoch [249/2000], Avg Train Loss: 0.2893, Avg Val Loss: 0.2777\n",
      "\n",
      "Validation loss improved from 0.2780 to 0.2777. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2896\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2774\n",
      "Epoch [250/2000], Avg Train Loss: 0.2896, Avg Val Loss: 0.2774\n",
      "\n",
      "Validation loss improved from 0.2777 to 0.2774. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2947\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2771\n",
      "Epoch [251/2000], Avg Train Loss: 0.2947, Avg Val Loss: 0.2771\n",
      "\n",
      "Validation loss improved from 0.2774 to 0.2771. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2909\n",
      "LOG: Epoch [252/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2769\n",
      "Epoch [252/2000], Avg Train Loss: 0.2909, Avg Val Loss: 0.2769\n",
      "\n",
      "Validation loss improved from 0.2771 to 0.2769. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2898\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2766\n",
      "Epoch [253/2000], Avg Train Loss: 0.2898, Avg Val Loss: 0.2766\n",
      "\n",
      "Validation loss improved from 0.2769 to 0.2766. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2946\n",
      "LOG: Epoch [254/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2763\n",
      "Epoch [254/2000], Avg Train Loss: 0.2946, Avg Val Loss: 0.2763\n",
      "\n",
      "Validation loss improved from 0.2766 to 0.2763. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2960\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2761\n",
      "Epoch [255/2000], Avg Train Loss: 0.2960, Avg Val Loss: 0.2761\n",
      "\n",
      "Validation loss improved from 0.2763 to 0.2761. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2971\n",
      "LOG: Epoch [256/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2759\n",
      "Epoch [256/2000], Avg Train Loss: 0.2971, Avg Val Loss: 0.2759\n",
      "\n",
      "Validation loss improved from 0.2761 to 0.2759. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2943\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2756\n",
      "Epoch [257/2000], Avg Train Loss: 0.2943, Avg Val Loss: 0.2756\n",
      "\n",
      "Validation loss improved from 0.2759 to 0.2756. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2917\n",
      "LOG: Epoch [258/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2754\n",
      "Epoch [258/2000], Avg Train Loss: 0.2917, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2756 to 0.2754. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2952\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2751\n",
      "Epoch [259/2000], Avg Train Loss: 0.2952, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2751. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [260/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2748\n",
      "Epoch [260/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2748\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2748. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2866\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2746\n",
      "Epoch [261/2000], Avg Train Loss: 0.2866, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2748 to 0.2746. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2949\n",
      "LOG: Epoch [262/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2743\n",
      "Epoch [262/2000], Avg Train Loss: 0.2949, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2743. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2957\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2741\n",
      "Epoch [263/2000], Avg Train Loss: 0.2957, Avg Val Loss: 0.2741\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2741. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2878\n",
      "LOG: Epoch [264/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2738\n",
      "Epoch [264/2000], Avg Train Loss: 0.2878, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2741 to 0.2738. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2736\n",
      "Epoch [265/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.2736\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2736. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2734\n",
      "Epoch [266/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2734\n",
      "\n",
      "Validation loss improved from 0.2736 to 0.2734. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2732\n",
      "Epoch [267/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2734 to 0.2732. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2729\n",
      "Epoch [268/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2729\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2729. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2918\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [269/2000], Avg Train Loss: 0.2918, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2729 to 0.2727. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2725\n",
      "Epoch [270/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2725. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2889\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2723\n",
      "Epoch [271/2000], Avg Train Loss: 0.2889, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2723. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2721\n",
      "Epoch [272/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2721\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2721. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2719\n",
      "Epoch [273/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2719\n",
      "\n",
      "Validation loss improved from 0.2721 to 0.2719. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2717\n",
      "Epoch [274/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2719 to 0.2717. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2715\n",
      "Epoch [275/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2715\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2715. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2713\n",
      "Epoch [276/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2713\n",
      "\n",
      "Validation loss improved from 0.2715 to 0.2713. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2711\n",
      "Epoch [277/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2713 to 0.2711. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2709\n",
      "Epoch [278/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2709. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2706\n",
      "Epoch [279/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2706\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2706. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [280/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2704\n",
      "Epoch [280/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2704\n",
      "\n",
      "Validation loss improved from 0.2706 to 0.2704. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2701\n",
      "Epoch [281/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2701\n",
      "\n",
      "Validation loss improved from 0.2704 to 0.2701. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [282/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2699\n",
      "Epoch [282/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2699\n",
      "\n",
      "Validation loss improved from 0.2701 to 0.2699. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2748\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2696\n",
      "Epoch [283/2000], Avg Train Loss: 0.2748, Avg Val Loss: 0.2696\n",
      "\n",
      "Validation loss improved from 0.2699 to 0.2696. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2694\n",
      "Epoch [284/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2694\n",
      "\n",
      "Validation loss improved from 0.2696 to 0.2694. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2691\n",
      "Epoch [285/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2694 to 0.2691. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2689\n",
      "Epoch [286/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2689. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2710\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2687\n",
      "Epoch [287/2000], Avg Train Loss: 0.2710, Avg Val Loss: 0.2687\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2687. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [288/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2685\n",
      "Epoch [288/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2685\n",
      "\n",
      "Validation loss improved from 0.2687 to 0.2685. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2683\n",
      "Epoch [289/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2683\n",
      "\n",
      "Validation loss improved from 0.2685 to 0.2683. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2681\n",
      "Epoch [290/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2681\n",
      "\n",
      "Validation loss improved from 0.2683 to 0.2681. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2751\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2679\n",
      "Epoch [291/2000], Avg Train Loss: 0.2751, Avg Val Loss: 0.2679\n",
      "\n",
      "Validation loss improved from 0.2681 to 0.2679. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2677\n",
      "Epoch [292/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2679 to 0.2677. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2719\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2675\n",
      "Epoch [293/2000], Avg Train Loss: 0.2719, Avg Val Loss: 0.2675\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2675. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2673\n",
      "Epoch [294/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2675 to 0.2673. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2728\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2671\n",
      "Epoch [295/2000], Avg Train Loss: 0.2728, Avg Val Loss: 0.2671\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2671. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [296/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2669\n",
      "Epoch [296/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2669\n",
      "\n",
      "Validation loss improved from 0.2671 to 0.2669. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2667\n",
      "Epoch [297/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2667\n",
      "\n",
      "Validation loss improved from 0.2669 to 0.2667. Saving model...\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [298/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2666\n",
      "Epoch [298/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2667 to 0.2666. Saving model...\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2678\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2664\n",
      "Epoch [299/2000], Avg Train Loss: 0.2678, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2664. Saving model...\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2696\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2662\n",
      "Epoch [300/2000], Avg Train Loss: 0.2696, Avg Val Loss: 0.2662\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2662. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2729\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2660\n",
      "Epoch [301/2000], Avg Train Loss: 0.2729, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2662 to 0.2660. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2695\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2658\n",
      "Epoch [302/2000], Avg Train Loss: 0.2695, Avg Val Loss: 0.2658\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2658. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2703\n",
      "LOG: Epoch [303/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2656\n",
      "Epoch [303/2000], Avg Train Loss: 0.2703, Avg Val Loss: 0.2656\n",
      "\n",
      "Validation loss improved from 0.2658 to 0.2656. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2654\n",
      "Epoch [304/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2654\n",
      "\n",
      "Validation loss improved from 0.2656 to 0.2654. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [305/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2652\n",
      "Epoch [305/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2652\n",
      "\n",
      "Validation loss improved from 0.2654 to 0.2652. Saving model...\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2704\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2650\n",
      "Epoch [306/2000], Avg Train Loss: 0.2704, Avg Val Loss: 0.2650\n",
      "\n",
      "Validation loss improved from 0.2652 to 0.2650. Saving model...\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2648\n",
      "Epoch [307/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2648\n",
      "\n",
      "Validation loss improved from 0.2650 to 0.2648. Saving model...\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2696\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2647\n",
      "Epoch [308/2000], Avg Train Loss: 0.2696, Avg Val Loss: 0.2647\n",
      "\n",
      "Validation loss improved from 0.2648 to 0.2647. Saving model...\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2651\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2645\n",
      "Epoch [309/2000], Avg Train Loss: 0.2651, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2647 to 0.2645. Saving model...\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2724\n",
      "LOG: Epoch [310/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2643\n",
      "Epoch [310/2000], Avg Train Loss: 0.2724, Avg Val Loss: 0.2643\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2643. Saving model...\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2668\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2642\n",
      "Epoch [311/2000], Avg Train Loss: 0.2668, Avg Val Loss: 0.2642\n",
      "\n",
      "Validation loss improved from 0.2643 to 0.2642. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2686\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2641\n",
      "Epoch [312/2000], Avg Train Loss: 0.2686, Avg Val Loss: 0.2641\n",
      "\n",
      "Validation loss improved from 0.2642 to 0.2641. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2749\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2639\n",
      "Epoch [313/2000], Avg Train Loss: 0.2749, Avg Val Loss: 0.2639\n",
      "\n",
      "Validation loss improved from 0.2641 to 0.2639. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2709\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2638\n",
      "Epoch [314/2000], Avg Train Loss: 0.2709, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2639 to 0.2638. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2719\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2637\n",
      "Epoch [315/2000], Avg Train Loss: 0.2719, Avg Val Loss: 0.2637\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2637. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2635\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2635\n",
      "Epoch [316/2000], Avg Train Loss: 0.2635, Avg Val Loss: 0.2635\n",
      "\n",
      "Validation loss improved from 0.2637 to 0.2635. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [317/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2633\n",
      "Epoch [317/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2633\n",
      "\n",
      "Validation loss improved from 0.2635 to 0.2633. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2559\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2631\n",
      "Epoch [318/2000], Avg Train Loss: 0.2559, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2633 to 0.2631. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2574\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2629\n",
      "Epoch [319/2000], Avg Train Loss: 0.2574, Avg Val Loss: 0.2629\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2629. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2693\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2627\n",
      "Epoch [320/2000], Avg Train Loss: 0.2693, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2629 to 0.2627. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2613\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2626\n",
      "Epoch [321/2000], Avg Train Loss: 0.2613, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2626. Saving model...\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2544\n",
      "LOG: Epoch [322/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2624\n",
      "Epoch [322/2000], Avg Train Loss: 0.2544, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2624. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2642\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2622\n",
      "Epoch [323/2000], Avg Train Loss: 0.2642, Avg Val Loss: 0.2622\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2622. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2668\n",
      "LOG: Epoch [324/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2620\n",
      "Epoch [324/2000], Avg Train Loss: 0.2668, Avg Val Loss: 0.2620\n",
      "\n",
      "Validation loss improved from 0.2622 to 0.2620. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2713\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2617\n",
      "Epoch [325/2000], Avg Train Loss: 0.2713, Avg Val Loss: 0.2617\n",
      "\n",
      "Validation loss improved from 0.2620 to 0.2617. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2649\n",
      "LOG: Epoch [326/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2615\n",
      "Epoch [326/2000], Avg Train Loss: 0.2649, Avg Val Loss: 0.2615\n",
      "\n",
      "Validation loss improved from 0.2617 to 0.2615. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2655\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2613\n",
      "Epoch [327/2000], Avg Train Loss: 0.2655, Avg Val Loss: 0.2613\n",
      "\n",
      "Validation loss improved from 0.2615 to 0.2613. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2697\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2612\n",
      "Epoch [328/2000], Avg Train Loss: 0.2697, Avg Val Loss: 0.2612\n",
      "\n",
      "Validation loss improved from 0.2613 to 0.2612. Saving model...\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2618\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2610\n",
      "Epoch [329/2000], Avg Train Loss: 0.2618, Avg Val Loss: 0.2610\n",
      "\n",
      "Validation loss improved from 0.2612 to 0.2610. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2644\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2608\n",
      "Epoch [330/2000], Avg Train Loss: 0.2644, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2610 to 0.2608. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2650\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2607\n",
      "Epoch [331/2000], Avg Train Loss: 0.2650, Avg Val Loss: 0.2607\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2607. Saving model...\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2617\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2605\n",
      "Epoch [332/2000], Avg Train Loss: 0.2617, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2607 to 0.2605. Saving model...\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2590\n",
      "LOG: Epoch [333/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2604\n",
      "Epoch [333/2000], Avg Train Loss: 0.2590, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2604. Saving model...\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2582\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2602\n",
      "Epoch [334/2000], Avg Train Loss: 0.2582, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2602. Saving model...\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2599\n",
      "LOG: Epoch [335/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2600\n",
      "Epoch [335/2000], Avg Train Loss: 0.2599, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2600. Saving model...\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2578\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2598\n",
      "Epoch [336/2000], Avg Train Loss: 0.2578, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2598. Saving model...\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2510\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2596\n",
      "Epoch [337/2000], Avg Train Loss: 0.2510, Avg Val Loss: 0.2596\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2596. Saving model...\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2584\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2595\n",
      "Epoch [338/2000], Avg Train Loss: 0.2584, Avg Val Loss: 0.2595\n",
      "\n",
      "Validation loss improved from 0.2596 to 0.2595. Saving model...\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2631\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2593\n",
      "Epoch [339/2000], Avg Train Loss: 0.2631, Avg Val Loss: 0.2593\n",
      "\n",
      "Validation loss improved from 0.2595 to 0.2593. Saving model...\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2549\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2591\n",
      "Epoch [340/2000], Avg Train Loss: 0.2549, Avg Val Loss: 0.2591\n",
      "\n",
      "Validation loss improved from 0.2593 to 0.2591. Saving model...\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2609\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2589\n",
      "Epoch [341/2000], Avg Train Loss: 0.2609, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2591 to 0.2589. Saving model...\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2563\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2588\n",
      "Epoch [342/2000], Avg Train Loss: 0.2563, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2588. Saving model...\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2501\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2586\n",
      "Epoch [343/2000], Avg Train Loss: 0.2501, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2586. Saving model...\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2561\n",
      "LOG: Epoch [344/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2585\n",
      "Epoch [344/2000], Avg Train Loss: 0.2561, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2585. Saving model...\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2506\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2584\n",
      "Epoch [345/2000], Avg Train Loss: 0.2506, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2584. Saving model...\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2602\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2582\n",
      "Epoch [346/2000], Avg Train Loss: 0.2602, Avg Val Loss: 0.2582\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2582. Saving model...\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2591\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2581\n",
      "Epoch [347/2000], Avg Train Loss: 0.2591, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2582 to 0.2581. Saving model...\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2506\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2580\n",
      "Epoch [348/2000], Avg Train Loss: 0.2506, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2580. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2621\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2579\n",
      "Epoch [349/2000], Avg Train Loss: 0.2621, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2579. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2485\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2578\n",
      "Epoch [350/2000], Avg Train Loss: 0.2485, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2578. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2504\n",
      "LOG: Epoch [351/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2577\n",
      "Epoch [351/2000], Avg Train Loss: 0.2504, Avg Val Loss: 0.2577\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2577. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2536\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2576\n",
      "Epoch [352/2000], Avg Train Loss: 0.2536, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2577 to 0.2576. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2551\n",
      "LOG: Epoch [353/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2575\n",
      "Epoch [353/2000], Avg Train Loss: 0.2551, Avg Val Loss: 0.2575\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2575. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2651\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2574\n",
      "Epoch [354/2000], Avg Train Loss: 0.2651, Avg Val Loss: 0.2574\n",
      "\n",
      "Validation loss improved from 0.2575 to 0.2574. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2475\n",
      "LOG: Epoch [355/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2573\n",
      "Epoch [355/2000], Avg Train Loss: 0.2475, Avg Val Loss: 0.2573\n",
      "\n",
      "Validation loss improved from 0.2574 to 0.2573. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2525\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2573\n",
      "Epoch [356/2000], Avg Train Loss: 0.2525, Avg Val Loss: 0.2573\n",
      "\n",
      "Validation loss improved from 0.2573 to 0.2573. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2500\n",
      "LOG: Epoch [357/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2572\n",
      "Epoch [357/2000], Avg Train Loss: 0.2500, Avg Val Loss: 0.2572\n",
      "\n",
      "Validation loss improved from 0.2573 to 0.2572. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2533\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2571\n",
      "Epoch [358/2000], Avg Train Loss: 0.2533, Avg Val Loss: 0.2571\n",
      "\n",
      "Validation loss improved from 0.2572 to 0.2571. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2469\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2570\n",
      "Epoch [359/2000], Avg Train Loss: 0.2469, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2571 to 0.2570. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2505\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2569\n",
      "Epoch [360/2000], Avg Train Loss: 0.2505, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2569. Saving model...\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2470\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2568\n",
      "Epoch [361/2000], Avg Train Loss: 0.2470, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2568. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2481\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2567\n",
      "Epoch [362/2000], Avg Train Loss: 0.2481, Avg Val Loss: 0.2567\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2567. Saving model...\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2474\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2566\n",
      "Epoch [363/2000], Avg Train Loss: 0.2474, Avg Val Loss: 0.2566\n",
      "\n",
      "Validation loss improved from 0.2567 to 0.2566. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2542\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2564\n",
      "Epoch [364/2000], Avg Train Loss: 0.2542, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2566 to 0.2564. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2486\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2563\n",
      "Epoch [365/2000], Avg Train Loss: 0.2486, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2563. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2515\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2561\n",
      "Epoch [366/2000], Avg Train Loss: 0.2515, Avg Val Loss: 0.2561\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2561. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2408\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2559\n",
      "Epoch [367/2000], Avg Train Loss: 0.2408, Avg Val Loss: 0.2559\n",
      "\n",
      "Validation loss improved from 0.2561 to 0.2559. Saving model...\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2418\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2557\n",
      "Epoch [368/2000], Avg Train Loss: 0.2418, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2559 to 0.2557. Saving model...\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2467\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2555\n",
      "Epoch [369/2000], Avg Train Loss: 0.2467, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2555. Saving model...\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2518\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2554\n",
      "Epoch [370/2000], Avg Train Loss: 0.2518, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2554. Saving model...\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2452\n",
      "LOG: Epoch [371/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2552\n",
      "Epoch [371/2000], Avg Train Loss: 0.2452, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2552. Saving model...\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2436\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2551\n",
      "Epoch [372/2000], Avg Train Loss: 0.2436, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2551. Saving model...\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2430\n",
      "LOG: Epoch [373/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2550\n",
      "Epoch [373/2000], Avg Train Loss: 0.2430, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2550. Saving model...\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2457\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2549\n",
      "Epoch [374/2000], Avg Train Loss: 0.2457, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2549. Saving model...\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2520\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2548\n",
      "Epoch [375/2000], Avg Train Loss: 0.2520, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2548. Saving model...\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2460\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2547\n",
      "Epoch [376/2000], Avg Train Loss: 0.2460, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2547. Saving model...\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2386\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2546\n",
      "Epoch [377/2000], Avg Train Loss: 0.2386, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2546. Saving model...\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2475\n",
      "LOG: Epoch [378/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2545\n",
      "Epoch [378/2000], Avg Train Loss: 0.2475, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2545. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2389\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2544\n",
      "Epoch [379/2000], Avg Train Loss: 0.2389, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2544. Saving model...\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2480\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2543\n",
      "Epoch [380/2000], Avg Train Loss: 0.2480, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2543. Saving model...\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2457\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2542\n",
      "Epoch [381/2000], Avg Train Loss: 0.2457, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2542. Saving model...\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2435\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2541\n",
      "Epoch [382/2000], Avg Train Loss: 0.2435, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2541. Saving model...\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2409\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2539\n",
      "Epoch [383/2000], Avg Train Loss: 0.2409, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2539. Saving model...\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2488\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2538\n",
      "Epoch [384/2000], Avg Train Loss: 0.2488, Avg Val Loss: 0.2538\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2538. Saving model...\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2477\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2537\n",
      "Epoch [385/2000], Avg Train Loss: 0.2477, Avg Val Loss: 0.2537\n",
      "\n",
      "Validation loss improved from 0.2538 to 0.2537. Saving model...\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2456\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2535\n",
      "Epoch [386/2000], Avg Train Loss: 0.2456, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2537 to 0.2535. Saving model...\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2434\n",
      "LOG: Epoch [387/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2533\n",
      "Epoch [387/2000], Avg Train Loss: 0.2434, Avg Val Loss: 0.2533\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2533. Saving model...\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2454\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2531\n",
      "Epoch [388/2000], Avg Train Loss: 0.2454, Avg Val Loss: 0.2531\n",
      "\n",
      "Validation loss improved from 0.2533 to 0.2531. Saving model...\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2474\n",
      "LOG: Epoch [389/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2530\n",
      "Epoch [389/2000], Avg Train Loss: 0.2474, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2531 to 0.2530. Saving model...\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2405\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2528\n",
      "Epoch [390/2000], Avg Train Loss: 0.2405, Avg Val Loss: 0.2528\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2528. Saving model...\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2463\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2527\n",
      "Epoch [391/2000], Avg Train Loss: 0.2463, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2528 to 0.2527. Saving model...\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2432\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2526\n",
      "Epoch [392/2000], Avg Train Loss: 0.2432, Avg Val Loss: 0.2526\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2526. Saving model...\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2392\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2524\n",
      "Epoch [393/2000], Avg Train Loss: 0.2392, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2526 to 0.2524. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2491\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2523\n",
      "Epoch [394/2000], Avg Train Loss: 0.2491, Avg Val Loss: 0.2523\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2523. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2426\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2522\n",
      "Epoch [395/2000], Avg Train Loss: 0.2426, Avg Val Loss: 0.2522\n",
      "\n",
      "Validation loss improved from 0.2523 to 0.2522. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2392\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2521\n",
      "Epoch [396/2000], Avg Train Loss: 0.2392, Avg Val Loss: 0.2521\n",
      "\n",
      "Validation loss improved from 0.2522 to 0.2521. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2394\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2520\n",
      "Epoch [397/2000], Avg Train Loss: 0.2394, Avg Val Loss: 0.2520\n",
      "\n",
      "Validation loss improved from 0.2521 to 0.2520. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2381\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2518\n",
      "Epoch [398/2000], Avg Train Loss: 0.2381, Avg Val Loss: 0.2518\n",
      "\n",
      "Validation loss improved from 0.2520 to 0.2518. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2460\n",
      "LOG: Epoch [399/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2517\n",
      "Epoch [399/2000], Avg Train Loss: 0.2460, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2518 to 0.2517. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2364\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2516\n",
      "Epoch [400/2000], Avg Train Loss: 0.2364, Avg Val Loss: 0.2516\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2516. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2364\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2514\n",
      "Epoch [401/2000], Avg Train Loss: 0.2364, Avg Val Loss: 0.2514\n",
      "\n",
      "Validation loss improved from 0.2516 to 0.2514. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2450\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2513\n",
      "Epoch [402/2000], Avg Train Loss: 0.2450, Avg Val Loss: 0.2513\n",
      "\n",
      "Validation loss improved from 0.2514 to 0.2513. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2355\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2511\n",
      "Epoch [403/2000], Avg Train Loss: 0.2355, Avg Val Loss: 0.2511\n",
      "\n",
      "Validation loss improved from 0.2513 to 0.2511. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2314\n",
      "LOG: Epoch [404/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2510\n",
      "Epoch [404/2000], Avg Train Loss: 0.2314, Avg Val Loss: 0.2510\n",
      "\n",
      "Validation loss improved from 0.2511 to 0.2510. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2354\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2508\n",
      "Epoch [405/2000], Avg Train Loss: 0.2354, Avg Val Loss: 0.2508\n",
      "\n",
      "Validation loss improved from 0.2510 to 0.2508. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2356\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2507\n",
      "Epoch [406/2000], Avg Train Loss: 0.2356, Avg Val Loss: 0.2507\n",
      "\n",
      "Validation loss improved from 0.2508 to 0.2507. Saving model...\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2370\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2506\n",
      "Epoch [407/2000], Avg Train Loss: 0.2370, Avg Val Loss: 0.2506\n",
      "\n",
      "Validation loss improved from 0.2507 to 0.2506. Saving model...\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2345\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2505\n",
      "Epoch [408/2000], Avg Train Loss: 0.2345, Avg Val Loss: 0.2505\n",
      "\n",
      "Validation loss improved from 0.2506 to 0.2505. Saving model...\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2318\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2504\n",
      "Epoch [409/2000], Avg Train Loss: 0.2318, Avg Val Loss: 0.2504\n",
      "\n",
      "Validation loss improved from 0.2505 to 0.2504. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2281\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2503\n",
      "Epoch [410/2000], Avg Train Loss: 0.2281, Avg Val Loss: 0.2503\n",
      "\n",
      "Validation loss improved from 0.2504 to 0.2503. Saving model...\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2359\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2502\n",
      "Epoch [411/2000], Avg Train Loss: 0.2359, Avg Val Loss: 0.2502\n",
      "\n",
      "Validation loss improved from 0.2503 to 0.2502. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2350\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2500\n",
      "Epoch [412/2000], Avg Train Loss: 0.2350, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2502 to 0.2500. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2310\n",
      "LOG: Epoch [413/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2499\n",
      "Epoch [413/2000], Avg Train Loss: 0.2310, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2499. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2312\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2498\n",
      "Epoch [414/2000], Avg Train Loss: 0.2312, Avg Val Loss: 0.2498\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2498. Saving model...\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2306\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2497\n",
      "Epoch [415/2000], Avg Train Loss: 0.2306, Avg Val Loss: 0.2497\n",
      "\n",
      "Validation loss improved from 0.2498 to 0.2497. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2359\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2495\n",
      "Epoch [416/2000], Avg Train Loss: 0.2359, Avg Val Loss: 0.2495\n",
      "\n",
      "Validation loss improved from 0.2497 to 0.2495. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2284\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2494\n",
      "Epoch [417/2000], Avg Train Loss: 0.2284, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2495 to 0.2494. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2358\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2494\n",
      "Epoch [418/2000], Avg Train Loss: 0.2358, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2494. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2375\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2493\n",
      "Epoch [419/2000], Avg Train Loss: 0.2375, Avg Val Loss: 0.2493\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2493. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2346\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2492\n",
      "Epoch [420/2000], Avg Train Loss: 0.2346, Avg Val Loss: 0.2492\n",
      "\n",
      "Validation loss improved from 0.2493 to 0.2492. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2318\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2492\n",
      "Epoch [421/2000], Avg Train Loss: 0.2318, Avg Val Loss: 0.2492\n",
      "\n",
      "Validation loss improved from 0.2492 to 0.2492. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2289\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2491\n",
      "Epoch [422/2000], Avg Train Loss: 0.2289, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2492 to 0.2491. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2374\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2489\n",
      "Epoch [423/2000], Avg Train Loss: 0.2374, Avg Val Loss: 0.2489\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2489. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2256\n",
      "LOG: Epoch [424/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2488\n",
      "Epoch [424/2000], Avg Train Loss: 0.2256, Avg Val Loss: 0.2488\n",
      "\n",
      "Validation loss improved from 0.2489 to 0.2488. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2217\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2487\n",
      "Epoch [425/2000], Avg Train Loss: 0.2217, Avg Val Loss: 0.2487\n",
      "\n",
      "Validation loss improved from 0.2488 to 0.2487. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2357\n",
      "LOG: Epoch [426/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2485\n",
      "Epoch [426/2000], Avg Train Loss: 0.2357, Avg Val Loss: 0.2485\n",
      "\n",
      "Validation loss improved from 0.2487 to 0.2485. Saving model...\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2318\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2483\n",
      "Epoch [427/2000], Avg Train Loss: 0.2318, Avg Val Loss: 0.2483\n",
      "\n",
      "Validation loss improved from 0.2485 to 0.2483. Saving model...\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2309\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2481\n",
      "Epoch [428/2000], Avg Train Loss: 0.2309, Avg Val Loss: 0.2481\n",
      "\n",
      "Validation loss improved from 0.2483 to 0.2481. Saving model...\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2274\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2480\n",
      "Epoch [429/2000], Avg Train Loss: 0.2274, Avg Val Loss: 0.2480\n",
      "\n",
      "Validation loss improved from 0.2481 to 0.2480. Saving model...\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2227\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2478\n",
      "Epoch [430/2000], Avg Train Loss: 0.2227, Avg Val Loss: 0.2478\n",
      "\n",
      "Validation loss improved from 0.2480 to 0.2478. Saving model...\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2253\n",
      "LOG: Epoch [431/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2477\n",
      "Epoch [431/2000], Avg Train Loss: 0.2253, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2478 to 0.2477. Saving model...\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2306\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2476\n",
      "Epoch [432/2000], Avg Train Loss: 0.2306, Avg Val Loss: 0.2476\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2476. Saving model...\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2250\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2474\n",
      "Epoch [433/2000], Avg Train Loss: 0.2250, Avg Val Loss: 0.2474\n",
      "\n",
      "Validation loss improved from 0.2476 to 0.2474. Saving model...\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2289\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2473\n",
      "Epoch [434/2000], Avg Train Loss: 0.2289, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2474 to 0.2473. Saving model...\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2332\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2471\n",
      "Epoch [435/2000], Avg Train Loss: 0.2332, Avg Val Loss: 0.2471\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2471. Saving model...\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2231\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2470\n",
      "Epoch [436/2000], Avg Train Loss: 0.2231, Avg Val Loss: 0.2470\n",
      "\n",
      "Validation loss improved from 0.2471 to 0.2470. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2285\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2468\n",
      "Epoch [437/2000], Avg Train Loss: 0.2285, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2470 to 0.2468. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2308\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2467\n",
      "Epoch [438/2000], Avg Train Loss: 0.2308, Avg Val Loss: 0.2467\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2467. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2247\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2466\n",
      "Epoch [439/2000], Avg Train Loss: 0.2247, Avg Val Loss: 0.2466\n",
      "\n",
      "Validation loss improved from 0.2467 to 0.2466. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2272\n",
      "LOG: Epoch [440/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2464\n",
      "Epoch [440/2000], Avg Train Loss: 0.2272, Avg Val Loss: 0.2464\n",
      "\n",
      "Validation loss improved from 0.2466 to 0.2464. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2190\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2462\n",
      "Epoch [441/2000], Avg Train Loss: 0.2190, Avg Val Loss: 0.2462\n",
      "\n",
      "Validation loss improved from 0.2464 to 0.2462. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2223\n",
      "LOG: Epoch [442/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2460\n",
      "Epoch [442/2000], Avg Train Loss: 0.2223, Avg Val Loss: 0.2460\n",
      "\n",
      "Validation loss improved from 0.2462 to 0.2460. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2191\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2458\n",
      "Epoch [443/2000], Avg Train Loss: 0.2191, Avg Val Loss: 0.2458\n",
      "\n",
      "Validation loss improved from 0.2460 to 0.2458. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2264\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2456\n",
      "Epoch [444/2000], Avg Train Loss: 0.2264, Avg Val Loss: 0.2456\n",
      "\n",
      "Validation loss improved from 0.2458 to 0.2456. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2198\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2455\n",
      "Epoch [445/2000], Avg Train Loss: 0.2198, Avg Val Loss: 0.2455\n",
      "\n",
      "Validation loss improved from 0.2456 to 0.2455. Saving model...\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2167\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2453\n",
      "Epoch [446/2000], Avg Train Loss: 0.2167, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2455 to 0.2453. Saving model...\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2229\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2452\n",
      "Epoch [447/2000], Avg Train Loss: 0.2229, Avg Val Loss: 0.2452\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2452. Saving model...\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2250\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2451\n",
      "Epoch [448/2000], Avg Train Loss: 0.2250, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2452 to 0.2451. Saving model...\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2248\n",
      "LOG: Epoch [449/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2450\n",
      "Epoch [449/2000], Avg Train Loss: 0.2248, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2450. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2225\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2449\n",
      "Epoch [450/2000], Avg Train Loss: 0.2225, Avg Val Loss: 0.2449\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2449. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2271\n",
      "LOG: Epoch [451/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2448\n",
      "Epoch [451/2000], Avg Train Loss: 0.2271, Avg Val Loss: 0.2448\n",
      "\n",
      "Validation loss improved from 0.2449 to 0.2448. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2247\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2447\n",
      "Epoch [452/2000], Avg Train Loss: 0.2247, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2448 to 0.2447. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2218\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2446\n",
      "Epoch [453/2000], Avg Train Loss: 0.2218, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2446. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2226\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2446\n",
      "Epoch [454/2000], Avg Train Loss: 0.2226, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2446. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2199\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2446\n",
      "Epoch [455/2000], Avg Train Loss: 0.2199, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2446. Saving model...\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2186\n",
      "LOG: Epoch [456/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2445\n",
      "Epoch [456/2000], Avg Train Loss: 0.2186, Avg Val Loss: 0.2445\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2445. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2152\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2445\n",
      "Epoch [457/2000], Avg Train Loss: 0.2152, Avg Val Loss: 0.2445\n",
      "\n",
      "Validation loss improved from 0.2445 to 0.2445. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2196\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2444\n",
      "Epoch [458/2000], Avg Train Loss: 0.2196, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2445 to 0.2444. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2139\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2444\n",
      "Epoch [459/2000], Avg Train Loss: 0.2139, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2444. Saving model...\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2116\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2443\n",
      "Epoch [460/2000], Avg Train Loss: 0.2116, Avg Val Loss: 0.2443\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2443. Saving model...\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2232\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2442\n",
      "Epoch [461/2000], Avg Train Loss: 0.2232, Avg Val Loss: 0.2442\n",
      "\n",
      "Validation loss improved from 0.2443 to 0.2442. Saving model...\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2265\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2441\n",
      "Epoch [462/2000], Avg Train Loss: 0.2265, Avg Val Loss: 0.2441\n",
      "\n",
      "Validation loss improved from 0.2442 to 0.2441. Saving model...\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2137\n",
      "LOG: Epoch [463/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2440\n",
      "Epoch [463/2000], Avg Train Loss: 0.2137, Avg Val Loss: 0.2440\n",
      "\n",
      "Validation loss improved from 0.2441 to 0.2440. Saving model...\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2153\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2439\n",
      "Epoch [464/2000], Avg Train Loss: 0.2153, Avg Val Loss: 0.2439\n",
      "\n",
      "Validation loss improved from 0.2440 to 0.2439. Saving model...\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2198\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2438\n",
      "Epoch [465/2000], Avg Train Loss: 0.2198, Avg Val Loss: 0.2438\n",
      "\n",
      "Validation loss improved from 0.2439 to 0.2438. Saving model...\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2117\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2437\n",
      "Epoch [466/2000], Avg Train Loss: 0.2117, Avg Val Loss: 0.2437\n",
      "\n",
      "Validation loss improved from 0.2438 to 0.2437. Saving model...\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2130\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2435\n",
      "Epoch [467/2000], Avg Train Loss: 0.2130, Avg Val Loss: 0.2435\n",
      "\n",
      "Validation loss improved from 0.2437 to 0.2435. Saving model...\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2186\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2434\n",
      "Epoch [468/2000], Avg Train Loss: 0.2186, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2435 to 0.2434. Saving model...\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2188\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2433\n",
      "Epoch [469/2000], Avg Train Loss: 0.2188, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2433. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2127\n",
      "LOG: Epoch [470/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2432\n",
      "Epoch [470/2000], Avg Train Loss: 0.2127, Avg Val Loss: 0.2432\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2432. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2198\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2431\n",
      "Epoch [471/2000], Avg Train Loss: 0.2198, Avg Val Loss: 0.2431\n",
      "\n",
      "Validation loss improved from 0.2432 to 0.2431. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2178\n",
      "LOG: Epoch [472/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2430\n",
      "Epoch [472/2000], Avg Train Loss: 0.2178, Avg Val Loss: 0.2430\n",
      "\n",
      "Validation loss improved from 0.2431 to 0.2430. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2141\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2430\n",
      "Epoch [473/2000], Avg Train Loss: 0.2141, Avg Val Loss: 0.2430\n",
      "\n",
      "Validation loss improved from 0.2430 to 0.2430. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2080\n",
      "LOG: Epoch [474/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2429\n",
      "Epoch [474/2000], Avg Train Loss: 0.2080, Avg Val Loss: 0.2429\n",
      "\n",
      "Validation loss improved from 0.2430 to 0.2429. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2194\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2428\n",
      "Epoch [475/2000], Avg Train Loss: 0.2194, Avg Val Loss: 0.2428\n",
      "\n",
      "Validation loss improved from 0.2429 to 0.2428. Saving model...\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2176\n",
      "LOG: Epoch [476/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2427\n",
      "Epoch [476/2000], Avg Train Loss: 0.2176, Avg Val Loss: 0.2427\n",
      "\n",
      "Validation loss improved from 0.2428 to 0.2427. Saving model...\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2173\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2426\n",
      "Epoch [477/2000], Avg Train Loss: 0.2173, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2427 to 0.2426. Saving model...\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2143\n",
      "LOG: Epoch [478/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2426\n",
      "Epoch [478/2000], Avg Train Loss: 0.2143, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2426. Saving model...\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2186\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2425\n",
      "Epoch [479/2000], Avg Train Loss: 0.2186, Avg Val Loss: 0.2425\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2425. Saving model...\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2132\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2424\n",
      "Epoch [480/2000], Avg Train Loss: 0.2132, Avg Val Loss: 0.2424\n",
      "\n",
      "Validation loss improved from 0.2425 to 0.2424. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2155\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2423\n",
      "Epoch [481/2000], Avg Train Loss: 0.2155, Avg Val Loss: 0.2423\n",
      "\n",
      "Validation loss improved from 0.2424 to 0.2423. Saving model...\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2124\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2422\n",
      "Epoch [482/2000], Avg Train Loss: 0.2124, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2423 to 0.2422. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2131\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2421\n",
      "Epoch [483/2000], Avg Train Loss: 0.2131, Avg Val Loss: 0.2421\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2421. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2072\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2420\n",
      "Epoch [484/2000], Avg Train Loss: 0.2072, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2421 to 0.2420. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2113\n",
      "LOG: Epoch [485/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2419\n",
      "Epoch [485/2000], Avg Train Loss: 0.2113, Avg Val Loss: 0.2419\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2419. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2148\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2418\n",
      "Epoch [486/2000], Avg Train Loss: 0.2148, Avg Val Loss: 0.2418\n",
      "\n",
      "Validation loss improved from 0.2419 to 0.2418. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2123\n",
      "LOG: Epoch [487/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2418\n",
      "Epoch [487/2000], Avg Train Loss: 0.2123, Avg Val Loss: 0.2418\n",
      "\n",
      "Validation loss improved from 0.2418 to 0.2418. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2161\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2417\n",
      "Epoch [488/2000], Avg Train Loss: 0.2161, Avg Val Loss: 0.2417\n",
      "\n",
      "Validation loss improved from 0.2418 to 0.2417. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2144\n",
      "LOG: Epoch [489/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2417\n",
      "Epoch [489/2000], Avg Train Loss: 0.2144, Avg Val Loss: 0.2417\n",
      "\n",
      "Validation loss improved from 0.2417 to 0.2417. Saving model...\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2110\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2416\n",
      "Epoch [490/2000], Avg Train Loss: 0.2110, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2417 to 0.2416. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2067\n",
      "LOG: Epoch [491/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2416\n",
      "Epoch [491/2000], Avg Train Loss: 0.2067, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2416. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2105\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2415\n",
      "Epoch [492/2000], Avg Train Loss: 0.2105, Avg Val Loss: 0.2415\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2415. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2033\n",
      "LOG: Epoch [493/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2414\n",
      "Epoch [493/2000], Avg Train Loss: 0.2033, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2415 to 0.2414. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2069\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2412\n",
      "Epoch [494/2000], Avg Train Loss: 0.2069, Avg Val Loss: 0.2412\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2412. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2139\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2411\n",
      "Epoch [495/2000], Avg Train Loss: 0.2139, Avg Val Loss: 0.2411\n",
      "\n",
      "Validation loss improved from 0.2412 to 0.2411. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2111\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2410\n",
      "Epoch [496/2000], Avg Train Loss: 0.2111, Avg Val Loss: 0.2410\n",
      "\n",
      "Validation loss improved from 0.2411 to 0.2410. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2087\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2409\n",
      "Epoch [497/2000], Avg Train Loss: 0.2087, Avg Val Loss: 0.2409\n",
      "\n",
      "Validation loss improved from 0.2410 to 0.2409. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2065\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2408\n",
      "Epoch [498/2000], Avg Train Loss: 0.2065, Avg Val Loss: 0.2408\n",
      "\n",
      "Validation loss improved from 0.2409 to 0.2408. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2122\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2407\n",
      "Epoch [499/2000], Avg Train Loss: 0.2122, Avg Val Loss: 0.2407\n",
      "\n",
      "Validation loss improved from 0.2408 to 0.2407. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2100\n",
      "LOG: Epoch [500/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2407\n",
      "Epoch [500/2000], Avg Train Loss: 0.2100, Avg Val Loss: 0.2407\n",
      "\n",
      "Validation loss improved from 0.2407 to 0.2407. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2194\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2406\n",
      "Epoch [501/2000], Avg Train Loss: 0.2194, Avg Val Loss: 0.2406\n",
      "\n",
      "Validation loss improved from 0.2407 to 0.2406. Saving model...\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2110\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n",
      "Epoch [502/2000], Avg Train Loss: 0.2110, Avg Val Loss: 0.2405\n",
      "\n",
      "Validation loss improved from 0.2406 to 0.2405. Saving model...\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2053\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n",
      "Epoch [503/2000], Avg Train Loss: 0.2053, Avg Val Loss: 0.2405\n",
      "\n",
      "Validation loss improved from 0.2405 to 0.2405. Saving model...\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2036\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2404\n",
      "Epoch [504/2000], Avg Train Loss: 0.2036, Avg Val Loss: 0.2404\n",
      "\n",
      "Validation loss improved from 0.2405 to 0.2404. Saving model...\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2116\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [505/2000], Avg Train Loss: 0.2116, Avg Val Loss: 0.2405\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2081\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n",
      "Epoch [506/2000], Avg Train Loss: 0.2081, Avg Val Loss: 0.2405\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2049\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2406\n",
      "Epoch [507/2000], Avg Train Loss: 0.2049, Avg Val Loss: 0.2406\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2092\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2406\n",
      "Epoch [508/2000], Avg Train Loss: 0.2092, Avg Val Loss: 0.2406\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2164\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2406\n",
      "Epoch [509/2000], Avg Train Loss: 0.2164, Avg Val Loss: 0.2406\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2017\n",
      "LOG: Epoch [510/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2406\n",
      "Epoch [510/2000], Avg Train Loss: 0.2017, Avg Val Loss: 0.2406\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2104\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n",
      "Epoch [511/2000], Avg Train Loss: 0.2104, Avg Val Loss: 0.2405\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2036\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n",
      "Epoch [512/2000], Avg Train Loss: 0.2036, Avg Val Loss: 0.2405\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2039\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2404\n",
      "Epoch [513/2000], Avg Train Loss: 0.2039, Avg Val Loss: 0.2404\n",
      "\n",
      "Validation loss improved from 0.2404 to 0.2404. Saving model...\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2095\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2403\n",
      "Epoch [514/2000], Avg Train Loss: 0.2095, Avg Val Loss: 0.2403\n",
      "\n",
      "Validation loss improved from 0.2404 to 0.2403. Saving model...\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2111\n",
      "LOG: Epoch [515/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2402\n",
      "Epoch [515/2000], Avg Train Loss: 0.2111, Avg Val Loss: 0.2402\n",
      "\n",
      "Validation loss improved from 0.2403 to 0.2402. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2105\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2401\n",
      "Epoch [516/2000], Avg Train Loss: 0.2105, Avg Val Loss: 0.2401\n",
      "\n",
      "Validation loss improved from 0.2402 to 0.2401. Saving model...\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2042\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2399\n",
      "Epoch [517/2000], Avg Train Loss: 0.2042, Avg Val Loss: 0.2399\n",
      "\n",
      "Validation loss improved from 0.2401 to 0.2399. Saving model...\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1976\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2398\n",
      "Epoch [518/2000], Avg Train Loss: 0.1976, Avg Val Loss: 0.2398\n",
      "\n",
      "Validation loss improved from 0.2399 to 0.2398. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2120\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2397\n",
      "Epoch [519/2000], Avg Train Loss: 0.2120, Avg Val Loss: 0.2397\n",
      "\n",
      "Validation loss improved from 0.2398 to 0.2397. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2396\n",
      "Epoch [520/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.2396\n",
      "\n",
      "Validation loss improved from 0.2397 to 0.2396. Saving model...\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2028\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2395\n",
      "Epoch [521/2000], Avg Train Loss: 0.2028, Avg Val Loss: 0.2395\n",
      "\n",
      "Validation loss improved from 0.2396 to 0.2395. Saving model...\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2044\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2394\n",
      "Epoch [522/2000], Avg Train Loss: 0.2044, Avg Val Loss: 0.2394\n",
      "\n",
      "Validation loss improved from 0.2395 to 0.2394. Saving model...\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2049\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2393\n",
      "Epoch [523/2000], Avg Train Loss: 0.2049, Avg Val Loss: 0.2393\n",
      "\n",
      "Validation loss improved from 0.2394 to 0.2393. Saving model...\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1981\n",
      "LOG: Epoch [524/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2392\n",
      "Epoch [524/2000], Avg Train Loss: 0.1981, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2393 to 0.2392. Saving model...\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2391\n",
      "Epoch [525/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.2391\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2391. Saving model...\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2046\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2390\n",
      "Epoch [526/2000], Avg Train Loss: 0.2046, Avg Val Loss: 0.2390\n",
      "\n",
      "Validation loss improved from 0.2391 to 0.2390. Saving model...\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2069\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2389\n",
      "Epoch [527/2000], Avg Train Loss: 0.2069, Avg Val Loss: 0.2389\n",
      "\n",
      "Validation loss improved from 0.2390 to 0.2389. Saving model...\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2017\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2388\n",
      "Epoch [528/2000], Avg Train Loss: 0.2017, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2389 to 0.2388. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2056\n",
      "LOG: Epoch [529/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2388\n",
      "Epoch [529/2000], Avg Train Loss: 0.2056, Avg Val Loss: 0.2388\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2061\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2389\n",
      "Epoch [530/2000], Avg Train Loss: 0.2061, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2001\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2389\n",
      "Epoch [531/2000], Avg Train Loss: 0.2001, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2058\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2390\n",
      "Epoch [532/2000], Avg Train Loss: 0.2058, Avg Val Loss: 0.2390\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1998\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2390\n",
      "Epoch [533/2000], Avg Train Loss: 0.1998, Avg Val Loss: 0.2390\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [534/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2390\n",
      "Epoch [534/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.2390\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2390\n",
      "Epoch [535/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.2390\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [536/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2389\n",
      "Epoch [536/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1999\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2389\n",
      "Epoch [537/2000], Avg Train Loss: 0.1999, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2044\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2389\n",
      "Epoch [538/2000], Avg Train Loss: 0.2044, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2003\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2388\n",
      "Epoch [539/2000], Avg Train Loss: 0.2003, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2388. Saving model...\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1991\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2388\n",
      "Epoch [540/2000], Avg Train Loss: 0.1991, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2388. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1985\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2387\n",
      "Epoch [541/2000], Avg Train Loss: 0.1985, Avg Val Loss: 0.2387\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2387. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2039\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2386\n",
      "Epoch [542/2000], Avg Train Loss: 0.2039, Avg Val Loss: 0.2386\n",
      "\n",
      "Validation loss improved from 0.2387 to 0.2386. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1926\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2385\n",
      "Epoch [543/2000], Avg Train Loss: 0.1926, Avg Val Loss: 0.2385\n",
      "\n",
      "Validation loss improved from 0.2386 to 0.2385. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2384\n",
      "Epoch [544/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.2384\n",
      "\n",
      "Validation loss improved from 0.2385 to 0.2384. Saving model...\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1995\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2383\n",
      "Epoch [545/2000], Avg Train Loss: 0.1995, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2384 to 0.2383. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1995\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2381\n",
      "Epoch [546/2000], Avg Train Loss: 0.1995, Avg Val Loss: 0.2381\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2381. Saving model...\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1963\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2380\n",
      "Epoch [547/2000], Avg Train Loss: 0.1963, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2381 to 0.2380. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2379\n",
      "Epoch [548/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2379. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2378\n",
      "Epoch [549/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.2378\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2378. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1957\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2377\n",
      "Epoch [550/2000], Avg Train Loss: 0.1957, Avg Val Loss: 0.2377\n",
      "\n",
      "Validation loss improved from 0.2378 to 0.2377. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1984\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2376\n",
      "Epoch [551/2000], Avg Train Loss: 0.1984, Avg Val Loss: 0.2376\n",
      "\n",
      "Validation loss improved from 0.2377 to 0.2376. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1933\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2376\n",
      "Epoch [552/2000], Avg Train Loss: 0.1933, Avg Val Loss: 0.2376\n",
      "\n",
      "Validation loss improved from 0.2376 to 0.2376. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2375\n",
      "Epoch [553/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.2375\n",
      "\n",
      "Validation loss improved from 0.2376 to 0.2375. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1932\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2374\n",
      "Epoch [554/2000], Avg Train Loss: 0.1932, Avg Val Loss: 0.2374\n",
      "\n",
      "Validation loss improved from 0.2375 to 0.2374. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1864\n",
      "LOG: Epoch [555/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2373\n",
      "Epoch [555/2000], Avg Train Loss: 0.1864, Avg Val Loss: 0.2373\n",
      "\n",
      "Validation loss improved from 0.2374 to 0.2373. Saving model...\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2025\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2373\n",
      "Epoch [556/2000], Avg Train Loss: 0.2025, Avg Val Loss: 0.2373\n",
      "\n",
      "Validation loss improved from 0.2373 to 0.2373. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1938\n",
      "LOG: Epoch [557/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2373\n",
      "Epoch [557/2000], Avg Train Loss: 0.1938, Avg Val Loss: 0.2373\n",
      "\n",
      "Validation loss improved from 0.2373 to 0.2373. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2372\n",
      "Epoch [558/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.2372\n",
      "\n",
      "Validation loss improved from 0.2373 to 0.2372. Saving model...\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1960\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2372\n",
      "Epoch [559/2000], Avg Train Loss: 0.1960, Avg Val Loss: 0.2372\n",
      "\n",
      "Validation loss improved from 0.2372 to 0.2372. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2371\n",
      "Epoch [560/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.2371\n",
      "\n",
      "Validation loss improved from 0.2372 to 0.2371. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1889\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2371\n",
      "Epoch [561/2000], Avg Train Loss: 0.1889, Avg Val Loss: 0.2371\n",
      "\n",
      "Validation loss improved from 0.2371 to 0.2371. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1979\n",
      "LOG: Epoch [562/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2371\n",
      "Epoch [562/2000], Avg Train Loss: 0.1979, Avg Val Loss: 0.2371\n",
      "\n",
      "Validation loss improved from 0.2371 to 0.2371. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1866\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2370\n",
      "Epoch [563/2000], Avg Train Loss: 0.1866, Avg Val Loss: 0.2370\n",
      "\n",
      "Validation loss improved from 0.2371 to 0.2370. Saving model...\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1948\n",
      "LOG: Epoch [564/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2370\n",
      "Epoch [564/2000], Avg Train Loss: 0.1948, Avg Val Loss: 0.2370\n",
      "\n",
      "Validation loss improved from 0.2370 to 0.2370. Saving model...\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2369\n",
      "Epoch [565/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2370 to 0.2369. Saving model...\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1991\n",
      "LOG: Epoch [566/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2368\n",
      "Epoch [566/2000], Avg Train Loss: 0.1991, Avg Val Loss: 0.2368\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2368. Saving model...\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2366\n",
      "Epoch [567/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.2366\n",
      "\n",
      "Validation loss improved from 0.2368 to 0.2366. Saving model...\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2365\n",
      "Epoch [568/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.2365\n",
      "\n",
      "Validation loss improved from 0.2366 to 0.2365. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2364\n",
      "Epoch [569/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.2364\n",
      "\n",
      "Validation loss improved from 0.2365 to 0.2364. Saving model...\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2363\n",
      "Epoch [570/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.2363\n",
      "\n",
      "Validation loss improved from 0.2364 to 0.2363. Saving model...\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1970\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2362\n",
      "Epoch [571/2000], Avg Train Loss: 0.1970, Avg Val Loss: 0.2362\n",
      "\n",
      "Validation loss improved from 0.2363 to 0.2362. Saving model...\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2361\n",
      "Epoch [572/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.2361\n",
      "\n",
      "Validation loss improved from 0.2362 to 0.2361. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1903\n",
      "LOG: Epoch [573/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2361\n",
      "Epoch [573/2000], Avg Train Loss: 0.1903, Avg Val Loss: 0.2361\n",
      "\n",
      "Validation loss improved from 0.2361 to 0.2361. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2360\n",
      "Epoch [574/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.2360\n",
      "\n",
      "Validation loss improved from 0.2361 to 0.2360. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1940\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2359\n",
      "Epoch [575/2000], Avg Train Loss: 0.1940, Avg Val Loss: 0.2359\n",
      "\n",
      "Validation loss improved from 0.2360 to 0.2359. Saving model...\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1946\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2359\n",
      "Epoch [576/2000], Avg Train Loss: 0.1946, Avg Val Loss: 0.2359\n",
      "\n",
      "Validation loss improved from 0.2359 to 0.2359. Saving model...\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1892\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2357\n",
      "Epoch [577/2000], Avg Train Loss: 0.1892, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2359 to 0.2357. Saving model...\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1915\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2356\n",
      "Epoch [578/2000], Avg Train Loss: 0.1915, Avg Val Loss: 0.2356\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2356. Saving model...\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1854\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2355\n",
      "Epoch [579/2000], Avg Train Loss: 0.1854, Avg Val Loss: 0.2355\n",
      "\n",
      "Validation loss improved from 0.2356 to 0.2355. Saving model...\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1841\n",
      "LOG: Epoch [580/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2353\n",
      "Epoch [580/2000], Avg Train Loss: 0.1841, Avg Val Loss: 0.2353\n",
      "\n",
      "Validation loss improved from 0.2355 to 0.2353. Saving model...\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2352\n",
      "Epoch [581/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.2352\n",
      "\n",
      "Validation loss improved from 0.2353 to 0.2352. Saving model...\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1910\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2351\n",
      "Epoch [582/2000], Avg Train Loss: 0.1910, Avg Val Loss: 0.2351\n",
      "\n",
      "Validation loss improved from 0.2352 to 0.2351. Saving model...\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1914\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2350\n",
      "Epoch [583/2000], Avg Train Loss: 0.1914, Avg Val Loss: 0.2350\n",
      "\n",
      "Validation loss improved from 0.2351 to 0.2350. Saving model...\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1904\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2348\n",
      "Epoch [584/2000], Avg Train Loss: 0.1904, Avg Val Loss: 0.2348\n",
      "\n",
      "Validation loss improved from 0.2350 to 0.2348. Saving model...\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [585/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2347\n",
      "Epoch [585/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.2347\n",
      "\n",
      "Validation loss improved from 0.2348 to 0.2347. Saving model...\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1870\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2346\n",
      "Epoch [586/2000], Avg Train Loss: 0.1870, Avg Val Loss: 0.2346\n",
      "\n",
      "Validation loss improved from 0.2347 to 0.2346. Saving model...\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1889\n",
      "LOG: Epoch [587/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2346\n",
      "Epoch [587/2000], Avg Train Loss: 0.1889, Avg Val Loss: 0.2346\n",
      "\n",
      "Validation loss improved from 0.2346 to 0.2346. Saving model...\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1888\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2345\n",
      "Epoch [588/2000], Avg Train Loss: 0.1888, Avg Val Loss: 0.2345\n",
      "\n",
      "Validation loss improved from 0.2346 to 0.2345. Saving model...\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [589/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2345 to 0.2344. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1816\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [590/2000], Avg Train Loss: 0.1816, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2344. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1897\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [591/2000], Avg Train Loss: 0.1897, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2344. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1912\n",
      "LOG: Epoch [592/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [592/2000], Avg Train Loss: 0.1912, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2344. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1838\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2343\n",
      "Epoch [593/2000], Avg Train Loss: 0.1838, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2343. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [594/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [594/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1930\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [595/2000], Avg Train Loss: 0.1930, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1817\n",
      "LOG: Epoch [596/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [596/2000], Avg Train Loss: 0.1817, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1892\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [597/2000], Avg Train Loss: 0.1892, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1848\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [598/2000], Avg Train Loss: 0.1848, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1827\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [599/2000], Avg Train Loss: 0.1827, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1905\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [600/2000], Avg Train Loss: 0.1905, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1780\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [601/2000], Avg Train Loss: 0.1780, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1893\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2344\n",
      "Epoch [602/2000], Avg Train Loss: 0.1893, Avg Val Loss: 0.2344\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1868\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2343\n",
      "Epoch [603/2000], Avg Train Loss: 0.1868, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2343. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2343\n",
      "Epoch [604/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2343. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1950\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2343\n",
      "Epoch [605/2000], Avg Train Loss: 0.1950, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2343. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1895\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2343\n",
      "Epoch [606/2000], Avg Train Loss: 0.1895, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2343. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1920\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2342\n",
      "Epoch [607/2000], Avg Train Loss: 0.1920, Avg Val Loss: 0.2342\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2342. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1804\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2342\n",
      "Epoch [608/2000], Avg Train Loss: 0.1804, Avg Val Loss: 0.2342\n",
      "\n",
      "Validation loss improved from 0.2342 to 0.2342. Saving model...\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1874\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2342\n",
      "Epoch [609/2000], Avg Train Loss: 0.1874, Avg Val Loss: 0.2342\n",
      "\n",
      "Validation loss improved from 0.2342 to 0.2342. Saving model...\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1843\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2341\n",
      "Epoch [610/2000], Avg Train Loss: 0.1843, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2342 to 0.2341. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1934\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2341\n",
      "Epoch [611/2000], Avg Train Loss: 0.1934, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2341. Saving model...\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1797\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2340\n",
      "Epoch [612/2000], Avg Train Loss: 0.1797, Avg Val Loss: 0.2340\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2340. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1813\n",
      "LOG: Epoch [613/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2340\n",
      "Epoch [613/2000], Avg Train Loss: 0.1813, Avg Val Loss: 0.2340\n",
      "\n",
      "Validation loss improved from 0.2340 to 0.2340. Saving model...\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1851\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2339\n",
      "Epoch [614/2000], Avg Train Loss: 0.1851, Avg Val Loss: 0.2339\n",
      "\n",
      "Validation loss improved from 0.2340 to 0.2339. Saving model...\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1824\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2338\n",
      "Epoch [615/2000], Avg Train Loss: 0.1824, Avg Val Loss: 0.2338\n",
      "\n",
      "Validation loss improved from 0.2339 to 0.2338. Saving model...\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1851\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2338\n",
      "Epoch [616/2000], Avg Train Loss: 0.1851, Avg Val Loss: 0.2338\n",
      "\n",
      "Validation loss improved from 0.2338 to 0.2338. Saving model...\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2337\n",
      "Epoch [617/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2338 to 0.2337. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1801\n",
      "LOG: Epoch [618/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2336\n",
      "Epoch [618/2000], Avg Train Loss: 0.1801, Avg Val Loss: 0.2336\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2336. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1793\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2335\n",
      "Epoch [619/2000], Avg Train Loss: 0.1793, Avg Val Loss: 0.2335\n",
      "\n",
      "Validation loss improved from 0.2336 to 0.2335. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1823\n",
      "LOG: Epoch [620/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2334\n",
      "Epoch [620/2000], Avg Train Loss: 0.1823, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2335 to 0.2334. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1823\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2333\n",
      "Epoch [621/2000], Avg Train Loss: 0.1823, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2333. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1766\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2331\n",
      "Epoch [622/2000], Avg Train Loss: 0.1766, Avg Val Loss: 0.2331\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2331. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1815\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2330\n",
      "Epoch [623/2000], Avg Train Loss: 0.1815, Avg Val Loss: 0.2330\n",
      "\n",
      "Validation loss improved from 0.2331 to 0.2330. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1814\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2328\n",
      "Epoch [624/2000], Avg Train Loss: 0.1814, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2330 to 0.2328. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1807\n",
      "LOG: Epoch [625/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2327\n",
      "Epoch [625/2000], Avg Train Loss: 0.1807, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2327. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1818\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2325\n",
      "Epoch [626/2000], Avg Train Loss: 0.1818, Avg Val Loss: 0.2325\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2325. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1805\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2324\n",
      "Epoch [627/2000], Avg Train Loss: 0.1805, Avg Val Loss: 0.2324\n",
      "\n",
      "Validation loss improved from 0.2325 to 0.2324. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1827\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2323\n",
      "Epoch [628/2000], Avg Train Loss: 0.1827, Avg Val Loss: 0.2323\n",
      "\n",
      "Validation loss improved from 0.2324 to 0.2323. Saving model...\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1820\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2322\n",
      "Epoch [629/2000], Avg Train Loss: 0.1820, Avg Val Loss: 0.2322\n",
      "\n",
      "Validation loss improved from 0.2323 to 0.2322. Saving model...\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1775\n",
      "LOG: Epoch [630/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2321\n",
      "Epoch [630/2000], Avg Train Loss: 0.1775, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2322 to 0.2321. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1824\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2320\n",
      "Epoch [631/2000], Avg Train Loss: 0.1824, Avg Val Loss: 0.2320\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2320. Saving model...\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1758\n",
      "LOG: Epoch [632/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2320\n",
      "Epoch [632/2000], Avg Train Loss: 0.1758, Avg Val Loss: 0.2320\n",
      "\n",
      "Validation loss improved from 0.2320 to 0.2320. Saving model...\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1785\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [633/2000], Avg Train Loss: 0.1785, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2320 to 0.2319. Saving model...\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1763\n",
      "LOG: Epoch [634/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [634/2000], Avg Train Loss: 0.1763, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2319. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1765\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [635/2000], Avg Train Loss: 0.1765, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2319. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1749\n",
      "LOG: Epoch [636/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [636/2000], Avg Train Loss: 0.1749, Avg Val Loss: 0.2319\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1823\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [637/2000], Avg Train Loss: 0.1823, Avg Val Loss: 0.2319\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1854\n",
      "LOG: Epoch [638/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [638/2000], Avg Train Loss: 0.1854, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2319. Saving model...\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1755\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [639/2000], Avg Train Loss: 0.1755, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2319. Saving model...\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1770\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2319\n",
      "Epoch [640/2000], Avg Train Loss: 0.1770, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2319. Saving model...\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1832\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2318\n",
      "Epoch [641/2000], Avg Train Loss: 0.1832, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2318. Saving model...\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1784\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2318\n",
      "Epoch [642/2000], Avg Train Loss: 0.1784, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1735\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2318\n",
      "Epoch [643/2000], Avg Train Loss: 0.1735, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1703\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2318\n",
      "Epoch [644/2000], Avg Train Loss: 0.1703, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1762\n",
      "LOG: Epoch [645/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2317\n",
      "Epoch [645/2000], Avg Train Loss: 0.1762, Avg Val Loss: 0.2317\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2317. Saving model...\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1749\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2317\n",
      "Epoch [646/2000], Avg Train Loss: 0.1749, Avg Val Loss: 0.2317\n",
      "\n",
      "Validation loss improved from 0.2317 to 0.2317. Saving model...\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1826\n",
      "LOG: Epoch [647/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2315\n",
      "Epoch [647/2000], Avg Train Loss: 0.1826, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2317 to 0.2315. Saving model...\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1793\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2314\n",
      "Epoch [648/2000], Avg Train Loss: 0.1793, Avg Val Loss: 0.2314\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2314. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1808\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2313\n",
      "Epoch [649/2000], Avg Train Loss: 0.1808, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2314 to 0.2313. Saving model...\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1742\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2313\n",
      "Epoch [650/2000], Avg Train Loss: 0.1742, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2313. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1769\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2312\n",
      "Epoch [651/2000], Avg Train Loss: 0.1769, Avg Val Loss: 0.2312\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2312. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1804\n",
      "LOG: Epoch [652/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2311\n",
      "Epoch [652/2000], Avg Train Loss: 0.1804, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2312 to 0.2311. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1792\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2311\n",
      "Epoch [653/2000], Avg Train Loss: 0.1792, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1815\n",
      "LOG: Epoch [654/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2311\n",
      "Epoch [654/2000], Avg Train Loss: 0.1815, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1754\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2311\n",
      "Epoch [655/2000], Avg Train Loss: 0.1754, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1763\n",
      "LOG: Epoch [656/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2310\n",
      "Epoch [656/2000], Avg Train Loss: 0.1763, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2310. Saving model...\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1768\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2310\n",
      "Epoch [657/2000], Avg Train Loss: 0.1768, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2310. Saving model...\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1810\n",
      "LOG: Epoch [658/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2309\n",
      "Epoch [658/2000], Avg Train Loss: 0.1810, Avg Val Loss: 0.2309\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2309. Saving model...\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1761\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2308\n",
      "Epoch [659/2000], Avg Train Loss: 0.1761, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2309 to 0.2308. Saving model...\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1714\n",
      "LOG: Epoch [660/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2307\n",
      "Epoch [660/2000], Avg Train Loss: 0.1714, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2307. Saving model...\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1768\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2307\n",
      "Epoch [661/2000], Avg Train Loss: 0.1768, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2307. Saving model...\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1691\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2306\n",
      "Epoch [662/2000], Avg Train Loss: 0.1691, Avg Val Loss: 0.2306\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2306. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1714\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2305\n",
      "Epoch [663/2000], Avg Train Loss: 0.1714, Avg Val Loss: 0.2305\n",
      "\n",
      "Validation loss improved from 0.2306 to 0.2305. Saving model...\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1721\n",
      "LOG: Epoch [664/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2304\n",
      "Epoch [664/2000], Avg Train Loss: 0.1721, Avg Val Loss: 0.2304\n",
      "\n",
      "Validation loss improved from 0.2305 to 0.2304. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1803\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2303\n",
      "Epoch [665/2000], Avg Train Loss: 0.1803, Avg Val Loss: 0.2303\n",
      "\n",
      "Validation loss improved from 0.2304 to 0.2303. Saving model...\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1751\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2302\n",
      "Epoch [666/2000], Avg Train Loss: 0.1751, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2303 to 0.2302. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1717\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2301\n",
      "Epoch [667/2000], Avg Train Loss: 0.1717, Avg Val Loss: 0.2301\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2301. Saving model...\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1764\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2301\n",
      "Epoch [668/2000], Avg Train Loss: 0.1764, Avg Val Loss: 0.2301\n",
      "\n",
      "Validation loss improved from 0.2301 to 0.2301. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1709\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2300\n",
      "Epoch [669/2000], Avg Train Loss: 0.1709, Avg Val Loss: 0.2300\n",
      "\n",
      "Validation loss improved from 0.2301 to 0.2300. Saving model...\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1723\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2300\n",
      "Epoch [670/2000], Avg Train Loss: 0.1723, Avg Val Loss: 0.2300\n",
      "\n",
      "Validation loss improved from 0.2300 to 0.2300. Saving model...\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1724\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2300\n",
      "Epoch [671/2000], Avg Train Loss: 0.1724, Avg Val Loss: 0.2300\n",
      "\n",
      "Validation loss improved from 0.2300 to 0.2300. Saving model...\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1687\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2299\n",
      "Epoch [672/2000], Avg Train Loss: 0.1687, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2300 to 0.2299. Saving model...\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1738\n",
      "LOG: Epoch [673/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2299\n",
      "Epoch [673/2000], Avg Train Loss: 0.1738, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2299. Saving model...\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1696\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2299\n",
      "Epoch [674/2000], Avg Train Loss: 0.1696, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2299. Saving model...\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1759\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2299\n",
      "Epoch [675/2000], Avg Train Loss: 0.1759, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2299. Saving model...\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1726\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2298\n",
      "Epoch [676/2000], Avg Train Loss: 0.1726, Avg Val Loss: 0.2298\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2298. Saving model...\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1723\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2298\n",
      "Epoch [677/2000], Avg Train Loss: 0.1723, Avg Val Loss: 0.2298\n",
      "\n",
      "Validation loss improved from 0.2298 to 0.2298. Saving model...\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1808\n",
      "LOG: Epoch [678/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2297\n",
      "Epoch [678/2000], Avg Train Loss: 0.1808, Avg Val Loss: 0.2297\n",
      "\n",
      "Validation loss improved from 0.2298 to 0.2297. Saving model...\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1672\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2297\n",
      "Epoch [679/2000], Avg Train Loss: 0.1672, Avg Val Loss: 0.2297\n",
      "\n",
      "Validation loss improved from 0.2297 to 0.2297. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1748\n",
      "LOG: Epoch [680/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2297\n",
      "Epoch [680/2000], Avg Train Loss: 0.1748, Avg Val Loss: 0.2297\n",
      "\n",
      "Validation loss improved from 0.2297 to 0.2297. Saving model...\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1724\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2296\n",
      "Epoch [681/2000], Avg Train Loss: 0.1724, Avg Val Loss: 0.2296\n",
      "\n",
      "Validation loss improved from 0.2297 to 0.2296. Saving model...\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1687\n",
      "LOG: Epoch [682/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2295\n",
      "Epoch [682/2000], Avg Train Loss: 0.1687, Avg Val Loss: 0.2295\n",
      "\n",
      "Validation loss improved from 0.2296 to 0.2295. Saving model...\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1689\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2294\n",
      "Epoch [683/2000], Avg Train Loss: 0.1689, Avg Val Loss: 0.2294\n",
      "\n",
      "Validation loss improved from 0.2295 to 0.2294. Saving model...\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1715\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2294\n",
      "Epoch [684/2000], Avg Train Loss: 0.1715, Avg Val Loss: 0.2294\n",
      "\n",
      "Validation loss improved from 0.2294 to 0.2294. Saving model...\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1691\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2293\n",
      "Epoch [685/2000], Avg Train Loss: 0.1691, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2294 to 0.2293. Saving model...\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1685\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2293\n",
      "Epoch [686/2000], Avg Train Loss: 0.1685, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2293. Saving model...\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1753\n",
      "LOG: Epoch [687/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2292\n",
      "Epoch [687/2000], Avg Train Loss: 0.1753, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2292. Saving model...\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1630\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2292\n",
      "Epoch [688/2000], Avg Train Loss: 0.1630, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2292. Saving model...\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1725\n",
      "LOG: Epoch [689/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2291\n",
      "Epoch [689/2000], Avg Train Loss: 0.1725, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2291. Saving model...\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1722\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2291\n",
      "Epoch [690/2000], Avg Train Loss: 0.1722, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2291. Saving model...\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1722\n",
      "LOG: Epoch [691/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2290\n",
      "Epoch [691/2000], Avg Train Loss: 0.1722, Avg Val Loss: 0.2290\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2290. Saving model...\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1655\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2289\n",
      "Epoch [692/2000], Avg Train Loss: 0.1655, Avg Val Loss: 0.2289\n",
      "\n",
      "Validation loss improved from 0.2290 to 0.2289. Saving model...\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1693\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2289\n",
      "Epoch [693/2000], Avg Train Loss: 0.1693, Avg Val Loss: 0.2289\n",
      "\n",
      "Validation loss improved from 0.2289 to 0.2289. Saving model...\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1722\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2288\n",
      "Epoch [694/2000], Avg Train Loss: 0.1722, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2289 to 0.2288. Saving model...\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1634\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2287\n",
      "Epoch [695/2000], Avg Train Loss: 0.1634, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2287. Saving model...\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1653\n",
      "LOG: Epoch [696/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2286\n",
      "Epoch [696/2000], Avg Train Loss: 0.1653, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2286. Saving model...\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1600\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2284\n",
      "Epoch [697/2000], Avg Train Loss: 0.1600, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2284. Saving model...\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1679\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2283\n",
      "Epoch [698/2000], Avg Train Loss: 0.1679, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2283. Saving model...\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1740\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2282\n",
      "Epoch [699/2000], Avg Train Loss: 0.1740, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2282. Saving model...\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1709\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2281\n",
      "Epoch [700/2000], Avg Train Loss: 0.1709, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2281. Saving model...\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1626\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2280\n",
      "Epoch [701/2000], Avg Train Loss: 0.1626, Avg Val Loss: 0.2280\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2280. Saving model...\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1605\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2279\n",
      "Epoch [702/2000], Avg Train Loss: 0.1605, Avg Val Loss: 0.2279\n",
      "\n",
      "Validation loss improved from 0.2280 to 0.2279. Saving model...\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1652\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2278\n",
      "Epoch [703/2000], Avg Train Loss: 0.1652, Avg Val Loss: 0.2278\n",
      "\n",
      "Validation loss improved from 0.2279 to 0.2278. Saving model...\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1695\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2277\n",
      "Epoch [704/2000], Avg Train Loss: 0.1695, Avg Val Loss: 0.2277\n",
      "\n",
      "Validation loss improved from 0.2278 to 0.2277. Saving model...\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1695\n",
      "LOG: Epoch [705/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2276\n",
      "Epoch [705/2000], Avg Train Loss: 0.1695, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2277 to 0.2276. Saving model...\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1691\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2276\n",
      "Epoch [706/2000], Avg Train Loss: 0.1691, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2276. Saving model...\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1723\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2275\n",
      "Epoch [707/2000], Avg Train Loss: 0.1723, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2275. Saving model...\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1617\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2275\n",
      "Epoch [708/2000], Avg Train Loss: 0.1617, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2275. Saving model...\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1640\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2275\n",
      "Epoch [709/2000], Avg Train Loss: 0.1640, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2275. Saving model...\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1669\n",
      "LOG: Epoch [710/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2274\n",
      "Epoch [710/2000], Avg Train Loss: 0.1669, Avg Val Loss: 0.2274\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2274. Saving model...\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1662\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2274\n",
      "Epoch [711/2000], Avg Train Loss: 0.1662, Avg Val Loss: 0.2274\n",
      "\n",
      "Validation loss improved from 0.2274 to 0.2274. Saving model...\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1641\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [712/2000], Avg Train Loss: 0.1641, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2274 to 0.2273. Saving model...\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1663\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [713/2000], Avg Train Loss: 0.1663, Avg Val Loss: 0.2273\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1606\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [714/2000], Avg Train Loss: 0.1606, Avg Val Loss: 0.2273\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1635\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [715/2000], Avg Train Loss: 0.1635, Avg Val Loss: 0.2273\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1643\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2274\n",
      "Epoch [716/2000], Avg Train Loss: 0.1643, Avg Val Loss: 0.2274\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1602\n",
      "LOG: Epoch [717/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2274\n",
      "Epoch [717/2000], Avg Train Loss: 0.1602, Avg Val Loss: 0.2274\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1690\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2274\n",
      "Epoch [718/2000], Avg Train Loss: 0.1690, Avg Val Loss: 0.2274\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1631\n",
      "LOG: Epoch [719/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [719/2000], Avg Train Loss: 0.1631, Avg Val Loss: 0.2273\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1644\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [720/2000], Avg Train Loss: 0.1644, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2273. Saving model...\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1625\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2273\n",
      "Epoch [721/2000], Avg Train Loss: 0.1625, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2273. Saving model...\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1625\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2272\n",
      "Epoch [722/2000], Avg Train Loss: 0.1625, Avg Val Loss: 0.2272\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2272. Saving model...\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1662\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2271\n",
      "Epoch [723/2000], Avg Train Loss: 0.1662, Avg Val Loss: 0.2271\n",
      "\n",
      "Validation loss improved from 0.2272 to 0.2271. Saving model...\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1619\n",
      "LOG: Epoch [724/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2270\n",
      "Epoch [724/2000], Avg Train Loss: 0.1619, Avg Val Loss: 0.2270\n",
      "\n",
      "Validation loss improved from 0.2271 to 0.2270. Saving model...\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1731\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2268\n",
      "Epoch [725/2000], Avg Train Loss: 0.1731, Avg Val Loss: 0.2268\n",
      "\n",
      "Validation loss improved from 0.2270 to 0.2268. Saving model...\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1633\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2267\n",
      "Epoch [726/2000], Avg Train Loss: 0.1633, Avg Val Loss: 0.2267\n",
      "\n",
      "Validation loss improved from 0.2268 to 0.2267. Saving model...\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1591\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2265\n",
      "Epoch [727/2000], Avg Train Loss: 0.1591, Avg Val Loss: 0.2265\n",
      "\n",
      "Validation loss improved from 0.2267 to 0.2265. Saving model...\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1660\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [728/2000], Avg Train Loss: 0.1660, Avg Val Loss: 0.2264\n",
      "\n",
      "Validation loss improved from 0.2265 to 0.2264. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1655\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [729/2000], Avg Train Loss: 0.1655, Avg Val Loss: 0.2264\n",
      "\n",
      "Validation loss improved from 0.2264 to 0.2264. Saving model...\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1608\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2263\n",
      "Epoch [730/2000], Avg Train Loss: 0.1608, Avg Val Loss: 0.2263\n",
      "\n",
      "Validation loss improved from 0.2264 to 0.2263. Saving model...\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1685\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [731/2000], Avg Train Loss: 0.1685, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1611\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [732/2000], Avg Train Loss: 0.1611, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1597\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [733/2000], Avg Train Loss: 0.1597, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1621\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [734/2000], Avg Train Loss: 0.1621, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1618\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [735/2000], Avg Train Loss: 0.1618, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1620\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2265\n",
      "Epoch [736/2000], Avg Train Loss: 0.1620, Avg Val Loss: 0.2265\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1685\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2265\n",
      "Epoch [737/2000], Avg Train Loss: 0.1685, Avg Val Loss: 0.2265\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1611\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2265\n",
      "Epoch [738/2000], Avg Train Loss: 0.1611, Avg Val Loss: 0.2265\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1672\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2265\n",
      "Epoch [739/2000], Avg Train Loss: 0.1672, Avg Val Loss: 0.2265\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1632\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [740/2000], Avg Train Loss: 0.1632, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1606\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2264\n",
      "Epoch [741/2000], Avg Train Loss: 0.1606, Avg Val Loss: 0.2264\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1597\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2263\n",
      "Epoch [742/2000], Avg Train Loss: 0.1597, Avg Val Loss: 0.2263\n",
      "\n",
      "Validation loss improved from 0.2263 to 0.2263. Saving model...\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1659\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2261\n",
      "Epoch [743/2000], Avg Train Loss: 0.1659, Avg Val Loss: 0.2261\n",
      "\n",
      "Validation loss improved from 0.2263 to 0.2261. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1612\n",
      "LOG: Epoch [744/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2260\n",
      "Epoch [744/2000], Avg Train Loss: 0.1612, Avg Val Loss: 0.2260\n",
      "\n",
      "Validation loss improved from 0.2261 to 0.2260. Saving model...\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1598\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2259\n",
      "Epoch [745/2000], Avg Train Loss: 0.1598, Avg Val Loss: 0.2259\n",
      "\n",
      "Validation loss improved from 0.2260 to 0.2259. Saving model...\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1648\n",
      "LOG: Epoch [746/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2259\n",
      "Epoch [746/2000], Avg Train Loss: 0.1648, Avg Val Loss: 0.2259\n",
      "\n",
      "Validation loss improved from 0.2259 to 0.2259. Saving model...\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1636\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2259\n",
      "Epoch [747/2000], Avg Train Loss: 0.1636, Avg Val Loss: 0.2259\n",
      "\n",
      "Validation loss improved from 0.2259 to 0.2259. Saving model...\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1610\n",
      "LOG: Epoch [748/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [748/2000], Avg Train Loss: 0.1610, Avg Val Loss: 0.2258\n",
      "\n",
      "Validation loss improved from 0.2259 to 0.2258. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1612\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [749/2000], Avg Train Loss: 0.1612, Avg Val Loss: 0.2258\n",
      "\n",
      "Validation loss improved from 0.2258 to 0.2258. Saving model...\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1611\n",
      "LOG: Epoch [750/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [750/2000], Avg Train Loss: 0.1611, Avg Val Loss: 0.2258\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1577\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [751/2000], Avg Train Loss: 0.1577, Avg Val Loss: 0.2258\n",
      "\n",
      "Validation loss improved from 0.2258 to 0.2258. Saving model...\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1581\n",
      "LOG: Epoch [752/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [752/2000], Avg Train Loss: 0.1581, Avg Val Loss: 0.2258\n",
      "\n",
      "Validation loss improved from 0.2258 to 0.2258. Saving model...\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1661\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [753/2000], Avg Train Loss: 0.1661, Avg Val Loss: 0.2258\n",
      "\n",
      "Validation loss improved from 0.2258 to 0.2258. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1608\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2258\n",
      "Epoch [754/2000], Avg Train Loss: 0.1608, Avg Val Loss: 0.2258\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1616\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2257\n",
      "Epoch [755/2000], Avg Train Loss: 0.1616, Avg Val Loss: 0.2257\n",
      "\n",
      "Validation loss improved from 0.2258 to 0.2257. Saving model...\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1622\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2257\n",
      "Epoch [756/2000], Avg Train Loss: 0.1622, Avg Val Loss: 0.2257\n",
      "\n",
      "Validation loss improved from 0.2257 to 0.2257. Saving model...\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1584\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2257\n",
      "Epoch [757/2000], Avg Train Loss: 0.1584, Avg Val Loss: 0.2257\n",
      "\n",
      "Validation loss improved from 0.2257 to 0.2257. Saving model...\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1573\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2256\n",
      "Epoch [758/2000], Avg Train Loss: 0.1573, Avg Val Loss: 0.2256\n",
      "\n",
      "Validation loss improved from 0.2257 to 0.2256. Saving model...\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1615\n",
      "LOG: Epoch [759/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2255\n",
      "Epoch [759/2000], Avg Train Loss: 0.1615, Avg Val Loss: 0.2255\n",
      "\n",
      "Validation loss improved from 0.2256 to 0.2255. Saving model...\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1630\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2254\n",
      "Epoch [760/2000], Avg Train Loss: 0.1630, Avg Val Loss: 0.2254\n",
      "\n",
      "Validation loss improved from 0.2255 to 0.2254. Saving model...\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1561\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2253\n",
      "Epoch [761/2000], Avg Train Loss: 0.1561, Avg Val Loss: 0.2253\n",
      "\n",
      "Validation loss improved from 0.2254 to 0.2253. Saving model...\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1523\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2251\n",
      "Epoch [762/2000], Avg Train Loss: 0.1523, Avg Val Loss: 0.2251\n",
      "\n",
      "Validation loss improved from 0.2253 to 0.2251. Saving model...\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1559\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2250\n",
      "Epoch [763/2000], Avg Train Loss: 0.1559, Avg Val Loss: 0.2250\n",
      "\n",
      "Validation loss improved from 0.2251 to 0.2250. Saving model...\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1549\n",
      "LOG: Epoch [764/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2249\n",
      "Epoch [764/2000], Avg Train Loss: 0.1549, Avg Val Loss: 0.2249\n",
      "\n",
      "Validation loss improved from 0.2250 to 0.2249. Saving model...\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1613\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2248\n",
      "Epoch [765/2000], Avg Train Loss: 0.1613, Avg Val Loss: 0.2248\n",
      "\n",
      "Validation loss improved from 0.2249 to 0.2248. Saving model...\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1602\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2246\n",
      "Epoch [766/2000], Avg Train Loss: 0.1602, Avg Val Loss: 0.2246\n",
      "\n",
      "Validation loss improved from 0.2248 to 0.2246. Saving model...\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1598\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2245\n",
      "Epoch [767/2000], Avg Train Loss: 0.1598, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2246 to 0.2245. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1569\n",
      "LOG: Epoch [768/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2244\n",
      "Epoch [768/2000], Avg Train Loss: 0.1569, Avg Val Loss: 0.2244\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2244. Saving model...\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1647\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2244\n",
      "Epoch [769/2000], Avg Train Loss: 0.1647, Avg Val Loss: 0.2244\n",
      "\n",
      "Validation loss improved from 0.2244 to 0.2244. Saving model...\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1568\n",
      "LOG: Epoch [770/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2244\n",
      "Epoch [770/2000], Avg Train Loss: 0.1568, Avg Val Loss: 0.2244\n",
      "\n",
      "Validation loss improved from 0.2244 to 0.2244. Saving model...\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1545\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2244\n",
      "Epoch [771/2000], Avg Train Loss: 0.1545, Avg Val Loss: 0.2244\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1553\n",
      "LOG: Epoch [772/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2244\n",
      "Epoch [772/2000], Avg Train Loss: 0.1553, Avg Val Loss: 0.2244\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1506\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2244\n",
      "Epoch [773/2000], Avg Train Loss: 0.1506, Avg Val Loss: 0.2244\n",
      "\n",
      "Validation loss improved from 0.2244 to 0.2244. Saving model...\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1550\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2243\n",
      "Epoch [774/2000], Avg Train Loss: 0.1550, Avg Val Loss: 0.2243\n",
      "\n",
      "Validation loss improved from 0.2244 to 0.2243. Saving model...\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1444\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2241\n",
      "Epoch [775/2000], Avg Train Loss: 0.1444, Avg Val Loss: 0.2241\n",
      "\n",
      "Validation loss improved from 0.2243 to 0.2241. Saving model...\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1611\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2240\n",
      "Epoch [776/2000], Avg Train Loss: 0.1611, Avg Val Loss: 0.2240\n",
      "\n",
      "Validation loss improved from 0.2241 to 0.2240. Saving model...\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1528\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2239\n",
      "Epoch [777/2000], Avg Train Loss: 0.1528, Avg Val Loss: 0.2239\n",
      "\n",
      "Validation loss improved from 0.2240 to 0.2239. Saving model...\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1565\n",
      "LOG: Epoch [778/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2238\n",
      "Epoch [778/2000], Avg Train Loss: 0.1565, Avg Val Loss: 0.2238\n",
      "\n",
      "Validation loss improved from 0.2239 to 0.2238. Saving model...\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1509\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2237\n",
      "Epoch [779/2000], Avg Train Loss: 0.1509, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2238 to 0.2237. Saving model...\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1551\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2236\n",
      "Epoch [780/2000], Avg Train Loss: 0.1551, Avg Val Loss: 0.2236\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2236. Saving model...\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1526\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2236\n",
      "Epoch [781/2000], Avg Train Loss: 0.1526, Avg Val Loss: 0.2236\n",
      "\n",
      "Validation loss improved from 0.2236 to 0.2236. Saving model...\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1565\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2235\n",
      "Epoch [782/2000], Avg Train Loss: 0.1565, Avg Val Loss: 0.2235\n",
      "\n",
      "Validation loss improved from 0.2236 to 0.2235. Saving model...\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1607\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2234\n",
      "Epoch [783/2000], Avg Train Loss: 0.1607, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2235 to 0.2234. Saving model...\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1514\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2233\n",
      "Epoch [784/2000], Avg Train Loss: 0.1514, Avg Val Loss: 0.2233\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2233. Saving model...\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1577\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2232\n",
      "Epoch [785/2000], Avg Train Loss: 0.1577, Avg Val Loss: 0.2232\n",
      "\n",
      "Validation loss improved from 0.2233 to 0.2232. Saving model...\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1503\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2232\n",
      "Epoch [786/2000], Avg Train Loss: 0.1503, Avg Val Loss: 0.2232\n",
      "\n",
      "Validation loss improved from 0.2232 to 0.2232. Saving model...\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1488\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2231\n",
      "Epoch [787/2000], Avg Train Loss: 0.1488, Avg Val Loss: 0.2231\n",
      "\n",
      "Validation loss improved from 0.2232 to 0.2231. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1579\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2231\n",
      "Epoch [788/2000], Avg Train Loss: 0.1579, Avg Val Loss: 0.2231\n",
      "\n",
      "Validation loss improved from 0.2231 to 0.2231. Saving model...\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1487\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2229\n",
      "Epoch [789/2000], Avg Train Loss: 0.1487, Avg Val Loss: 0.2229\n",
      "\n",
      "Validation loss improved from 0.2231 to 0.2229. Saving model...\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1543\n",
      "LOG: Epoch [790/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2228\n",
      "Epoch [790/2000], Avg Train Loss: 0.1543, Avg Val Loss: 0.2228\n",
      "\n",
      "Validation loss improved from 0.2229 to 0.2228. Saving model...\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1609\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2227\n",
      "Epoch [791/2000], Avg Train Loss: 0.1609, Avg Val Loss: 0.2227\n",
      "\n",
      "Validation loss improved from 0.2228 to 0.2227. Saving model...\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1611\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2226\n",
      "Epoch [792/2000], Avg Train Loss: 0.1611, Avg Val Loss: 0.2226\n",
      "\n",
      "Validation loss improved from 0.2227 to 0.2226. Saving model...\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1483\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2226\n",
      "Epoch [793/2000], Avg Train Loss: 0.1483, Avg Val Loss: 0.2226\n",
      "\n",
      "Validation loss improved from 0.2226 to 0.2226. Saving model...\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1485\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2225\n",
      "Epoch [794/2000], Avg Train Loss: 0.1485, Avg Val Loss: 0.2225\n",
      "\n",
      "Validation loss improved from 0.2226 to 0.2225. Saving model...\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1475\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2224\n",
      "Epoch [795/2000], Avg Train Loss: 0.1475, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2225 to 0.2224. Saving model...\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1568\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2224\n",
      "Epoch [796/2000], Avg Train Loss: 0.1568, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2224. Saving model...\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1470\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2224\n",
      "Epoch [797/2000], Avg Train Loss: 0.1470, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2224. Saving model...\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1466\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2224\n",
      "Epoch [798/2000], Avg Train Loss: 0.1466, Avg Val Loss: 0.2224\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1529\n",
      "LOG: Epoch [799/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2224\n",
      "Epoch [799/2000], Avg Train Loss: 0.1529, Avg Val Loss: 0.2224\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1540\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2224\n",
      "Epoch [800/2000], Avg Train Loss: 0.1540, Avg Val Loss: 0.2224\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1567\n",
      "LOG: Epoch [801/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2223\n",
      "Epoch [801/2000], Avg Train Loss: 0.1567, Avg Val Loss: 0.2223\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2223. Saving model...\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1552\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2223\n",
      "Epoch [802/2000], Avg Train Loss: 0.1552, Avg Val Loss: 0.2223\n",
      "\n",
      "Validation loss improved from 0.2223 to 0.2223. Saving model...\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1554\n",
      "LOG: Epoch [803/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2222\n",
      "Epoch [803/2000], Avg Train Loss: 0.1554, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2223 to 0.2222. Saving model...\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1523\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [804/2000], Avg Train Loss: 0.1523, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2221. Saving model...\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1529\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [805/2000], Avg Train Loss: 0.1529, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1438\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [806/2000], Avg Train Loss: 0.1438, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1484\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [807/2000], Avg Train Loss: 0.1484, Avg Val Loss: 0.2221\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1527\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [808/2000], Avg Train Loss: 0.1527, Avg Val Loss: 0.2221\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1488\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [809/2000], Avg Train Loss: 0.1488, Avg Val Loss: 0.2221\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1500\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2222\n",
      "Epoch [810/2000], Avg Train Loss: 0.1500, Avg Val Loss: 0.2222\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1511\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2222\n",
      "Epoch [811/2000], Avg Train Loss: 0.1511, Avg Val Loss: 0.2222\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1481\n",
      "LOG: Epoch [812/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [812/2000], Avg Train Loss: 0.1481, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1470\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2220\n",
      "Epoch [813/2000], Avg Train Loss: 0.1470, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2220. Saving model...\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1517\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2219\n",
      "Epoch [814/2000], Avg Train Loss: 0.1517, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2219. Saving model...\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1501\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2218\n",
      "Epoch [815/2000], Avg Train Loss: 0.1501, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2218. Saving model...\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1492\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2216\n",
      "Epoch [816/2000], Avg Train Loss: 0.1492, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2216. Saving model...\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1476\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2216\n",
      "Epoch [817/2000], Avg Train Loss: 0.1476, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2216. Saving model...\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1440\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2215\n",
      "Epoch [818/2000], Avg Train Loss: 0.1440, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2215. Saving model...\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1503\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2214\n",
      "Epoch [819/2000], Avg Train Loss: 0.1503, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2214. Saving model...\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1535\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2213\n",
      "Epoch [820/2000], Avg Train Loss: 0.1535, Avg Val Loss: 0.2213\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2213. Saving model...\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1523\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2211\n",
      "Epoch [821/2000], Avg Train Loss: 0.1523, Avg Val Loss: 0.2211\n",
      "\n",
      "Validation loss improved from 0.2213 to 0.2211. Saving model...\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1440\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2210\n",
      "Epoch [822/2000], Avg Train Loss: 0.1440, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2211 to 0.2210. Saving model...\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1454\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2208\n",
      "Epoch [823/2000], Avg Train Loss: 0.1454, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2208. Saving model...\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1508\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2207\n",
      "Epoch [824/2000], Avg Train Loss: 0.1508, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2207. Saving model...\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1430\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2207\n",
      "Epoch [825/2000], Avg Train Loss: 0.1430, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2207. Saving model...\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1470\n",
      "LOG: Epoch [826/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2207\n",
      "Epoch [826/2000], Avg Train Loss: 0.1470, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1516\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2208\n",
      "Epoch [827/2000], Avg Train Loss: 0.1516, Avg Val Loss: 0.2208\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1435\n",
      "LOG: Epoch [828/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2207\n",
      "Epoch [828/2000], Avg Train Loss: 0.1435, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1423\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2208\n",
      "Epoch [829/2000], Avg Train Loss: 0.1423, Avg Val Loss: 0.2208\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1511\n",
      "LOG: Epoch [830/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2208\n",
      "Epoch [830/2000], Avg Train Loss: 0.1511, Avg Val Loss: 0.2208\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1512\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2209\n",
      "Epoch [831/2000], Avg Train Loss: 0.1512, Avg Val Loss: 0.2209\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1549\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2209\n",
      "Epoch [832/2000], Avg Train Loss: 0.1549, Avg Val Loss: 0.2209\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1455\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2210\n",
      "Epoch [833/2000], Avg Train Loss: 0.1455, Avg Val Loss: 0.2210\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1398\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2211\n",
      "Epoch [834/2000], Avg Train Loss: 0.1398, Avg Val Loss: 0.2211\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1474\n",
      "LOG: Epoch [835/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2211\n",
      "Epoch [835/2000], Avg Train Loss: 0.1474, Avg Val Loss: 0.2211\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1516\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2212\n",
      "Epoch [836/2000], Avg Train Loss: 0.1516, Avg Val Loss: 0.2212\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1483\n",
      "LOG: Epoch [837/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2212\n",
      "Epoch [837/2000], Avg Train Loss: 0.1483, Avg Val Loss: 0.2212\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1438\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2213\n",
      "Epoch [838/2000], Avg Train Loss: 0.1438, Avg Val Loss: 0.2213\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1437\n",
      "LOG: Epoch [839/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2214\n",
      "Epoch [839/2000], Avg Train Loss: 0.1437, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1441\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2214\n",
      "Epoch [840/2000], Avg Train Loss: 0.1441, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1463\n",
      "LOG: Epoch [841/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2213\n",
      "Epoch [841/2000], Avg Train Loss: 0.1463, Avg Val Loss: 0.2213\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1463\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2212\n",
      "Epoch [842/2000], Avg Train Loss: 0.1463, Avg Val Loss: 0.2212\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1492\n",
      "LOG: Epoch [843/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2211\n",
      "Epoch [843/2000], Avg Train Loss: 0.1492, Avg Val Loss: 0.2211\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1445\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2209\n",
      "Epoch [844/2000], Avg Train Loss: 0.1445, Avg Val Loss: 0.2209\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1427\n",
      "LOG: Epoch [845/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2208\n",
      "Epoch [845/2000], Avg Train Loss: 0.1427, Avg Val Loss: 0.2208\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1431\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2207\n",
      "Epoch [846/2000], Avg Train Loss: 0.1431, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2207. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1540\n",
      "LOG: Epoch [847/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2206\n",
      "Epoch [847/2000], Avg Train Loss: 0.1540, Avg Val Loss: 0.2206\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2206. Saving model...\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1412\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2205\n",
      "Epoch [848/2000], Avg Train Loss: 0.1412, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2206 to 0.2205. Saving model...\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1435\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2204\n",
      "Epoch [849/2000], Avg Train Loss: 0.1435, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2204. Saving model...\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1444\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2203\n",
      "Epoch [850/2000], Avg Train Loss: 0.1444, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2203. Saving model...\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1475\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2202\n",
      "Epoch [851/2000], Avg Train Loss: 0.1475, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2202. Saving model...\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1488\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2200\n",
      "Epoch [852/2000], Avg Train Loss: 0.1488, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2200. Saving model...\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1393\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2199\n",
      "Epoch [853/2000], Avg Train Loss: 0.1393, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2199. Saving model...\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1401\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2198\n",
      "Epoch [854/2000], Avg Train Loss: 0.1401, Avg Val Loss: 0.2198\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2198. Saving model...\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1411\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2197\n",
      "Epoch [855/2000], Avg Train Loss: 0.1411, Avg Val Loss: 0.2197\n",
      "\n",
      "Validation loss improved from 0.2198 to 0.2197. Saving model...\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1394\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2196\n",
      "Epoch [856/2000], Avg Train Loss: 0.1394, Avg Val Loss: 0.2196\n",
      "\n",
      "Validation loss improved from 0.2197 to 0.2196. Saving model...\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1416\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2195\n",
      "Epoch [857/2000], Avg Train Loss: 0.1416, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2196 to 0.2195. Saving model...\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1464\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2195\n",
      "Epoch [858/2000], Avg Train Loss: 0.1464, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2195. Saving model...\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1486\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2196\n",
      "Epoch [859/2000], Avg Train Loss: 0.1486, Avg Val Loss: 0.2196\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1462\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2197\n",
      "Epoch [860/2000], Avg Train Loss: 0.1462, Avg Val Loss: 0.2197\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1396\n",
      "LOG: Epoch [861/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2199\n",
      "Epoch [861/2000], Avg Train Loss: 0.1396, Avg Val Loss: 0.2199\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1501\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2200\n",
      "Epoch [862/2000], Avg Train Loss: 0.1501, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1440\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2202\n",
      "Epoch [863/2000], Avg Train Loss: 0.1440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1400\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2202\n",
      "Epoch [864/2000], Avg Train Loss: 0.1400, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1396\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2201\n",
      "Epoch [865/2000], Avg Train Loss: 0.1396, Avg Val Loss: 0.2201\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1447\n",
      "LOG: Epoch [866/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2201\n",
      "Epoch [866/2000], Avg Train Loss: 0.1447, Avg Val Loss: 0.2201\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1450\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2201\n",
      "Epoch [867/2000], Avg Train Loss: 0.1450, Avg Val Loss: 0.2201\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1463\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2200\n",
      "Epoch [868/2000], Avg Train Loss: 0.1463, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1411\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2199\n",
      "Epoch [869/2000], Avg Train Loss: 0.1411, Avg Val Loss: 0.2199\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1433\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2198\n",
      "Epoch [870/2000], Avg Train Loss: 0.1433, Avg Val Loss: 0.2198\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1444\n",
      "LOG: Epoch [871/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2198\n",
      "Epoch [871/2000], Avg Train Loss: 0.1444, Avg Val Loss: 0.2198\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1413\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2198\n",
      "Epoch [872/2000], Avg Train Loss: 0.1413, Avg Val Loss: 0.2198\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1434\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2197\n",
      "Epoch [873/2000], Avg Train Loss: 0.1434, Avg Val Loss: 0.2197\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1330\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2196\n",
      "Epoch [874/2000], Avg Train Loss: 0.1330, Avg Val Loss: 0.2196\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1463\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2195\n",
      "Epoch [875/2000], Avg Train Loss: 0.1463, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2195. Saving model...\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1444\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2194\n",
      "Epoch [876/2000], Avg Train Loss: 0.1444, Avg Val Loss: 0.2194\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2194. Saving model...\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1420\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2192\n",
      "Epoch [877/2000], Avg Train Loss: 0.1420, Avg Val Loss: 0.2192\n",
      "\n",
      "Validation loss improved from 0.2194 to 0.2192. Saving model...\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1345\n",
      "LOG: Epoch [878/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2191\n",
      "Epoch [878/2000], Avg Train Loss: 0.1345, Avg Val Loss: 0.2191\n",
      "\n",
      "Validation loss improved from 0.2192 to 0.2191. Saving model...\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1410\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2190\n",
      "Epoch [879/2000], Avg Train Loss: 0.1410, Avg Val Loss: 0.2190\n",
      "\n",
      "Validation loss improved from 0.2191 to 0.2190. Saving model...\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1394\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2189\n",
      "Epoch [880/2000], Avg Train Loss: 0.1394, Avg Val Loss: 0.2189\n",
      "\n",
      "Validation loss improved from 0.2190 to 0.2189. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1377\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2188\n",
      "Epoch [881/2000], Avg Train Loss: 0.1377, Avg Val Loss: 0.2188\n",
      "\n",
      "Validation loss improved from 0.2189 to 0.2188. Saving model...\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1428\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2188\n",
      "Epoch [882/2000], Avg Train Loss: 0.1428, Avg Val Loss: 0.2188\n",
      "\n",
      "Validation loss improved from 0.2188 to 0.2188. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1401\n",
      "LOG: Epoch [883/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2187\n",
      "Epoch [883/2000], Avg Train Loss: 0.1401, Avg Val Loss: 0.2187\n",
      "\n",
      "Validation loss improved from 0.2188 to 0.2187. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1407\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2185\n",
      "Epoch [884/2000], Avg Train Loss: 0.1407, Avg Val Loss: 0.2185\n",
      "\n",
      "Validation loss improved from 0.2187 to 0.2185. Saving model...\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1398\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2184\n",
      "Epoch [885/2000], Avg Train Loss: 0.1398, Avg Val Loss: 0.2184\n",
      "\n",
      "Validation loss improved from 0.2185 to 0.2184. Saving model...\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1404\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2183\n",
      "Epoch [886/2000], Avg Train Loss: 0.1404, Avg Val Loss: 0.2183\n",
      "\n",
      "Validation loss improved from 0.2184 to 0.2183. Saving model...\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1375\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [887/2000], Avg Train Loss: 0.1375, Avg Val Loss: 0.2182\n",
      "\n",
      "Validation loss improved from 0.2183 to 0.2182. Saving model...\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1420\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [888/2000], Avg Train Loss: 0.1420, Avg Val Loss: 0.2182\n",
      "\n",
      "Validation loss improved from 0.2182 to 0.2182. Saving model...\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1408\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [889/2000], Avg Train Loss: 0.1408, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1385\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [890/2000], Avg Train Loss: 0.1385, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1367\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [891/2000], Avg Train Loss: 0.1367, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1341\n",
      "LOG: Epoch [892/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [892/2000], Avg Train Loss: 0.1341, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1362\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [893/2000], Avg Train Loss: 0.1362, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1429\n",
      "LOG: Epoch [894/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2183\n",
      "Epoch [894/2000], Avg Train Loss: 0.1429, Avg Val Loss: 0.2183\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1363\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2183\n",
      "Epoch [895/2000], Avg Train Loss: 0.1363, Avg Val Loss: 0.2183\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1380\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2184\n",
      "Epoch [896/2000], Avg Train Loss: 0.1380, Avg Val Loss: 0.2184\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1488\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2183\n",
      "Epoch [897/2000], Avg Train Loss: 0.1488, Avg Val Loss: 0.2183\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1361\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2184\n",
      "Epoch [898/2000], Avg Train Loss: 0.1361, Avg Val Loss: 0.2184\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1317\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2186\n",
      "Epoch [899/2000], Avg Train Loss: 0.1317, Avg Val Loss: 0.2186\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2186\n",
      "Epoch [900/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2186\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1431\n",
      "LOG: Epoch [901/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2185\n",
      "Epoch [901/2000], Avg Train Loss: 0.1431, Avg Val Loss: 0.2185\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1365\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2185\n",
      "Epoch [902/2000], Avg Train Loss: 0.1365, Avg Val Loss: 0.2185\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1345\n",
      "LOG: Epoch [903/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2184\n",
      "Epoch [903/2000], Avg Train Loss: 0.1345, Avg Val Loss: 0.2184\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1296\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2183\n",
      "Epoch [904/2000], Avg Train Loss: 0.1296, Avg Val Loss: 0.2183\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1409\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [905/2000], Avg Train Loss: 0.1409, Avg Val Loss: 0.2182\n",
      "\n",
      "Validation loss improved from 0.2182 to 0.2182. Saving model...\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1358\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2180\n",
      "Epoch [906/2000], Avg Train Loss: 0.1358, Avg Val Loss: 0.2180\n",
      "\n",
      "Validation loss improved from 0.2182 to 0.2180. Saving model...\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1357\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2178\n",
      "Epoch [907/2000], Avg Train Loss: 0.1357, Avg Val Loss: 0.2178\n",
      "\n",
      "Validation loss improved from 0.2180 to 0.2178. Saving model...\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1329\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2178\n",
      "Epoch [908/2000], Avg Train Loss: 0.1329, Avg Val Loss: 0.2178\n",
      "\n",
      "Validation loss improved from 0.2178 to 0.2178. Saving model...\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1387\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2177\n",
      "Epoch [909/2000], Avg Train Loss: 0.1387, Avg Val Loss: 0.2177\n",
      "\n",
      "Validation loss improved from 0.2178 to 0.2177. Saving model...\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1310\n",
      "LOG: Epoch [910/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2177\n",
      "Epoch [910/2000], Avg Train Loss: 0.1310, Avg Val Loss: 0.2177\n",
      "\n",
      "Validation loss improved from 0.2177 to 0.2177. Saving model...\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1392\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2177\n",
      "Epoch [911/2000], Avg Train Loss: 0.1392, Avg Val Loss: 0.2177\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1351\n",
      "LOG: Epoch [912/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2178\n",
      "Epoch [912/2000], Avg Train Loss: 0.1351, Avg Val Loss: 0.2178\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1331\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2178\n",
      "Epoch [913/2000], Avg Train Loss: 0.1331, Avg Val Loss: 0.2178\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1389\n",
      "LOG: Epoch [914/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2179\n",
      "Epoch [914/2000], Avg Train Loss: 0.1389, Avg Val Loss: 0.2179\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1358\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2179\n",
      "Epoch [915/2000], Avg Train Loss: 0.1358, Avg Val Loss: 0.2179\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1336\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2180\n",
      "Epoch [916/2000], Avg Train Loss: 0.1336, Avg Val Loss: 0.2180\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1350\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2180\n",
      "Epoch [917/2000], Avg Train Loss: 0.1350, Avg Val Loss: 0.2180\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1426\n",
      "LOG: Epoch [918/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2180\n",
      "Epoch [918/2000], Avg Train Loss: 0.1426, Avg Val Loss: 0.2180\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1442\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2180\n",
      "Epoch [919/2000], Avg Train Loss: 0.1442, Avg Val Loss: 0.2180\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1364\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2181\n",
      "Epoch [920/2000], Avg Train Loss: 0.1364, Avg Val Loss: 0.2181\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1346\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2181\n",
      "Epoch [921/2000], Avg Train Loss: 0.1346, Avg Val Loss: 0.2181\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1373\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [922/2000], Avg Train Loss: 0.1373, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1356\n",
      "LOG: Epoch [923/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [923/2000], Avg Train Loss: 0.1356, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1289\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2182\n",
      "Epoch [924/2000], Avg Train Loss: 0.1289, Avg Val Loss: 0.2182\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2181\n",
      "Epoch [925/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.2181\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1357\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2181\n",
      "Epoch [926/2000], Avg Train Loss: 0.1357, Avg Val Loss: 0.2181\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1283\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2181\n",
      "Epoch [927/2000], Avg Train Loss: 0.1283, Avg Val Loss: 0.2181\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1361\n",
      "LOG: Epoch [928/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2179\n",
      "Epoch [928/2000], Avg Train Loss: 0.1361, Avg Val Loss: 0.2179\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1303\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2177\n",
      "Epoch [929/2000], Avg Train Loss: 0.1303, Avg Val Loss: 0.2177\n",
      "\n",
      "Validation loss improved from 0.2177 to 0.2177. Saving model...\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1339\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2175\n",
      "Epoch [930/2000], Avg Train Loss: 0.1339, Avg Val Loss: 0.2175\n",
      "\n",
      "Validation loss improved from 0.2177 to 0.2175. Saving model...\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1326\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2172\n",
      "Epoch [931/2000], Avg Train Loss: 0.1326, Avg Val Loss: 0.2172\n",
      "\n",
      "Validation loss improved from 0.2175 to 0.2172. Saving model...\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2171\n",
      "Epoch [932/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2171\n",
      "\n",
      "Validation loss improved from 0.2172 to 0.2171. Saving model...\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [933/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2169\n",
      "Epoch [933/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2169\n",
      "\n",
      "Validation loss improved from 0.2171 to 0.2169. Saving model...\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [934/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2167\n",
      "\n",
      "Validation loss improved from 0.2169 to 0.2167. Saving model...\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1362\n",
      "LOG: Epoch [935/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2164\n",
      "Epoch [935/2000], Avg Train Loss: 0.1362, Avg Val Loss: 0.2164\n",
      "\n",
      "Validation loss improved from 0.2167 to 0.2164. Saving model...\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2162\n",
      "Epoch [936/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2164 to 0.2162. Saving model...\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1317\n",
      "LOG: Epoch [937/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2160\n",
      "Epoch [937/2000], Avg Train Loss: 0.1317, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2160. Saving model...\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2159\n",
      "Epoch [938/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2159\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2159. Saving model...\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1393\n",
      "LOG: Epoch [939/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [939/2000], Avg Train Loss: 0.1393, Avg Val Loss: 0.2158\n",
      "\n",
      "Validation loss improved from 0.2159 to 0.2158. Saving model...\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1307\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [940/2000], Avg Train Loss: 0.1307, Avg Val Loss: 0.2158\n",
      "\n",
      "Validation loss improved from 0.2158 to 0.2158. Saving model...\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1352\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [941/2000], Avg Train Loss: 0.1352, Avg Val Loss: 0.2158\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1312\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [942/2000], Avg Train Loss: 0.1312, Avg Val Loss: 0.2158\n",
      "\n",
      "Validation loss improved from 0.2158 to 0.2158. Saving model...\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2157\n",
      "Epoch [943/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2158 to 0.2157. Saving model...\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1358\n",
      "LOG: Epoch [944/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [944/2000], Avg Train Loss: 0.1358, Avg Val Loss: 0.2158\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [945/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.2158\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1362\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2159\n",
      "Epoch [946/2000], Avg Train Loss: 0.1362, Avg Val Loss: 0.2159\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2160\n",
      "Epoch [947/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2161\n",
      "Epoch [948/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2162\n",
      "Epoch [949/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1330\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2163\n",
      "Epoch [950/2000], Avg Train Loss: 0.1330, Avg Val Loss: 0.2163\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2165\n",
      "Epoch [951/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2165\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2166\n",
      "Epoch [952/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.2166\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [953/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2168\n",
      "Epoch [954/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2168\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1342\n",
      "LOG: Epoch [955/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2168\n",
      "Epoch [955/2000], Avg Train Loss: 0.1342, Avg Val Loss: 0.2168\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2168\n",
      "Epoch [956/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2168\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [957/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [957/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [958/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [959/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [959/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [960/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [961/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [962/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [963/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2167\n",
      "Epoch [964/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2167\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2166\n",
      "Epoch [965/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2166\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1314\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2166\n",
      "Epoch [966/2000], Avg Train Loss: 0.1314, Avg Val Loss: 0.2166\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2165\n",
      "Epoch [967/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2165\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [968/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2165\n",
      "Epoch [968/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2165\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2163\n",
      "Epoch [969/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2163\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1283\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2163\n",
      "Epoch [970/2000], Avg Train Loss: 0.1283, Avg Val Loss: 0.2163\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1334\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2162\n",
      "Epoch [971/2000], Avg Train Loss: 0.1334, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2161\n",
      "Epoch [972/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [973/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2161\n",
      "Epoch [973/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2160\n",
      "Epoch [974/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1300\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2159\n",
      "Epoch [975/2000], Avg Train Loss: 0.1300, Avg Val Loss: 0.2159\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [976/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2158\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2158\n",
      "Epoch [977/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2158\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2157\n",
      "Epoch [978/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2157. Saving model...\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2156\n",
      "Epoch [979/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2156\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2156. Saving model...\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [980/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2156\n",
      "Epoch [980/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2156\n",
      "\n",
      "Validation loss improved from 0.2156 to 0.2156. Saving model...\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1373\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2155\n",
      "Epoch [981/2000], Avg Train Loss: 0.1373, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2156 to 0.2155. Saving model...\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [982/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2155\n",
      "Epoch [982/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2155. Saving model...\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2155\n",
      "Epoch [983/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2155. Saving model...\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2154\n",
      "Epoch [984/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2154\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2154. Saving model...\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1317\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2154\n",
      "Epoch [985/2000], Avg Train Loss: 0.1317, Avg Val Loss: 0.2154\n",
      "\n",
      "Validation loss improved from 0.2154 to 0.2154. Saving model...\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [986/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2154\n",
      "Epoch [986/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2154\n",
      "\n",
      "Validation loss improved from 0.2154 to 0.2154. Saving model...\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1351\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [987/2000], Avg Train Loss: 0.1351, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2154 to 0.2153. Saving model...\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [988/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [989/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [990/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [990/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1335\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [991/2000], Avg Train Loss: 0.1335, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1340\n",
      "LOG: Epoch [992/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [992/2000], Avg Train Loss: 0.1340, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1338\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [993/2000], Avg Train Loss: 0.1338, Avg Val Loss: 0.2153\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [994/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [994/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2153\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [995/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2153\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1330\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [996/2000], Avg Train Loss: 0.1330, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [997/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2153. Saving model...\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [998/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2152. Saving model...\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1245\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [999/2000], Avg Train Loss: 0.1245, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1000/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1001/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1326\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1002/2000], Avg Train Loss: 0.1326, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1003/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1004/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1005/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1006/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1007/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1007/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1008/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1009/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1009/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1010/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1011/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1307\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1012/2000], Avg Train Loss: 0.1307, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1013/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1014/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1015/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1016/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1016/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1017/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1018/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1019/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1020/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1318\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2152\n",
      "Epoch [1021/2000], Avg Train Loss: 0.1318, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2152. Saving model...\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1381\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1022/2000], Avg Train Loss: 0.1381, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2151. Saving model...\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1023/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1023/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1289\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1024/2000], Avg Train Loss: 0.1289, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1025/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1026/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1027/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2151\n",
      "Epoch [1028/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1029/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2150. Saving model...\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1030/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1031/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1032/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1033/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1302\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1034/2000], Avg Train Loss: 0.1302, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1035/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1036/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1037/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1037/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1038/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1330\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1039/2000], Avg Train Loss: 0.1330, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1040/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2150. Saving model...\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1278\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1041/2000], Avg Train Loss: 0.1278, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2149. Saving model...\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1042/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1042/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1043/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1044/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1044/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1045/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1046/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1303\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1047/2000], Avg Train Loss: 0.1303, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1048/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1049/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1050/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1051/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1051/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1188\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1052/2000], Avg Train Loss: 0.1188, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1053/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1054/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1253\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1055/2000], Avg Train Loss: 0.1253, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1056/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1057/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1058/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1191\n",
      "LOG: Epoch [1059/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1059/2000], Avg Train Loss: 0.1191, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1060/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1061/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1062/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1300\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1063/2000], Avg Train Loss: 0.1300, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1064/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1065/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1065/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1066/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1067/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1068/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1069/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1070/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1071/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1071/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1072/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1174\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1073/2000], Avg Train Loss: 0.1174, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1074/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1075/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1076/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1077/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1078/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1078/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1079/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1080/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1081/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1082/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1083/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1084/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1311\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1085/2000], Avg Train Loss: 0.1311, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1086/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [1087/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2150\n",
      "Epoch [1087/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2150\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1295\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1088/2000], Avg Train Loss: 0.1295, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1089/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1090/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1091/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1092/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1093/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1094/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1191\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1095/2000], Avg Train Loss: 0.1191, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [1096/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1096/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1097/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1098/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1099/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1100/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1101/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1102/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1103/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1104/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1105/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1105/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1106/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1107/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1108/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1109/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1324\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1110/2000], Avg Train Loss: 0.1324, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1219\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1111/2000], Avg Train Loss: 0.1219, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1319\n",
      "LOG: Epoch [1112/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1112/2000], Avg Train Loss: 0.1319, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1113/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1114/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1115/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1317\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1116/2000], Avg Train Loss: 0.1317, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1350\n",
      "LOG: Epoch [1117/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1117/2000], Avg Train Loss: 0.1350, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1118/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1179\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1119/2000], Avg Train Loss: 0.1179, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1120/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1121/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1122/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1122/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1123/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1124/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1269\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1125/2000], Avg Train Loss: 0.1269, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1324\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1126/2000], Avg Train Loss: 0.1324, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1161\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1127/2000], Avg Train Loss: 0.1161, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1128/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1129/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1130/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1131/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1132/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1197\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1133/2000], Avg Train Loss: 0.1197, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1134/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1135/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1310\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1136/2000], Avg Train Loss: 0.1310, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1137/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1137/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1138/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1139/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1140/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1141/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1142/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1142/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1143/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1144/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1144/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1298\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1145/2000], Avg Train Loss: 0.1298, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1146/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1147/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1333\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1148/2000], Avg Train Loss: 0.1333, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1149/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1149/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1150/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1151/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1152/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1153/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1154/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1155/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1156/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1157/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1158/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1159/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1160/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1161/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1162/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1163/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1164/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1165/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1166/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1166/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1167/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1168/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1168/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1169/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [1170/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1170/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1171/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1172/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1173/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1174/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1200\n",
      "LOG: Epoch [1175/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1175/2000], Avg Train Loss: 0.1200, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1176/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1177/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1177/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1178/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1179/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1180/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1181/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1182/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1182/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1183/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1296\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1184/2000], Avg Train Loss: 0.1296, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1185/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1192\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1186/2000], Avg Train Loss: 0.1192, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1187/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1188/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1189/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1190/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1191/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1192/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1193/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1177\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1194/2000], Avg Train Loss: 0.1177, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1195/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1196/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1197/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1198/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1199/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1199/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1200/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1201/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1288\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1202/2000], Avg Train Loss: 0.1288, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1203/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1318\n",
      "LOG: Epoch [1204/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1204/2000], Avg Train Loss: 0.1318, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1208\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1205/2000], Avg Train Loss: 0.1208, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1199\n",
      "LOG: Epoch [1206/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1206/2000], Avg Train Loss: 0.1199, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1207/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1291\n",
      "LOG: Epoch [1208/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1208/2000], Avg Train Loss: 0.1291, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1209/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1245\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1210/2000], Avg Train Loss: 0.1245, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1291\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1211/2000], Avg Train Loss: 0.1291, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1212/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1213/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1213/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1214/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1215/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1216/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1217/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1218/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1219/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1220/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1220/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1221/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1222/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1223/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1224/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1225/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1226/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [1227/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1227/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1228/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1229/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1311\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1230/2000], Avg Train Loss: 0.1311, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1231/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1232/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1232/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1233/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1299\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1234/2000], Avg Train Loss: 0.1299, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1298\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1235/2000], Avg Train Loss: 0.1298, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1236/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1237/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1238/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1183\n",
      "LOG: Epoch [1239/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1239/2000], Avg Train Loss: 0.1183, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1299\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1240/2000], Avg Train Loss: 0.1299, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1241/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1242/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1243/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1244/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1245/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1246/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1307\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1247/2000], Avg Train Loss: 0.1307, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [1248/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1248/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1249/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1250/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1251/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1252/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1182\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1253/2000], Avg Train Loss: 0.1182, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1254/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [1255/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1255/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1256/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1375\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1257/2000], Avg Train Loss: 0.1375, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1258/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1259/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [1260/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1260/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1261/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1298\n",
      "LOG: Epoch [1262/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1262/2000], Avg Train Loss: 0.1298, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1263/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [1264/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1264/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1269\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1265/2000], Avg Train Loss: 0.1269, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1266/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1304\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1267/2000], Avg Train Loss: 0.1304, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1268/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1269/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1269/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1270/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1271/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1271/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1272/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1273/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1274/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1275/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1276/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1277/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1333\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1278/2000], Avg Train Loss: 0.1333, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1311\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1279/2000], Avg Train Loss: 0.1311, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1219\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1280/2000], Avg Train Loss: 0.1219, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1281/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1282/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1282/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1283/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1284/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1285/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1286/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1311\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1287/2000], Avg Train Loss: 0.1311, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [1288/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1288/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1175\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1289/2000], Avg Train Loss: 0.1175, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1297\n",
      "LOG: Epoch [1290/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1290/2000], Avg Train Loss: 0.1297, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1291/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1292/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1321\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1293/2000], Avg Train Loss: 0.1321, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1294/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1276\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1295/2000], Avg Train Loss: 0.1276, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1172\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1296/2000], Avg Train Loss: 0.1172, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1297/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1297/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1278\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1298/2000], Avg Train Loss: 0.1278, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1299/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1299/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1324\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1300/2000], Avg Train Loss: 0.1324, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1301/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1289\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1302/2000], Avg Train Loss: 0.1289, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1303/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [1304/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1304/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1305/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1306/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1307/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1196\n",
      "LOG: Epoch [1308/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1308/2000], Avg Train Loss: 0.1196, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1301\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1309/2000], Avg Train Loss: 0.1301, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1310/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1310/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1311/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1312/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1313/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1314/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1315/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1316/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1166\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1317/2000], Avg Train Loss: 0.1166, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1318/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1318/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1319/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1320/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1320/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1321/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1192\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1322/2000], Avg Train Loss: 0.1192, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1323/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1324/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1325/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1325/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1326/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1327/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1328/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1329/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [1330/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1330/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1331/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1332/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1333/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1334/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1324\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1335/2000], Avg Train Loss: 0.1324, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1283\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1336/2000], Avg Train Loss: 0.1283, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1337/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1338/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1338/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1339/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [1340/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1340/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1341/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1342/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1343/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1344/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1345/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1346/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1347/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1348/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1349/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1350/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1350/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1351/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [1352/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1352/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1353/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1354/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1355/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1356/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1357/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1358/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [1359/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1359/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1245\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1360/2000], Avg Train Loss: 0.1245, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1361/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1173\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1362/2000], Avg Train Loss: 0.1173, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1363/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1364/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1365/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [1366/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1366/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1289\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1367/2000], Avg Train Loss: 0.1289, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1167\n",
      "LOG: Epoch [1368/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1368/2000], Avg Train Loss: 0.1167, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1318\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1369/2000], Avg Train Loss: 0.1318, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1295\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1370/2000], Avg Train Loss: 0.1295, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1371/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1372/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1373/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1374/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1375/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1376/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1377/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1378/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1379/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1380/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1321\n",
      "LOG: Epoch [1381/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1381/2000], Avg Train Loss: 0.1321, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1162\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1382/2000], Avg Train Loss: 0.1162, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [1383/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1383/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1384/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1385/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1386/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1387/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1388/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1388/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1175\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1389/2000], Avg Train Loss: 0.1175, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1390/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1390/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1391/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1392/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1392/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1393/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [1394/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1394/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1395/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1288\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1396/2000], Avg Train Loss: 0.1288, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1397/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1339\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1398/2000], Avg Train Loss: 0.1339, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1399/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1400/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1401/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1402/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1403/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1311\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1404/2000], Avg Train Loss: 0.1311, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1156\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1405/2000], Avg Train Loss: 0.1156, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1406/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1406/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1407/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1408/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1408/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1409/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1410/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1410/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1253\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1411/2000], Avg Train Loss: 0.1253, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1412/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1413/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1159\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1414/2000], Avg Train Loss: 0.1159, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1362\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1415/2000], Avg Train Loss: 0.1362, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1416/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1417/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1418/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1419/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1420/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1421/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1422/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1423/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1423/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1424/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1425/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1425/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1426/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1427/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1427/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1428/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1429/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1341\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1430/2000], Avg Train Loss: 0.1341, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1431/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1432/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1394\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1433/2000], Avg Train Loss: 0.1394, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1434/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1326\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1435/2000], Avg Train Loss: 0.1326, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1362\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1436/2000], Avg Train Loss: 0.1362, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1342\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1437/2000], Avg Train Loss: 0.1342, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1438/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1438/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1276\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1439/2000], Avg Train Loss: 0.1276, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1369\n",
      "LOG: Epoch [1440/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1440/2000], Avg Train Loss: 0.1369, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1441/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1442/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1443/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [1444/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1444/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1445/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1446/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1446/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1447/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1200\n",
      "LOG: Epoch [1448/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1448/2000], Avg Train Loss: 0.1200, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1288\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1449/2000], Avg Train Loss: 0.1288, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1450/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1451/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1172\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1452/2000], Avg Train Loss: 0.1172, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1453/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1453/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1454/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1298\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1455/2000], Avg Train Loss: 0.1298, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1456/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1457/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1335\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1458/2000], Avg Train Loss: 0.1335, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1208\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1459/2000], Avg Train Loss: 0.1208, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1460/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1460/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1461/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1278\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1462/2000], Avg Train Loss: 0.1278, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1163\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1463/2000], Avg Train Loss: 0.1163, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1464/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1301\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1465/2000], Avg Train Loss: 0.1301, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1219\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1466/2000], Avg Train Loss: 0.1219, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1467/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1467/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1156\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1468/2000], Avg Train Loss: 0.1156, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1329\n",
      "LOG: Epoch [1469/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1469/2000], Avg Train Loss: 0.1329, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1470/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1471/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1471/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1472/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1473/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1473/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1474/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1475/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1253\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1476/2000], Avg Train Loss: 0.1253, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1477/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1342\n",
      "LOG: Epoch [1478/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1478/2000], Avg Train Loss: 0.1342, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1479/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [1480/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1480/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1299\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1481/2000], Avg Train Loss: 0.1299, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1482/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1482/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1483/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [1484/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1484/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1193\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1485/2000], Avg Train Loss: 0.1193, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [1486/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1486/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1487/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1488/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1489/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1490/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [1491/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1491/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1492/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1325\n",
      "LOG: Epoch [1493/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1493/2000], Avg Train Loss: 0.1325, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1494/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1495/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1496/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1497/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1201\n",
      "LOG: Epoch [1498/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1498/2000], Avg Train Loss: 0.1201, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1499/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1500/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1500/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1501/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1502/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1503/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1504/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1298\n",
      "LOG: Epoch [1505/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1505/2000], Avg Train Loss: 0.1298, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1506/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1507/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1283\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1508/2000], Avg Train Loss: 0.1283, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1509/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1510/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1511/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1512/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1512/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1513/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1514/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1304\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1515/2000], Avg Train Loss: 0.1304, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1210\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1516/2000], Avg Train Loss: 0.1210, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1517/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1518/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [1519/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1519/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1520/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1521/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1521/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1522/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1523/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1523/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1524/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1525/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1525/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1526/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1527/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1528/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1529/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1529/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1530/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1531/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1531/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1322\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1532/2000], Avg Train Loss: 0.1322, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1533/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1534/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1535/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1536/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [1537/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1537/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1538/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1539/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1540/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1541/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1541/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1176\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1542/2000], Avg Train Loss: 0.1176, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1543/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1543/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1544/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1545/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1278\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1546/2000], Avg Train Loss: 0.1278, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1547/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1548/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1549/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1550/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1550/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1551/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [1552/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1552/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1553/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1191\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1554/2000], Avg Train Loss: 0.1191, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1555/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1249\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1556/2000], Avg Train Loss: 0.1249, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1557/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1558/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1559/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1560/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1561/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1562/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1563/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1564/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1565/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1304\n",
      "LOG: Epoch [1566/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1566/2000], Avg Train Loss: 0.1304, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1567/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1568/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1569/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1305\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1570/2000], Avg Train Loss: 0.1305, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1571/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1289\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1572/2000], Avg Train Loss: 0.1289, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1573/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1573/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1574/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1575/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1575/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1304\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1576/2000], Avg Train Loss: 0.1304, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1577/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1578/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1579/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1311\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1580/2000], Avg Train Loss: 0.1311, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1581/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1341\n",
      "LOG: Epoch [1582/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1582/2000], Avg Train Loss: 0.1341, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1583/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1357\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1584/2000], Avg Train Loss: 0.1357, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1585/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1586/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1586/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1587/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1588/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1589/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1590/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1591/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1591/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1592/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1593/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1594/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1595/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1334\n",
      "LOG: Epoch [1596/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1596/2000], Avg Train Loss: 0.1334, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1597/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1598/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1599/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1600/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1181\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1601/2000], Avg Train Loss: 0.1181, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1602/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1603/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1161\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1604/2000], Avg Train Loss: 0.1161, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1605/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1306\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1606/2000], Avg Train Loss: 0.1306, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1171\n",
      "LOG: Epoch [1607/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1607/2000], Avg Train Loss: 0.1171, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1608/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1609/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1610/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1611/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1611/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1612/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1613/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1614/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1351\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1615/2000], Avg Train Loss: 0.1351, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1616/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1617/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1618/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1619/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1297\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1620/2000], Avg Train Loss: 0.1297, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1298\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1621/2000], Avg Train Loss: 0.1298, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1622/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1623/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1624/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1624/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1625/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1626/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1627/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1628/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [1629/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1629/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1630/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1631/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1632/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1633/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1634/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1635/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1636/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1637/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1638/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1638/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1639/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1640/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1640/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1268\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1641/2000], Avg Train Loss: 0.1268, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1642/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1642/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1305\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1643/2000], Avg Train Loss: 0.1305, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1644/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1645/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1646/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1647/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1647/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1648/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1649/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1649/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1650/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1651/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1652/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1653/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1278\n",
      "LOG: Epoch [1654/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1654/2000], Avg Train Loss: 0.1278, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1288\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1655/2000], Avg Train Loss: 0.1288, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1656/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1656/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1657/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1658/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1659/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1660/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1661/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1662/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1663/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1664/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1665/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1666/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1302\n",
      "LOG: Epoch [1667/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1667/2000], Avg Train Loss: 0.1302, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1668/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1669/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1670/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1671/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1672/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1307\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1673/2000], Avg Train Loss: 0.1307, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1674/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1197\n",
      "LOG: Epoch [1675/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1675/2000], Avg Train Loss: 0.1197, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1208\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1676/2000], Avg Train Loss: 0.1208, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1677/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1302\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1678/2000], Avg Train Loss: 0.1302, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1679/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1680/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1680/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1681/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1682/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1683/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1684/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1685/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1686/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1687/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1331\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1688/2000], Avg Train Loss: 0.1331, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1689/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1690/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1691/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1691/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1692/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1693/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1693/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1305\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1694/2000], Avg Train Loss: 0.1305, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1197\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1695/2000], Avg Train Loss: 0.1197, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1696/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1338\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1697/2000], Avg Train Loss: 0.1338, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1698/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1699/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1700/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1700/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1701/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1702/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1703/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1333\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1704/2000], Avg Train Loss: 0.1333, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1705/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1706/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1707/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1708/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1708/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1709/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1289\n",
      "LOG: Epoch [1710/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1710/2000], Avg Train Loss: 0.1289, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1711/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1712/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1712/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1291\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1713/2000], Avg Train Loss: 0.1291, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1296\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1714/2000], Avg Train Loss: 0.1296, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1715/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1299\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1716/2000], Avg Train Loss: 0.1299, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1319\n",
      "LOG: Epoch [1717/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1717/2000], Avg Train Loss: 0.1319, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1328\n",
      "LOG: Epoch [1718/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1718/2000], Avg Train Loss: 0.1328, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1719/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1719/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [1720/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1720/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [1721/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1721/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1722/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1722/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1305\n",
      "LOG: Epoch [1723/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1723/2000], Avg Train Loss: 0.1305, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1269\n",
      "LOG: Epoch [1724/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1724/2000], Avg Train Loss: 0.1269, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1725/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1725/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1726/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1726/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1727/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1727/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1728/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1728/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1729/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1729/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1730/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1730/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1731/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1731/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [1732/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1732/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1374\n",
      "LOG: Epoch [1733/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1733/2000], Avg Train Loss: 0.1374, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1734/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1734/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1193\n",
      "LOG: Epoch [1735/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1735/2000], Avg Train Loss: 0.1193, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [1736/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1736/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1737/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1737/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1738/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1738/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1739/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1739/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1740/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1740/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [1741/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1741/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1346\n",
      "LOG: Epoch [1742/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1742/2000], Avg Train Loss: 0.1346, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [1743/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1743/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [1744/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1744/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1745/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1745/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1746/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1746/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1747/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1747/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1748/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1748/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [1749/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1749/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [1750/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1750/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1751/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1751/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1752/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1752/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1333\n",
      "LOG: Epoch [1753/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1753/2000], Avg Train Loss: 0.1333, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1754/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1754/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1210\n",
      "LOG: Epoch [1755/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1755/2000], Avg Train Loss: 0.1210, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1245\n",
      "LOG: Epoch [1756/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1756/2000], Avg Train Loss: 0.1245, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [1757/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1757/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1758/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1758/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1759/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1759/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [1760/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1760/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1761/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1761/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1762/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1762/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1215\n",
      "LOG: Epoch [1763/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1763/2000], Avg Train Loss: 0.1215, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1764/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1764/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [1765/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1765/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [1766/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1766/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1767/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1767/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1768/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1768/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1314\n",
      "LOG: Epoch [1769/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1769/2000], Avg Train Loss: 0.1314, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1770/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1770/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1771/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1771/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1330\n",
      "LOG: Epoch [1772/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1772/2000], Avg Train Loss: 0.1330, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [1773/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1773/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1774/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1774/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1306\n",
      "LOG: Epoch [1775/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1775/2000], Avg Train Loss: 0.1306, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1269\n",
      "LOG: Epoch [1776/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1776/2000], Avg Train Loss: 0.1269, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1777/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1777/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1778/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1778/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1288\n",
      "LOG: Epoch [1779/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1779/2000], Avg Train Loss: 0.1288, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1780/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1780/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1781/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1781/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1782/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1782/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1783/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1783/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1324\n",
      "LOG: Epoch [1784/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1784/2000], Avg Train Loss: 0.1324, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1785/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1785/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1786/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1786/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1787/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1787/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1788/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1788/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1321\n",
      "LOG: Epoch [1789/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1789/2000], Avg Train Loss: 0.1321, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1790/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1790/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [1791/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1791/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1309\n",
      "LOG: Epoch [1792/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1792/2000], Avg Train Loss: 0.1309, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1313\n",
      "LOG: Epoch [1793/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1793/2000], Avg Train Loss: 0.1313, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1794/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1794/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1795/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1795/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1326\n",
      "LOG: Epoch [1796/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1796/2000], Avg Train Loss: 0.1326, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1287\n",
      "LOG: Epoch [1797/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1797/2000], Avg Train Loss: 0.1287, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1798/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1798/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1304\n",
      "LOG: Epoch [1799/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1799/2000], Avg Train Loss: 0.1304, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1341\n",
      "LOG: Epoch [1800/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1800/2000], Avg Train Loss: 0.1341, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [1801/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1801/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1802/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1802/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [1803/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1803/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1804/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1804/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [1805/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1805/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1806/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1806/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [1807/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1807/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1808/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1808/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1809/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1809/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1810/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1810/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1295\n",
      "LOG: Epoch [1811/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1811/2000], Avg Train Loss: 0.1295, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1812/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1812/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1813/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1813/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1814/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1814/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [1815/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1815/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1816/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1816/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [1817/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1817/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [1818/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1818/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1819/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1819/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1820/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1820/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1821/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1821/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [1822/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1822/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1823/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1823/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1824/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1824/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1825/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1825/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1272\n",
      "LOG: Epoch [1826/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1826/2000], Avg Train Loss: 0.1272, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1827/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1827/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1828/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1828/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1829/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1829/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1830/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1830/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1322\n",
      "LOG: Epoch [1831/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1831/2000], Avg Train Loss: 0.1322, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1832/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1832/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [1833/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1833/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1834/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1834/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1835/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1835/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1836/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1836/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1837/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1837/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1838/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1838/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [1839/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1839/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [1840/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1840/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [1841/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1841/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1192\n",
      "LOG: Epoch [1842/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1842/2000], Avg Train Loss: 0.1192, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [1843/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1843/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1844/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1844/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1845/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1845/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1846/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1846/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1847/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1847/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1848/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1848/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [1849/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1849/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1850/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1850/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1310\n",
      "LOG: Epoch [1851/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1851/2000], Avg Train Loss: 0.1310, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1193\n",
      "LOG: Epoch [1852/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1852/2000], Avg Train Loss: 0.1193, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1853/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1853/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1854/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1854/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1855/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1855/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1856/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1856/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1857/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1857/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [1858/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1858/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [1859/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1859/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1860/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1860/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [1861/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1861/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1317\n",
      "LOG: Epoch [1862/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1862/2000], Avg Train Loss: 0.1317, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1863/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1863/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [1864/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1864/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1865/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1865/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [1866/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1866/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1867/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1867/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1264\n",
      "LOG: Epoch [1868/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1868/2000], Avg Train Loss: 0.1264, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1869/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1869/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1870/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1870/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1332\n",
      "LOG: Epoch [1871/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1871/2000], Avg Train Loss: 0.1332, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [1872/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1872/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1873/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1873/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [1874/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1874/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1188\n",
      "LOG: Epoch [1875/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1875/2000], Avg Train Loss: 0.1188, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [1876/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1876/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [1877/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1877/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1301\n",
      "LOG: Epoch [1878/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1878/2000], Avg Train Loss: 0.1301, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1879/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1879/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1880/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1880/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1181\n",
      "LOG: Epoch [1881/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1881/2000], Avg Train Loss: 0.1181, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1882/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1882/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1292\n",
      "LOG: Epoch [1883/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1883/2000], Avg Train Loss: 0.1292, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1884/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1884/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [1885/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1885/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [1886/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1886/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1288\n",
      "LOG: Epoch [1887/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1887/2000], Avg Train Loss: 0.1288, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1888/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1888/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1889/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1889/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1271\n",
      "LOG: Epoch [1890/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1890/2000], Avg Train Loss: 0.1271, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1891/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1891/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [1892/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1892/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1269\n",
      "LOG: Epoch [1893/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1893/2000], Avg Train Loss: 0.1269, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1894/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1894/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1895/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1895/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1896/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1896/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1312\n",
      "LOG: Epoch [1897/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1897/2000], Avg Train Loss: 0.1312, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1313\n",
      "LOG: Epoch [1898/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1898/2000], Avg Train Loss: 0.1313, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1899/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1899/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [1900/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1900/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1901/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1901/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1902/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1902/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1188\n",
      "LOG: Epoch [1903/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1903/2000], Avg Train Loss: 0.1188, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [1904/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1904/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1303\n",
      "LOG: Epoch [1905/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1905/2000], Avg Train Loss: 0.1303, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1906/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1906/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1907/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1907/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [1908/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1908/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [1909/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1909/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1910/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1910/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1911/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1911/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1912/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1912/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1208\n",
      "LOG: Epoch [1913/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1913/2000], Avg Train Loss: 0.1208, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1201\n",
      "LOG: Epoch [1914/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1914/2000], Avg Train Loss: 0.1201, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1915/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1915/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1916/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1916/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1257\n",
      "LOG: Epoch [1917/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1917/2000], Avg Train Loss: 0.1257, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [1918/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1918/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1919/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1919/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1920/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1920/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1291\n",
      "LOG: Epoch [1921/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1921/2000], Avg Train Loss: 0.1291, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [1922/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1922/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [1923/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1923/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1924/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1924/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [1925/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1925/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [1926/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1926/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1219\n",
      "LOG: Epoch [1927/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1927/2000], Avg Train Loss: 0.1219, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1928/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1928/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [1929/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1929/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1296\n",
      "LOG: Epoch [1930/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1930/2000], Avg Train Loss: 0.1296, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1273\n",
      "LOG: Epoch [1931/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1931/2000], Avg Train Loss: 0.1273, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1932/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1932/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [1933/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1933/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [1934/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1934/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1319\n",
      "LOG: Epoch [1935/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1935/2000], Avg Train Loss: 0.1319, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1936/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1936/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1937/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1937/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [1938/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1938/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1939/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1939/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1258\n",
      "LOG: Epoch [1940/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1940/2000], Avg Train Loss: 0.1258, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [1941/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1941/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [1942/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1942/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [1943/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1943/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [1944/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1944/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [1945/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1945/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1147\n",
      "LOG: Epoch [1946/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1946/2000], Avg Train Loss: 0.1147, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1201\n",
      "LOG: Epoch [1947/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1947/2000], Avg Train Loss: 0.1201, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [1948/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1948/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1240\n",
      "LOG: Epoch [1949/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1949/2000], Avg Train Loss: 0.1240, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1950/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1950/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [1951/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1951/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [1952/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1952/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1176\n",
      "LOG: Epoch [1953/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1953/2000], Avg Train Loss: 0.1176, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1199\n",
      "LOG: Epoch [1954/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1954/2000], Avg Train Loss: 0.1199, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [1955/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1955/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [1956/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1956/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1957/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1957/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1958/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1958/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [1959/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1959/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1238\n",
      "LOG: Epoch [1960/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1960/2000], Avg Train Loss: 0.1238, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1198\n",
      "LOG: Epoch [1961/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1961/2000], Avg Train Loss: 0.1198, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [1962/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1962/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [1963/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1963/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1248\n",
      "LOG: Epoch [1964/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1964/2000], Avg Train Loss: 0.1248, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [1965/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1965/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1251\n",
      "LOG: Epoch [1966/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1966/2000], Avg Train Loss: 0.1251, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [1967/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1967/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1306\n",
      "LOG: Epoch [1968/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1968/2000], Avg Train Loss: 0.1306, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [1969/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1969/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1184\n",
      "LOG: Epoch [1970/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1970/2000], Avg Train Loss: 0.1184, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [1971/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1971/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1171\n",
      "LOG: Epoch [1972/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1972/2000], Avg Train Loss: 0.1171, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1356\n",
      "LOG: Epoch [1973/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1973/2000], Avg Train Loss: 0.1356, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1974/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1974/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1331\n",
      "LOG: Epoch [1975/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1975/2000], Avg Train Loss: 0.1331, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [1976/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1976/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [1977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1253\n",
      "LOG: Epoch [1977/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1977/2000], Avg Train Loss: 0.1253, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [1978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1978/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1978/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [1979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1359\n",
      "LOG: Epoch [1979/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1979/2000], Avg Train Loss: 0.1359, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [1980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [1980/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1980/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [1981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1266\n",
      "LOG: Epoch [1981/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1981/2000], Avg Train Loss: 0.1266, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [1982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1259\n",
      "LOG: Epoch [1982/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1982/2000], Avg Train Loss: 0.1259, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [1983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [1983/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1983/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [1984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [1984/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1984/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1155\n",
      "LOG: Epoch [1985/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1985/2000], Avg Train Loss: 0.1155, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [1986/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1986/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1987/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1987/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1267\n",
      "LOG: Epoch [1988/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1988/2000], Avg Train Loss: 0.1267, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [1989/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1989/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [1990/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1990/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [1991/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1991/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1992/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1992/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1338\n",
      "LOG: Epoch [1993/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1993/2000], Avg Train Loss: 0.1338, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [1994/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1994/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [1995/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1995/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1279\n",
      "LOG: Epoch [1996/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1996/2000], Avg Train Loss: 0.1279, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1158\n",
      "LOG: Epoch [1997/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1997/2000], Avg Train Loss: 0.1158, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [1998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1232\n",
      "LOG: Epoch [1998/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1998/2000], Avg Train Loss: 0.1232, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [1999/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [1999/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n",
      "LOG: Epoch [2000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [2000/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2149\n",
      "Epoch [2000/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2149. Saving model...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:23:24.784624Z",
     "iopub.status.busy": "2025-05-08T17:23:24.783625Z",
     "iopub.status.idle": "2025-05-08T17:23:34.839701Z",
     "shell.execute_reply": "2025-05-08T17:23:34.839701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/2312], Loss: 0.1063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [20/2312], Loss: 0.1215\n",
      "Test Batch [30/2312], Loss: 0.5000\n",
      "Test Batch [40/2312], Loss: 0.0467\n",
      "Test Batch [50/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [60/2312], Loss: 0.5000\n",
      "Test Batch [70/2312], Loss: 0.5000\n",
      "Test Batch [80/2312], Loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [90/2312], Loss: 0.5000\n",
      "Test Batch [100/2312], Loss: 0.0442\n",
      "Test Batch [110/2312], Loss: 0.5000\n",
      "Test Batch [120/2312], Loss: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [130/2312], Loss: 0.5000\n",
      "Test Batch [140/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [150/2312], Loss: 0.5000\n",
      "Test Batch [160/2312], Loss: 0.0697\n",
      "Test Batch [170/2312], Loss: 0.5000\n",
      "Test Batch [180/2312], Loss: 0.5000\n",
      "Test Batch [190/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [200/2312], Loss: 0.0890\n",
      "Test Batch [210/2312], Loss: 0.5000\n",
      "Test Batch [220/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [230/2312], Loss: 0.0670\n",
      "Test Batch [240/2312], Loss: 0.0292\n",
      "Test Batch [250/2312], Loss: 0.1248\n",
      "Test Batch [260/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [270/2312], Loss: 0.5000\n",
      "Test Batch [280/2312], Loss: 0.5000\n",
      "Test Batch [290/2312], Loss: 0.0763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [300/2312], Loss: 0.0656\n",
      "Test Batch [310/2312], Loss: 0.5000\n",
      "Test Batch [320/2312], Loss: 0.0622\n",
      "Test Batch [330/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [340/2312], Loss: 0.5000\n",
      "Test Batch [350/2312], Loss: 0.0960\n",
      "Test Batch [360/2312], Loss: 0.1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [370/2312], Loss: 0.1106\n",
      "Test Batch [380/2312], Loss: 0.0660\n",
      "Test Batch [390/2312], Loss: 0.0319\n",
      "Test Batch [400/2312], Loss: 0.5000\n",
      "Test Batch [410/2312], Loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [420/2312], Loss: 0.0518\n",
      "Test Batch [430/2312], Loss: 0.1157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [440/2312], Loss: 0.5000\n",
      "Test Batch [450/2312], Loss: 0.0595\n",
      "Test Batch [460/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [470/2312], Loss: 0.0783\n",
      "Test Batch [480/2312], Loss: 0.5000\n",
      "Test Batch [490/2312], Loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [500/2312], Loss: 0.0332\n",
      "Test Batch [510/2312], Loss: 0.0372\n",
      "Test Batch [520/2312], Loss: 0.0670\n",
      "Test Batch [530/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [540/2312], Loss: 0.5000\n",
      "Test Batch [550/2312], Loss: 0.0747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [560/2312], Loss: 0.5000\n",
      "Test Batch [570/2312], Loss: 0.5000\n",
      "Test Batch [580/2312], Loss: 0.0424\n",
      "Test Batch [590/2312], Loss: 0.0510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [600/2312], Loss: 0.5000\n",
      "Test Batch [610/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [620/2312], Loss: 0.0749\n",
      "Test Batch [630/2312], Loss: 0.0163\n",
      "Test Batch [640/2312], Loss: 0.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [650/2312], Loss: 0.5000\n",
      "Test Batch [660/2312], Loss: 0.0785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [670/2312], Loss: 0.0612\n",
      "Test Batch [680/2312], Loss: 0.5000\n",
      "Test Batch [690/2312], Loss: 0.0522\n",
      "Test Batch [700/2312], Loss: 0.0938\n",
      "Test Batch [710/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [720/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [730/2312], Loss: 0.0273\n",
      "Test Batch [740/2312], Loss: 0.5000\n",
      "Test Batch [750/2312], Loss: 0.1090\n",
      "Test Batch [760/2312], Loss: 0.0637\n",
      "Test Batch [770/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [780/2312], Loss: 0.5000\n",
      "Test Batch [790/2312], Loss: 0.0319\n",
      "Test Batch [800/2312], Loss: 0.0835\n",
      "Test Batch [810/2312], Loss: 0.5000\n",
      "Test Batch [820/2312], Loss: 0.0974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [830/2312], Loss: 0.5000\n",
      "Test Batch [840/2312], Loss: 0.0408\n",
      "Test Batch [850/2312], Loss: 0.2200\n",
      "Test Batch [860/2312], Loss: 0.0222\n",
      "Test Batch [870/2312], Loss: 0.1227\n",
      "Test Batch [880/2312], Loss: 0.0309\n",
      "Test Batch [890/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [900/2312], Loss: 0.5000\n",
      "Test Batch [910/2312], Loss: 0.5000\n",
      "Test Batch [920/2312], Loss: 0.0245\n",
      "Test Batch [930/2312], Loss: 0.0952\n",
      "Test Batch [940/2312], Loss: 0.0727\n",
      "Test Batch [950/2312], Loss: 0.5000\n",
      "Test Batch [960/2312], Loss: 0.5000\n",
      "Test Batch [970/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [980/2312], Loss: 0.0361\n",
      "Test Batch [990/2312], Loss: 0.0536\n",
      "Test Batch [1000/2312], Loss: 0.0403\n",
      "Test Batch [1010/2312], Loss: 0.0380\n",
      "Test Batch [1020/2312], Loss: 0.1268\n",
      "Test Batch [1030/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1040/2312], Loss: 0.0674\n",
      "Test Batch [1050/2312], Loss: 0.0719\n",
      "Test Batch [1060/2312], Loss: 0.0419\n",
      "Test Batch [1070/2312], Loss: 0.0455\n",
      "Test Batch [1080/2312], Loss: 0.0293\n",
      "Test Batch [1090/2312], Loss: 0.0843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1100/2312], Loss: 0.1486\n",
      "Test Batch [1110/2312], Loss: 0.1231\n",
      "Test Batch [1120/2312], Loss: 0.0353\n",
      "Test Batch [1130/2312], Loss: 0.0632\n",
      "Test Batch [1140/2312], Loss: 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1150/2312], Loss: 0.0213\n",
      "Test Batch [1160/2312], Loss: 0.0504\n",
      "Test Batch [1170/2312], Loss: 0.0605\n",
      "Test Batch [1180/2312], Loss: 0.1274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1190/2312], Loss: 0.0533\n",
      "Test Batch [1200/2312], Loss: 0.1093\n",
      "Test Batch [1210/2312], Loss: 0.0785\n",
      "Test Batch [1220/2312], Loss: 0.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1230/2312], Loss: 0.1163\n",
      "Test Batch [1240/2312], Loss: 0.5000\n",
      "Test Batch [1250/2312], Loss: 0.5000\n",
      "Test Batch [1260/2312], Loss: 0.0324\n",
      "Test Batch [1270/2312], Loss: 0.0534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1280/2312], Loss: 0.1668\n",
      "Test Batch [1290/2312], Loss: 0.5000\n",
      "Test Batch [1300/2312], Loss: 0.1106\n",
      "Test Batch [1310/2312], Loss: 0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1320/2312], Loss: 0.1138\n",
      "Test Batch [1330/2312], Loss: 0.0572\n",
      "Test Batch [1340/2312], Loss: 0.0305\n",
      "Test Batch [1350/2312], Loss: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1360/2312], Loss: 0.1938\n",
      "Test Batch [1370/2312], Loss: 0.1374\n",
      "Test Batch [1380/2312], Loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1390/2312], Loss: 0.0716\n",
      "Test Batch [1400/2312], Loss: 0.0837\n",
      "Test Batch [1410/2312], Loss: 0.0836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1420/2312], Loss: 0.0719\n",
      "Test Batch [1430/2312], Loss: 0.5000\n",
      "Test Batch [1440/2312], Loss: 0.0995\n",
      "Test Batch [1450/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1460/2312], Loss: 0.0829\n",
      "Test Batch [1470/2312], Loss: 0.0781\n",
      "Test Batch [1480/2312], Loss: 0.1069\n",
      "Test Batch [1490/2312], Loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1500/2312], Loss: 0.0526\n",
      "Test Batch [1510/2312], Loss: 0.0688\n",
      "Test Batch [1520/2312], Loss: 0.5000\n",
      "Test Batch [1530/2312], Loss: 0.0656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1540/2312], Loss: 0.1113\n",
      "Test Batch [1550/2312], Loss: 0.0828\n",
      "Test Batch [1560/2312], Loss: 0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1570/2312], Loss: 0.0734\n",
      "Test Batch [1580/2312], Loss: 0.0792\n",
      "Test Batch [1590/2312], Loss: 0.1333\n",
      "Test Batch [1600/2312], Loss: 0.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1610/2312], Loss: 0.0726\n",
      "Test Batch [1620/2312], Loss: 0.1512\n",
      "Test Batch [1630/2312], Loss: 0.1129\n",
      "Test Batch [1640/2312], Loss: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1650/2312], Loss: 0.0360\n",
      "Test Batch [1660/2312], Loss: 0.0873\n",
      "Test Batch [1670/2312], Loss: 0.1539\n",
      "Test Batch [1680/2312], Loss: 0.1299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1690/2312], Loss: 0.1864\n",
      "Test Batch [1700/2312], Loss: 0.1498\n",
      "Test Batch [1710/2312], Loss: 0.0953\n",
      "Test Batch [1720/2312], Loss: 0.0379\n",
      "Test Batch [1730/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1740/2312], Loss: 0.5000\n",
      "Test Batch [1750/2312], Loss: 0.0533\n",
      "Test Batch [1760/2312], Loss: 0.0720\n",
      "Test Batch [1770/2312], Loss: 0.0448\n",
      "Test Batch [1780/2312], Loss: 0.0609\n",
      "Test Batch [1790/2312], Loss: 0.0871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1800/2312], Loss: 0.0633\n",
      "Test Batch [1810/2312], Loss: 0.0725\n",
      "Test Batch [1820/2312], Loss: 0.0934\n",
      "Test Batch [1830/2312], Loss: 0.0353\n",
      "Test Batch [1840/2312], Loss: 0.0834\n",
      "Test Batch [1850/2312], Loss: 0.0795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1860/2312], Loss: 0.0874\n",
      "Test Batch [1870/2312], Loss: 0.1381\n",
      "Test Batch [1880/2312], Loss: 0.0797\n",
      "Test Batch [1890/2312], Loss: 0.5000\n",
      "Test Batch [1900/2312], Loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1910/2312], Loss: 0.1011\n",
      "Test Batch [1920/2312], Loss: 0.1678\n",
      "Test Batch [1930/2312], Loss: 0.1230\n",
      "Test Batch [1940/2312], Loss: 0.1058\n",
      "Test Batch [1950/2312], Loss: 0.0582\n",
      "Test Batch [1960/2312], Loss: 0.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1970/2312], Loss: 0.0951\n",
      "Test Batch [1980/2312], Loss: 0.0617\n",
      "Test Batch [1990/2312], Loss: 0.0456\n",
      "Test Batch [2000/2312], Loss: 0.0627\n",
      "Test Batch [2010/2312], Loss: 0.0446\n",
      "Test Batch [2020/2312], Loss: 0.0551\n",
      "Test Batch [2030/2312], Loss: 0.0414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2040/2312], Loss: 0.1078\n",
      "Test Batch [2050/2312], Loss: 0.1260\n",
      "Test Batch [2060/2312], Loss: 0.1721\n",
      "Test Batch [2070/2312], Loss: 0.1141\n",
      "Test Batch [2080/2312], Loss: 0.5000\n",
      "Test Batch [2090/2312], Loss: 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2100/2312], Loss: 0.1697\n",
      "Test Batch [2110/2312], Loss: 0.1179\n",
      "Test Batch [2120/2312], Loss: 0.1482\n",
      "Test Batch [2130/2312], Loss: 0.0359\n",
      "Test Batch [2140/2312], Loss: 0.0728\n",
      "Test Batch [2150/2312], Loss: 0.2049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2160/2312], Loss: 0.5000\n",
      "Test Batch [2170/2312], Loss: 0.5000\n",
      "Test Batch [2180/2312], Loss: 0.0543\n",
      "Test Batch [2190/2312], Loss: 0.5000\n",
      "Test Batch [2200/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2210/2312], Loss: 0.5000\n",
      "Test Batch [2220/2312], Loss: 0.0962\n",
      "Test Batch [2230/2312], Loss: 0.0274\n",
      "Test Batch [2240/2312], Loss: 0.1000\n",
      "Test Batch [2250/2312], Loss: 0.0317\n",
      "Test Batch [2260/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2270/2312], Loss: 0.1020\n",
      "Test Batch [2280/2312], Loss: 0.5000\n",
      "Test Batch [2290/2312], Loss: 0.0356\n",
      "Test Batch [2300/2312], Loss: 0.5000\n",
      "Test Batch [2310/2312], Loss: 0.5000\n",
      "\n",
      "Test Loss: 0.2018\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:23:34.841710Z",
     "iopub.status.busy": "2025-05-08T17:23:34.841710Z",
     "iopub.status.idle": "2025-05-08T17:23:51.398578Z",
     "shell.execute_reply": "2025-05-08T17:23:51.398578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/2312 for test dataset.\n",
      "  Processed batch 20/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/2312 for test dataset.\n",
      "  Processed batch 40/2312 for test dataset.\n",
      "  Processed batch 50/2312 for test dataset.\n",
      "  Processed batch 60/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 70/2312 for test dataset.\n",
      "  Processed batch 80/2312 for test dataset.\n",
      "  Processed batch 90/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 100/2312 for test dataset.\n",
      "  Processed batch 110/2312 for test dataset.\n",
      "  Processed batch 120/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 130/2312 for test dataset.\n",
      "  Processed batch 140/2312 for test dataset.\n",
      "  Processed batch 150/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 160/2312 for test dataset.\n",
      "  Processed batch 170/2312 for test dataset.\n",
      "  Processed batch 180/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 190/2312 for test dataset.\n",
      "  Processed batch 200/2312 for test dataset.\n",
      "  Processed batch 210/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 220/2312 for test dataset.\n",
      "  Processed batch 230/2312 for test dataset.\n",
      "  Processed batch 240/2312 for test dataset.\n",
      "  Processed batch 250/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 260/2312 for test dataset.\n",
      "  Processed batch 270/2312 for test dataset.\n",
      "  Processed batch 280/2312 for test dataset.\n",
      "  Processed batch 290/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 300/2312 for test dataset.\n",
      "  Processed batch 310/2312 for test dataset.\n",
      "  Processed batch 320/2312 for test dataset.\n",
      "  Processed batch 330/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 340/2312 for test dataset.\n",
      "  Processed batch 350/2312 for test dataset.\n",
      "  Processed batch 360/2312 for test dataset.\n",
      "  Processed batch 370/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 380/2312 for test dataset.\n",
      "  Processed batch 390/2312 for test dataset.\n",
      "  Processed batch 400/2312 for test dataset.\n",
      "  Processed batch 410/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 420/2312 for test dataset.\n",
      "  Processed batch 430/2312 for test dataset.\n",
      "  Processed batch 440/2312 for test dataset.\n",
      "  Processed batch 450/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 460/2312 for test dataset.\n",
      "  Processed batch 470/2312 for test dataset.\n",
      "  Processed batch 480/2312 for test dataset.\n",
      "  Processed batch 490/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 500/2312 for test dataset.\n",
      "  Processed batch 510/2312 for test dataset.\n",
      "  Processed batch 520/2312 for test dataset.\n",
      "  Processed batch 530/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 540/2312 for test dataset.\n",
      "  Processed batch 550/2312 for test dataset.\n",
      "  Processed batch 560/2312 for test dataset.\n",
      "  Processed batch 570/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 580/2312 for test dataset.\n",
      "  Processed batch 590/2312 for test dataset.\n",
      "  Processed batch 600/2312 for test dataset.\n",
      "  Processed batch 610/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 620/2312 for test dataset.\n",
      "  Processed batch 630/2312 for test dataset.\n",
      "  Processed batch 640/2312 for test dataset.\n",
      "  Processed batch 650/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 660/2312 for test dataset.\n",
      "  Processed batch 670/2312 for test dataset.\n",
      "  Processed batch 680/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 690/2312 for test dataset.\n",
      "  Processed batch 700/2312 for test dataset.\n",
      "  Processed batch 710/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 720/2312 for test dataset.\n",
      "  Processed batch 730/2312 for test dataset.\n",
      "  Processed batch 740/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 750/2312 for test dataset.\n",
      "  Processed batch 760/2312 for test dataset.\n",
      "  Processed batch 770/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 780/2312 for test dataset.\n",
      "  Processed batch 790/2312 for test dataset.\n",
      "  Processed batch 800/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 810/2312 for test dataset.\n",
      "  Processed batch 820/2312 for test dataset.\n",
      "  Processed batch 830/2312 for test dataset.\n",
      "  Processed batch 840/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 850/2312 for test dataset.\n",
      "  Processed batch 860/2312 for test dataset.\n",
      "  Processed batch 870/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 880/2312 for test dataset.\n",
      "  Processed batch 890/2312 for test dataset.\n",
      "  Processed batch 900/2312 for test dataset.\n",
      "  Processed batch 910/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 920/2312 for test dataset.\n",
      "  Processed batch 930/2312 for test dataset.\n",
      "  Processed batch 940/2312 for test dataset.\n",
      "  Processed batch 950/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 960/2312 for test dataset.\n",
      "  Processed batch 970/2312 for test dataset.\n",
      "  Processed batch 980/2312 for test dataset.\n",
      "  Processed batch 990/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1000/2312 for test dataset.\n",
      "  Processed batch 1010/2312 for test dataset.\n",
      "  Processed batch 1020/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1030/2312 for test dataset.\n",
      "  Processed batch 1040/2312 for test dataset.\n",
      "  Processed batch 1050/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1060/2312 for test dataset.\n",
      "  Processed batch 1070/2312 for test dataset.\n",
      "  Processed batch 1080/2312 for test dataset.\n",
      "  Processed batch 1090/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1100/2312 for test dataset.\n",
      "  Processed batch 1110/2312 for test dataset.\n",
      "  Processed batch 1120/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1130/2312 for test dataset.\n",
      "  Processed batch 1140/2312 for test dataset.\n",
      "  Processed batch 1150/2312 for test dataset.\n",
      "  Processed batch 1160/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1170/2312 for test dataset.\n",
      "  Processed batch 1180/2312 for test dataset.\n",
      "  Processed batch 1190/2312 for test dataset.\n",
      "  Processed batch 1200/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1210/2312 for test dataset.\n",
      "  Processed batch 1220/2312 for test dataset.\n",
      "  Processed batch 1230/2312 for test dataset.\n",
      "  Processed batch 1240/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1250/2312 for test dataset.\n",
      "  Processed batch 1260/2312 for test dataset.\n",
      "  Processed batch 1270/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1280/2312 for test dataset.\n",
      "  Processed batch 1290/2312 for test dataset.\n",
      "  Processed batch 1300/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1310/2312 for test dataset.\n",
      "  Processed batch 1320/2312 for test dataset.\n",
      "  Processed batch 1330/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1340/2312 for test dataset.\n",
      "  Processed batch 1350/2312 for test dataset.\n",
      "  Processed batch 1360/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1370/2312 for test dataset.\n",
      "  Processed batch 1380/2312 for test dataset.\n",
      "  Processed batch 1390/2312 for test dataset.\n",
      "  Processed batch 1400/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1410/2312 for test dataset.\n",
      "  Processed batch 1420/2312 for test dataset.\n",
      "  Processed batch 1430/2312 for test dataset.\n",
      "  Processed batch 1440/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1450/2312 for test dataset.\n",
      "  Processed batch 1460/2312 for test dataset.\n",
      "  Processed batch 1470/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1480/2312 for test dataset.\n",
      "  Processed batch 1490/2312 for test dataset.\n",
      "  Processed batch 1500/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1510/2312 for test dataset.\n",
      "  Processed batch 1520/2312 for test dataset.\n",
      "  Processed batch 1530/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1540/2312 for test dataset.\n",
      "  Processed batch 1550/2312 for test dataset.\n",
      "  Processed batch 1560/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1570/2312 for test dataset.\n",
      "  Processed batch 1580/2312 for test dataset.\n",
      "  Processed batch 1590/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1600/2312 for test dataset.\n",
      "  Processed batch 1610/2312 for test dataset.\n",
      "  Processed batch 1620/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1630/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1640/2312 for test dataset.\n",
      "  Processed batch 1650/2312 for test dataset.\n",
      "  Processed batch 1660/2312 for test dataset.\n",
      "  Processed batch 1670/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1680/2312 for test dataset.\n",
      "  Processed batch 1690/2312 for test dataset.\n",
      "  Processed batch 1700/2312 for test dataset.\n",
      "  Processed batch 1710/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1720/2312 for test dataset.\n",
      "  Processed batch 1730/2312 for test dataset.\n",
      "  Processed batch 1740/2312 for test dataset.\n",
      "  Processed batch 1750/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1760/2312 for test dataset.\n",
      "  Processed batch 1770/2312 for test dataset.\n",
      "  Processed batch 1780/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1790/2312 for test dataset.\n",
      "  Processed batch 1800/2312 for test dataset.\n",
      "  Processed batch 1810/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1820/2312 for test dataset.\n",
      "  Processed batch 1830/2312 for test dataset.\n",
      "  Processed batch 1840/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1850/2312 for test dataset.\n",
      "  Processed batch 1860/2312 for test dataset.\n",
      "  Processed batch 1870/2312 for test dataset.\n",
      "  Processed batch 1880/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1890/2312 for test dataset.\n",
      "  Processed batch 1900/2312 for test dataset.\n",
      "  Processed batch 1910/2312 for test dataset.\n",
      "  Processed batch 1920/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1930/2312 for test dataset.\n",
      "  Processed batch 1940/2312 for test dataset.\n",
      "  Processed batch 1950/2312 for test dataset.\n",
      "  Processed batch 1960/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1970/2312 for test dataset.\n",
      "  Processed batch 1980/2312 for test dataset.\n",
      "  Processed batch 1990/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2000/2312 for test dataset.\n",
      "  Processed batch 2010/2312 for test dataset.\n",
      "  Processed batch 2020/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2030/2312 for test dataset.\n",
      "  Processed batch 2040/2312 for test dataset.\n",
      "  Processed batch 2050/2312 for test dataset.\n",
      "  Processed batch 2060/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2070/2312 for test dataset.\n",
      "  Processed batch 2080/2312 for test dataset.\n",
      "  Processed batch 2090/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2100/2312 for test dataset.\n",
      "  Processed batch 2110/2312 for test dataset.\n",
      "  Processed batch 2120/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2130/2312 for test dataset.\n",
      "  Processed batch 2140/2312 for test dataset.\n",
      "  Processed batch 2150/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2160/2312 for test dataset.\n",
      "  Processed batch 2170/2312 for test dataset.\n",
      "  Processed batch 2180/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2190/2312 for test dataset.\n",
      "  Processed batch 2200/2312 for test dataset.\n",
      "  Processed batch 2210/2312 for test dataset.\n",
      "  Processed batch 2220/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2230/2312 for test dataset.\n",
      "  Processed batch 2240/2312 for test dataset.\n",
      "  Processed batch 2250/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2260/2312 for test dataset.\n",
      "  Processed batch 2270/2312 for test dataset.\n",
      "  Processed batch 2280/2312 for test dataset.\n",
      "  Processed batch 2290/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2300/2312 for test dataset.\n",
      "  Processed batch 2310/2312 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:23:51.401584Z",
     "iopub.status.busy": "2025-05-08T17:23:51.401584Z",
     "iopub.status.idle": "2025-05-08T17:23:51.404929Z",
     "shell.execute_reply": "2025-05-08T17:23:51.404929Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:23:51.406942Z",
     "iopub.status.busy": "2025-05-08T17:23:51.406942Z",
     "iopub.status.idle": "2025-05-08T17:24:09.744114Z",
     "shell.execute_reply": "2025-05-08T17:24:09.744114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:09.747119Z",
     "iopub.status.busy": "2025-05-08T17:24:09.747119Z",
     "iopub.status.idle": "2025-05-08T17:24:09.959121Z",
     "shell.execute_reply": "2025-05-08T17:24:09.959121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 91.11%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      0.60      0.75         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       0.80      0.80      0.80         5\n",
      "           5       0.80      0.80      0.80         5\n",
      "           6       0.83      1.00      0.91         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 96.50%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     65946\n",
      "           1       0.96      0.90      0.93      7573\n",
      "           2       0.77      0.87      0.82      3065\n",
      "           3       0.67      0.90      0.76      2660\n",
      "           4       0.92      0.89      0.91      6559\n",
      "           5       0.84      0.92      0.88      9223\n",
      "           6       0.91      0.87      0.89      7262\n",
      "           7       1.00      0.98      0.99     42801\n",
      "           8       0.96      1.00      0.98      2838\n",
      "\n",
      "    accuracy                           0.96    147927\n",
      "   macro avg       0.89      0.92      0.91    147927\n",
      "weighted avg       0.97      0.96      0.97    147927\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:09.962129Z",
     "iopub.status.busy": "2025-05-08T17:24:09.961128Z",
     "iopub.status.idle": "2025-05-08T17:24:10.525919Z",
     "shell.execute_reply": "2025-05-08T17:24:10.525919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:10.529204Z",
     "iopub.status.busy": "2025-05-08T17:24:10.529204Z",
     "iopub.status.idle": "2025-05-08T17:24:10.545203Z",
     "shell.execute_reply": "2025-05-08T17:24:10.545203Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:10.548593Z",
     "iopub.status.busy": "2025-05-08T17:24:10.548593Z",
     "iopub.status.idle": "2025-05-08T17:24:12.573893Z",
     "shell.execute_reply": "2025-05-08T17:24:12.573893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.2815  |  Val Loss: 2.1808\n",
      "Validation loss improved from inf to 2.1808.\n",
      "[Epoch 2/1000] Train Loss: 2.2088  |  Val Loss: 2.1243\n",
      "Validation loss improved from 2.1808 to 2.1243.\n",
      "[Epoch 3/1000] Train Loss: 2.1439  |  Val Loss: 2.0721\n",
      "Validation loss improved from 2.1243 to 2.0721.\n",
      "[Epoch 4/1000] Train Loss: 2.0802  |  Val Loss: 2.0232\n",
      "Validation loss improved from 2.0721 to 2.0232.\n",
      "[Epoch 5/1000] Train Loss: 2.0253  |  Val Loss: 1.9791\n",
      "Validation loss improved from 2.0232 to 1.9791.\n",
      "[Epoch 6/1000] Train Loss: 1.9744  |  Val Loss: 1.9423\n",
      "Validation loss improved from 1.9791 to 1.9423.\n",
      "[Epoch 7/1000] Train Loss: 1.9288  |  Val Loss: 1.9090\n",
      "Validation loss improved from 1.9423 to 1.9090.\n",
      "[Epoch 8/1000] Train Loss: 1.8864  |  Val Loss: 1.8768\n",
      "Validation loss improved from 1.9090 to 1.8768.\n",
      "[Epoch 9/1000] Train Loss: 1.8484  |  Val Loss: 1.8453\n",
      "Validation loss improved from 1.8768 to 1.8453.\n",
      "[Epoch 10/1000] Train Loss: 1.8086  |  Val Loss: 1.8151\n",
      "Validation loss improved from 1.8453 to 1.8151.\n",
      "[Epoch 11/1000] Train Loss: 1.7712  |  Val Loss: 1.7853\n",
      "Validation loss improved from 1.8151 to 1.7853.\n",
      "[Epoch 12/1000] Train Loss: 1.7344  |  Val Loss: 1.7566\n",
      "Validation loss improved from 1.7853 to 1.7566.\n",
      "[Epoch 13/1000] Train Loss: 1.7006  |  Val Loss: 1.7285\n",
      "Validation loss improved from 1.7566 to 1.7285.\n",
      "[Epoch 14/1000] Train Loss: 1.6665  |  Val Loss: 1.7018\n",
      "Validation loss improved from 1.7285 to 1.7018.\n",
      "[Epoch 15/1000] Train Loss: 1.6336  |  Val Loss: 1.6764\n",
      "Validation loss improved from 1.7018 to 1.6764.\n",
      "[Epoch 16/1000] Train Loss: 1.6031  |  Val Loss: 1.6524\n",
      "Validation loss improved from 1.6764 to 1.6524.\n",
      "[Epoch 17/1000] Train Loss: 1.5756  |  Val Loss: 1.6300\n",
      "Validation loss improved from 1.6524 to 1.6300.\n",
      "[Epoch 18/1000] Train Loss: 1.5487  |  Val Loss: 1.6077\n",
      "Validation loss improved from 1.6300 to 1.6077.\n",
      "[Epoch 19/1000] Train Loss: 1.5223  |  Val Loss: 1.5860\n",
      "Validation loss improved from 1.6077 to 1.5860.\n",
      "[Epoch 20/1000] Train Loss: 1.4955  |  Val Loss: 1.5632\n",
      "Validation loss improved from 1.5860 to 1.5632.\n",
      "[Epoch 21/1000] Train Loss: 1.4675  |  Val Loss: 1.5394\n",
      "Validation loss improved from 1.5632 to 1.5394.\n",
      "[Epoch 22/1000] Train Loss: 1.4399  |  Val Loss: 1.5158\n",
      "Validation loss improved from 1.5394 to 1.5158.\n",
      "[Epoch 23/1000] Train Loss: 1.4118  |  Val Loss: 1.4924\n",
      "Validation loss improved from 1.5158 to 1.4924.\n",
      "[Epoch 24/1000] Train Loss: 1.3844  |  Val Loss: 1.4696\n",
      "Validation loss improved from 1.4924 to 1.4696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/1000] Train Loss: 1.3581  |  Val Loss: 1.4467\n",
      "Validation loss improved from 1.4696 to 1.4467.\n",
      "[Epoch 26/1000] Train Loss: 1.3324  |  Val Loss: 1.4243\n",
      "Validation loss improved from 1.4467 to 1.4243.\n",
      "[Epoch 27/1000] Train Loss: 1.3077  |  Val Loss: 1.4026\n",
      "Validation loss improved from 1.4243 to 1.4026.\n",
      "[Epoch 28/1000] Train Loss: 1.2831  |  Val Loss: 1.3818\n",
      "Validation loss improved from 1.4026 to 1.3818.\n",
      "[Epoch 29/1000] Train Loss: 1.2603  |  Val Loss: 1.3610\n",
      "Validation loss improved from 1.3818 to 1.3610.\n",
      "[Epoch 30/1000] Train Loss: 1.2369  |  Val Loss: 1.3407\n",
      "Validation loss improved from 1.3610 to 1.3407.\n",
      "[Epoch 31/1000] Train Loss: 1.2137  |  Val Loss: 1.3208\n",
      "Validation loss improved from 1.3407 to 1.3208.\n",
      "[Epoch 32/1000] Train Loss: 1.1918  |  Val Loss: 1.3010\n",
      "Validation loss improved from 1.3208 to 1.3010.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/1000] Train Loss: 1.1697  |  Val Loss: 1.2817\n",
      "Validation loss improved from 1.3010 to 1.2817.\n",
      "[Epoch 34/1000] Train Loss: 1.1479  |  Val Loss: 1.2626\n",
      "Validation loss improved from 1.2817 to 1.2626.\n",
      "[Epoch 35/1000] Train Loss: 1.1263  |  Val Loss: 1.2437\n",
      "Validation loss improved from 1.2626 to 1.2437.\n",
      "[Epoch 36/1000] Train Loss: 1.1053  |  Val Loss: 1.2252\n",
      "Validation loss improved from 1.2437 to 1.2252.\n",
      "[Epoch 37/1000] Train Loss: 1.0849  |  Val Loss: 1.2068\n",
      "Validation loss improved from 1.2252 to 1.2068.\n",
      "[Epoch 38/1000] Train Loss: 1.0644  |  Val Loss: 1.1887\n",
      "Validation loss improved from 1.2068 to 1.1887.\n",
      "[Epoch 39/1000] Train Loss: 1.0443  |  Val Loss: 1.1711\n",
      "Validation loss improved from 1.1887 to 1.1711.\n",
      "[Epoch 40/1000] Train Loss: 1.0246  |  Val Loss: 1.1540\n",
      "Validation loss improved from 1.1711 to 1.1540.\n",
      "[Epoch 41/1000] Train Loss: 1.0055  |  Val Loss: 1.1371\n",
      "Validation loss improved from 1.1540 to 1.1371.\n",
      "[Epoch 42/1000] Train Loss: 0.9868  |  Val Loss: 1.1203\n",
      "Validation loss improved from 1.1371 to 1.1203.\n",
      "[Epoch 43/1000] Train Loss: 0.9677  |  Val Loss: 1.1039\n",
      "Validation loss improved from 1.1203 to 1.1039.\n",
      "[Epoch 44/1000] Train Loss: 0.9489  |  Val Loss: 1.0877\n",
      "Validation loss improved from 1.1039 to 1.0877.\n",
      "[Epoch 45/1000] Train Loss: 0.9302  |  Val Loss: 1.0712\n",
      "Validation loss improved from 1.0877 to 1.0712.\n",
      "[Epoch 46/1000] Train Loss: 0.9119  |  Val Loss: 1.0546\n",
      "Validation loss improved from 1.0712 to 1.0546.\n",
      "[Epoch 47/1000] Train Loss: 0.8940  |  Val Loss: 1.0380\n",
      "Validation loss improved from 1.0546 to 1.0380.\n",
      "[Epoch 48/1000] Train Loss: 0.8757  |  Val Loss: 1.0216\n",
      "Validation loss improved from 1.0380 to 1.0216.\n",
      "[Epoch 49/1000] Train Loss: 0.8577  |  Val Loss: 1.0053\n",
      "Validation loss improved from 1.0216 to 1.0053.\n",
      "[Epoch 50/1000] Train Loss: 0.8400  |  Val Loss: 0.9892\n",
      "Validation loss improved from 1.0053 to 0.9892.\n",
      "[Epoch 51/1000] Train Loss: 0.8226  |  Val Loss: 0.9730\n",
      "Validation loss improved from 0.9892 to 0.9730.\n",
      "[Epoch 52/1000] Train Loss: 0.8058  |  Val Loss: 0.9571\n",
      "Validation loss improved from 0.9730 to 0.9571.\n",
      "[Epoch 53/1000] Train Loss: 0.7890  |  Val Loss: 0.9415\n",
      "Validation loss improved from 0.9571 to 0.9415.\n",
      "[Epoch 54/1000] Train Loss: 0.7728  |  Val Loss: 0.9262\n",
      "Validation loss improved from 0.9415 to 0.9262.\n",
      "[Epoch 55/1000] Train Loss: 0.7563  |  Val Loss: 0.9114\n",
      "Validation loss improved from 0.9262 to 0.9114.\n",
      "[Epoch 56/1000] Train Loss: 0.7404  |  Val Loss: 0.8969\n",
      "Validation loss improved from 0.9114 to 0.8969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] Train Loss: 0.7250  |  Val Loss: 0.8828\n",
      "Validation loss improved from 0.8969 to 0.8828.\n",
      "[Epoch 58/1000] Train Loss: 0.7102  |  Val Loss: 0.8690\n",
      "Validation loss improved from 0.8828 to 0.8690.\n",
      "[Epoch 59/1000] Train Loss: 0.6954  |  Val Loss: 0.8555\n",
      "Validation loss improved from 0.8690 to 0.8555.\n",
      "[Epoch 60/1000] Train Loss: 0.6804  |  Val Loss: 0.8423\n",
      "Validation loss improved from 0.8555 to 0.8423.\n",
      "[Epoch 61/1000] Train Loss: 0.6666  |  Val Loss: 0.8294\n",
      "Validation loss improved from 0.8423 to 0.8294.\n",
      "[Epoch 62/1000] Train Loss: 0.6528  |  Val Loss: 0.8170\n",
      "Validation loss improved from 0.8294 to 0.8170.\n",
      "[Epoch 63/1000] Train Loss: 0.6395  |  Val Loss: 0.8049\n",
      "Validation loss improved from 0.8170 to 0.8049.\n",
      "[Epoch 64/1000] Train Loss: 0.6268  |  Val Loss: 0.7931\n",
      "Validation loss improved from 0.8049 to 0.7931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65/1000] Train Loss: 0.6142  |  Val Loss: 0.7817\n",
      "Validation loss improved from 0.7931 to 0.7817.\n",
      "[Epoch 66/1000] Train Loss: 0.6026  |  Val Loss: 0.7705\n",
      "Validation loss improved from 0.7817 to 0.7705.\n",
      "[Epoch 67/1000] Train Loss: 0.5904  |  Val Loss: 0.7599\n",
      "Validation loss improved from 0.7705 to 0.7599.\n",
      "[Epoch 68/1000] Train Loss: 0.5793  |  Val Loss: 0.7495\n",
      "Validation loss improved from 0.7599 to 0.7495.\n",
      "[Epoch 69/1000] Train Loss: 0.5681  |  Val Loss: 0.7395\n",
      "Validation loss improved from 0.7495 to 0.7395.\n",
      "[Epoch 70/1000] Train Loss: 0.5574  |  Val Loss: 0.7298\n",
      "Validation loss improved from 0.7395 to 0.7298.\n",
      "[Epoch 71/1000] Train Loss: 0.5463  |  Val Loss: 0.7203\n",
      "Validation loss improved from 0.7298 to 0.7203.\n",
      "[Epoch 72/1000] Train Loss: 0.5364  |  Val Loss: 0.7111\n",
      "Validation loss improved from 0.7203 to 0.7111.\n",
      "[Epoch 73/1000] Train Loss: 0.5259  |  Val Loss: 0.7019\n",
      "Validation loss improved from 0.7111 to 0.7019.\n",
      "[Epoch 74/1000] Train Loss: 0.5160  |  Val Loss: 0.6930\n",
      "Validation loss improved from 0.7019 to 0.6930.\n",
      "[Epoch 75/1000] Train Loss: 0.5062  |  Val Loss: 0.6842\n",
      "Validation loss improved from 0.6930 to 0.6842.\n",
      "[Epoch 76/1000] Train Loss: 0.4967  |  Val Loss: 0.6757\n",
      "Validation loss improved from 0.6842 to 0.6757.\n",
      "[Epoch 77/1000] Train Loss: 0.4872  |  Val Loss: 0.6675\n",
      "Validation loss improved from 0.6757 to 0.6675.\n",
      "[Epoch 78/1000] Train Loss: 0.4781  |  Val Loss: 0.6591\n",
      "Validation loss improved from 0.6675 to 0.6591.\n",
      "[Epoch 79/1000] Train Loss: 0.4687  |  Val Loss: 0.6506\n",
      "Validation loss improved from 0.6591 to 0.6506.\n",
      "[Epoch 80/1000] Train Loss: 0.4594  |  Val Loss: 0.6423\n",
      "Validation loss improved from 0.6506 to 0.6423.\n",
      "[Epoch 81/1000] Train Loss: 0.4504  |  Val Loss: 0.6337\n",
      "Validation loss improved from 0.6423 to 0.6337.\n",
      "[Epoch 82/1000] Train Loss: 0.4412  |  Val Loss: 0.6252\n",
      "Validation loss improved from 0.6337 to 0.6252.\n",
      "[Epoch 83/1000] Train Loss: 0.4313  |  Val Loss: 0.6162\n",
      "Validation loss improved from 0.6252 to 0.6162.\n",
      "[Epoch 84/1000] Train Loss: 0.4214  |  Val Loss: 0.6072\n",
      "Validation loss improved from 0.6162 to 0.6072.\n",
      "[Epoch 85/1000] Train Loss: 0.4112  |  Val Loss: 0.5978\n",
      "Validation loss improved from 0.6072 to 0.5978.\n",
      "[Epoch 86/1000] Train Loss: 0.4001  |  Val Loss: 0.5887\n",
      "Validation loss improved from 0.5978 to 0.5887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 87/1000] Train Loss: 0.3903  |  Val Loss: 0.5795\n",
      "Validation loss improved from 0.5887 to 0.5795.\n",
      "[Epoch 88/1000] Train Loss: 0.3805  |  Val Loss: 0.5708\n",
      "Validation loss improved from 0.5795 to 0.5708.\n",
      "[Epoch 89/1000] Train Loss: 0.3701  |  Val Loss: 0.5626\n",
      "Validation loss improved from 0.5708 to 0.5626.\n",
      "[Epoch 90/1000] Train Loss: 0.3607  |  Val Loss: 0.5547\n",
      "Validation loss improved from 0.5626 to 0.5547.\n",
      "[Epoch 91/1000] Train Loss: 0.3518  |  Val Loss: 0.5471\n",
      "Validation loss improved from 0.5547 to 0.5471.\n",
      "[Epoch 92/1000] Train Loss: 0.3432  |  Val Loss: 0.5399\n",
      "Validation loss improved from 0.5471 to 0.5399.\n",
      "[Epoch 93/1000] Train Loss: 0.3345  |  Val Loss: 0.5332\n",
      "Validation loss improved from 0.5399 to 0.5332.\n",
      "[Epoch 94/1000] Train Loss: 0.3257  |  Val Loss: 0.5268\n",
      "Validation loss improved from 0.5332 to 0.5268.\n",
      "[Epoch 95/1000] Train Loss: 0.3180  |  Val Loss: 0.5208\n",
      "Validation loss improved from 0.5268 to 0.5208.\n",
      "[Epoch 96/1000] Train Loss: 0.3101  |  Val Loss: 0.5149\n",
      "Validation loss improved from 0.5208 to 0.5149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 97/1000] Train Loss: 0.3029  |  Val Loss: 0.5093\n",
      "Validation loss improved from 0.5149 to 0.5093.\n",
      "[Epoch 98/1000] Train Loss: 0.2956  |  Val Loss: 0.5042\n",
      "Validation loss improved from 0.5093 to 0.5042.\n",
      "[Epoch 99/1000] Train Loss: 0.2887  |  Val Loss: 0.4992\n",
      "Validation loss improved from 0.5042 to 0.4992.\n",
      "[Epoch 100/1000] Train Loss: 0.2818  |  Val Loss: 0.4944\n",
      "Validation loss improved from 0.4992 to 0.4944.\n",
      "[Epoch 101/1000] Train Loss: 0.2756  |  Val Loss: 0.4899\n",
      "Validation loss improved from 0.4944 to 0.4899.\n",
      "[Epoch 102/1000] Train Loss: 0.2692  |  Val Loss: 0.4856\n",
      "Validation loss improved from 0.4899 to 0.4856.\n",
      "[Epoch 103/1000] Train Loss: 0.2631  |  Val Loss: 0.4813\n",
      "Validation loss improved from 0.4856 to 0.4813.\n",
      "[Epoch 104/1000] Train Loss: 0.2574  |  Val Loss: 0.4771\n",
      "Validation loss improved from 0.4813 to 0.4771.\n",
      "[Epoch 105/1000] Train Loss: 0.2518  |  Val Loss: 0.4734\n",
      "Validation loss improved from 0.4771 to 0.4734.\n",
      "[Epoch 106/1000] Train Loss: 0.2462  |  Val Loss: 0.4694\n",
      "Validation loss improved from 0.4734 to 0.4694.\n",
      "[Epoch 107/1000] Train Loss: 0.2408  |  Val Loss: 0.4658\n",
      "Validation loss improved from 0.4694 to 0.4658.\n",
      "[Epoch 108/1000] Train Loss: 0.2359  |  Val Loss: 0.4622\n",
      "Validation loss improved from 0.4658 to 0.4622.\n",
      "[Epoch 109/1000] Train Loss: 0.2309  |  Val Loss: 0.4588\n",
      "Validation loss improved from 0.4622 to 0.4588.\n",
      "[Epoch 110/1000] Train Loss: 0.2260  |  Val Loss: 0.4555\n",
      "Validation loss improved from 0.4588 to 0.4555.\n",
      "[Epoch 111/1000] Train Loss: 0.2213  |  Val Loss: 0.4525\n",
      "Validation loss improved from 0.4555 to 0.4525.\n",
      "[Epoch 112/1000] Train Loss: 0.2167  |  Val Loss: 0.4494\n",
      "Validation loss improved from 0.4525 to 0.4494.\n",
      "[Epoch 113/1000] Train Loss: 0.2123  |  Val Loss: 0.4465\n",
      "Validation loss improved from 0.4494 to 0.4465.\n",
      "[Epoch 114/1000] Train Loss: 0.2081  |  Val Loss: 0.4438\n",
      "Validation loss improved from 0.4465 to 0.4438.\n",
      "[Epoch 115/1000] Train Loss: 0.2036  |  Val Loss: 0.4411\n",
      "Validation loss improved from 0.4438 to 0.4411.\n",
      "[Epoch 116/1000] Train Loss: 0.1997  |  Val Loss: 0.4384\n",
      "Validation loss improved from 0.4411 to 0.4384.\n",
      "[Epoch 117/1000] Train Loss: 0.1959  |  Val Loss: 0.4358\n",
      "Validation loss improved from 0.4384 to 0.4358.\n",
      "[Epoch 118/1000] Train Loss: 0.1918  |  Val Loss: 0.4332\n",
      "Validation loss improved from 0.4358 to 0.4332.\n",
      "[Epoch 119/1000] Train Loss: 0.1881  |  Val Loss: 0.4308\n",
      "Validation loss improved from 0.4332 to 0.4308.\n",
      "[Epoch 120/1000] Train Loss: 0.1843  |  Val Loss: 0.4285\n",
      "Validation loss improved from 0.4308 to 0.4285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 121/1000] Train Loss: 0.1809  |  Val Loss: 0.4264\n",
      "Validation loss improved from 0.4285 to 0.4264.\n",
      "[Epoch 122/1000] Train Loss: 0.1774  |  Val Loss: 0.4244\n",
      "Validation loss improved from 0.4264 to 0.4244.\n",
      "[Epoch 123/1000] Train Loss: 0.1739  |  Val Loss: 0.4225\n",
      "Validation loss improved from 0.4244 to 0.4225.\n",
      "[Epoch 124/1000] Train Loss: 0.1705  |  Val Loss: 0.4204\n",
      "Validation loss improved from 0.4225 to 0.4204.\n",
      "[Epoch 125/1000] Train Loss: 0.1672  |  Val Loss: 0.4186\n",
      "Validation loss improved from 0.4204 to 0.4186.\n",
      "[Epoch 126/1000] Train Loss: 0.1641  |  Val Loss: 0.4169\n",
      "Validation loss improved from 0.4186 to 0.4169.\n",
      "[Epoch 127/1000] Train Loss: 0.1611  |  Val Loss: 0.4152\n",
      "Validation loss improved from 0.4169 to 0.4152.\n",
      "[Epoch 128/1000] Train Loss: 0.1580  |  Val Loss: 0.4135\n",
      "Validation loss improved from 0.4152 to 0.4135.\n",
      "[Epoch 129/1000] Train Loss: 0.1550  |  Val Loss: 0.4119\n",
      "Validation loss improved from 0.4135 to 0.4119.\n",
      "[Epoch 130/1000] Train Loss: 0.1521  |  Val Loss: 0.4104\n",
      "Validation loss improved from 0.4119 to 0.4104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 131/1000] Train Loss: 0.1493  |  Val Loss: 0.4088\n",
      "Validation loss improved from 0.4104 to 0.4088.\n",
      "[Epoch 132/1000] Train Loss: 0.1465  |  Val Loss: 0.4075\n",
      "Validation loss improved from 0.4088 to 0.4075.\n",
      "[Epoch 133/1000] Train Loss: 0.1439  |  Val Loss: 0.4062\n",
      "Validation loss improved from 0.4075 to 0.4062.\n",
      "[Epoch 134/1000] Train Loss: 0.1412  |  Val Loss: 0.4050\n",
      "Validation loss improved from 0.4062 to 0.4050.\n",
      "[Epoch 135/1000] Train Loss: 0.1386  |  Val Loss: 0.4037\n",
      "Validation loss improved from 0.4050 to 0.4037.\n",
      "[Epoch 136/1000] Train Loss: 0.1360  |  Val Loss: 0.4024\n",
      "Validation loss improved from 0.4037 to 0.4024.\n",
      "[Epoch 137/1000] Train Loss: 0.1336  |  Val Loss: 0.4012\n",
      "Validation loss improved from 0.4024 to 0.4012.\n",
      "[Epoch 138/1000] Train Loss: 0.1311  |  Val Loss: 0.4000\n",
      "Validation loss improved from 0.4012 to 0.4000.\n",
      "[Epoch 139/1000] Train Loss: 0.1288  |  Val Loss: 0.3987\n",
      "Validation loss improved from 0.4000 to 0.3987.\n",
      "[Epoch 140/1000] Train Loss: 0.1264  |  Val Loss: 0.3977\n",
      "Validation loss improved from 0.3987 to 0.3977.\n",
      "[Epoch 141/1000] Train Loss: 0.1242  |  Val Loss: 0.3966\n",
      "Validation loss improved from 0.3977 to 0.3966.\n",
      "[Epoch 142/1000] Train Loss: 0.1219  |  Val Loss: 0.3958\n",
      "Validation loss improved from 0.3966 to 0.3958.\n",
      "[Epoch 143/1000] Train Loss: 0.1197  |  Val Loss: 0.3950\n",
      "Validation loss improved from 0.3958 to 0.3950.\n",
      "[Epoch 144/1000] Train Loss: 0.1176  |  Val Loss: 0.3941\n",
      "Validation loss improved from 0.3950 to 0.3941.\n",
      "[Epoch 145/1000] Train Loss: 0.1155  |  Val Loss: 0.3934\n",
      "Validation loss improved from 0.3941 to 0.3934.\n",
      "[Epoch 146/1000] Train Loss: 0.1135  |  Val Loss: 0.3929\n",
      "Validation loss improved from 0.3934 to 0.3929.\n",
      "[Epoch 147/1000] Train Loss: 0.1115  |  Val Loss: 0.3921\n",
      "Validation loss improved from 0.3929 to 0.3921.\n",
      "[Epoch 148/1000] Train Loss: 0.1096  |  Val Loss: 0.3914\n",
      "Validation loss improved from 0.3921 to 0.3914.\n",
      "[Epoch 149/1000] Train Loss: 0.1077  |  Val Loss: 0.3909\n",
      "Validation loss improved from 0.3914 to 0.3909.\n",
      "[Epoch 150/1000] Train Loss: 0.1058  |  Val Loss: 0.3901\n",
      "Validation loss improved from 0.3909 to 0.3901.\n",
      "[Epoch 151/1000] Train Loss: 0.1040  |  Val Loss: 0.3893\n",
      "Validation loss improved from 0.3901 to 0.3893.\n",
      "[Epoch 152/1000] Train Loss: 0.1023  |  Val Loss: 0.3889\n",
      "Validation loss improved from 0.3893 to 0.3889.\n",
      "[Epoch 153/1000] Train Loss: 0.1005  |  Val Loss: 0.3885\n",
      "Validation loss improved from 0.3889 to 0.3885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 154/1000] Train Loss: 0.0988  |  Val Loss: 0.3881\n",
      "Validation loss improved from 0.3885 to 0.3881.\n",
      "[Epoch 155/1000] Train Loss: 0.0971  |  Val Loss: 0.3876\n",
      "Validation loss improved from 0.3881 to 0.3876.\n",
      "[Epoch 156/1000] Train Loss: 0.0956  |  Val Loss: 0.3871\n",
      "Validation loss improved from 0.3876 to 0.3871.\n",
      "[Epoch 157/1000] Train Loss: 0.0940  |  Val Loss: 0.3866\n",
      "Validation loss improved from 0.3871 to 0.3866.\n",
      "[Epoch 158/1000] Train Loss: 0.0924  |  Val Loss: 0.3862\n",
      "Validation loss improved from 0.3866 to 0.3862.\n",
      "[Epoch 159/1000] Train Loss: 0.0909  |  Val Loss: 0.3857\n",
      "Validation loss improved from 0.3862 to 0.3857.\n",
      "[Epoch 160/1000] Train Loss: 0.0895  |  Val Loss: 0.3853\n",
      "Validation loss improved from 0.3857 to 0.3853.\n",
      "[Epoch 161/1000] Train Loss: 0.0880  |  Val Loss: 0.3848\n",
      "Validation loss improved from 0.3853 to 0.3848.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 162/1000] Train Loss: 0.0867  |  Val Loss: 0.3845\n",
      "Validation loss improved from 0.3848 to 0.3845.\n",
      "[Epoch 163/1000] Train Loss: 0.0852  |  Val Loss: 0.3843\n",
      "Validation loss improved from 0.3845 to 0.3843.\n",
      "[Epoch 164/1000] Train Loss: 0.0839  |  Val Loss: 0.3841\n",
      "Validation loss improved from 0.3843 to 0.3841.\n",
      "[Epoch 165/1000] Train Loss: 0.0826  |  Val Loss: 0.3837\n",
      "Validation loss improved from 0.3841 to 0.3837.\n",
      "[Epoch 166/1000] Train Loss: 0.0813  |  Val Loss: 0.3833\n",
      "Validation loss improved from 0.3837 to 0.3833.\n",
      "[Epoch 167/1000] Train Loss: 0.0801  |  Val Loss: 0.3832\n",
      "Validation loss improved from 0.3833 to 0.3832.\n",
      "[Epoch 168/1000] Train Loss: 0.0788  |  Val Loss: 0.3829\n",
      "Validation loss improved from 0.3832 to 0.3829.\n",
      "[Epoch 169/1000] Train Loss: 0.0777  |  Val Loss: 0.3826\n",
      "Validation loss improved from 0.3829 to 0.3826.\n",
      "[Epoch 170/1000] Train Loss: 0.0764  |  Val Loss: 0.3823\n",
      "Validation loss improved from 0.3826 to 0.3823.\n",
      "[Epoch 171/1000] Train Loss: 0.0752  |  Val Loss: 0.3820\n",
      "Validation loss improved from 0.3823 to 0.3820.\n",
      "[Epoch 172/1000] Train Loss: 0.0741  |  Val Loss: 0.3818\n",
      "Validation loss improved from 0.3820 to 0.3818.\n",
      "[Epoch 173/1000] Train Loss: 0.0730  |  Val Loss: 0.3817\n",
      "Validation loss improved from 0.3818 to 0.3817.\n",
      "[Epoch 174/1000] Train Loss: 0.0719  |  Val Loss: 0.3815\n",
      "Validation loss improved from 0.3817 to 0.3815.\n",
      "[Epoch 175/1000] Train Loss: 0.0709  |  Val Loss: 0.3815\n",
      "Validation loss improved from 0.3815 to 0.3815.\n",
      "[Epoch 176/1000] Train Loss: 0.0699  |  Val Loss: 0.3814\n",
      "Validation loss improved from 0.3815 to 0.3814.\n",
      "[Epoch 177/1000] Train Loss: 0.0688  |  Val Loss: 0.3812\n",
      "Validation loss improved from 0.3814 to 0.3812.\n",
      "[Epoch 178/1000] Train Loss: 0.0679  |  Val Loss: 0.3810\n",
      "Validation loss improved from 0.3812 to 0.3810.\n",
      "[Epoch 179/1000] Train Loss: 0.0669  |  Val Loss: 0.3808\n",
      "Validation loss improved from 0.3810 to 0.3808.\n",
      "[Epoch 180/1000] Train Loss: 0.0659  |  Val Loss: 0.3808\n",
      "Validation loss improved from 0.3808 to 0.3808.\n",
      "[Epoch 181/1000] Train Loss: 0.0650  |  Val Loss: 0.3808\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 182/1000] Train Loss: 0.0640  |  Val Loss: 0.3807\n",
      "Validation loss improved from 0.3808 to 0.3807.\n",
      "[Epoch 183/1000] Train Loss: 0.0632  |  Val Loss: 0.3805\n",
      "Validation loss improved from 0.3807 to 0.3805.\n",
      "[Epoch 184/1000] Train Loss: 0.0623  |  Val Loss: 0.3804\n",
      "Validation loss improved from 0.3805 to 0.3804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 185/1000] Train Loss: 0.0614  |  Val Loss: 0.3803\n",
      "Validation loss improved from 0.3804 to 0.3803.\n",
      "[Epoch 186/1000] Train Loss: 0.0606  |  Val Loss: 0.3804\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 187/1000] Train Loss: 0.0597  |  Val Loss: 0.3805\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 188/1000] Train Loss: 0.0589  |  Val Loss: 0.3805\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 189/1000] Train Loss: 0.0581  |  Val Loss: 0.3805\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 190/1000] Train Loss: 0.0573  |  Val Loss: 0.3806\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 191/1000] Train Loss: 0.0565  |  Val Loss: 0.3806\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 192/1000] Train Loss: 0.0557  |  Val Loss: 0.3807\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 193/1000] Train Loss: 0.0549  |  Val Loss: 0.3808\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 194/1000] Train Loss: 0.0543  |  Val Loss: 0.3810\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 195/1000] Train Loss: 0.0535  |  Val Loss: 0.3811\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 196/1000] Train Loss: 0.0528  |  Val Loss: 0.3814\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 197/1000] Train Loss: 0.0521  |  Val Loss: 0.3816\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 198/1000] Train Loss: 0.0514  |  Val Loss: 0.3817\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 199/1000] Train Loss: 0.0507  |  Val Loss: 0.3818\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 200/1000] Train Loss: 0.0500  |  Val Loss: 0.3821\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 201/1000] Train Loss: 0.0494  |  Val Loss: 0.3823\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 202/1000] Train Loss: 0.0488  |  Val Loss: 0.3825\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 203/1000] Train Loss: 0.0481  |  Val Loss: 0.3826\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 204/1000] Train Loss: 0.0475  |  Val Loss: 0.3828\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 205/1000] Train Loss: 0.0469  |  Val Loss: 0.3830\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 206/1000] Train Loss: 0.0463  |  Val Loss: 0.3834\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 207/1000] Train Loss: 0.0457  |  Val Loss: 0.3838\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 208/1000] Train Loss: 0.0451  |  Val Loss: 0.3842\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 209/1000] Train Loss: 0.0445  |  Val Loss: 0.3846\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 210/1000] Train Loss: 0.0440  |  Val Loss: 0.3848\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 211/1000] Train Loss: 0.0434  |  Val Loss: 0.3852\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 212/1000] Train Loss: 0.0428  |  Val Loss: 0.3855\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 213/1000] Train Loss: 0.0423  |  Val Loss: 0.3861\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 214/1000] Train Loss: 0.0418  |  Val Loss: 0.3866\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 215/1000] Train Loss: 0.0412  |  Val Loss: 0.3869\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 216/1000] Train Loss: 0.0407  |  Val Loss: 0.3874\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 217/1000] Train Loss: 0.0401  |  Val Loss: 0.3877\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 218/1000] Train Loss: 0.0397  |  Val Loss: 0.3884\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 219/1000] Train Loss: 0.0392  |  Val Loss: 0.3887\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 220/1000] Train Loss: 0.0387  |  Val Loss: 0.3891\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 221/1000] Train Loss: 0.0382  |  Val Loss: 0.3896\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 222/1000] Train Loss: 0.0377  |  Val Loss: 0.3900\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 223/1000] Train Loss: 0.0372  |  Val Loss: 0.3904\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 224/1000] Train Loss: 0.0368  |  Val Loss: 0.3908\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 225/1000] Train Loss: 0.0363  |  Val Loss: 0.3912\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 226/1000] Train Loss: 0.0359  |  Val Loss: 0.3916\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 227/1000] Train Loss: 0.0355  |  Val Loss: 0.3920\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 228/1000] Train Loss: 0.0350  |  Val Loss: 0.3925\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 229/1000] Train Loss: 0.0346  |  Val Loss: 0.3930\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 230/1000] Train Loss: 0.0342  |  Val Loss: 0.3936\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 231/1000] Train Loss: 0.0338  |  Val Loss: 0.3940\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 232/1000] Train Loss: 0.0334  |  Val Loss: 0.3946\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 233/1000] Train Loss: 0.0330  |  Val Loss: 0.3950\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 234/1000] Train Loss: 0.0326  |  Val Loss: 0.3955\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 235/1000] Train Loss: 0.0323  |  Val Loss: 0.3960\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 236/1000] Train Loss: 0.0319  |  Val Loss: 0.3966\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 237/1000] Train Loss: 0.0315  |  Val Loss: 0.3970\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 238/1000] Train Loss: 0.0312  |  Val Loss: 0.3974\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 239/1000] Train Loss: 0.0308  |  Val Loss: 0.3979\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 240/1000] Train Loss: 0.0304  |  Val Loss: 0.3984\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 241/1000] Train Loss: 0.0301  |  Val Loss: 0.3988\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 242/1000] Train Loss: 0.0297  |  Val Loss: 0.3993\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 243/1000] Train Loss: 0.0294  |  Val Loss: 0.3998\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 244/1000] Train Loss: 0.0291  |  Val Loss: 0.4003\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 245/1000] Train Loss: 0.0287  |  Val Loss: 0.4008\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 246/1000] Train Loss: 0.0284  |  Val Loss: 0.4013\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 247/1000] Train Loss: 0.0281  |  Val Loss: 0.4019\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 248/1000] Train Loss: 0.0278  |  Val Loss: 0.4025\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 249/1000] Train Loss: 0.0275  |  Val Loss: 0.4030\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 250/1000] Train Loss: 0.0272  |  Val Loss: 0.4035\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 251/1000] Train Loss: 0.0269  |  Val Loss: 0.4040\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 252/1000] Train Loss: 0.0266  |  Val Loss: 0.4046\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 253/1000] Train Loss: 0.0263  |  Val Loss: 0.4050\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 254/1000] Train Loss: 0.0260  |  Val Loss: 0.4055\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 255/1000] Train Loss: 0.0257  |  Val Loss: 0.4061\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 256/1000] Train Loss: 0.0255  |  Val Loss: 0.4067\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 257/1000] Train Loss: 0.0252  |  Val Loss: 0.4072\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 258/1000] Train Loss: 0.0249  |  Val Loss: 0.4076\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 259/1000] Train Loss: 0.0247  |  Val Loss: 0.4082\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 260/1000] Train Loss: 0.0244  |  Val Loss: 0.4088\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 261/1000] Train Loss: 0.0241  |  Val Loss: 0.4093\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 262/1000] Train Loss: 0.0239  |  Val Loss: 0.4097\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 263/1000] Train Loss: 0.0236  |  Val Loss: 0.4103\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 264/1000] Train Loss: 0.0234  |  Val Loss: 0.4107\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 265/1000] Train Loss: 0.0232  |  Val Loss: 0.4112\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 266/1000] Train Loss: 0.0229  |  Val Loss: 0.4117\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 267/1000] Train Loss: 0.0227  |  Val Loss: 0.4123\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 268/1000] Train Loss: 0.0225  |  Val Loss: 0.4128\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 269/1000] Train Loss: 0.0223  |  Val Loss: 0.4134\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 270/1000] Train Loss: 0.0220  |  Val Loss: 0.4139\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 271/1000] Train Loss: 0.0218  |  Val Loss: 0.4144\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 272/1000] Train Loss: 0.0216  |  Val Loss: 0.4149\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 273/1000] Train Loss: 0.0214  |  Val Loss: 0.4154\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 274/1000] Train Loss: 0.0211  |  Val Loss: 0.4158\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 275/1000] Train Loss: 0.0209  |  Val Loss: 0.4164\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 276/1000] Train Loss: 0.0207  |  Val Loss: 0.4169\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 277/1000] Train Loss: 0.0205  |  Val Loss: 0.4175\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 278/1000] Train Loss: 0.0203  |  Val Loss: 0.4181\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 279/1000] Train Loss: 0.0201  |  Val Loss: 0.4186\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 280/1000] Train Loss: 0.0200  |  Val Loss: 0.4191\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 281/1000] Train Loss: 0.0198  |  Val Loss: 0.4197\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 282/1000] Train Loss: 0.0196  |  Val Loss: 0.4202\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 283/1000] Train Loss: 0.0194  |  Val Loss: 0.4208\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 284/1000] Train Loss: 0.0192  |  Val Loss: 0.4213\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 285/1000] Train Loss: 0.0190  |  Val Loss: 0.4218\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 285 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:12.577184Z",
     "iopub.status.busy": "2025-05-08T17:24:12.576185Z",
     "iopub.status.idle": "2025-05-08T17:24:14.806349Z",
     "shell.execute_reply": "2025-05-08T17:24:14.805333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.1721 | Test Accuracy: 96.54%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:14.809348Z",
     "iopub.status.busy": "2025-05-08T17:24:14.808349Z",
     "iopub.status.idle": "2025-05-08T17:24:14.815536Z",
     "shell.execute_reply": "2025-05-08T17:24:14.814530Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:14.818537Z",
     "iopub.status.busy": "2025-05-08T17:24:14.817566Z",
     "iopub.status.idle": "2025-05-08T17:24:18.260518Z",
     "shell.execute_reply": "2025-05-08T17:24:18.260518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 98.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.64%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.54%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:18.263524Z",
     "iopub.status.busy": "2025-05-08T17:24:18.263524Z",
     "iopub.status.idle": "2025-05-08T17:24:18.279452Z",
     "shell.execute_reply": "2025-05-08T17:24:18.279452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          98.13\n",
      "1    LRM (CAE)          96.54\n",
      "2    MLP (CAE)          96.68\n",
      "3     TSCL LRM          96.71\n",
      "4     TSCL MLP          96.64\n",
      "5  SCL_SDL LRM          96.50\n",
      "6  SCL_SDL MLP          96.54\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          98.13\n",
      "3     TSCL LRM          96.71\n",
      "2    MLP (CAE)          96.68\n",
      "4     TSCL MLP          96.64\n",
      "6  SCL_SDL MLP          96.54\n",
      "1    LRM (CAE)          96.54\n",
      "5  SCL_SDL LRM          96.50\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
