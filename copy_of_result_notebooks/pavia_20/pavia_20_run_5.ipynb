{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:21.177002Z",
     "iopub.status.busy": "2025-05-08T17:24:21.177002Z",
     "iopub.status.idle": "2025-05-08T17:24:21.181508Z",
     "shell.execute_reply": "2025-05-08T17:24:21.181003Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:21.183515Z",
     "iopub.status.busy": "2025-05-08T17:24:21.183515Z",
     "iopub.status.idle": "2025-05-08T17:24:23.346960Z",
     "shell.execute_reply": "2025-05-08T17:24:23.346960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:23.349967Z",
     "iopub.status.busy": "2025-05-08T17:24:23.349967Z",
     "iopub.status.idle": "2025-05-08T17:24:27.016304Z",
     "shell.execute_reply": "2025-05-08T17:24:27.016304Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:27.019309Z",
     "iopub.status.busy": "2025-05-08T17:24:27.019309Z",
     "iopub.status.idle": "2025-05-08T17:24:27.039363Z",
     "shell.execute_reply": "2025-05-08T17:24:27.039363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:27.042369Z",
     "iopub.status.busy": "2025-05-08T17:24:27.042369Z",
     "iopub.status.idle": "2025-05-08T17:24:28.283586Z",
     "shell.execute_reply": "2025-05-08T17:24:28.283082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1096, 715)\n",
      "Hypercube shape: (1096, 715, 102)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAGxCAYAAADh4jqzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOyddXgcdf7HX9+ZWcluNu6exutuuLtLcTiOH+5ud7hz6KEHBQ4tHMULR6HYQal7mzRp3N02WRn5/TFt0jRJk1Sghbyfp88Dm5Hvzs6856PvjzAMw2AYwxjGMPZiSL/3AoYxjGEMY2cxTGTDGMYw9noME9kwhjGMvR7DRDaMYQxjr8cwkQ1jGMPY6zFMZMMYxjD2egwT2TCGMYy9HsNENoxhDGOvxzCRDWMYw9jrMUxkw9gteP311xFCsHTp0p0+lhCCK6+8chesqucx77777l16zGH8fhgmsmEMYxh7PYaJbBjDGMZej2EiG8bvAo/Hww033MD48eMJDg4mLCyMGTNm8Mknn/S7z0svvURmZiY2m42RI0fy3nvv9dqmurqaSy65hISEBKxWK6mpqdxzzz2oqrrd9XR0dHDjjTeSmpqK3W4nLCyMyZMn8+677+70dx3G7ofyey9gGH9OeL1eGhsbufHGG4mPj8fn8/HNN99w8skn89prr3Heeef12P7TTz/lu+++495778XpdPL8889z5plnoigKp556KmCS2NSpU5Ekib///e+kpaWxcOFC7r//foqLi3nttdf6Xc/111/Pm2++yf3338+ECRNwu92sXbuWhoaG3XodhrGLYAxjGLsBr732mgEYS5YsGdT2qqoafr/f+Otf/2pMmDChx98AIyAgwKiuru6xfXZ2tpGent712SWXXGIEBgYaJSUlPfZ//PHHDcBYt25dj2PeddddXf8/evRo48QTTxzKVxzGHoRh13IYvxs++OAD9tlnHwIDA1EUBYvFwquvvsqGDRt6bXvIIYcQHR3d9f+yLDNr1iwKCgooLy8H4PPPP+eggw4iLi4OVVW7/h111FEA/PDDD/2uZerUqXz55ZfceuutfP/993R2du7ibzuM3YlhIhvG74K5c+dy+umnEx8fz1tvvcXChQtZsmQJF154IR6Pp9f2MTEx/X62xf2rqanhs88+w2Kx9Pg3atQoAOrr6/tdzzPPPMMtt9zCxx9/zEEHHURYWBgnnngi+fn5u+LrDmM3YzhGNozfBW+99RapqanMmTMHIUTX516vt8/tq6ur+/0sPDwcgIiICMaOHcsDDzzQ5zHi4uL6XY/T6eSee+7hnnvuoaampss6O+6448jNzR309xrG74NhIhvG7wIhBFartQeJVVdX95u1/Pbbb6mpqelyLzVNY86cOaSlpZGQkADAsccey7x580hLSyM0NHSH1xYdHc0FF1zAqlWreOqpp+jo6MDhcOzw8Yax+zFMZMPYrViwYAHFxcW9Pj/44IOZO3cul19+OaeeeiplZWXcd999xMbG9unORUREcPDBB/O3v/2tK2uZm5vbowTj3nvvZf78+cycOZOrr76arKwsPB4PxcXFzJs3jxdffLGL9LbFtGnTOPbYYxk7diyhoaFs2LCBN998kxkzZgyT2F6AYSIbxm7FLbfc0ufnRUVFtLe38+KLLzJ79mxGjBjBrbfeSnl5Offcc0+v7Y8//nhGjRrFnXfeSWlpKWlpabz99tvMmjWra5vY2FiWLl3Kfffdx2OPPUZ5eTkul4vU1FSOPPLI7VppBx98MJ9++ilPPvkkHR0dxMfHc95553HHHXfs/EUYxm6HMIzhKUrDGMYw9m4MZy2HMYxh7PUYJrJhDGMYez2GiWwYwxjGXo89nsief/75rkbeSZMm8dNPP/3eSxrGMIaxh2GPJrI5c+Zw7bXXcscdd7BixQr2228/jjrqKEpLS3/vpQ1jGMPYg7BHZy2nTZvGxIkTeeGFF7o+y8nJ4cQTT+Shhx76HVc2jGEMY0/CHltH5vP5WLZsGbfeemuPzw8//HB++eWXXtt7vd4e7S26rtPY2Eh4eHiP6vFhDGMYewcMw6CtrY24uDgkafvO4x5LZPX19Wia1kPxAMz2kb767h566KE+CymHMYxh7N0oKyvrtyNjC/ZYItuCba0pwzD6tLBuu+02rr/++q7/b2lpISkpiX05GgXLbl/n7oQcEoSREIPo8KJXVIOmYWyjeCoUBRFgR1gsiEAHhqLAAG+xHmhsRmtsGvLa/AeNx31FG41NTjL/VoPhDKB+RhShby3usTYpKX5o6+kPut7354M9tq4jDAO8PgyfitHhRu/YMcke7+ET6YxQiFhQglpd03tJrkB8k9LRFXNtituPYZGwNHair924Q+f8M0HFz/+Yh8vlGnDbPZbIIiIikGW5l/VVW1vby0oDsNls2Gy2Xp8rWFDE3k1ktHQiWooQNhuWyBi0qFDkxla0iqpuQtOAdi/ghWY3kiwjORwIVyBGgA2EMP/1B8mKGOJ1EopC2eFBhDm9WPJDoGYDtVfNJO7berStjiW7gsESMOSv3et8HR606loMvXdYVwqwI2QZJIFwOs0PFRnDovT87vLmHayb+yfDwhGdXvSmZnS3e2jrUS1UHCLRNi6LuJ/SsDV4UcrqUSsqzVNZHAjVguRWketb0apqQDcwNA1pF96TcmgoRlIM5Jegd3TssuP+7tj8Mw8mNLTHEpnVamXSpEnMnz+fk046qevz+fPnc8IJJ/wmaxBTxpD31wDi5wsCP12B4ff9JuftD4bXaz4klVUYwUEwJgu5vBa9qcl8uHVt84YGhqqitbZCaytIMlKAHckViBHo2DWWESAnxqNktgEQuUJHDgnG0m6gre9pbQink53NKAlVQ6uu6WWJbkEPEmpu2byTQMgyUqATERaKoci9dxQCw2FHBESjdHhQq2q6r+P21qMoNOTYAR/+CD8lJwFYsdQlk/6qDW1TMVpzM2JhK4ausf2JATuJyDA8sYE4aly7h8i2EIlhdP//HpYj3KPLL66//npeeeUVZs+ezYYNG7juuusoLS3l0ksv3f0nF4Ly23ReOPQNzrnvc7yHjNv95xwsDAOtuQVj5XoMtxs5MgJpTCZKanJPq0uSETYb6Bq6241aXYNeXAYtbf27aENA44xYghwe6hpdhPyvhI59Mgms2uaRlWSw7rz1YbS5e5KYJCOPykLenlzPFkJvbkGvrN7+dxYCwxmAkhSPtMWi2x7GZ9M8tjc9+SP95F4VjZg82nzYB0GKO43GZmw1u88SU5ITkcbldN1bcnCQeV8NAGGzIaenIpTdby/tsRYZwKxZs2hoaODee++lqqqK0aNHM2/ePJKTk3f/yQ0DY0kwS9NTmf3TAWQv2shvcEsOCMnlQm9r6/p/774jsTZ5Ees2oW7zNpbDQiAkCK2wFMnpQG9rMx/smlpEs810PUOC+rZUBoCSkkTDcZ2EASE/2VGrqmlOG0Hc27k9rpMUYDfdu53FNtawGJfNhoudKC1hxP6qEfhTgRnj68dS0D0e5KYWCN++TplhtSDiopHrm9Ca+o8ZVu0TBErfFrrhVPFE2hn4Ud8+hMWKFBS43e8FoNU3QH3DbrP6jMZmRLu7aw3aFot3exACKS2ZzqRgHF4/aln5blrd5tPtyXVkO4PW1laCg4M5kBMGFyMTAsnh6OGiSE4nIi4abVPJb/NmHQiSDFNHIa8vNt1GNgfSw8PQG5sxJmQhN3dAQxNaQ2PXbnJEOJ2TRyB0A8vXPSd/C0UB2SQyox911r7gOXYq3ssb6fBZiL8L9FUbkEOCe93kSkw0RlDgjn7jbtTW9zh287kzqD3Ab/6PIZDaZFxFEpErO7GsKezzYRM2G1Ji3OBca8OA7ZCZ9+gplB0qo7s0EL0foZhvFYLeW9T18AuLFTk+Bj3QgdTmRi0p67U2OTSkR9JADg9DT4rFWJW7Z9x/Q4ASH0dnTiz24kb0ssoh3VtboBp+vucTWlpaCAoK2u62e7Rr+Vui9YxpyF8EoR00EQAlNZncf4yi8JwYxK6wKHYBhCSQ27yw2awXioKwWtFqajH8PqR1hdDShntGOpLd3rWf0enBXu0mIL+uV8DfUFUMr3fIN1rdOPOatFW6IL8E6ONNLckQYN9216HDMDC0rdxCScbnEqBuvn2FgR6k0jLOx6ZZVjpmZPZ9GJ8PoQ3SpRYCIkJR4uMQFmuvP9vmLSH70SJCVlm617EVavYxkNNSuo5lTMiiIzsab1wganQI0jZijUKW0VvbenymNbXslSSGJONLjcJe1Q61DchxMSiJCeb9sLtOuduOvJdADg/DmDGOkHXNqLrEyMfWIGel486O4p4D53LvmW9Tcc2k33uZgEk62ro8tLo6AER2OmSmdJGT7naj1dTizKvHGJPRtZ/udmOsK0APciAF7rx1JGw2fKEmIThLFAyfj4aLZiBtkyaXI8N3jVspBJJzqwdf14j+11IyZ3cSttiCrdIChgBDMOI/fmxfLe37OIYBniEQ9ua4mZwYhxwR3ovQ1Ooaop5fRPrbfoJXWZFaFXMdgGHXqDkkpuu8SpVp2ckdKixZ2ysor3d09A7U69reR2IAuoayahOGIuGZmkFHVhT+hHAzq7yb8KcmMjkykvxnkzjrtS/Jvc6JfkcEP702BapqsX+zivs/Pg0Zg0NmLYbpY3/v5faCqK7D2LCpV/xEyy/EWLKmx2eG34exflOP+NoWSHb74ALcm9Fx5Dg0h05jq4Pk98qQRiTTnih6HFsODYVd4VJuhhHo6GHFGH4fLF5DxMsLSXupBOGRQBhU7mNHTBrV99tfksE+9MiVocgQFoKUHI8cHdWT0HQN6acVRP9zIdmPFpH4uUCpN4m1NQ3kkGAA1Ioq7OVtWJo6wTBMl34nLBQ5JBg5JwM5InyHj7E7obs7UF02DEXC0upDXpG3W7P+f1oik7PSKXgmjsem/Icncg/hqNHrqJvoJOq5X9BaWzH8PtLuXsHtK07ksOC1RD9ZvP0M2e8Arb5h0C6hsNl6ucjCZkNMHk3zyeMxRo4Y1HHk8DA0qyDnyXqUdYFoFVW0jI9kxPvdE7nlkGCICN1+3dpQIUlI0ZE9XOYtUCurSPpKR6m30JmokneRA/dJk3udXw507pyFKEkQ7EJKju/tchoGanUNAZ8sJuPJTcQskLG0iK4wALqGvi4PPW8TcngYUkriToUsRGgIaqgDxB76COsalvxKHBvrkJfnofcx4m9XYs8I/vzGkCMjqX5M5smRc3iw4GgSLqikJDCcmJY1bB1B0T0eRtzn47+vj2H5J6OJb1n0u615ZyEFBeEbnYj83fKuz7TpI2nKtG/xhgYFERxEa7KMNziasPUaUkgwbYkSge/nbd5AIEKCMXZDf6thURAJscjNrejNLd3lGIaB7YslZPwcDLFR1O4bQVOmICgqEq2mFsDM0EaE7XQ9m3kwCcMZgJQcD21ujJZWdK+3O6tXU0vQu7UESTLa1q6hYRbDGh4vemHpDrmNkt2O7vOjFpUgikrMDPEAdV1yeBh6uxthNYm3L6t8V0JJTMBoa+u69kPGDtSp/fmITAjybkvjmZGvc+e6E4m5Y3OQup+Usr42l4IzR5BQtBhjb4xXbIbe2kpnhIUgh8OMxQiBz2UZEokBtI2JwnlwLU1tDqJvbMSXk4SrdJvrsjub9CUJwkKQg1yg6xjuTgy3G8Pn6/odw3MLQEhdJCKHhiJCg3eozGTAtQS7EEGBKH4Vo6UNraW1m6D6ul8MY8gdBD1OGR2JlhCOvCwX3eNBiY1BTYxE3ljab1mE4e4wLXdt99+/QlHwpkVh20S/z9R2MX0s7vgAHJUe5Oo6KBzcbn86IjNmjuPSw+cjY5Ac0oS/SWagPJaWP8iruQdDCIFuEUhhoSaRGQbOJcX4DhmB3zk44pGcTioOlIgEjCInasU6qs9MInF23m9eY2eSkllsK0JcSJpu9qB6vLBV4awICMAIsO0WC7H7JALDaoHIMJSQIIzm1p6Etguh1zcihwSie71ILhf+ETFYNlWhtrb3XJLFipAldI8HKTQEo7EJw+s1C1lVtSveONROADk8DL2ltd8OC0NVsSzLRxtKUmWrY9dnOdEt4KwwMOobB95pM/50RIZu8G7hZBKzGln/8wjSmlf/3iva/RACMSKJ0KV16PXdsSytppbQzz2QEINo6xiwoFIfNYKgEc0ARC3RkQOd6PLmgszNkGy2XW/5DAQhzHMqMth6ZhZ/6yJJw6KYhBYUiF7fuFPWV1/Q3W5YtQHJbkfERCL5NHR3RxdpSg4HwmZDzUlCaXBDXoFJPL6egXbd4wVjaN0dcnQUhAQhOj39EhkM3nWVXC70dpOAhSzjnpGOZoOQTT5YtAZNH3xy4E9HZGLhKmL+L4pn9z+dtC9W7b4mWyGQM9Mwyip//0Zew0DL3QSA5HQgWSzg96N7PGZh7frWQR2m9EgXwZZa6ptcZP1aRuOxI4la4e+xjQh07l7Xci+BYbMi4qJR2txmUmY7D/6OQNht6KUVyB3haJlJyOV1CEnCMzIeXRHIPh2j0iyu3fb+E4pirkeSwRic1Si5XAhHAGpewS77DtqYEXiibBiSQJfBG2wmLuyF9ahDjJHtoSmPXQs5MpLi+2cgjc4GTEsk8INFPX/g7Tx8Qy3mU+LjqP+/6ez7wRpqz91DejR1DSU+Fu+MLLwzsvDtMwoxadSg++DkyEj82eb1Cv7BjlZTS0ekhO27rSxaIUwiG4YJITCCApET43vV2O0stOaWbhGBVXnQ6UFNjES3SEiqga2wru9Sm0AnIiDAFBIYZCmK5HBAcjxaedUu/Q5i4WoCfy4iaFEZ9kYVBAgdUHcgCbJLV7aHouiKDB6Z9Sabzu6/fKLmyhlmY+w2kJxOqp93UHfJ1EGdSxqXg+1dP7fc+A6z18wk+sM9R3fK8HjNulFJoFsk/CH2rkzWQNBTYnA5PTS3BxDzZRlSSiKhBf4e5R+SzbZrCmD/YDAsCiIm0nTNdkc2d7PSiZxbQkBpC/b1Fb1aoLZAa2g0CU7XBu0piNREs2ZxV9eBGQZaXR1qRSWWH1YRtraD0HwPWlVv4dSB8KcgshFvVPDgxqMQ2uZ+u9HZVF8zE2VECkgyrWdNp2WMH1HeWxxP7+igc1EEE85fgxIfN+C5aqeFcEhELrf+ciqZ15T2iB/93tDq63Hk16O4VSytPuy5VYO+maunu7BZVHx1DvS6elrHReFcVdljm2G3cjsQAoJd/bY87Qpora1o6zeibiYCyeXa6d9DiYlGuDt3+31sqCpi4SqkH1bskBv+pyAytaiEyEvMB3bjS6MJfamGR656lah3Gmj6bATVB2nk/K2kR6P1FhgzxzHyiI2cHLGUDbcmDuhiRr62jE8vOJDMS9buUSQGmEWbhcVIP69G/Lq2SwBwIEguFy1jzFhY2EoJ3eenPV7utb/oo1h1GD1hOOzICbFmSchulLcRFitSSDBClpGDgnaI0CSnE19GHHptfb/bKLExu9xt3hH84YlMDg1BGj8StbyC1LuXkPCRTJi1Aw2BZgia1kSQc3tx/8V7hsGooCpkDK4++L/o+2y/VWlL68wWl0uJ6a1m+7tjiD18nftmExHXgqZLhK3vxJgxBqXD6FG0KNntphLtMAbElsymlJK42wjN8PtQy8qRIyMQwUHdv9VgY71CIJLjsTT20QPKZjWPnAw6xibAiO3r6f8W+MMTWdHlmYx9bT0bX5qCHBFOwCeLKTwzjpveuJCGkx2MuHVhVxP2tpDGj6T6Zh9jA7rjDXXjByfZLGw2Ws+cjvM/KnJOxsA77MFoTrcgSzqN+WHIK/Opmewg+ques0XFLnBj/nSQpB6E1hfJyBHhyOFhIARKQjwNf51B7ZWbwyKDgFpd06UFJoeGIgdvXw6n67zZ6egOK3repr7/HhVBZ3IIkmogNQ6tU0DYbBgzx/VuNxNiUIKNfeEPT2Qj3qnmg5+n8eTB7yLPEZTcOwPh7iTxvl9Qq6rRDpqIkpzY5755F7l4aPRHOCUvud5Y3nvwSKL/uRDJ4aD99OkUvTuO2itm9n3i0ekccsvPLF2ejl5Qshu/4e7FFrdS0yVGzPUiAp1Y3EZPt1IIRKCj/4MMY/vYTGhKUnwveR+ERPt+6XQeP4X8K5NomOGnebyPggtjURLiBz72Vlazoapmoe5Ay3E48EcFIm0s7TdepVbV4NhQjXXhBtTyClONeJCxP8Pnw++y0HHY2B7WqORw0HHUOJO4h4g/PJGpRaVkvtpOmS+cy+O/4x9nvUbliyEYM8eBEHjCLay/LZbOE7uzknJWOhtfnUz8AvhP/RRyvbHMeeBIgt9ZhBwSQu5zOVxz/7vcP+ljhNZPvcuqPJb+33hyHiz+3bX+dwbuQ3JAFQQ/Hoi8eD3NB40gcnFPxdLfpQj2DwjDakEKD+vxcGt1dQR8vBjHvJWkzm0naI0VdIEvWqXyhGTzRRwbM6jjb8lWbkFfLq1QFKTgIKwlDV3inX0fTEMtKUPv6EBJSoCpo5AyUwe1DqFYCChuRrMJ9KndSiVbXNjmQzPNDO8QSp7+8AqxhwSdQ/5To7lrn09Z0JTNyRHL8Rkyt3wzi8wrlphaUQnx5F2biK1BIvZXDw3XdnD/qI9Z1ZHMa2tnEPmJHdf7ptqn+9Rp3PjQ2zSogTw1+2QSnlv5+xe87i4IQeldM4he5Mf25RKQZBrPn0rkR+t79PXJIcEQFfE7LvSPBaFqGO4OszF+G3UTYbHSfsIEaidL+CP8YAjkVpmkL/3Yftkw+JIKRUGfMgq5w4dUv/m3tFnxxYdiqW9H25A/qOMoyYl40qKwb6xGraweVOxVGpeDoUiwtgBGpuONdhBQ2oIhSTROCEUNAMkPSl0Hiz/726AUYv/wRHbglNuxPdZO5dwU4t7LZ+OtacgewYgHV+M+bBRlh0POk/XoxeW0njKRzjObuTNnHk7Jy2ULziPzFQ8sWYsUEIB335EEbKhm/R1xSJ0S6dcvYqhd+nsb5KAgRHAQ7rGxOAqbqd03gvB/LeyxjZIQj+EYzljucug6wt2J3tKK3tnZ0woeP5LiE0PwhegIv0ALVnEUW0h5o3hQ2Wg5OorO8Unm/2wT27TVdWAsWzeoJW5xA/vK+PcHoSgYmmZ+HyFwnzKVzrDezqHm87DmtTuGiWyLZr8tOByt3Q26ZjbTWi1mg/G8cK5N+oZvW0cy74MZJD+3FsMwqPi/Mej7thA0x8WYG1bx0ycTCJhezzUZC7j721PIvm0Dhs83ZI0lYbPtkHb57wXJ6UTv9FB/0VTC1nfSnBFAxLIm9NW5XdsIi9WUs9lFI+aG0QcMw7TSOjrN2QybQxWS3Y6w2zCS49h4QTC6S0VqVQhdJ4h4Y8l267GEzYbkCjSlhRKi8cSaIpiWVh/K+uLBDRjZBluC90N9Lox9xtMwqncSbShE9qe4+7TWbiUCw+8zpZ9VlfzKKAAOCVrPvX95i+q3YhExkcQ+8QuJZ21C9hkUt4Xz2F9m80DOJ1iFRshaCa2tbcg/lhwSTN6Loyn9+8w+xQH3OAhB0c3jKLp/Ks0jDSxri3DHCYy8oh6bSc6AYRLb3RDCLNkIdpmy25sznLrHY466W7WBtA86QRPoQSqNE3XkxJ6JAMnhQElJ6vp/w+tFq28wLam8IpROFVt9J9KSDTtEYmD2f7IDctbyslxsLTtnT/0p70AxeTQ1F0/l2gkL+KB+Cld+dCEF3mgeHPkxme+V4j90ErrHg+OjRchneLnh7Qv5sS2L+2efSfRrK4bsTgpFoeSyUTy57xweOvffVF42cTd9s10HJSEeLaODsPF1xH+vo6cnElKg947Z7IIZAMMYPAxFNjOcyQk9atAshdUE5VoIzLUSuUjCaO4O1EsOB7XnjEML7btwVfd4kH9Zh7F8w04lprTmlh1S+9A9HgLLOnf4vPAnVL8AKD0yiMcumM1S9wgKHhhJ2mcLmf/FfnyQYdawRJXUoGGOHNMtkPr4Gla9nEB85UL0zX69MX0sluIac3zXAMTmO3g8N53/H+zCT743hsiVu1f2d1eg/sBEwkPq6PBZCC1opXFCKOGfrOuhOyYsVgz77mm3Gcb2saWoVg4NxmhpRa2pJebJ7ha7Lb+TkpxI6axELK0GrMnr/3i/c2ZdyStDys5C30FG+tNZZHJIMJOPWYtmSHz06oHYP1tsfv79csL/tZDwVxeDJCEUhaCiTjL+mkvplWPMAOpmwpJzMpj6wnJGflFD1XUzugZM9AVhsVJ+oY8YpQWPYeG1fx6N/P2K3+Cb7gSEoH6i+V3bK4KgoBg1gF7peGG3DbuVvzO2DEZREuL7LKo1LApyJ7jKNcTozF3bRbArx7vtpHrtn+IuFIqCmDIGYbPReGwOJ4Sv5LnSg4l/v3fVsnrQeMa8V0Dei+Op2tfBIWEb6EjqGTQ1FIn/1aZxYNAG7r/sdTbeMbLvcyoKFddO5q4JX+AzZK6bfxbRb63d8zOdhkHMQvD6FRK+NpBCQwhoHJoI3zB+Qwhhtodt5XJugVZQRNwba2lNVth4QRBS5uCGzAB9E5UQXRX4clqy+f+SvPNdHTs5ROVPQWTIMpX7u9j0Wg7H3vw9TsnLwVF55N2U2qsX0vK/tcx/eQZnTlrMIxfNZnFbKhlves1CQacT9eBJUFCK48xWrvzmPD5pmEjiN1uJCwpBzVUzyXtuAiW3T+XWi+YQLrdz/eJZZN+yYbcPfthVsLg1OtaE4py/FjU5Ckdlb3dY2Ibdyj0NhkWB8JAeCSWttZWoFxaR+VoLbVl9t0JtCyUhHmPGmF6dBkpMNEpCPEIIqG8ym9JHJKEkJyI5HMg5GeZowSFaa0ZiNJIfbC1GX4PbB17v0HfZ+2B4vcS/sJLyt1OY7DCzbuMCSnn6hNd5Y9o+NN8yHvHzSjMTNDmHmLmbWPljDu/dMpmIBTY69hck1SdTeWQ0t17xLncsOZGsu5vJvHwZ1bHRWCu6B8LK2emcefF8xgWUoiGQMfAZMvHvWbZLYkJRqLlkKo5aDddHy3a5ouhQIAcFUXq0RPgys9q6OdNJ+Ge5vXX5d+PA1WHsBDaPztPLKnsMQtFXbcBVEow2CIlrw+9HaHovV1Stqes+5ubJUVpBkTlEeWw2nbGBSLFByB4VeU3hoF/cHUlBWN06gV+tQR+dRnN2INoQzKw/hUUmbDYKbxvH3aM+7/G5jMGFMf8j++l1uE+dhu+wCZz8r/m0vBGIL9JJxvkrEDoE1Bo0TYrkgkvmESJ3cNPEr1GjzbjYtqoZRnk1L397CMW+COTNivFWoVF2qNRv2YXkcLDpwSlcduXHXHjvJ7SeOnk3XIXBQY6OIv/2UYQmNRG+ug2EoD1e9Fkxrjc2Izo8iE4votML+rD7uafAsFlR4mJ6WUZac0tXaEManY0cGWn+YRvXUKuphcXrercpbTPezjyQDFNG44021YF1q4RQ9SF5H7pFmAMWhEBuchOxoBRlCDmxPwWReQ4ey32z3sEpmaUDz5QdwiNFR+IzzB85I8AkI8fqcubVjeHC5F9oS7KBYeAq9RK5sJ6Mq9eTbatCQ/DIwqOQFq2l8sZpbHxlXJeENpj9bOnXL+Gtvx3LPfnH0qqb5PXgkXMomJ2NNDabbVH9l/E8dtKbJFkaKPJGEli6c6nonUHH5GRCRjfQ5rYjVzchBwcRUGf0Wchr+H2o5RWoZeWoZeXoJRXQ2IzYAaniYex6GA47Snys6er1EcMSNQ10Tkqh/fTp1F0yvbdw6BCknoRu9BgtKDe2979xH5A9Op3hElJYKNTUo5ZXmPLXg8SfgsgcS4u5c/kJaAgeLjwK/s9GwOmtXPPDWazqTOKtR47G+eFisFlxKD6eeflkQt4ys5mWxblsuCaUsyLN4bzzW0Yz8oF6mJDDqWd/z/P7vsXof+dRf/EMU8AOQNdwfriIkFOrefSRs/i8aTwhcgfPTn2X0a/nUXv5zC6Tvf306Zx12X+xCJXv2nL4+dbpiF9W/S7XCSGomWJK9qh1AWg1dWjNLYS/+uugdjf8PrPIsrQcauuhqXXYSvudYQTYzCEoyaZUkGS3d1lpWl0d1q+WEPxDIbZWg/LTUnokCgYNXYOVuQQs3EhASTMBpS1ohaUD77cVAv6XS3ChD/fYWLAoyOFheMIGH/n6U7QoKcKCHBlJ0RUZpMxt7GqxkVwuREIMWm4BUmAguU9kg2SQc0N+V3Vz9TUz+fsVb/Fk4aEcGbee2T8dQMYVi0wX7Po0zjnyByY7C/HoVp4uOgTbgyFIP67skZmUR2aSe7OLJ/aZg134adYc3P7f07HVy1x4+n8ZYy/nyZLDkK92oq3rrvWRRmfTnhmM46PFv0mmU4mNYeM/YggNdmP/VygBHy/u+ffEBAybxYy9aBqGbgz41hYWK1JQICLINaznv4dAqJo53LitHa2pxfwNhUDfZxyd0TaCF5Wb0jy/NSQZaWwWjWODEbqBR/EO91puS2T9QUweTfFxQYRt0Kk6VCXn1iJTdUBVEYpC6a1T8WR4yLm1kg23JZPzVA1qYfHmnQVydjobL4zgnuPfJ1xuJ98bw/PvH0Pqk2t7xBckp5OS68dx69nvE6WYsYMtyYBiXwTv3XC0qTCxGUpsDCXPhXNR1s+89+CRBL89OKtopzB9LPV3eGhtc5B5c12vm7nj5GnUTDaNeKGDpU0Q96MbJbcUralp+8eWZOTIcITTMSz5swdBeH1o1bVdoQPJ6cTIThmwaVwODYWocESHp0u4cZdAkjFmjKExJwBVHW4aHxSRyVnpRL9Rw6yIxSx0p7P43DE0jg/F3qTh+HYtuU+MJm2OivzDKoxpo2nKcRA2e7PygxAIWe4ivPrzpzDzsqUcHbIanyFz/ZLTyXjUh75yfdf5JLudlhPHE3FZMZfHfwfAGk8Cr79zBImPLu7KVG4hsUfGfojfULj5w3NJvXVhr/XvarScPR39rAY8CyKJ/ccvvTcQAjkngw1XhYBls8uoC5RGhYjVBqErGtALS7ffGC/J5mzN4CCwWoZJbU+ArmNU1Q6pvUhMGoU30oHs1VB+Wr1rs+xbyCxRsOLd4abxPiEHBdF0wQxqL5+J9ryHUyOW4DEsfPzaASBJtCcIAr5cTuUl43nykHdouLYDYVFQcksJf3NZ13HaTp9G0dsjkcaPxFBVwl9dSO7VI7l2+em06QH8c+q7jJ69gbrLumNnuseD671fUS8O5LKfzqHCH8qHDx9GwkMLu24EYbGy/q6kLhK7ft45pN3320xDD/14DS3LI4j5dZsM5eaiR2lsNkWnRoCy+d2nCRxFFiJWG/gCBQXnRlB8+yQ6Tppmqpf2VUuka+htbWaSoLgMGpoQ/t+v1GQYdJVrDHm6k2FgqevoQWJbCsF3CrqGWLiGsOWDH97zp7PIaq6ayd1X/xsJHasw4zvXLj+dtOsbKbgsifR/FqHFhbP/a0uZ6Cjmsm/OJ/PyZT1jQVPHMP6lNRzk2sAidxpzXzuQ2BeWYXi9CIuV+vMmMfXSFRwTuhKPbuWfJQfhfTUW15xu/TLJ4cAYlQYr87r63ISikP/4ZB44ag4hcgeXLTiP7OvW71Aj7o6i9vKZxPyvsYdUT8s502lJl/CGaxgBW+qSBNE/yoR8sMK0wIRAdrno2C+L0iMkEOCokAnJ1wha34hRVIa+ue6oFyQZOTwM4XIOW2i/I4RfRa+tH9T9JrlcGNkpsGJDDyKTg4LQM5NgTf5OS1aphp/v+WTYItsW8qgs9j1vGXbh7yKxOfVTSXxWoeCSJJK+MgtX/I+0MdFRTKtuJ+UjvZc88MZLbBzk2oDHsOA3ZG677F3ynhqHkpKE4fcR/upCis9J4MqfzsatW7kl9SsuuOtTcwjw5tFZekcHxpI1PZp1q66a2kVitaqLEe/pvxmJicmj0febgBoIbOo53DXsq3xC8nQMSzcJBZRYCJ27uvtmNQy01lYCfswloEombJWEZoOKI3Q2XB1K0e0TqL1sBsY+43trsuuaOai1uAzqGhFt7j2/jesPCMOiIGKjBjXeTW9rw1i6tpdLafh8+INtSCOS+tlz9+BPk0aS7HZyb3FydejKrs9K/eGU3pFJR4KF2F9VpJ9WUHrjTG5KeJ+vWsZQ7QkiYFF+j4p238HjuXOmWVh73bdnMfLRWr6ZuQ+jLipBCw7p2k7LKyDrUhvPnn0aEy9dyUlhy/nbVW9x48TTGHlPHWpx7/R0W6qGXTLbnaKUNmqu9JC0NGj72um7CDVTg9APbyL0NUsXeUpOJ/qYNHS/hs8lQOomF1szpmrpVpAcDurOGE3oRg3n3MVER0dhhIcAoDmtNOUEUnq4A+34LCJWGYQuq0fLL+pRfb4laSA5nWZNkSJjyNJwc/pvBUlCREcgKwpac/P2Xyh9/E0kxqFbJHwxLpTC305I9A/vWs444h4CF2yg45iJXPLoh4TLZqGehuDKb88l499+WlPshMxZipSaRNDrzRTMziL6i0KM8BD0jUVIyfFmXYyhIwUEkH/POA4/cAXF5yV2aZv7D59M3VgrcY/3DpLLWenk3enimRnvAnB37vFEnF7eq1pecrnYdPtorj/hU1Ks9Vy24DyER8LWKJPy8PIhizkOBeohkyg6USH7jg1dxClsNtzHjKc1UcadYKAFq11kJrwyKZ9o2P63vut7+I6cghog4fhoUb/nkVwujKxk6ie4aE0DpV2QsMDdf+2cEAirFTkivDs5MDx27jeB6PCgNzUP2isQioI+dRSqQ0H26siL1+8UkQ3FtfzDW2RnPPAlT393GiLJ3UViAE8UH87IR+ooPCeO5IeWIhSFDTeFI5ZHklyhUnPMCKI+XE/J7ZM595RveX3ewaixXkIW2sh8MJdfs5LxnhhOYn4RhqpiCPBOcpsP2TbvBi2vAMfqmWjTJTyGBeWdMPSOjb3Wqre1MeJvS3hr6bGEXFVKxEKF02/4mhHWOu4cdQIp9/nR1+TtFrfL8uManJMm9yBXw+vFMXcRjs2ZRs8+2ZQcK2PYNQybRtGpAuv+47rKMKqnWRjxZiXbC93rbW2wdC3hSyE6NobW6ckoG8u7rN5ecsmG2VWgVlSa/Xw2G8LlQjgDzLq0YVIbGgwDoemDikUaDjsiIBq5tR2ttm7A+85QVcSva7E5HRidnb9pv/Af3l6PU5p56uTXeHTS3K7PqtVg3K/FUXNILLG/+jD8PtqOHcdDB/wHEeqj8dJ2LrrhUypej2PSEet5551DOPOoH3li5vs0j9HRmpqIvaoDX7DBxtljaTl7OrF/34S/xYYcFop+wIQebUtiwihmnbsAq9C45fvTCf5geb/rNVQV54eL0I5rxxsqGGGtwyl5eXLC++zz1ko2vTUeaVzOLr9O2sxRuEr1vm++zZlG61dLyH6hGaXeTJ44Cy0EFUL8d23IbV7sdVByWhxKcuKgMldqVTWOjxah1Xdnp/SxGZTcNBHtwIm9e1MNw5R3rqtDLSnDKKs0Y2odHjPz+cd0LnYtmtvMzovBtpIJAcEulOiowWUjN98rfd1HksOBkpzYY3ydsNl2ycvoD+9afrAyG4er59vnsp/OIefhFkpOjiLxscVIKYloL/m5Lnk+GoJbXrkQuRP2OWc5ax4ch+OTpYhx2ZQfHkzSyxu64zh2O7lPjeXxg9/DKXnxGBYe23Q48YEt5Liqmf/QfgR/vJLCOydwz2nvUacG8flf9ofFa3qtVxqdjaiu6/FQC5uN5tMmYD+vmqtSFnT1ii5yp/HRqwcS925+v1PSh3y9zppO2M8VqCVl291Ostspu3Yi7nQf6W9qSD+s6PE3dXI21TMcSD6wNxoEFXuwbKxAb2gc1Bta2Gz49xlNxYFWhCaI/8GDdVXRwAW3QiCHhEBE6LCVtj1U13WHDhQFyeFAhAZjDEKSSfhV9PrGfpvB5fAwtLR4JK+KVNOIWlvfFf8UNhuMycAbEYDs0VB+XouQJfzTRyJ5NSyldb2mPw3FtfzDE9lNvxzNgdHdk74/bJhM2RWpVBwYROJntWh5BVTcOpNHLpqNjMHDhUfhPK8Tva0dKSJsuw+2sNkofTuDJ8Z/wEJ3Ov+rS+PypO+7COeD+ilUnxWBXl1L+5FjaE2SiXlmUa+2HjFhFCH/rGJ5aSIjHld7VVVLLhfll43hoNOXcHSIWVPmM2TeqZ1O6TOZuOYMrepfTk9l0wUxpN6zrHsiz9jsAd1W35FTqJphwRvjB9kgfKGF8Fd7F+oKixUpJBg9xXzzto5wIvsMAvNbMHILehOaEGYm0zDQGs3hv3JkJDUnp9M4UUVuk4lcBqELCnupjWx7HCUmGsPlHNL1+DNBuDt7j4sTAjksFEKDB06q6DpGTX2fZCY5HPinZqPZZWwNHqSC8q4XkBwSjGdqBnKnhqXBjb6xECk8zBxJJwRKp4r00+pu4lMU/P7OYSLbQmQHj76Jkr+5eHTSXCr8ocy98nDccRa8wRJRz5mBeSU2hvV3J3LC5BWsvm08lq+XDnB0E+rBk7jwhY8Jkd3c9MaFpDy9luJrRnPDWXOp8QfzzfX7Yvlm2fYPIslsfH4SgZsUgoo1mrJlohf7CFhe0svaUlKSyL84nutPNJMBGoIb37yQpHsXDs2tmjqGSS+t4uvn9iH8lT6ISFGQY6IxOjt7zCusuGUm7ozuchGl3kL6fasHFQwWNhuMTqcj0YmjohOpsKLr2HJoKPm3ZKMFGDgqJYILNeyNKvVjbLSO3nw+QyA3K6TM82JZlNv/IFpJRklOGO7r7AdC1cwylz56ZCWHAykmauD4ma5Dbd+TyOXwMIgI65mNBpMsg4PQ293dxd+TR+ONMMfAyR4N+cdVoGsosTFo8RGoK9fxnf+DYSLbUhBrDQyh9uyxCAMilrdSdngwiY8t7lWRLGWkDnrCMoAxYxwhj5WzrCiJrGtL0FtaKXhoCo+f+CY3LzuZ1LPWbb+pWpKpvnoaHNhE/HkVaK2tSC4XefePIjqzjrAL3ahV1T12EYqC57AJ6NfWkxDYTMuptl7bDAgh2PjqJE4et5wNZ41Ayyvo+lyJj0ONC8MXZkdxq1jWFKK7O01liwMnUnKUDTXcLBEJKLKS9EjP6yjZ7QiXq1+XV1isyPExdGZGobT5kZasw9A0Gi+YTv00DZQB1DI0gb3KQvJnLRgrcvu8vsJmxiqNQMewm9kXtnIvt8WQyKypZUiDeQGT0EZmYhSXY2Sn4I00FWgtLT7Er6vNZMQWgmtu48eF9w8XxG6B7nYT8fJCIl5fRvEJQaS8tglDVVESE1BSkwEzyD4UEgMQC1fhPsdJ1rUlaA2NuI+fxM3HfoJd+IkJbUPbf9x2A6TGtNFcfPFnXJH1A03Hmrr/ens7kk8gCwO9tbf5bqgqti+X4Dy1nuaLo4ZOYoBksxES3s7BwevJ/0tk9+eBgXSOjMUXZgbZtQAZ78R01H1Ho8THIf+wgsxnS0n8TCJ4tZX4H7fJTAmBNiEL36hE0wLb9nopCnJEGFpFNZb5y5A8Kh3HTkSJjiL8zSWkfKQjOgZ4gGQDXTaomxSEHBbSfdzI7u9heL2oVdUYFdXQ0DQsJbQNRFD/Ba96RwdaafnARcmSBKHB3dJVg4QcFYk/zIHh8yNX1KN0mkkapdXTdT7hM+8p1dm/2MO2+NPZ3yPea0CtrjHjW88EcVBiPkv+MR1vsKBlXw9KsZ30Vyr6LFhVD5mErbIVKmqoPnsUEas7UX9ZZcZ0MtMIv6aYJIsZrL89bR4VL4TyxJsnk/CQ6foJRcF34DjsK4rQGhrpjLHjlLzMqx9DyPpWdEAOCyVzcgm+e2LQ3YU9zi+HBHfJC+ltbbCu//Fe24Pu8RDxRAAVL4YxYkpZ1wR0o7MTe1kLnsRgDEmY/6ymReNLj0ZpNXskA8or6D0XGhASwjBQ2rwYvt7jxeSYaIzgQKhvNMsqVqwjsDiU9n0zsNdFY1uwmpzcaCqPTaR5jNqndWattpD+SrmZtdysDS+Fh/X5wtA7OqCjA9HajhRgRzgdEGA3C2z/xJaaEWBDcjj6dc8NVUWtqjbdxO3FzSQJosKRA+yDTuagacidfgzVj1pdg9zQhDQhy1QY3oKiCpTQdNQhsNOfwrXsU/1Ckim7fRrnz5pPsrWeELn7R3248CgclwtTi3wzlPg4gt/vJED2s6Yhljszv6DAG8ObLx5J7Lu5tLwdwt/Sv+hximbNwTN3zcL1nhmMb/zLDC69+SPeLJuO9HgE9iWb6JiZjrXZj7R4vRl4FwJpXA766rweblPtFTNJO2MjeZ9kkvDSmp0eYiIUhYKHJ3Pj0Z/x7s3HYP+8W3tMjozENyoRzd5tHQlVJyC3GsPlgIqafl2TLYTSZ/rd6cTw+XvPUBQCMX4kHclOXL+WoNU34DtwHMUnKRi2rVxHVSLrlQ6MpWuRI8Lx5yQh+TXk+jaEuxPD3TFwF4QkI9ltCJsN4QjoOr9ht/65ugda2rafONkMyeVCigwf0NUUPr/Zp9lf7HLrbRWlV1jH0LQeFqDkdKIlRvLthseHY2RbE5lkt6N7PAhFQZs+GumXNaBrdJw8jaPu/p6JjuIe+79cuT+5/80g5Xmz3EI9eBKN2TaiTintKtP4tHECk1wlzC6aya0ZX+HRLdz20ylcNX0BI+0VXDb/fLKuXWVaOzPHMfLZdcwvzsK/MYj/O+5r/v3GEcQ99otpEfl83aa1xYqQJbSJWeRfaCEwz0rOCXkUt4RxfuqvPPnlMaTduGin66bkoCA6Pwwl1NaBd5aM4e7A0DR0t9uMdaUm0pkU3GW9CFU3g7JLNuyW1hM5NBT3vhlYm/0oy/LwT83uEZNDlRj5cDVqSRnS2GxESaU5RkwS+MakYCuqG7B8pF9IMnJQIGKzLLQRsGvqm/ZY6Dp6ScWgBvMOOm5mGGadWkPj4GWyty4g36aYfLj8gp5EZhs9mrKjw4l77BeMmePY/8VFvPP+waS8ZNZhdZw0jfBri7kg7mfsonu0m8ewcM/6Y4k5qwzd7UaJiWbkvFoODNrANYvPIOuOJkpPi+e880yV18u/+AuZNy7Hd9BYio9RyHmysstFbTl7OmEXlWJcFYSoqKHs/3JIeKFvy6rszpnYpzbQ3OzkhsnzaVEdzL95f+w/rafgrrHEf69im7ek1347go6Tp3HSvfOZ/daRpkjipqoeb2plRAre5DA0m3kTC90gYF1lrxS+5HR2v4135pYSAjk9lbYxkQQtqwRVo/KEFJrHqiAbxCyQCXr3195vdYt1l07Llux2RKATEejEsA4+VrNXYZBWGWxOhoUEm0q/g7DOtKqaAV92wmZDSk9BW78RhISckdoj2zlMZHQT2UG206m7YjoJ7xVi+P3UvBbOAzmfmL2W35xH5mVLzBhXeBhFV2RzwWnzybFXcM2PZxEa2cZB8flsODTYrIeRZNpOm0LVkX5G/r3GVMYUAqaMpuAqhREvg/RT/1PE5chItLo6lMQEtOgQjKVr+9yu8S8zyLgol/qbkvAFW9ECJBxzF9HwfzM4+aoFvPf6ISS8mQ+S6PNGlLPS0YID+iy87Qv5T0/H1igx4qVNqDW1vYhIstsRyQl0poSYbqCqE7CuArW6xjxfRAQEB6IVFKEkxKNWVvf/Rt7mravEx6FHhiDKa3oUA0suFx0H5hBQ3YlYtwljVBpFxweCBCMeWDUoF2aXQJJR4mIwHH1PwNqrYRhQUz8kUQJhsyFHRgxosQpVQ6uo2i6ZCUVBcrnQmprMwtyUBJPUNmOYyOgmskmn3I9dtxK4IJeyNxKwW1R0A67K+J5//f1kAt/vWUyqHTSRouOsZN2Xh3AEsPHqZNLvX7tDMSk5PZWis2NJfmBxL80mw+frvwlcCOSoyF4ktaX5PPwbO23HtmOxqMTdL/cgRDFhFGH/rEQ1JNovDEHb2Hua+tZQEuIp+Ec4wV86CX19+yq0SmoyntQIdKtkVme3+5CrGtEjQ5AaWlHLyrcbRJZDghF2excBglkb502NwLq2rEfJhpyeil5SgRwfQ+uEWAK/WY9IjGXjX8LJerr0t9WU36y1NtgK+L0KhgH1TWZ912At2i3XIyJsu9aZaG3v8VtDd5mTUVLR8z6RZCSrpcczMUxkdBPZmAsfIOatdZTdNJnrz53Lm9cfR8D/cmk7fCSBn67o+eMJYcZchjAGC8yK95JjJDLfcHeTihCU3zoDaWoz8acXICzKLrMi5FFZ7PvuSiY6iplTP5XaWSGoJWXIIzPRnu1gY2Esrsh2ol3tWC63ddeJbYZkt6N7vcjZ6RT83UHMHFuvQSP9njsoCD0rGW+YDclvYN9Ui9HuhuiIHm/TvqDEx6FWVvWy+ITFagZ7N193JTEBPTwIfdUGMzWfEE/r1ASCVlSbAzMam4f8G+0SbBaAJMT1x4uf6TrUN6K1tA46NCBsNiRXYL/upvD6TKtsq5e4kphAx6hYAspazftlO+caFlbcCtHfViKNSOLoUxcSb2ki7s4CjMwknB8u6vUGEhNHUnXdtF5j4reGfsAEGv46AyXFFI6TXC6M6+t4/qjXCXu6oms2oBITTeRBlcQ+bqX+/Em0zY2h9oqZfT8AQxwvr63L4/MHDiLfG8MJ4StomhFvrr/VTeczcWRespzESxupbnXhf96LMiKla1/vMVOoeC8VY8ZYjPJqUp82Bk1iAFprK8ay9ThWl2Nbmo9aUobW2IShSOb8xO1ArajsVsi127sznH6fSUxbxpRV10JuYde2ankFgfNW0T46GjUjASH9TiSyWQDSqK6DptY/1vxOSYLIcJSkhD5rAPuC4fV2j//b0ry/1TUxbGar2tbQGxqx1XXgDw1Azk7fdcvfZUfaQ6HX1JF7RxD7uMxi11Mil1FxSHCv7ZSUJOxP1HP7xe9SOycB9ZBJvbaRHA7KrlC557bX8LxiZtmkiDBinK1oCMrbQzC8XuSgIBoPTKHxqzjyL7Bw5Y0fcmPa19DH8+c9agobn5+EMXPc4L6QEAiLFVeRm3o1kOsWnEnwF2ZvplpeQcAni0HXTJN+YQgzIwpxZ5nFop0nTmXa/Utoq3YhLdlgusu/7sA8AF1Drarujq0ICS3QZkofD+YrWKxIcTHmOLnNkCMjMaaPRg4JxvD3drt1jwf750uQO/24j5s0KBXT3QW9rQ2trg6togrRsfs04n5zCIFhsyLHxQyazGBzMXlTE2p5hXlNti6mDQ1GiYnueoHrHR0Yy9YhL1oPjS27bul/dNdy5KUPcvjFK/n+pWnIJ9TTvCqCEfcs7xWEVGJjEO8Kslw1tGs2wi1u5r22L7GvrOxyCbfMuHRKXhq0QJ65/3RC3voVJSWJDdfHkPKJiuWbZSipyWy4IYY7DvkEu+QnXG7nqdJDkU7p6KHiIDmdlL2ZwuNj/8M/yw9GP7Gjq+C1PzSfN4PW49qJDm4jIqCdzvOcqEUlvbYTk0ahPdqKcX8k8nfLkUNDCfvC4NeiVNIv3DnBOyQZJTa6R+ZSGZGCGuEaXIJhi1W61a0nLFb0yTkoDe0Dx/Xi42idlkjQ8qo+C5e3t245PWVI2brBHFOJjcZw9lkivNdC+FW0yuodvk/kkGBEWGiXyyncnWj1DUM63nCMjG4ie2LpTJ794WQy/r4aKTSkz4spZ4wAIfDFBWNp7EB0eMm/N5gHJn/E3z44i5Q7zCC4Eh9H3qPR3D/5Y+5cdgLZcTWUfZxKzFO/dGXj5OgoOt8K4MbU//JgwdHYHw2l5koPnaUuIpeAtV3H+d/V6B4P1dfO5J4r/o1Ht/D0PbMIemdgFQtpdDYV9wuOSMplxfUTkL/vW9tMWKzIMVHdMwclGX2fsViL63bNHEJJBkNHDgtFa2g0pamjIvok1cFASU3GmxKObUNFrwAxbC60leWu305YrEiZqXijA7Fv2WegW3lzhtmQpcHN4hwsJBklOvIP19vZp1LGUPa32ZDjYroa+IWqYTQ2Dfiy3oLfNUb20EMPMWXKFFwuF1FRUZx44onk5fVspTEMg7vvvpu4uDgCAgI48MADWbeup3SN1+vlqquuIiIiAqfTyfHHH095+dAfwESlkUeOf4e8h8aCJHU/CFPGUHHrTNSDJ8HLHqL/XYut1JwepBUUoTXZ0A2JwK1e+GpFJekXrucfD59B+mN+9EucBFbqW74UAJWnp3Ndynzmt4wm6GYryoJlJJxZABFeLv3bXC559EMKZmdTd9kMzr/oK+zCz20/nkrw+4NT3NDX5hJ3aj7rT01G/qH/Ug/D7+tJWLqG9NOKvklMknv0Kg5uIRqSzQaaGRPR3e4dJjFhseKPCUFp9qLW1iNnjDDHyW0FOSEOKbA7Bmf4fWjr8rCtKMQzMh7fEZNNMcsB4o1KWR3KuiJE8C50TTe72kZF9R9qtJ3hsCOH9A7DDHp/rxetsvuaGIpsxuHi48w49C4k/V1OZD/88ANXXHEFv/76K/Pnz0dVVQ4//HDcW0m9PProozzxxBP885//ZMmSJcTExHDYYYfRtlWJw7XXXstHH33Ee++9x//+9z/a29s59thj0bShBVjfrZvGHe+dzchxJZSdvtVkF8Ng4glrufzFD7gicQHfr89Cr+uuY0r80uDvH51B1Bs9ycLwegl7bSHGinVoeQU9yjf0/SZw4AWLkYXO13Ondo1Uqz9nIjdN/JoYpYVwuZ1np77L3de/wUh7BaX+cDJm+4YkC2yoqjntfBcY03JEOIUPTqXs/Iwh76t7PIN+u253DTFR+IOtCL+ZuTSq69C2tsqEwGjuW2lBa2pC+XYZtu9WY9hk9P3G9k9ohtEV2xuSSzpI6B0d6LX1fxylWiEgMnyXkhlCYDgDEPExphBBUNDeoRBbV1dHVFQUP/zwA/vvvz+GYRAXF8e1117LLbfcApjWV3R0NI888giXXHIJLS0tREZG8uabbzJr1iwAKisrSUxMZN68eRxxxBEDnneLazn2vAeIenMFcmioGWjcyq0Uk0dTdJPEgxM+5qaFp5J9X1OP/sq+9Pf7gxITjetDPxdE/8xXLWPIPzEGtawcJSWJ7A/LOSzYtDibNQe3zz+diNRGbsz4mmbNyRt3HU/Qpyt363CRLWg9czrWdh37Z4tBCDY9Op2nT3qNm16/kMT7+5gu/htADg1FzU5CWVe00xOjhM2GPjEbX5gV58qKnXKNtoYyIgXDopjxuwHuCTk09I+lVGsYGGWVO3V/butm9vibu7PPspw9qvyipcV8Y4eFmbMMi4qKqK6u5vDDD+/axmazccABB/DLL+aDtGzZMvx+f49t4uLiGD16dNc228Lr9dLa2trjH0D4HHM6j9bU1Cs2ZixdS9r/FfPww2ezb2YBrf8UPbM1/dywSnwcviOn9NCU92XFcVyEeS4ZHT00EDkkmPW3RXNw8HpzDQjuXHoiWTeuIvz0Sv5x/1msdcdz+X0fUPZOGq1nTR/gau4chMVK9eF+jn7wOypvmokcHITm0mjWfl9FVa2pCfHr6v5JbAiEYHi9iIWrcPxSgCc7Fu/RU7pKYnZqjRVVphstBn5ktKYmqKn/47iZQiBtO4t0K0hO54ClN70ss63/5gxAiYvt/p2FQHK5hjSxfLcSmWEYXH/99ey7776MHj0agOpqUz8rOjq6x7bR0dFdf6uursZqtRIaGtrvNtvioYceIjg4uOtfYmKiuYYBsiRaaythsxdSe3kirV/HmDfrduIskstFybOhnPPkZ9SdO8H8UAiURRu4++PTadACOSx4HVmvFVDxehxPHvwuMiYhvlkzk6yba9A9HnS3m/Av8lhen0i43M79Yz7BHzCEN/gQa8/AjCuNvLOKtwqmcMdF79J8ZA5ZV63k0RdmIW8uqZNzMga8KXcL+nppCIGxz3i8R042x8ENAVtcTsfCAtzj43vU0u3Q8rxe01ofZCGu1tqKXlXzh9FC2168TFittB8+esDfyPB60coqEK3tvX5vwxnQNbhZyDJGehIiYPBtYbuVyK688kpWr17Nu+++2+tvYpu3rGEYvT7bFtvb5rbbbqOlpaXrX1nZ0FQQjBXriH3iFxifTcV/ss1MZh9oPHE094z+jC/rRxM1Nw/Jbqfogel0HDaW9PvX8sQ/Tmde81jGOMrR/xfKdT+cwdKOVNZ4Eqi/I6WHq9N0eCbXjfgGgIfzjyTqw/WDWquSnEjFf7Ipu3PmkOup1IpKkq5s5uF/mvVnht9H/Je1WFoN87vMiqT8inE7RJQ7BElGGj8SJTGhl+WlxMfhibQS8L9cs3tgC4RATBqFesikAeM3WlMTtnlLMSyKaUWPzf7NiFr3eKCh+Y8RMxMCERbaZ32Z1tSE45Olg1KLNVQVtboGo7qul3UmXIGmEoyqYqxcj97W3s9RemO3EdlVV13Fp59+ynfffUdCQkLX5zEx5kCKbS2r2traListJiYGn89H0zbp8a232RY2m42goKAe/4YKOTSUjX9xIv8QDPU9z63Ex+E9agohF5QhC53CdzLQGhqpuWACydPK8QZL5D6aQ8w3VRScP4LX7ziBhH8uJ6DEysfPHMTrbx+B8nPPJvGwH0u5+Yuz+LxpPK5HXIMOnLePieW6nG85+IRliJghZhsxySz62V8gLZGiB2fgeKWZjlhB27HjcEyqR8xswn3S5N7j2HYh5OgoM9Br6Ai3B62quvdb2u/HWdhqShxlj+h6Y2MYqEE2mtOseKZmDOx6GgZaXgH279cgvCptR442ifM3gNbUZN5LfwDLzFBk5Njovq+3rg2JsPW2NrSyCmjqbokyLApyfKz5choi+e9yIjMMgyuvvJK5c+eyYMECUlNTe/w9NTWVmJgY5s+f3/WZz+fjhx9+YObMmQBMmjQJi8XSY5uqqirWrl3btc3ugD4ijoglEjHPLkIEBfaYTbnpkmQufeo/XJ38Ddd/fTbRb6xCGpsNRzeiXOMk+K1fyX6uFfwq1Dfh/GIlwuVCHenGdmoNiU90TyxSUpORXC7UikoyblpK0WnRXWPVJJcL/+GTux/aPmCft4wXHzuJ5Y9PQMsv7He77UGy2ym6XebJ019jWmgRrkn1dJzXjEXWcVj9dF7QRPVFE4fs0g0WJRemUzw7CWG1ouUX9sraCosVrbYOI6/I1HNbV4C+xSoToktWSPLpyMFBpgU9gBWpezxmpvnzlei7INs6WGhNTRjlVX+ImJlhtfSo1O8Xkjxgd4Chql0tX71KNGKif98Y2RVXXMFbb73FO++8g8vlorq6murqajo7OwHTpbz22mt58MEH+eijj1i7di0XXHABDoeDs846C4Dg4GD++te/csMNN/Dtt9+yYsUKzjnnHMaMGcOhhx66q5dsrmvyaKbNXok7VoChs/6OGCL/VUnrWdPpPHEqZ57wAyFyB2/WzCTnH2bsI+9GB+r34ehrzTILfW0uKDLSHJm8p8dhxEeSfmUZwdcrXbE6z3FTGT23hIKX0hATRpmm9lalAI0njeavz36EMteK78gpfS9W1wibvXDIY+B6HMLjIe2mZm5bexJvFUzF920EVqU7/mORdTr3b2PjrRnUXmnW222vB3VIEIKQA6p5cNzHfR5TWKx0HD0eOSKi67oZfl/Xf8vhYbTHbi6y1Ayz0bmmHmmQumGG17vTCrtDhe7xYPQxg2FvhOFyokRH9b+BJCMm5qBNyTEzuANAb2szEwFb+jSFwAgKRE6IHfSadjmRvfDCC7S0tHDggQcSGxvb9W/OnDld29x8881ce+21XH755UyePJmKigq+/vprXFvFe5588klOPPFETj/9dPbZZx8cDgefffYZsrx7Yje+MDujAsrJOHIT0pgskj4TtPttXHPXHC555EOmOTdRrQZT+kwmamExRk4aARvsxP+rZ0tOxbHxnBf3Cy8c+gb7/XsZDUdnYRR2E1XFARKjAsp5duq7xL9QQtsZ07ssCcnhQD+9Abduo+r1VHSlO4uz9XTmXQW1pIyESxqIfsyG1EdOxLLYRcZda4j7vBx/kEzZ1eNp/MsM06LcDqkJi5Waq2f2ayF5j5rMc1nv8lnD+D6TMXJcNB2RMkT2/RAY7W5kn+l6tKTZze6C1tbBlwdI8u9SGqE1tSB8/oE33AtgBDr6t7h0DTQDNdCClrF9F35LjNNMBFT2uD7G72mRGYbR578LLrigaxshBHfffTdVVVV4PB5++OGHrqzmFtjtdp599lkaGhro6Ojgs88+68pE7g7Yf93IPa+dzf7h+aS+WkxHpIz3XDu3fX8qmmHe9PfOP4mguWZLUGeCk8Byo9ebPXb2Kh544Ww+apzIOEcJV9/5PuXvjoDpY5HsdtLvWMFTT51GqT+c0yKWcPHdcyn92zTkiHCqLxjPTZn/5aGFRxPx7oouHX05LQXbHI3Su2YOqZl3MNBqahE/r8RVqVLX6MKndpOPL9hA7/SgFpcS8PFikp5fS0ihh6Kz48m/b2y/3QDCbqM1UwOjd1xI2GyUn+Mn3WKw+uUxfUobaZHBGBJ4EvoultQ9HkJy2xAa6AoIy9AUXJXEODpOnIr/8MlmacZvRWq6hlZVM/CEor0BktRvc7lQFNSQzZ9vpVSiJMT3CNcA+Manoe87HtjcrVFRvUNk/4fvtex3+EgfEIpC3vMTePzAOTRogTz0w7Hk/K2I2hPTMY5vIOZqL2pRCZLdTs37yWi6RMzDlj4VJJSEeErPSCagzsDeolE9XcYfpjLyvirU8gq8R02m/qIOHhzzEbLQea7sYKaFFTPNuYlb1p7cdVyhKGx8ehLPH/E6bt3GbctPJO1+H/q6PJS42CE34vb/5U2xPD0rGc2hUDc2gNYsjfhvIejXkh69jJLdjvvIsQTmt6BtnuQkJo1CKq4y+y7tdiqumEjsE70HB/sPn8wR//iB2R8fyogHVvRpRfmOnEJrkoLQIOqn2r6byDfP4ESR0SqqBy0KKCxWvAePpTXZvCckFZxVKs7VFX0WZe4uyKGhENl/HHRvQZ/N5ZKMMX00/iArkl/Hvq7cnJg0Kgu8vl5DffKuS2LE3E7EL2Yd5pbZp35Z59uCp4abxodKZEpyIgkf1PP1qtEkfwxxtxeQ2xBFxEN25LWF6G1tSA4Hm/42jntPfo8QuYMf27L46JN9GfHipl7NznJ0FBVnpSP5IPbrajbcEEH2861QVIGwWUFVqTpnFBln5HFO9EKsojtGdcWvZ5F+zgpaz5zOJXfNZXl7Mj+8NYWo48qYGVHIvxfuwwlTlvN1UTYpd3h6iSfuCkhOJyI2io7MCHwuGVuLhmNVWZ8N2vq+42lNDUCzQeTiJvS1+f1OsxYB9u2m6rcQGYDFbRC+oHiH5nf2BWVECjWHxGJsY4RJKoTke1CWbxzU5PSdxmYi/iNIaAu/ilZe1eNlIo3OxpNghooCCup7dsz02FngP2wSQjVQFizr/lhRMMKD+Kb65WEiGyqR1Vw1E+OQJhKudeOPD+PUV74mSmnllvfPJfWuJRiqSvEDM7jvtHcIkrotCQ3BMyWH0vxGIqHvmNsJm41N907kqVNeY21nIt+fMxl91QbkkGAKX04iPaqe1qcScX61GuFyUXV6BmlnbOS8mF/wGBaevvNMgufnwdwAToxZybvXHo31v0tREuKpfM7FQ6M+AsCt27j/6XOIem73thcJixXGZdIw1oUhQdiGTrOlaJvsnxwSjHdiOh3RFgwJQta3ITYWD5ochMVK+/ET6AzvjnoonRC2pgVj7UYzuykESkz0DpGbHB1Fy/6pqAESmgWMbcJ4zloN5/x1vwmZCZsNOSrSHEW3t7czNbX2kCqX7Hak8DA8WbEo7b5ByTttO1BGUwTf+T8YJrKhEtmWjnzd7UaOCKfsL1kEHFhHxAXNGG43m/4+jshlOjXTBdcd9QVp1p6aVs2ag9sXnkz6yypCNzjvjS8Il9tZ5E7j17PHoq/NRXK5yHtwJHcf9iFWoXHbz6eQ87gp+ytHRlJ1egbN4/xkX7uOkhvG8/dz3uWBV88k7vFFpoUjBIUPT+epU16jWXNy5w8nk3XV6kG7l5LLRfOxowjOb+93+Ml2IQRyRARt+42gdoKErUkQvbgDy9ptSE2SUeJjcY+JpWGkBWurQeSyVliVN2CDvBwaCuEhABgOG57YQPyBMpJq4NzUCoWliIRYhNe3Q+PfhKKY2vER4XgyY/CEK3hDpC4rLXSjl/7kkXYH/gi9mf3pl8mRkQiXE3Qdrbyy399ejgjHn52I7FGRa5pRy8qH9chgx4isL8hBQWhtbbSdPo3z7vqMR345iphvFWytGmG3FHNx3I+99vmxLYsF/5jJ9OuWsp9rI/e+cA4xT25lMUky7pMm4z6vBafNR05oDSteHkvk22bMSLLbTe2tz0KIsLtpOsXeZX1ITiehX1updAfDk5E411YNSV/Mf/hkzn76czZ6Yvj0o5kkfuNGWrxuSOobXdcmNJTOqWkUnyBBgIZrjY2Etwt6iRZKDgfqlCxqxwegOiFsg4br2w1Dm96jKMiREejhIQjDwCgqo/2IMQQtrxwSmcnhYQi73dT+33x+YbPRefg43DEyhgDZB5Hf/LYDTpSYaIygwN/sfLsD29MvUxLi0erq+3/hCoGSlIAeEmhO1GpoHCYy2HVEBuZbZcNDySiNFtLvW0vZFWNIfn0TelQoAf9s6JPM7sk/ltYfo/GPayf9srI+Rfwkux0REMCGJ0Zwy7SveGTRkeQ83o62Lg9hsbLx8Yncd+QHPF90ALbHQ7F+v4rWUyfz17s+5p/PnkzU80N3J4XNhu+AMZQeZuHcw38gwtLGM3OPJf2fhX0KGg4G6iGTaLveJIW6mmCSPpJwLi7ue1TdqCw2XhCG5tKIWyARsqQKo7UNvaV1yGSqJCfiHh2Do6CpxzzE/iAUBXW/sWg22ZwCtXBdD6FGY0IWLZlO1ABB+Kr2QY/T2yUQAiUudu9WmjUMjMqaXeaWDxMZu5bI2mZNp3GUIHRKLXVNLqzrHCQ+aGbk5Kx08i6N4NrDvyTDZlpNrbqdh54+m7hPSqh6PpDmJidpsw3kn9f0+bBKDgfFN47nyfNe5aaX/krcYyZBSU4nlReN47S/LiBY7uTZT4/mgINX882yUWRdt2qns5XyqCzKjwznkr9+xgtvHEf8IzsWZ5ODgth0yygco5uwWczvV1MTTNJcmcDl5ahVNT1IxnvUFFoubcNmUWntsKOqEkapk+jFOkHf5A5J40xYrDA+C1QdY8W6Abf17zcGAPv68j6JW7LbkeJi0Gvqfpugf48FCuSwUAgL2WvdTNHpNS3ZXUArQyGywVec/UkhjR9J1nXrmBVh1nQ1aw5efPvUrh9Kyysg/fpNfHjk4dhurOKKpAXcs+ZYUj4tpeipUDobbJw5fgkpL9bz8JIjif/YQuC8VT3KDvSODvzBOq26nbDcbqLT3W5inv6Fn3+YSMmdEnee9AE1ajDlLyej74KSC21dHokt8ZSeE46+E1yvtbaSevcytGkjKTvMgZ7pJiKyDe9lOlWtEdiWppD4ZQPahgLQNWz/XY4SO5WGbIj7ScMdLdO4vxfvBe1sODyTkFUW4r6sRCurHLCswvD7YOlaJJuNgR4dQ9OwtJnH23oY8BZsKedQC4u7P5TkbhIWAikwEN3d0a/1J40fidSyg2q5hoHW0IisaRAZvleSmRFgQ4mO2mHrfkcxbJFtB3JoKBufS+bByR8hY+CUvFzx61lkXpzXZyGnHB1FwXVp2LJacFe6MCSD7OtWI5IT2HhxBLcd/TEhcgfPX3YayrfdqWZpbDYJ/yrDrVppPkHqesgku53S6ybiCzVI+6AdT5Sd5hEWov/Zuz5rIAiLFWG39SrgbT1rOtfcNYfHnjiDiJe2P6B3sFBiomk6IJWqw1XsQV4Sn5LxRFrxOSVC8tqRCsogLpqO5GBsXy7p2qdlnxRqp0hYMlrRdQmtIJCUzzqQV+bvusni25ldKmemobvsGMtMy04ODaX9gAwCNzZDrfmbFFyfSeK3vh6/39aQ7Hbajx5H0IrqHZb+BnMYjuH6fXXidhiGAXUN/VrWkt2OFBnRHYPs5142Qpx82/TGsGu5s0RWdsdMHvvLbK7+7AICqiUOPX0xuRdndd3ofUIIpDFZFJwTStq7rV3ujrBY8e8/hsJTZEY+XovusFN6fBjBm3Tirizg8Ij1vH/ZkWydLSu/bSb2mfWkhjQSau2k8vSwIWfp5IwRNE+MomYaROXUEXpOU3cNlySz8ZUJBAR5SD6nYJcr1CoJ8XiyYlAWLAfDMGeAZiZRMyOY5lEqlmaZuJ9U7PNXdVteQiCPzKR2RhiNE3Qcse246xzEficTlN8Gq/MHPxF7iOias7nZ/Zcjwqk9IRNhQMjGTqRf1lB+yzS8ETqZs5u6ioG3hWS303HoWGyN3h1OpCAESnSUSWZ7oWWGYUBre59xUqEodB45EW+IRPBGd5+xSGGxUnrZaPKevn2YyHaGyJTEBNI+qqFTs1JxXixafhFKYhxqWeWgxfW2yOD0RRBtZ0zn6nvm4JI7kTH4oH4KVcdYTdciJJi8v+cQlNZM3BVtFF6UzMwjV1N1XECPWp1t0XzuDIRhEPqfzbLZQrDpsWncc9wHOCUv1/88i4wLV3atX3I6qZ8TT8TtUtd8gcFcF8NhRy8s3SlCUZIT2XhFAoFZTXiWh5H4TQfKmsIemUzJbse3zyiKj7UQnNaEYQjac0NJ+azTLFzdVVZaP5CDgvCPS8OSW47e2orh9aIePInCMySERyLmF0Ho90XozS19/sbSuBza04J6hRKGtIaQ4L3WzcQwoKa+z+y0UBSaz5hMU5YgfXZln9ZrxyGj+eWbu/cMqevfG8JiRTto4pAFCJtnJJARUMuqF8aaVfO6ZlpDgyQxoShsunsC1XNS0A6c2OvvQf9Zyh3zZiFjUKu6WP7m2C5LqeSyUTxwzBzkz0LR6xuwT2jEqXjNboB+IDmdhF9Ywk1/f4fcF0YhZ6Yhxo/kgsO/J1xup9ofTNorWo/16x0dRP1f66BJDABVpeaASMpumkzzeTO2Kze03cOUlJF+31qCX3SBAYVXQO4zGTT8dUaX8KHu8aB8u4zM21YS9oQT/8IwLGlt1N/kIffJUbhPmWYG+3cSwmZDSUxASU7sodagtbYi/W8lhAV3TXCyrStD+CUMh0bVIRq5t6ZScPcE6i6dYcovbaUKoa/agGtNHSJ5x7XPtOYWaB28wOAeBSEgOsK8ptsKqaoqIe8tJXleBx1ZfStpWL/pf0pYr1P90S2yqcffxzmPLODx748i5478Qc8yFBYr7SdMIPCzlTuUHew8YSrnP/wp8ZYmvm0dyTevziDm1eVdb2Y5JwP7S81cHPcjl80/n8wrloGuIYcEo88NpLY9kJjzqtGaW1AS4mnaN5Ggj1b0uxYlORH5334ujPsfduFnXvNYmv0BnBW5CIDLfjqHrP9btWNuTh/Y4iqXHWolfXbNDuuibYE0Npvik8LwZXRiNFlJ+kon4Ns1PS0ZIZBzMig9PgJ9cis2i0p7bijp77agr9qww5kyaVwOdVNDzP/2gavch72gFrWkDGPmOPLPsWFtkEl/rhDPqAQKT5NB6UMo0RBYqxXSXy7rWdsnyUhOxw5LBwmLFTkhts/BHXsLRJt74Nmj2wz7GS6/oJvIDvr8Um7M+QmfIfNk8WFID0Vg+XHXPdD9QXI6yb97LEash4MzNnJIyHr+vuI40h5W0Veup/20aRz/9wXYJD9fnb9vV5V9+W0z+dsF7/L03bMIendoemNyRDhVs7LIODOPs6IXYRemioBbt/HkbWfi/HDRLv+eckgwCGmXDbtVEhMo/EsS0rgWtLXBpH7UjLGuoKcbKwRydjqlx0diTG1B0yRcXwYS+WneoOSWe32HiHCaDsvA5+q2Gpw1GgGfLsF3+CSKTzU/l1tlNIcOlu2rvVqrLaS/tJnMNstyC586NMt3GwibDTkmCmM7Vvmeju2R2ZY6PqVu86g+wxgmMugmstS7H+C2M74k3mI+aBX+UB5afhTx71pw/pi70+PHtovN5rScMYINN4Xx+AFzWOwewZJbJmNdsBL//uNwx1oIfndJD2tsYmgZq05M3qH2G9hMaKdnkXFWHufH/MwzJYcindjym4sJ7iiEosD4bIqPC0LL6ECrs5P4jW7WpG1dOS4E+r7jKTrRhiu9mea6QNLe0rH8un7IMSklMQEtOoTW9EB8LkHkwiZTYSQpgfW3xfZtgW0HlloLKV+Yig5SQAB6Z+fO11ZJMkpSPMYgBST3SDS1otX3PftTTk/FlxiKpaEDNpXha28eJrIui0w5BfWIqYy9dyVHh3TL7bh1Gzf+dDoj761BLSlDDgmm5PJR2BoNYj4Y/JtdO2gi7fFWQj9as90CSsnhYOODY3nymH9T4I3h1XeOJPGxpT0sjc4TpnLNY+/RrDl4+l8nk/DfBkqPCyf57dIhtSFtgZIQT/F5yVhb2O1N5bsFkoyclkzjtCjqJoIerBK22ELMF6WoldVd8T5hs+E5dCylp+kEh7pprgoidKVMzLdDd3nl9FTq9jdFLCOWNSM1t7P+1tgBrbC+ILwyyZ/p2L83XWQ5NBQR7Nqp4cDbmw+5t0C0uc12pb6Kw+12sFjQ3R2ommeYyLbNWhozx1F0peDWCV91WWdrPAl8c+FMhF+n5HaJR8Z/CMA1888h88plAwb2lYR4PK/LXJ70PTcvOoWsh9xo6zeaw1wbm3rV0dReOZP7r52NjEGz5uClq08xFS22Un/NezyWv0/6jLt+OglLvcL9p7zDYw+fRdjsodd4basmsDdDKAqMyaLk+GA8yT7spVaSP2+Flbld31Eam031fXR1F9Q3B5L8ijy0UIIQ6PuMA8AfZMGxpJi6Y9Opn6mCGPhRER0yUYsFrSkSnQkqSAahyxWi31yNSIqj5MRIUl4v3ClZoj+Em+lXMRqatusRDVf29wHxyyrSllh5+6BjKbtA5Ybx83n97SNIXLGU/NdG8dyEd7q2lTv7LpjcFvUHJ3Fc1HfYJR/PzXiHy244l+yrHLS9IIAwXJcEd719lYR4kk/b1DXjsloNxlbbiRQSTN0rLmRJJ/TMejIu3sgrh51MyhU1/GW/n/lX2f5EvLeKQdsDkoyckw66Tu7lYWS/0IS2fuMQr9aeB0NVYcU6klbJyOkp1BwYxca/OLHVTCWo2CDiuzI8EU4kyXSfNV3CqLZTepEH+8SpJHzd2DXIZPsnMsxMJWATAs0wiPzIR3vSKDyJA5ebKB0SYfM3EdLQiOeICZQcK2iaqNKeMhbNZqAH+tl06QhSH3fvsKtveL2opeV7tZ6ZYVHMjKbN1q+rORT84csvtobh92H5eilp56/nk7MOIOmZVUipiZwzxmw/0hDcsOpU0t/bxkUUos80f8ibv/LLmeO4+tMLqFVdIBkgy7R9Gkt5QRTrb4mh/uIZCEXBkxnD/uH5Xfs+s/RgjFW5tB6SzZVp31Hf5MLweMm/ZwwYYD+uhqefOI3KbxMHXS8l2e1UXzONQ+cs4YD3V+JMaMMoq9rxC7YnQtfQNm4i4uWFZN26nqSv2vAGCzbcEk/RKQoW2aR87Ytwsu5eT8Y97SCg4FY7hXdPNKctDbYma0sbWnMLI14uxF4+sAXkj/BTc0IaCAnbvKUkf26AJvBH+NFdplXnjfNTfe6YnZsdahhodXv5NHMhIDQIJSlhpyXc/1REtgWG34e+cj1GTir+F3xMdZpSyi9VHEjypbUYS3pWGredPg3PF3F0nji15wU3DLR1eWTcvJRXbzqZ/bLz8U7LJOqFRWS82cl5M3/m8us+YuM/JmP5aQ1fXro/l/14LsW+CKLmW1ES44i5dhN2yY9ebafwjglcd/QXlJ2go3s8RLy8kISH+nEpJZm6y2bQemb38JLKSyZyx2VvM9JeQbDcQezjVvS2NuSQ4F1Sb7WnQW9rg8VriH72F7KfqiUoT6au0YWmS/iCTbLS8gqIe3whI57R0RUouNdF/cXTBzXdZ2uoVdWkvlUF/oEfmcbJKo1nTUJYrdjmLSXxv9BDklYYNI9V8R4xcacKXQ2v15w+tDeTGWDYrMhxMUOu9dwaf5oY2baQ7HY6P43h1hFfArDIncbPl03p0g3fAjk8jKa3Qrkr43NqVRcPrj6KhOct9CW8J2eMwKisoX7WWPa/YhGHBZvtSY8VH4HlmBoMr9e0zg6fgGNZCW37pHLVw+9x+6dnkn7HCuTYaIrOTSDlvequILU0fiSaw4KysRyj3d2VjXOfMo1z7vucNt3OgrOn4okN5MjHvmdcgOnKXrNsFqlnr0cEBFD4Sir+mgByHqvYoaTBbwH1kElYftj5shglNgb3hETKDpcxLAaJXxnYvzDjncJmo+XkCdQf50GvsZP9SNGQmpuFotBxzERqJ8l4YweImekCW5WFqBXm9yk7xui9vV8i+VMD23+XD7rQus91bYmZWS17ZwfAFhgGNLWgN7eYYxKHECP7U1pkAN79R3NBUncm78uKkSjri3tt175vOmclLUVDEKW08dTE90l9JK/PCUJafiF6Rwdh6918tG48taoLDUHFL/EIq2kRGaqKbd4StJpaWpNlgiQPkk+YcY/iUhLv+6WLxITNRsmdEufM/oKIz/zkPjsGY5/xyJlpRF1TSIq1nhdX7o8oqaT+EncXibl1G6GfOTBUlfJLxvDghI95/ujXqX7eMeQJ250nTEXOSh/SPlsw2Kp/YbHCbXV4Dxm/Q+fZGmpVNbZ5S8i8fTVJn+uUHS6ovXya2Vrl9RL07q+k/tNAD/Gz4fYUmDpm0Mc2VJWATxYz4uk8IhYqoG2HNCQDb7yPsmMMyo7ug8QALDolxwvqLp7a1c2wIzC8XrNUp65h757OJASEhSAnxg/Z1fxTEpmcnkrMXZuIUbqzirdnzGPDw1m9zFvHF8v54oL9ufrzCyj1m1O3fyhK639StWHAr6vJ/L91vHrjybxauR93z3qP1g8iaT1retcNK4eGknxiIQ1aIPE/9m2FGH6V8LedPLXxEI4OW8MLB/2bc179nOh/1/LXuJ9Y3pFC1kMdeCemc0PON137PVt8MKGfrEMZkULqcYXcuOAMVnUmcW/Op2y4KX7Q10lMHs1B9/6M7hpkQHkra0Cy29nwUNqgpkV7Dh3HhYk/41jbt7rojkDv6MD25RKy7y9C6TBYf3scLWdPR0lMQPyyipG3V+ColNl0jULbrOlDenC0hkbC31xG+lsq4QstiI7txLqEYcZO+4NFp2mSStVfx+0UmcHmdqam326C+u6CYVE2u5qDV8z9UxIZbW5W18Sh0f3gWYXGXQd+jJ6T0mNTQ1Uxlqwh48al/Ptvx/H3vONJ/JdlYJ0srxf754vxnAIPvHImx8St47q736XxlLEAFF+ew4Vx/6PEG4G1uZ9Mmq7h+GgR0WeU8dxtp3PZ9+dSowYzK2IxMgaz5x+Etn4jtqX5PPvEKbxTNw0NQfucWIzOTtbfGkn+ghFkXraE9146jLWdiWT+e3BigZLdTsH1Cv9euM+gtP3liHDyX5tI9TUzMWaMo/OgMYTGDK7YuD1B4d6Vx6DV1g9q+6FAq6klbPZCcp5qJGSjm/ZxcWgHTURvd5Pw+GKSXpOoOkztTgQMEobfh/TTCsJfXUj6u55Bxc76hTBoGePfNWTW0GjOzdzLYVgURFTEoLf/48fIpJNRjN43mRwdRdm56Rx99i8c5NoAwE1rTiH+jE3bTdFLdvvQlQyEwJgxltY73YTeqiDKagj8TOLCmP9x5UcXknbTQpBktP3HYcgCyat1lQD0PLmMGJdN4awgMqcX47stCrGwO6YnZ4yg5NQYUt4soWN0HGXnqmT8dQO6x0PFLTPxjOsg7exVg3I/yu6YyesXPc2dZ1/UK27YFzzHTeX0R77k0wsPoiXNQc3+GjHfy4NqsxIWK8Ki/CZqFsLpwAgNonFiGCG55gAWJSaaitPSaBmpkva+ivzdwINHJKcTKSwUtbwCKTCQ/L+PRgvdySnihiDhSwnHR4t3zkUUAjkkZK8faKJq3uG5ll0tSnc9QOZLFX3qIoEZTN90q8I1Y7/j/ZuP6pruvTsgR0eh1dbRfM50bvv7m9iFn/sLjsH6eCj1Y22ccv73NPidbDolZsD2JMnl6lepVImJpuNNO23vxxH+r4Uo8XE453ipfiyNgE8G/n6Sw8HYnzv4siSH2JM3DioQLdntaBOyehDrngYlIR7D60Orr0coFppnTSS4oKNrwLKYMoa8vwaQOlfH+t3q7VrdcmYaosNjtkwZBi1nT6fmoB1LVEjtCo4KiY54Hd2mE7ZSJuqt1Tsttb1XSwAxNCL7w7uWD530FkX/jEYZkdLn3/WV60m7sIBPLjqYgK927wiw9hkp1Fw1g6CiTmZX7ovPkLkz/QtOevob7I0GHxaNY17eaNTSgTOLeltbvwSz6bI0To1fjqvUD5JM3vVJtPrsBP5vcEN81SlZXBX+P2yfhgw6m6Z7PDtMYkJRaD5vxm5/4NTyClPPzTAw/D7CljWw8a82Gv8ywxR9XLKGnCcaqNjPQuG9k7bramr5hT206cMXFCO1Dr2+XGm0kP1YKXH/WET2Y6VE/SLTNEan4pJxKKnJO/xdAbSWVtPN/GPaKj3whycyGYPHJ3xA/oP9M7re0YH4ZfcrYgR8uoyYn1oQmoF6us41351NgxZIhq2ay2/9kAszFpL6MoO+8eTISPKfmYack9H1mTFjHLNO/IE0ay0nPzEf3+ETiVlo4Hs4dtD9o6WH2VnliyBqwW8zDq3uwimcc8s85KjemeC+IGy2IdeB9QVtQz7pb6k0HOgl/+5RiMmj0QtLSHsil7ifVDZcF0Ht5TP7TgRs8xupVdUkLNBRGiyDj5cZguhFumnV6RpqRSUhby4k6+UW/EGw8ZI45My0Hf+ChoFaXYNRXYfo2LXqv3sa/vBEBuDRrVC4B+if6xrGinWIhavQamrJumo1TzxxOqX+cGKUFjJs1dROHPw4sPpj0nniqLfheTfaQRORg4KovEllhtO0vDJs1VQcoOD8zyIsXy8d9HFTP2zluvf/gla1+wdIyCHBHHrZQp5YfGj/meBtUHrzJMYsaEIeldXj8y0EpyTEI0cMzqWSflhBzp21GBJU3qlRe9GUrhKZrH+5ac3Qqbp8kummDQD754tJv3c1OU81EvGzBfTtn19qkwn6obeVrK/OJeUfa0j9pIOKo6N3jswwrXe1ovIPTWZ/CiKzSz78ITtecNgXtraCdhSG10vEy7/yzo3HcOPqU3mu7GBiv28xjz197IAtLBFfbuKWOedydtwi2uOsGIZBp9valY2dUz+VtHeHrhNmrFhH6u0Ld3rc3GBQfcZIRgWUM/L2ikGdT0lJ4uRTfmJ/Vy7o3R2oksuFf5/ReKak0TE6js5JqYiJIwfVBqSWlZP1cCHWL0Jo27+TjfeMQho/EmPFOrLuzUNXIO+uHJSY6AGPpbvdaHkFhL+1jLj5EsLdv7sp+QV6W9/qr3pbG2LhKhL+U7JLyAzDQKuu+UNkNPvCH57IVnYmUacGEbp6J/ratoEcHkbu5Tsm8dwLhoHtiyUknFkAJ7mRymvheTfHvvoDG1+ciJg8utcuYtIo5IwRaDW1RC3XeXj9EYR+ug69rY2sa0u4euGZVKvBrH9u9E6J+e1uyCHB7P9/S7j721MGXWG/8dJ4bghfxG3PX4i2obt3VQoLAQGGtNkKEgIkCYzBtdtrNbWE/2sh6Q97EAZsulVBP2ACWlMTcf9YRNQSaJ9ixqyUlKQBj2f4fQR+sIjsFxsIKO67PUy3GkgDBLHV8goS/lNC3T5R5sttZ1qaVBW1ugaxt0pnbwd/+KzljMPvoTM1kIhXFu9UG0gXhKD6mhnYDqsj9Jj8gbcfANuWcyixMay/K4n7D/qQcLmd79py+PyDmSS/X4VWWIqSGIf7XzJTIkqY98EMbDMaiLzf2mMSjRweRtv+GTjn7ZhM928BoSjkvTiekycsZ8OZqWgbN213e3lUFqX3Kbwz8VWuKzi9q+WrC5KMZLUghYZghAXji3Ji21CxQ/MV5ego8m9Ig4ROkv8lofy0GkM3qL5qGvYmg9r9VEJWWYh9a92ghgnLkZFUnJ1B6yh/zwp/Q5D2jjaocg9hs+Hf13ypbZlKtcPYUp4RHmKS/R6K4fILdn6KkpyZhl5U1ktiufrqGbxx7ZOc98/riP3HzokVSuNyqLgHvGtDGPHI2i5ZF2Gz4T1oLGWHKOy331pOjVjCz22ZrDwnh8YJoRx/83dMdBSzqjOJebcdZJaMSDLeIyaiBUgEfrVmt9dk7SzknAwS3yin9P9STL397W2bnkrOnBKOC1nJHfknYnsibPsxP0lGyPJOTXmSnE7qzhpLxxFt2L4LIvrlpQhZouWE8dQe7yUspJ26klBynqhDKyga8HhySDAV54+idaQf5O5HLmitlZinhzCndOoYfGF27D/n7rTirxwUBFHheyyZDZdf7AL4o4PYdP8k/IdPRklNpuGiGVR/lM1nNzzKC3UHEv9i36UGkt1Oy9nTB47NSDK5lwfy6Oi5PDbrDQpvHY0cFIQcEY7h82H9aglpNy2k5sJYbl51Cu2aDdHpJfitX3nn7UNo1hzMffTQrro3fZ+xnPXEF9zwyNt0HjRqV1+OXQ7dYeXrFaMHJDGA2gNjOD/8F+685f8IPLKwB4lJdrs5uWhrl0vXdnr2pe52E/HaEiJfd9A6vRPP4ePQPR5cc34l6lMbkjCITmlkw+3heI+eMqC6iNbcQuxziwlbpvRQwmjNVIfUUcDiNTjWVdFw8mgz2bETrqbW2moOHtaHrn67p+FPI6w4VEg/rcC670zGPrSS00IXM90GspCAQNY1xuJ09y2h3HzSeCSNAd3YjhMmM2VUAbc891cyTt5IYAnkPpSDYdOwVWQx4sl1GH4VbUM+SecGsH7aGJoPshER7GTs8Ru489MzyPhgBTrmm7X0apUkSwPv1E3DsbGBXZva2PXYNCsIyyDzELoF/rLmPCI/WcG2dotIjKNpShQB9UkErC5DrandZXVThqpi/3wxcZZplJyqMnJZNGp1DYHlHgqbXDicHqJjmmm5RKF+7GQSn1nZryW8heii527EE5FFR+pmN9OqU3VYNFEFxYMOfahl5UR85aPxsBHYUyZj+3LH1TO01laE17vXK84OW2TbQcJDv7Do8cn4DWUziZkYEVzfNXx3aygJ8dTMMAj5bmCd+IBqDz5NwVWm0XGSQWi+F0MYZF+XR+RKjeKrRlH9TiIdJ01F7+hA+WUdgVUqlXfpOBUfWU+VmLE1Sab8/0bz0PiP8Bky614fNWidesnppOihGej7jh/0NdkZCEXBc+xU6i+ZQdLECtIf63tS99aQQ0ORj2kg8KWQPq0sLb+Q0MU1tCZaqD16BPo+45Acjl26budnyxDtCv5UU5JcqW0l8gsbcffLdHwbRcfqUCwzGim5bjxKcmLvAwiBNnMUrSdPRNjtJP8rH0eRpcsyax6lwtShWdFaTS0h7y1FaOA5epLpJu4gDK/XHDzd0rbXFs8OE9kACHr3V65//BI69O6H6PqY+UjRvYs3K05OJuvV1n7boYDN2TQZsXAVbfck0JIio9U3YFmcR86tuaCZjeKOSoOLMn7GH2De7IbXi23eEhJu9FB4W7ZZF2Sz4T1iIlde9DF24Wd25X5E/6c3OQhF6dMFaT1mDLef9CGV++3aB79fjMniX889yQu3PkPVDwkDFujKoaHYP1E4MC4f58L+uxK0wlKCSnwYEjSODKD9iDE9BuXuLAzdAF3QnOmg7tIZ1O4fTcgnazCWriX2H78w4oEVON4KxpvTyfq7ovEePaXn9TYMlEUbcFZ6aTgwET05uieZWXXyz3QMSVIITIvR+tUS7PUeGk4cNahat36ha2g1tRiVNXtlvdkwkQ0ChizwD+CsSeNHolnZfsxHCOoumc7G5ychp6eiLFhG3ONmwkB3u2k7JIe2uTFsfHEqp137DS2qA9UuelSWawVFKAuWgSSz8dEJjL9/Ba8U7sPSjlTK3hnRkxyEQHK5aDh3Chufm4J68KSuB0xJTsR+cSWPrz+MpCd3b2sWmJm7TWcE8UjVEdx97Dkk3j/wMJX8W7N5NfUT5r8+Y/ukp2tYFqwksFJF9oIwDLyjE3dOSnorKEnxKFGdNIwzUB2CyPd69kHqHg+BHywi60E3ok2h5i8eWs+Y1kPJQvd4kH5aQVCRh4axLvSUGJPMCk0yM5wq+ecMncwA+HU14f/dRNvB2WYN4k7EzXS32+w0aGrdq2Jnw1nLPuA5biplRwqyn6pDD3ZwzBs/IQmdEwI30GEIri08DXGm1iO1LzkcGH51u0Fm/YAJTHt6Ke+umcy0EcVseimbsI+2ylZOGcPGKy3cPOW/xFhaWNieTk5AJff8eAI5dxSbfYJbQRqbTWeCC9tXy9H3G4tldTFtB2USUOVBWrqB5tMnknRZPokBTRwWvI4f27JYdawprFj7UiA3Zf6X526Yhf2z3dcoby5UpvLDLM5JX8L3505BX7l+wF3kkZns+94qlrck0nG8NqgBwMJmQ1itu3x+Z/tp06ibIDHirmUDJhEku522Y8ZReYIfpdJG+mt1aHlbWZOSjDQmk8axIYTmtiMVV1NyUQYdI8yYmeiQyX6pGW3dwG73thAWKx1Hj0f2Gli/3jnV2S3Hk5wBiOCg3yV+Nlx+wRCJTJKpvWwacXMLMfx+Aj+GN1O/4j/tMbh1Gy9s3J+4K9rQw4MQqo6+sWjIWTElJYngt9s4O3ohN796IWF5Gq6rymjsdGB7IayLTISi4D9gHCVHWglbC5ff9iGRSisvlB+E+6F4rP/tXXagxMZQ+WIIHatDue6UT9GQeHr1QVw+5kcybNX8p34KM4I38fCio8i6dB2b7prAk6e9hke38tg9ZxH89tAmmg8ZkkzFf7Kxzg8i8oXBj7Uz9hmP0PQudYrfC3WXzUBSIfxfW61dCISy+b4y9F59unLGCArPicEXopN914Ze9WbKiBQaZsYQXNCBUt5A8bnJXWRmqbeQ/kZ9j4LfoUAaPxJ3ciCuVdU7NUNzC4SiIMfGYATs3ICQoWK4/GKIkNNTOOb/fsL1Hx/t+6bR/pdgJjx/DUXeSB7++nhiL2pALa9AX7UBbV3e0FP7QlB4QQJnRy9ExiDq4ArsDT7EeRLNS6KYfPdSOk6eBphxD+XbZWT8bQXtiaaLkO+NIa8ymuoZ1j7dBsPvp7UohItO+poUaz1p1lqemTyHbFsV/20eQ825kXxw8RHk3FFF58FjuOaEz1nsNlte0q/IRUzaveUaclgIo6OriFw2tIpy8fPKHSaxwSjTDgQ5Kx05PIygYpXoeSXdn0dH0XrmNKqunEzVlZOpu3BKr1IILb+Q1EdXEVAtseHBrF5V+WphMWFfbqQjLgBPZgzJr3S7mf4IP7mXhu9wJb++cj2BvxRRcVwC0tjsnbsIbO4IqKgy3c091O4ZtsiAiltn8shF5uDcBi2Qd6um0nlvHLZVRWhNLTttomsHTuSk5+eTZjWTANVqMI+9cSq+EIOkr334A2UqDpLIurv7zd1++nRUm0AYBroiCP33YrPdpr+fSwh8R0zGuL6O61O/xio0mjUHD714JjFPmnE4JTEB3+uCcLublkuiqDwkjMsu+YT/NWfQcHncoFy+oUIoCkX3TCGwFCJe/vW3eRCEoOTuGaQ+0n85xNaQo6PQUmN6kKYxYxxtf28n9Cq9R8GrHBpK+V9y8AeCpR38QWa8XvJB5GqVgK9W9njRSU4n5ZePwzOhg8CfHcS+3bMbQA4Po/GoTELy3L3dTK9M5CKJ8M9yB+Va9/peQUHUzhpFYIWK7averqawWJEyUoY091RyuZAiwn6TSefDFtkQEVKg8d/mMWgIwuV2rkxYwJjHVkFM5E6TmJKcSNQDRV0k1qAF8uQLp5LwyCIyHi+garqN6hky2U9X9bjBXXOXElTUiSEEER+vN9fRDwlITidyxghs36zAcW4Hf3vuAha605nfNIqYhaYVJLlclD3r4tCoXCofS0dfm0vMs4v4zxVHAFB6VMhOfc/+YGgaaa/XDJnElOREih6cYapYDBGlf5vBP86ejTZ+4MZ+yeEg/8k4Kg4I7LJ+5Mw0qm/xYXsmrFfVvn9sCv5Ak7TiX1pF4vwO7A2gW6F2kkL9BZN6lGDobjdx/1hE+iNemsf62fBQVg/VDq2hkbBfa2gcFYiW2tMyM2watfupFF2VM7Si2S3Hbm0l6uMC3DEKjedP7TUMxlD9eGNdQ0ow6G1taGUVZmZzD7KB/lxEJsnIIzN7fez8zyI2nRLDlfPPw62bcYAv8kYjWtoxZozboYdpCzpyYjgxcnmXIsUjGw4n9kVzPJlWV0figwtJ+MZH3uVxVF8zs0thwVBVpP+tJOTtxdvv5xOC/HvHMO2DDRS/k4N7Sgqxzy1l8Xlj+akoDf2BJuTISMovHcNdI7/gy6pROL/erMGvm31+TWe6SHl9cLVnW593UDAMs65tCDe9UBTW3xrLM6fPRgQMXtZoy7qmHLWWYxwe2pMG3rd+1jikwgDiH/mla42NUyKR54di+6pnPFIaP5LKfQJwVhk4vliJ7nYjfl5J3OtriVypITRoTxAUn5UIU8d0u7e6hr5qAyPvKsVRqrDhelcPdRNtUzERP9fQlursRWYIA0+Sj9yrIuk4edqQpwtpdXWE/3sJobkd1JyahTR6K1fTMFAWLEd1WTFmjhu0O26oKmp5halztofM1PxTEZlktdAwqQ9SEgLviEhybsnlvmfPYZE7jfQHPdQdmsT5r39O3evheI8ZuA1lW8ihoRjX1/HkpkO58odz0BDYLWpPxQPDwPrTWojv5MGrZtP4WmDPosoBLEI5J4P99lnHW/89AGmVi6n3LiH/0YmgGYw4bwOWSxT0pibciRoWoXJt6jdsvH+seUNvfpDUkjLUqupBf6+aq2aiHTBhSNdiKGg/YRILjn6Cy745v2sOpzwqC2PGuEHtLwsDzdDp1QbQByI/zSP9xZ4B8eC3fyXquV96kK9QFGpmBKPZIGJFWw/3UWttxfHJUlLmNmBrBM0OpUe5aD+hZ6GqWl1D0pPLSfhCZuP/WWk7bXO92WayD563Ds1poXNSCimvbSJmgdw1cs5waJQfqVN64yQ8x/a2rrYHQ1URC1cRPbeA2n1CEVO2ItnNZGYpHfrgly7rrPP3Fyb4UxGZ7vEQ8mYfWTPDQPlptXlD1uq8kzsZI6+QiJ9reCr/EO7ImseF//iI/McmosTHDepcQlHY8EAG+0ZtIuQ2G7ZyK4XeaK5P/4aCZ+LMWZHCrBErunMiD07+CBmD29K/JPe6+MEVdEoyG64J5oeNGcQs1IlZ5GXZrZNIH1vOfu+soPSWydDciqGqZN9XyM3vXIBbt/HM8a9zxJxfKXx4ap8dCtuDkhDPhLPXYMvdPeqxckgwk29fRokaRPbz5hQmoSi0ZwSj1Pcsq9D3m0DzuT0lso3pY7km+hvea48kdNHA4+W0hkZTsnqgdcVE44kwz+OJCujdPaBraOvyiJu9xrTOdKgfK1N28ege1pnu8eCYu4ichxqo3teg9vIZXYWselsb8g+rCNjUQOfYREK/WE/cNxKic3M9nGTQmeqj9ASD/FuyUA+eNLQxdnV1RM5ehjvRgfu4rUjWMEwLawcUkrckAoyqWoT6+zXG/amIrAeE6PkAqCpKfBz1J3aS/IyE4feh5RcScWYV1317FlFKG88c+zp1LzuRxo8c8PAdx05kRGY1Be5IamYEc/us93n5tWN46epTCA9pZ8x7BRQ+NJ1N907kvlnvECR58BgWrv/4fAKLJTbcl0zHSdO2SzTNZ0/lzKmLSHlLwpXXhOzVUdr8dKoWJjqKefj816l/IwzvMVPQW1tJuX8pL9x+Kj+2ZZNtq+K+E96j5IaJQxpB5h4Xx/frsnZIHmcwaDoqh7uifuSijy7u0lIzVJX/Z++sw6Qq2zD+OzEz293dxVK71IIdgIWKiordgoGB2ApKiKggIragYmCLhYWCSHdtd3fH7M455/vjwMKyvSzqh9zXtRcXM++JmTnnPu/7PPdzP3Z/JLcrvTIk5dEwsZqy20ahjR5M1rMJ3LD8O4aYTOyqD0At732AvCNIbq6UnRWAZAanVJXyAQYKbxmCFBbcbqxaW4vN11sI+qIMQy202EPOeHuazxjcNquZlkn0wmKqBlrIeCAG2e9gv1FVQUnNwDqlhKZRETj8sI/Id2oxlB4uaULQsLi0kHGlSNHt8Ye37QG0lmZsvtqCXWYtRZMHtF1qHvmZw4L1h3ZPQgiqos/O8gv/MTL7T2Yt5ZAgDjzhhlxqIGzWbj2zJQjkPZKA2UXT27MdgYz5Cbxy2bsA7G4M4NeppyD+ubPTY4uDosie4EKjj4VZZ31Jg2ripT1nE3ZXHkp5BZKDA8mzYnh4/Cq85CqMgv7jP5t2AY5XV6JUViIH+pPxghOiqBL0UD2WjKy2n8Hfj+AvS7nQeRcrShJIfT0a1w1FpN3ixfOX6x2aDqHEYs+8vefh85oR+fcdiIOiSL7VgbljP8VKbGFO8vk4vmjXrS+W5OyM8Wsjxa8H96jNW1+gnjKEjMusiJyTilJW3u14ydOD1IU+fJbwBhEGAUkQaNIsJLz+IP6zj81mCfTZYPn1w2lyE/D9rRptxwEkNzeKLw3D7CzgesCC7abMdmLlQ+dWcW4I1SEiggLem8wY1u9r46MmBweScZ0vTT4WopbWtDHClP390JrMKKWlSE6OVFwYTfHpSruu5cZCA2Fv5rYuw3sKycmRhjERiC1au65Roq0tjWfE0GIj4rgmFc3XA3VfaptQh+TqAi0W3UXj0HY2Nojurv0ioD0piKVzIpOcHEl6OZTnEr5gef4YEtN8CV/egmoQGbdkLQfqfEh5aQB2n2/VnzSnD+XMVzYQZ5MFwJQ11xNx+1YQJWRf73YXj+TgQOL8KHx/E7h81k+Em4q4f9skwu4pbHOxS+7uOHytcKPnX4AuyXj/7osw/Lr98BhPDzKmhuE8ohjTYhdMP27V3xAl0l4YzuIJyznQ5MuXc86leIzGsCFpXOmxFVux45jF7sYA3lt5LgHP6eLb4jtGcM4tGznb4QAPLL+l2xvffP5wpi76lPfOHKOXsXQDydMDXJ1QUzKOa2MXwWBEGTWAFnt9+VY62EDAkr39ovBvunAEpUNkAr+uQN13mGQEk4nmU2MpHWJCk8Bzm7ljw0NRQjl9MAWnWKFJYFOg4bUqo+2MVpQwj48j+yKBwG+1DqUSoF9bebfF0uCtIrYItLgfflj1lcwQJZrHxlHrL+P5c167NoSytxfVYwKxWAk4frS19bwEkwnL6AGIZgVh07625ytKyB5uaHY2x+R1dlJ+0RkEgbxbBvDS6E954svJCLcYoUXgyrdXM2rRVhylRq5028LNs74m9ZVhyIH+GErqWLYvgSbNwO+10UQvOqjzumwYgV+W0XjJiDZJgOy7YxkzOAXHHcV89chY7t82ifD7its9sbNuD+cqj8OlQc/8NBHj2r1txijFJQTN3kbdGk/Gzl+H+bzhADRcMoyHxn9LrWLN+++Pw/nnFKLnZFPeZNuOxJo0A9saglEQiLbKp8lDAUlCUxQ8Xt3AvpuieGDXFT0KjJfEG3gr97QedwRXq6oRGs0oYwYixA/od1eKQzjU9dv0w1a9sH7ehn4hMdHenspIGc+tzahHlQxpZjOGX7fjvzwZ+1yVwtEmmsfGtw8FqArSHztbl5r1vgKFl4S0jW2pCqYfthL1Rh0540Wqrx7eYZ2oUlODz+JtRMxLIeyDcqSqw1nGZu8WCi/w772AVlUwrt6K5y/5FFzoT83Vo9omKAqLcPg1CesypS1ZKQrGolrklLz2pKseLN8rr/rbJBr/KSIT7eyIuCQFERVVArWgCJfdEu5yDT/kxPDx/RfwZsFpeBmqeGXcezh+VEf1QFfC78xgzrzr2DhzBMqBFIShAxg6YxcTnHdyw7xVZD8+rPUCcshUyXk+Aq2+AdtNmYTemNJhPMlnQxMztk+kWZMoV+ywyxYRrdvHw0RbaywjanGR6zA0WPT+i7eXEmQsY/b+8/H7oYL0+yKpODOI2/z/bLf9jO0T2XD5AB5672ZezTmL6JcKEYP8yfk0lqaLRqDuTiRoSjFBKwu7/f48T8snZ5NfjysbNLMZS2Y2ikmiLM6B6osGHZtDw98IOSiA6vMHoAlgtSG50xtSKSvH8dNteG8wUzrUSOFtce0bhWgayoEU/FdmY6iDRk8Bybt9IxN11wGiXyqkJlgk7+GRHba801qaUcorUA6k4L6dw3EzTcC6QuszcViycvD+YB/GOpWCG2PbauGC/bAqaPtg0Cy6V55SVq7Lmpwc28k3lMpKKKv8W+Jm/ykiU2trqXvAm1lJFzL/4g9JezeKG+/9AUlQMW9yxbh6K01XCNy99lqqFFuu99xAwbkKSl09Lu9uxPqbLUju7mQ9KnKh8y4Avi0ZTPDKUlKXDyX3ydE4fr4D61XbSX44BKevLVRfMqTDc5F+30HobZnct/o6WjSJp+9cQdKzRyURBIG0R2KYN+Qr5q+7AOmvvVRdNIB7Q37j99po3N6xodnTlsAfGwi8KwUnqYGcFld+q4mhWZM40OSL/5sGlJR0/J/dgHhJNWpRCYkznFg49FPOmr2e+stHolZV98iu2fy2NyHPdh4b7PBzurpQ62vQJVGqhvL/0PhCECg+25dGdxHvjQ2odXWIVlZoowd36Mp6qKws8ONc5EaNnEs9aRk7rN3sTPFyxmIDdjkaaiezWktWDoEv7EBuhIz7otu1vDsSzt8fwOcXCSz6bVzvKR6T44dSU4PVt1vw+bWMvEv8aZg4EmlAJPXBdmgHOrdRkr09aRoRjhjU3otNqaxEyS047gLa/xSRAWhb9+I1tYHpa69kzrCvCDcV8V7RGIKW6RkxpbiEyKl7Wfj8JOZnjif83ebWqbPk7k7aYh9ejPuMEos9K8tG0Piw/mSdEr+Wmdd9SOrzccj+PkTOz2Dv19F4TU2n8ZIR+sU/YmCbi1utrSXigZ288cxE3so7FWO1oKv0D07tm8fG88CEVXxTPpSY+cVoFgsttgLb64P5ZtVobDKqMFQ0UfV4Q2usbeEnl3DgfA+m/XItb302Xrf8OeJ4ZVcPZfYpXwEw0jad22d/QcoLcT3qDGS/clObRik9gpc7mgiCAk7bivqnAcxxhmhnR7OTgNcfFXq9p6aBwUBlpA1Zl7hSd8VIZH+/dttZsnNx+2AHbvtaKB5mpPS6oa3dwgWTiaLRDhirwP2L/V2WTqlNTXgv2YL3hmYS73FEGNpxLaxSU4Pd51sJ+lrDZauMz5ryfvl+lQMp+C7bhyoLZF3qin1SZZcxTs3ORu9eJXVMolpL80FroJ71Le0L/nPB/kMQDEaqJsURMjWZlOVRbZ0NDkK0tUVrboHBEWjb9lF75ShmzF5BvWpi4YJJeHyRhFJVhezrQ/XbJp4I+x6AmSkX4TJdRDmQgjg4GhSNZk9bRr6wlW8+OwW/ue2D6qKtLYgiSQuiCQkrIm+TL+eO20GsbR6f3zXucEZRlJD9fci83p+xl2whxqaAAIOe3VucezbCdQKWvPzWuN3Rmajs94IxGSw8HfNdm8zmg+/cgt+8Y8/yHQ1BlpEOVitY8gv+VWUtnUH29yN7cgAB76a2iW0KJhPK8GhK42xosQXfdXqH+nafSRCQosMpPNONZgfw2NlCo5tEdaiI1+YWjKu39vhcWsYOI3OiSOQb9Wg79/fXR+wZRAkxJpwmP3tM5U1oW/e2GyK5utASG4ihrAElMa1rIhUEZE8PNHvbHsXyTmYt6Z7IZF8flJIyRFtrfbnTyQ8geXrQEBeIVWkj9f621PpL1AarhD+ys00aXYyN4tSPdrZmN9fVRrJ+1iisv9YD+lrCYByezyflqwjcd5kpG2jCb2V62/iZIGA5Kw7l4fLWwu8p664j4tad7c9PlBDiosmYLjI77hskNBY8MxnHFV3LIiRnZzAaiPihgh9SBiAl2XLNZWv44NszCX56a/9kFwUBydVFN0P8P7y8ZH8/cicF4P9heofxTdHGhuqLBlEVLuKcouL0Z1aHlRGSgwPllwygJkS/ae2yNdw+39frRITlrHhyzzXiu9bSLz5jvcbB61KubW7TdvDQe8LB5NGRv7Xk5gqS1KFbsuTqAi5O3ZLZSSKjayJTTx3KkJd38d2qBIIXdd+bUD1lCCEvJbN29RACn96k/3BH3PCirS3J82NZNO6DVk0YwI6GIL5/9gzsv96J1tKM5OSIWt9I1oeRPD/0C74qjyfxlQHt/MCkiFBGf76f7EZXcqcGwb60Tg0DRRsbim4aQrMDBCzc0aOlnyDLNI0dimoUKBwtYV0koElgn6vivKng2D2sBAE50B+1pOxf35buSAiyjPnsIdQEGmhyFRBU8F9dibo3pb1zxMHZWclwG1QJPHaaMf61v+33LwhUXzOS6hARz60tWK870MZZtjeQ/f1IesAP110Czh/0U4/W3qArMjsaooQ2KpYWewM2KaVYMrPbD7G31/VmcucxvZPyiy4gyDJp18mc7XCA2ZNXoH5ph/mC4Z2Ol2IikJ4pJaPWjZDFKUjhIYh2RyjhBYHMhwe1kpiCQHqzXl4UZ5PFbc8eLG0KCkCpqkZraSbgZYm5qedzsetOqsNF/cb38kQYFkvKO8NIucMdO6mJzIcjERIzSZ03lJzlAR2WR2ktFprcwXN7c4/jV5rFgumHrdilVBHxSi5+3xbhs2ADTj8cQC06+AQdMRDZ26vnX2ybA2hYcvL7xROspxDt7Xs0TnJz7bSSQfL1pni4Eft8C0HvZ2FVoZE9wZnK60a0FvMfgmY2I67fhe+KVJzTLBSOMlFyw8GY2MGZhjg4mtoAEe8NZkyrt/WZxEDvnBT1Uh61QYKe0exFrWW/4GBNpmqSuz+2qiCX1YEg0OLl1PGQ2lrUgiIE87G17TuE405k8+bNQxAE7rvvvtbXNE1j5syZ+Pj4YG1tzRlnnMH+/W3X/2azmXvuuQc3NzdsbW2ZMGECeXm9FPt1AM1iIfr5Mu7ecjW1qhX3BfzKOfP+JO+x0e2lAaJE4kP2JLhmIj9oj1JeQcrTDiQtDkUYOgBBlqm6bhR3XfZDK4nN2H0Z315/OtM+vpnfamLwkqt59cJlWH/QQNntCUiuLgh/7cJ1ipnH3rueoAW7abh0BFHflzLgjQO8dvoHLLl4Ga99dR7GHWmkzB3Eixet4LHY1VScHoA2enAbQhOsTKBC7Nzd1F82slffhXIgBUtuXmvpj1JT00qGUm0TZecEYz5vOEL8gF6TkuzrjWBv16tt+grJwYG0J2JRzozrepyTI+ZPbCn4MKBD4lNLywn6ohTTjzuw5Bfg+V0mjmkqtYEC2TeE6o61R0sMSkux/noLQZ+X6MHxq3ypu3wEUkwEOec5YVugYVq/v1+W2JbcPAKf246hDtLvi+zQyeW4QtMQ/9zZbdMYAC0nH0NtCxZbuVP9oNrUhCW3AKG+8ZhP7bguLbdu3cqkSZNwcHDgzDPPZNGiRQDMnz+fOXPmsHz5ciIiIpg9ezbr1q0jOTkZ+4MX2JQpU/j2229Zvnw5rq6uPPjgg1RUVLB9+3akTrIjR6Inwf66CUPxmJbB7T7raNIMzEk+H/cH1VaP9ZZz4rn05V9597UL8Hh1I7KXJ8NW55Jgm8aBJl/e+GocV01YR4JtGgoCD+26HP8XRKSaJpQDKUiRYbgtL2Gy+2ZAF6e+lHEuhvkurdlEwWSicGUI82O/bD23BVnjMN1jovg0N56c/gEGwcK9m64m9FWVMa9vZWN5MI0v+WK9ekdrjWjVO1ZUrvfql7KcVogSsrcnFacHUOcnYp+tohgFakIFAr+v7TD42/r9ynK7uMnxhDB8IMm3WOO0R8bnq4z2MStBIOfJBPbdsYRP6tz56IzhPXP8EASEITHkn+OIxRbsMzXcf8roNHZmiY+k4FRrNAFsirR2jUr6A4fs0DMuk/D8S8Rp5bbjWjnRV4hWVojOTliKS7teCh+8zjTbtrZL/4oYWV1dHXFxcSxdupTZs2czZMgQFi1ahKZp+Pj4cN999/Hwww8D+uzL09OT+fPnc8cdd1BdXY27uzsffPABV155JQAFBQX4+/vzww8/MG7cuG6P32mJkoNDm9owOdCfpPt8efK8L/GSq5mddgH2lxQg2NnSslJ/khgm1es1km6u2H0NN3utb3e8JXlnod1oIONGP0LeyWktFTFfMJyCa5sRxMNfs/0vtri+ezDOIUoU3zWSG+/8gbIWez7ZP4yQV1VUk8SFS9YQbiri4T2XEXhXOYqPK7VzGnko9GdKLA48t/k8fFfJFI0UCR2eg3Sz1C8e7R3hUNJDkwQa3CWqI8Fjm4rdNzt7Zf3dPH44hQkGgp7d0u83nxQTQX2IE/XeEp6/5Lf5LoRhscz57F2GGGWi37+L4Ed73jsAdNePilP9qQoXkZrBbU8L1n+0l1GIVlYU3h6HTbGK89rM41ZcD3qdZvLd3jjvF3B9v58SNf8UOiCzfwWR3XDDDbi4uLBw4ULOOOOMViLLyMggNDSUHTt2MHToYU+riy++GCcnJ9577z3WrFnD2WefTUVFBc5HqJsHDx7MJZdcwqxZs9odz2w2Yz4ii1hTU4O/v38bIpOiw6leqND4jSee7+1uvQhFW1uSX43ipTErefzd6/FfsIXk14YyMiad6js82tTYiYOjSb7NAU3UcN0hUTFEZULCdnY9MRTT6m2I1tZtLm7J2ZmasyJ0LZUGDn9mts/kiBLqmEEUJVjj8/wGvZD4eQfuHvAHXxcOwXhtS+vsQYyNIvb9ZEKtSvAy6EmKN/NOg6m2vWpWIRiM3RJQzeRROH25q8PYm+TuTuU5oQgqOCZVox1I73Z/kpsro9fkU2B2IvN08bglAiRnZ6rPjcRYo2D1VxJqbS0NE0fy6aIX+aYukm8vGNZhAPrQOVadHY7TztL2hpAHZ2cFZzrS4gBWJeD9S1Hr0vzQb10RJRH8cUG7Qv/jAdnXh+QHAjCViwS+ldph8fr/DUQJ2ccLzUbXWvaGyI5LNPaTTz5hx44dbN3aXi9TVKTfkJ6ebYOnnp6eZGdnt44xGo1tSOzQmEPbH4158+Z1SHCtECUSpzvyWtgHVN1nw+NjLiHy/jzUqmpypg3mqVGfM33VtYS/vIvCqSN49JSvefPFi3Hd1/bJre5OJPzuw/93FQRSfbwxFeoFw0fenIIskzU1muduXI5RUHi78FQat3UQL1AVxD934nOwwih7ki8e71n4vGUc1unlqDV6TELy9CB/tkBtSTB7H4+hdJgDE6aupUWVMNb0fPnSeMkIiq9uIvh5BW37fmQ/XxpjvDH8fNgRVXJ1oWQYOH7a8VNeKS3F4WPdlcEyIJi6iXFYrAUc05swJOnf69HEVnhVJJMcV3HdE9Nxajj4vYpSjzNwQvwAsh8RURSBsCdqO61GUCorsft8K8LQKDKnDyT0zSxsvt7GuOAZ2BaqOGR2IVFpbqHOT6QqzBOPnS5Y/5l0OFusaWg79+OX6UhDQgQlcQayJnnhscsV2+05FFwWSpMr+Pxl7pQo+xuW/AIiX1BJmhFE6vQwwl/g/5fMVAWltAzJ17vLbGZH6Pdgf25uLtOmTWPFihVYdeGlJRxd5qFp7V47Gl2NefTRR6murm79y83NPWpjFSz6tk5SA4tHfUz6fWFo8VE8dP3nPPvDRMKf3IMlLoILb/6Tn8ticN9aRcVNCaQuHtnqmS77+5E9azTV14zSU8gmE/WDfBFj2jdGLb1lOE9d/zFGQSHJ7E3h4tAeLf38fq6mbKCMqaQRDDJlK30pnZJA+t2hXBu2BbvHrdG278ftjY2suz+B/DX+lJ0V2COTPSksGKf7c7hjwHpqwvR4ZOrUAIpGtLVdKb48ErlB6Ha5olRVI/y1C/tPN+O2sZTqUCuSHwslfXY86ulD25TMuO1qYPKz03H+WH/AiVZWyD49z4w2+tiyZ/RyPh75Nhi7afGn6iRtl6ORMzkIwSDj/eIGHD7qWmen1NTg+1MFhjooGmmg+NpY3X/uiM+hVFVjWr2NoJWFGBqgeLiBvKsOktj6TlwwjiMshUVEPn0Au2yBtPvD/v4kQD9CM5v7lM3sdyLbvn07JSUlxMfHI8sysiyzdu1aFi9ejCzLrTOxo2dWJSUlre95eXnR3NxM5VGdY44cczRMJhMODg5t/tpA04h6pZapG66hRrVCQiN0dDZmZxNvZ51C1Is5CLa2GJ4tYYRtOtd6bWLU+7u55+HPWHr+cpLucwcg/9IAFl3zDnc++SXCKnvSl0dwz8srGfPRLipvGNV6ONnXh/Drk3GSGlAQeOPT87H7/LDbRVdZQG3nfgJf20/+uY44vF3Os1HfMOO+T3j8is94+5uxaDsOdzvSRDjn0q1c/vDPEBvW6T4PHTPpSWfu8P2D174bh/3KTYhDYrj8vL+OGihQe2Y9gT92kU0ShNZslBQZhhQdjpKaifPyjUTOTsF1r0bm7VB438jWbLC4fheub29sJUfB2hpLQc8ttg/hyg139HgZ7fFlEmZnjfoLhvR4/+q+JHzfT8Rtj0KTm0DWxU7UThretixJ01DSMvH9KA1jNTQ7gnOKivz730tih6DU1OD55hb8f20m8R6nHtuC/xvRms1s7Hk5XL8T2dlnn83evXvZtWtX69+wYcO45ppr2LVrFyEhIXh5efHLL7+0btPc3MzatWsZPXo0APHx8RgMhjZjCgsL2bdvX+uYvkDdl4TPKgPzX5jMu0WncL3PRlqmleNwr4Alv4CCq8O50fcvpv12LbNevp7d1b6tAlfNWv/XfWcjP1QNwkuu5l7/31g8bCXJTd6sXHEWbpsPFgKLEomP+HOdp55B/LFyMCHv5x++wAWBjGeGk//I6E4dYJWqanxe2EzewnDeLx6Nk9TAgsSxBH9egzggUncccHPF+FgR5zju58M3x7UhuI5Qf1E8j4/4gS31oYQvK0W0sSHpXht2VPojqIfHSS7OuDg0IO3qnCwqrx9F0pKDRe7FpdSHOiEczCYr5RU4rthExOw6Gr000h6OQT11aLs0vFJZ2aNlpTAsloaJI8m5UMOstWC7zbrHZKFUVuK9QaFsUCdLFUFADg5s149BqazE9qttBK6qRGqCimiR7GsC9LrHI2ZnDfGBtNjqMzGHr3b+o5UMmsWCvGY7Mc8XkzvWFm304GMqIv9HoSooZd3LPA6h32Nk9vb2xMbGtnnN1tYWV1fX1tfvu+8+5s6dS3h4OOHh4cydOxcbGxsmT54MgKOjI7fccgsPPvggrq6uuLi4MH36dAYOHMg555zTp/MSB0VBZj526XWUxDmQ/WYEMy/0wfUzG5SUzQjDByI1aSx8+mqivtuPWltL08cuvHr6JNzvyyAhMp2yhMGIf+4k+e5B/Do9krmDv6ZZk/jwk7Pxe34DrbekquDzB3w5fBjBNmXsf2IgxszD8Sdt1CCmXvwjVkILX6w/F3H9ro5PWlWw/XwzlWkxTLnresLfbab0mUYmBe3kzd/OBmBxwHJm7L6MwOX7ULq4ieRAf1zvy8JVruPFFRPxT91M3sMjscoG8b5aAoIqOMRlRVdEUplvwbEhvdP9WU0uwrDz8LLQOq++XUxMSUwl9MkcxLAgcs93pf6KgQStsmAqa4TUbFCUHol4U6cZSDnrNSrVRkZvuxXfN3ahdrvVYWgSGDqpChIkicJxPtgVeWL3V6aukTpErge7HwUWe1I6LoTaIIHsCY54esdh9ctuhAFhlA424LG9BXnNDv4tRTKWzGxC3mgi7Z4Q7AeMwG3ZvyOjKXt5opSV9/hcjiwB7HbffT2pY8GMGTNobGxk6tSpVFZWMnLkSH7++edWDRnAwoULkWWZSZMm0djYyNlnn83y5ct7pCE7GtrowcQv3cGniXGEzjMTtiCJsoujCJlagFJWjhA/gIbZdZzhtp/f3x6J1qgvqZTyCmy+3EzTWhcS746m+QqVsI3Apj0E3ezA3InX0egm4P/ytna+hLZfbKboL08K7T0wph12oBAHR2O/II9wUxH3fncjYRu6LyBWdx0g4naB3McSeC7qM4yCwqsXLkNBQELDybYRwdYGjpCVHI2MG/x5wfddnth/CUFLE2kcG4caV0vw1CJdjrLn4LaiRN0Z9QQtM3Y6u5AD/RnrnciGeyUUQcAyIBh5bwYdza00sxllfzK+KUYkP29qB3tScKoTYrMTzU4atgUCohncd9YjZxSiVlS1I8SwVxVi0+/GdZ+C73e7OyQ/0coK0c0VraWlTVZYDvQn7yyRsE87zpBqFgsem2vIP9uR8uhwbAs03Ne0dVq1FBXj/EEZTgkDKTjVhuLhBqyChtHsCLaFml569C8hsUOwFBUT9gqkPBBC40MjCFrWcd3o3wmtobFjEjvYSepYcMLXWp5lezXln4QwN+ZrAN4uPJX6u9zaeKNrowdz/ltriTIVUq7YMe/dK/F7sa3OSTAYkTzddWeJ4QPJO8sev1+rYXdyj58wYmwU9q+XcrPXelaUJFB5mVWv2rDJfr4kPuTPjHO/Jch42M9KQeCRvRPxm6mh7k7scFv19KGkXS8RM7MIJJH05x0JfaS2nURAcnUhbYk/oTcldzpbqrwxAeNVxdhdmINoY4Ma6t87Z4aDSRHZx5va4X40uEpUDNLQ7C2IVTL2WSJOqS3YpFegZub2SKcm2tqiWSxt/fD9fEl81A+XXSKu73Rdnyj7+lB0YSAN3gJSE7gkWrD9ZV87iYgUFkzROV40eAs4ZGq4ftb/gtf+hOTpQfq9oVhsNUJXNiJs3P1Pn1IbyH6+1A/0waq0EW172woIi9bCH3xzstYSAE2jssyeckUvl7nV+08yrmwr6xA27uGLJ8fxev4ZOEn1PHrzSnIeGdGmMa/W0tzaNqzRy5rpN33ORR+sI/X5YR16U3WEvPEu3Oy1nhKLPYnvRfdYWV55QwLKGXFY8gsIv38rK566kHu2XM27RacA6M4XA78gdlkSJXeN7jAuIq7dScSt21ErKkme44rLF7Yd6pw0bw9cvrfucslXOkqh9icvncC9PZCKum8S0vYgupOpJb8A66+34PrORiKm7yB6QTXuO0Bu0MgdK5FyhzsZz8Tr9svdtMdT6+vbLUXyLgtErhbx+Dyp21icJb8A9+U78N7QjCZCSZxM2VWD2/22alYuVpUaciO4fZP0ryYx0P31gmdux+svjdQbTLSMHdbr/qzHE1pNLWKLSvkge4T4AX2O6Z3wM7IzuBh1fALRs/cxwXkn2xqC+ev6ONRd7QPjsp8viY/48dzYT7ASWng2+UJsXndqLQU6BEGWabggjjOf+YsRtum8kDkO66vruu36U3lDAg8//iEzvp9M2INbe6afEgTSnx/FtPN/4P0Xz8dl2SadCEQJKToM8dUapvj9jnRwcftu0SnUntfcqVVMzdWj4PpSnC7N771JIvpS7fwfd/HV1HOR1u6EkQMRtif1St3fI4gSgiQhBvqiuNlTEWOLU3oThpI6EEU06bDURayo1bOfR32f5bcm6J5xR2a/DyrILYXFnX7/cqA/5af6Uh0mYqgF7z9rYZt+vVjOHEJhggnvDeZ/LEPZV8ghQaTc7o19Nni8vb3/f7MeQHJ1QbCzRS2rOBwjPSgIr4ywwq7Ags2mNJTKypMzsiMh2ljTcn8FE5x3Uq7Y8d38M2jwt+vQD92Sl0/kjL0seG4yyWZvno36httf/IKiqSPajNMsFsRmDRGNJtVI3k4f1NquLZxFGxtKz2jm0e2XEjlHzwb2qBBb0/BbYyHQWMq59/x12Mn1YENY7TqJe1fdSFazG1WKDakfR3ZKYsLwgZw2YxOTA7aR80Bcr/ohHkLyPb58lDMcef0eJHt7BLNyTDeEIMsdO1eo+n6VtEzYtAeXZZuQd6SBRaHR34Gi01xIvt2R5DscSZztRf5DI9t8n4IsY12utiUxQDltMFnXByF3YMt8CJbsXJxW7sBtj4LFWu9LWX31cLSEgRSNNOG2z/J/R2IAlowswl9Mo8Eb8u8b1nd3k77gYDhBqawGUUR0d0U85KKhKshbE3E50IDZWaLmrIhemxSc8EQGUFlvTb1q4qnvr8Cm1ELpIBmlqqrDsWpDAy7LNvHLbacwdf21NKkHhZejBpH36GhkP1+0hMGMnruZwTY5PPzNNYQ9tbP7DEtYABcN3EPoPDNKWTmlt48g88MYPZvaBSRXF/Kva8EoKHy8YwSW7MNBaNnPF626hrDpW/nwiQt54tsr8Xqn496Uoo0NmdMFzrRPJNxUxPM3v4v0oULDpSN73HlHcnXhtnG/UffjwWWll3vvl5VHQTAaUQaGdH/hapreBDY1A+PqrXgs2UDEfduJuG8n/l9INA+pp/CeEQjDByIYjAjW1ijG9p+rydWAaoKsK3305rSdLGUONbINXFWBdYlGdbhI7rk2OKcoWK/a/n9HYoeglJYS9Ox2TJUaSQ8FHT+9mSghB/ojyDJyoP9h1xZVwZKZjSUrp01LQbWpCWHjbpx/SsE+uRohKqyddVJX+E8sLU0ePpRcEoZNqUJJnETwgg5cOgWBsttG4ZLchPjnHr1syMYGLSYEITGTtLfCeWXEx8xMuQhB0Hg6/Dumrr6R6AUF5F7mj9+qwvYlM4fcMy0WfV+RwWi7DtA8Np7xL6wlzFTMvPnX4PpO5wXMUkwEIe9lU9FsQ+EzoRh/0mUc0oBI5KXV7M3wJXr6QdlAF9kfQZapuySeoAeSudpjU+tSNMnszSfzxrfpWdjpubi5kn5/BGGv61k92dtLz4Qd4yUk2tgcW92lICAOjiZrghNNwWZolEAEx/0yXq9taWeC2XhaDMUjDIgtYKwClyQzxq0pnc5kRVtbCm4djNyk4bHi3x3c7ykEWcZy6iDSr5Tx/FPEZXVKj+x5egxRQowNR92brOsLB0eiGmWETXu6vV5EGxsqLhuM0tzEzk8eP+kQe7T7RfO4YVhtSO7wghVkGfEXDyZ47mbR5xMIWXg4tiI5O5O/zItZA75t9bm/Z8vVhC5UyJwu8FL8pyzIGI/NXWJrATGCQP6MBAyjK/B6SmjNJkphwZhfV3go6Cem77kc/xtyurU+lgZEYnGy1hthoGfYshY7M8CzCHvZzJbCAPyuyeoRGchenqQv9mBR3Ketr2U1u/HWyxNwe6N3jhDHCsnJEa25pf+Kx0UJ2dOd+qH+oEHxSANoELw4sV2crOWcoRTHG1EPVnUZasBnXQ3sTmmzVBZkGS0umtxz7Qn6uhzlqP6W//cYNYi0uyW0chNRr5aipHSuHewtjjQmkL08wcYaGpt0iczBePIhy/mjwxNNF46g2q2Fvct6RmT/iaXlIRh/3t4paWiqRlKuF0HGMl6cvIykRcGtcTSlshKf6/J4/N3r2d2ox6gsDTJNHlZcEbkTCY1HQn7E+4MSqq5LQPbyRBwczR3Xf8+8AV+RcYUToKfC616FC7z2MW37lQTeW9Uj/3Zlf3IriQFgkDE3Gama4cefawZSn6P/yFJkWI+yPiP8symx2FOl6Er7IGMZje5dLC8FAcnZuf+zXW4uCD49Xz50C1XBUlikN+r9cSshb2fT7KiS9nAUckhQm3GGX7YT+G4awSsKcduj0GIH2Rc4UHZDvJ6pFAQEg5H6i+LJHWuPQ5aKmtx/N/m/Bpv2EDmrGqlJIG2WHZaz4vtt10eSk6W4BEtGFpaiYtTqw9e8ZmMFYvtrz25fEdZlPZc9/6dmZIUPjsZvdSdPVVEi5c2hLDljBRIaCgL3b72SkBcsur7lILTRg6l8rJFHIlYzO/F8rD9youbKWp6K/Q4HsYka1Yq3ck+j9Bt/brnje2oVK/6YkoCwYTdZs0fx+GWf8dqsy3H8sgdxtS4gGIxI/j6kznEk/KEyFHcnGp5roGSzFyEvJ3e6TCi6fzS33vo97y08H1O1SugDiVzpvoWHlt/cqSmjYDLRckosZicZmyIzhqwSLAWFxx4nEiUEsfvC9N5CkGXE0CCU1ExEKxONpw+gOtSA1x8VbSyZDm8goI0eTPFwG8zOIJl1U0RNggZPAe+NZgxrd/8r1PHHC5KzMyWXR1F9ZiN+7xsw/bb7b81qyv5+urzpSB2ZoPKH+uXJpeWRRCbFRBD0Xg4VzTaUPhncpt/jIUieHqQ+GMojF32Fr0FfinxWNpzCm31QDqS0jhPt7Ul7IpbnLv2QtTWRpN4aTsGZTlx0w5+cYqePO1SY/vQ71+K7YDP1E4dx+ayf2FIVTPFTIRg39YMGSRBa/c/koADKx/hw4+Pf8u7zE3Be3n6ZqI0eTMTLSfz2bTwBz27Ufdj9/TjwhDfWOQb853ThLisISB7uWEK8qfezQrSAbVYdQkrWPxozEm1sSH9iMCGf1RwW5R4qaFcUPZlQU4Pk6UHBlWF4bqpF2JHYISmJtrY0nRpD0Si9obChDvx+rEDd33mn8RMJgixTO3EYhRc0Y7/DCu/Xtx/Tw7bjgwiIJlM76Y/s59uuXeBJ+cXREASSb3NhgvNOznU5gNm54wyZUlxCyCNbWPLKRPJb9GVlfoMjwlFeX2ptLWFP7+TRL6/BTjLT6G2L18INrH9sFKlmPaVtK5p5dMclBLyZiHl8HBc9vYYoUyFnuyRy3avfkvRKNOqpQ0l/cVTfG0kc9D9rvHgEsV/lcOeTXzJ/03m4fLwD0d6e1CUjUU8ZAujkqzxTSUadK/bZGnKALvS05OXjvEtG6O4+1TSU4hKEjbuxX7UL+5Qqyoc6UH3RwE4L3/8OVFw2mM3XvUj+2Uf0W9A0XSCrqKgHHRSU4hK8395FXZAtRVNHUDN5VHuxa309pt/3EPxRMSEfleD/fpo+g/sPkBjosiK7TzcR8UoztfFNpM+K67HYu6eQgwNpHj0Ayd29zetHz8Z6i/8EkQmShFwv0KQZ+KRgOPbfd1GmoSp4vLaRVxdfSqrZi6p3/VsV/W2GNTUR8sRWdk0K051h7e3JPVfCXmpsXZaG3VOIZjZTc2cNg61zeC7jPD65/TxeXnI5Z8Qkc9WbP/LShPdJX+qnE04fVM2SszONt1Vxmn0SP5cPIHpuOZrZTONpUcw991OGv7KDommj0RobEWe60NBiZNpjnzL462zSFySQ82QCN939A1ovrgTNbEbLzEVQwGLVeYfp4w3Zz5czHtjIR7WRBHyY0e59raW5zfJIbWjA7tNN+KxMo8VaIOkBP0rvTEAKC26Vf2hmM0pKOkpyWoc9Gf8L0LbtI+rZKgQNEh/xRYoI7Zf9Sp4eNIa5ocmC7g/YEUSpx3KgI3HiLy2FS5BGxyOnF5J6fyiPX/IFszZMIGpax9nLVggC2qhBiDuSejS9Vs6I49Y3vsJJamB9XQQ7JkWgpKRTM3kU055eiSiovPz4Vdh9pjcikSLDKBjrQdikFK732sC+Rn++WXAWTh/2vmeh7OVJ6r0hBH3b0FpLJ9rbUzI5llNv30qcbRYvvDUJ74Wbkf19SJrmy4sXrWjTafyB5bf0rnGJICD7+aJ4OMK+tGNfgogSotHQq2oDydODIauLWPXJKfjO7yS+J8udxrYkBwcaR0dSMtSAbaGG25f72/Rz+K9DcnUhbXokBNfj9rUNjl93bHveU8iB/li8nZELK7FkHzQ+PUKiBHo8FlVDdHKkubqc382fnoyROTo6EnvrHG59YA1fFw6m5RUvGl0lVBm8VmWQPjUE2zxwf29Hz29EUaL09hFUDlEI/6AZYeNeUBUEk4nKK+NwvjGHjE0BBD+2ESksGN8PS7jMdRtflA8j/1yp3Y0iubmS+lAEz17yCc2axMyfLyNyRscOD72GKJH7aTQvDfmMEos9c1dOIviFvdDSQs4DcVxz1W+tndF7TWT9BEGWkQL8KBjvg1WV2q2D69GQosNR07I7DUwL8QNo9LbFurix865PB8u96sIcsf5mS8dj/qOQnBwpvyiGsrFN2O6yxvfVnjWB7hRHaR0lVxdwdUbLL2qNtQomE5bRAxD3pPNb2TsnY2QAnpfmEGIq5jb/P5k873uqw3QSKz87mCsvXsdj0z8kfVm03li1C1TekEDBjNEU3j+Se+/7gtfOeY+L3/qNggdHItrbo5nNOL2/EekahbCX9IB/yRleXOSyE4BfdwxAqWsfFFfKyvHYriEKKg2qCZc9IoKfNw0TR/a46Syga6j8/Q7bXYsSRfeMZEbsz61DLrhwE6KrM4KtDX5zN/DT46ezJO+snh/jOEAMDuCOn37mz8dewndKWq/jhUpiapfZNbGxhTofCbNrF3G8g+Vetr/s0/8vCNRfPpK6SaPaLDv/i1CqqnH6YCMRL5qpjWoh/664Y4uJHjVvUioqUVIz2iSMtOZmDBWNqJ1U33SEE57Iqt/x577Pb2LhnKv4ozKShZOWkb3UDdc/cvjjiTHsa/TjuWFfknN513WHblvLafBSufT6tXjJeveiUGMJM29bQfpbwa01kJbColaxn8fXKcxNPZ8mzUDwF0qHS0bJ1QVuLsFKaOGFHy7C9d0tpNzpyT3PfULS89E9/pzm8XHErsqjZYxuXqmcNphbb/8eL7mavU1+LF5wBfvuiqUh0gObr0WUM+Kw+nYL2nUS96+4Bavyf2hiLooMMJZgJ1qxMuRnsqZ0XbLVaxSWYlWpIjZ3r0lqFeZqGvbf7cY2v4n8C73JnDmc6mtGtdWi/ceg7jpA9GNZNDtA+syh/VenedAJ5ejX1L0pvZK7nPBEZvflVkIe2YjT+xupud2ddbVRzB/0BXmvOmIqM/P7Y2N45Otr8H+raz8t5UAKYQ9uZtNtcczYN5FmTQ9w24pmFg77FNsV9e1+XKWsHLsFDmysCyNnvKHdk0y0tSV5USCPhf3A2wWnEfliFuU3j2D6+d/SoJpw2tezmYDs64PHYxmsLw7BtCNNL8N5pIpwUxHNmsQbP52L67ubYNMecsbL3OS9npw7FIrvGQ0tLQTM3IDHux3XaB43iBLq6UNJussVb0kX2qpoCN2EBwWTCambZcaRUCorsf96J4Y/O28m3BHUpiaEv3bhtXgzoR+VoxoEku71ouTu0Xozkv8glNJSQl/PwOLVTObNId1aKx0J0camw9+t09luL+PEJzyRtUFBCck1nhS1OPFg1C8MXbobwaIRMmMjSlV199trGmzZi9/1+Tzw9Q1kNbu1vrU1ORi1ugbljDiE4QNbX5d+38HOqYNRHBWSFg1qR2auv1nxau5ZVC8IQPFzZ+K9a/A3ljP/48vxeG1zjz6WpbCY6um+OE1VUaqqqb5oINNCfgNge0MwkYsPp7Yjl5Zwz/c34rTahurBzTR8YIXl7Pj+1wt1AcnZmczZI3hu+RtkXP4GNqKRTU0KI+beQ+BrXT9Qsh+Np/TyAb063tHZy15BVVAOpOhNVZ46gPvOBioGOqKNHtwrQj1RYCksImpuFYqNRs6NYT1eZqoNDR0mUkQnxz5lKY/GCR/sP1LZX3FTAiOn7mD/EweJZnopCW6ZbH5wOIa/9nV7M0sODuRMjSVg6T6U2loqbhrFXTO+YO6u8YRNK6LyrBCarqoizjOPzCciMfx6WHQryDLNZwzG+Ed7hbjk7Aw+Hti9UcbNXuu5d9uVhN2d362/WYfn6O6OzZcat3r/SZViw/MLr8L9jU1tpu+ivT3pj8by2MQv8JKr+a0mhl33D0Fcu7PXxzsEbcwQpD3pPSq5OnQO1RcMoM5XZPgVe1ifHULQVXu71BJJMRGkPWXV5++mPyG5ulB9dgSGWgXb5FKU3IJjUsLLIUGoBUX9k+T5GyA5OZJx/wAMteC35BgTAJ3gpCC2A4g2NtSeV8e+pwZhvS0Dqz8PYD1F5OOtIzEV1pDxdBzamCGdbx8bRerrIZgqNZTaWqTQIMpGt/BXdTjhj1aDoz0NXiJek3NJXBSLx6zM1l6YoIsNDb9u73Ddr1RWkjfelRu8/iLV7EXwIjq8UQVZ1oWEXejNlPIK0j6N4LvKITRrEtJR95ZoY0PqU7H4DCukoFkX/Z7tcID8U6072FvPkTHRCtGx+xmK7O+nu13U1mL/ySa8X9xAwbkCoXd3X/KUer0rfm8b/nESA/17tv9yG7a7cjEHulAzMU6fjfexHlVxtkWws+3nszx+UKqqCXlxHxY7yLvnGBMA/YD/DJGpjY2EPlCB3KTg/2MjRTcNQUnLJOL2rSiJqXhtUXB7Ppuq6xI6bHRbF+HIKSHpeGyqQhwUhfh2E1fHbyFrRgSaJFK9WL8JNbMZQ53Kjlw/hNp6vYi8BwaGfsuTuOevyby0dhxsab+8EgxGSm4dTsgPNYiDIrv4oAqer2wg83IPnv5jIudPW0fFjaMQTCadxJ4ZxOhT9mNzt8S6G4axOPdsmjUJq7K+TcyVM+LI+2IAqltzh8Lho6E1NLRzu1Bra7vtjq2ePhSxhTaz3H8Soq0topMjluJS5PX7sP90M8b8Kiqvjm+nWu8R9qT2r43O3wClpobgl/bRYgd5d/+zZPafITI0jZoRfgx+YRfnOe/FYg1V1yW0rs/tN+dgLbVw5cM/IUQGt9vc7qd9/JkRis8buYx4fw9T/H7n6y9PwbAznbKXZc7zOYBLYgvKqFjk+4oIe6qe6jFBXPzQGgpetW8TN+sISnkFkVOTiXpof4eBTiE6hGvv/on9VV4IhWUd7KEtLNm5REzdzi/zTiXw5lSSFw6mcuIgzjx1L6V3+KCkpOu1iVNteXzfJXit6ZuK3VDVxDXh27BK69lF3JebVbSxIWeqQsjKyu4H/01Q6+tRysqR7GwRjAa9hCs1A7c1OVSeE4r5vOG9ks9oLc3/l6VQSk1N68ys6Ja4f+w8/jNEJjk4EDg9mXMd92MltPDgrZ9TEyIgGI1Iri6kv+zORLdtLNl2JtqBtHbbq/X1REzLZ82eaIJNpTywfRJBb6ZRcsUAHov4kWqLNaosUDHAGsvLXqBptNiKrC6M4emY7xj59g7yHhutu2R2ArW+vt3FLA6JQTkzjoYABzIa3eFFj56XzqgK9p9somaGLwmDUznvoXX8/ufANh2klMRU/K7N7rMPlbrrAH+NDSJgXs+FpKKNTe+0WZKE58dWHTtX/MNQamraaKAsefk4fLIZm6wqCm8aiHrKkH9Vs4/jgUMzs3pfjebxw/+Rc/jvBPsFgZynErj/qq8JMOgxliSzN++mJlCf6cjCC9+noMWZL27vomEugCjROCEeu41Z1JwSzEUz1zDYOgfQDQpfXXYxPi9sbCUkyd2dpAUBLD1lBQoCi7LPpeUFL0w/tu9nKcZGkfuMhP8sFXVPEqLJRNVXvtwd8gelFnte+/o8gp7Y1KcntzZmCGGLkqhotqHqXm+9K/mhc/T0AAe7w6aQxxOihDgoEm1f73RC/4+QQ4JIvd0bQYGAHxsRN+zttazg/wnikBiSb7Un4p263rUH7AQng/0dQdMIeHYz7z11EcuLx6AgEGUq5PnYL3n1omVIgsrzv16ItGlf1/tRFay/3kJLlG8bEqtRrVj41QQCPspqo05XAz0x5BqZnzkeRRO5xW89pz+3gaYL2zY0Ea2sSH/CyAuDPmfo8v2Yxw9DU1SKU9ypV01sqgohdHF6n0hMMBjJmCowwXknN3r+xch3d1F+yyi9zk2WSXo8mKxJx78RhWhlpS/F8op7TGLdVVz8m2HJyCLk6R34/2om+wJriu4ZieTk2P2GfzNkXx9KpyT0rpKkA6i7E3HdIZJ8j/Xf/rv9d4gMQFWw+2wztVfZ8NCym0kye7e+lWr2ImJZXY9uMCksmJbHK1tJrEkz8MTnkwl7PZesxc5YfSlSeWMCAEKLQshze7C+tpFpv13L84uu4oN1pzDima00XTSiNQOpNjUR+JrED1WDGGKbTYu9hNbSTPj9W1nw7cVUzAjosxuDYJBB0M0iARJs07j1gVWkLhlB+pzhzB33KULPzTj7DCEkAIw9zzpK4SHkXNH7Tk/HDYKgdzS3sWnzshQe0mlplWY2I/2+g9BZO7EuV8meMuCYCaM/oY0eTOoL7oy+eQepT8Ue27lpGu6f78eUZ+DAw55/K5n9t4jsICy5efjP3cgPt5/BrNQLKVfsePOT89E66HV5NOSgABqW6tbWh7CiaBThr2ajmQwM9irgdp91NEyo0dXruxP1wHBxCcYyCVOVRsT0Xaz6YRTnz/2domkjW/cjrt1J4oOx/FEdjeOUHKSYCGRfb2wKBIQNfe8QrTY0EDEtn/s/u6nVZy3IWMbScctZdNky3i9IIPCL4j7vv8fnkZrV42C/YDBSdI4nAStzj/NZ9QySszOMHIhleLQe3D8CWn5Rt59LbWrCccUmPLc3U3nxgH+NmFZstODqVIcsKow/YwdJC6KRYiL6vD+lpoaQlw4gNogcmOHZd6+9XuKEJ7KCBzovvha3JeI0qYS3p00kcFHXYkzQl0aJ9/u0IbESiz1pn0aQPzEIJS2Tyru8mfLb9fg+J7aJh8iB/owbv43KKBHNbCb0xSR+LYnCPrdtzERcu5OsyT6kFbkjv1bDgUd98Pvm2EznQC8vCX58Cyvuu5BVlUNbX5fQSN0a+LfEx3qTmROD/HBOaT5s9/I3QZBlZH8/pOjwNjIKtbYWKSkbY04ZSnVbhfqRcpLOrrVDPQ8MP2/D5ccULAOCkQM77635d0HbuR/HJ6zYVByELCpcPHwHSQ/b6a3y+gilqpqI5VUI1grl53chFepHnPBE9uR1H1PykbfemOMIaAmDqP3Gl9JJsdiklPZIkV5y/VAWnPdRm9dm/nYZjV4aPquLAD2LF3HnNthyRG2fKJH4kA+uhnpCVpaBIJD2cBTOpgYcfkvhaCipGYRNyaJweTCB32pYMrNb3xMMRoT4AR02GO4WqoLxp22k3xPB9D2Xty41H7roG+quGNnNxn8vlNQM5N+Ov2ZMMBiRnByRQ4J0p4uYMCzezghNzahHlNRoFgtKVbVOrB2Q8SHSU+sbkJwcO52JCCYTSnkF4o4kyk/1pWHiPx8307bvx+lJE1tLdeODCbF7KJ6rddtztSuoe5KIXNRIyVnNxzTD6ylOeCKzElqYE/0NIStyWxvsAjR6WnGmVypPPfIerh9WUH5Lgn7xCYIeCxkUheTm2mZfzY4C2UfUV85OuwCrAgn3nWrbGc1RF7oUGcKUM37lg59PR03JQIgfwKXjNpKyMrJdJ+xDUKqqcVm2Uc9uCgLC8IHkPTqajPejmbjid/jSmqrrE/rkKsumPQTcXsTdf1zLxvowAgzlVEb8uy8FycGhXWzqmCAIyEEBCJEhYDKhlpajFZag7k2GLXuxZGb3qv5UPfQ7HpyFKxWViPb2rTITpbIS0cWpjROt02c7qfOWSJql25736bfsL+xJpSD/MPme5ptOyRz1mGZm6u5EvH42kHSn83GPl53w8otHN47jFA+9O7eCwOLsc9CecEXYvA8hPobUaTIPx/+Eh1zDl2Vx7F0Ri12BwoRnf+Wv8jCapzrp7dgMRtBUms8aQvMDFTwR9j33fH4zEYsy9Ca1XUC0sqLq0iE4by8l92JPxl61iS83DyPy3h09Si4IBiPJSwfz8hkfYjzCHqLI4sjCNy7H5+29Pa5xbHtiEtqoWPxfSmfTqkH4zf37jRW7hCAg2duDhyuqvQ1iZl7PivsPQZQQbW0QHR3QbK3RcgvaLAO7co89EpKDA0ptba+X95KTo74MPVobaGODYG+nJ28EgZaz48g/3YjLAQ3n1cmdPtyOFbKfLwUTAvFZld22CkMQEGQDZTfGE3VTIm6muta3vtkaR/SMpL4754oSNVcOp3i0RtSstF6Vl/VGfnHCE9mUdZdyoW/b5dveJj/eWzEO/1f3ojU20nzGYAyPFnNXwBoqFDt21AUSa5vPu5mjcbmhmuZYf7THy8je7UPkSzkgSyRO98Flj4jnz3moxaU9LpqVosNJfNCRkI+1Xi2dJDdXEp8PZtbor/GQD5NWvWpizkvX4P76Rv2Jrqm9v+HCghFaLH97POpoHEksoq0tWlQQgqJhdrPGKruyx3E8ydMDHO0RGprAaECrqESpqWuv4TrYbUmwtgJFPW4Egigh+3pjydUfqILBiKbo/nSCwYhobYWmKAg2NlSfGYrjb/3c9Rtd45U6w8j5EftZXxCC88t2rddf87hhZF0mEL2gnGY/J+pnVDPSQw9nWFSJ77cOJvrV6tY2ipJnL0TZBz9v9qPDMFaD1+KNPb4+TxIZh4nsk13R2Nu3XzY1aQaeSx2P4S1XbL7eguTiTPr9kdw/cRUNqomPXxyH+/pi1Jx8Mt+P5OX4lSgI3PPDDYTfu7n1Jsj/MABVFQmcXo8lI6tnJ9dHwhEMRsqvjSduyi4udTnsHzbl1xuIfjqL9MVeWG20w3vJll6LTQ/FEJXk9lUNopUVopcHlqycXu2zV8cfEEnNiy04XKfXXYqDomhxtcGwOQl1UBhyUVWPjy8YjGiWlg6/X9HKCgwGBBtrBBtrNPlgs4vyyuNX6yhKCAYZQZIQZBm1oQHNYtHjnK5OIIqgqigZOcjenpSMDcTt45395ighDokh/WED50ccFqkmVnlhmeuJcWMiqW9HcH7Efr7dMpSIu7YixA+g+tnGVjID+LMgBI8n9Cz80XbVPYHk5Ej2lAF47GzBuLq9GLwjnBTEHgEJ/QtPNXsx9YcbeXjfRKoUG6yEFmZGfMuk2avJeyQBWiwEPbmJz+4Zz4/FA6gcoNfOZT8Sz9yhXwNQ1OKE7+8Hd6xpaGYzLTuceWLADzS9qWI+r4flGarSN3V+SzMuyzaSdXcY9267khKLniG7IH43uDlzWlA6D975KcmvDe11Aa+alYvZ17FdUkS0siJ5/hByL+vftmBHQjCZKJ2vcXfw761dp8XSKox7s1EbGhD3pKEUFrfbprMMYUfZUUGWEYbFog4KR3R3Raurx5KVg5KaoXdNOp4F26qCZjYj2NuhKQrSwVZ8am0tSlqmfvy0TL1Ten4BbjuqaEnoH/NG2c+XlOmmNiQGEO1UhOHxIsyjowl+Q+DnjCh8ftcJStu2D8cnrdlccjiudapPBklT7HVDhT5cu0pVNYGv7acwwYByRv/XZJ7wRAYHY2O7zyR82hZ8rspk6cNX8PC+idSoVoSbiph383IqPvFASxiEvGYHhsvriHizFMvZ8dx8xU/YimaaNAPzv7oU228PLwc1VSP4tVReefJKfG2ryDvnbwrWbtlLyHVJLJl3BV+UD+Mcp/00edux/ofBeMi1nDPoAIJ172x5NLMZw1/7MPs6IgyLbQ1KV00cgqFGwGfxtuPxSQDImBnHqkHv8tRXV7UuWY60DFcbGtoE3mU/X4gJg5aWDvfXETRVQyqthm0HsGRkdVjXeryhFJegNjZhydKX8J3NmtXdich/7jnm48m+PiTN8+CCqI6rVaIcizE+VoRiEAm+PrW1wxfoLeEcH7Pim51DUDX94TJmUAoZM+P6rIFTqqrx3Goh43JDr9xle4L/BJE9sf8SIh6rQJANaBYL1l9vweeaHB5bdTXlih1GQWFmxLec/9ZaKm4chVJVhZKSTuFoE5GmQgBezTmTsOf2t7n4Sm8fQc4bHjjur6T8UmvCZx57fdkhiIOiukxbay3NOL+3kdy7Q/i0ZDhlg0wYa/SY2cYvB/cp3qOZzVhllNLieNjGyPGzHQQ9veWYTAO7ghzoz9QJPzLm6wcJndm9saPs7YXmaIeQnNlm6SUYjMiB/p0X5auKHgP8p2sdVaV1idkVjrUOVTAYSb8jkAui9yF20X35EJmZT2nvuqvt3E/09FS++yseVRNwM9Ux9pwdFF81oM+urtard2BVLJF7fc/dZXuCE57I0ps9cXzDHktWDmJEMFpctB6nqK8n7JFtzHn/ylb//ShTIaG3JiMenM0EvbyPab9cy46GIJqW+LTL3JidBZ6K/Y6BK5Kpjw/oW+awA4hWVuQ/IzD84/1kPJ/QpXBS27qXqptdqQ2zMOKq3bySdRb+S3vnT38Ikrs7Zaf5YnY6fJNpLc3H9eZXS8tZfeOpRDywvduYkOTmqtvlHEhpK0K1tUUMOdj8paDwuJ1rf6INUQmCPkM5ghwkBwdkL88+7VswGMm/fxinj9/VJYkdwiEyazknvt17SlU1UU8n8t1f8VhUCVlUiL4xkarrRvWJzDSLhaAlidQFW6gfP6jX23eGE57I3ls+DtOP+rJIqK5DqmpAUw+aIFoseG1tRj3ia9iyPRy1SV/GKDU1RE7bxbqbh7dZUor29khhwQQs2csLcydjVmVOn7uhf9b+gkDhbXE8Fr2aBNs0Xpn4LrYfNlB/2chO7WCU5DSiH0tm+/JBCC+595lQLRG+WKygyUVEDOle9yO5u+sKeDdXpLD2Hm49gdrQgLZ1b9czEEFAiolAsLfTpS5HLQnVhgaUlPROxar/Nhw9u5XCgsHtsMBZtLenOS6Mphi/jn9zUepccGswkvfAMEZfvhNrqedL7yjHYgyPFiPEt5+ZHSKzH/8aikWVcDPVEX5n38lMqawk6vUaCkdJKGf2T7zshCcyz6WbWy9uS16+7rt1cIYhGIxU3V3b2nH7o9KRhK00o42Kbd1ea2lG27avzY2Wd+dAzvl6N0kvR+K+OoOUqwL48OfTMFS1n1FIAyKpmTyqx2JHcXA019zxE07S4RnHzV7ruX3OF2TMiu/QvRb0i839tY09zgi1O09PD6rCDsbVNBCau78Jsm8Npy7CGbW6FsXFrk/H7SmERjNKbicOtB21FPs/gpKerUsbDn4G0c4WxUpC6OQzSQ524NpxZYfk6oxxTHmvSOwQKhptkEo61ukpVdVEzmxPZpXX943M1D1JhL9fTu45pn4Ry57wRCbadq4Gr79oKLeHrQegXLEjdXEMOWNtkEu6Fv/VhVgIMxUxdcTvqJ4uKKkZhD60EfWoonMpPAS3twtxvT1bd6DoAfLOdWKgVV671z3kWuZd/iGZ70diObv9EuBYofp7oBzkSLsCC5ac7m2r/X6vw/anPWiWFsT9XWu8RHt7xCExfVPna3qZ1v+zf5kgy0hurnod59ElSUct3ZWyCqxzqjHuyeowNqlUVXeqqbMUFeMxS2ZTcVCvzq+oyQHnudatWreO0BGZRdyRSNG0hLaf6QhiEwzGTh/iyoEUgr6pI2ma9zGT2QlPZJlLgtESBrf/MkWJvPNUgoy6bfSTP1+ObWEzTimqngrvAtFPpPHwrstYuu7sNm6rR0IKC6ZuiUaAdSV18/16VO4iOTsz8JLE1v8fklccgq1o5uX4lYx/+Q+yZ43uV2cB4UAG9vkW7AoUrP/o2G67HTbt0eNamtbGJbUjiI4ONHnZosWE9OwJ3sXy6XhBMBgRTCZ91tsPLcr0nQrIXp4IUWFYwv1oiPFCiQrscv9aSzPKgSNEsaLULobW1Qz0UO1kT8msotmG9HciETZ2nyntiMxOvWY7yTOj9b6ugoDs492azBAd7JA93Drf4bYDuG+DpGneiLZ9b75ywhPZ80O/5OJ31pDz1Mi2TSFUhYBvBFZXD2R3YwCRb1VjsZZwXZPV7T6V8gqCH60j5oWSjguIw4JpWKpxd/Aavn/7VGwyKvWLWZa7DOBaogMY46wLUn+pHsBbj17G3Vuupklraxsz0CqP5ya/T82HTjSPG9YvVspqQwNWP+3EevWOds1B+gNqWTlyvQWpvGelPpKzY68lJL2BIMttHm6SszPKyBiUETGow6IRO1nCd7dP0da2zX4FSUKzt0VLzkDanYqhzoIm9e62k/190NxderV87imZqZrApj8G4LJ8S4/330pm64e2JgDOG7OTwjccEYbEYMkvaJ09q9U1XZclqQrOX+7BUC1SOrnvwf8TXtn/2a4obOwlFASm77yCwOdBMLeQeoMTIV80Yiiqpj7SHdPqbf0SZxGtrEhaGsuS01bwwPZJBC4SyB1rS/DraWhergS8lcVv6wYT8UZJ2+WBIJD2wRBeHfURNaoV8xZdg8fSDYhWVpRcP5RzpmzkTPvEdscrsdgz89fLiH6puOeVBccAyc0VwdamT+VMPa1t1Af3Xj3eG8jBgWiSiFDXgOLrhmJnxFBQjZqVh2CQe03moo0NytAIFCsJQ00zYnVDh30QDmmwuqpdPCRLOJTFlRwcWqsBen5Cep2pFhZA1Rwzozyz2g1RNYHv/oon6unE3tWwHoTk7Ez22z6cG5Tc+tq3iQOJvDsDpboGwWjsceG97O3FgScDiHynHm27LmM6qezvABIaC4d+ysi3dzDqgz0suXgZg5fsQRMF3WGin26a3PviWHjqJ6yrjSJgiUTWBBtC3sxAKSkl6T4bJrjsZMklyxDfakQOCdI3EgTqLxvBnUPWAbAw/Ry83tONFNWmJtze3MjeyeHcvXky9WrbmYKHXMvS8ctx/KCa2qtGdZoM6BeIErk3RqI66kuAruIfR26jnjoUBKF3N+Jxfr5asnIQLAqagx1SSTVytRk1Jx+tpbkNicmB/oiDozv+XgUBOTgQydkZTVGQy+pQDSJmVyuafR073Eapqem2AFuwMullS0ds09v4YNmtI0h9IxSprBqnx01sKGqbVbaoEt+v7zuJIUqUTIwi3qftA+2CqH0kzYpG9vTolXuIpbCIoFUa2Rc49klf9p8hskNIsE1jpK3+pIyyLkSz7UdRno0NIedlYCW0sKUsEGNeBWHz9mMpLKL4ngTuHLautWRKFDS0g+U4wpAYJs78hYFWedSoVgjL3dvFnJTEVMJuPsC856/h9fwz2h37es8N3DnzczLfj0SKDm97XoOjyXo24Zh9ryxnDEFuBHVfKlJkGPUXDkX2brtUNl8wHPWUIYfP+/TBVMRY/Wuyiq1CVE3TS5RS0rHk5qHuOtDhjae4O2KxNyF2MCOQA/xoiHBHsLVBM5tRs3KxzqnGOr0cU1IBWsth8hFkGcFk6rbBMuhLt2Ne3gtwKKKm7dyPyxPGVjKzqBI//jWUyJk9IzEpOhxh2OFMvuTsTNE9I4m5dT8uxgZKmuz5MS0GiyohChoXjtlO4nzfXl9vxp934JSmUnrN0O4HH4X/HJEdQrMmseDTiWgH+tYGrSOoDQ3UPevLfTsmcXfg7xQssqYxIYLyWxKYdOtvrR7/qWYv6mf5oqRlIlpZkTLNihgrPUv4S2UsTms6PifNbMb17Y20XGvg7m8O21Yfgodcy8vxK2FpfZuqgOTbHZh/1QckLQ5FHBLTp0C25OZK7jlGvD/cjxQVSs1AVxw2ZmHJL2gzziajCqnxcOrfuDMd93f/HU11JVcXtGExvWpFJ1XUIW0+0K6BsBQeQlOoXmZj8dF97DSzWQ/Sp2ZgKSxqkzARBoSjjIihMS4QKSyoR8cWbWyQIkL75FPm9tYWwu/MaM1CHiKzX7Ii+WV1XM9JzNODpEfsERdUYD5/OLKfL0nPRnD6dVtxMTZQ22JFxmuRhN6Rzep1Qw+T2YC9JD0T1TsDUFXB6es91AbRa13ifyZGdjR+q4nhwOWBxyWuJFpZkfRqLK+d/gHlih1OUn3rTKzI4shrcy/D6QO9rZs2ZgiXv/0zAYZyFARmvHMzfvO69wUTZJmW0wZTONqEaXgFT0T/gK14eEYx5ZcbiJii95qUfX048KwPS05bwYEmX17/5VwiZ/fOKqb2ylHYZ9Yjl9ZQPtobl18z+twMpcvPZTL1aknSG8henii+bq0xmGOBFBEKgoDF1VbX3W3a0+WsUzCZICYMs6cNpvImtK1dV1+ItraoA0JodrHCZm9+6wNDtLFBCPaH/KK+xbU68UjrcKynB4lzArhoyG5EQaPMbEdVszUhdmWIgka9xcQfvw8i9OkdepMVBwdypsZyxmXbkUVFj8FtiCPq6ZRelcw1jxtG0Sgjfs9tYk3TpydjZF3hh88SjltwXG1qImZOGQ+8dwsGwdJKYgCzt1+A80d6TE729sJuXn5rn825aecT+FZyZ7ttA81iQV6zHf/ZG/C+oZCn372WA026+22zJuGYeHjWYckvIPqBVO754QYcpUYWX7ScomXuMKrnWSLHb/cgpedTNcwLh4zGDklMtLdHHBTV5xo6KTqcjJlx/VqDdySUsnLErP4pYVJS9NZ8FjuDPgPthhg0sxkhLQdjlRmxqmupCoDo4kyLg1F/2B2Mj0lOjrSMjKLR3wE1PKBv511V3SMSE0wmkp4KbiUxADdTHWH2pYiChkWV+Ou7wYTN3Nn64FFqaghYuo8f/9KXhqKgceHoHSTNiujVzMz4y05sCzRqxw3s8Tb/SSKblXohQSuOn7cW6D0NAxfsYN6ia1hePAaA5cVjCJ/XqF+YgkDSw0Hc6P0XoMstbJ916JWD5iEoVdX4PreBdz4cT5Nm4N2CU/FZmdZuTPi0Lax45EIef/lmgpwqcHwhX9f+9ABqQwOCvR02Jc0Im9u7Kch+vmQvCyRvlog6pJce7YJA00UjiFiRiSYBUvdLKcnJESk8pNtxor1961Jas1j61a5HKyzBVNIAKVk9Gq/W1sLmvaiZ3V97SmERxvImrDMqUEoPXhO+XihGEUNtC2JmQdc7OAYIskzRHfGcPazjgnNVE/jji3gCF+1tWx8rSih19US+WsKfBfpv00pmz/SCzFQFj88OUB3a8yX1CU9kR2f5Siz2WL3s0qWCub+gNjXhsXQDtdfaM3XDNeQuCkfdpwtohWGx3HPu6lbr6mKzA1J10zEJMV0TLWQ1u1H1fABKSSnC8IFtlfSaRoO7RJMbNN3hRMHCMJSyzm9s0d4eacDhLjiWrBzEtTs7FMuqlVUEP1iNz8RE2NQ7Cxp1zGDOnbOO31aOIOSRLd2KawEERwcUZ9suvy/BYEQdEIwgGzodcyxQa2tRdx3oXWD+iBlWl8MsFrSd+3WJjqqAIKDYm7BJKkbcvK9PD7yeQPbyJGP2cIZfsxtbueMlfpnZDt81tW1rekUJIT4GMSYcJTUDjydl0mp13aYoaFyYsIOkZ3tOZkpVNf7flnY/8NDhezzy/xQvPz+Jryr0wtQmzcDcT6/A9Fvfe0T2BZbMbMKv39HG7ynlRhuiTIeXOdd6bGToBwcovWNU3zokAXZrU/n8qXFY/boHy1lxnL1sA8nzBiEH6cuQpotGEHPLfp6fvJziU92w/WJzl/Y8gsnY42yjWl/fp6Jtyd2djDsF1t6TgM/zG3rstGHJzkXYmdzl8SQ3Fyw2BkS7vivG+xOCyYQUE9G3pbOmIe7PxJKTd9xKtWQvTw7M8Wf8Ods6JbGSJnsylkbC1qNm5aqCmJqDkKPPFNXdiZS+E0RJk16dIgoaF47aQeHV0T0+n960KDzhicxlexnZU0OZ8ue1LMo8h5CFScfNW6sjiLa2CPED2mXKrL3q2o09zT6Zpx78gIaVjrorQC9nZ0plpU5OZjNW+/N4L2UUr1ywHNP7jZTcPZoRs7Yy0W0HD++6DPed7Y9/NDRzM0pS11ndY6mRE+IHkDgvkNDXNH2m10t09ztaiksxbko8fl78vYTWoocU+ppfU/vQAKWnEK2sODArgIsG7+7U+ucQiTl+tLnD81Cqqg9r5DQNpxWbyJ8Xzrr8UP0YgobpwpLj0lHphM9ajv/xNso+jsLlyz2Izk5tu8ccZ0jhISivNxPrVEDi9eGtzRtAd8VIe8KK2fFf4yC2d81INXvx6hfnE/pOXp+bgsjeXiQ9782cEV9jLzUC8OSBi/G6qbTbWJEUE0FDsCM2GVUoiakdjhFjo8gf64L3S73sviQI1F45kopokZAlqe2kDT3dB/Cv0acdKwSDEWGAbjMuNFv0z1VSjlJRedw/oyDLFN49ghFXd76c7I7EuoJ6+lDc52bhYVWLqgn8+e5wPJZ2f82cVPYfgVu8/+TKh39CdHf9W0lMkGUSH3FhSsAffP/dKJQDKYj29hRNG43s74eSmEbIjUk8t3Ay7xad0mrueAjhpiJenLyMggv73o3aUlhE+M37eXb51eS3uPDkgYvxvqu+RwFvTRax+nVPpySmnjKEtOud8f80u8P3u0LFjaNochIIenZL30gMPcNpPm9Yu96j/68QnRxpdrHGYm/C4mxDs5c9aogvQgeJD8nBod96YPaExIqaHMh8tXMSk6LD24mwj4S4bhcZr0VS0mSvZzyPw0r/hCeybQ3BrCmLROtLGUYHkL299A7M3VxIgiwzPDKTl7POJmRRIqKNDUkLonn8rg8J/rKU1EX6Tej+2kbqLoGHP7yRKqWtxc2W+lC81h5blk1racZ/wRa+uvI0vG4u63GSQ92T1KmeSxwcTfbdKhGv5Pb64SDED0BQwf3N3nd6arOfyhrqfGQs4cevKcrfCaW0FOOG/Ugb9yJs2I28YX/HhpOiRMvQUGT/Tiy9ewFBlim8p3sSy341AoePOyaxlrHDKF0gwNJ6msd30nxH03D8cDN7VkVjUSVszyzRTUj7sSHxiU9kN8dgfsKzb/VkR0EODqRqmQ3jPt5EytJ4hOEd61xEe3vy74oj2r4IaY4rSlUVxdcNYt6Zn/HI6qv46bc47j37J3JfddR7BJaVEzhnG88vuop3i05BQWBHQxBrZp3SmuU8FmgWC+qepH7JdElurqRf7UT4QxW9zvxKYcFkXO6A26qkY7bPbgnxAgHkiu4znP8vUJuadOI62KGrQ2gqxuxytJruY5xdQTAYdRK7qhsSW9I5iVXemIDD47mM8c4gwqEE20fyuiSzgNf2sXrtUIa55+I1N4OCB0b2G5md8ESmJKUhrt91zPsRraxIfMCLe4J/J8pUyGvnvMdp72yh+tpR7bJQJZNjefj2lax643SktTvRRg/moinreOqrq4h6Jo2Qx7bw1cNjqauxRjAYWu1+3V/bSP1VVkz75ka+WHIWNl9u7uhU/lFUjAsn/I2C3pOYszOJj7sQtrz0mIPvkqcH1aEHLX7EfvIN+3/BoRrRY/wOS2+K7xmJfdJ5TMy2yIJFO0whYfalXZKZUlNDxDMHWL1WF8w2O/Vf7O+4EFl+fj7XXnstrq6u2NjYMGTIELZvP6KNmqYxc+ZMfHx8sLa25owzzmD//rZlI2azmXvuuQc3NzdsbW2ZMGECeXnHX/vVGdSmJiIf2cfip69kc72ehYmzyeKBpz4mdfYQvXuPKMGoQQy7ZRczt1+E1wd7kQP8sJlbyPvbEwh5eoc+K1IVrL7bQsTNe0CWMD5VRNaT8Uju7ljy8gmdvhn3ZdspvyWhx4LVvwtOK7dhyexdXExycCBpUTAuG40dNgDu7b4qzwrR3Ww1UG2O3Yvt/wGCLPfNXbcTuCQ3kVXXsXFlT0gMwLh6KyXLgmhWD2fkD5GZNmZIh9soNTWEz9pPxuIogmdt77fGNv1OZJWVlYwZMwaDwcCPP/7IgQMHePHFF3Fycmod8/zzz/PSSy+xZMkStm7dipeXF+eeey61Rwjs7rvvPr766is++eQT1q9fT11dHRdeeCGK8s+181Lr67H/ZBN/zBjNcxnnAeAgNvHSxe8T+k0pKW8OJeDldMY67cf1eyvUujoyr/enuMGOmGdKkDzc9a7dg6KQgwKQ/HyoeM3Avf6/8fzV75H7pruuRNc0BINM4/k1JE8P+sc+b0fodQdzZ2eSno1BNiq4Lzv24nG1sQnH1Do81pfh8W067DmYjBAEXe1/AgT/D1kDHQkxPBhLfOQxO5i07m/tTrRn3dlf5d3m9aImB3Je6Z7EQF+e1vu0nxGH2ZeScReddv9Sa2ux/2RTv8qg+l1+8cgjj/DXX3/x559/dvi+pmn4+Phw33338fDDDwP67MvT05P58+dzxx13UF1djbu7Ox988AFXXnklAAUFBfj7+/PDDz8wbty4bs/jkPziDC5GFgzI/n6UnOuP+/fp/VLsLAf6U/KqNc9GfdPm9WZNYtrayUTdn0zN+BiiHtxPwa1+ZF/sgu+6RkqHWCOZNVrsBQxnlDEn+vD292y5mtAbDrT+wLrfl3DciqhbP4uvD2p5Rbft2HoLydmZ9Nf9MZla8Lu15Lip0UH/rsSwQLTs/OPicPt3QnJ1aSe7EAdF0eRjj01SMZas/iuvs5wVj+szWfhYV7eSmP3K7klMig4n/Vo3zjh3V4eNTlRNYGNRMLavOup+f305t39SfrFq1SqGDRvGFVdcgYeHB0OHDuWtt95qfT8zM5OioiLGjh3b+prJZOL0009nwwZdW7J9+3ZaWlrajPHx8SE2NrZ1zNEwm83U1NS0+TsSSlEJLXYCLR+ZaJg48pg/pyU7F4+7Gpnyyw2kNx/umry8cAzRD6UjSCKG24pZ98dA6kMdsC3UaPQ00jCmDs9v0vF5eQvW7znzZsFpgO6K4f+u1OYppbU094rEJHd3qq5LOGzY2AMIQwegrQCiuq9b7C2qxunlTcebxOCgz31S2v89iYFupX40kQgFpZjKm1BLyvr1WPIfu0j+PJKMOrdekVjuXAPjxm3rtFuTKGiM8c7A6qGCLqUZ/YV+J7KMjAxee+01wsPD+emnn7jzzju59957ef/99wEoKioCwNOzrSGfp6dn63tFRUUYjUacj5peHznmaMybNw9HR8fWP3//ttNaraUZ72V7cbWq57yZf1A0bXS3pSKCydRlQwRLdi4xc/LZUaMrlXNaXMn5IAylspLcWwcwNeh3nBPBfns+7hvLCJ9+AIffbFGKS9AsFuy+2cnubXq87ZmfJmJc27fGugByUAAV7zny6FMfoL3T3CP1tOTqAi9WcYHnXrCofT52Z7D/dCvB1/ZPtrRHOEHEsR1BKStH27av/4laVfBesgXLFIcekZg2ZgjKkkbO9E/tUfPfCIcSUp607bLJdH+g34lMVVXi4uKYO3cuQ4cO5Y477uC2227jtddeazNOOKr8RtO0dq8dja7GPProo1RXV7f+5ea2V8OrtbVU3u9LZqMbT921gqSFgzo1cJMD/cl4L5LaLzz1rGJHaWJRIulBfya6baNZk1j04SW4vr0JAO+NDayviSDothRq432pjnUhwTGdqJsSqbl6FKK9PeXXxTPngpW8XXgq0QsL+hwzkIMDqXjNwMyIbylqcaR2sT+W7K4TI4LBSOKcMKb6/05Wkxstbv0XSG6Fqvyt5WAnPI4TUWsWC8qBlB7tv9nJQJB9eY9IDPSZ2fkR+0me53pcyazficzb25uYmJg2r0VHR5OTo6/rvbz0LNzRM6uSkpLWWZqXlxfNzc1UHpViPnLM0TCZTDg4OLT56xBb9pL+ZDQfFo3ktXPfo/E1VXdNPQKSqwslr1qzeNhKngj7nktf/YWUpfHt2pM1XhTPk+d9iYTG/PTxBC3Z33oxCH/tIvHBWGRBJW+iBftVu/jowQuoabFi2syVCKvsufi+38ltcaF4YWif4x5ycCAVS2WeDv8OgBe/naB3RT+YDZK9PDsk4cqr4hkQlUuTZuBshwMUnHJ8PMBO4sSBIMuoBgGL2jvt199BZv1OZGPGjCE5ua05YEpKCoGB+lInODgYLy8vfvnll9b3m5ubWbt2LaNHjwYgPj4eg8HQZkxhYSH79u1rHXMssNqaTmG9A28Xnsr04J8Y8/4Ofal5ML2tNbdQmejKjoYgAEKNJSw5533SXvVrbSkve3vh9VA6XnI1qWYvbGY7tBPdimt3Un2ZkajpuWhmM6YftmK5XOHJb67iEq9dmMQWvp51DjZfbka0sSHtpVHUTRrV48/RcOlI7FfUtpKYgoB1iYB2MLNbf/lI/FbVkDVrRJtWeFJEKL63pdEw24eFM69mfV0v/cNO4vhDEJB9fZD9/fql3d+xQnJyJP+BEQQ9nIS9ofdJoUNkljLPtdWNpT/R71nLrVu3Mnr0aGbNmsWkSZPYsmULt912G2+++SbXXHMNAPPnz2fevHksW7aM8PBw5s6dyx9//EFycjL29rrtx5QpU/juu+9Yvnw5Li4uTJ8+nfLycrZv347UA+O9o7OWrR9YlkldMAy7bBG/z7PJvjaQCVeuZ4RdBk/um4Drm7Z6lkUQYORA8h5SeCx2Na6SrqT+rSaGb79NQAlvYNGIT8hvceGNRRfj9tYWqq4ZQWU0hL2Y3HU9oyBgPm8YtX4ybm9uBKBu0iimzf6Yp3ZNIHBS97EybcwQxizdwkjbdLY1BPPh52fRHN7IQ/E/8/yvFxL+USMBL6dzmes2FATu+/ImQmZsRHJwIHFhBAtP+4Tpq64lcmEujTHetNhJ/0oB7n8ZkrMz+Hj02da6387j4DVz3qB9GMVjsxBSNYEfUwYQ8VhFt6uQ3mQtj4v7xXfffcejjz5KamoqwcHBPPDAA9x2222t72uaxqxZs3jjjTeorKxk5MiRvPrqq8TGHu7U0tTUxEMPPcRHH31EY2MjZ599NkuXLm0XxO8MHRLZQQKpn1qN++SiVssRYVgsWTME7otdQ5Nm4JO543H8UI91CSYT5ZPjGHLnHi5z3dbuOFN+vYGIKVsRB0UxdPl+PkuMI3xqZq8uPNnPF9fPahntmM6y5ybg9P7GLsfXXzaSM57cwCl2KdSrJma9cS3eL27QNVsLQ3hpzEqKWhzxN5YjofFmwWk03u2KkFVA4ouRvHzGh62Gjo8duASvm8v+voD8Sfz/QZQou20Eg27ah6Oh8Zh3p2oCq1NjCH+0sksy+8eJ7N+AjohMcnCg8AMf3OebEDa0NVeUXF2oXOHM0+HfsTT/TCwXNdBwaiTW65JQa2uRosNJfMiRl0/9qJUEfqgaROrNoZCZT/pbwZwZkkreVZ696gUg2tiQtGgAs077isULrsD1XZ1A8x5JQG4C71faFlerpwwhfGESE5x3Uq+aePyTawias6NVpiE5O5P2cBQtHi04udbh7VCDNs0BLTmT5MWDePmswySmIHD/tkmE3Zn9jz7xT+LfAUGW0VStY7W9KFF6xwhG3bzzmGdl0DMyO2nj0wnUhoYOSQwARaEkyZ2VZSMofjsYLciHS57/heTnYhDt7VESU4m+L4UnXr+RHQ1B5Lc4s+GNYZCZT/JzMVwcsZeMByJ7TmKihOTkiNrQQORrDcz7aBJuK3aApiG5OHP2ZVuZcedKCu4dcXiT2Ci8F2QwwXknCgIPr5rchsQAlOoavP9ScNlkoGWjC9xuhbo3mdIb4ph9xpftSeyewpMkdhL6NT4qFim8kzZsqoLnin2s3jIYVTv2+lZR0BgffoDUec79YrT4nyIyzWLpmMTQ3S3D7t9E8QUGnD/ZTm24XgqyaOwH5L3vjzAsFqW2Fu+XNrLulhG8NecSXN/ZQtENA1k09gO+2DcUaVP7phydofjukZg/1xtoaDv3E/DMBp2QBIHSiyMZZpeJq1SH1dmlbZxi3Y2HXQ9Uo9amCSyiRNU1I7h6/vc0jq3F/9W9KKkZVNw4ijvu/6Y1zgewOPscncT66Ad2EicYWlpQjRKCuXO5jFpbS9RTqaz+eRjVLdbHfMjDZOZ4zGT2nyKynkApr0Bracb2q218e8/ZzEs7jycHfE/COztQxwzWLVa27sVxxSYkRwdOvXErRkHh2ZHfkLwkrkfpZfWUIZx/03pu8NtAs6/T4TcEgYobR3Hj9O/wkGspsdhj/sW9VdKh7ksi8dpQPisbztfl8UQvKm6zDFDHDOKmR1exviqcwJkWfUkcE0HclF2tLecAFueejTDDsd9I7Hi1bzuJvw9qUxOmvTko+R0Lzg9BKa8g+Ikt7H0nlormY9ceioLG+LBEMq/1Pbb9HPOZnKhQFeQ123G6vIi5r1zDitWnY9jTthmCWlfPuveG81nZcFylOpac8z7pC5y69FiSgwMJejGV0+yT2VYXjHFv1uH3fLyJvWMfZtVAlWLDgncn4bW4bSZRSUwlZ3oYWdMj2i1j5cpGFuwYS/qSqFYfM00U2VdxuDB4XW0kLU959kuTWtBNFvPujuuXfZ3EPwultLRnAmZVwfWdLWTPjWJzybEvC8vMdnhs77jUqafoee/4/1NIDvZQ27HuRbS1RbCx0aUSndiJCAYZr9e3oVlaUI7Ki2gtzXi+soGC36N4/VVbbvT5C5s1dgAUPjAaxQRByzOwFOpPOcndnZQ5zkx1/QmAb3cOIaLiiEyoKFJwbxCFSgCZMyRCXtuL2sF5deavpu5LIuJWK9QjYmbqviTsnhpI1nI3bEQzPyw7Bc8/e+mx3wUqBzri/14q/5wnyUn8I1AVrL7dgnVhLJufDWSkR+8tzwGaVZmdP0UTsPrYpD8n/Iws9zU/3cm1g9KmnHsHM/DnUlKWxnfo+1VxcwINnzqjDotGiono1EJF3ZdE8+32zJl3HV4rk5ADfDnrmi08f8u7FLzuhJYwGNnbi9SXfYn2LeL+z25iZdkIgj7X2pSFWHLzEPdnkDvWkcDFYtu+gT2E2tSE5OjQ2kVcMJlIvd4Gg6DwwluT8FzSv1oxxxWbTsbZ/sPQtu3D8UlrNhUH9XrbZlXm9+/iCHp+xzH7kp3wRDZnwNec8s5WCu9PaEdEgV8U813GAF446xNylrq0VRyPGsRpd22mYLs34tb9CBXVKF3YCyvJabi8uxGlspKSs3yJsSlAQmPegK+4+J01WH9q4b4hv1H/jC/Bj26k+CIrjD8f4c8lCEieHuRNGYyhXi9x6guE+AHkLvMld7qKYDCiDY5gxlnf8cLKiXgv3NxvRnYn8c9AMBiRYiIQTKbuB/9N0Lbtw3mGzDeb43qc0VQ1gdWJMQS9sLtf7KNOeCIDGGaTyewpy0l8IbwNmSkp6QRcl8mzS65lgEcRHp9UUnvVKOTgQNxfykFBJGxROprFoi8POyABycGBjPkJlEwd3eqU4bJ8C0uXXsKBJj2AGWos4VbvPwk1lpBzrl5uopSWtpmN1Vw1kqDvamiMa8B7Wd9dMFJutOPZ2FXEeBYhRgSTOdGOlfnDCH419V9NYrKfL83jhtE8blinM+iTANHBDsXOBP+gwWhHUPclEf14Kt9t6J7MVE3g54woomdW9KirfE9wwhNZvao/uYyCwsunf0TiwjCkmIjWG0VtaMBz8QZqLpFYvy6W22d+Se5CG4Y5ZrH+9eEoJV0vm7LvimXBxA8459aNiG4Hi8pVBc9XNvD5s2NZWXZYB1au2OHSQYxdiokg/N4DpNe4EXF/QZ+WlIcQ9WQSj71/PZd67CTuwwM8fPFXOJsawL1v3cv/Lmh1dVjn1mCdW6N31f4XzTj+TVAqKhF2JB63buPHAqWykqinkvjur/guySyr3pWgeWqvhOPd4YQnMkk47LNlFBReO3UFoz/Z026pqZSWEvbUThYtvZxLg/ewpiwKz28zurQ2UU8fyjVX/4aV0MLqTxLaNdK1X7mJ4us9WJClO9oaBAs1wUK7IuCUm1y53G0beb8FHJN7rWAwUnjNAII+KWLpE5fz0Z7hzN89luIloVS+qOgE/jdAMBj12WkvZlVKVTXKgRSUAym671Y/u9WeMNC0fyWJHYJSVU3U04mdkllWnStVLwWg7eyfrPkhnPBEZiW0UKNaMX3P5XxRPgw4vNRMWhzadnbW1ITn4g1suW4gSX8Foznad7pfKTIM7+fSibPJ4qnkCQR83HGZhZKSjmmKzIKscTiITcy69kOyHx2GaGODFBNB/eUjiXijiPtWX0fQh33rKH4ITecO5pxbNlLxsojT1kKi7k0nfHo5BWcrPBz2E8orDUieHt3v6BggubmSvHgI5Z/6kPtYAlJ4yMll4n8Mh8jsx1+HUWa2a329otmG0iVBWH+zpd+PecITGcCjmyfid3UauXcFM237lSgIGAWFpaM/ZOTH+yh8IKFNswd1TxLBj2/qtOOPHOhP9csqk903s7E+DLfpdNkeTUnNwDTVwEelI1vJrGSlHzZvVHDv3E9IesKFyId2t5vRIUq9CuqaftzGlqeHE+JYTumrJtTwAJSiYmwzDdSrJu4KWEPSk8HHxUblEIquiOCi4TsZ7ZXJOZduRX3DTOX1o0AQUE8Z8q+wpDmJ4w+lqpqQx7aQ8mY0ZWY7KpptSF0cg/2qXcfleCc8kc1OvYCox0rRzGa0bfsInZrHgx/ezG81MSgIjLRNZ/ady8l917tVsgB0uaRMu82PJ8O+p0kz8Nnnp6MkpnZ7HkpKOiV3+zM/czwOYhNzor/hVu8/sRXNWCeb2i2lBIOR8ptGUPFlAGJsVM8+rKZh9e0WqifboWkCCW9vp+HCOPxe3MZzb1/JnsYAXhn/HsLyljb7lBwc+sXwThszBNfL81rdQ0VBI8KhhOowEIxGCk6zAa3/LbVP4l8KVcH5vU2kvh7N/mUDcPx8x3FrpHPCE5nhI6c2syWlvILApzdw4PJA7v7zGpo1CaOgsGDgF4S+kkLFzQldKvOl8BAuuUC32XkudTxBSxJ7fC7a9v1YT5V4eN/E1iTEw3suI/Dd9jO/6svjuH/GpzwTuQrrpeWIg6N7fBxLdi5uj0t4GqoZ+8w6Gi4Ygs8LG/lj2mh+qY7lbr81xLyXQtntCcj+fmTdE0vW5GMnsvzTbIh2bF/iYqzVl5bWxf/u+M5JHAdoGk7vb8Ttrf5t/3Y0Tngis/9uT4evWzKyiL4/jWl/TqZJ021+Jjjv5J4Zn5HxXFtH1SNRH+mGo6R7MhXnO5N1dzSFD4xuJ6jVW7kdQYiCgBQZhpKejc/kbGa9cS3fVQ7B9zmxXYBfGD6QM2dsaC3yvt1nHcFvZyJFhPb4cxePdsLLUM0wm0zGPrOOxouHI/2+gwP3xvLwvomc5XiAx6Z/SNTXBTx343K0fuhcH/hmEr99MZzEKq82gd5GT7Xbfgwn0UeIEpKDg94P9d+M4+wWdsITWVdPAaWqmuj7Upi5+PrWlm4eci2LJi4jbbFPh4Fxq++38ud1cUz94UZmnfoVL93wDs9MeZ/ScYftT6TwEKpX+ZPyzhBkP11L1njxcIZ/mkjGcyMQrK3wfnEDiQ/HwrYDbfYv+/pQ+LiF0+wP24Wnmr1Y+1UcWl5hjz5z/WUjuXzKmtZEx2/FkfrM7NKRCH/twveOch7YPgmDYOFcx/2t1j7HCqW8Ar/nNiLfJvPDH/EkVXti0SS8NmgItjYopmMns84eMP9VSC5ONI2KgMBjK7r+xyAISG6uxxw7PeGJrDsoNTV4LtnIl3ePZUHWOJo1CQmNhcNXIn8qYj5vOIJ8REmqpqHuTiTiwZ28+cRlrChJ4JXss3D7MR042Fn7CSeeCP+eiIBitDp9VtViLTLIOpeZF39KS6xeaCuvadsyXvbzJfdVR+bGftX6WqrZixXPnY/fvI09agXWck485z/9B3E2WVQpNjy5cjLaIg8CjGWMm7UW9fShKMUlhE7N49F3b6RcsUNBQDiG0JUUEUrlDQk6yWgalowsQmdshQedWL1hCA6JleTdGIX7zmMTP0oxEZRdEHZM+zjh4OKE1KhAWtY/fSa9huzvhzggEsHK6piXnSd80XiPoGnIa7Yj7XRm2pxrSRisB+89rWo5/8UfePHbCUQszMBSVHx4k5ZmbD/fTOV6T6xkBUtxCZKTI0kLQ3hlzIcUtThR/a4fjlWbdI+xeF1HNjvxfLw2J3I0bzSPG4bjk5nM8/oNCX0a3qQZeHPZBfis2NijqbloZUXRnWbibLKoUa2Yv/hqgt/ejujgwOwvr8Arvgj73Eos6LMn/wVbWFg2iYpTzUR/nE9fo1cNYS6MuHsHm68IRP02DM+v9W7u2s79hO+WUEUBl0BHhE0dL/N7ipLRrnhsrDhZoH4EtJx85Jz8/zvdnRQZhgZoSWlY+iFu+p+yuu4JBFlGMOrTXMHaCvNKOx4I+pk38s+g4P1g3N7f3unTQxs9mDNe30ScTRaP7r8U7xsKUaprqJ48kuse/56sJjd2PjAU6Y8dbbZrHj+chHmb2ywnAab8cR1R0xJ7VMYhmEykz4rjuYkfoiDw1Cdt3WMFkwnRybFDwa1gMPb5iSg5OFB7TjRhMw7gaGjEokpsKQnA8q0bXl+k9VtBuSDLqCMGIGzcc0I34v2vQLS3R2ts7DL5c9Lq+lggSYiODqgNDSjlFeTs8EXRRKb6/s79Mz4l5e3YToPuwqZ9rLl3DDP2TeTuiD8oXeFJ1rOjuOqx1ZhVA+sWjuJoEtNGD25HYs2axN2bJxO9oKpLEjOfP1yv8bS3p3yyTmK2oplHfr6qnQW2ZjZ3WjVwLNP6zPtjiZixv7UphSwqjPbKZNQtO0l+LLTfxLCt7r4nSeyEgFpb268Z7BOeyCRnp9Z+ld1BtLIibXYcppVKawfyiJcyeD59PM2ahKtUxytjPiLsoxzKb0loH6BUFaQ/duB7VSbvPTKBphaZWVd8QripiLc/Ho/Tik1th58+lJon6tvNxB7fdwnht6d0KMgVraz0WNSIgZw3/w9Ov2ULgp8XigmsRJ2QNEk7bnqdo2FVDvWKsU2Wcl1+KH+tiCPwR8tJ4jmJvwUnPJGhKIhHdQg/BNHKqnXGIFpZkfrsUF645ANu9P6LxlBXACxFxThcXcmMj24kyeyNhMb5TnuYPuMTUt7peHamNjVh/c0W/K7OYMFLVzE79QKCvmzrdqGeOpThi7YzM+LbNtsuyTsL/8ctHc7ERFtbsqfHkTgniIoBdmQ0urHu7eEoial4/V5KcpMPi3LOIfKdBqRupuL9BY+lm6ma5sO3ewfRqOhL+NpEF3zfT8Tw8zZkP1+9TOkkTgJ9SSnED2h1iukvnPgxMnEisqbzteTq0to4V7S3h2Bf1H16YD9z7giev+wDrIQWHjtwCd63V7UJ7iMIaKMGkXatFTPO/I70Jg9G2aWztiaSpGkDuvQPE21s2mQcZV8fSt6w49mob9qMSzV78cX0sXqD4KP3YWtL8vxYFoz9mJUlw6m7yRGKy1Dq6vXMpyBQdd0obEosCBYV8/RKrOc7Ia3d/bfY94i2ttSNjaXkqkbODklhy5tDcX1rIxnPJSAAwY903avzJE58iLa2tAyPRGpo6ZGDx8m+lhwmsshpcwlclqo34nB1QWtuQa2tRQ4JQqusRqmsRBg+kPHL/yTKVMij+y/F5+66TmsnRVtb1IGhSJlFNMQHohoF7PeU9NiSRJBl0p4bxsuXLG/NTh7CtE9uJnjm1vY/sCiRMW8EL058j2m/X0PMrHws+QUd7l/y9IBPZO71/430Zg9eWHce0U+k93sDXmFYLMUjHfD5JhtLXn7r67KXJ5WnB2NV3oKppB6fN/PIeixSl5qcxH8PgoBkb48W4ocmCQgtCkJOz1oQngz2H4HpN3xO1rtBMGIgSnkFam2tPq1tbkGprES0taX4iRaiTIWsr4vA62mxywJwwc+b4uF2pL3sRflt9eRdakGr7Zk+SjAYyXl0BLMvWtmOxABumLCGysnD25dIqQq+f1iY9tu1hC9r7pTEAJSSUupf8uPdolPwN5Sz8OyPKLg6skfn1xvUBtsSd90eSt+woeHSka3nbCkqxn7lJgy/bqd4jDM7Vgw6SWL/RQiCbpM1PBb8vBByi9B2JqHuSToufVRP+BmZ/4JnWXzpZ6ypiWHPo0Mw/Lqzdal1ZFysSTXwyhOTsPusc097ydWF1FcCeGXEx4De5PaeH28g/N4t3Qa1BYOR7EeH8fQ1H+Mk6cvMZk2iSTPgIB7WAJVY7Jm7chIhS1KPSbogubuTOCcIVIGohxKPyayxI9ReOYphD21HFDSqW6z540Ak9vuM+L2f3Dr7E21tURub/tXOtCfRjxAEEES9A1lwoO6dZjRAZU2fruWTS0sOE9lZtleT89gwrrpoHc5yPavuPwfDz3rnoqL7RzNr6vtYCS18VjacwvMMKJWVne4z/5HRzL/13dbZ1FcVceRd6tzlDAkOkthjw5h1zYetpHWgyZcPlo5HtGgMu3UXl7oclmUoCEzfeQWB8zWk8loSn3bDfrcJr4W9634kOTgg2Nq0dnHqD0hOjqQ+FoP34CLi3NraDqmawKZXhuH83sl42AkFUdJdSzqhCtHWFsHbA8XNHik1T49Di9IxP8BOLi2PgFrfQNCTm9hy/SBe23camZMOBvpHDCTuyr1YCXo/vfNd9pD2cFQbX7IjYT5vOGddvrXNkvDPVUO7JTGA+ouG8sTklW1I7LM5Y/FYugG3NzeSe6M/U9dfS/PBym0JjYVDP8XmpWJyF9rwbMLXqH0o6lZqavqVxACU6hqsiwWcrBrbvL67wpdtL8Tj9lf/Hu8k/llIbq6IgyIRpI4vQEGWUQeG0hjmRovdEcLzv3kWfsITGdBaHxlyUxpyhYHaz9xxfKmAK922sLk+lCV5ZyEJKs9f9gEVH7q2t4QeMZDyAQa+Xx/P3iY/AJLM3gT81PVyTXJwIP+R0Zzz9J+tThYHmnz5fPZYHD4+rClTDqQQdW8qD3xzPbsbD5se3u6zjnmxXzHrq0n4Lup/V80+QdPwfmkjlikOfPfHMGpb9C7jRVUOOP+RiZKWiRQZRvP44f/wiZ5ERxBMpi5tqg4PFPSGMAMDEavrO8wwyl6eqMMH0OJgxFhlxjqpCKWi8xXN8cQJv7Q8ukRJtLGh6KYhTLh9LfE2mTy1+EZ8PthP6aUxuFyby+3+69heH8QPy07B99t8NFki9VZPwmbvQ62ro+XceK56+Qde3HMOQVft7Xy6bWVF+vII5sV9ja14WJw69fubCJ+2qcNtEAQYHovjSwXc7LUeBYEXMsdhc11TWynIvwSCyUTz6QPJvBLOG7SPNT/EEThzIymvDif8AzPCxt3/9CmexFGQvb1Q3Z1Q9yZ3eO1Kbq5oXu4gCSi2RuSSGpT0rLZjRQkpJABzoAtis4oxs0RfmfQzlZxcWnYBtaEBj1d1X/4HVl2Pz8fJKFXVuCzbiHRpDU98dC1DbLN57t53sH6/nqT73Al/p0QPlmsa5TFGPOQa7H+x7fSHEwxGMh+NY3bcN21I7LeaGKLe7OKJpWmwZS9Zb+szwu8rh2B1v/W/hsTEwdFkzUloFQFrZjOGn7cRdW8ie+cNJuTDYqTQIALDSpBTO8/8nsQ/B7WyCqGwvFMSs0T6oxkkhJwihE37UNIy9bFHzOIESaLF2wljaT3Spv26/OYfng/954jsENQ9SYQ+uKmNvkqpqSFwzjaeXnENVYoNZ7om4/mXgJKiW/SIVlZYjy3h89JheK7uuNkIQM3EOGZe9XGbbCTArko/tJzuEwNV4xpYXxdBykMxqPuSjuFT9hyyt5de6dAFku6057zxWyl6QabqusN9DtT6emy+3IySko7iYgcvu/e7bu0k+gdqU1OnGUTBYEA+kI22c7+e9FIV3WxgUBRCfEyrnZXW0oy0aT/q3uTj6vraG/xniawzaC3NBM7bxqwPr2bJpxfh8PFhOYYWHcp1QZtJfju6jQj0SAgGI0VjNIosju3eu9N/LemPxnbZUKTmsjjuHPgn3753KkcXmB9PlIwPJuPJoTSPH96h26hoZYXRRSfm03zTGX7vDnLe8aHq+raNW9iyF9P37SsTTuLfD0thUZusvezliTIqhmY3W8SaRrQjmgJrLc3/+CzsSPy3iawTZwbRwQ5NguCX9h3+sQSB1BvsqbTY4vF757MqraWZ8GlbeGvF+ZQrdm3esxXNzLv8QzKejuuwFlIOCSLgnhRe2Xg23q/8vcF99y/2E/ZaDk0uEiVXxyIdVZ9aefkQTgtKP3yuosJZASkMumsPWVN73k+grxBkmfrLR55sLfc3Qq2qxphRinFzkm5g8C8irqPxnyUyQZYR4mJ04d5RyJoSxZWXrKX84gGtsydxUBS3n/0b72w4DUt2N/EfTcP/pe28d7BW9wAASBBJREFU8swVrVnOQzhEZsUfeiGHBLW+LtrYcGC6B46GRmLmlvztTTqUmhosefk4frYDQYP866KQvTxb35cbNdbnhNCsHvbi/CUzisTnYwn6vO9NhXuMgZE0OYn/6pvp/w6CoMe+Onk4qE1NWHLzeuSH90/jP0tkmqohNraguDm0iw15bzDzaUocUx7/guRXB6IlDCb5ZkeCTSUEfqv1SCOjmc04friJr549t0MymxP9DcrbLTRePALR1paUOYOYOHIb6Q9HY8nM7tfP2htoLc24vrURv5UZVJ4erFt9m0zYfrGZ4Fuy2bg8jv1V3qiaQLBbOdYlzZ32/+xPCMmZuL13stSpXyAIurXV8FjUMYOQ3Nz+6TM6Zvzn5Bc9hWAyUXxLPOfdth5fUyW2opnXM07D+fKCHnnnHwnzecORHixmWuCv7Rp9ZDW78fL+s7gj5k+WvXU+Xot6p94/3pD9/ag41Q+7nCbkbUmoTU3IwYFkXe3L0AsPsCE1hIjb9/9t/mcn0XeIVlYIft5Y3B1QTRJSQwtSer6u/foX0sDJEiV6T2SCLCN5eaK1tLRxUpUGRJJ0uzP3nrOaz2aO67IWsyvIXp7kvu7C87FftnuvXLFj3rtX4vfiln9l30fBYIQhkdQF2GD3zXb9HEUJLWEgYrOCtnXvP32KJ9EFRHt7RCdHmkPcUUwSxkozQlJWt1bT/zROEhm9JDJRQg70Qy0pQ7NY2s0uBMP/2jvP8DiK+49/tlzRnXq3uqxiyb3bMr1DMCWB0EINCb04JLQk/1ASbFoISQg1hA6GQOjVDmAg7kVuki3L6r3X053uduf/4mxhYUmWbJWTtJ/n0Qvtze3Oze19d2Z+zYw8MQF9b9ERffFKajJt/4DfTPy8a2Z2KBGTVBU5IACtuWXkg68lCYTwZjUwmQctH7/BICMrKEHeOFsRaMcVHYCs6ZhyyhAOB8Ll8mkB24/hEDtAZKsF0dKK3t7e4xJJuL37QEf65Wv5hQRc2cE/Sk4EoEW3HiRiamJ8t9qNsr+dzpnJqJE+sI+x/5mnKFT+NI2Oc+ajhIeNbJ8MuiMryFPTcM5LQYsOgZp6zBvyUNflotXWeu/x/t7HkoQSEoIaG+Pz9USNcnB4vf0Z4L7XYSMECf5eX53/23IOE/+ejb7vxpJtNpypkcgeHeV/jQiPB62pGdOaHDw+VO5Lq28g8qk1qInxNJyShq0mCcvWIsMJdrjZn6bdYkEOC/WOvy6QWxxYqxvQauvRDmMWL1utyOFh6GGBCElC35Hn8zM4Q8iGEcliIffuZK4NfZkVzVNIflDziqisoGSm0hlhR1clLCXNaAfcOLrT6X0ihgRCfWNXuu4RRQg8RSUElpSjpCXTdFIaqjMFc4sHc05ZrxWbDI4c2WpFDg5CBNgRNgvCrKJ3uBGV1aBreIp6jzrp85zhYYggf3SbGY+ENyVPU5NPGgJ+iCFkw4BssyGHhaLX1gHg0C189/gCgrd483YpqUl0xAeCEPgVNXnj235IRAgd8YHY+pmNdtjQNbTd+QTk7UVNjKfmhFhaTkohOC+FsM/3GoI2BEhBgeitbegHjO2RbnVLQYEIPwuiyLuPBqCNAgHbj7HZ3xeShGQ2H5lrgaxQducCEk8tQrrUG7SrzUxDzS3pSrXtyspAdXgwFVThqa7pOaA3KhJJVfFUVPr8E1IJDqJhcSY1CwXhG2XCP92LVls/8saKA5DtdiSTOiRplw+FZLF4i0Dr+vfOpvt8u+TQEITFhOTsBEnyiYDskWIgm/3GjKwPZH9/b83I3D3dX5Ak1JgJhxaVfUVDpizcS9PDCVirt3jLYa3dgbYvIFefloJQZUzlDX1muRhNMxutqZmg19YRkj2JgotCaLhjIpI7hYQvOlG/2uwTP0zPrDTKTrSR/EYV2t59Dsh9ZEEdCOqEaITd7/sDzW3oTc0o0ZFoUcHeB6SjE0+QFVNVc1fhGjkyHC0sAKWsFr2pGWQjkqG/GELWB3JoMLT0sJST9hl7D3GTKRFhBGQ20PRQApZPNiAkidzHJhL+jZnQF9YgpSXjCvaGQDlTIrHY/aCyts9026MGIdB37CL5XhXZ34572kTKj/PDPDWL2A/Lvfs4I/UjlRU6Q8y4JrrYdXMEflXRAExY7eRIA/VlqxVnZiy62XuPSLrA3OiPXCJ5Z1o5BegdHWhCoFit6PL395KnsBiKJDyGeA0YQ8j6QJhUREPTwS/oWr9SXGvVNURd1IbesS8ttBDIzSbqZ+uEvgBSVS1StB2hyuhmmY6EIJQof8ybNLSWlsH9MMOBrMDcydRP9yfsn979v/2WV/nbLSSsUXGeOovys2KJfrJ8SCxh6oRosPacXUSva0CyWmk7KhnFKci4ZQ+i8/s0NMLj6aG21cDQXS4sWwpA3he/6Pagu1xoLhf8YMKt92SJNkTssDCErBeUiAgklxvtCKoP6cfMQmrrhOycrmMZj5bSeHQ8AFpdPdaiQJwTw/DLrQK3m46pcRAbBaNIyJTJ6ey+JhRzbDvuEjvBvaRQEx4Plk82ECUrCF2j6bIs2uIkEj5u8BZKPsI9NGneNHKu8gN1nxh4JAJ3q8j7TmuvikZxCfxz6r25047oar0gxMjPqCUJJTUZWtpG1ZbEkWAIWW/IEtoRFO6QbTbyr4FrZq7n7cdOJvQF7wzFU1ZOwPIDcpnVN2E1qXjKK5EUBUmPwx3uj6KqPu+7sx9PsB/+RTJxD9b0aqzoxj7BsrRoNM5wUjJXQdqwgMQ3yxGtbX37o0mSNyuH+v2tK/wsuOKDaUk0M/mBYu/+EniXtz34B/qOyWFokFQTeqAfck+riTGKYbUcAuSAAPY8k8Kj895mec18Wi+w9mspiiShpCQhafqIZsAYNiQJJT2F0rMisdYLwrJbKD09iPgVLYhNOw8WRFmh5oYFNM3qJHqliuryvm4vbEOuqEVvaPKZjKUjzr5wstGMYbUcQWSbjd1/msJj817lf61p1P4hGbW8n+lnhOjZh2ysIgTa7nxiducjmcx4jp6KI8FD2W8Fls8XErmmkbLTQolb0QR7S6n4+TS045qJf9mO3/vrun6ogrE/yxowo1zEBoohZINM7SUzeOSM13DqJr58ZiHh/zWK1fYH4XFjKazDVhJHZ7CK31n15B1jJyK0hrJFZtoqM4lIrMXtUfDPaxpVzpoGQ48hZINIyyULufRXn2KVO7nz/StJfX7DEVvBxg37Qp7iH6lADg7CPSUBbbKVlnCvP5Yf0FYZAQJaMzRsOX2fbqwiqSpKeBhafaOxjD4AQ8gGCXViEsfevpY0SxV3bD2PSY8W4Rklm/W+hPB40OrqkVfVE7FqpHvjewhN80YB2P3AFIRwOr2lCsc5hpANElpYAKFqO7dnn0/yTbU+U4vSYIwhBJ591nTJYukq0TbeGfOjoAQHQnPHkF9HbNjOyhuOJimv3OuCYGAwxAiXy0gxvo8xn1hx9wMp3aoBHQmSxdJjGbf9yN9uGTcOiEeMrKBGR6FOiPZmnDXoHVnp874zGAIh83g8/P73vyc5ORk/Pz8mTpzI/fffj67rXW2EENx7773ExMTg5+fH8ccfz86dO7udx+VycfPNNxMeHo7dbufss8+mrOwQZdh64NGj3iTonU7qf5F1yErafSJJ5D8wi5a3wo0f3iAg+1lpyUqi+ahEtPSEke6OT6OEhUK0b2doHWkGXcgeeughnn76aZ544glyc3N5+OGHeeSRR/j73//e1ebhhx/mscce44knnmDDhg1ER0dzyimn0HrApuWSJUt49913Wb58Od999x1tbW0sXrwYTRu4x9DlUav51e1vUfbGRMSiGQMv8ipJ1F+9kN/86ENOmrAb6UgE0QAAvb0d27vrsL+9DtYbxUv6QrS2QuPoCVkbCQbds3/x4sVERUXx/PPPdx0777zzsNlsvPLKKwghiImJYcmSJdx5552Ad/YVFRXFQw89xLXXXktzczMRERG88sorXHjhhQBUVFQQHx/PJ598wmmnnXbIfuz37J969QO4f+TmmszvyLBUsrUjgWf/exLpLzSjb8/rX43KrBmc/ty3hKptPP7k+UQ9sc6ncmsZHBrJYjH2k0YZI+rZf/TRR/P000+Tl5dHeno6W7du5bvvvuPxxx8HoLCwkKqqKk499dSu91gsFo477jhWr17Ntddey6ZNm3C73d3axMTEMHXqVFavXt2jkLlcLlwH3Kgt+4Kuw59fj/qilU/nH8szp/pz7OIt/OXMl9l98gSe2ng8okMBQNIlMh6vRdtT0O28amwMlocqmGwt58a1l5BqiJjPIZnMSGZvGNqBVbCUwEBaT8qkIVOhI0on6UM35q+3jpoYVoP+M+hCduedd9Lc3ExGRgaKoqBpGg888AAXX3wxAFVVXtNxVFT3DfioqCiKi4u72pjNZkJCQg5qs//9P2TZsmXcd999PXdK12DtNhLWQtm/Yrn/jCuon6Vx8pydzAssJFptwi1Unn7jJ8g/yKFYdWYi90x4CQ2J8C+shoj5AvtiUhvnReGIklE7BM5QCd0M7kCd9H/Wo+Xuoe2EDBovayPA6iIAqLvJhJg1n4RXC7pcGEYramI8ekOT4UO2j0EXsjfffJNXX32V119/nSlTppCdnc2SJUuIiYnhiiuu6Gon/WCfSghx0LEf0lebu+++m9tuu63r/5aWFuLjvelyZKvV+6T2ePCUlRP2XDlhQEV0FO+FHUP1UaG0JkFacSk/fFa3HN+BWdLY7Egi/Jvyg143GB4kkxk5MRapvQPhdJF3XRRKvIPgj+2EvLkZ0dmJ54TZ1N7iYNedgSS+MRf759uwVaSx96cR+E9qxGZ2wwk15KTFk/xWLKYvs0flg0m223GmRGLVxfAJ2WCkfR9CBl3Ibr/9du666y4uuugiAKZNm0ZxcTHLli3jiiuuIDram42zqqqKCRMmdL2vpqama5YWHR1NZ2cnjY2N3WZlNTU1LFq0qMfrWiwWLJaeE+rl3z8LfYKT5H9JmNbv9qZ2EcLrtFpVTfhOCIceRSrxOZkl6gWYTBpxVQU9tBhhxkCWg76QTGbErEnkX2BHTWgn5N0oAt9YS/qyPCQ/Pzzl28FsBiGwbNxD9CMTqVpooewKB+bZs0l8v460pSVo6QmUnBGKltFOVFzjvtnZAhLeKPbmxR9FCJcLa0Ftr/1Wo6PQm5p7Ttx4ANK+38shxUlWqL12Pu5Tm5G/CSbmv4OTP24wGXSrpcPhQJa7n1ZRlC73i+TkZKKjo1mxYkXX652dnaxatapLpObMmYPJZOrWprKykh07dvQqZH2htktcNWMNFzz5GWErTBT9cSHMn9Yvdwzlq80kXZZHwk1Nh7wxhhtJVVEy05BM5pHuyuAjSbBwOnv/OIc9V9iQOyUiltsI+TQXAK2hEWH3o/a6heQ9OwXJYkFraUFas50Jf15NymMenJE6e++xUnz9FJAlEj9uIfRjP1xuFZvZjf2EGnY/HEHdtVnIAQEj/IH7j/B4ek0VrsbH4ZwSh3wIFyElMBCmpSEH+PfZTk1ORJqRwbG/2MAj095h6Y3/4pTX17Pn73OR5kzxmXtv0K2WV155JStXruSZZ55hypQpbNmyhWuuuYaf//znPPTQQ4DXRWPZsmW88MILpKWlsXTpUr7++mt2795NwL4b6vrrr+ejjz7ixRdfJDQ0lN/85jfU19ezadMmFEU5ZD8OzEdmCQnH8VYItyV/gVnS0JCocgfzatkCqlfFEr+yDXlbPqKzc/RsBMsK6oQoRHAAWk7e2JmVSRJKeDg1Z6fSnA4JX3Ri2VzQVV9RUlXk9InsuTKMS09bxSxbEb9adyFpV25HnpRC7q8CCM42E/P2XoTTiXtqMs0pfrSkQGew92Eq7BohEa2YVe+MQhcSdYWhpL/QhticMzrHUlZQI8NxZcYiuzTUHYV9p0uXFWSz6fuHsyShZKSi5xd3BaNLqsqeF6YhNJn4dxQuf/gDYk3fZ7/NccbyYv4CAl8NJOCT7T0msTwSBmK1HHQha21t5f/+7/949913qampISYmhosvvpg//OEPmM1e9RZCcN999/HMM8/Q2NjIggUL+Mc//sHUqVO7zuN0Orn99tt5/fXX6ejo4KSTTuLJJ5/s2vc6FAcKmeNnx3Ds7Wv57OVFtM3pIDOuisWR24g3ezORVrmD+W9DJmu2pTHp5s2jQszkgAD0zCSkLbvHRBYESVWR05KpOj4cj59E9Np25A25B302x48XcOK93zHfvhdNyDxacBr2O/3Qs3NwnTGPMx7+mkxrOW/Vzmf7W5OJfWWXt6CxJHUVjVH87XimJNOYaQOgNVHCNL0JISSClgcQ+NG2Qf9RDjWSyYwSE4Ve19C1dTJQlLBQtIbGrvc2XZbF9b97h5UNk2k4U6L55HRaf9bCL9NWk2ap4i/Fp1C/PJ6YSwupbA3E/FIIgR8PnqCNqJD5CvuFbNItSxHHunEX+ZNy+xqQFSSTClNTKT8xCMf0Di6cuomjAvL41YYLmXjZzlEhZPvrIHbVRRytSBIiazplJ9mxVQmi/luJp6i01/0XJTwM/S0rTo+J+i9iiH8+t3uO/PnTKDrHn+NPyebYoDyevut8bO+u67sPsoI0K4PKo4NoTdNIf8mB2DC+nXQliwXHBzH8NuUTXq3Jov5EJ7rTiaSqdJwxG+uSCmreSSDyydVU3bqIh25+nibNxiN5p+BZGU7c20X9y4rcB4aQ8b2Q3fzdOSSFtvP5JVnoW3MPbigrqEnxlJwfQ2iOB+tH64e/s+ONfctH17QEWpLMCAWvgBUW92smoSYlIBqa+lw6qbExuBMiUHeVDKgYiHRArQTZasV17FTMDc6eU2+PYaS5U/nJK1+SYKrn5vUXk3L5jm4PeHVCNPhZ8RQUUXPTIpYt+d4BXkPivfo55Dw6Ff9/H+Ih0gdGqusD2Hn9JL49KoqInF7STesanoIiYh4uGtZ+jVfUxHgajopFdgsUtyDi3V1oTU0DquXoKSo5dJvyCqTyigGnwD7wx+o8birVv3SiKDr2txcQ8sHOceG3Jakqu39uI1hpp17zJ+Z180GrlAP98KK/beT6yVdw87ErmWwtR0FwXthGUv9Qw+eNx2Ja2c9U70fS57E+IxuJ4iNDhZqUgGjvQKutHemuDBglIoK2o5JxBimEf7Tbu2/l6+xfch4bROeiVpy1fiR8CrYvd47+JX0fyDMyaU0LxK+2E3RQs/MPLeCygjQ7k7ybzTx51GsAlLtDeOuKUw47ltaYkfkY0pwpyE4PWm7+YfveSCYzem09HEbQ/IgiK7RcOI+GyRKJnziwfbQTbTTsQQLoGmLTTqI3S0hfTybvKoma2QqBwdMJLHEif7vNp3ypBovSM0IILNSRV20BQD9Ee28jDbFxB6HfZMFR3kOvli3Aum1P/95/hIz5fGRDgRIYiJrUv9Qzst1O/X1uTn1rHfmPzTs8vxtJQszJQA4N8Tlftl6RJO/G/DHTsbRopPw5B2mNb8U5KqnJeE6ac+hsKEIgtuxk0t07SP7rTkKWb0JXZUp/u8Drj2i3D0+HhwpJ6hqDlosXcuaFqwm/oQhlUuqATiPb7ZjO/z4fX/XXscN2vxpCdhiU3DCVtHcqqLhjEUpmWp8/hPqfTuf29M/JsFQSmNwE8gBTCAEIgVre8H3hWR9GiYqk8YosKn+VRdtRKZi27MXy8QY0H+x7e0YEpz7+Dfl/XoA8PaPruGSxoGSmIdts3drr7e1oTc0IdydquxtmtlDzOzf5f5iONHfq6Es7LSu0XLKQqnczyH9lpnf/crLECQG5XBv7NaVnRQ7odJVXz+BXKSsBeLbiWJL+M3xbIKNs5H0DzQLHBORxyjU7WHNJGm9sn0vYSutBez/KpFTm37iZQNlJp1DweyP4sGPVPKUDTyo5XMhWK0xKpn5WMK5gicgtHYS/X4DW1OzT9Sb9t5SxsiaDf5z9An+YdDYhZyle48+iKSx+4kte3rsA/+eD8Ptgw8EWy/U7SbonleqjQlFPaaPi9xqdW+eT/E4D+rZdI/OBBoKsUH3jApbc+DbRqvchc+e5VxP7bSedFylsciQT/0F1/78/WcF5dCuBspMmzUbtXyZiyz18i+VAMYTsMEh6JJu/bb6I0vM93DX/M/6R9TrOhSZevjqL5nvnoH7ptdKUnBvJjSEfAaBIOlVndBKYP3XMmPJlmw3XokzqplsIyfMQtqUJsXOPtxLSSHeuH3jKK3A/Oo8Xf38U7o8jQPemPik/1kqGpZKlk99jz9JonpxxJglftCFn532/VNI1tJ27Cd8J2p7ZFJxnwz69ib3mEJK3jeCH6if6omlcfu1n2GQX/6w8hlPDc4jM7kBXZHRkXt6YRXr+ln6fT02MQ90UwB8Dz0QXEsGfbh2WvbH9GFZLvBY1ra5uwOIiqSrtZ83BfGMlNyR8jV12ccPHV5F269qu8zaclkLnBY1cleItFZfjjOXZnKOIfsGK5dMNA/5cksk8op78ss2GPjWF8hMCsDYIQnI7MG0r6DscxsdRAgPRWlu7vv+Gn2dx2i3fkeW/B2VfZdI17amsv3x6z76IeGel7qzJFJ1pJqBAJmp9C0qldzvAFy2cec/P5anjXuGflcfQfmM4u39tY9JNe5BsfuQ/PoGJD3sQW3Ye+kQAskLlrxYQucmJOXsvemo8YuOOI+6j4RDLAIRMkpBmTkbK3XvYG5NKYCD1507B//JynB4V/x8Vd7NmyVYrYkoKeVf6c/0JK5lmLeP6lVeQft3AnG+VqEjcaTGoG3cN+6a/EhaKa0YyNXMtSB6I+6ASvbh8dIVHSRIdZ8/DVtHRt+e+rKDGx1ByQTzzz9vGT8I3sjT/RwSeW3HIcVejoyi7KAVnVhuqquEqCiD1jTbI3jVihg45IAA5NBhPSRkIgTw1g5QXCpnuX8orvzuLgP8V0njSRAJf9z6AZasVvdPdf4vs/Gmc8cK3FHREsGXpbGz/GZwlpSFkDNCPTFYGxYyuBAbimTYR6X/ZvV5HP2o6+ZerhGxSiXh6zYDOr8bGgElFr6qBScmQXzLkT3slJITG0ydRvUgQUKAQ93aJT+/X9YUaH8fcjwpx6ibe/zCLxD8cevzVpASqT4klPLvtIPFTwkJxLEjB7+ud3eILJVWFaZMoPjsIdWYTkiTo3BpCyr9K8RSXDvrn6g15egZ5t/uRGlPLMRH5LH/tROL/uhkpPobcO8JQ61Um3r2WhqsWolmgM1Ai9uE1SIpC/oNz0UI9JC8H81fben1gyXY7e/+Zyt/mLQfgjqeuZsKfVw9K/w0/soEySL5AWktL7yK27zryt1tI//bwzu8pr/D+SGZlInV6EJ3uwzvRoZAV5OmTKD0tGI9dEL3OQ8Z9BehNzUdcPd11xjxsJS1oO3cPUmf7T9n5CdxgX4mC4L1J0w/ZXjKZKbg8jsXnruGDjxeSvOX78CVkhaLrM/jdZW/yXPEx1H0ZQ+Kr3txmwuOBLTtJ2Oodx6JzQrDPrWN3WhjB/40j4q0dwxMhkFdEzLszmPq7CubaCmm+cA07/xWOtqeA9GsKkVQTQgiEArfc+g73rT4byWxGMptRXBJPHPsKVYuCuP+LHxO9WiJ4Rd5BjszNZ03jT3PeAGC7M46YL5sZiZmRIWSjDKFpKAXl3bIUDBaSquI8bRblx6hofoK4Lz3Yv8xFb20dlM1715nzqJ1hIuGr4kE428BQo6OYccEO/l5yEumBNYS/Yzvke+oun8N9l75GoOzk61lp3eIwlaBAOmI9FLoiuGvip2gTJT74ySw2/jOL8Gf3zfR0DT07h8Qd3nFtPENGO7uRXfMyif8MbB9nD9nSXLbbaT9lCkIGVfZuu7/75QJS6vYt+4TounbUJ8UsSzqPuI06pbfNQdIh4YsO6s/3J1pt5skfvYjzDBMv35BF0RtZTPigGE95BbLdjnRlTZdV/uWXTiMme2CrjMFi/ArZIC0nhx0hhiS8x3XmPCoXqriDdUJ2QNR7BWjVNYNneZIVOsJUEh7bPCJOvaWXpHCs/wpqbk4gv7iTID0PYbP1mXLGXq2hICjqDCf4QVu3fmuNjcR9ITHh+CZK3GH8fdfx/DpzJevVWSipybRnRGBfuxetrh7h8WD5eAOTvrLRcfwUms+QqL+sjZrZc0j4vAN1++AbS9pOncri+78k0VxHsOKgXvMn8VN3jw8/T3kFSb+rQCyaweX3r+aZLceg/jWXp357PhVnu3kw6x0CZSfXxHxD523/43/XpPPpq4uQ3fDbid5wpN2uCST8u2xAMbODyfgUMklCmp2J3NKBXljq+xvWwyC6toImJpabIK8I3eEYfPcJXSP45TXDapLfjxIcRPqP86hz++OIs2ETkbgebKN4VxppN/e+Md0eraBIOo9+ehapazd2WzLJ0zNIviOXaFMTN31zKYlvS9x/4WLSn11P7t9m89DJb/JB3SwK/rqQwHc2IjwedIcDyycbmPS1DdKTaM4QKM1Oas+bQuTXFd7sH4OE7f2NfCifyPVL3wbg96t+wqTvtvW67FMCA6n7nYMJpkYS3lDQnU7s76wj/QMzfzvnIirOcnPX/M9IMNVzQkAuJ1yfS73mT6DsFfd3SmYRUjVye6fjU8iEAE3gCfNHKTf5tJApERFIZtMR53Y6FFrunkM3OlxkBUmWRsxqpzW3UPX4fIqvCuXqpR/jFCYyLJVcX3JZn+8LKujkV6suYvLjZd33BiWJXdcHcmvEuzxSdBqZtxegNTSSsS4EbDaOmplHoOzk0sg11N+/nXvPOYuID6wEvv29oJGdQ0C2N44xojyEyosyCCiLwrZi2xHPWGuvy6JxhoYlzEGw0k6OM5aMv7Wi9+GMXX/OFO5Me43fZZ9D0sqtXYIn3J3Y315H+nsq/846jfxLVc6Zu4VTgnYQprR5xxcJx8pIgpz5R9TvI2HchijJDhem0jqf9PGBffGc8XFIFvOQi9hQIpnMlN21AHlSysh1Qgjs76wj/IIynnv8bHa2xbK3M5LUl/ued6pfbiL9FxsPstLKFgv+hSofNc7k3Albyf/NJGSLBa2+Aa21lbI/pnHTe1ehIRGmtPH3+W8Qd9Me5KCeLW9aYyMRz6zH3ORG8j/CuE1JoilTcPfxH/H47LdQEHxePRmKey+wosbHEfWLQjQkol+09vhgFx6P11B17Qb2nB/LbW9eRb3mzfe/vj2F+H8fOrXSUDI+3C+Ug+tRHrhxeyCy3T7i4qZERCBZLWhVNT49W+wP8tQMQp6ppvk8s7dqlQ+gxsbQNjsO68ebjmjJribGU3BlPIvO2EbVeYHdHjh7H13Io+e8ym2f/4z0yWU4/hqL3/v98xuUp2bgCfPDXFR3WO4akqriOWY6hT8XnJaRS8H1qX06qJbcs4i/XPY8z1Yci/PHWr/2YCWTmdYP4/ht6ifc+dzPiX14zaAbnww/Mr4XspOCL0OalIqcW9SvnEp7XpyB1GAm/gsN63+3jUgdPzkgYEwl8FMnRI/6gri9ss951lNa0U0UWy9aSOUpHjLvLARFQauu6eMk3Wk/bwGV53YiKwL/72zEfHx4/meSqqLETuhyhO0JdWISGf8uYZ5/If+4+4J+O7Mqqckc9+4O3iycTfQVNQPKwttfBiJkY35pKZwulL3lSBMi+5VCRzVp/PnMV7nh8bfYe99sbzmsYc5q0B8Rk0xmlLDQQ6eg8QGGQsT0o2d6y7j1o6TfkKJrXpH5wcwuYPla0q/eiFZXPyARA7C/s46MOyoJXOWH++Rm9jwYStsFCw/KxnEohMfj7Vsfc5XCn8VwStBOHss/mYCv8vp97t03RDHJWolleciQiNhAGfNCpjtd3r2LvL2HXqbpGqk3l3HX65dT3BnO4+e/wNz38tn99ExcZ8wb+R/NPpTwMKqvnUvJLzJQ42JHujvDjySR/zMzt9+2nPx/ZSDPnOy17I4hPJVVhD+7lvj7dKQCG46fNZH/hxk4frzAW5NyEFACA4k9vpQqTxD+fw3qtyApEREcv2gHb9fOJfTLwkHpy5Ey5oVsoGh19STes5oPf3cSWxxJZNnzeer4V7j5r2+y66kpKKnJw9IP2W7vebYlSbRnpeAMh4BSHdHW3mM7eXoGzJ82DD0dfiTVhBLUiSzp/H3+G5z46jrqfz5/pLs1+AiBvjWXiQ9sxe/1YPQ4Jy1XtFBy/VTcp84dkKD1tKqoPW8KNyZ8xdLs0zF/1f+UHXpTM6v2prH9zck+s+9pCFkv+L2/ni/+71herckCwC67eOqYV+E5Fx3nDOGPRpJQ0iYiR4YftCSQrVY8J86mdqb3pgze0UTrCel4TpjdTcykWVMoWRyKI3ZgS5HRgnB3kvbLPTzy4CV80DiLNEs10ij0be4vusNBwJtrybi9ktCn/Yn/62YsFW0U3zgVx08WHDJDrRIRQd5f53TLaqwfPZNzfvUVTZqNuH8NLKOKcHeSfmsJMf/ynZJ5Y36z/0iLj6hJCex9OIj7Z37Q5fy3tSOBD+4/8YhKXfV6vcR40AWesvJuQibb7TScN52WiRJin2YpThAqCAlivnNh+t8OOo+bRvVc715g0sve2L+xjJKZRuVJEUS/tB29tRXZakVKjEPL2zsmcr71hmQyU3DfHOxTGmnLDSHtlYZeK84XLs3i0Z++xF+LT6b20zhiVzay6/oAnjr5JW788CrS7tjsk9Zxw2rJ4FZRkq1Wqn4xmzN/8S1H+3s3RP/bMpmcM6MGfSNbslgOspQqERHUnJ1KR5RESJ5G80QF9w8ewn61EPNJBUUXxqBZIShfEPzq2gH/mJXJ6aDpaLtHzrnxSGi4KosfLfmGf799HElP7hod1ZoOE9lmo/WMaVT+uBNF0Yl9yYz5s4Nz3NX/Moszb/qGLHs+GhIFrihkSee/dRm4fmbx2WwmhtVykNGdTiKfWM2my6dww6dX0qJbiTS3wCBZMyWTuWsPoyd3D/ekWHQzJHzQQNC6cszNB4tTUIEb0dKK4gJLE4RuObygclFQQv2CiAEXnvAF1OgoZl63jSx7Pr+79E1cM4dnP3Ok0B0O7O+sY9J9zch7bPjtrQe8Dq4HGj/CnlvD+sunc8PHV7GjI540SxXRajMlr6T6rIgNlHE3I5NtNsTkiSj1rWgVVV3CoSbGI1raDmm5kUxman8+ByFD5D83HdmUXJJQIiOQbH5oZZW9n0tWkK0WRGYyZScH4fnB1pckIPHDZlpSA+gIk5nw+s4jKvYh22zUXzCDsHeGKd3MIKFERaK9buZXiSv4v13nEH5BWZ9B4WOK/fG4ksTehxcStg3CvyrpvrUgScgzMik+MxjdDElLN3nvf0lC9vPzubEylpb0LmSSqiKnJeOaEIji0pDX56CEhdAx3bs35Zdb6fXQliQks3nIHGJlux3JbAZF9i5/+vE1SHOnUnJGIHoPE0HFCYrLm7lVyz9yk7gyZRJtaUH4vd9D4Q0fRslMo+A+K3FPmlC+3jzS3RkRmi9dSNPZ7eiajP1/dia80cMSW5JACK9v5dQ03CFWLFWt6HuKBvxwVtImerOyDMJ9dyDG0rIPhMeDlrsHy+Z8ZIcbyaSitzswtXQiVBkR5I9kMiNPmYQSET4kfVAiIpBDvY6EWl19v4VCbNpJzLdOJB0CigRRGzxY6yA4Tyd6vYv41/cO2s2k5eQhJMlb7m4UoeXuIemSXMariAEEvbqW5D+50ar9UE+vI/eBVBw/+YH/mRDemVh6MpIQKC6NjoQgmJE+4OtJzk700pGNBx53M7LekKdn4Am0IkwycqeOqaRuaPYPZAU1MhxPdc1hzXQkiwVt/mTUDbnoTqc3nKndMSRpfmSbjfqfziD8g10+4b1tMDBku526C6fTcKKT0OB26sqCmfRPR7e4y/3FbJS0iXSkhOFXOjLZe3vCmJEdBvr23Zh2l2MpbkA3ywh/vyG6kOZ1ItwnYmpsDLXXZ/W7WrVwuZC/3dKV6kVvbR2yXGW6w0HEqnLqz8o4vArpBiOK3t5O6L/WkHF7JZ3/Dcc/qo2C38g0XpGFHBAA0LWMlFrb8cuvQ8sdndZqQ8j2IwRabS2egiIsRfXoVrNXXIY49CXnD7Hc9avXKb1phk9WqvYUlRC0x4Hz1BmjIq7T4GA8lVVE/3UdUX+14qn1w3NeA8W3TOt2b3uqqr3bEqMxazKGkPWIp7AYubAMz6w01MS4IzqXEhbqjQXshehVCtXuYO7++ZuU3zbfJ8VMWrsN2aXjPmn2SHfF4HDRNZSvNzPpzu0o74bSkeqi4QrfvN8OB0PIekGyWvHYVTrjQo9oVtZ8YhqtKQG9vh74xjr+/uGPCJA7uOvqN2m+YO5hX2vIEALTfzfTEWHqFuZiMPrQHQ5CX1jD5HtrcERLlN4+H3lG5kh364gxhKwXtPpG/MpaMe0qQwkNRp2YdFjnEbJE0MY+LDpCkPLHbfx2+48JU9qYeut23xQLIQj5Io/GhTHGEnMM4CkuJe6hdSR80kjROSHUXZuFkpqMEhEx0l07LAwh6wXh7kTbuRuttha9uRUGUEOy9aKFVN+8COZPQ3XpaBV9ZwjQ29uJ+yNsdCRzbtgm8q+O9cm0NFp9A6Y2fdS5ZBj0gq6hb80l6dFshAx77g9i91/icPx4QZcxYLRgCFk/EO7Ofgdfq0kJVC92YT2jhprfuSk9tZ/XyM7h38+fiCZk/nDBW1T8eoFPipntyx3UzQ8bdTe6Qe/oDgcRz6wn9SEXUqWVtiubybt/CtKsKSPdtX5jCNlgIisUXhZHRKg3rKepIpCgXBXh6cdsTghi/rWdO16/kt+vPpf2RA0lNHho+3sY6A4H4d9V0bR4irHEHEvsm52l3bMV8zshKBMcFN0tU/+LrFHhejM2TBY+hLVO4NZkWnLCyHyuivpF0f1+r97aSuI9q7v+91VDuJZfiH9sMEraRG+6HIMxg+5wEPzyGkI3Z7DnqmDEOfUUJs4h9flyPEUjWympL4wZ2WCia4TlOGnfEkbaI3lo+YWYHLo3t/4YQ1m9k/qFkSjhYSPdFYMhQN+xi/Rle9A/C8c0pYW8paHU/zLLZ7cUDCHrJ/L0jEMWf1AiIqhY5MfEv+V5YygB/8I26n+U3m/P/dGCcHcS/lUpdYvTffbmNjgytLp6Ip9aR8yjKlqDBW1xI7v/NAU1OXGku3YQhpD1k7LTQmk+a3qfbRzzkzC1gXNmkjdBoawgNu3E2qiR96dpsLDv9482PKVl3v2ys4z9sjGLriGt3sqkO7YT9EwAqILdD4RQd00WksUy0r3rwtgj6yfR6zsovAZC1id6Pf+tVmovnYUjWsLcDP4VGppFIrDEg8euULMojM7Twwnd7cZ/QzEh0RPZc7GNjPywrtnaWEDLL8SWEIrr9LlYPts4qlL+GPQf3eHA8skGMtaFUnXBJDpObaUwYTbJ77X2Wfx3uDCyX/QTJSqSwieiiHzZD//tVVSfFEtzGljSW+jMCyTt78XdKk2Dd6nZMSeJmlkmIra6aZ5oAgFRz270yRzph40k0XnqHIQsGWI2HpAVmDuZPVfYsEQ6sK30J/L1wU/CaWS/GELKLnRTeUYske/kkPL7DVg+DyT1kd0HiRiAVluL+bMNJL1eim6SkDsFzuNbqf7l3FFh0u4P+2P1zF9soi1GRT965sh2yGDo0TVYv52M3+dh/8KfxqNc7Ho4E/epc0csdtMQsgPoa9PakzIBq9lN4Bo/ol7aitbUjNA0ot46dIELT3Epfu+vJ+JfG4j7m0rzFA3XSTMGu/vDjjoxiZpfzEMJ95aui1i+DXNJ3Uh3y2CY0BobCXtuDZl3VhC2WaHwQij/1XzkqRnD3hdDyPahTEpFn5Lc6wZmc6oNi8lD66IOSNtntRFiQAkHhceD/O0WJt2VQ2egguuMeYisGaMy5Ec7fjb5V01gwvuFaLW1gDfUylNcihIVaWz+jyM8lVWEPbeGyb8vI6BEZ/f1QdT/MmvQKqL3B0PIDsDtb8KTNeWgL0AJDKTmWK93vt5oRio+srS+emsrAf/ZiCNSpegWKLjPinPxfJ+yAvWFbLNRtcBKyiM7eyyH586IxXX6XEPMxhmeyiqC3s8m494CzC2C3fdORpo7dVjuA0PI9qHtzsfUsm8DPi66m6g4jp5ESGQrDc12QrbLR1ShaD/C4yHkpTWkPOTGU2Kn5ZctVF4355C+ar6A7nAQ+/AatJaWHl+Xv8lG0oUhZuMMJSICbU4GelMzAW+tI3qNoODXCrXXLRzy2ZkhZAcgd2qYc8tA0xGdXlFTQkIoPk/Q0moj5SE34c+uHdRr6tk5pN23E9O7ITgWOMj703RvXUJfpy/LpBCYv9iErBliNp7Q6htQsvd4LfJC4P/2emJfNNGUqbPrT5l0nDsfJThoSO4HQ8gOQK5uQKut91bZ3vdDFbFR+Ic60FpMSOW1Q+JaoLe2EvLiGlIf7kTSJHLujkE/bpZPZr/oN0JgWrEJc1MnStDw7ZUYjCC6ht7e/v3/QmD+fCOT7t5B2qsOSn8kyH04HeZN9d7bgyhohkPsAfS03yN2F9BeMhs5zAUhgbBvY3so0LNzSNsbQP1PprL3Ko2AWQuIfSMfrbpmyK45pAiBtGYr7uNmYapq9T4gDMYdens7rN9OZnEkBAUgyiqpuHUBcifEfFAyKNXKjBnZIVDCQhCBblL/5hmWTA96ayshL61h0l8cOMMFuUsTaLwyC9lqHfJrDxXqht3ULYxAmZQ60l0xGEG06hq0vL3oHR2gQ+eJzeT+Mcpr6DpC/7NxK2Sy3X7IrBSSyUz5BSmYy81IW/OGqWde9K25JN+7gfgPZepOcFF0x2yfDNbtD7rDQdi/t3rFLD1lpLtjMNIIQfTf15Fwv4652ELD1W0U3jMPad60wxa08SlkkoQUGw1a7xm/lOAgSn8zl7YFHaT+oxDhcg1jB70Ijwe/99Yz6c8OPP6C3HvDvLOzUWDZ/CFdYpYVaczMDLoSOSYv20zYs3Y6Iz2U3qVTcuf8wzJ2GbGWvVB7fRbKmfXoH4QR/s/1I17vTw4IoOHcqTT+yIGyy87EVyrwFBSNaJ8Oh67q5evr0HL3jHR3DHwENToKPToMhKA1LRBdlbB/tIUvW18bmljLb775hrPOOouYmBgkSeK9997r9roQgnvvvZeYmBj8/Pw4/vjj2blzZ7c2LpeLm2++mfDwcOx2O2effTZlZd03/BobG7nssssICgoiKCiIyy67jKampoF29/BYOJ2OE9uoqw0g6t38ERcx8O6dBb+6lpRlLlzJLnbdF+ItEjHK9s72z8xaJofiOmPe6LbMGgwanqpq9Owc9K25BHyeQ+1siYLf9F4P9ocMWMja29uZMWMGTzzxRI+vP/zwwzz22GM88cQTbNiwgejoaE455RRaD4iMX7JkCe+++y7Lly/nu+++o62tjcWLF6MdsNS75JJLyM7O5rPPPuOzzz4jOzubyy67bKDdHTCSxUL9FDv6Ln8S/y13hd/4BEKgb9tF5r21mPf40XhZG0V3zj7sUnUjhe5wYP/PekxtHpovmTesoSwGvo/e2krqvVsJGsCE/YiWlpIk8e6773LuuecC3tlYTEwMS5Ys4c477wS8s6+oqCgeeughrr32Wpqbm4mIiOCVV17hwgsvBKCiooL4+Hg++eQTTjvtNHJzc5k8eTJr165lwYIFAKxdu5asrCx27drFpEmTDtm3w11auk+eg6Wug5b0QIK21KDtKRjgqAwPkslMx+kzKTlLIFk1Yt8z4f/JVnSnc6S7NiDU5ERqjo8h4p2dvUYKGIxPRiyNT2FhIVVVVZx66vc10CwWC8cddxyrV3uLamzatAm3292tTUxMDFOnTu1qs2bNGoKCgrpEDGDhwoUEBQV1tfkhLpeLlpaWbn8DRpKonmdBmBSE5E0a6KsIdyfWD9eTeWc+gRusVJ7vouQ2r2VzqGsEyAEBg7Yk9BQWE/l1BW0nZqCkTRyUcxqMPwZVyKqqvA6lUVFR3Y5HRUV1vVZVVYXZbCYkJKTPNpGRkQedPzIysqvND1m2bFnXflpQUBDx8fED7r+Smow2q5W66f4EvZ89KhIEao2NRD2xhvQ/OXAHCnJ+G0nD6el4TpwzZNesumwaiv/g1SDwFBZj/2wb9QujkGdONkKaDAbMkLhfSD+4EYUQBx37IT9s01P7vs5z991309zc3PVXWlo6sD5bLORfHYUkQeSqqtG1RBMCLSePlD9uI3SDSugnu2mLMyPPyBwSUYh6buOgLwN1p5PQf2+hI8aOc/E8Q8wMBsSgCll0tLeG4w9nTTU1NV2ztOjoaDo7O2n8QR6vH7aprq4+6Py1tbUHzfb2Y7FYCAwM7PY3EJp/Mgv/yQ3YVvqj7S0a0Ht9Bb29negPC0HohK8opOL4EFxnzB306wxVmm7d6cTyyQbUdg3PCbOH5BoGY5NBFbLk5GSio6NZsWJF17HOzk5WrVrFokWLAJgzZw4mk6lbm8rKSnbs2NHVJisri+bmZtavX9/VZt26dTQ3N3e1GUyU9BRqF7twrg8j6q1do2JJ2Rueyiq0pmY8lVVM+Md6dJPkzToQETHSXes36pebMK/2uuyMlhxt4x1JVZFnevOPKVGRB72mRkcNaRrsAZ+5ra2N/Pzvg38LCwvJzs4mNDSUhIQElixZwtKlS0lLSyMtLY2lS5dis9m45JJLAAgKCuLqq6/m17/+NWFhYYSGhvKb3/yGadOmcfLJJwOQmZnJ6aefzi9/+UueeeYZAK655hoWL17cL4vlgJAV8q+KRCqHhIc2oo2hoiCSnx+lp0NEQiOlZyUy8bUE1K82jwqh3r+0d540Hb+SVvSdu0dFv8czQpFwhVlR7bEoTc1d0TBycgKu2GBMG9oQHs+QXHvAQrZx40ZOOOGErv9vu+02AK644gpefPFF7rjjDjo6OrjhhhtobGxkwYIFfPHFFwQckA//L3/5C6qqcsEFF9DR0cFJJ53Eiy++iKJ8bwl77bXXuOWWW7qsm2effXavvmtHgqQouEM0Ut70jK3KRoDe1oapUUFOFERNaKLuFhOR2kzkVVv6fxJZQVIUJKsFva3tsMVkf1iV7nAM6H3WL7agLZiK68x5WD9af+g3GIwIwuOBzTn4hYYgJkQiBfij7RMybW8xalEZ+hD+vsZ9iJI6IZqcPyQw+aEqPEUlw9jDoUe229m9dBqRaXXoQqI+L4yMx8oGlDZFTYzHmRqJkMCaXXTYNTnV2Bi0mrrDflioSQlj7vsZs0jSoMyejXJw/UVWqDw3mdAtCp7igVk5fR3JZKb+/OmEp9bT6VFoXRfBpAf2DDj3k7CYsRbUYa1oRbS1H/oNPfVl397Ikcx494uYGheLfswoTzo5lpCVg/dfR2BuNH6FTJKov3o+rYkQ9VbOmNh/UeNikeZMAaDjtJm4f9JIW4cFv1dDSHxo02HNpqSWNjxFJWg5eYftkqKEh6G3DE7xVq2qGmRwnDvXEDMfQI2JRjid3owyvdRqVcLDkO2D53fYE+NWyJT0FFpOdJD0UcegFBMZUWTFW57tugRkp3cztXaWSnOjnZgnzPj/e91hpyHy1NShJiX0WzTkgICDAtk91TW9VqGWLJYB+YwJjwd51RasNS7azp93kIXMYHgRrk701laUyAjkXpyk9aZm5PDQIRWzcZnqWrZa2XNVBNbNEsra9YzauZisIMkSTRfNxRUkk/KX74sFJ79WgWhtP/Kgd11DKy3vdwaQHg0Cfcx2ZX87ehsDFlr5u2yCkxKoP3kiAWWxKP/bPmQWMYPe0WprQZIQrW3egj37H3gH3C/C4xnyrZtxKWRkTAQZEl7Zi2cU3vyy3U7r6VNpTFdIfL+OoNfWoWSk4pwzEdPKZtC1Qc1VNiCBGOAS/VBV2vvCU1RCcFkFWtY0mJmBlL3LELORQAj0jg6UtIlowTbkTg09O2dYuzAul5ZCkYj9yoOn6uDoAZ9FVlCCg3CeNZ/CO6cja4LE53aj+Vto++kC2tJDsHyXM2S502SbDTW656iKkWR/9XaxaSdt584xlpojhRBoewpQmjsQqjykzq89Mf5mZJJEa0oAwRurGA3Pbtlux5WVQVWWheA9OsHbG0mqMtMeZ6P5xDTspR0EvL8F4XKhD2E/dIcDOToS2Wr1zThUIQj8IpfWkzKxl0UhNu4YEwac0YbU3oHYUzjsyUjHlx/Z/GnUzfInYn0LYsvOvk8wksgKir+d2vOn0B4jEb7dg39eI55QO80T/Qja60DNLUH7QbyqgdfVw3nKLNwBCkH/zTuipatBP5AklOBgRGdn95qWg8BA/MjGzYxMmZzO7ltUQlbhkyImqSrMmASSRFVWIAHlGpFfVYAk0Z4RQePMMEK2NhDyVi7C5WLkk28PgB42gIcK4fFg+XQD9uREqs+dRORHe0dvXdDRgBBINr8+C/kMB+NCyJSICKqOCyNsBYS+vsnnrJSyzUbFNTMxtQmivqxkwnP5SP52Oqck0BZrIfSbUizlFWijcPKsBAZCXDSiuHzQn9h94SksJvKjDmoWpxD5EYaYDSGe8oqR7sLYFzLZ5kft4lQmvFuAp6ra50RMMpkRbg9xy/fSPiuBjtRwnPOjsTRp+JU0E7R6J55RGAMqqSpySAhaygTUmha0YRSx/WjVNUR+hCFmI4BssyEF+ENwIDS1DPnYj3khcy2YRPCeDp+xUEqqipwUj/D3oy05ACQwN3twmmXsu2rQSssx6cLrvzXSnT1MJFVFmpyKrihIW3bjGYGaoPvpJmbf+HvTl/v6zFaSUBPiQBcDDinzBdTYGFzp0WgW75aCuckGBwiZOiEa4XYfdtxuj9cctDP5KDVzLMRslUbcz0S22XAtyqR2lgVdhbiv2gj4ahdacwsIgQqHZUWVAwJoOmsKQW9t9B0fKkVBKqrwevP7gGho1TVEvuPCsSgd98wIAt7b4tuZTiQZYVKhpucfuhobg2hvH/6IFElCjZmAp6Kyz+9VjwjuErGeziGCAxCFg+sgO+aFzNQKlnV5Q+qa0BtKVCR6fCT10wNwREuE7fQQ/9xOtJa2I59xyQqOc+fSHikTtqPDd0QMr5e+NoKzsJ7QmpqxfLIBv5mTcZ0wHb+8Gt/NpqFrfRa+0VtaEc7hH19JUUDXD/lwkto6gO/DkZSG9u/vdSGGpDDzmBeymPeLeo3zGypkm43WM6ZRfoaG3KYSsh2SXivFU1w6aMtFac5k3DaJyBc2H3Yc5XhEz87BbDJTf8Fswpwun9lyGAjDfT/vR3g8eCp7Lv5zIHpxOX6yDIqMJ8QGjUNf5m98+ZENJbKCPC2d6qxgXCESliZBxKY2pK15htD4IEpEBHVnphK6vQWxyffccUYFkoQaHYXe7BWqHpNmHkFuMsOPbBiR7XY6jptMzWwTlkaIyHagbNvb9dQck0+JMYBWW0voGy20nzkTJXoe1pXbjAfOQJAV5Mlp6IA7IwYhS1iyCw92QB6meZIhZIeLrNB56mwqjlIJKIHkF4vxlJUDjMh+nK+xP2XLcPqODRThcmF7dz3yjEzqL55NxIpin/CJGhUIHQpLQdOQwjIxV7WiNYxcpIkhZANEjY2h8ZgE6qdJKA6JlJcq0fILR0Xc5nAhW61IEyLRi0ZB1l0h0LNzCC8Npf70dAKKI5G/yx7pXg0Y2W5HjghDr6kbcF2Ew0II9PZ2lIgIzHtr0KprQZJB9L4LLFksSGnJ6P5mlEYH2u78XtsOFEPI+oOsIM3IoOTMIDpiPVirZZL/0wxbd6P5kLXQVxAeD3pBiTckSVaGPYD4cNDqGwh6YwOOc+diOWE26nc7fNtF4wdIsdF0RgZgamqGYdCx/Wi1td5l5tQ0hM2MtDGnVwu6bLPREReA5NFRq92D2g9DyHpDVpBmZVC9MIiWFB09yEPoekHySxVolVU+5e4wXKgTvAWYD2W52j82ckAApMQPe26qw0bXsL23EZE1jcaL5hD+5ehZamp5e5HzFbRhfGjIViu6y4US6A9uDcmtIfqKuZQl1HYP5qLaQXf0NYSsByRVpf3sOdRd7MDlcBKy2kL0x5V4ysrH9xLSz4po7f+el+joQC6uHMIODQG6hvS/bMLyIqg5K5WIbyx9+nT5DJKEZFIRnYf28xoMlPAwXNOTsGwv8c7KmluQ/f3pywlCq29A/l8zniEQW0PIDkAJD8M5M4nKRRZcYTrxL/lh/263t3L3SHfOB+gp66xkMqNEhqM3NR+0sS88nlGbakirrSXiP520nJyBOikcv/9u9808bHi/A6an4Q62Yt1V2W0WKanqkKwe9ETv7Fzs/86F6J9/2xDNGA0hw7sEaj8xk9LTwK9cJW5VB+rGPPT29lEb7zgsyAr63Ew6A0z45Ug+baE8HLSmZuzvrEeenkH9hbMIX12NtqdgpLt1ELKflY5wP6/PlnpAaJCswIxJqFWNaHX13pz6gzRbk3YVYTGpaMNhWOgHY1bI9k9xPbh7duaSJDzHzqB6noWOWA9BuzykP1CKp6IaXdcYPdu8I4jmRskvRtUFrqYmhBiD81YBZG8juCCA5qPSUWKnYP52h0/tkWrtzZh3laEF+eMqK0EID0pkBFpiJEpDE7qzHZKioaEZreYIi9Hsp61pcM7TBx68BoH++OyPWc/+goICUlJSRrobBgYGR0hpaSlxcXF9thmzM7LQ0FAASkpKCAoKGuHejDwtLS3Ex8dTWlp6yHCPsY4xFt3x1fEQQtDa2kpMTMwh245ZIZNlb+KeoKAgn/pyRprAwEBjPPZhjEV3fHE8+jsJGek0XQYGBgZHjCFkBgYGo54xK2QWi4V77rkHi8Uy0l3xCYzx+B5jLLozFsZjzFotDQwMxg9jdkZmYGAwfjCEzMDAYNRjCJmBgcGoxxAyAwODUY8hZAYGBqOeMStkTz75JMnJyVitVubMmcO333470l0adJYtW8a8efMICAggMjKSc889l927d3drI4Tg3nvvJSYmBj8/P44//nh27uxeNcjlcnHzzTcTHh6O3W7n7LPPpqxs9FW4PpBly5YhSRJLlizpOjaexqK8vJxLL72UsLAwbDYbM2fOZNOmTV2vj7mxEGOQ5cuXC5PJJJ577jmRk5Mjbr31VmG320VxcfFId21QOe2008QLL7wgduzYIbKzs8WZZ54pEhISRFtbW1ebBx98UAQEBIh33nlHbN++XVx44YViwoQJoqWlpavNddddJ2JjY8WKFSvE5s2bxQknnCBmzJghPB7PSHysI2b9+vUiKSlJTJ8+Xdx6661dx8fLWDQ0NIjExERx5ZVXinXr1onCwkKxcuVKkZ+f39VmrI3FmBSy+fPni+uuu67bsYyMDHHXXXeNUI+Gh5qaGgGIVatWCSGE0HVdREdHiwcffLCrjdPpFEFBQeLpp58WQgjR1NQkTCaTWL58eVeb8vJyIcuy+Oyzz4b3AwwCra2tIi0tTaxYsUIcd9xxXUI2nsbizjvvFEcffXSvr4/FsRhzS8vOzk42bdrEqaee2u34qaeeyurVq0eoV8NDc3Mz8H3mj8LCQqqqqrqNhcVi4bjjjusai02bNuF2u7u1iYmJYerUqaNyvG688UbOPPNMTj755G7Hx9NYfPDBB8ydO5ef/vSnREZGMmvWLJ577rmu18fiWIw5Iaurq0PTNKKiorodj4qKoqrq0OXeRytCCG677TaOPvpopk6dCtD1efsai6qqKsxmMyEhIb22GS0sX76czZs3s2zZsoNeG09jUVBQwFNPPUVaWhqff/451113Hbfccgsvv/wyMDbHYsym8ZEkqdv/QoiDjo0lbrrpJrZt28Z333130GuHMxajbbxKS0u59dZb+eKLL7Barb22Gw9joes6c+fOZenSpQDMmjWLnTt38tRTT3H55Zd3tRtLYzHmZmTh4eEoinLQU6OmpuagJ9BY4eabb+aDDz7gq6++6pZJMzraWyCir7GIjo6ms7OTxh8UCRlt47Vp0yZqamqYM2cOqqqiqiqrVq3ib3/7G6qqdn2W8TAWEyZMYPLkyd2OZWZmUlJSAozN+2LMCZnZbGbOnDmsWLGi2/EVK1awaNGiEerV0CCE4KabbuI///kPX375JcnJyd1eT05OJjo6uttYdHZ2smrVqq6xmDNnDiaTqVubyspKduzYMarG66STTmL79u1kZ2d3/c2dO5ef/exnZGdnM3HixHEzFkcdddRBbjh5eXkkJiYCY/S+GDEzwxCy3/3i+eefFzk5OWLJkiXCbreLoqKike7aoHL99deLoKAg8fXXX4vKysquP4fD0dXmwQcfFEFBQeI///mP2L59u7j44ot7NLPHxcWJlStXis2bN4sTTzzRZ83sA+FAq6UQ42cs1q9fL1RVFQ888IDYs2ePeO2114TNZhOvvvpqV5uxNhZjUsiEEOIf//iHSExMFGazWcyePbvLJWEsgbfGz0F/L7zwQlcbXdfFPffcI6Kjo4XFYhHHHnus2L59e7fzdHR0iJtuukmEhoYKPz8/sXjxYlFSUjLMn2bw+aGQjaex+PDDD8XUqVOFxWIRGRkZ4tlnn+32+lgbCyMfmYGBwahnzO2RGRgYjD8MITMwMBj1GEJmYGAw6jGEzMDAYNRjCJmBgcGoxxAyAwODUY8hZAYGBqMeQ8gMDAxGPYaQGRgYjHoMITMwMBj1GEJmYGAw6vl/Qaojpca2ZdMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Pavia_gt.mat'\n",
    "data_files = 'Pavia.mat'\n",
    "label_files = 'pavia_gt'\n",
    "hypercube_files = 'pavia'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:28.286592Z",
     "iopub.status.busy": "2025-05-08T17:24:28.286592Z",
     "iopub.status.idle": "2025-05-08T17:24:28.292417Z",
     "shell.execute_reply": "2025-05-08T17:24:28.292417Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:28.295421Z",
     "iopub.status.busy": "2025-05-08T17:24:28.294425Z",
     "iopub.status.idle": "2025-05-08T17:24:34.920848Z",
     "shell.execute_reply": "2025-05-08T17:24:34.920848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 148152\n",
      "Extracted windows shape: (148152, 5, 5, 102)\n",
      "Corresponding labels shape: (148152,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:34.923916Z",
     "iopub.status.busy": "2025-05-08T17:24:34.923916Z",
     "iopub.status.idle": "2025-05-08T17:24:34.931113Z",
     "shell.execute_reply": "2025-05-08T17:24:34.931113Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:34.934129Z",
     "iopub.status.busy": "2025-05-08T17:24:34.934129Z",
     "iopub.status.idle": "2025-05-08T17:24:40.245764Z",
     "shell.execute_reply": "2025-05-08T17:24:40.245764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 65971 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 7598 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 3090 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 2685 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 6584 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 9248 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 7287 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 42826 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 2863 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t180 samples\n",
      "\tshape (180, 5, 5, 102) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t45 samples\n",
      "\tshape (45, 5, 5, 102) --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- Test set created with: \n",
      "\t147927 samples\n",
      "\tshape (147927, 5, 5, 102) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(180, 5, 5, 102)\n",
      "(45, 5, 5, 102)\n",
      "(147927, 5, 5, 102)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:40.248983Z",
     "iopub.status.busy": "2025-05-08T17:24:40.247981Z",
     "iopub.status.idle": "2025-05-08T17:24:40.251850Z",
     "shell.execute_reply": "2025-05-08T17:24:40.251850Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:40.254860Z",
     "iopub.status.busy": "2025-05-08T17:24:40.254860Z",
     "iopub.status.idle": "2025-05-08T17:24:40.925176Z",
     "shell.execute_reply": "2025-05-08T17:24:40.925176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 180\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:40.928180Z",
     "iopub.status.busy": "2025-05-08T17:24:40.928180Z",
     "iopub.status.idle": "2025-05-08T17:24:40.933178Z",
     "shell.execute_reply": "2025-05-08T17:24:40.933178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:40.935684Z",
     "iopub.status.busy": "2025-05-08T17:24:40.934684Z",
     "iopub.status.idle": "2025-05-08T17:24:41.376633Z",
     "shell.execute_reply": "2025-05-08T17:24:41.376633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (118521, 5, 5, 102)\n",
      "Validation data shape: (29631, 5, 5, 102)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:41.379642Z",
     "iopub.status.busy": "2025-05-08T17:24:41.378638Z",
     "iopub.status.idle": "2025-05-08T17:24:41.382866Z",
     "shell.execute_reply": "2025-05-08T17:24:41.382866Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:41.384875Z",
     "iopub.status.busy": "2025-05-08T17:24:41.384875Z",
     "iopub.status.idle": "2025-05-08T17:24:41.692368Z",
     "shell.execute_reply": "2025-05-08T17:24:41.691864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:41.695372Z",
     "iopub.status.busy": "2025-05-08T17:24:41.695372Z",
     "iopub.status.idle": "2025-05-08T17:24:41.699874Z",
     "shell.execute_reply": "2025-05-08T17:24:41.699372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:41.702879Z",
     "iopub.status.busy": "2025-05-08T17:24:41.702879Z",
     "iopub.status.idle": "2025-05-08T17:24:41.711131Z",
     "shell.execute_reply": "2025-05-08T17:24:41.711131Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:24:41.715135Z",
     "iopub.status.busy": "2025-05-08T17:24:41.715135Z",
     "iopub.status.idle": "2025-05-08T17:29:20.666689Z",
     "shell.execute_reply": "2025-05-08T17:29:20.666689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/1852], Loss: 0.1680, PSNR: 5.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0876, PSNR: 7.3061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0458, PSNR: 9.5537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0268, PSNR: 12.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0133, PSNR: 13.7657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0105, PSNR: 16.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0088, PSNR: 17.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0093, PSNR: 17.8695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0070, PSNR: 18.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0060, PSNR: 18.8991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.0319, PSNR: 13.7977\n",
      "\t[Val]   Batch [1/463] Loss: 0.0053, PSNR: 17.9460\n",
      "\t[Val]   Batch [10/463] Loss: 0.0050, PSNR: 19.0844\n",
      "\t[Val]   Batch [20/463] Loss: 0.0051, PSNR: 18.0742\n",
      "\t[Val]   Batch [30/463] Loss: 0.0060, PSNR: 18.6706\n",
      "\t[Val]   Batch [40/463] Loss: 0.0048, PSNR: 17.7412\n",
      "\t[Val]   Batch [50/463] Loss: 0.0051, PSNR: 17.9703\n",
      "\t[Val]   Batch [60/463] Loss: 0.0048, PSNR: 18.0208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0068, PSNR: 18.3955\n",
      "\t[Val]   Batch [80/463] Loss: 0.0061, PSNR: 20.2882\n",
      "\t[Val]   Batch [90/463] Loss: 0.0059, PSNR: 19.3822\n",
      "\t[Val]   Batch [100/463] Loss: 0.0059, PSNR: 19.1141\n",
      "\t[Val]   Batch [110/463] Loss: 0.0069, PSNR: 18.5110\n",
      "\t[Val]   Batch [120/463] Loss: 0.0047, PSNR: 17.9973\n",
      "\t[Val]   Batch [130/463] Loss: 0.0055, PSNR: 19.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0064, PSNR: 18.9716\n",
      "\t[Val]   Batch [150/463] Loss: 0.0073, PSNR: 19.0075\n",
      "\t[Val]   Batch [160/463] Loss: 0.0059, PSNR: 19.2486\n",
      "\t[Val]   Batch [170/463] Loss: 0.0075, PSNR: 18.2321\n",
      "\t[Val]   Batch [180/463] Loss: 0.0055, PSNR: 18.9905\n",
      "\t[Val]   Batch [190/463] Loss: 0.0060, PSNR: 19.3129\n",
      "\t[Val]   Batch [200/463] Loss: 0.0060, PSNR: 18.6903\n",
      "\t[Val]   Batch [210/463] Loss: 0.0058, PSNR: 18.3159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0057, PSNR: 19.5335\n",
      "\t[Val]   Batch [230/463] Loss: 0.0067, PSNR: 19.3640\n",
      "\t[Val]   Batch [240/463] Loss: 0.0051, PSNR: 18.1365\n",
      "\t[Val]   Batch [250/463] Loss: 0.0066, PSNR: 17.3495\n",
      "\t[Val]   Batch [260/463] Loss: 0.0057, PSNR: 18.3498\n",
      "\t[Val]   Batch [270/463] Loss: 0.0044, PSNR: 17.4965\n",
      "\t[Val]   Batch [280/463] Loss: 0.0054, PSNR: 20.2273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0059, PSNR: 17.2533\n",
      "\t[Val]   Batch [300/463] Loss: 0.0060, PSNR: 19.4761\n",
      "\t[Val]   Batch [310/463] Loss: 0.0056, PSNR: 19.3679\n",
      "\t[Val]   Batch [320/463] Loss: 0.0056, PSNR: 19.2454\n",
      "\t[Val]   Batch [330/463] Loss: 0.0065, PSNR: 18.6542\n",
      "\t[Val]   Batch [340/463] Loss: 0.0053, PSNR: 19.5840\n",
      "\t[Val]   Batch [350/463] Loss: 0.0070, PSNR: 19.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0047, PSNR: 20.4355\n",
      "\t[Val]   Batch [370/463] Loss: 0.0069, PSNR: 18.5893\n",
      "\t[Val]   Batch [380/463] Loss: 0.0068, PSNR: 18.7316\n",
      "\t[Val]   Batch [390/463] Loss: 0.0062, PSNR: 18.5483\n",
      "\t[Val]   Batch [400/463] Loss: 0.0054, PSNR: 17.6174\n",
      "\t[Val]   Batch [410/463] Loss: 0.0054, PSNR: 19.9036\n",
      "\t[Val]   Batch [420/463] Loss: 0.0055, PSNR: 18.7071\n",
      "\t[Val]   Batch [430/463] Loss: 0.0054, PSNR: 18.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0053, PSNR: 19.1201\n",
      "\t[Val]   Batch [450/463] Loss: 0.0042, PSNR: 16.4402\n",
      "\t[Val]   Batch [460/463] Loss: 0.0058, PSNR: 17.8569\n",
      "Epoch [1/50] Validation Loss: 0.0058, PSNR: 18.6822\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0050, PSNR: 17.6622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0052, PSNR: 19.1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0050, PSNR: 19.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0058, PSNR: 19.2607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0049, PSNR: 20.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0040, PSNR: 20.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0036, PSNR: 22.1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0050, PSNR: 20.7530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0025, PSNR: 20.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0033, PSNR: 21.6066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.0042, PSNR: 20.2590\n",
      "\t[Val]   Batch [1/463] Loss: 0.0025, PSNR: 21.2523\n",
      "\t[Val]   Batch [10/463] Loss: 0.0023, PSNR: 22.5030\n",
      "\t[Val]   Batch [20/463] Loss: 0.0022, PSNR: 21.6057\n",
      "\t[Val]   Batch [30/463] Loss: 0.0029, PSNR: 21.9369\n",
      "\t[Val]   Batch [40/463] Loss: 0.0023, PSNR: 21.0060\n",
      "\t[Val]   Batch [50/463] Loss: 0.0024, PSNR: 21.2968\n",
      "\t[Val]   Batch [60/463] Loss: 0.0022, PSNR: 21.3497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0033, PSNR: 21.5825\n",
      "\t[Val]   Batch [80/463] Loss: 0.0029, PSNR: 23.5165\n",
      "\t[Val]   Batch [90/463] Loss: 0.0027, PSNR: 22.6797\n",
      "\t[Val]   Batch [100/463] Loss: 0.0029, PSNR: 22.1985\n",
      "\t[Val]   Batch [110/463] Loss: 0.0033, PSNR: 21.7452\n",
      "\t[Val]   Batch [120/463] Loss: 0.0022, PSNR: 21.2589\n",
      "\t[Val]   Batch [130/463] Loss: 0.0025, PSNR: 22.8288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0031, PSNR: 22.1445\n",
      "\t[Val]   Batch [150/463] Loss: 0.0033, PSNR: 22.3928\n",
      "\t[Val]   Batch [160/463] Loss: 0.0029, PSNR: 22.3072\n",
      "\t[Val]   Batch [170/463] Loss: 0.0037, PSNR: 21.3162\n",
      "\t[Val]   Batch [180/463] Loss: 0.0028, PSNR: 21.9786\n",
      "\t[Val]   Batch [190/463] Loss: 0.0027, PSNR: 22.7076\n",
      "\t[Val]   Batch [200/463] Loss: 0.0028, PSNR: 22.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0029, PSNR: 21.2438\n",
      "\t[Val]   Batch [220/463] Loss: 0.0028, PSNR: 22.6327\n",
      "\t[Val]   Batch [230/463] Loss: 0.0031, PSNR: 22.7764\n",
      "\t[Val]   Batch [240/463] Loss: 0.0024, PSNR: 21.4248\n",
      "\t[Val]   Batch [250/463] Loss: 0.0032, PSNR: 20.4555\n",
      "\t[Val]   Batch [260/463] Loss: 0.0028, PSNR: 21.5094\n",
      "\t[Val]   Batch [270/463] Loss: 0.0020, PSNR: 20.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0025, PSNR: 23.5145\n",
      "\t[Val]   Batch [290/463] Loss: 0.0028, PSNR: 20.5337\n",
      "\t[Val]   Batch [300/463] Loss: 0.0029, PSNR: 22.6991\n",
      "\t[Val]   Batch [310/463] Loss: 0.0028, PSNR: 22.3744\n",
      "\t[Val]   Batch [320/463] Loss: 0.0027, PSNR: 22.4326\n",
      "\t[Val]   Batch [330/463] Loss: 0.0030, PSNR: 22.0687\n",
      "\t[Val]   Batch [340/463] Loss: 0.0026, PSNR: 22.7984\n",
      "\t[Val]   Batch [350/463] Loss: 0.0035, PSNR: 22.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0024, PSNR: 23.3358\n",
      "\t[Val]   Batch [370/463] Loss: 0.0032, PSNR: 21.8975\n",
      "\t[Val]   Batch [380/463] Loss: 0.0030, PSNR: 22.2515\n",
      "\t[Val]   Batch [390/463] Loss: 0.0028, PSNR: 21.9881\n",
      "\t[Val]   Batch [400/463] Loss: 0.0027, PSNR: 20.7286\n",
      "\t[Val]   Batch [410/463] Loss: 0.0025, PSNR: 23.2820\n",
      "\t[Val]   Batch [420/463] Loss: 0.0026, PSNR: 22.0739\n",
      "\t[Val]   Batch [430/463] Loss: 0.0027, PSNR: 21.2378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0026, PSNR: 22.2055\n",
      "\t[Val]   Batch [450/463] Loss: 0.0020, PSNR: 19.6593\n",
      "\t[Val]   Batch [460/463] Loss: 0.0027, PSNR: 21.2236\n",
      "Epoch [2/50] Validation Loss: 0.0027, PSNR: 21.9586\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0026, PSNR: 21.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0022, PSNR: 21.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0025, PSNR: 22.2282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0028, PSNR: 23.4674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0022, PSNR: 23.3246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0022, PSNR: 23.8658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0020, PSNR: 24.4720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0021, PSNR: 23.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0017, PSNR: 21.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0017, PSNR: 22.3510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.0023, PSNR: 22.7879\n",
      "\t[Val]   Batch [1/463] Loss: 0.0015, PSNR: 23.4572\n",
      "\t[Val]   Batch [10/463] Loss: 0.0014, PSNR: 24.7362\n",
      "\t[Val]   Batch [20/463] Loss: 0.0013, PSNR: 23.9042\n",
      "\t[Val]   Batch [30/463] Loss: 0.0016, PSNR: 24.3852\n",
      "\t[Val]   Batch [40/463] Loss: 0.0014, PSNR: 22.9842\n",
      "\t[Val]   Batch [50/463] Loss: 0.0015, PSNR: 23.3822\n",
      "\t[Val]   Batch [60/463] Loss: 0.0014, PSNR: 23.3693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0018, PSNR: 24.0526\n",
      "\t[Val]   Batch [80/463] Loss: 0.0016, PSNR: 26.0245\n",
      "\t[Val]   Batch [90/463] Loss: 0.0016, PSNR: 24.9569\n",
      "\t[Val]   Batch [100/463] Loss: 0.0017, PSNR: 24.4915\n",
      "\t[Val]   Batch [110/463] Loss: 0.0018, PSNR: 24.2629\n",
      "\t[Val]   Batch [120/463] Loss: 0.0014, PSNR: 23.2584\n",
      "\t[Val]   Batch [130/463] Loss: 0.0014, PSNR: 25.3385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0018, PSNR: 24.5324\n",
      "\t[Val]   Batch [150/463] Loss: 0.0018, PSNR: 25.1900\n",
      "\t[Val]   Batch [160/463] Loss: 0.0018, PSNR: 24.3323\n",
      "\t[Val]   Batch [170/463] Loss: 0.0022, PSNR: 23.5775\n",
      "\t[Val]   Batch [180/463] Loss: 0.0017, PSNR: 24.0466\n",
      "\t[Val]   Batch [190/463] Loss: 0.0016, PSNR: 25.1066\n",
      "\t[Val]   Batch [200/463] Loss: 0.0016, PSNR: 24.5218\n",
      "\t[Val]   Batch [210/463] Loss: 0.0018, PSNR: 23.2588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0017, PSNR: 24.7039\n",
      "\t[Val]   Batch [230/463] Loss: 0.0016, PSNR: 25.6647\n",
      "\t[Val]   Batch [240/463] Loss: 0.0014, PSNR: 23.6214\n",
      "\t[Val]   Batch [250/463] Loss: 0.0020, PSNR: 22.6025\n",
      "\t[Val]   Batch [260/463] Loss: 0.0017, PSNR: 23.6324\n",
      "\t[Val]   Batch [270/463] Loss: 0.0012, PSNR: 22.9838\n",
      "\t[Val]   Batch [280/463] Loss: 0.0015, PSNR: 25.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0016, PSNR: 22.8352\n",
      "\t[Val]   Batch [300/463] Loss: 0.0017, PSNR: 24.8763\n",
      "\t[Val]   Batch [310/463] Loss: 0.0018, PSNR: 24.2772\n",
      "\t[Val]   Batch [320/463] Loss: 0.0016, PSNR: 24.6713\n",
      "\t[Val]   Batch [330/463] Loss: 0.0017, PSNR: 24.6109\n",
      "\t[Val]   Batch [340/463] Loss: 0.0015, PSNR: 25.0155\n",
      "\t[Val]   Batch [350/463] Loss: 0.0021, PSNR: 24.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0017, PSNR: 24.8218\n",
      "\t[Val]   Batch [370/463] Loss: 0.0018, PSNR: 24.4251\n",
      "\t[Val]   Batch [380/463] Loss: 0.0016, PSNR: 25.0793\n",
      "\t[Val]   Batch [390/463] Loss: 0.0015, PSNR: 24.6486\n",
      "\t[Val]   Batch [400/463] Loss: 0.0017, PSNR: 22.6515\n",
      "\t[Val]   Batch [410/463] Loss: 0.0014, PSNR: 25.6004\n",
      "\t[Val]   Batch [420/463] Loss: 0.0015, PSNR: 24.4059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0017, PSNR: 23.1395\n",
      "\t[Val]   Batch [440/463] Loss: 0.0016, PSNR: 24.2333\n",
      "\t[Val]   Batch [450/463] Loss: 0.0013, PSNR: 21.3884\n",
      "\t[Val]   Batch [460/463] Loss: 0.0016, PSNR: 23.4637\n",
      "Epoch [3/50] Validation Loss: 0.0016, PSNR: 24.2394\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0019, PSNR: 23.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0017, PSNR: 22.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0019, PSNR: 24.2156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0015, PSNR: 23.6540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0015, PSNR: 23.8802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0018, PSNR: 24.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0014, PSNR: 25.5243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0013, PSNR: 25.4047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0013, PSNR: 24.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0012, PSNR: 25.7553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.0016, PSNR: 24.3489\n",
      "\t[Val]   Batch [1/463] Loss: 0.0012, PSNR: 24.5131\n",
      "\t[Val]   Batch [10/463] Loss: 0.0011, PSNR: 25.7816\n",
      "\t[Val]   Batch [20/463] Loss: 0.0010, PSNR: 24.9867\n",
      "\t[Val]   Batch [30/463] Loss: 0.0013, PSNR: 25.4645\n",
      "\t[Val]   Batch [40/463] Loss: 0.0012, PSNR: 23.9650\n",
      "\t[Val]   Batch [50/463] Loss: 0.0011, PSNR: 24.4487\n",
      "\t[Val]   Batch [60/463] Loss: 0.0011, PSNR: 24.3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0014, PSNR: 25.1719\n",
      "\t[Val]   Batch [80/463] Loss: 0.0012, PSNR: 27.2557\n",
      "\t[Val]   Batch [90/463] Loss: 0.0013, PSNR: 26.0501\n",
      "\t[Val]   Batch [100/463] Loss: 0.0013, PSNR: 25.6215\n",
      "\t[Val]   Batch [110/463] Loss: 0.0014, PSNR: 25.4519\n",
      "\t[Val]   Batch [120/463] Loss: 0.0011, PSNR: 24.3175\n",
      "\t[Val]   Batch [130/463] Loss: 0.0011, PSNR: 26.4774\n",
      "\t[Val]   Batch [140/463] Loss: 0.0014, PSNR: 25.6425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0013, PSNR: 26.3735\n",
      "\t[Val]   Batch [160/463] Loss: 0.0015, PSNR: 25.3127\n",
      "\t[Val]   Batch [170/463] Loss: 0.0017, PSNR: 24.5825\n",
      "\t[Val]   Batch [180/463] Loss: 0.0014, PSNR: 25.0632\n",
      "\t[Val]   Batch [190/463] Loss: 0.0012, PSNR: 26.1703\n",
      "\t[Val]   Batch [200/463] Loss: 0.0012, PSNR: 25.7188\n",
      "\t[Val]   Batch [210/463] Loss: 0.0015, PSNR: 24.2522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0014, PSNR: 25.7130\n",
      "\t[Val]   Batch [230/463] Loss: 0.0012, PSNR: 26.9189\n",
      "\t[Val]   Batch [240/463] Loss: 0.0011, PSNR: 24.7178\n",
      "\t[Val]   Batch [250/463] Loss: 0.0015, PSNR: 23.6277\n",
      "\t[Val]   Batch [260/463] Loss: 0.0014, PSNR: 24.6221\n",
      "\t[Val]   Batch [270/463] Loss: 0.0010, PSNR: 24.0654\n",
      "\t[Val]   Batch [280/463] Loss: 0.0012, PSNR: 26.7947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0013, PSNR: 23.9522\n",
      "\t[Val]   Batch [300/463] Loss: 0.0014, PSNR: 25.8320\n",
      "\t[Val]   Batch [310/463] Loss: 0.0014, PSNR: 25.3044\n",
      "\t[Val]   Batch [320/463] Loss: 0.0012, PSNR: 25.8098\n",
      "\t[Val]   Batch [330/463] Loss: 0.0013, PSNR: 25.7238\n",
      "\t[Val]   Batch [340/463] Loss: 0.0012, PSNR: 26.1210\n",
      "\t[Val]   Batch [350/463] Loss: 0.0016, PSNR: 25.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0014, PSNR: 25.6463\n",
      "\t[Val]   Batch [370/463] Loss: 0.0014, PSNR: 25.5732\n",
      "\t[Val]   Batch [380/463] Loss: 0.0012, PSNR: 26.3078\n",
      "\t[Val]   Batch [390/463] Loss: 0.0012, PSNR: 25.8392\n",
      "\t[Val]   Batch [400/463] Loss: 0.0014, PSNR: 23.6529\n",
      "\t[Val]   Batch [410/463] Loss: 0.0011, PSNR: 26.6967\n",
      "\t[Val]   Batch [420/463] Loss: 0.0012, PSNR: 25.4582\n",
      "\t[Val]   Batch [430/463] Loss: 0.0014, PSNR: 24.0842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0013, PSNR: 25.3441\n",
      "\t[Val]   Batch [450/463] Loss: 0.0011, PSNR: 22.4123\n",
      "\t[Val]   Batch [460/463] Loss: 0.0013, PSNR: 24.4899\n",
      "Epoch [4/50] Validation Loss: 0.0012, PSNR: 25.3324\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0013, PSNR: 26.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0018, PSNR: 25.3656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0014, PSNR: 24.9616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0013, PSNR: 24.7566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0012, PSNR: 24.4685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0011, PSNR: 24.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0010, PSNR: 25.4281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0010, PSNR: 27.2741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0015, PSNR: 24.0375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0010, PSNR: 25.2176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.0013, PSNR: 25.3744\n",
      "\t[Val]   Batch [1/463] Loss: 0.0009, PSNR: 25.5103\n",
      "\t[Val]   Batch [10/463] Loss: 0.0009, PSNR: 26.8088\n",
      "\t[Val]   Batch [20/463] Loss: 0.0008, PSNR: 26.0037\n",
      "\t[Val]   Batch [30/463] Loss: 0.0010, PSNR: 26.5182\n",
      "\t[Val]   Batch [40/463] Loss: 0.0009, PSNR: 24.8583\n",
      "\t[Val]   Batch [50/463] Loss: 0.0009, PSNR: 25.4191\n",
      "\t[Val]   Batch [60/463] Loss: 0.0009, PSNR: 25.3008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0011, PSNR: 26.2387\n",
      "\t[Val]   Batch [80/463] Loss: 0.0009, PSNR: 28.5096\n",
      "\t[Val]   Batch [90/463] Loss: 0.0010, PSNR: 27.1737\n",
      "\t[Val]   Batch [100/463] Loss: 0.0010, PSNR: 26.6919\n",
      "\t[Val]   Batch [110/463] Loss: 0.0011, PSNR: 26.5938\n",
      "\t[Val]   Batch [120/463] Loss: 0.0009, PSNR: 25.3081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [130/463] Loss: 0.0009, PSNR: 27.4923\n",
      "\t[Val]   Batch [140/463] Loss: 0.0011, PSNR: 26.7760\n",
      "\t[Val]   Batch [150/463] Loss: 0.0010, PSNR: 27.5414\n",
      "\t[Val]   Batch [160/463] Loss: 0.0012, PSNR: 26.1976\n",
      "\t[Val]   Batch [170/463] Loss: 0.0014, PSNR: 25.5634\n",
      "\t[Val]   Batch [180/463] Loss: 0.0011, PSNR: 26.0637\n",
      "\t[Val]   Batch [190/463] Loss: 0.0010, PSNR: 27.1495\n",
      "\t[Val]   Batch [200/463] Loss: 0.0009, PSNR: 26.8461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0012, PSNR: 25.2274\n",
      "\t[Val]   Batch [220/463] Loss: 0.0011, PSNR: 26.6881\n",
      "\t[Val]   Batch [230/463] Loss: 0.0009, PSNR: 28.1665\n",
      "\t[Val]   Batch [240/463] Loss: 0.0009, PSNR: 25.7967\n",
      "\t[Val]   Batch [250/463] Loss: 0.0013, PSNR: 24.5300\n",
      "\t[Val]   Batch [260/463] Loss: 0.0011, PSNR: 25.5238\n",
      "\t[Val]   Batch [270/463] Loss: 0.0008, PSNR: 25.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0009, PSNR: 27.8190\n",
      "\t[Val]   Batch [290/463] Loss: 0.0010, PSNR: 25.0283\n",
      "\t[Val]   Batch [300/463] Loss: 0.0011, PSNR: 26.7299\n",
      "\t[Val]   Batch [310/463] Loss: 0.0011, PSNR: 26.2264\n",
      "\t[Val]   Batch [320/463] Loss: 0.0010, PSNR: 26.9065\n",
      "\t[Val]   Batch [330/463] Loss: 0.0010, PSNR: 26.8594\n",
      "\t[Val]   Batch [340/463] Loss: 0.0009, PSNR: 27.1590\n",
      "\t[Val]   Batch [350/463] Loss: 0.0013, PSNR: 26.9117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0012, PSNR: 26.3340\n",
      "\t[Val]   Batch [370/463] Loss: 0.0011, PSNR: 26.7309\n",
      "\t[Val]   Batch [380/463] Loss: 0.0009, PSNR: 27.5408\n",
      "\t[Val]   Batch [390/463] Loss: 0.0009, PSNR: 27.0104\n",
      "\t[Val]   Batch [400/463] Loss: 0.0011, PSNR: 24.5706\n",
      "\t[Val]   Batch [410/463] Loss: 0.0009, PSNR: 27.7345\n",
      "\t[Val]   Batch [420/463] Loss: 0.0009, PSNR: 26.4950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0011, PSNR: 24.8954\n",
      "\t[Val]   Batch [440/463] Loss: 0.0010, PSNR: 26.3394\n",
      "\t[Val]   Batch [450/463] Loss: 0.0009, PSNR: 23.2829\n",
      "\t[Val]   Batch [460/463] Loss: 0.0010, PSNR: 25.4230\n",
      "Epoch [5/50] Validation Loss: 0.0010, PSNR: 26.3716\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0012, PSNR: 25.2958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0011, PSNR: 27.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0012, PSNR: 25.3465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0011, PSNR: 26.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0010, PSNR: 26.3584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0010, PSNR: 26.2478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0010, PSNR: 27.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0009, PSNR: 26.0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0012, PSNR: 25.8289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0010, PSNR: 25.4693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.0011, PSNR: 26.1591\n",
      "\t[Val]   Batch [1/463] Loss: 0.0008, PSNR: 26.4646\n",
      "\t[Val]   Batch [10/463] Loss: 0.0007, PSNR: 27.7585\n",
      "\t[Val]   Batch [20/463] Loss: 0.0006, PSNR: 27.0268\n",
      "\t[Val]   Batch [30/463] Loss: 0.0008, PSNR: 27.4241\n",
      "\t[Val]   Batch [40/463] Loss: 0.0008, PSNR: 25.8145\n",
      "\t[Val]   Batch [50/463] Loss: 0.0007, PSNR: 26.4165\n",
      "\t[Val]   Batch [60/463] Loss: 0.0007, PSNR: 26.2245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0009, PSNR: 27.1446\n",
      "\t[Val]   Batch [80/463] Loss: 0.0007, PSNR: 29.5511\n",
      "\t[Val]   Batch [90/463] Loss: 0.0008, PSNR: 28.1040\n",
      "\t[Val]   Batch [100/463] Loss: 0.0008, PSNR: 27.6327\n",
      "\t[Val]   Batch [110/463] Loss: 0.0008, PSNR: 27.5895\n",
      "\t[Val]   Batch [120/463] Loss: 0.0007, PSNR: 26.3154\n",
      "\t[Val]   Batch [130/463] Loss: 0.0007, PSNR: 28.4674\n",
      "\t[Val]   Batch [140/463] Loss: 0.0009, PSNR: 27.7375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0008, PSNR: 28.4940\n",
      "\t[Val]   Batch [160/463] Loss: 0.0010, PSNR: 27.0536\n",
      "\t[Val]   Batch [170/463] Loss: 0.0011, PSNR: 26.4084\n",
      "\t[Val]   Batch [180/463] Loss: 0.0009, PSNR: 27.0183\n",
      "\t[Val]   Batch [190/463] Loss: 0.0008, PSNR: 28.0620\n",
      "\t[Val]   Batch [200/463] Loss: 0.0007, PSNR: 27.8423\n",
      "\t[Val]   Batch [210/463] Loss: 0.0010, PSNR: 26.1340\n",
      "\t[Val]   Batch [220/463] Loss: 0.0009, PSNR: 27.5614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [230/463] Loss: 0.0007, PSNR: 29.1916\n",
      "\t[Val]   Batch [240/463] Loss: 0.0007, PSNR: 26.7832\n",
      "\t[Val]   Batch [250/463] Loss: 0.0010, PSNR: 25.4827\n",
      "\t[Val]   Batch [260/463] Loss: 0.0009, PSNR: 26.3602\n",
      "\t[Val]   Batch [270/463] Loss: 0.0006, PSNR: 26.2012\n",
      "\t[Val]   Batch [280/463] Loss: 0.0007, PSNR: 28.7981\n",
      "\t[Val]   Batch [290/463] Loss: 0.0008, PSNR: 26.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0009, PSNR: 27.6035\n",
      "\t[Val]   Batch [310/463] Loss: 0.0009, PSNR: 27.1423\n",
      "\t[Val]   Batch [320/463] Loss: 0.0008, PSNR: 27.9589\n",
      "\t[Val]   Batch [330/463] Loss: 0.0008, PSNR: 27.8038\n",
      "\t[Val]   Batch [340/463] Loss: 0.0007, PSNR: 28.1516\n",
      "\t[Val]   Batch [350/463] Loss: 0.0011, PSNR: 27.7529\n",
      "\t[Val]   Batch [360/463] Loss: 0.0010, PSNR: 27.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0008, PSNR: 27.7406\n",
      "\t[Val]   Batch [380/463] Loss: 0.0007, PSNR: 28.5862\n",
      "\t[Val]   Batch [390/463] Loss: 0.0007, PSNR: 28.0228\n",
      "\t[Val]   Batch [400/463] Loss: 0.0009, PSNR: 25.4845\n",
      "\t[Val]   Batch [410/463] Loss: 0.0007, PSNR: 28.6716\n",
      "\t[Val]   Batch [420/463] Loss: 0.0007, PSNR: 27.4825\n",
      "\t[Val]   Batch [430/463] Loss: 0.0009, PSNR: 25.8098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0008, PSNR: 27.2595\n",
      "\t[Val]   Batch [450/463] Loss: 0.0007, PSNR: 24.3191\n",
      "\t[Val]   Batch [460/463] Loss: 0.0008, PSNR: 26.3454\n",
      "Epoch [6/50] Validation Loss: 0.0008, PSNR: 27.3378\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0008, PSNR: 27.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0008, PSNR: 27.6464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0013, PSNR: 26.5508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0008, PSNR: 27.1961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0008, PSNR: 25.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0008, PSNR: 27.3132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0009, PSNR: 26.9003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0008, PSNR: 27.8433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0008, PSNR: 27.0773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0008, PSNR: 26.5567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0009, PSNR: 26.7943\n",
      "\t[Val]   Batch [1/463] Loss: 0.0006, PSNR: 27.2768\n",
      "\t[Val]   Batch [10/463] Loss: 0.0006, PSNR: 28.6726\n",
      "\t[Val]   Batch [20/463] Loss: 0.0005, PSNR: 27.9801\n",
      "\t[Val]   Batch [30/463] Loss: 0.0007, PSNR: 28.2316\n",
      "\t[Val]   Batch [40/463] Loss: 0.0006, PSNR: 26.6844\n",
      "\t[Val]   Batch [50/463] Loss: 0.0006, PSNR: 27.3242\n",
      "\t[Val]   Batch [60/463] Loss: 0.0006, PSNR: 27.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0007, PSNR: 27.9688\n",
      "\t[Val]   Batch [80/463] Loss: 0.0006, PSNR: 30.5505\n",
      "\t[Val]   Batch [90/463] Loss: 0.0006, PSNR: 28.9921\n",
      "\t[Val]   Batch [100/463] Loss: 0.0007, PSNR: 28.5036\n",
      "\t[Val]   Batch [110/463] Loss: 0.0007, PSNR: 28.4674\n",
      "\t[Val]   Batch [120/463] Loss: 0.0006, PSNR: 27.2180\n",
      "\t[Val]   Batch [130/463] Loss: 0.0006, PSNR: 29.3377\n",
      "\t[Val]   Batch [140/463] Loss: 0.0007, PSNR: 28.6019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0007, PSNR: 29.3781\n",
      "\t[Val]   Batch [160/463] Loss: 0.0008, PSNR: 27.8272\n",
      "\t[Val]   Batch [170/463] Loss: 0.0010, PSNR: 27.1179\n",
      "\t[Val]   Batch [180/463] Loss: 0.0007, PSNR: 27.9066\n",
      "\t[Val]   Batch [190/463] Loss: 0.0007, PSNR: 28.8942\n",
      "\t[Val]   Batch [200/463] Loss: 0.0006, PSNR: 28.8402\n",
      "\t[Val]   Batch [210/463] Loss: 0.0008, PSNR: 26.9362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0007, PSNR: 28.3876\n",
      "\t[Val]   Batch [230/463] Loss: 0.0006, PSNR: 30.1013\n",
      "\t[Val]   Batch [240/463] Loss: 0.0006, PSNR: 27.6809\n",
      "\t[Val]   Batch [250/463] Loss: 0.0008, PSNR: 26.2669\n",
      "\t[Val]   Batch [260/463] Loss: 0.0008, PSNR: 27.1226\n",
      "\t[Val]   Batch [270/463] Loss: 0.0005, PSNR: 27.2449\n",
      "\t[Val]   Batch [280/463] Loss: 0.0006, PSNR: 29.6753\n",
      "\t[Val]   Batch [290/463] Loss: 0.0006, PSNR: 26.9025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0008, PSNR: 28.3620\n",
      "\t[Val]   Batch [310/463] Loss: 0.0008, PSNR: 27.9782\n",
      "\t[Val]   Batch [320/463] Loss: 0.0006, PSNR: 28.8985\n",
      "\t[Val]   Batch [330/463] Loss: 0.0006, PSNR: 28.6948\n",
      "\t[Val]   Batch [340/463] Loss: 0.0006, PSNR: 29.0612\n",
      "\t[Val]   Batch [350/463] Loss: 0.0009, PSNR: 28.5397\n",
      "\t[Val]   Batch [360/463] Loss: 0.0009, PSNR: 27.6737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0007, PSNR: 28.5674\n",
      "\t[Val]   Batch [380/463] Loss: 0.0006, PSNR: 29.5705\n",
      "\t[Val]   Batch [390/463] Loss: 0.0006, PSNR: 28.9881\n",
      "\t[Val]   Batch [400/463] Loss: 0.0007, PSNR: 26.2519\n",
      "\t[Val]   Batch [410/463] Loss: 0.0006, PSNR: 29.5322\n",
      "\t[Val]   Batch [420/463] Loss: 0.0006, PSNR: 28.3441\n",
      "\t[Val]   Batch [430/463] Loss: 0.0008, PSNR: 26.6096\n",
      "\t[Val]   Batch [440/463] Loss: 0.0007, PSNR: 28.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [450/463] Loss: 0.0005, PSNR: 25.2482\n",
      "\t[Val]   Batch [460/463] Loss: 0.0007, PSNR: 27.1287\n",
      "Epoch [7/50] Validation Loss: 0.0006, PSNR: 28.2207\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0008, PSNR: 27.3638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0011, PSNR: 26.1699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0007, PSNR: 27.5532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0007, PSNR: 27.4327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0008, PSNR: 27.8092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0007, PSNR: 26.7963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0006, PSNR: 26.5408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0007, PSNR: 29.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0009, PSNR: 27.3900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0008, PSNR: 27.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0008, PSNR: 27.3984\n",
      "\t[Val]   Batch [1/463] Loss: 0.0005, PSNR: 28.0610\n",
      "\t[Val]   Batch [10/463] Loss: 0.0005, PSNR: 29.4954\n",
      "\t[Val]   Batch [20/463] Loss: 0.0004, PSNR: 28.8138\n",
      "\t[Val]   Batch [30/463] Loss: 0.0006, PSNR: 29.0429\n",
      "\t[Val]   Batch [40/463] Loss: 0.0005, PSNR: 27.4205\n",
      "\t[Val]   Batch [50/463] Loss: 0.0005, PSNR: 28.1240\n",
      "\t[Val]   Batch [60/463] Loss: 0.0005, PSNR: 27.8295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0006, PSNR: 28.7794\n",
      "\t[Val]   Batch [80/463] Loss: 0.0005, PSNR: 31.4628\n",
      "\t[Val]   Batch [90/463] Loss: 0.0005, PSNR: 29.8213\n",
      "\t[Val]   Batch [100/463] Loss: 0.0006, PSNR: 29.3239\n",
      "\t[Val]   Batch [110/463] Loss: 0.0006, PSNR: 29.3330\n",
      "\t[Val]   Batch [120/463] Loss: 0.0005, PSNR: 27.9960\n",
      "\t[Val]   Batch [130/463] Loss: 0.0005, PSNR: 30.1228\n",
      "\t[Val]   Batch [140/463] Loss: 0.0006, PSNR: 29.4542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0005, PSNR: 30.2815\n",
      "\t[Val]   Batch [160/463] Loss: 0.0007, PSNR: 28.5316\n",
      "\t[Val]   Batch [170/463] Loss: 0.0008, PSNR: 27.8586\n",
      "\t[Val]   Batch [180/463] Loss: 0.0006, PSNR: 28.7009\n",
      "\t[Val]   Batch [190/463] Loss: 0.0006, PSNR: 29.6398\n",
      "\t[Val]   Batch [200/463] Loss: 0.0005, PSNR: 29.6584\n",
      "\t[Val]   Batch [210/463] Loss: 0.0007, PSNR: 27.6964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0006, PSNR: 29.1689\n",
      "\t[Val]   Batch [230/463] Loss: 0.0005, PSNR: 30.9843\n",
      "\t[Val]   Batch [240/463] Loss: 0.0005, PSNR: 28.4812\n",
      "\t[Val]   Batch [250/463] Loss: 0.0007, PSNR: 27.0041\n",
      "\t[Val]   Batch [260/463] Loss: 0.0006, PSNR: 27.8452\n",
      "\t[Val]   Batch [270/463] Loss: 0.0004, PSNR: 28.0855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0005, PSNR: 30.4846\n",
      "\t[Val]   Batch [290/463] Loss: 0.0005, PSNR: 27.7818\n",
      "\t[Val]   Batch [300/463] Loss: 0.0007, PSNR: 29.0339\n",
      "\t[Val]   Batch [310/463] Loss: 0.0006, PSNR: 28.7225\n",
      "\t[Val]   Batch [320/463] Loss: 0.0005, PSNR: 29.7842\n",
      "\t[Val]   Batch [330/463] Loss: 0.0005, PSNR: 29.5842\n",
      "\t[Val]   Batch [340/463] Loss: 0.0005, PSNR: 29.8976\n",
      "\t[Val]   Batch [350/463] Loss: 0.0007, PSNR: 29.2892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0008, PSNR: 28.1803\n",
      "\t[Val]   Batch [370/463] Loss: 0.0006, PSNR: 29.4462\n",
      "\t[Val]   Batch [380/463] Loss: 0.0004, PSNR: 30.5266\n",
      "\t[Val]   Batch [390/463] Loss: 0.0005, PSNR: 29.8710\n",
      "\t[Val]   Batch [400/463] Loss: 0.0006, PSNR: 26.9719\n",
      "\t[Val]   Batch [410/463] Loss: 0.0005, PSNR: 30.3158\n",
      "\t[Val]   Batch [420/463] Loss: 0.0005, PSNR: 29.1732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0007, PSNR: 27.3351\n",
      "\t[Val]   Batch [440/463] Loss: 0.0006, PSNR: 28.8449\n",
      "\t[Val]   Batch [450/463] Loss: 0.0005, PSNR: 26.0860\n",
      "\t[Val]   Batch [460/463] Loss: 0.0006, PSNR: 27.8667\n",
      "Epoch [8/50] Validation Loss: 0.0005, PSNR: 29.0358\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0009, PSNR: 28.4544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0007, PSNR: 26.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0007, PSNR: 28.2967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0006, PSNR: 28.7855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0006, PSNR: 29.7103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0007, PSNR: 27.5739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0006, PSNR: 27.6405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0008, PSNR: 27.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0005, PSNR: 29.2160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0007, PSNR: 27.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0007, PSNR: 27.8827\n",
      "\t[Val]   Batch [1/463] Loss: 0.0005, PSNR: 28.6344\n",
      "\t[Val]   Batch [10/463] Loss: 0.0004, PSNR: 30.1003\n",
      "\t[Val]   Batch [20/463] Loss: 0.0004, PSNR: 29.4382\n",
      "\t[Val]   Batch [30/463] Loss: 0.0005, PSNR: 29.6114\n",
      "\t[Val]   Batch [40/463] Loss: 0.0005, PSNR: 27.9465\n",
      "\t[Val]   Batch [50/463] Loss: 0.0004, PSNR: 28.7910\n",
      "\t[Val]   Batch [60/463] Loss: 0.0004, PSNR: 28.3795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0005, PSNR: 29.3695\n",
      "\t[Val]   Batch [80/463] Loss: 0.0004, PSNR: 32.0934\n",
      "\t[Val]   Batch [90/463] Loss: 0.0005, PSNR: 30.4131\n",
      "\t[Val]   Batch [100/463] Loss: 0.0005, PSNR: 29.9421\n",
      "\t[Val]   Batch [110/463] Loss: 0.0005, PSNR: 29.9329\n",
      "\t[Val]   Batch [120/463] Loss: 0.0004, PSNR: 28.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [130/463] Loss: 0.0004, PSNR: 30.7266\n",
      "\t[Val]   Batch [140/463] Loss: 0.0005, PSNR: 30.0158\n",
      "\t[Val]   Batch [150/463] Loss: 0.0005, PSNR: 30.9211\n",
      "\t[Val]   Batch [160/463] Loss: 0.0006, PSNR: 29.0543\n",
      "\t[Val]   Batch [170/463] Loss: 0.0007, PSNR: 28.4243\n",
      "\t[Val]   Batch [180/463] Loss: 0.0005, PSNR: 29.2486\n",
      "\t[Val]   Batch [190/463] Loss: 0.0005, PSNR: 30.2264\n",
      "\t[Val]   Batch [200/463] Loss: 0.0004, PSNR: 30.2962\n",
      "\t[Val]   Batch [210/463] Loss: 0.0006, PSNR: 28.2301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0005, PSNR: 29.7168\n",
      "\t[Val]   Batch [230/463] Loss: 0.0004, PSNR: 31.6049\n",
      "\t[Val]   Batch [240/463] Loss: 0.0004, PSNR: 29.1167\n",
      "\t[Val]   Batch [250/463] Loss: 0.0006, PSNR: 27.5646\n",
      "\t[Val]   Batch [260/463] Loss: 0.0006, PSNR: 28.3783\n",
      "\t[Val]   Batch [270/463] Loss: 0.0003, PSNR: 28.6927\n",
      "\t[Val]   Batch [280/463] Loss: 0.0004, PSNR: 31.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0005, PSNR: 28.3852\n",
      "\t[Val]   Batch [300/463] Loss: 0.0006, PSNR: 29.5219\n",
      "\t[Val]   Batch [310/463] Loss: 0.0006, PSNR: 29.2680\n",
      "\t[Val]   Batch [320/463] Loss: 0.0004, PSNR: 30.4224\n",
      "\t[Val]   Batch [330/463] Loss: 0.0005, PSNR: 30.2303\n",
      "\t[Val]   Batch [340/463] Loss: 0.0004, PSNR: 30.4623\n",
      "\t[Val]   Batch [350/463] Loss: 0.0007, PSNR: 29.8059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0007, PSNR: 28.5459\n",
      "\t[Val]   Batch [370/463] Loss: 0.0005, PSNR: 30.0361\n",
      "\t[Val]   Batch [380/463] Loss: 0.0004, PSNR: 31.2030\n",
      "\t[Val]   Batch [390/463] Loss: 0.0004, PSNR: 30.4555\n",
      "\t[Val]   Batch [400/463] Loss: 0.0006, PSNR: 27.5092\n",
      "\t[Val]   Batch [410/463] Loss: 0.0004, PSNR: 30.8859\n",
      "\t[Val]   Batch [420/463] Loss: 0.0004, PSNR: 29.7547\n",
      "\t[Val]   Batch [430/463] Loss: 0.0006, PSNR: 27.9070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [440/463] Loss: 0.0005, PSNR: 29.3832\n",
      "\t[Val]   Batch [450/463] Loss: 0.0004, PSNR: 26.6750\n",
      "\t[Val]   Batch [460/463] Loss: 0.0005, PSNR: 28.4399\n",
      "Epoch [9/50] Validation Loss: 0.0005, PSNR: 29.6300\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0009, PSNR: 27.0301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0007, PSNR: 27.7793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0006, PSNR: 30.7309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0008, PSNR: 27.2795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0006, PSNR: 27.4714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0006, PSNR: 28.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0006, PSNR: 28.7807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0008, PSNR: 26.6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0006, PSNR: 28.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0007, PSNR: 27.2370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0006, PSNR: 28.3006\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 29.0036\n",
      "\t[Val]   Batch [10/463] Loss: 0.0004, PSNR: 30.6319\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 29.8548\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 30.0620\n",
      "\t[Val]   Batch [40/463] Loss: 0.0004, PSNR: 28.3926\n",
      "\t[Val]   Batch [50/463] Loss: 0.0004, PSNR: 29.2918\n",
      "\t[Val]   Batch [60/463] Loss: 0.0004, PSNR: 28.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0005, PSNR: 29.7949\n",
      "\t[Val]   Batch [80/463] Loss: 0.0004, PSNR: 32.5684\n",
      "\t[Val]   Batch [90/463] Loss: 0.0004, PSNR: 30.8234\n",
      "\t[Val]   Batch [100/463] Loss: 0.0004, PSNR: 30.3851\n",
      "\t[Val]   Batch [110/463] Loss: 0.0004, PSNR: 30.3649\n",
      "\t[Val]   Batch [120/463] Loss: 0.0004, PSNR: 29.0527\n",
      "\t[Val]   Batch [130/463] Loss: 0.0004, PSNR: 31.1025\n",
      "\t[Val]   Batch [140/463] Loss: 0.0005, PSNR: 30.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0004, PSNR: 31.2958\n",
      "\t[Val]   Batch [160/463] Loss: 0.0005, PSNR: 29.5689\n",
      "\t[Val]   Batch [170/463] Loss: 0.0007, PSNR: 28.7788\n",
      "\t[Val]   Batch [180/463] Loss: 0.0005, PSNR: 29.7362\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 30.6786\n",
      "\t[Val]   Batch [200/463] Loss: 0.0004, PSNR: 30.7521\n",
      "\t[Val]   Batch [210/463] Loss: 0.0005, PSNR: 28.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0005, PSNR: 30.1442\n",
      "\t[Val]   Batch [230/463] Loss: 0.0004, PSNR: 31.9038\n",
      "\t[Val]   Batch [240/463] Loss: 0.0004, PSNR: 29.6448\n",
      "\t[Val]   Batch [250/463] Loss: 0.0006, PSNR: 28.0508\n",
      "\t[Val]   Batch [260/463] Loss: 0.0005, PSNR: 28.8727\n",
      "\t[Val]   Batch [270/463] Loss: 0.0003, PSNR: 29.2943\n",
      "\t[Val]   Batch [280/463] Loss: 0.0004, PSNR: 31.5463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0004, PSNR: 28.8334\n",
      "\t[Val]   Batch [300/463] Loss: 0.0005, PSNR: 29.9226\n",
      "\t[Val]   Batch [310/463] Loss: 0.0005, PSNR: 29.8149\n",
      "\t[Val]   Batch [320/463] Loss: 0.0004, PSNR: 30.9261\n",
      "\t[Val]   Batch [330/463] Loss: 0.0004, PSNR: 30.6741\n",
      "\t[Val]   Batch [340/463] Loss: 0.0004, PSNR: 30.9646\n",
      "\t[Val]   Batch [350/463] Loss: 0.0006, PSNR: 30.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0007, PSNR: 28.9175\n",
      "\t[Val]   Batch [370/463] Loss: 0.0005, PSNR: 30.3473\n",
      "\t[Val]   Batch [380/463] Loss: 0.0004, PSNR: 31.5939\n",
      "\t[Val]   Batch [390/463] Loss: 0.0004, PSNR: 30.8605\n",
      "\t[Val]   Batch [400/463] Loss: 0.0005, PSNR: 27.9715\n",
      "\t[Val]   Batch [410/463] Loss: 0.0004, PSNR: 31.3021\n",
      "\t[Val]   Batch [420/463] Loss: 0.0004, PSNR: 30.2331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0005, PSNR: 28.3801\n",
      "\t[Val]   Batch [440/463] Loss: 0.0005, PSNR: 29.7921\n",
      "\t[Val]   Batch [450/463] Loss: 0.0004, PSNR: 27.1745\n",
      "\t[Val]   Batch [460/463] Loss: 0.0005, PSNR: 28.8296\n",
      "Epoch [10/50] Validation Loss: 0.0004, PSNR: 30.0831\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0006, PSNR: 27.5992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0006, PSNR: 28.0573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0005, PSNR: 29.1651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0006, PSNR: 29.6801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0008, PSNR: 26.4614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0006, PSNR: 28.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0005, PSNR: 29.8687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0006, PSNR: 27.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0005, PSNR: 28.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0005, PSNR: 28.8373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0006, PSNR: 28.7060\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 29.5504\n",
      "\t[Val]   Batch [10/463] Loss: 0.0003, PSNR: 31.1597\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 30.3729\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 30.6096\n",
      "\t[Val]   Batch [40/463] Loss: 0.0004, PSNR: 28.8911\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 29.8541\n",
      "\t[Val]   Batch [60/463] Loss: 0.0004, PSNR: 29.3747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0004, PSNR: 30.3304\n",
      "\t[Val]   Batch [80/463] Loss: 0.0003, PSNR: 33.1953\n",
      "\t[Val]   Batch [90/463] Loss: 0.0004, PSNR: 31.4102\n",
      "\t[Val]   Batch [100/463] Loss: 0.0004, PSNR: 30.9423\n",
      "\t[Val]   Batch [110/463] Loss: 0.0004, PSNR: 30.9616\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 29.4922\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 31.6877\n",
      "\t[Val]   Batch [140/463] Loss: 0.0004, PSNR: 31.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0004, PSNR: 32.0005\n",
      "\t[Val]   Batch [160/463] Loss: 0.0005, PSNR: 30.0449\n",
      "\t[Val]   Batch [170/463] Loss: 0.0006, PSNR: 29.3582\n",
      "\t[Val]   Batch [180/463] Loss: 0.0004, PSNR: 30.2783\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 31.0858\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 31.2775\n",
      "\t[Val]   Batch [210/463] Loss: 0.0005, PSNR: 29.3166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0004, PSNR: 30.5785\n",
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 32.5774\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 30.1658\n",
      "\t[Val]   Batch [250/463] Loss: 0.0005, PSNR: 28.6191\n",
      "\t[Val]   Batch [260/463] Loss: 0.0005, PSNR: 29.3747\n",
      "\t[Val]   Batch [270/463] Loss: 0.0003, PSNR: 29.7066\n",
      "\t[Val]   Batch [280/463] Loss: 0.0004, PSNR: 32.0525\n",
      "\t[Val]   Batch [290/463] Loss: 0.0004, PSNR: 29.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0005, PSNR: 30.3520\n",
      "\t[Val]   Batch [310/463] Loss: 0.0005, PSNR: 30.2380\n",
      "\t[Val]   Batch [320/463] Loss: 0.0003, PSNR: 31.4959\n",
      "\t[Val]   Batch [330/463] Loss: 0.0004, PSNR: 31.2447\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 31.4810\n",
      "\t[Val]   Batch [350/463] Loss: 0.0005, PSNR: 30.8438\n",
      "\t[Val]   Batch [360/463] Loss: 0.0006, PSNR: 29.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0004, PSNR: 31.0289\n",
      "\t[Val]   Batch [380/463] Loss: 0.0003, PSNR: 32.2998\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 31.4348\n",
      "\t[Val]   Batch [400/463] Loss: 0.0004, PSNR: 28.4469\n",
      "\t[Val]   Batch [410/463] Loss: 0.0004, PSNR: 31.7361\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 30.7461\n",
      "\t[Val]   Batch [430/463] Loss: 0.0005, PSNR: 28.8803\n",
      "\t[Val]   Batch [440/463] Loss: 0.0004, PSNR: 30.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 27.6062\n",
      "\t[Val]   Batch [460/463] Loss: 0.0004, PSNR: 29.3869\n",
      "Epoch [11/50] Validation Loss: 0.0004, PSNR: 30.6237\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0004, PSNR: 27.9661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0009, PSNR: 27.6308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0005, PSNR: 30.2992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0005, PSNR: 28.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0005, PSNR: 30.1139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0006, PSNR: 28.7482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0007, PSNR: 27.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0005, PSNR: 29.4584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0005, PSNR: 30.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0004, PSNR: 28.6052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0005, PSNR: 29.0159\n",
      "\t[Val]   Batch [1/463] Loss: 0.0004, PSNR: 29.7724\n",
      "\t[Val]   Batch [10/463] Loss: 0.0003, PSNR: 31.3789\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 30.6151\n",
      "\t[Val]   Batch [30/463] Loss: 0.0004, PSNR: 30.8200\n",
      "\t[Val]   Batch [40/463] Loss: 0.0004, PSNR: 29.1413\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 30.2143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [60/463] Loss: 0.0003, PSNR: 29.6609\n",
      "\t[Val]   Batch [70/463] Loss: 0.0004, PSNR: 30.6233\n",
      "\t[Val]   Batch [80/463] Loss: 0.0003, PSNR: 33.4953\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 31.6783\n",
      "\t[Val]   Batch [100/463] Loss: 0.0004, PSNR: 31.2822\n",
      "\t[Val]   Batch [110/463] Loss: 0.0004, PSNR: 31.2351\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 29.6674\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 31.9391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0004, PSNR: 31.2388\n",
      "\t[Val]   Batch [150/463] Loss: 0.0003, PSNR: 32.3482\n",
      "\t[Val]   Batch [160/463] Loss: 0.0005, PSNR: 30.3907\n",
      "\t[Val]   Batch [170/463] Loss: 0.0005, PSNR: 29.6172\n",
      "\t[Val]   Batch [180/463] Loss: 0.0004, PSNR: 30.5463\n",
      "\t[Val]   Batch [190/463] Loss: 0.0004, PSNR: 31.3456\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 31.6256\n",
      "\t[Val]   Batch [210/463] Loss: 0.0004, PSNR: 29.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0004, PSNR: 30.7705\n",
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 32.7377\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 30.4511\n",
      "\t[Val]   Batch [250/463] Loss: 0.0005, PSNR: 28.9506\n",
      "\t[Val]   Batch [260/463] Loss: 0.0004, PSNR: 29.7269\n",
      "\t[Val]   Batch [270/463] Loss: 0.0002, PSNR: 29.9632\n",
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 32.3399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 29.7087\n",
      "\t[Val]   Batch [300/463] Loss: 0.0005, PSNR: 30.6125\n",
      "\t[Val]   Batch [310/463] Loss: 0.0004, PSNR: 30.5871\n",
      "\t[Val]   Batch [320/463] Loss: 0.0003, PSNR: 31.8078\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 31.5533\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 31.7724\n",
      "\t[Val]   Batch [350/463] Loss: 0.0005, PSNR: 31.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0006, PSNR: 29.3966\n",
      "\t[Val]   Batch [370/463] Loss: 0.0004, PSNR: 31.2433\n",
      "\t[Val]   Batch [380/463] Loss: 0.0003, PSNR: 32.6452\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 31.6600\n",
      "\t[Val]   Batch [400/463] Loss: 0.0004, PSNR: 28.6855\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 31.9563\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 31.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0004, PSNR: 29.1254\n",
      "\t[Val]   Batch [440/463] Loss: 0.0004, PSNR: 30.4933\n",
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 27.8316\n",
      "\t[Val]   Batch [460/463] Loss: 0.0004, PSNR: 29.6949\n",
      "Epoch [12/50] Validation Loss: 0.0003, PSNR: 30.9001\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0005, PSNR: 30.0867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0006, PSNR: 28.2149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0006, PSNR: 27.7033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0005, PSNR: 29.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0005, PSNR: 29.6375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0004, PSNR: 29.4841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0006, PSNR: 28.4026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0005, PSNR: 30.4893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0004, PSNR: 29.0631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0006, PSNR: 28.2029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0005, PSNR: 29.2993\n",
      "\t[Val]   Batch [1/463] Loss: 0.0003, PSNR: 30.2061\n",
      "\t[Val]   Batch [10/463] Loss: 0.0003, PSNR: 31.8718\n",
      "\t[Val]   Batch [20/463] Loss: 0.0003, PSNR: 31.0795\n",
      "\t[Val]   Batch [30/463] Loss: 0.0003, PSNR: 31.3570\n",
      "\t[Val]   Batch [40/463] Loss: 0.0003, PSNR: 29.5803\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 30.6474\n",
      "\t[Val]   Batch [60/463] Loss: 0.0003, PSNR: 30.1144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0004, PSNR: 31.1426\n",
      "\t[Val]   Batch [80/463] Loss: 0.0003, PSNR: 33.9656\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 32.1413\n",
      "\t[Val]   Batch [100/463] Loss: 0.0003, PSNR: 31.7266\n",
      "\t[Val]   Batch [110/463] Loss: 0.0003, PSNR: 31.7650\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 30.1199\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 32.4682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [140/463] Loss: 0.0003, PSNR: 31.7739\n",
      "\t[Val]   Batch [150/463] Loss: 0.0003, PSNR: 32.9154\n",
      "\t[Val]   Batch [160/463] Loss: 0.0004, PSNR: 30.9096\n",
      "\t[Val]   Batch [170/463] Loss: 0.0005, PSNR: 30.1494\n",
      "\t[Val]   Batch [180/463] Loss: 0.0003, PSNR: 31.0739\n",
      "\t[Val]   Batch [190/463] Loss: 0.0003, PSNR: 31.7238\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 32.0636\n",
      "\t[Val]   Batch [210/463] Loss: 0.0004, PSNR: 30.2442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [220/463] Loss: 0.0004, PSNR: 31.2127\n",
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 33.3118\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 30.9998\n",
      "\t[Val]   Batch [250/463] Loss: 0.0004, PSNR: 29.4530\n",
      "\t[Val]   Batch [260/463] Loss: 0.0004, PSNR: 30.2890\n",
      "\t[Val]   Batch [270/463] Loss: 0.0002, PSNR: 30.4049\n",
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 32.7366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 30.2430\n",
      "\t[Val]   Batch [300/463] Loss: 0.0004, PSNR: 31.0286\n",
      "\t[Val]   Batch [310/463] Loss: 0.0004, PSNR: 31.0532\n",
      "\t[Val]   Batch [320/463] Loss: 0.0003, PSNR: 32.2920\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 31.9937\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 32.2934\n",
      "\t[Val]   Batch [350/463] Loss: 0.0004, PSNR: 31.6521\n",
      "\t[Val]   Batch [360/463] Loss: 0.0006, PSNR: 29.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0003, PSNR: 31.8109\n",
      "\t[Val]   Batch [380/463] Loss: 0.0002, PSNR: 33.1047\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 32.1179\n",
      "\t[Val]   Batch [400/463] Loss: 0.0004, PSNR: 29.1388\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 32.3619\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 31.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0004, PSNR: 29.6236\n",
      "\t[Val]   Batch [440/463] Loss: 0.0004, PSNR: 30.9412\n",
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 28.3196\n",
      "\t[Val]   Batch [460/463] Loss: 0.0003, PSNR: 30.1939\n",
      "Epoch [13/50] Validation Loss: 0.0003, PSNR: 31.3874\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0004, PSNR: 30.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0004, PSNR: 29.7972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0004, PSNR: 31.8614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0006, PSNR: 28.3222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0006, PSNR: 30.2650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0006, PSNR: 28.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0005, PSNR: 29.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0004, PSNR: 31.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0005, PSNR: 28.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0006, PSNR: 28.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0005, PSNR: 29.5596\n",
      "\t[Val]   Batch [1/463] Loss: 0.0003, PSNR: 30.4326\n",
      "\t[Val]   Batch [10/463] Loss: 0.0002, PSNR: 32.1300\n",
      "\t[Val]   Batch [20/463] Loss: 0.0002, PSNR: 31.3282\n",
      "\t[Val]   Batch [30/463] Loss: 0.0003, PSNR: 31.6507\n",
      "\t[Val]   Batch [40/463] Loss: 0.0003, PSNR: 29.8211\n",
      "\t[Val]   Batch [50/463] Loss: 0.0003, PSNR: 30.9549\n",
      "\t[Val]   Batch [60/463] Loss: 0.0003, PSNR: 30.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0003, PSNR: 31.4613\n",
      "\t[Val]   Batch [80/463] Loss: 0.0002, PSNR: 34.2329\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 32.4220\n",
      "\t[Val]   Batch [100/463] Loss: 0.0003, PSNR: 32.0796\n",
      "\t[Val]   Batch [110/463] Loss: 0.0003, PSNR: 32.1164\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 30.3515\n",
      "\t[Val]   Batch [130/463] Loss: 0.0003, PSNR: 32.6808\n",
      "\t[Val]   Batch [140/463] Loss: 0.0003, PSNR: 32.0229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0003, PSNR: 33.2820\n",
      "\t[Val]   Batch [160/463] Loss: 0.0004, PSNR: 31.2644\n",
      "\t[Val]   Batch [170/463] Loss: 0.0004, PSNR: 30.4721\n",
      "\t[Val]   Batch [180/463] Loss: 0.0003, PSNR: 31.3329\n",
      "\t[Val]   Batch [190/463] Loss: 0.0003, PSNR: 31.9563\n",
      "\t[Val]   Batch [200/463] Loss: 0.0003, PSNR: 32.3139\n",
      "\t[Val]   Batch [210/463] Loss: 0.0003, PSNR: 30.5770\n",
      "\t[Val]   Batch [220/463] Loss: 0.0004, PSNR: 31.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [230/463] Loss: 0.0003, PSNR: 33.5737\n",
      "\t[Val]   Batch [240/463] Loss: 0.0003, PSNR: 31.2489\n",
      "\t[Val]   Batch [250/463] Loss: 0.0004, PSNR: 29.7101\n",
      "\t[Val]   Batch [260/463] Loss: 0.0003, PSNR: 30.6651\n",
      "\t[Val]   Batch [270/463] Loss: 0.0002, PSNR: 30.6746\n",
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 32.9808\n",
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 30.5186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [300/463] Loss: 0.0004, PSNR: 31.3014\n",
      "\t[Val]   Batch [310/463] Loss: 0.0003, PSNR: 31.3905\n",
      "\t[Val]   Batch [320/463] Loss: 0.0003, PSNR: 32.5225\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 32.3017\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 32.5331\n",
      "\t[Val]   Batch [350/463] Loss: 0.0004, PSNR: 31.9065\n",
      "\t[Val]   Batch [360/463] Loss: 0.0005, PSNR: 29.8497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [370/463] Loss: 0.0003, PSNR: 32.0405\n",
      "\t[Val]   Batch [380/463] Loss: 0.0002, PSNR: 33.4624\n",
      "\t[Val]   Batch [390/463] Loss: 0.0003, PSNR: 32.3791\n",
      "\t[Val]   Batch [400/463] Loss: 0.0004, PSNR: 29.4228\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 32.5928\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 31.6829\n",
      "\t[Val]   Batch [430/463] Loss: 0.0004, PSNR: 29.8861\n",
      "\t[Val]   Batch [440/463] Loss: 0.0003, PSNR: 31.1834\n",
      "\t[Val]   Batch [450/463] Loss: 0.0003, PSNR: 28.5606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [460/463] Loss: 0.0003, PSNR: 30.4945\n",
      "Epoch [14/50] Validation Loss: 0.0003, PSNR: 31.6552\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0010, PSNR: 27.2665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0004, PSNR: 29.8911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0004, PSNR: 30.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0005, PSNR: 28.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0005, PSNR: 30.1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0005, PSNR: 28.4938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0004, PSNR: 30.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0004, PSNR: 29.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0005, PSNR: 29.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0004, PSNR: 29.3449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0005, PSNR: 29.8171\n",
      "\t[Val]   Batch [1/463] Loss: 0.0003, PSNR: 30.7141\n",
      "\t[Val]   Batch [10/463] Loss: 0.0002, PSNR: 32.4282\n",
      "\t[Val]   Batch [20/463] Loss: 0.0002, PSNR: 31.5891\n",
      "\t[Val]   Batch [30/463] Loss: 0.0003, PSNR: 32.0028\n",
      "\t[Val]   Batch [40/463] Loss: 0.0003, PSNR: 30.1042\n",
      "\t[Val]   Batch [50/463] Loss: 0.0002, PSNR: 31.2835\n",
      "\t[Val]   Batch [60/463] Loss: 0.0003, PSNR: 30.7460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0003, PSNR: 31.8708\n",
      "\t[Val]   Batch [80/463] Loss: 0.0002, PSNR: 34.5514\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 32.7416\n",
      "\t[Val]   Batch [100/463] Loss: 0.0003, PSNR: 32.3711\n",
      "\t[Val]   Batch [110/463] Loss: 0.0003, PSNR: 32.4464\n",
      "\t[Val]   Batch [120/463] Loss: 0.0003, PSNR: 30.6497\n",
      "\t[Val]   Batch [130/463] Loss: 0.0002, PSNR: 32.9879\n",
      "\t[Val]   Batch [140/463] Loss: 0.0003, PSNR: 32.3599\n",
      "\t[Val]   Batch [150/463] Loss: 0.0002, PSNR: 33.6844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [160/463] Loss: 0.0003, PSNR: 31.7299\n",
      "\t[Val]   Batch [170/463] Loss: 0.0004, PSNR: 30.8753\n",
      "\t[Val]   Batch [180/463] Loss: 0.0003, PSNR: 31.6512\n",
      "\t[Val]   Batch [190/463] Loss: 0.0003, PSNR: 32.2326\n",
      "\t[Val]   Batch [200/463] Loss: 0.0002, PSNR: 32.6124\n",
      "\t[Val]   Batch [210/463] Loss: 0.0003, PSNR: 30.9995\n",
      "\t[Val]   Batch [220/463] Loss: 0.0003, PSNR: 31.7590\n",
      "\t[Val]   Batch [230/463] Loss: 0.0002, PSNR: 33.9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [240/463] Loss: 0.0002, PSNR: 31.5699\n",
      "\t[Val]   Batch [250/463] Loss: 0.0003, PSNR: 30.0812\n",
      "\t[Val]   Batch [260/463] Loss: 0.0003, PSNR: 31.1343\n",
      "\t[Val]   Batch [270/463] Loss: 0.0002, PSNR: 30.9673\n",
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 33.2494\n",
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 30.8994\n",
      "\t[Val]   Batch [300/463] Loss: 0.0004, PSNR: 31.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [310/463] Loss: 0.0003, PSNR: 31.7349\n",
      "\t[Val]   Batch [320/463] Loss: 0.0002, PSNR: 32.8072\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 32.5911\n",
      "\t[Val]   Batch [340/463] Loss: 0.0003, PSNR: 32.8612\n",
      "\t[Val]   Batch [350/463] Loss: 0.0004, PSNR: 32.3376\n",
      "\t[Val]   Batch [360/463] Loss: 0.0005, PSNR: 30.0331\n",
      "\t[Val]   Batch [370/463] Loss: 0.0003, PSNR: 32.4205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [380/463] Loss: 0.0002, PSNR: 33.7686\n",
      "\t[Val]   Batch [390/463] Loss: 0.0002, PSNR: 32.6653\n",
      "\t[Val]   Batch [400/463] Loss: 0.0003, PSNR: 29.7348\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 32.7828\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 32.0271\n",
      "\t[Val]   Batch [430/463] Loss: 0.0003, PSNR: 30.1983\n",
      "\t[Val]   Batch [440/463] Loss: 0.0003, PSNR: 31.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [450/463] Loss: 0.0002, PSNR: 28.9670\n",
      "\t[Val]   Batch [460/463] Loss: 0.0003, PSNR: 30.9111\n",
      "Epoch [15/50] Validation Loss: 0.0003, PSNR: 31.9930\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/1852], Loss: 0.0005, PSNR: 29.9432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [200/1852], Loss: 0.0004, PSNR: 29.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [400/1852], Loss: 0.0004, PSNR: 29.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [600/1852], Loss: 0.0004, PSNR: 30.4541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [800/1852], Loss: 0.0004, PSNR: 30.2250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1000/1852], Loss: 0.0003, PSNR: 29.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1200/1852], Loss: 0.0004, PSNR: 30.5967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1400/1852], Loss: 0.0005, PSNR: 30.7892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1600/1852], Loss: 0.0005, PSNR: 30.2951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1800/1852], Loss: 0.0004, PSNR: 28.2781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0004, PSNR: 30.0276\n",
      "\t[Val]   Batch [1/463] Loss: 0.0003, PSNR: 30.8772\n",
      "\t[Val]   Batch [10/463] Loss: 0.0002, PSNR: 32.5759\n",
      "\t[Val]   Batch [20/463] Loss: 0.0002, PSNR: 31.6743\n",
      "\t[Val]   Batch [30/463] Loss: 0.0003, PSNR: 32.1096\n",
      "\t[Val]   Batch [40/463] Loss: 0.0003, PSNR: 30.2237\n",
      "\t[Val]   Batch [50/463] Loss: 0.0002, PSNR: 31.4759\n",
      "\t[Val]   Batch [60/463] Loss: 0.0002, PSNR: 30.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [70/463] Loss: 0.0003, PSNR: 32.0533\n",
      "\t[Val]   Batch [80/463] Loss: 0.0002, PSNR: 34.7147\n",
      "\t[Val]   Batch [90/463] Loss: 0.0003, PSNR: 32.8752\n",
      "\t[Val]   Batch [100/463] Loss: 0.0003, PSNR: 32.5526\n",
      "\t[Val]   Batch [110/463] Loss: 0.0003, PSNR: 32.6015\n",
      "\t[Val]   Batch [120/463] Loss: 0.0002, PSNR: 30.7860\n",
      "\t[Val]   Batch [130/463] Loss: 0.0002, PSNR: 33.2237\n",
      "\t[Val]   Batch [140/463] Loss: 0.0003, PSNR: 32.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [150/463] Loss: 0.0002, PSNR: 33.8914\n",
      "\t[Val]   Batch [160/463] Loss: 0.0003, PSNR: 32.0026\n",
      "\t[Val]   Batch [170/463] Loss: 0.0004, PSNR: 31.0967\n",
      "\t[Val]   Batch [180/463] Loss: 0.0003, PSNR: 31.8132\n",
      "\t[Val]   Batch [190/463] Loss: 0.0003, PSNR: 32.3401\n",
      "\t[Val]   Batch [200/463] Loss: 0.0002, PSNR: 32.7210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [210/463] Loss: 0.0003, PSNR: 31.2253\n",
      "\t[Val]   Batch [220/463] Loss: 0.0003, PSNR: 31.8423\n",
      "\t[Val]   Batch [230/463] Loss: 0.0002, PSNR: 34.0600\n",
      "\t[Val]   Batch [240/463] Loss: 0.0002, PSNR: 31.7657\n",
      "\t[Val]   Batch [250/463] Loss: 0.0003, PSNR: 30.2334\n",
      "\t[Val]   Batch [260/463] Loss: 0.0003, PSNR: 31.4195\n",
      "\t[Val]   Batch [270/463] Loss: 0.0002, PSNR: 31.1547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [280/463] Loss: 0.0003, PSNR: 33.3824\n",
      "\t[Val]   Batch [290/463] Loss: 0.0003, PSNR: 31.0025\n",
      "\t[Val]   Batch [300/463] Loss: 0.0003, PSNR: 31.8836\n",
      "\t[Val]   Batch [310/463] Loss: 0.0003, PSNR: 31.8871\n",
      "\t[Val]   Batch [320/463] Loss: 0.0002, PSNR: 33.0083\n",
      "\t[Val]   Batch [330/463] Loss: 0.0003, PSNR: 32.7054\n",
      "\t[Val]   Batch [340/463] Loss: 0.0002, PSNR: 33.0437\n",
      "\t[Val]   Batch [350/463] Loss: 0.0004, PSNR: 32.5255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [360/463] Loss: 0.0005, PSNR: 30.1244\n",
      "\t[Val]   Batch [370/463] Loss: 0.0003, PSNR: 32.5762\n",
      "\t[Val]   Batch [380/463] Loss: 0.0002, PSNR: 33.8670\n",
      "\t[Val]   Batch [390/463] Loss: 0.0002, PSNR: 32.6993\n",
      "\t[Val]   Batch [400/463] Loss: 0.0003, PSNR: 29.8666\n",
      "\t[Val]   Batch [410/463] Loss: 0.0003, PSNR: 32.9026\n",
      "\t[Val]   Batch [420/463] Loss: 0.0003, PSNR: 32.1622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Val]   Batch [430/463] Loss: 0.0003, PSNR: 30.3734\n",
      "\t[Val]   Batch [440/463] Loss: 0.0003, PSNR: 31.6805\n",
      "\t[Val]   Batch [450/463] Loss: 0.0002, PSNR: 29.1115\n",
      "\t[Val]   Batch [460/463] Loss: 0.0003, PSNR: 31.1478\n",
      "Epoch [16/50] Validation Loss: 0.0003, PSNR: 32.1439\n",
      "Early stopping triggered at epoch 16. No improvement for 3 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAClsElEQVR4nOzdZ3hU1f728e/MpFcIEBJI6DUUASkCUhWsiCJYUBT12A7yKHZEBFREbGDlFBX0z0E5HsGKCEgXULp0QQKhhQAhhdTJzH5e7GSSIQlJIMkEcn+uKxcza/bsvWYRY27W2r9lMQzDQERERERERC6I1dMdEBERERERuRQoXImIiIiIiJQDhSsREREREZFyoHAlIiIiIiJSDhSuREREREREyoHClYiIiIiISDlQuBIRERERESkHClciIiIiIiLlQOFKRERERESkHChciYhUEbNmzcJisbi+vLy8iIqK4r777uPIkSNux+7atYsRI0bQpEkT/Pz8qF27Np06deKxxx4jJSXFddzIkSOxWCy0adMGh8NR6JoWi4XHHnvM9fzAgQNufbBardSsWZOrrrqKRYsWlfgZGjVq5Pb+4r5mzZp1/gNVDvLG+sCBA6U6fuHChdxwww3UqVMHX19foqOjuffee9m5c2fFdvQ8LF++vEqPPRT+vhMRuVR4eboDIiLibubMmbRq1YqMjAxWrlzJlClTWLFiBdu2bSMwMJDNmzfTs2dPWrduzUsvvUSjRo04efIkW7du5csvv+Tpp58mJCTE7Zw7d+5k1qxZPPDAA6Xqw+jRoxk+fDgOh4Pdu3czadIkrr/+epYuXUrv3r2Lfd/8+fPJyspyPf/444/55JNPWLhwIaGhoa72pk2blnFUPOfZZ5/lzTff5Nprr+Wjjz6ibt26/Pnnn7zzzjt06tSJOXPmMGTIEE93s5DXXnuNfv36FWq/mMZeRORio3AlIlLFtG3bls6dOwPQr18/HA4Hr7zyCt988w133XUX06dPx2q1snz5coKDg13vGzp0KK+88gqGYbidLzAwkE6dOjFhwgSGDx+Ov79/iX1o0KABV1xxBQA9e/akefPm9OnTh08++eSc4apjx45uzxcuXAjA5ZdfTu3atYt9X3p6OgEBASX2q7J98cUXvPnmmzz66KN89NFHrvbevXtz55130qdPH0aMGEGHDh1o0qRJpfWrNOPVvHlz19+hiIhUDi0LFBGp4vJ+QT548CAAp06dIiQkhKCgoCKPt1gshdqmTp3KkSNHePfdd8+rD3lh7/jx4+f1/oJGjhxJUFAQ27ZtY+DAgQQHB3PVVVcBkJ2dzauvvkqrVq3w9fWlTp063HfffZw4ccLtHI0aNeLGG29k4cKFdOrUCX9/f1q1asWnn35a6Hrr1q2jZ8+e+Pn5Ua9ePcaOHYvdbi9VXydPnkzNmjV56623Cr0WGBjI+++/T3p6OtOmTQNg+vTpWCwW9u3bV+j45557Dh8fH06ePOlqW7JkCVdddRUhISEEBATQs2dPfvnlF7f3TZw4EYvFwqZNmxg6dCg1a9Yst9mnvHGcP38+7du3x8/PjyZNmvDee+8VOjYuLo67776b8PBwfH19ad26NW+//TZOp9PtuKysLF5++WVat26Nn58ftWrVol+/fqxZs6bQOf/v//6P1q1bExAQwGWXXcYPP/zg9vqJEyd46KGHiI6Odn0/9OzZkyVLlpTL5xcRKW8KVyIiVVzeL+p16tQBoHv37hw7doy77rqLFStWkJGRUeI5unfvzi233MLUqVNJTEwscx9iY2MBaNGiRZnfW5Ts7Gxuuukm+vfvz7fffsukSZNwOp0MHjyY119/neHDh/Pjjz/y+uuvs3jxYvr27Vvoc27dupWnnnqKMWPG8O2339K+fXseeOABVq5c6Tpm586dXHXVVSQlJTFr1iz+8Y9/sHnzZl599dUS+3js2DF27NjBwIEDi50l6t69O+Hh4SxevBiAu+++Gx8fn0L3NTkcDmbPns2gQYNcM3izZ89m4MCBhISE8Nlnn/Hf//6XsLAwrrnmmkIBC2DIkCE0a9aMr776in/84x8l9t/pdJKTk1Po62xbtmzhiSeeYMyYMcyfP58ePXrw+OOPuwXKEydO0KNHDxYtWsQrr7zCd999x9VXX83TTz/tdu9UTk4O1113Ha+88oortM2aNYsePXoQFxfndt0ff/yRDz74gJdffpmvv/6asLAwbrnlFvbv3+86ZsSIEXzzzTe89NJLLFq0iI8//pirr76aU6dOlfj5RUQ8whARkSph5syZBmCsW7fOsNvtRmpqqvHDDz8YderUMYKDg434+HjDMAwjMzPTuPnmmw3AAAybzWZ07NjRGDdunJGQkOB2znvvvdcIDAw0DMMwdu/ebdhsNuOpp55yvQ4Yo0aNcj2PjY01AGPq1KmG3W43MjMzjS1bthjdu3c3IiMjjdjY2DJ9pgkTJhiAceLECbc+Acann37qduwXX3xhAMbXX3/t1r5+/XoDMD766CNXW8OGDQ0/Pz/j4MGDrraMjAwjLCzMePjhh11tt99+u+Hv7+8aO8MwjJycHKNVq1YGcM7Ps27dOgMwnn/++XN+xm7duhn+/v6u50OGDDGioqIMh8PhaluwYIEBGN9//71hGIaRlpZmhIWFGYMGDXI7l8PhMC677DKja9eurra8MXzppZfO2Y88y5Ytc31vFPV16NAh17ENGzY0LBaLsWXLFrdzDBgwwAgJCTHS0tIMwzCM559/3gCM3377ze24Rx991LBYLMaePXsMwzCMzz//3ACMf//73+fsI2DUrVvXSElJcbXFx8cbVqvVmDJliqstKCjIeOKJJ0r1uUVEqgLNXImIVDFXXHEF3t7eBAcHc+ONNxIREcFPP/1E3bp1AfD19WX+/Pns3LmTadOmcccdd3DixAkmT55M69at2bNnT5HnbdmyJQ888AAffPBBoVmEsz333HN4e3vj5+dHhw4d2L59O99//z2NGjUqt8956623uj3/4YcfqFGjBoMGDXKbaenQoQMREREsX77c7fgOHTrQoEED13M/Pz9atGjhWj4JsGzZMq666irX2AHYbDZuv/32cvschmG4LcW87777OHz4sNvStZkzZxIREcF1110HwJo1a0hMTOTee+91+6xOp5Nrr72W9evXk5aW5nads8erJFOnTmX9+vWFvgqOBUCbNm247LLL3NqGDx9OSkoKmzZtAmDp0qXExMTQtWtXt+NGjhyJYRgsXboUgJ9++gk/Pz/uv//+EvvXr18/t3sG69atS3h4uNvfX9euXZk1axavvvoq69atK/VyThERT1G4EhGpYj7//HPWr1/P5s2bOXr0KH/88Qc9e/YsdFzr1q154oknmD17NnFxcbzzzjucOnWK8ePHF3vuiRMnYrPZznkMwOOPP8769etZvXo1b731Fna7ncGDB5fbcqyAgIBCFQ2PHz9OUlISPj4+eHt7u33Fx8e73asEUKtWrULn9fX1dVs+eOrUKSIiIgodV1Tb2fKCW96SyOIcPHiQ6Oho1/PrrruOyMhIZs6cCcDp06f57rvvuOeee7DZbK7PCmYRkrM/69SpUzEMo9DyzcjIyBL7XFCTJk3o3LlzoS9vb2+34841Pnl/36dOnSry+vXq1XM77sSJE9SrVw+rteRfL0rz9zd37lzuvfdePv74Y7p3705YWBj33HMP8fHxJZ5fRMQTVC1QRKSKad26tauARGlZLBbGjBnDyy+/zPbt24s9LjIykieeeILXX3+dp556qtjjoqKiXH3o2bMnERER3H333UyYMIEPPvigTH0rrr9nq127NrVq1XJVGDxbwVmO0qpVq1aRv4iX5pfzyMhI2rRpw6JFi4qtzrd27VqOHz/OsGHDXG02m40RI0bw3nvvkZSUxJw5c8jKyuK+++5zHZN339X7779fbEW/s2eYihqz8nCu8ckLQLVq1eLYsWOFjjt69CiQ/3nq1KnD6tWrcTqdpQpYJalduzbTp09n+vTpxMXF8d133/H888+TkJBQ7PeJiIgnaeZKROQiU9QvuWD+opuSkuKaTSjOc889R1hYGM8//3ypr3nXXXfRt29f/v3vf7st2ypPN954I6dOncLhcBQ549KyZcsyn7Nfv3788ssvblUOHQ4Hc+fOLdX7x40bx+nTp3n66acLvZaWlsb/+3//j4CAAMaMGeP22n333UdmZiZffPEFs2bNonv37rRq1cr1es+ePalRowY7d+4s8rN27twZHx+fMn/e87Fjxw62bt3q1jZnzhyCg4Pp1KkTAFdddRU7d+50LRPM8/nnn2OxWFz7aV133XVkZmZWyEbFDRo04LHHHmPAgAGF+iEiUlVo5kpE5CLz0EMPkZSUxK233krbtm2x2Wzs3r2badOmYbVaee655875/pCQEMaNG1coEJRk6tSpdOvWjVdeeYWPP/74Qj5Cke644w7+85//cP311/P444/TtWtXvL29OXz4MMuWLWPw4MHccsstZTrniy++yHfffUf//v156aWXCAgI4MMPPyx0P1Nx7rzzTjZt2sRbb73FgQMHuP/++6lbty579uxh2rRp/PXXX8yZM6fQHletWrWie/fuTJkyhUOHDvGvf/3L7fWgoCDef/997r33XhITExk6dCjh4eGcOHGCrVu3cuLECWbMmFGmz3q2vXv3sm7dukLtUVFRREVFuZ7Xq1ePm266iYkTJxIZGcns2bNZvHgxU6dOdc3WjRkzhs8//5wbbriBl19+mYYNG/Ljjz/y0Ucf8eijj7qqSN55553MnDmTRx55hD179tCvXz+cTie//fYbrVu35o477ih1/5OTk+nXrx/Dhw+nVatWBAcHs379ehYuXFglN20WEQFULVBEpKrIqxa4fv36cx73888/G/fff78RExNjhIaGGl5eXkZkZKQxZMgQY+3atW7HFqwWWFBWVpbRuHHjYqsFvvnmm0Vee9iwYYaXl5exb9++Un2m4qoFFtUnwzAMu91uvPXWW8Zll11m+Pn5GUFBQUarVq2Mhx9+2Ni7d6/ruIYNGxo33HBDoff36dPH6NOnj1vbr7/+alxxxRWGr6+vERERYTzzzDPGv/71rxKrBRa0YMEC4/rrrzdq1apleHt7G/Xr1zdGjBhh7Nixo9j35F3D39/fSE5OLvKYFStWGDfccIMRFhbmOu8NN9xgfPXVV65jihrDcympWuC4ceNcx+aN4//+9z+jTZs2ho+Pj9GoUSPjnXfeKXTegwcPGsOHD3eNQcuWLY0333zTrSqiYZhVG1966SWjefPmho+Pj1GrVi2jf//+xpo1a1zHnP19V7A/9957r2EYZlXMRx55xGjfvr0REhJi+Pv7Gy1btjQmTJjgqmIoIlLVWAzDMDyQ6URERMTDGjVqRNu2bQtt3isiIudH91yJiIiIiIiUA4UrERERERGRcqBlgSIiIiIiIuVAM1ciIiIiIiLlQOFKRERERESkHChciYiIiIiIlANtIlwEp9PJ0aNHCQ4OxmKxeLo7IiIiIiLiIYZhkJqaSr169bBazz03pXBVhKNHjxIdHe3pboiIiIiISBVx6NAhoqKiznmMwlURgoODAXMAQ0JCPNybi5fdbmfRokUMHDgQb29vT3en2tC4e4bG3TM07p6hcfcMjbtnaNw9oyqNe0pKCtHR0a6McC4KV0XIWwoYEhKicHUB7HY7AQEBhISEePw/iupE4+4ZGnfP0Lh7hsbdMzTunqFx94yqOO6luV1IBS1ERERERETKgcKViIiIiIhIOVC4EhERERERKQe65+o8GYZBTk4ODofD012psux2O15eXmRmZmqcyonNZsPLy0tbBIiIiIhUQQpX5yE7O5tjx46Rnp7u6a5UaYZhEBERwaFDhxQGylFAQACRkZH4+Ph4uisiIiIiUoDCVRk5nU5iY2Ox2WzUq1cPHx8fBYdiOJ1Ozpw5Q1BQUIkbrknJDMMgOzubEydOEBsbS/PmzTWuIiIiIlWIR8PVjBkzmDFjBgcOHACgTZs2vPTSS1x33XXY7XZefPFFFixYwP79+wkNDeXqq6/m9ddfp169esWec9asWdx3332F2jMyMvDz87vgPmdnZ+N0OomOjiYgIOCCz3cpczqdZGdn4+fnpxBQTvz9/fH29ubgwYOusRURERGRqsGj4SoqKorXX3+dZs2aAfDZZ58xePBgNm/eTFRUFJs2bWL8+PFcdtllnD59mieeeIKbbrqJDRs2nPO8ISEh7Nmzx62tvH8JVVgQT9H3noiIiEjV5NFwNWjQILfnkydPZsaMGaxbt44HHniAxYsXu73+/vvv07VrV+Li4mjQoEGx57VYLERERFRIn0VERERERIpSZe65cjgcfPXVV6SlpdG9e/cij0lOTsZisVCjRo1znuvMmTM0bNgQh8NBhw4deOWVV+jYsWOxx2dlZZGVleV6npKSApjV7ux2u9uxdrsdwzBwOp04nc5SfrrqyTAM158aq/LjdDoxDAO73Y7NZiv0et737Nnfu1KxNO6eoXH3DI27Z2jcPUPj7hlVadzL0geLkfcbsIds27aN7t27k5mZSVBQEHPmzOH6668vdFxmZiZXXnklrVq1Yvbs2cWeb926dezbt4927dqRkpLCu+++y4IFC9i6dSvNmzcv8j0TJ05k0qRJhdrnzJlT6L4qLy8vIiIiiI6OvuBqbQ6nwaZDKZxMy6Z2oA+dokOwWS+u4hg33ngj7dq1Y8qUKaU6Pi4ujssuu4yVK1fSrl27Cu7dpSk7O5tDhw4RHx9PTk6Op7sjIiIicklLT09n+PDhJCcnExIScs5jPR6usrOziYuLIykpia+//pqPP/6YFStWEBMT4zrGbrczbNgw4uLiWL58eYkfqiCn00mnTp3o3bs37733XpHHFDVzFR0dzcmTJwtdKzMzk0OHDtGoUaMLuo9r4fZ4Xv5hF/Epma62iBA/XrqxNde2Lf8ljUXNcBR0zz33MHPmzDKfNzExEW9vb4KDgwu9ZhgGqampBAcHuyoqOhwOTpw4Qe3atfHyqriJ0wMHDtC0aVPX8xo1atCuXTsmTZpEnz59AEhISOCll15i4cKFHD9+nJo1a9K+fXsmTJjgmj1t0qQJBw8e5Ndff+WKK65wnW/MmDFs3bqVpUuXAjBp0iRefvllIH9Zat++fZkyZQrR0dHl+tkyMzM5cOAA0dHRRX4P2u12Fi9ezIABA/D29i7Xa0vxNO6eoXH3DI27Z2jcPUPj7hlVadxTUlKoXbt2qcKVx5cF+vj4uApadO7cmfXr1/Puu+/yz3/+EzAH9rbbbiM2NpalS5eWKViBefN/ly5d2Lt3b7HH+Pr64uvrW6jd29u70F+mw+HAYrFgtVrPu7DAwu3HGDVnM2en2uMpmYyas5kZd3fi2raR53Xu4hw7dsz1eO7cubz00ktuRT/8/f3dPo/dbi/VN3Lt2rWLfS1vKWDeeIH593Guao/lJe96S5YsoU2bNiQkJPDCCy9w4403sn37dho3bsywYcOw2+189tlnNGnShOPHj/PLL7+QlJTkNhZ+fn6MHTuWFStWuNrywmLecRaLhTZt2rBkyRKcTid//fUXo0aN4o477mDt2rXl/tksFkuR358FlfS6VAyNu2do3D1D4+4ZGnfP0Lh7RlUY97Jcv8qVHTMMwzWLlBes9u7dy5IlS6hVq9Z5nW/Lli1ERpZvWDn7GunZOaX6Ss20M+G7HYWCFeBqm/jdTlIz7aU6X2knHiMiIlxfoaGhrtmViIgIMjMzqVGjBv/973/p27cvfn5+zJ49m1OnTnHnnXcSFRVFQEAA7dq144svvnA7b9++fXniiSdczxs1asRrr73G/fffT2hoKG3btuVf//qX6/UDBw5gsVjYsmULAMuXL8disfDLL7/QuXNnAgIC6NGjR6Fqj6+++irh4eEEBwfzt7/9jeeff54OHTqU+Llr1apFREQE7du355///Cfp6eksWrSIpKQkVq9ezdSpU+nXrx8NGzaka9eujB07lhtuuMHtHA8//DDr1q1jwYIF57xW3pLRevXq0atXLx588EHWrVvnuodPRERERC5tHp25euGFF7juuuuIjo4mNTWVL7/8kuXLl7Nw4UJycnIYOnQomzZt4ocffsDhcBAfHw9AWFiY636ne+65h/r167vu+Zk0aRJXXHEFzZs3JyUlhffee48tW7bw4YcfVtjnyLA7iHnp53I5lwHEp2TSbuKiUh2/8+VrCPApn7/G5557jrfffpuZM2fi6+tLZmYml19+Oc899xwhISH8+OOPjBgxgiZNmtCtW7diz/P222/zyiuv8Pzzz/Of//yHUaNG0bdvX1q1alXse8aNG8fbb79NnTp1eOSRR7j//vv59ddfAfjPf/7D5MmT+eijj+jZsydffvklb7/9No0bNy7T58u7f85utxMUFERQUBDffPMNV1xxRZEzl3kaNWrEI488wtixY7n22mtLNWMZHx/PvHnzsNlsJS7JFBERERFg2RSw2qDPs4VfW/EGOB3Qb2zl96sMPDpzdfz4cUaMGEHLli256qqr+O2331i4cCEDBgzg8OHDfPfddxw+fJgOHToQGRnp+lqzZo3rHHFxcW5L3pKSknjooYdo3bo1AwcO5MiRI6xcuZKuXbt64iNeVJ544gmGDBlC48aNqVevHvXr1+fpp5+mQ4cONGnShNGjR3PNNdfw1VdfnfM8119/PX//+99p1qwZTzzxBLVr12b58uXnfM/kyZPp06cPMTExPP/886xZs4bMTPN+tPfff58HHniA++67jxYtWvDSSy+VuRhGWloaY8eOxWaz0adPH7y8vJg1axafffYZNWrUoGfPnrzwwgv88ccfRb7/xRdfJDY2lv/85z/FXmPbtm0EBQUREBBAZGQky5cvZ9SoUQQGBpapryIiIiLVktUGyyabQaqgFW+Y7daq/w/WHp25+uSTT4p9rVGjRqVa8nb2L+3Tpk1j2rRpF9q1MvH3trHz5WtKdezvsYmMnLm+xONm3deFro3DSnXt8tK5c2e35w6Hg9dff525c+dy5MgRV+GPksJC+/btXY/zlh8mJCSU+j15SzgTEhJo0KABe/bs4e9//7vb8V27dnUVkziXHj16YLVaSU9PJzIyklmzZrmC2a233soNN9zAqlWrWLt2LQsXLuSNN97g448/ZuTIkW7nqVOnDk8//TQvvfQSt99+e5HXatmyJd999x1ZWVl8++23fPXVV0yePLnEPoqIiIhUe04ndH0Q0hNh2WSsJ/4kKjUM68odsGoq9BtX9IxWFePxghaXAovFUuqleb2a1yEy1I/45Mwi77uyABGhfvRqXqfSy7KfHZrefvttpk2bxvTp02nXrh2BgYE88cQTZGdnn/M8Z9/0Z7FYStznquB78opFFHxPXlue0t5rNnfuXGJiYqhRo0aR9+z5+fkxYMAABgwYwEsvvcTf/vY3JkyYUChcATz55JN89NFHfPTRR0Veq2BxljZt2rB3714effRR/u///q9UfRURERG5YFVhaZ09wwxJGYln/Xna/Dr7tbx2I/93P9v2r7gc4CAXTbAChatKZ7NamDAohkdnb8ICbgErLz5MGBRTJfa7WrVqFYMHD+buu+8GzLCzd+9eWrduXan9aNmyJb///jsjRoxwtW3YsKFU742OjnYryV6SmJgYvvnmmyJfCwoKYvz48UycOJFBgwaVeK7x48fTokULxowZQ6dOnUrdBxEREZHzlre0DtwDSd7Sun7jSn8up6P4QOQKSwUe572Wk1nyuYvjHQgBYRjJh7FgYFi9sVwkwQoUrjzi2raRzLi7E5O+38mx5AL7XIX6MWFQTLmXYT9fzZo14+uvv2bNmjXUrFmTd955h/j4+EoPV6NHj+bBBx+kc+fO9OjRg7lz5/LHH3/QpEmT8z7nqVOnGDZsGPfffz/t27cnODiYDRs28MYbbzB48OBi3/fQQw8xbdo0vvjii3MW9QBzj6zBgwfz0ksv8cMPP5x3X0VERERKLS+IFAxYy6fC8tfgilHQfAD8tbRwICoUlhIhM/n8+2H1Av+a4B8GAWHmn/41IeCsNrfXwsDLF1a8gWXZZBwWL2xOuxkML5KApXDlIde2jWRATAS/xyaSkJpJeLAfXRuHVYkZqzzjx48nNjaWa665hoCAAB566CFuvvlmkpMv4D+083DXXXexf/9+nn76aTIzM7ntttsYOXIkv//++3mfMygoiG7dujFt2jT++usv7HY70dHRPPjgg7zwwgvFvs/b25tXXnmF4cOHl+o6Tz31FD179uS3334rMYyJiIiInDenE5Lj4MQeM6BEtDcD1rIC93+v+9D8KivfkPzw4wpEZ4ekmu6v+YaA5Tx+r82dYXP0fp4fUmO4MXgntqJm4qooi1Ham1eqkZSUFEJDQ4vchTkzM5PY2FgaN26Mn5+fh3p4cXA6naSkpBASEnLeGy4XZ8CAAURERFTL+5lK+h602+0sWLCA66+/3uOb7lUnGnfP0Lh7hsbdMzTunlHlxt3pgNMHzBB1Ynf+nyf/BHv6ud9r8ykiEBUzk+QKUDXBVkmfu8DSRXuPMfnjvmZa/pJGDwSsc2WDs2nmSqq89PR0/vGPf3DNNddgs9n44osvWLJkCYsXL/Z010REREQqhiMHTsfmBqjcEJWQG6IcWUW/x+YDtZpDnZaQdhIOrASrNzjt0Otp6P/i+c0mVRanIz9A2e357XmByunwTL/KQOFKqjyLxcKCBQt49dVXycrKomXLlnz99ddcffXVnu6aiIiIyIXJyYbE/e6zUCd2w6l94CimQrOXH9RuDnVamUGqTivzq2ZjsHm5F6/o82z+cy/fqr207lxVDKtyvwtQuJIqz9/fnyVLlni6GyIiIiLnLyfLDEyuWahd5p+Jf4Ezp+j3eAdA7RZnhaiWULNR8Rvqnh2soOgiF1IhFK5ERERERAq6kL2i7Blwcm/uLNSu/NmoxP1u+zi58QlyD095M1Gh0VDW+9YLLq0r6CJaWncxU7gSERERESmo4F5RPcbktxecFcpOM+9/KjgLdWK3WWyCYurF+YbmhqfcABWeG6JC6pffvVCXwNK6i5nClYiIiIhIQQWW0Vmz0qiRFor1q3vhzx8hrCls/j/3Eudn86sB4a1zQ1Tr/DAVHFG1C0rIBVO4EhEREZHqKycLkuLg9EFIOmDOPJ0+aP7p5YttzXT6FDw+8a/8xwG13Weg8kJUYB2FqGpK4UpERERELl1OJ5yJzw9NSQfdA1TqMYpdxleAgQVL14fc740KrF3BnZeLjcKViIiIiFzcMpIKh6akg7lhKq74faHyeAdCzYZmFb4auX/WbAj7foH1/8Zh8cJm5JhhqssDFf5x5OKlcCVl0rdvXzp06MD06dMBaNSoEU888QRPPPFEse+x2WzMnz+fm2+++YKubbFYyuU8IiIiUgkupOLe2XKyIOlQ4WV7eYEqM/nc77fYIDQqPzS5AlTuV0Ctwsv4VrxhBqvez/NDagw3Bu/EplLmUgKFK08ozx82pTRo0CAyMjKK3C9q7dq19OjRg40bN9KpU6cynXf9+vUEBgaWVzcBmDhxIt988w1btmxxaz927Bg1a9Ys12udbdasWdx3332u5xEREfTq1YupU6fSuHFjADZv3sz48eP5/fffSUlJISIigm7duvHhhx9Su3ZtDhw4QOPGjalTpw5//fUXwcHBrvN16NCBm2++mYkTJwJmWF2xYgUA3t7eREdHc9tttzFx4kR8fX0r9LOKiIhUqIIV9wr+zlOw4l4e19K9IpbtJR2ElKOUuHQvsI77rFPBxyFR5ua6pVWgj84eY2DBApy9nsZmK+YzieRSuPKEsvywKScPPPAAQ4YM4eDBgzRs2NDttU8//ZQOHTqUOVgB1KlTp7y6WKKIiIhKuU5ISAh79uzBMAx2797Nww8/zE033cSWLVs4deoUV199NYMGDeLnn3+mRo0axMbG8t1335Genu52ntTUVN566y0mTZp0zus9+OCDvPzyy2RnZ7N+/XpXuJsyZUqFfUYREZEKd/bGtd0ehiWTYMMn0LQ/nDkOs4fmBqgyLN0rGJrylvHVaAC+QeXX94J7RdnthT+T9oqSYpRxVzIpkmGYex2U9qv7KOj9jPnDZumrZtvSV83nvZ8xXy/tuYySb8AEuPHGGwkPD2fWrFlu7enp6cydO5cHHniAU6dOceeddxIVFUVAQADt2rXjiy++OOd5GzVq5FoiCLB371569+6Nn58fbdu2ZdmyZYXe89xzz9GiRQsCAgJo0qQJ48ePx577g2vWrFlMmjSJrVu3YrFYsFgsrj5bLBa++eYb13m2bdtG//798ff3p1atWjz00EOcOXPG9frIkSO5+eabeeutt4iMjKRWrVqMGjXKda3iWCwWIiIiiIyMpF+/fkyYMIHt27ezb98+1qxZQ0pKCh9//DEdO3akcePG9O/fn+nTp9OgQQO384wePZp33nmHhISEc14vICCAiIgIGjRowK233sqAAQNYtGjROd8jIiJSpTmd5t5PAbUgvI35O87rDcxgBfDXUlj/MexbDKf2msHKYjODUuPe0Oke6D8ebv0E/vYLPL0PXjgCf18Lw7+E616HKx6FltdB3ZjyDVZgriAqbmaqz7PlvsJILh2auSoP9nR4rd75vXflm+ZXcc9L8sJR8Cl5WZ6Xlxf33HMPs2bN4qWXXsKSu674q6++Ijs7m7vuuov09HQuv/xynnvuOUJCQvjxxx8ZMWIETZo0oVu3biVew+l0MmTIEGrXrs26detISkri8ccfL3RccHAws2bNol69emzbto0HH3yQ4OBgnn32WW6//Xa2b9/OwoULXUsYQ0NDC50jPT2da6+9liuuuIL169eTkJDA3/72Nx577DG3ALls2TIiIyNZtmwZ+/bt4/bbb6dDhw48+OCDJX6ePP7+/gDY7XYiIiLIyclh/vz5DB061DWORbnzzjtZvHgxL7/8Mh988EGprrV161Z+/fVXGjVqVOr+iYiIeFxONhzbCnFr4OBaOLQOMk4XfWz9zkUXjyjr0j2RKkjfwdXI/fffz5tvvsny5cvp168fYC4JHDJkCDVr1qRmzZo8/fTTruNHjx7NwoUL+eqrr0oVrpYsWcKuXbs4cOAAUVFROJ1Oxo8fz7Bhw9yOe/HFF12PGzVqxFNPPcXcuXN59tln8ff3JygoCC8vr3MuA/zPf/5DRkYGn3/+ueuerw8++IBBgwYxdepU6tatC0DNmjX54IMPsNlstGrVihtuuIFffvml1OHq8OHDvPnmm0RFRdGiRQt8fHx44YUXGD58OI888ghdu3alf//+3HPPPa5r5rFYLLz++usMGjSIMWPG0LRp0yKv8dFHH/Hxxx9jt9vJzs7GarXy4Ycflqp/IiIiHpF1Bg7/bgapuLVweAPkZLgf4x0AUZ3NVTYHVoHNBxzZ0OIa3a8klyyFq/LgHWDOIJXV6mnmLFXeD5vez8CVY8p+7VJq1aoVPXr04NNPP6Vfv3789ddfrFq1yrUEzeFw8PrrrzN37lyOHDlCVlYWWVlZpS5YsWvXLho0aEBUVJSrrUuXLoWO+9///sf06dPZt28fZ86cIScnh5CQkFJ/jrxrXXbZZW5969mzJ06nkz179riCTps2bcybT3NFRkaybdu2c547OTmZoKAgDMMgPT2dTp06MW/ePHx8fACYPHkyTz75JEuXLmXdunX84x//4LXXXmPlypW0a9fO7VzXXHMNV155JePHj2fOnDlFXu+uu+5i3LhxpKSkMHXqVEJCQrj11lvLNB4iIiIV6swJM0TFrTNnp479AcZZ9x35h0GD7tCwOzToAZHtzd918u4n7/Ns/v3loIAllySFq/JgsZRqaZ6bFW+YwersHzY2nwr9YfPAAw/w2GOP8eGHHzJz5kwaNmzIVVddBcDbb7/NtGnTmD59Ou3atSMwMJAnnniC7OzsUp3bKOL+r7OXza1bt4477riDSZMmcc011xAaGsqXX37J22+/XabPYRhGsUvyCrZ7e3sXes3pdJ7z3MHBwWzatAmr1UrdunWLDJe1atVi2LBhDBs2jClTptCxY0feeustPvvss0LHvv7663Tv3p1nnnmmyOuFhobSrFkzAGbPnk2bNm345JNPeOAB7aMhIiIeYBhmhb6Da/OX+Z3aW/i40Aa5QSr3q3YLsBa4nb9goa68323OLnKhgCWXGIUrT/DgD5vbbruNxx9/nDlz5vDZZ5/x4IMPusLIqlWrGDx4MHfffTdg3kO1d+9eWrduXapzx8TEEBcXx9GjR6lXz7wHbf369W7H/PrrrzRs2JBx4/IrIh48eNDtGB8fHxyOc1fhiYmJ4bPPPiMtLc0Vfn799VesVistWrQoVX+LY7VaXWGnNHx8fGjatClpaWlFvt61a1eGDBnC888/X+K5vL29eeGFFxg7dix33nknAQGln5kUERE5L04nJOw0Z6YOrjH/TD1W+LjwmPwg1bC7uW/UOc/rcP9dJ48q7sklTOHKEzz4wyYoKIjbb7+dF154geTkZEaOHOl6rVmzZnz99desWbOGmjVr8s477xAfH1/qcHX11VfTsmVL7rnnHt5++22SkpJ49dVX3Y5p1qwZcXFxfPnll3Tp0oUff/yR+fPnux3TqFEjYmNj2bJlC1FRUQQHBxfa8+muu+5iwoQJ3HvvvUycOJETJ04wevRoRowYUejep/L0ww8/8OWXX3LHHXfQokULDMPg+++/Z8GCBcycObPY902ePJk2bdrg5VXyf3LDhw/nhRde4KOPPnK7B05ERKRc5GTB0c35QSruN8g6axNeqxfU65gbpHpAdDcICCvbdc5VUU8zVnKJUrjyBA//sHnggQf45JNPGDhwoFv58PHjxxMbG8s111xDQEAADz30EDfffDPJySXsep7LarUyf/58HnjgAbp27UqjRo147bXXGDp0qOuYwYMHM2bMGB577DGysrK44YYbGD9+vGtTXYBbb72VefPm0a9fP5KSkpg5c6ZbCASzfPnPP//M448/TpcuXQgICODWW2/lnXfeuaCxKUlMTAwBAQE89dRTHDp0CF9fX5o3b87HH3/MiBEjin1fixYtuP/++/nXv/5V4jV8fHx47LHHeOONN3jkkUcICirn8rIiIlK9ZKbAod/NJX5x68ziE2fvKeUTBFFdzCDVoDvUvxx8tHpCpKwsRlE3ylRzKSkphIaGkpycXKjQQmZmJrGxsTRu3Bg/Pz8P9fDi4HQ6SUlJISQkBKtVW6qVl5K+B+12OwsWLOD6668vdM+ZVByNu2do3D1D416Jlk0Bqw36PFt43Fe8kbsa5qx/tE09nn+vVNxaOL4djLPuNw6onV94omF3qNtOZdCLoe93z6hK436ubHA2/VckIiIiUlVZbfn3Y/coUFE47/7tvi/Aqb9y75fKLUCRuL/weWo2MoNUgyvM2alazcyCXCJSrhSuRERERKqqAgWvrA4HGK2w/vQMbJoJdVrBhk9g+WtnvckCddvmBqncAhQh9Sq96yLVkcKViIiISFViGHAmAU4fgNOx5pK+um2xrXydmwDXfNOJ3eafNh+o1yl/mV90V/Cv4ZGui1R3ClciIiIilS0nC5IOmeHp9AFIjM0PU6cPgD29yLdZAAOwNLs6v5JfvU7grfvARaoChavzpDog4in63hMRuQgYBmScNsOSW3A6aD5OPowZk4phsUJIFIQ1Mu+XSoqD/ctxWmxYDYdZGr23tusQqWoUrsoor1pJeno6/v7+Hu6NVEfp6ea/Znq6co6ISLXnyIGUw4VnnRJzQ9TZe0edzTsQwhqb4SnvK6wx1GwModHg5WMet+IN2PQ5jt7P80NqDDcG78SWV+RC+0WJVCkKV2Vks9moUaMGCQkJgLnfkkXVdorkdDrJzs4mMzNTpdjLgWEYpKenk5CQQI0aNbDZbJ7ukojIxaFAOfNCiitnnicrtZjwdACSD4Ez59zXDo7MDU6NC4Sn3OeBtUuu2JdXFbDfOJw9xsCCBTh7PW3+P0ABS6TKUbg6DxEREQCugCVFMwyDjIwM/P39FUDLUY0aNVzfgyIiUgrWYoJIXnDpPhoO/Fr0/U/pp859bpsv1GxYdICq0fDCN+J1OqDfOLPfdnt+e97ncDou7PwiUq4Urs6DxWIhMjKS8PBw7AV/0Ikbu93OypUr6d27t5awlRNvb2/NWImIlFWBcuYc+8MsS77vF0jcBxYbrH3f/CpOQK3iZ5+CI6EiV2cUN6MGmrESqYIUri6AzWbTL7rnYLPZyMnJwc/PT+FKREQqX8ZpOLAa9q+A2BVm2+7v3Y8xHGbAqhFddHiq2RD8Qiu75yJykVK4EhERkUuDPRMOrTPD1P7lcGyLuUdUHovVrOKHYS4VvOtrM0SFRoNNvxKJyIXTTxIRERG5ODkdZoDav9wMVId+g5xM92Nqt4DGfaBJHziyCVa/Y26668iGw+uhaT9P9FxELlEKVyIiInJxMAw4uddc4rd/ORxYBZlnlTsPjswNU32hcW8IrW+2r3jDDFZ5xSHyilmA7l0SkXKjcCUiIiJVV8qx/DC1fwWkHnV/3TcUGvfKn52q3aJwefMC5cxdQapgkYuCz0VELoDClYiIiFQdGUlmEYrYFWaYOrnH/XWbLzTolhum+kHkZSXfL1WwnHlBKmcuIuVM4UpEREQ8x55p3iuVNzt1dLN7EQosUK9D7jK/PtDgCvD2L9s1VM5cRCqJwpWIiIhUHqcDjm3ND1Nx6woXoajVLD9MNboSAsI80VMRkTJTuBIREZGKYxhw6i/Yv8wMVLGrIDPJ/ZigCPN+qbxAlVeEQkTkIqNwJSIiIiVbNsXcG6qoZXQr3si9ryl3+V1qfP7GvfuXQ8oR9+N9Q6BRr/xAVVQRChGpthxOg99iE9l40kKt2ES6NwvHZr04fkYoXImIiEjJrLb8yno9xuS351XiazsMFjxrBqoTu93fa/OB6G65YaofRHbQpr0iUqSF248x6fudHEvOBGx8vncDkaF+TBgUw7VtIz3dvRJZPXnxGTNm0L59e0JCQggJCaF79+789NNPrtcNw2DixInUq1cPf39/+vbty44dO0o879dff01MTAy+vr7ExMQwf/78ivwYIiIil74+z5oV95ZNxrridWql7sL2fzflBi4LbP8Kfv9nbrCymAGq5xMwYj48dxBG/gC9n4GozgpWIlKkhduP8ejsTbnBKl98ciaPzt7Ewu3HPNSz0vPoT7eoqChef/11mjVrBsBnn33G4MGD2bx5M23atOGNN97gnXfeYdasWbRo0YJXX32VAQMGsGfPHoKDg4s859q1a7n99tt55ZVXuOWWW5g/fz633XYbq1evplu3bpX58URERC5+hgFJcXB4PaSfguBIbKvf4kr3g8wiFHmb96oIhYiUkcNpMOn7nRhFvGYAFmDS9zsZEBNRpZcIejRcDRo0yO355MmTmTFjBuvWrSMmJobp06czbtw4hgwZApjhq27dusyZM4eHH364yHNOnz6dAQMGMHasue577NixrFixgunTp/PFF19U7AcSERG52GWnm+XQD/8OhzeYoerM8SIPNSxWLDd9YC73C42q5I6KyMUsx+Hk5Jlsjqdkcjwlk3X7TxWasSrIAI4lZ/J7bCLdm9aqvI6WUZWZl3c4HHz11VekpaXRvXt3YmNjiY+PZ+DAga5jfH196dOnD2vWrCk2XK1du5YxY8a4tV1zzTVMnz692GtnZWWRlZXlep6SkgKA3W7HbrdfwKeq3vLGTmNYuTTunqFx9wyN+wUyDEg6gOXweixHNmI9sh6O78BiuG+qa1i9MOq2w4jqAqnx2HZ/h8Pihc3IwXE6DmdAXdDfQYXT97tnXKzj7nAabDh4moTULMKDfencsGalzPgYhsHpdDsJqVkcT8nM/TPL7c+E1CxOnsnCWdQ0VQmOJaVht4eUf8fPoSx/9x4PV9u2baN79+5kZmYSFBTE/PnziYmJYc2aNQDUrVvX7fi6dety8ODBYs8XHx9f5Hvi4+OLfc+UKVOYNGlSofZFixYREBBQlo8jRVi8eLGnu1Atadw9Q+PuGRr30rE5MqmZvp+aaX9RM20fYen78M1JLXRchndNTgc2IzGgGacDm5IU0Ain1YcWh7+h9bHv2BU5hD8jbqZF/De0Xvk6f+79kz8jbq78D1RN6fvdMy6mcd96ysK8A1aSsvPDVA0fgyGNnFxW6zwSTa5MByRnQ3K2heRsSMmGpGwLKdmQbLfkvgYOo3QhzopBsA/U8DEfx54puRzE/h1bWHB483l/hvORnp5e6mM9Hq5atmzJli1bSEpK4uuvv+bee+9lxYoVrtctZ5VmNQyjUNvZyvqesWPH8uSTT7qep6SkEB0dzcCBAwkJqdxkfCmx2+0sXryYAQMG4O3t7enuVBsad8/QuHuGxv0cDAMS/8JyZAOWIxuwHt4AJ3ZiMZzuh9l8MCLaY9TvjBHVBaN+Z7xC6lMHqFPgOOuqt7Btnoej9/M0vOJx/ly8mIYjPsSxrgWtV75Oi+YtcPZ6ulI/YnWj73fPuNjG/ecdx5m5dmuhe5eSsy3M/NPG+3dcxjVt3CcisnKcJKRmkpA3w5Q3y5SSRUJqpmvGKS3bQWmFBXoTHuxH3WBf6ob4Eh7sS3junxEhfoQH+xIW6OOaTXM4Dfq+vZLjKVlF3ndlASJCfXns9t6Vfs9V3qq20vB4uPLx8XEVtOjcuTPr16/n3Xff5bnnngPMmajIyPyyiwkJCYVmpgqKiIgoNEtV0nt8fX3x9fUt1O7t7X1R/EdU1WkcPUPj7hkad8/QuAOZKXBkY+59Ur+b90plnC58XEgURHeBqK4Q1QVLZHssXoX/H1iIBeg3DlufZ/HOXSLj7e2Nrf9YsNmwOR3YqvvfQSXR97tnXAzj7nAaTP5pT7FFIQCen7+D5XtPkpCaTULu/U6n00u/7C3Y14u6oX7UDfGlbrAf4SF+RIT4UjfEfGwGKT98vMpWlNwbmHhTGx6dvQlLgf6C+eMHYMKgNvj5+pTpvOWhLH/vHg9XZzMMg6ysLBo3bkxERASLFy+mY8eOAGRnZ7NixQqmTp1a7Pu7d+/O4sWL3e67WrRoET169KjwvouIiFQKpxNO7YVDuSHq8HpI2AVn/0rl5WeWRI/uAlG5XyH1zu+aeRsEF6WojYVFpMI5nAYJqZkcPp3B4dPprN137qIQAGeycvjfxiOF2n29rNTNDUfmn2c/NmebAn0rLj5c2zaSGXd3KrDPlSniItrnyqPh6oUXXuC6664jOjqa1NRUvvzyS5YvX87ChQuxWCw88cQTvPbaazRv3pzmzZvz2muvERAQwPDhw13nuOeee6hfvz5TpkwB4PHHH6d3795MnTqVwYMH8+2337JkyRJWr17tqY8pIiJiWjbF3Iy3qDCy4g1wOooOMRlJcGQDHMoNUkc2QGZy4eNqNDQDVHRXcz+puu3Aq/L/lVdEyofTaZCQmsXh0+muAHUoMYPDSebzo0kZ2B1lv4fqxvaR9GlRxxWaIkL8CPH3KvHWm8pwbdtIBsREsHZfAotW/cbAXt3o3iy8SpdfL8ij4er48eOMGDGCY8eOERoaSvv27Vm4cCEDBgwA4NlnnyUjI4O///3vnD59mm7durFo0SK3Pa7i4uKwWvOnHXv06MGXX37Jiy++yPjx42natClz587VHlciIuJ5Vlvupru4B6wVb5jt/caZAevEnvylfYfWw8k9hc/l5Q/1O+XPSEV1geDil8CLSNk5nAa/xSay8aSFWrGJ5f5LvtNpcOJMwfCUwaHE/CB1NCmTbIfznOfwslqoV8OfqJr++NgsLP/zZInXvatbwypdztxmtdCtcRindhl0axx20QQr8HC4+uSTT875usViYeLEiUycOLHYY5YvX16obejQoQwdOvQCeyciIlLO8gJVwYC1ZCKsngYNe8LBX+HX9yC7cAU/ajbOnZHKDVJ124Ctat//IXIxW7j9WIHlaTY+37uByDIuT3M6DU6eyeJQblg67PZnBkdOZ5QYnmxWC/Vq+BFVI4Comv5Eh5l/RtU0/6wb4udWFOLKqUuJT848R1EIP7o21ibfFaXK3XMlIiJySes+Ck7+aQasvJAFZrDK4x1ozkoVDFOBtSu/ryLV1MLtx3h09qZCASU+OZNHZ29ixt2duLZtJIaRN/NUeNbpyOkMDidlkJ1TcniKDPVzC0zRuX9GhQVQN9gXL1vpikPYrBYmDIopoShEzEU1E3SxUbgSERGpaKf+gr2LzK8Dq8GR7f56rWa51fs6m4GqTmuw6X/RIp7gcBpM+n7nOSvuPf7lFurV2M3RpEyySghPVgtEhvq7hyfX7JM/ESF+pQ5PpXEpFIW4mOknt4iISHmzZ5ozUXsXw96fIXG/++t+oWZBCqsXOHOg/e2quCfiAYZhkJRu51DuUr1DielsOHC6xIp7WTlOYk+aG8vmhaf6Nf2LnH2KCPXDuxzDU2nkFYX4PTaRhNRMwoPNpYCasap4ClciIiLlIelQ7uzUYohdAfb0/Nes3tCwOzQfaB73+z/N4hV9ns0vZgEKWCIVICXT7lquV3DZXt7zsmyMW9Bj/Zpye5cGHglPpWGzWqp00YpLlcKViIjI+XDY4dBv8OfPZqA6scv99eBIaD7ADFSN+4BfiBmkCgYrKLrIhcglxOE0KnQGJS0rp0BwSncrHnEoMZ2UzJwSzxEe7OtarmcBvtlytMT39GxWh+iwgHL4BHIpUbgSEREprdR42LfEnKH6axlkpeS/ZrGa9021GGgGqrpt4ew9Y5wO92CVJ++58/z+BV2kqnKvuGcqa8W9TLvDDEp5VfbyZqFynyemZZd4jlqBPkSFuS/Xy7vvqX4Nf/y8ba5j88qvq+KenA+FKxERkeI4HXBkk3nf1N5FcGyr++sBtaDZAHOGqml/CCjhl62iNgjOoxkrucSUtuJedo6To0kZbvc9FQxPJ1KzSrxWqL830WH+RNUIMP+smf9nVE1/AnxK/yuvKu7JhVC4EhERKSg9Efb9YoapfUsgI9H99Xodofk15uxUvQ7mxsAi4qY0Fff+3xebCQvcwfHULIyiDiwgyNer0B5P0XnFI8L8CfEr3z3fVHFPzpfClYiIVG9OJ8T/kVvZbxEc2QBGgdLKvqHQrL8ZpppdDUHhnuurSBWVlePgUGIGcYlpHDyVzrr9p0qsuJftMIhPMWel/L1tbuHp7KV7of7eWM5eZlvB8irurd2XwKJVvzGwVze6NwvXjJWck8KViIhUP5nJsH85/LkI9i2GM8fdXw9vk3/vVFRX7TklApzJyuHgqTTiTqVz4FQ6cYlpHDiZTlxiOkeTM0qcfSrKkwNaMLxbA2oF+lR6eCoNm9VCt8ZhnNpl0E2lzKUU9H8LERG59BkGnNidXyo9bq25v1Qe70Bo0je3ut8ACI3yWFdFipJXZGHjSQu1YhMrZAbFMAwS07JdwengqfTcrzTiEtM5eebchSMCfWw0rBVIw1oBeNksfL/1WInX7NIojNpBvuX1EUQ8TuFKREQuLsummPc5FVUAYsUbuRX5xkJ2GsSuyi1GsRiSD7kfW6u5OTPVfAA07AFe+gVPqib3ins2Pt+7ocwV9/I4nQbHUjI5eCo/PBWcgTqTde6y5bUCfWhQK4CGYQGuIGV+BbrNPjmcBhsOnFbFPal2FK5EROTiYrXl7wnVY0x+e95mvM0GwP8NgQOrwVGgypjNFxr3yr93qlbTyu23yHkobcW9grJznBw+nT/rdDAx//Gh0xlk5zgpjsUCkSF+NKgVQKNagblBKj9EBZeycIQq7kl1pXAlIiIXlwKb7lpzsqmTYsE26z2zEAWY91DlCW2Qf+9Uo17gow0/5eJRmop7Y+dtY//JNFcxiQMn0zmWnIHzHPc/edssRNXMnXEKC6BBrUAa5YanqJoBbns+XQhV3JPqSOFKREQuPm1vhb9+wbbqTXoUbLd6QYPuucv9BkKdloU38hW5SKzed6LEinun0+28sXBPoXZ/b5vbkr2GBWag6tXwr7QZo7yKe7/HJpKQmkl4sLkUUDNWcqlSuBIRkYtDThbs+h42zoIDq9xeMixWLMM+M4tS+IV4pHsi58PpNIhPyWT/iTRiT57hrxNp7D9pPj6UmFGqc3RqUIMrm9V2zUA1qBVAnSDfKlN9z2a10L1pLU93Q6RSKFyJiEjVduJP2PQZbJlTYENfC4Q1gcS/cFi8sBk5ZjXAmJs82lWR4qRk2ok9kcb+k2eIPZHGXyfT2H8ijQMn08iwOy7o3M9c00rhRaSKULgSEZGqx54BO78zQ9XBX/Pbg+tBpxGQfQbWfoij9/P8kBrDjcE7seUVuSiqiqAI5j1MFbk8ze5wcigxnf15IepkmjkTdSKNk2eyin2fl9VCg7AAmtQJpEmdIJrUDqRx7UAa1grk5o9+5bgq7olcNBSuRESk6kjYBRs/g61fQGaS2WaxQvNr4PKRZpW/1e/A2g+h3zicPcbAggU4ez2NzVagiqAClpzFvZy56XzKmRuGwYkzWbnL+NLYf+JM7p/mXlA556gkUSfYl8a1A2laJ5AmtYNoXDuQJnUCiQ4LwNtmLfI9E1VxT+SionAlIiKelZ0OO78x76U69Ft+e2g0dLoHOtwFofXz250O6DfODFB2e357XqByXtgSK7n0nE858/TsHFdoygtR+0+mEXsijdRz7AXl722jce1AGtcJpGltcyYq73lIKcuYF6SKeyIXF4UrERHxjPjtZqD647+QlWy2WWzQ8jpzlqppf3NPq7P1G1v8OTVjJWcpTTnzF+Zv5/DpDA6eSmf/yTPsP5F2zip9FgtE1fR3zT41rZMfoiJC/LCW80xSXsW9tfsSWLTqNwb26kb3ZuGasRKpghSuRESk8mSnwfZ5ZqjK25cKoEYD6HQvdLwbgiM81j259Pwem1hiOfPEtGxe/XFXofYaAd40KTD7lBeiGoSV315QpWWzWujWOIxTuwy6qZS5SJWlcCUiIhXv6BazOMUfX0F2qtlm9YJWN5izVI37grXoe05EysIwDI4mZ7LtcDI7jiazZNfxUr2vfVQIPZvVyQ1T5j1RNQN9Kri3InKpUbgSEZGKkZUK2/5nzlId25LfHtbEnKXqMByCwj3VO7kEGIbB4dMZbDuSzPYjyWw7ksyOoykkpmWX+Vxjr4tROXMRuWAKVyIiUn4MA45uMiv+bfsf2NPMdqu3uQdVp3uhUS/NUkmZOZ0GcYnpZpA6aoap7UdSSM6wFzrWy2qhed1g2tUPIaZeCO//so/EtGyVMxeRCqdwJSIiFy4zGbZ9Zc5SxW/Lb6/VzFz2d9mdEFjbU72Ti4zTaRB7Ki03QOXPSKVmFq7S522z0DIimHb1Q2lTL5R29UNpGRHsdk9URIifypmLSKVQuBIRkfNjGHB4gxmodswDe7rZbvOFmMFmqGrYwyytJlIMh9Ng/4kzuUv7Uth+xLxXKi27cEl9Hy8rrSOCaVs/lLb1zSDVom4wPl7nnglVOXMRqSwKVyIiUjYZp83y6RtnQcLO/PY6rcxA1f52CNASq0uVw2nwW2wiG09aqBWbWKaS4DkOJ/tOnMktNpHCtiPJ7DyaQoa9cJDy87bSOjKEdvVDaVvPDFPN6wYVu9luSfLKmf8em0hCaibhweZSQM1YiUh5UrgSEZGSGQbErTMr/u2YDzm5//rv5QdtbjFDVXQ3zVJd4hZuP1Zg9sfG53s3EFnM7E92jpO9Camue6O2HUlm17EUsnKchc4b4GMjJjLENRvVtn4oTesE4nWeQao4NqtFRStEpEIpXImISPHSE2Hrl+Ys1ck9+e3hbXJnqYaBf01P9U4q0cLtx3h09qZCRSHikzN5dPYmnr+uFcF+3q5iE7uPpZLtKBykgny9iKmXOyNV3/yzce0gzSCJyCVB4UpEpDpaNgWsNujzbOHXlk+F0wfAaYed34Ejy2z3DoC2Q+Dy+6D+5ZqlqkYcToNJ3+8sstpeXtuUn3YXei3Yz4u29UJpF2XORrWtF0KjWoFYFaRE5BKlcCUiUh1ZbbBssvk4L2ClnYR5D8JfS92PjWhnBqp2Q8EvtHL7KR5ldzj583gq32w+4lYIojht64VwZfM6rlmpBmEBWBTCRaQaUbgSEamO8gLVssmQdBCy02HnN2DkLuPyCTLDVKd7oV5HzVJVAw6nwb6EM/xxOIltR5L543AyO4+lkF3EPVLFebB3EwZ3qF+BvRQRqdoUrkREqiN7BgRHQGA4bJ6d3x4cCX2fh7a3gm+w5/onFSpvH6lth80Qte1IEtuPFF21L9jPi4ZhAWw/mlLiecOD/SqiuyIiFw2FKxGR6iT5MKz/xCxQkZHo/prVG54qfN+MXNwMw+BQYgZbXTNSZpA6k1V4Q95AHxtt6ofSvn4o7aNr0L5+KA3CAjCAK6cuJT45s8j7riyYe0Z1bawS/CJSvSlciYhc6vLKqP/2D9j1PRi5sxOhDaB2M/MeK5sPOLJhxRtFF7mQi4JhGBxNzmTb4aTcGSlzZio5w17oWD9vK23qmaXP20eZX+eq2jdhUAyPzt6EBdwClqXA66r4JyLVncKViMilyp4J2782Q1X8H/ntjXpBt0fg+HZYPgX6jTMD1Yo3Che5kArhcBrlspltQkomfxxO5o8jyWzLnZk6eSa70HE+NiutI4NpFxVK+/o1aBcVSvPwoDLtI3Vt20hm3N2pwD5Xpohi9rkSEamOFK5ERC41KUdhw6ewYSaknzTbvPyg/W3Q9WGIaGsGqYLBCtyLXBR8LuXKfSNeU3Eb8RZ06kyWayYq7z6p4ylZhY7zslpoUTc4dzaqBu2jQmlRNxgfrwvfkPfatpEMiIlg7b4EFq36jYG9utG9WbhmrEREcilciYhcCgwDDq83Z6l2fgvO3PtpQqKg69/Mqn8BBe6HcTrcg1WevOfOwoUN5MKVtBHvjLs7cW3bSJLT7WaQOpLkKjpxJCmj0PmsFmgenjsjFWUu8WsdGYKft63CPoPNaqFb4zBO7TLodp4zbiIilyqFKxGRi1lOFuyYb4aqo5vz2xv0gCsegZY3gK2IH/X9xhZ/Ts1YVYjSbMT7xNwt1F2wi4OJhYMUQJM6gbSvH0q73BmpmMgQAn31v3IRkapCP5FFRC5GqfHmsr8Nn0Jagtlm84V2w6DbQxB5mWf7J4X8HptY4ka8mXanK1g1CAugXVQol0WF0q5+DdrUDyHEz7syuioiIudJ4UpE5GJyeKM5S7VjPjhzK8AFR0KXv8HlIyGwtke7J+5yHE52Hkth/YHTfLflSKne8/e+TXmodxNqBPhUcO9ERKS8KVyJiFR1OdnmfVS//QOObMhvj+4G3R6G1jeBTTMaVUF6dg5b4pJYf+A06w8ksinuNOnZZbt/rVfzOgpWIiIXKYUrEZGq6kyCudnv+k/gTLzZZvOBtrdC14egfiePdk/MCn4bDp5mfWwi6w+eZseRZHKc7ndVhfh50blRGJ0a1mDm6gMkpmVrI14RkUuUwpWISFVzdDP89k9zjypH7p5FQXWh8wPQ+T4ICvds/6opwzA4lJjB+gOJrq+/TqQVOi4y1I8ujcLo0jiMLo1q0iI8GGtuRb1mdYK0Ea+IyCVM4UpEpCpw2GHXd2aoOvRbfnv9zuaGvzGDwUtLxSqTw2mwOz7FNSu14UBikftKtagbZIapRmF0blSTqJoBxZ5TG/GKiFzaPBqupkyZwrx589i9ezf+/v706NGDqVOn0rJlS9cxFkvR/4L3xhtv8MwzzxT52qxZs7jvvvsKtWdkZODn51c+nRcRKQ9pJ/OX/qUeNdus3tDmFvN+qqjOHu1edZJpd7DlUBIbDiTy+4HTbDp4mjNZOW7HeNsstI+qQedGNenS0AxTZb0/Km8j3t9jE0lIzSQ82FwKqBkrEZGLn0fD1YoVKxg1ahRdunQhJyeHcePGMXDgQHbu3ElgYCAAx44dc3vPTz/9xAMPPMCtt956znOHhISwZ88etzYFKxGpMo79Yc5SbfsKHLmzIYF1oPP95ldwhGf7dxFwOA1+i01k40kLtWIT6d4svEwBJSk9mw0HTrP+YCLrYxPZdiQZu8P9bqhgXy86NaxJl0Y16dIojMuia5TLBr02q4XuTWtd8HlERKRq8Wi4WrhwodvzmTNnEh4ezsaNG+nduzcAERHuv2B8++239OvXjyZNmpzz3BaLpdB7RUQ8ypEDe340Q9XBX/PbIzvAFY+as1Vevh7r3sVk4fZjBZbW2fh87wYiS1had/h0OhsOnOb3A4lsOJDIn8fPFDomPNiXLo3D6Jq7xK9VRIhmlEREpNSq1D1XycnJAISFFV0p6fjx4/z444989tlnJZ7rzJkzNGzYEIfDQYcOHXjllVfo2LFjkcdmZWWRlZW/jj4lJQUAu92O3W4v68eQXHljpzGsXBp3zzjnuKcnYt0yG+vGT7CkmHsdGVYvjFaDcHZ5CKN+Z7BYzAoH+nsr0c87jjP6y62FKu7FJ2fy6OxNvH/HZQxoHc7ehDNsiEtiw4HTbIxLKnID3ya1A+nSqAaXN6jJ5Q1rEF3T3205utORg7NsldSrBf2c8QyNu2do3D2jKo17WfpgMQyjqIqwlc4wDAYPHszp06dZtWpVkce88cYbvP766xw9evScS/zWrVvHvn37aNeuHSkpKbz77rssWLCArVu30rx580LHT5w4kUmTJhVqnzNnDgEBxd+YLCLVW8tj8zAsVv6MuLnQay3iv8EvOwkLDqIT12AzzB/MWV7BHKjVjwO1+5Ppo5LbZeU0YNImG0nZkF9jryADLwt4WSDT6f661WIQHQhNgg2ahBg0CTYI0vZgIiJSgvT0dIYPH05ycjIhISHnPLbKhKtRo0bx448/snr1aqKiooo8plWrVgwYMID333+/TOd2Op106tSJ3r1789577xV6vaiZq+joaE6ePFniAErx7HY7ixcvZsCAAXh76zeYyqJxrzzWVW9hW/k6jt7Pk3XF4+a4X9Uf3wX/D9vOeW7HGnXb4ejyEEabW8BL93+er99iE7n70w0lHwgE+NjoGF2DyxvWoEvDmrSPCiHAp0ot2Lho6eeMZ2jcPUPj7hlVadxTUlKoXbt2qcJVlfi/zOjRo/nuu+9YuXJlscFq1apV7Nmzh7lz55b5/FarlS5durB3794iX/f19cXXt/B9Dt7e3h7/y7wUaBw9Q+NeCfqPBZsN27LJ+OZk0vR4PP7vj8aSZS5xxmKD1oOg2yNYGlyBVzHVT6V0zmTlsGzPqVId+/TAljzSpwleNmsF96p6088Zz9C4e4bG3TOqwriX5foeDVeGYTB69Gjmz5/P8uXLady4cbHHfvLJJ1x++eVcdtll53WdLVu20K5duwvprohIYZ3ugb9+wbZmOm3z2rz8zAIVnR+AGtGe7N1F7+CpNH7ZlcCyPQn8tj+RbIezVO+7vGFNBSsREal0Hg1Xo0aNYs6cOXz77bcEBwcTHx8PQGhoKP7+/q7jUlJS+Oqrr3j77beLPM8999xD/fr1mTJlCgCTJk3iiiuuoHnz5qSkpPDee++xZcsWPvzww4r/UCJSPSTuh1/fgy1z8kupA4bVhuW5A+DtX/x7pVh2h5P1BxJZtjuBX3YnsP9EmtvrDcP8OXEmm/TsoqtMWDA35O3aWPeziYhI5fNouJoxYwYAffv2dWufOXMmI0eOdD3/8ssvMQyDO++8s8jzxMXFYbXm/wtlUlISDz30EPHx8YSGhtKxY0dWrlxJ165dy/0ziEg1E78NVk+DHfPByJ1FCakPKUdwWLywOXNgzfvQ51nP9vMicvJMFsv3nGDZ7gRW/nmC1AIb93pZLXRtHEb/VuH0bxVOkzpBLNx+jEdnbwJwqxiYt+hywqAYlU8XERGP8PiywNJ46KGHeOihh4p9ffny5W7Pp02bxrRp0y6kayIi7g6ugVXvwL7F+W3NrjY3+908G0fv5/khNYYbg3diWzbZfF0Bq0iGYbDjaApLdyewdHcCWw8nUfB/B7WDfOjb0gxTVzavTYif+1r3a9tGMuPuTgX2uTJFlLDPlYiISEWrEgUtRESqJMOAP382Z6oOrTPbLFaIuRmuHAN/LoRlk6HfOJw9xsCCBTh7PY3NZjPbQQErV1pWDr/uO8nS3eb9U8dTstxeb1s/hP6t6tK/VTjt64diLWHm6dq2kQyIiWDtvgQWrfqNgb260b1ZuGasRETEoxSuRETO5siBHfPMUJWw02yz+UCH4dDj/0Gtpmbb7h+h3zgzQBXcYDAvUFXz3WfjTqWzdPdxftlduBhFgI+NK5vVpn+rcPq1CqduSNnL09usFro1DuPULoNujcMUrERExOMUrkRE8tgzYPNsWPMeJMWZbT5B0Pl+uOLvEHLWcrN+Y4s/VzWcsbI7nGw4cJple8zlfvsSzri93iAswHXvVLcmYfh62TzUUxERkYqhcCUikpkM6z+GdTMg7YTZFlDLLKfe5W/gX9Oz/avCTuUWo1i6J7cYRaZ7MYrOjWpyVau69GsVTtM6gVi015eIiFzCFK5EpPpKPQ7rPoINn0JWitkWGm0u/et4N/gEeLZ/lcDhNPg9NpGE1EzCg80S5udaXmcYBjuPpbhKpW855F6MolagD31a1uGqVnXp1aJwMQoREZFLmcKViFQ/ibHm0r/N/8nfo6pOK7NIRdtbwVY9AsHC7ccKVdyLLKLiXnp2Dr/uO2UWo9idQHxKptt52tQLcS33ax9VQ/c+iYhItaVwJSLVR/x2+HU6bP86f4+qqC5w5ZPQ4loosF/epS5vr6izN8SIT87k0dmbeOXmtjicBkt3J7B2/ymyc/KLUfh72+jZrDZXtQ6nX8twIkLLXoxCRETkUqRwJSKXvoNrzcp/e3/Ob2t6FfR6Ehr2hGp2H5DDaTDp+52FghXkb8r74jfb3dqjw/zp3zKc/q3r0q1xGH7eKkYhIiJyNoUrEbk0GQbsXWSGqri1uY0WaHMz9HwC6nXwXN887PfYRLelgMVpHRHMzR3rc1XrcJrWCVIxChERkRIoXInIpcWRAzvm5+5RtcNss/nAZXdCz8fz96iqpuKTM5m3+XCpjn2kb1MGd6hfwT0SERG5dChcicilwZ4JW2bDr+9B0kGzzScILh8J3UdBSD2Pds9TDMPgz+NnWLwznsU7j7P1cHKp3xserHupREREykLhSkQubpnJZin1tR9BWoLZFlALuj0KXR6AgDDP9s8DHE6DDQcSWbzzOIt3HefgqXTXaxYLdIgKZV9CGqlZOUW+3wJEhJpl2UVERKT0FK5E5OJ0JsHc9Hf9x/l7VIVEQY/R0GkE+AR6tn+VLCPbwcq9J1i88zi/7DrO6XS76zUfLytXNqvNwJi69G8dTniwn6taIOBW2CLvrqoJg2JUUl1ERKSMFK5E5OJy+gCseR82z4ac3KIMtVvClU9Au2HVZo8qgJNnsvhl13EW7zzOqr0nySpQLr1GgDf9W4UzMKYuvZrXIdDX/cf9tW0jmXF3p0L7XEUUsc+ViIiIlI7ClYhcHI7vgNXTc/eocpht9S8396hqeX212aNq/4kz5nK/ncfZGHcao8C0U1RNfwbGRDAgpi5dGtXEy3buMbm2bSQDYiL4PTaRhNRMwoPNpYCasRIRETk/Clci4lnLpoDVBn2eLfzaijfg9EFIPwl/Lsxvb9LP3KOqUa9Lfo8qp9Ngy+EkV6Dal3DG7fV29UMZEFOXATF1aRURXOZy6Tarhe5Na5Vnl0VERKothSsR8SyrDZZNNh/nBSzDgPkPwx9zCxxogZib4MoxUK9jpXezMmXaHaz96xSLdh5nya7jnEjNcr3mlRuGBsTU5erWdalXw9+DPRUREZGCFK5ExLPyAtWyyWA4oVYzWDg2v/Kf1Rsuu8Pc+Ld2M491s6IlpWezdHcCi3ceZ8WfJ0jPdrheC/L1om/LOgyIqUvfluGE+lef+8pEREQuJgpXIuJ5vZ6C+O2wfEp+m9Ubuj18Se9RdSgx3bXc7/cDiTic+TdQRYT4cXVMOANjIriiSS18vKrHPWUiIiIXM4UrEfEcpxN2zoflU+Hknvx2iw2e/vOi2aPK4TT4LTaRjSct1IpNpHuz8CKLQhiGwY6jKSzKDVS7jqW4vd6ybrDr/ql29UOxqrCEiIjIRUXhSkQqn9MJu7+H5a9Dwk6zzcsXcrLA5gOObHP/qqKKXFQxC7cfK1DO3MbnezcQWaCcud3h5Lf9iSzeGc/incc5WqDsudUCnRuFMTA3UDWsVb325hIREbnUKFyJSOUxDNj9oxmqjm8z23xDIfIyOLAS+o0zA9WKNwoXuaiC8jbiNc5qj0/O5JHZm+jcsCZ7jqeSmpnjes3f20bvFrUZEBNB/1bhhAX6VG6nRUREpMIoXIlIxTMMs5T68ilwbKvZ5hMMVzwKzhxY/U5+sAL3IhcFn1chDqfBpO93FgpWgKttw8HTANQK9OHq1ubs1JXNa+Pnbau0foqIiEjlUbgSkYpjGLBviRmSjm4227wD4YpHoPtj5j1Vy6a4B6s8ec+dDqqi32MTc5cCntvEQTGM6N5IG/OKiIhUAwpXIlL+DAP+WgrLXoMjG8w27wDo+hD0+H8QWGDT2n5jiz9PFZyxAvjrxBk+Xr2/VMfWDPRRsBIREakmFK5EpPwYBsSuMGejDq0z27z8ocsD5j5VQXU82r0LcSYrhwV/HOO/Gw65lvuVRniwXwX2SkRERKoShSsRKR8HVpszVQd/NZ/bfPNDVXBdj3btfBmGwYaDp/nv+kP8uO2Ya2NfqwX6tKjD5kNJJKfbi7zvygJEhPrRtfHFUU5eRERELpzClYhcmINrYflrELvSfG7zgcvvgyvHQEikZ/t2no6nZPL1psN8teEwsSfTXO2NawcyrHMUt3aKom6In6taoAXcAlbeIsAJg2K0JFBERKQaUbgSkfNz6Hdzpmr/MvO51Rs63QO9noLQ+p7t23nIznGydPdx/rvhMMv3JODMTUsBPjZuaBfJbV2i6dywJhZLfli6tm0kM+7uVGCfK1NEgX2uREREpPpQuBKRsjm80Zyp2rfEfG71go53m6GqRgPP9u087I5P4b/rD/PNliMkpmW72rs0qsmwztHc0C6SQN/if1Re2zaSATERrN2XwKJVvzGwVze6NwvXjJWIiEg1pHAlIqVzdLO5+e+fC83nFht0GA69n4aajTzatbJKzrDz3dajfLXhEH8cTna1hwf7cuvlUQy7PIomdYJKfT6b1UK3xmGc2mXQrXGYgpWIiEg1pXAlIud27A8zVO350XxusUL7O6DPMxDWxLN9KwOn02Dt/lP8d8MhFm6PJyvHCYCX1cLVretyW5coejevg5fN6uGeioiIyMVK4UpEinZ8hxmqdn1nPrdYod0w6P0s1G7m2b6VweHT6fxvo1mc4khShqu9Zd1ghnWO4paO9akV5OvBHoqIiMilQuFKRNwl7IYVr8OO+bkNFmh7K/R5Duq08GjXSivT7uDnHfF8teEwv/51EiO3OEWwnxeDO9Tjts7RtKsf6lacQkRERORCKVyJiOnEn7BiKmz/Gldh8Ziboe/zEN7akz0rFcMw2H4khf9uOMS3W46Qkpnjeq1ns1rc1jmaa9pE4Odt82AvRURE5FKmcCVS3Z36ywxV274Cw7wPidaDoM/zENHWs30rhVNnsvhmi1mcYnd8qqu9fg1/hl4exdDLo4gOC/BgD0VERKS6ULgSqa4SY2Hlm7D1SzAcZlvLG8yZqsj2nu1bCXIcTlbtPcl/Nxxiya7j2B3mTJuPl5Vr20RwW+doejSthVVV+0RERKQSKVyJVDenD5qhasuc/FDV/BroNxbqdfRYtxxOg99jE0lIzSQ82I+uRZQ0jz2ZxlcbDvH1psMcT8lytbePCmXY5VHcdFl9QgO8K7vrIiIiIoDClUj1kXQIVr0Fm2eDM/d+pGZXQ98XIOpyj3Zt4fZjTPp+J8eSM11tkaF+TBgUQ6/mdViw7RhfbTjM7wcSXa/XDPDmlo5RDOscRevIEE90W0RERMSNwpXIpWDZFLDaoM+zhV/7+UU4uBrit4PTbrY16Qf9XoDorpXbzyIs3H6MR2dvyiuh4XIsOZNHZm/C18vq2pPKaoE+LepwW+dormpdFx8v7UklIiIiVYfClcilwGqDZZPNxz3GmH+mxsPXI+HIhvzjGvUyQ1XDHpXexaI4nAaTvt9ZKFgVlJXjpGGYP7d1acCtnaKICPWrtP6JiIiIlIXClcilIG/GatlkrJkptDn8J14f3J+//K9hT+g7Fhr38lwfi/B7bKLbUsDivH5re7o3rV0JPRIRERE5fwpXIpeKbo9A7Apsa9+nWV5bSBTc/CE07gNVcMPc2JNnSnVcQmpWyQeJiIiIeJjClcjFzp4JGz6BlW9BRn7BB8PqhWXM9ioZqhLTsvn3qv18ujq2VMeHB2spoIiIiFR9ClciFyunw9yjavkUSD5ktvmHQUYiDosXNmeOWXK9qCIXHpIXqj5bc4D0bLMMvJfVQo6z6LuuLEBEqFmWXURERKSqU7gSudgYBuxZAL+8DCd2m23B9aBeB9izAEfv5/khNYYbg3diyyty4eGAVVSoals/hCeuaoHd4eTv/9kE4FbYIm++bcKgmEL7XYmIiIhURR6tYzxlyhS6dOlCcHAw4eHh3HzzzezZs8ftmJEjR2KxWNy+rrjiihLP/fXXXxMTE4Ovry8xMTHMnz+/oj6GSOU58Ct8MhC+HG4GK78aMOAV6Hi3Gbj6jcPZ62kA889+48wqgive8Eh3T53J4vWfdnPl1KXMWP4X6dkO2tYP4eN7OvP9Y1dydUxdrmsXyYy7OxWqAhgR6seMuztxbdtIj/RdREREpKw8OnO1YsUKRo0aRZcuXcjJyWHcuHEMHDiQnTt3EhgY6Dru2muvZebMma7nPj4+5zzv2rVruf3223nllVe45ZZbmD9/PrfddhurV6+mW7duFfZ5RCrMsT/Mmap9i83n3gFwxaPQ4/+Bfw1zn6t+48wZKrs9/315M1ZOR6V299SZLP69KpbP1xaeqbqqdTiWs+4Du7ZtJANiIvg9NpGE1EzCg82lgJqxEhERkYuJR8PVwoUL3Z7PnDmT8PBwNm7cSO/evV3tvr6+RERElPq806dPZ8CAAYwdOxaAsWPHsmLFCqZPn84XX3xRPp0XqQyJ+2HZa7DtK/O51Qs63WuGpuAC/030G1v8OSpxSWBZQ1VBNquF7k1rVVZXRURERMpdlbrnKjk5GYCwMPeb15cvX054eDg1atSgT58+TJ48mfDw8GLPs3btWsaMGePWds011zB9+vQij8/KyiIrK7/Uc0pKCgB2ux17wVkAKZO8sdMYnoczx7Gufhvr5s+x5O5V5WwzBEfv5yGsiXlMMePqiXE/lZbNp78eYPZvh1yhqk29YEb3a0r/lnWwWCzk5ORUWn88Qd/vnqFx9wyNu2do3D1D4+4ZVWncy9IHi2EYRZfpqmSGYTB48GBOnz7NqlWrXO1z584lKCiIhg0bEhsby/jx48nJyWHjxo34+voWeS4fHx9mzZrF8OHDXW1z5szhvvvucwtReSZOnMikSZMKtc+ZM4eAgIBy+HQipePlSKfZ8QU0PbEQL2c2AMeD27Or3lCSAxp5tnNFOGOHpUetrIq3kO00Z6WiAg2ui3LSpqZRFavAi4iIiJRJeno6w4cPJzk5mZCQkHMeW2Vmrh577DH++OMPVq9e7dZ+++23ux63bduWzp0707BhQ3788UeGDBlS7PnOXn5kGEaxS5LGjh3Lk08+6XqekpJCdHQ0AwcOLHEApXh2u53FixczYMAAvL29Pd2dqi0nE+uGT7CumY4l4zQAznqX4+w/nrCGV9KzDKeqjHF3zVRtLH6mqrrR97tnaNw9Q+PuGRp3z9C4e0ZVGve8VW2lUSXC1ejRo/nuu+9YuXIlUVFR5zw2MjKShg0bsnfv3mKPiYiIID4+3q0tISGBunXrFnm8r69vkbNg3t7eHv/LvBRoHM/BkQNbvzD3qko5YrbVbglXvYS11Q1YLyCkVMS4X8g9VdWFvt89Q+PuGRp3z9C4e4bG3TOqwriX5foeDVeGYTB69Gjmz5/P8uXLady4cYnvOXXqFIcOHSIysvjyzN27d2fx4sVu910tWrSIHj16lEu/RS6YYcCu72HpK3DyT7MtJMosTNH+DrBViX/3cFGoEhERESmZR3+DGzVqFHPmzOHbb78lODjYNdsUGhqKv78/Z86cYeLEidx6661ERkZy4MABXnjhBWrXrs0tt9ziOs8999xD/fr1mTJlCgCPP/44vXv3ZurUqQwePJhvv/2WJUuWFFpyKOIRsSthyUQ4stF87l8Tej0NXf4G3n7nfGtlKypUtasfyhNXN6d/K4UqERERkYI8Gq5mzJgBQN++fd3aZ86cyciRI7HZbGzbto3PP/+cpKQkIiMj6devH3PnziU4ONh1fFxcHFZr/n7IPXr04Msvv+TFF19k/PjxNG3alLlz52qPK/Gso1vMvar++sV87h0A3UdBj9HgF+rRrp1NoUpERESk7Dy+LPBc/P39+fnnn0s8z/Llywu1DR06lKFDh55v10TKz6m/YOmrsGOe+dzqDZ3vg97PQFDxWwp4gkKViIiIyPmrWjd2iFxKUuNhxVTY9Dk4cwALtBsG/V6AsJLvL6xMClUiIiIiF07hSqS8ZSTBr+/CuhmQk2G2NR8IV70EEe082rWznTqTxb9W7ef/1h5UqBIRERG5QApXIuXFngG//RNWT4PMJLMtqitcPREalWWnqoqXF6o+X3OQDLtClYiIiEh5ULgSuVCOHNgyG5ZPhdSjZlud1uZMVcvroBKDisNp8FtsIhtPWqgVm0j3ZuHYrPnXV6gSERERqTgKVyLnyzBg57fmXlWn9pltodHmPVXtbwerrVK7s3D7MSZ9v5NjyZmAjc/3biAy1I8Jg2Lo0ihMoUpERESkgilciZyP/cvNvaqObjafB9Qyq/91vh+8fCu9Owu3H+PR2Zs4u/7mseRMHpm9CR+blWyHE1CoEhEREakoClciZXF0sxmq9i83n/sEQffHzP2q/EI80iWH02DS9zsLBauCsh1O2tYLYcyAFgpVIiIiIhVE4Uokz7Ip5lK+Ps8Wfu2n5+CvZXByj/nc6g1dHoBeT0NQncrt51l+j03MXQp4buNuaE33prUroUciIiIi1ZPClUgeqw2WTTYf5wWslKPw5fD85X9YzPup+r0ANRt6pJtnS0gtOViZx2VVcE9EREREqjeFK5E8eYFq2WTIyTI3/l37Qe4GwECL6+Cq8VC3jef6WITwYL9yPU5EREREzo/ClUhBfZ4Fhx1WvpHfFhIFt34MDbt7rl/FMAyDfSdSz3mMBYgI9aNr47DK6ZSIiIhINaVwJVKQIwcSduY/t3rBmO2VuldVaaVl5TBu/ja+2XLU1WYBt8IWeb2eMCjGbb8rERERESl/Vk93QKTKMAxY8BTs/sF8bvUylwSufNOz/SrC3uOpDP7wV77ZchSb1cLz17Xio+GdiAh1X/oXEerHjLs7cW3bSA/1VERERKT60MyVSJ4Vb8DGWebjNrfCsE/NtrOLXHjY/M2HeWHedjLsDsKDfXn/zo50a1ILgGvaRrB2XwKLVv3GwF7d6N4sXDNWIiIiIpVE4UoEYMNMWP6a+bjFtWawAvciFwWfe0Cm3cGk73fyxe9xAPRsVot37+hI7aD8TYttVgvdGodxapdBt8ZhClYiIiIilUjhSmT3j/Djk+bjhlfC8Lnur+cFKqejcvtVwMFTafz9P5vYcTQFiwVG92/O41c1V3gSERERqUIUrqR6i1sH/7sfDCd0HAE3vV/0cR6csVq4PZ5n/reV1MwcwgJ9mH57B3q38OzGxSIiIiJSmMKVVF8Ju2HO7ZCTae5hdeP0KlUV0O5w8vpPu/lkdSwAlzesyQfDOxIZ6u/hnomIiIhIURSupHpKPgKzh0BmEkR1haGfgq3q/OdwNCmDx+ZsYlNcEgAP9mrMs9e2wtumAp8iIiIiVVXV+W1SpLJknIbZt0LKEajdwrzHyifA071yWb4ngTFzt3A63U6wnxdvDbuMa9pEeLpbIiIiIlIChSupXuwZ8MVwOLELgiPh7nkQEObpXgHgcBq8u+RP3l+2D8OANvVCmHHX5TSoVXWCn4iIiIgUT+FKqg+nA77+G8StAd9QuPtrqBHt6V4BcCI1i8e/3Myav04BcFe3Boy/MQY/b5uHeyYiIiIipaVwJdWDYcCPT8HuH8DmC3fOgbptPN0rAH7bf4rRX2wmITWLAB8bU4a0Y3CH+p7uloiIiIiUkcKVVA8r34SNMwEL3PpvaHSlp3uE02nwz5X7eWvRHhxOg+bhQcy4uxPNwoM93TUREREROQ8KV3Lp2zgLlk02H1//JsQM9mh3AJLSs3nqv1v5ZXcCAEM61ufVW9oS4KP/JEVEREQuVuVa13nTpk3ceOON5XlKkQuzewH8MMZ83PsZ6PqgZ/sDbDmUxA3vreaX3Qn4eFmZMqQdb992mYKViIiIyEWuzOFq8eLFPPPMM7zwwgvs378fgN27d3PzzTfTpUsXcnJyyr2TIucl7jf4331gOKHj3dBvnEe7YxgGn605wLB/rOFIUgYNawUw79Ee3Nm1AZYqtHmxiIiIiJyfMv1T+WeffcZ9991HWFgYiYmJfPzxx7zzzjv8/e9/59Zbb2Xr1q20bdu2ovoqUnon9sCc2yAnE1pcCze+Cx4MMKmZdp6ft40f/zgGwDVt6vLmsMsI8fP2WJ9EREREpHyVaeZq2rRpvPbaa5w8eZIvv/ySkydPMm3aNDZv3szMmTMVrKRqSD4C/zcEMpMgqgsMnQk2zy2523UshZs++JUf/ziGl9XC+Btj+MfdlytYiYiIiFxiyvQb519//cXtt98OwNChQ7HZbLzzzjs0bdq0QjonUmYZp+E/QyHlMNRqDsP/Cz6e24T3vxsOMf6b7WTlOIkM9eOD4Z24vGFNj/VHRERERCpOmcJVWloagYGBAFitVvz8/IiOrhqbsIpgz4QvhkPCTgiOhBHzICDMI13JyHYw/tvt/G/jYQD6tKjDtNs7EBbo45H+iIiIiEjFK/NaqZ9//pnQ0FAAnE4nv/zyC9u3b3c75qabbiqf3omUltMB8/4GcWvANxTu/hpqNPBIV/46cYZR/9nE7vhUrBZ4ckAL/t63GVarilaIiIiIXMrKHK7uvfdet+cPP/yw23OLxYLD4biwXomUhWHAgqdh1/dg84E750DdNh7pyg9/HOW5//1BWraD2kG+vHdHB3o0q+2RvoiIiIhI5SpTuHI6nRXVD5Hzt/It2PApYIEh/4ZGV1Z6F7JyHLz24y4+W3sQgK6Nw/jgzo6Eh/hVel9ERERExDO0a6lc3DZ+BsteNR9f/ya0ubnSu3AoMZ3H5mxi6+FkAP7etylPDmiBl61c9+gWERERkSquTOFq5cqVpTqud+/e59UZkTLZvQB+eMJ83Otp6PpgpXfhl13HefK/W0nOsBPq78202y+jf6u6ld4PEREREfG8MoWrvn37FvuaJXeDVovFQk5OzgV1SqREcb/B/+4Dwwkd74b+L1bq5XMcTt5ctId/rtgPwGXRNfhweEeianqu7LuIiIiIeFaZwtXp06eLbE9PT+fdd9/lvffeo0mTJuXSMZFindgDX9wOOZnQ/Bq48V2wVF4lvuMpmYyes5nfDyQCMLJHI164vjU+XloGKCIiIlKdlSlc5ZVgz+N0Ovn000+ZNGkSVquVDz/8sFA1QZFylXIU/m+IuVlwVBcYNgtslXfr4K/7TvL4l5s5eSabIF8vpt7anhvaR1ba9UVERESk6jrv30rnzZvHCy+8wIkTJxg7diyjR4/G19e3PPsm4i4jCWbfCimHoVZzuHMu+JT/MjyH0+D32EQSUjMJD/aja+MwLMAHy/YxbcmfGAa0igjmo7s60aROULlfX0REREQuTmUOVytWrOC5555j27ZtPP744zz33HOFZrREyp09E74cDgk7ISjC3CQ4sFa5X2bh9mNM+n4nx5IzXW3hwb7UDvJl57EUAG7vHM2kwW3w87aV+/VFRERE5OJVpnB1/fXX88svv3DffffxzTffEBERUVH9EsnndMC8v8HBX8E3xAxWNRuW+2UWbj/Go7M3YZzVnpCaRUJqFt42C1OGtGfo5VHlfm0RERERufiVKVwtXLgQLy8v5s6dy3//+99ij0tMTLzgjokAYBjw07Ow63uw+cAdcyCibblfxuE0mPT9zkLBqqAa/j7c0rF+uV9bRERERC4NZQpXM2fOrKh+iBRt1Vuw/mPAAkP+BY17Vchlfo9NdFsKWJQTZ7L4PTaR7k3LfzmiiIiIiFz8yhSuVAlQKtWmz2Hpq+bj696ANrdU2KUSUs8drMp6nIiIiIhUPxdcwzozM5O5c+eSlpbGgAEDaN68eXn0S6q7PT/B94+bj3s9Bd0eqtDLhQf7letxIiIiIlL9lClcPfPMM2RnZ/Puu+8CkJ2dTffu3dmxYwcBAQE8++yzLF68mO7du1dIZ6WaOPQ7fHUfGE7ocBf0H1/hl+zaOIzwYF8SUrOKfN0CRISaZdlFRERERIpiLcvBP/30E1dddZXr+X/+8x8OHjzI3r17OX36NMOGDePVV18t9fmmTJlCly5dCA4OJjw8nJtvvpk9e/a4Xrfb7Tz33HO0a9eOwMBA6tWrxz333MPRo0fPed5Zs2ZhsVgKfWVmaklXlXfiT5hzG+RkQPOBMOhdsFgq/LJ2hxN/n6JLq+ddfcKgGGzWiu+LiIiIiFycyhSu4uLiiImJcT1ftGgRQ4cOpWHDhlgsFh5//HE2b95c6vOtWLGCUaNGsW7dOhYvXkxOTg4DBw4kLS0NgPT0dDZt2sT48ePZtGkT8+bN488//+Smm24q8dwhISEcO3bM7cvPT0u6qrSUozB7CGSchvqdYdgssHlX+GUNw2Dc/O0cPJVOgI+NOkHum2FHhPox4+5OXNs2ssL7IiIiIiIXrzItC7RarRhGfrHqdevWMX58/pKtGjVqcPr06VKfb+HChW7PZ86cSXh4OBs3bqR3796EhoayePFit2Pef/99unbtSlxcHA0aNCj23BaLRftwXUwykmD2UEg+BLWawfD/gk9gpVx65q8H+HrTYawW+NeIznRvWovfYxNJSM0kPNhcCqgZKxEREREpSZnCVatWrfj+++958skn2bFjB3FxcfTr18/1+sGDB6lbt+55dyY5ORmAsLDi72tJTk7GYrFQo0aNc57rzJkzNGzYEIfDQYcOHXjllVfo2LFjkcdmZWWRlZV/r01KSgpgLku02+1l/BSSJ2/sShzDnExsX9yJNWEHRmA4OXf8F3xCoBLGfs1fp5i8YBcAz1/bkm6NQnE6cujcIAQIAcDpyMHpqPCulJtSj7uUK427Z2jcPUPj7hkad8/QuHtGVRr3svTBYhSciirB119/zZ133kmvXr3Yvn07Xbp04YcffnC9/txzzxEbG3vODYaLYxgGgwcP5vTp06xatarIYzIzM7nyyitp1aoVs2fPLvZc69atY9++fbRr146UlBTeffddFixYwNatW4usZjhx4kQmTZpUqH3OnDkEBASU+bNIGRhOuhz4kHpJ67Fb/VndfBwpAcXPSJank5nw9jYb6TkWutRxcldTZ2Xc3iUiIiIiF5H09HSGDx9OcnIyISEh5zy2TOEK4JdffuGHH34gMjKS0aNH4+/v73pt0qRJ9OnTh759+5a506NGjeLHH39k9erVREVFFXrdbrczbNgw4uLiWL58eYkfrCCn00mnTp3o3bs37733XqHXi5q5io6O5uTJk2W6jriz2+0sXryYAQMG4O1dxL1ThoH15+exbfwEw+aD4465GI0qZpPgs6Vl5XDbv37nz4QztK8fwpwHuuDrXXRBi4tNieMuFULj7hkad8/QuHuGxt0zNO6eUZXGPSUlhdq1a5cqXJVpWWBGRgbz5s3jm2++wW63s2XLFt577z1q164NwIQJE86rw6NHj+a7775j5cqVxQar2267jdjYWJYuXVrmwGO1WunSpQt79+4t8nVfX198fX0LtXt7e3v8L/NSUOw4rnwLNn4CWLDc8k+8mvevlP44nQbPzd/KnwlnqBPsy7/u6UJQwKVX7ETfv56hcfcMjbtnaNw9Q+PuGRp3z6gK416W65epWuBLL73ErFmzuOGGG7jzzjtZvHgxjz76aJk7mMcwDB577DHmzZvH0qVLady4caFj8oLV3r17WbJkCbVq1Tqv62zZsoXISFV7qzI2/R8sfcV8fN1UaDuk0i79/tJ9/LzjOD42K/+4+3IiQi+9YCUiIiIila9MM1fz5s3jk08+4Y477gDgrrvuomfPnjgcDmy2si+pGjVqFHPmzOHbb78lODiY+Ph4AEJDQ/H39ycnJ4ehQ4eyadMmfvjhBxwOh+uYsLAwfHx8ALjnnnuoX78+U6ZMAczliVdccQXNmzcnJSWF9957jy1btvDhhx+WuY9SAfYshO8fNx9f+SR0e7jSLr1oRzzTlvwJwKs3t+XyhjUr7doiIiIicmkrU7g6dOgQvXrl3xPTtWtXvLy8OHr0KNHR0WW++IwZMwAK3aM1c+ZMRo4cyeHDh/nuu+8A6NChg9sxy5Ytc70vLi4OqzV/Ei4pKYmHHnqI+Ph4QkND6dixIytXrqRr165l7qOUs0Pr4auRYDjgsuFw1UuVduk/j6cyZu4WAEb2aMRtXcr+PSsiIiIiUpwyhSuHw+GaLXKdwMuLnJyc87p4SbU0GjVqVOIxAMuXL3d7Pm3aNKZNm3ZefZIKdOJPmDMMcjKg2QC46T0qqzxfUno2D36+gbRsB92b1GLcDa0r5boiIiIiUn2UKVwZhsHIkSPdij9kZmbyyCOPEBiYv+HrvHnzyq+HcmlIOQazb4WM01D/crjtM7BVzs2JOQ4no7/YzMFT6dSv4c+Hd3XC21am2w1FREREREpUpnB17733Fmq7++67y60zcglYNgWsNujzbH5bZrIZrJLjwL8mDP8KfAKLP0c5m7pwN6v2nsTf28a/7+lMWKBPyW8SERERESmjMoWrmTNnVlQ/5FJhtcGyyebjHmOwOrOxfTUCEnaYbZfdCYFlr/h4vuZtOsy/V8UC8Nawy4ipp33LRERERKRilClciZQob8Zq2WSsOTl0OrgUa9J6s63zA3DtlErryh+Hk3h+3jYAHuvXjBvaqxS/iIiIiFQchSspf7kBy7ZsMvXz2jrcBTe+U2ldSEjN5KHPN5Kd4+Tq1uE8OaBFpV1bRERERKon3dUvFSNmMHl1Hg2rF9z8UaVdOivHwaOzNxGfkkmz8CCm3d4Bq7VyqhKKiIiISPWlcCXlz+mE2bdiAQwsWJw5sOKNSrm0YRhM+HYHGw+eJtjPi3+NuJxgv8qpSigiIiIi1ZuWBUr5m3s3JB/CsHqzuPVUrqqVgC2vyEXBKoIVYPa6g3y5/hBWC7x/Z0ea1Amq0OuJiIiIiORRuJLytXgC7PkRAGf/l8g4VRtnr3uw2QpUEayggLX2r1NM+n4nAM9d24q+LcMr5DoiIiIiIkVRuJLytXex+WdEe5xdHoSFi8zneYHK6aiQyx4+nc6oOZvIcRrcdFk9HurdpEKuIyIiIiJSHIUrKT9/LTX3s7JYYdC7YD3r26uCZqzSs3N46PONJKZl07Z+CFNvbY/FogIWIiIiIlK5VNBCyoc9A3540nzc9SGo36lSLmsYBs/87w92HkuhdpAP/xzRGX8fW6VcW0RERESkIIUrKR8r34LTsRBcD/q/WGmX/Wj5X/z4xzG8bRZm3H059Wv4V9q1RUREREQKUriSC5ewC36dbj6+/k3wDa6Uyy7dfZy3Fu0BYOJNbejSKKxSrisiIiIiUhSFK7kwTid8/wQ4c6DlDdD6xkq57L6EMzz+xRYMA+7q1oC7ujWslOuKiIiIiBRH4UouzObP4dA68AmC6ytno+DkDDsPfb6B1KwcujYKY8KgNpVyXRERERGRc1G4kvOXehwWv2Q+7v8ihEZV+CUdToPHv9zM/pNp1Av146O7O+HjpW9jEREREfE8/VYq5+/nFyAzGSI7mBUCK8Fbi/awfM8JfL2s/OueztQO8q2U64qIiIiIlEThSs7PviWw/X8F9rSq+PLn3245wozlfwHwxtD2tK0fWuHXFBEREREpLYUrKbvs9Pw9rbo9CvU6VPgltx9J5rmv/wDgkT5NGdyhfoVfU0RERESkLBSupOxWvgFJByEkCvq9UOGXO3kmi4f/byOZdid9W9bhmWtaVvg1RURERETKSuFKyub4Dljzvvn4+jfBN6hCL5ed4+TvszdxJCmDxrUDefeOjtislgq9poiIiIjI+VC4ktIruKdV60HQ6voKv+TLP+zg9wOJBPt68e97OhPq713h1xQREREROR8KV1J6G2fC4d/BJxiuq/g9reb8FsfsdXFYLDD9jg40C6/YWTIRERERkQuhcCWlkxoPSyaZj68aDyH1KvRy6w8kMuG77QA8PbAlV7WuW6HXExERERG5UApXUjoLx0JWMtTrBF3+VqGXOpqUwaOzN2J3GNzQLpK/921aodcTERERESkPCldSsr2LYcc8sNgqfE+rTLuDh/5vAyfPZNM6MoQ3h7XHYlEBCxERERGp+hSu5Nyy0/L3tLriUYhsX2GXMgyD57/+g+1HUqgZ4M2/RlxOgI9XhV1PRERERKQ8KVzJua2YCslxEBpd4Xta/XvVfr7ZchSb1cJHd11OdFhAhV5PRERERKQ8KVxJ8eK3wZoPzMfXvwU+gRV2qeV7Enj9p90ATBgUQ/emtSrsWiIiIiIiFUHhSormdJh7WhkOiBkMLa+tsEvFnkxj9BebcRpwe+doRlzRsMKuJSIiIiJSURSupGgbPoUjG8A3BK6dWmGXSc208+DnG0jNzKFTgxq8fHMbFbAQERERkYuSwpUUlnIMfnnZfHzVSxASWSGXcToNxszdwr6EM0SE+PGPuy/H16viKhGKiIiIiFQkhSspbOFzkJUC9TtD5/sr7DLTlvzJkl0J+HhZ+eeIywkP8auwa4mIiIiIVDSFK3G3ZyHs/LbC97RasO0Y7y/dB8CUW9pxWXSNCrmOiIiIiEhlUbiSfFlnYMHT5uMej0FE2wq5zK5jKTz1360A/O3Kxtx6eVSFXEdEREREpDIpXEm+5VMg+RDUaAB9nquQSySmZfPg5xvIsDvo1bw2z1/XqkKuIyIiIiJS2RSuxHRsK6ybYT6+4Z0K2dPK7nAy6j+bOHw6gwZhAbx/Z0e8bPoWFBEREZFLg36zldw9rR4397RqMwSaD6iQy0z+cRdr958i0MfGx/d2pkaAT4VcR0RERETEE7w83QGpAtZ/DEc3g28oXDulXE7pcBr8FpvIxpMWasUmcjgpi1lrDgDwzu0daFE3uFyuIyIiIiJSVShcVXfJR+CXV8zHV0+A4IgLPuXC7ceY9P1OjiVnAjY+37vB9doTVzfnmjYXfg0RERERkapG4aq6W/gcZKdCVFe4/L4LP932Yzw6exNGMa+3CNeMlYiIiIhcmnTPVXW2ewHs+h6sXjBoOlgv7NvB4TSY9P3OYoOVBXjlx504nMUdISIiIiJy8VK4qq6yUgvsaTUa6ra54FP+HpuYuxSwaAZwLDmT32MTL/haIiIiIiJVjcJVdbVsCqQcgRoNofez5XLKhNTig9X5HCciIiIicjFRuKqOjm6G33L3tLrxHfAJKJfThgf7letxIiIiIiIXE4+GqylTptClSxeCg4MJDw/n5ptvZs+ePW7HGIbBxIkTqVevHv7+/vTt25cdO3aUeO6vv/6amJgYfH19iYmJYf78+RX1MS4ujpzcPa2c0HYoNLu63E7dtXEYkaF+WIp53QJEhvrRtXFYuV1TRERERKSq8Gi4WrFiBaNGjWLdunUsXryYnJwcBg4cSFpamuuYN954g3feeYcPPviA9evXExERwYABA0hNTS32vGvXruX2229nxIgRbN26lREjRnDbbbfx22+/VcbHqtrW/xuObQW/8tvTKo/NamHCoJgiX8sLXBMGxWCzFhe/REREREQuXh4NVwsXLmTkyJG0adOGyy67jJkzZxIXF8fGjRsBc9Zq+vTpjBs3jiFDhtC2bVs+++wz0tPTmTNnTrHnnT59OgMGDGDs2LG0atWKsWPHctVVVzF9+vRK+mRVVPJhWPqq+XjAyxAUXu6XuLZtJK/e0rZQe0SoHzPu7sS1bSPL/ZoiIiIiIlVBldrnKjk5GYCwMHPZWGxsLPHx8QwcONB1jK+vL3369GHNmjU8/PDDRZ5n7dq1jBkzxq3tmmuuKTZcZWVlkZWV5XqekpICgN1ux263n/fnqWpsPz6NNfsMzqhuONrdCRX02dKzzPO2CA/kitAU+ne/nCua1sFmtVxS41lV5Y2xxrpyadw9Q+PuGRp3z9C4e4bG3TOq0riXpQ9VJlwZhsGTTz7JlVdeSdu25sxHfHw8AHXr1nU7tm7duhw8eLDYc8XHxxf5nrzznW3KlClMmjSpUPuiRYsICCifYg+eFpG0kW6xP+G02FgeNJjUnxZW2LXm7rABFmL8U7i8tkHy3g38vLfCLifFWLx4sae7UC1p3D1D4+4ZGnfP0Lh7hsbdM6rCuKenp5f62CoTrh577DH++OMPVq9eXeg1i8X9Hh3DMAq1Xch7xo4dy5NPPul6npKSQnR0NAMHDiQkJKS0H6HqykrF65/PAWD0eJxefR+qsEudSstmzLrlAIwa3JOd61czYMAAvL29K+ya4s5ut7N48WKNeyXTuHuGxt0zNO6eoXH3DI27Z1Slcc9b1VYaVSJcjR49mu+++46VK1cSFRXlao+IiADMmajIyPx7dRISEgrNTBUUERFRaJbqXO/x9fXF19e3ULu3t7fH/zLLxZKpkHoMajbG1vdZbBX4mVbujcdpQJt6ITSqE8JOLqFxvMho3D1D4+4ZGnfP0Lh7hsbdMzTunlEVxr0s1/doQQvDMHjssceYN28eS5cupXHjxm6vN27cmIiICLfpwOzsbFasWEGPHj2KPW/37t0LTSEuWrTonO+5ZB3ZCL/903x84zvg7V+hl1u4wwy117SJqNDriIiIiIhUNR6duRo1ahRz5szh22+/JTg42DXbFBoair+/PxaLhSeeeILXXnuN5s2b07x5c1577TUCAgIYPny46zz33HMP9evXZ8oUs7T4448/Tu/evZk6dSqDBw/m22+/ZcmSJUUuObyk5e1phQHtboOm/Sv0cmeycli99yQA17ZVuBIRERGR6sWj4WrGjBkA9O3b16195syZjBw5EoBnn32WjIwM/v73v3P69Gm6devGokWLCA4Odh0fFxeH1Zo/CdejRw++/PJLXnzxRcaPH0/Tpk2ZO3cu3bp1q/DPVKX89g+I3wZ+NeCa1yr8csv3JJDtcNK4diDNw4PIycmp8GuKiIiIiFQVHg1XhmGUeIzFYmHixIlMnDix2GOWL19eqG3o0KEMHTr0Anp3kUuKg2WTzccDX4GgOhV+yYXbzZnHgW3qllhwRERERETkUuPRe66kghgGLHgG7OnQoAd0uLvCL5mV42D5nhOA7rcSERERkepJ4epStOs7+HMhWL1h0HSwVvxf85p9pziTlUPdEF86RNWo8OuJiIiIiFQ1CleXmsxkWPCs+fjKMVCnZaVc9ufcKoEDYyKwWrUkUERERESqH4WrS80vr8CZeAhrCr2eqpRLOpwGi3ceB7QkUERERESqL4WrS8nhDbD+Y/PxjdPA2+//t3en0VGUed/Hf5WFzkIIJCEbAoIEY0ADCgrIDWQUCPqgKAwICogvGO9BBJzxRkc5wqgg+CiojPjgcRmPMnA4MyCOSAjcENwQhQmyLxoFZQnIko2EJF3Pi5hIzAJqp6/u6u/nnBy6qrq7/v0nkvy8rrrKK6f94ptT+qH4vKLDQ3VDxxivnBMAAADwNYQrp6gs/+meVumjpY79vXbqrF1Vo1Y3XRWv0GC+pQAAABCY+E3YKTYvko7vlMJbSYOe8tppbduuud6KKYEAAAAIZIQrJzj9rbRxTtXjQU9JkXFeO/WuIwX6/sw5hYUGqV9K099LCwAAAPBVhCt/Z9vS6j9X3dOqfV+p291ePX31qNWAzvEKbxbs1XMDAAAAvoRw5e92r5QOrJWCm1UtYmF5dxn0mimBXRO8el4AAADA1xCu/Nm5M9IH06se931Iat3Zq6f/+kSR9h8vUkiQpd9dSbgCAABAYCNc+bP1f5WKjkuxnaT/esjrp69eJbD3FbGKjgj1+vkBAAAAX0K48leHt0hfvF71+P8skEJcXi+BVQIBAACAnxCu/NGF97TqdrfU4b+8XsKxs6XKPXxGliUNSmNKIAAAAEC48kefLpTyd0sRsV69p9WF1u6uGrXq3ral4luEGakBAAAA8CWEK39zKk/aOLfq8aCnpYgYI2VUTwnM7MqUQAAAAEAiXPkX25be/5NUcU7q0E9Kv8tIGaeLz2vz16ckcb0VAAAAUI1w5U92/lP6ar0U7JJu9f49raqt35uvSret1MQotY+NNFIDAAAA4GsIV/7i3GlpzaNVj/v9WYrrZKwUVgkEAAAA6iJc+aoNc6SceT9tr5spFedLcZ0ld0XVcQNKzldo0/4TkghXAAAAwIUIV74qKFja8HRVwDq0Wdr6ZtX+ttdLOXOrjhuQs++EyircahsTrquSoozUAAAAAPiiENMFoAH9/6fqzw1PS5/9v6rHSenSf96WMh776biX1UwJTEuUZeiaLwAAAMAXMXLly/r/j9Shv1Rysmr76Hajwep8hVvr9+ZLYgl2AAAA4OcIV76u44CfHgc3MxasJOnTr39QYWmF4pq7dG27VsbqAAAAAHwR4crXuSuq/gxuJlWer73IhZdVTwkcmJagoCCmBAIAAAAXIlz5spx5VddcZTwmzThR9Wf1Ihde5nbbyt59XBJTAgEAAID6sKCFr7owWFVPBbxwkYsLt73gP4dP60RhmaLCQtS7Y6zXzgsAAAD4C8KVr3JX1r94RfW2u9Kr5azZWTUl8Hep8WoWwoAnAAAA8HOEK1+V8WjDx7y8qIVt28raVTUlkBsHAwAAAPVjCAIXtfdYoQ6dKpErJEj9O7c2XQ4AAADgkwhXuKjqKYH/ldJakS4GOwEAAID6EK5wUdVLsA/ukmC4EgAAAMB3Ea7QqEM/lGjvsUIFB1m6+SrCFQAAANAQwhUaVT1qdUOHGLWKbGa4GgAAAMB3Ea7QqDU1UwJZJRAAAABoDOEKDcovLNW2Q6clSYO43goAAABoFOEKDcrefVy2LaW3bamk6HDT5QAAAAA+jXCFBlUvwc4qgQAAAMDFEa5Qr7PnyvXpVz9I4norAAAA4FIQrlCvDXvzVeG2lRLfXFe0bm66HAAAAMDnEa5Qr5+mBDJqBQAAAFwKwhXqKC2vVM7+E5IIVwAAAMClIlyhjk37T+hceaXatAxX1zYtTJcDAAAA+AXCFerI2nVcUtW9rSzLMlwNAAAA4B8IV6ilvNKtdXuqwhVTAgEAAIBLR7hCLVvyTunsuXLFRDZTz8tjTJcDAAAA+A2j4WrTpk0aOnSokpOTZVmWVq5cWeu4ZVn1fj377LMNvuebb75Z72tKS0ub+NM4Q9auqlUCB16VoOAgpgQCAAAAl8pouCouLlZ6eroWLlxY7/GjR4/W+nr99ddlWZaGDx/e6Pu2aNGizmvDwsKa4iM4ittt14SrwV0TDFcDAAAA+JcQkycfMmSIhgwZ0uDxxMTa1/y8++67ysjIUMeOHRt9X8uy6rwWF7f9uzM6XlCmyGbB6nNFnOlyAAAAAL9iNFz9EsePH9f777+vv//97xd9blFRkdq3b6/Kykp169ZNTz75pLp3797g88vKylRWVlazXVBQIEkqLy9XeXn5by/eT3yw44gkqX/nOAXLrfJy9296v+reBVIPfQF9N4O+m0HfzaDvZtB3M+i7Gb7U919Sg2Xbtt2EtVwyy7K0YsUKDRs2rN7j8+bN0zPPPKMjR440OsVv8+bNOnjwoK6++moVFBTohRde0OrVq7V9+3alpKTU+5qZM2dq1qxZdfYvWbJEERERv+rz+Bvblp7ODdaJUkvjUyp1bZxPfFsAAAAARpWUlGjMmDE6e/asWrRo/B6wfhOuUlNTNXDgQL300ku/6H3dbreuvfZa9evXTy+++GK9z6lv5Kpt27Y6efLkRRvoFAeOF+mWhZ8oNNjSZ49kKCrstw9qlpeXKzs7WwMHDlRoaKgHqsSloO9m0Hcz6LsZ9N0M+m4GfTfDl/peUFCguLi4SwpXfjEt8MMPP9S+ffu0bNmyX/zaoKAg9ezZUwcOHGjwOS6XSy6Xq87+0NBQ43+Z3rJ+30lJUt9OcYqJCvfoewdSH30JfTeDvptB382g72bQdzPouxm+0Pdfcn6/uM/Va6+9puuuu07p6em/+LW2bSs3N1dJSUlNUJlzZO2uWiUwsysLgQAAAAC/htGRq6KiIh08eLBmOy8vT7m5uYqJiVG7du0kVQ3DLV++XM8991y97zFu3Di1adNGc+bMkSTNmjVLvXr1UkpKigoKCvTiiy8qNzdXf/vb35r+A/mpw6dKtPP7AgVZ0s1XsQQ7AAAA8GsYDVdffPGFMjIyarYfeughSdL48eP15ptvSpKWLl0q27Y1evToet/j0KFDCgr6aQDuzJkzmjhxoo4dO6bo6Gh1795dmzZt0vXXX990H8TPrd19XJLU4/IYxTavOz0SAAAAwMUZDVcDBgzQxdbTmDhxoiZOnNjg8Y0bN9banj9/vubPn++J8gJGzY2DuzAlEAAAAPi1/OKaKzSdk0Vl+uKbU5KkwV2YEggAAAD8WoSrALdu93G5balrmxa6rFVg3NMLAAAAaAqEqwBXMyUwjSmBAAAAwG9BuApghaXl+vjgD5JYgh0AAAD4rQhXAWzDvhM6X+lWx7hIdYpvbrocAAAAwK8RrgJY9ZTAQV0SZVmW4WoAAAAA/0a4ClCl5ZXauDdfEqsEAgAAAJ5AuApQn3x1UsXnK5XYIkzpl7U0XQ4AAADg9whXAWrNzuopgQkKCmJKIAAAAPBbEa4CUEWlW+v2VE8JZJVAAAAAwBMIVwHoi29P61TxebWMCNX1HWJMlwMAAAA4AuEqAFVPCbwpNUGhwXwLAAAAAJ7Ab9YBxrZtZe8+LolVAgEAAABPIlwFmJ3fF+j7M+cUHhqsfp1bmy4HAAAAcAzCVYBZs+uoJGnAla0VFhpsuBoAAADAOQhXASZrV/WUQFYJBAAAADyJcBVAvjpRpIP5RQoJspSRGm+6HAAAAMBRCFcBJGtX1SqBfTrFKTo81HA1AAAAgLMQrgJI1o9LsLNKIAAAAOB5hKsAcfTsOW3/7qwsSxqYRrgCAAAAPI1wFSDW/riQxbXtWik+KsxwNQAAAIDzEK4CxJofpwRmskogAAAA0CQIVwHgdPF5bfnmlCSWYAcAAACaCuEqAKzbc1yVblupiVFqFxthuhwAAADAkQhXAaD6xsGZXRm1AgAAAJoK4crhissqtOnACUlMCQQAAACaEuHK4XL2n9D5CrfaxUQoNTHKdDkAAACAYxGuHC5r1083DrYsy3A1AAAAgHMRrhzsfIVb/7snXxLXWwEAAABNjXDlYJ98dVKFZRVqHeVS97atTJcDAAAAOBrhysGqVwkcmJagoCCmBAIAAABNiXDlUJVuW9m7f1yCnVUCAQAAgCZHuHKobYdO62RRmaLCQtSrY6zpcgAAAADHI1w5VNbOqlUCb0qNV7MQ/poBAACApsZv3Q5k27aydlcvwc6UQAAAAMAbCFcOtPtogQ6fOidXSJD6X9nadDkAAABAQCBcOVD1KoH9OrdWRLMQw9UAAAAAgYFw5UBrdzElEAAAAPA2wpXDfHOyWHuPFSo4yNLNV8WbLgcAAAAIGIQrh8n6cdSqV8cYtYxoZrgaAAAAIHAQrhwmiymBAAAAgBGEKwfJLyjVtkNnJEmD0ghXAAAAgDcRrhwka3fVKoHd2rZUYnSY4WoAAACAwEK4chBWCQQAAADMIVw5xNmScn361Q+SpMFdEgxXAwAAAAQewpVDrN97XBVuW50Tmqtj6+amywEAAAACjtFwtWnTJg0dOlTJycmyLEsrV66sdfzee++VZVm1vnr16nXR9/3nP/+ptLQ0uVwupaWlacWKFU30CXwHqwQCAAAAZhkNV8XFxUpPT9fChQsbfE5mZqaOHj1a87V69epG3/PTTz/VqFGjNHbsWG3fvl1jx47VyJEj9dlnn3m6fJ9x7nylcvafkES4AgAAAEwJMXnyIUOGaMiQIY0+x+VyKTHx0gPDggULNHDgQD366KOSpEcffVQ5OTlasGCB/vGPf/ymen3VpgMnVFruVpuW4eqS3MJ0OQAAAEBAMhquLsXGjRsVHx+vli1bqn///nr66acVHx/f4PM//fRTTZs2rda+wYMHa8GCBQ2+pqysTGVlZTXbBQUFkqTy8nKVl5f/tg/gBR98eUSSNPCq1qqoqDBczU+qe+cPPXQS+m4GfTeDvptB382g72bQdzN8qe+/pAbLtm27CWu5ZJZlacWKFRo2bFjNvmXLlql58+Zq37698vLyNGPGDFVUVGjr1q1yuVz1vk+zZs305ptvasyYMTX7lixZogkTJtQKUBeaOXOmZs2aVWf/kiVLFBER8ds+WBOrdEuPfRGsc5WWJnepUCcGrgAAAACPKSkp0ZgxY3T27Fm1aNH4L9s+PXI1atSomsddu3ZVjx491L59e73//vu68847G3ydZVm1tm3brrPvQo8++qgeeuihmu2CggK1bdtWgwYNumgDTfv4qx907rOtiokM1aSRAxUc1PDn9Lby8nJlZ2dr4MCBCg0NNV1OwKDvZtB3M+i7GfTdDPpuBn03w5f6Xj2r7VL4dLj6uaSkJLVv314HDhxo8DmJiYk6duxYrX35+flKSGj43k8ul6vekbDQ0FDjf5kXs25v1UIWg9ISFeZqZria+vlDH52IvptB382g72bQdzPouxn03Qxf6PsvOb9f3efqhx9+0OHDh5WUlNTgc3r37q3s7Oxa+9auXas+ffo0dXle53bbWrvruCRWCQQAAABMMzpyVVRUpIMHD9Zs5+XlKTc3VzExMYqJidHMmTM1fPhwJSUl6ZtvvtFf/vIXxcXF6Y477qh5zbhx49SmTRvNmTNHkjRlyhT169dPc+fO1e233653331X69at00cffeT1z9fUcr87o/zCMjV3hahPp1jT5QAAAAABzWi4+uKLL5SRkVGzXX3d0/jx47Vo0SLt2LFDb731ls6cOaOkpCRlZGRo2bJlioqKqnnNoUOHFBT00wBcnz59tHTpUj3++OOaMWOGrrjiCi1btkw33HCD9z6Yl1TfOHjAla3lCgk2XA0AAAAQ2IyGqwEDBqixxQqzsrIu+h4bN26ss2/EiBEaMWLEbynN59m2raydVeEqsytTAgEAAADT/OqaK/xk//EiffNDiZqFBGnAlQ3f9wsAAACAdxCu/FT1lMC+neLU3OVXiz4CAAAAjkS48lNrqqcEskogAAAA4BMIV37o8KkS7T5aoCBLuukqpgQCAAAAvoBw5YeqpwT2vDxGsc3r3vwYAAAAgPcRrvwQNw4GAAAAfA/hys+cKCzT59+ekiQNZgl2AAAAwGcQrvzMuj3HZdvS1W2i1aZluOlyAAAAAPyIcOVnqq+3GtwlwXAlAAAAAC5EuPIjBaXl+vjgSUlSJlMCAQAAAJ9CuPIjG/bmq7zSVsfWkeoUH2W6HAAAAAAXIFz5EVYJBAAAAHwX4cpPlJZXasO+fEmEKwAAAMAXEa78xEcHTqrkfKWSosN0TZto0+UAAAAA+BnClZ+oXiVwUFqCgoIsw9UAAAAA+DnClR+oqHRr3R6utwIAAAB8GeHKx1W6bb35yTc6XVKuSFewrmvfynRJAAAAAOpBuPJha3YeVd+5/6un3t8jSSouq9SA/7tRa3YeNVwZAAAAgJ8jXPmoNTuP6r/f3qajZ0tr7T92tlT//fY2AhYAAADgYwhXPqjSbWvWe7tl13Oset+s93ar0l3fMwAAAACYQLjyQVvyTtUZsbqQLeno2VJtyTvlvaIAAAAANIpw5YPyCxsOVr/meQAAAACaHuHKB8VHhXn0eQAAAACaHuHKB13fIUZJ0WFq6FbBlqSk6DBd3yHGm2UBAAAAaAThygcFB1l6YmiaJNUJWNXbTwxNU3BQQ/ELAAAAgLcRrnxUZtckLbrnWiVG1576lxgdpkX3XKvMrkmGKgMAAABQnxDTBaBhmV2TNDAtUVvyTim/sFTxUVVTARmxAgAAAHwP4crHBQdZ6n1FrOkyAAAAAFwE0wIBAAAAwAMIVwAAAADgAYQrAAAAAPAAwhUAAAAAeADhCgAAAAA8gHAFAAAAAB5AuAIAAAAADyBcAQAAAIAHEK4AAAAAwAMIVwAAAADgAYQrAAAAAPAAwhUAAAAAeADhCgAAAAA8IMR0Ab7Itm1JUkFBgeFK/Ft5eblKSkpUUFCg0NBQ0+UEDPpuBn03g76bQd/NoO9m0HczfKnv1ZmgOiM0hnBVj8LCQklS27ZtDVcCAAAAwBcUFhYqOjq60edY9qVEsADjdrt15MgRRUVFybIs0+X4rYKCArVt21aHDx9WixYtTJcTMOi7GfTdDPpuBn03g76bQd/N8KW+27atwsJCJScnKyio8auqGLmqR1BQkC677DLTZThGixYtjP9HEYjouxn03Qz6bgZ9N4O+m0HfzfCVvl9sxKoaC1oAAAAAgAcQrgAAAADAAwhXaDIul0tPPPGEXC6X6VICCn03g76bQd/NoO9m0Hcz6LsZ/tp3FrQAAAAAAA9g5AoAAAAAPIBwBQAAAAAeQLgCAAAAAA8gXAEAAACABxCu4HFz5sxRz549FRUVpfj4eA0bNkz79u0zXVbAmTNnjizL0tSpU02X4njff/+97rnnHsXGxioiIkLdunXT1q1bTZflaBUVFXr88cfVoUMHhYeHq2PHjvrrX/8qt9ttujRH2bRpk4YOHark5GRZlqWVK1fWOm7btmbOnKnk5GSFh4drwIAB2rVrl5liHaSxvpeXl2v69Om6+uqrFRkZqeTkZI0bN05HjhwxV7BDXOz7/UJ/+MMfZFmWFixY4LX6nOpS+r5nzx7ddtttio6OVlRUlHr16qVDhw55v9hLQLiCx+Xk5GjSpEnavHmzsrOzVVFRoUGDBqm4uNh0aQHj888/1+LFi3XNNdeYLsXxTp8+rRtvvFGhoaH64IMPtHv3bj333HNq2bKl6dIcbe7cuXrllVe0cOFC7dmzR/PmzdOzzz6rl156yXRpjlJcXKz09HQtXLiw3uPz5s3T888/r4ULF+rzzz9XYmKiBg4cqMLCQi9X6iyN9b2kpETbtm3TjBkztG3bNv3rX//S/v37ddtttxmo1Fku9v1ebeXKlfrss8+UnJzspcqc7WJ9/+qrr9S3b1+lpqZq48aN2r59u2bMmKGwsDAvV3qJbKCJ5efn25LsnJwc06UEhMLCQjslJcXOzs62+/fvb0+ZMsV0SY42ffp0u2/fvqbLCDi33nqrfd9999Xad+edd9r33HOPoYqcT5K9YsWKmm23220nJibazzzzTM2+0tJSOzo62n7llVcMVOhMP+97fbZs2WJLsr/99lvvFBUAGur7d999Z7dp08beuXOn3b59e3v+/Pler83J6uv7qFGj/Orfdkau0OTOnj0rSYqJiTFcSWCYNGmSbr31Vt18882mSwkIq1atUo8ePfT73/9e8fHx6t69u1599VXTZTle3759tX79eu3fv1+StH37dn300Ue65ZZbDFcWOPLy8nTs2DENGjSoZp/L5VL//v31ySefGKws8Jw9e1aWZTFi3sTcbrfGjh2rhx9+WF26dDFdTkBwu916//331blzZw0ePFjx8fG64YYbGp2yaRrhCk3Ktm099NBD6tu3r7p27Wq6HMdbunSptm3bpjlz5pguJWB8/fXXWrRokVJSUpSVlaX7779fDz74oN566y3TpTna9OnTNXr0aKWmpio0NFTdu3fX1KlTNXr0aNOlBYxjx45JkhISEmrtT0hIqDmGpldaWqpHHnlEY8aMUYsWLUyX42hz585VSEiIHnzwQdOlBIz8/HwVFRXpmWeeUWZmptauXas77rhDd955p3JyckyXV68Q0wXA2R544AF9+eWX+uijj0yX4niHDx/WlClTtHbtWt+dh+xAbrdbPXr00OzZsyVJ3bt3165du7Ro0SKNGzfOcHXOtWzZMr399ttasmSJunTpotzcXE2dOlXJyckaP3686fICimVZtbZt266zD02jvLxcd911l9xut15++WXT5Tja1q1b9cILL2jbtm18f3tR9SJFt99+u6ZNmyZJ6tatmz755BO98sor6t+/v8ny6sXIFZrM5MmTtWrVKm3YsEGXXXaZ6XIcb+vWrcrPz9d1112nkJAQhYSEKCcnRy+++KJCQkJUWVlpukRHSkpKUlpaWq19V111lc+uYuQUDz/8sB555BHddddduvrqqzV27FhNmzaNUVsvSkxMlKQ6o1T5+fl1RrPgeeXl5Ro5cqTy8vKUnZ3NqFUT+/DDD5Wfn6927drV/Iz99ttv9ac//UmXX3656fIcKy4uTiEhIX71c5aRK3icbduaPHmyVqxYoY0bN6pDhw6mSwoIN910k3bs2FFr34QJE5Samqrp06crODjYUGXOduONN9a51cD+/fvVvn17QxUFhpKSEgUF1f7/g8HBwSzF7kUdOnRQYmKisrOz1b17d0nS+fPnlZOTo7lz5xquztmqg9WBAwe0YcMGxcbGmi7J8caOHVvnWubBgwdr7NixmjBhgqGqnK9Zs2bq2bOnX/2cJVzB4yZNmqQlS5bo3XffVVRUVM3/1YyOjlZ4eLjh6pwrKiqqznVtkZGRio2N5Xq3JjRt2jT16dNHs2fP1siRI7VlyxYtXrxYixcvNl2aow0dOlRPP/202rVrpy5duug///mPnn/+ed13332mS3OUoqIiHTx4sGY7Ly9Pubm5iomJUbt27TR16lTNnj1bKSkpSklJ0ezZsxUREaExY8YYrNr/Ndb35ORkjRgxQtu2bdO///1vVVZW1vycjYmJUbNmzUyV7fcu9v3+8xAbGhqqxMREXXnlld4u1VEu1veHH35Yo0aNUr9+/ZSRkaE1a9bovffe08aNG80V3RjDqxXCgSTV+/XGG2+YLi3gsBS7d7z33nt2165dbZfLZaemptqLFy82XZLjFRQU2FOmTLHbtWtnh4WF2R07drQfe+wxu6yszHRpjrJhw4Z6/z0fP368bdtVy7E/8cQTdmJiou1yuex+/frZO3bsMFu0AzTW97y8vAZ/zm7YsMF06X7tYt/vP8dS7J5xKX1/7bXX7E6dOtlhYWF2enq6vXLlSnMFX4Rl27bd9BEOAAAAAJyNBS0AAAAAwAMIVwAAAADgAYQrAAAAAPAAwhUAAAAAeADhCgAAAAA8gHAFAAAAAB5AuAIAAAAADyBcAQAAAIAHEK4AAPAwy7K0cuVK02UAALyMcAUAcJR7771XlmXV+crMzDRdGgDA4UJMFwAAgKdlZmbqjTfeqLXP5XIZqgYAECgYuQIAOI7L5VJiYmKtr1atWkmqmrK3aNEiDRkyROHh4erQoYOWL19e6/U7duzQ7373O4WHhys2NlYTJ05UUVFRree8/vrr6tKli1wul5KSkvTAAw/UOn7y5EndcccdioiIUEpKilatWtW0HxoAYBzhCgAQcGbMmKHhw4dr+/btuueeezR69Gjt2bNHklRSUqLMzEy1atVKn3/+uZYvX65169bVCk+LFi3SpEmTNHHiRO3YsUOrVq1Sp06dap1j1qxZGjlypL788kvdcsstuvvuu3Xq1Cmvfk4AgHdZtm3bposAAMBT7r33Xr399tsKCwurtX/69OmaMWOGLMvS/fffr0WLFtUc69Wrl6699lq9/PLLevXVVzV9+nQdPnxYkZGRkqTVq1dr6NChOnLkiBISEtSmTRtNmDBBTz31VL01WJalxx9/XE8++aQkqbi4WFFRUVq9ejXXfgGAg3HNFQDAcTIyMmqFJ0mKiYmpedy7d+9ax3r37q3c3FxJ0p49e5Senl4TrCTpxhtvlNvt1r59+2RZlo4cOaKbbrqp0RquueaamseRkZGKiopSfn7+r/1IAAA/QLgCADhOZGRknWl6F2NZliTJtu2ax/U9Jzw8/JLeLzQ0tM5r3W73L6oJAOBfuOYKABBwNm/eXGc7NTVVkpSWlqbc3FwVFxfXHP/4448VFBSkzp07KyoqSpdffrnWr1/v1ZoBAL6PkSsAgOOUlZXp2LFjtfaFhIQoLi5OkrR8+XL16NFDffv21TvvvKMtW7botddekyTdfffdeuKJJzR+/HjNnDlTJ06c0OTJkzV27FglJCRIkmbOnKn7779f8fHxGjJkiAoLC/Xxxx9r8uTJ3v2gAACfQrgCADjOmjVrlJSUVGvflVdeqb1790qqWslv6dKl+uMf/6jExES98847SktLkyRFREQoKytLU6ZMUc+ePRUREaHhw4fr+eefr3mv8ePHq7S0VPPnz9ef//xnxcXFacSIEd77gAAAn8RqgQCAgGJZllasWKFhw4aZLgUA4DBccwUAAAAAHkC4AgAAAAAP4JorAEBAYTY8AKCpMHIFAAAAAB5AuAIAAAAADyBcAQAAAIAHEK4AAAAAwAMIVwAAAADgAYQrAAAAAPAAwhUAAAAAeADhCgAAAAA84P8DceLO8qW6rTsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:20.669695Z",
     "iopub.status.busy": "2025-05-08T17:29:20.669695Z",
     "iopub.status.idle": "2025-05-08T17:29:24.035255Z",
     "shell.execute_reply": "2025-05-08T17:29:24.035255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 101/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 201/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 301/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 401/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed batch 501/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:24.038260Z",
     "iopub.status.busy": "2025-05-08T17:29:24.037260Z",
     "iopub.status.idle": "2025-05-08T17:29:24.043204Z",
     "shell.execute_reply": "2025-05-08T17:29:24.043204Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:24.045213Z",
     "iopub.status.busy": "2025-05-08T17:29:24.045213Z",
     "iopub.status.idle": "2025-05-08T17:29:34.068133Z",
     "shell.execute_reply": "2025-05-08T17:29:34.068133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n",
      "Epoch [1/1000] completed, Average Training Loss: 2.1983\n",
      "    Validation Batch [1/1], Loss: 2.2004\n",
      "Validation Loss: 2.2004, Validation Accuracy: 11.11%\n",
      "Validation loss improved from inf to 2.2004. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.1509\n",
      "    Validation Batch [1/1], Loss: 2.2003\n",
      "Validation Loss: 2.2003, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2004 to 2.2003. Saving model...\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.1170\n",
      "    Validation Batch [1/1], Loss: 2.2003\n",
      "Validation Loss: 2.2003, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2003 to 2.2003. Saving model...\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.0909\n",
      "    Validation Batch [1/1], Loss: 2.2002\n",
      "Validation Loss: 2.2002, Validation Accuracy: 13.33%\n",
      "Validation loss improved from 2.2003 to 2.2002. Saving model...\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.0591\n",
      "    Validation Batch [1/1], Loss: 2.2001\n",
      "Validation Loss: 2.2001, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2002 to 2.2001. Saving model...\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.0389\n",
      "    Validation Batch [1/1], Loss: 2.2001\n",
      "Validation Loss: 2.2001, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2001 to 2.2001. Saving model...\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.0176\n",
      "    Validation Batch [1/1], Loss: 2.2000\n",
      "Validation Loss: 2.2000, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2001 to 2.2000. Saving model...\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000] completed, Average Training Loss: 1.9784\n",
      "    Validation Batch [1/1], Loss: 2.2000\n",
      "Validation Loss: 2.2000, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2000 to 2.2000. Saving model...\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 1.9957\n",
      "    Validation Batch [1/1], Loss: 2.1999\n",
      "Validation Loss: 2.1999, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.2000 to 2.1999. Saving model...\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 1.9623\n",
      "    Validation Batch [1/1], Loss: 2.1997\n",
      "Validation Loss: 2.1997, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1999 to 2.1997. Saving model...\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 1.9548\n",
      "    Validation Batch [1/1], Loss: 2.1994\n",
      "Validation Loss: 2.1994, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1997 to 2.1994. Saving model...\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 1.9320\n",
      "    Validation Batch [1/1], Loss: 2.1991\n",
      "Validation Loss: 2.1991, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1994 to 2.1991. Saving model...\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 1.9090\n",
      "    Validation Batch [1/1], Loss: 2.1987\n",
      "Validation Loss: 2.1987, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1991 to 2.1987. Saving model...\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 1.8943\n",
      "    Validation Batch [1/1], Loss: 2.1982\n",
      "Validation Loss: 2.1982, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1987 to 2.1982. Saving model...\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 1.8765\n",
      "    Validation Batch [1/1], Loss: 2.1978\n",
      "Validation Loss: 2.1978, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1982 to 2.1978. Saving model...\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n",
      "Epoch [16/1000] completed, Average Training Loss: 1.8897\n",
      "    Validation Batch [1/1], Loss: 2.1972\n",
      "Validation Loss: 2.1972, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1978 to 2.1972. Saving model...\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 1.8753\n",
      "    Validation Batch [1/1], Loss: 2.1965\n",
      "Validation Loss: 2.1965, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1972 to 2.1965. Saving model...\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 1.8795\n",
      "    Validation Batch [1/1], Loss: 2.1956\n",
      "Validation Loss: 2.1956, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1965 to 2.1956. Saving model...\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 1.8413\n",
      "    Validation Batch [1/1], Loss: 2.1945\n",
      "Validation Loss: 2.1945, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1956 to 2.1945. Saving model...\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 1.8395\n",
      "    Validation Batch [1/1], Loss: 2.1933\n",
      "Validation Loss: 2.1933, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1945 to 2.1933. Saving model...\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 1.8177\n",
      "    Validation Batch [1/1], Loss: 2.1920\n",
      "Validation Loss: 2.1920, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1933 to 2.1920. Saving model...\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 1.8076\n",
      "    Validation Batch [1/1], Loss: 2.1905\n",
      "Validation Loss: 2.1905, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1920 to 2.1905. Saving model...\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 1.7974\n",
      "    Validation Batch [1/1], Loss: 2.1888\n",
      "Validation Loss: 2.1888, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1905 to 2.1888. Saving model...\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 1.8142\n",
      "    Validation Batch [1/1], Loss: 2.1866\n",
      "Validation Loss: 2.1866, Validation Accuracy: 11.11%\n",
      "Validation loss improved from 2.1888 to 2.1866. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 1.7722\n",
      "    Validation Batch [1/1], Loss: 2.1840\n",
      "Validation Loss: 2.1840, Validation Accuracy: 15.56%\n",
      "Validation loss improved from 2.1866 to 2.1840. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 1.7653\n",
      "    Validation Batch [1/1], Loss: 2.1811\n",
      "Validation Loss: 2.1811, Validation Accuracy: 22.22%\n",
      "Validation loss improved from 2.1840 to 2.1811. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 1.7651\n",
      "    Validation Batch [1/1], Loss: 2.1779\n",
      "Validation Loss: 2.1779, Validation Accuracy: 22.22%\n",
      "Validation loss improved from 2.1811 to 2.1779. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 1.7430\n",
      "    Validation Batch [1/1], Loss: 2.1738\n",
      "Validation Loss: 2.1738, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.1779 to 2.1738. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 1.7382\n",
      "    Validation Batch [1/1], Loss: 2.1690\n",
      "Validation Loss: 2.1690, Validation Accuracy: 17.78%\n",
      "Validation loss improved from 2.1738 to 2.1690. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 1.7167\n",
      "    Validation Batch [1/1], Loss: 2.1634\n",
      "Validation Loss: 2.1634, Validation Accuracy: 17.78%\n",
      "Validation loss improved from 2.1690 to 2.1634. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 1.7165\n",
      "    Validation Batch [1/1], Loss: 2.1573\n",
      "Validation Loss: 2.1573, Validation Accuracy: 17.78%\n",
      "Validation loss improved from 2.1634 to 2.1573. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 1.7110\n",
      "    Validation Batch [1/1], Loss: 2.1502\n",
      "Validation Loss: 2.1502, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.1573 to 2.1502. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 1.6832\n",
      "    Validation Batch [1/1], Loss: 2.1419\n",
      "Validation Loss: 2.1419, Validation Accuracy: 22.22%\n",
      "Validation loss improved from 2.1502 to 2.1419. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 1.6761\n",
      "    Validation Batch [1/1], Loss: 2.1318\n",
      "Validation Loss: 2.1318, Validation Accuracy: 26.67%\n",
      "Validation loss improved from 2.1419 to 2.1318. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 1.6621\n",
      "    Validation Batch [1/1], Loss: 2.1203\n",
      "Validation Loss: 2.1203, Validation Accuracy: 26.67%\n",
      "Validation loss improved from 2.1318 to 2.1203. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 1.6433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.1073\n",
      "Validation Loss: 2.1073, Validation Accuracy: 31.11%\n",
      "Validation loss improved from 2.1203 to 2.1073. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 1.6291\n",
      "    Validation Batch [1/1], Loss: 2.0918\n",
      "Validation Loss: 2.0918, Validation Accuracy: 31.11%\n",
      "Validation loss improved from 2.1073 to 2.0918. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 1.6393\n",
      "    Validation Batch [1/1], Loss: 2.0743\n",
      "Validation Loss: 2.0743, Validation Accuracy: 33.33%\n",
      "Validation loss improved from 2.0918 to 2.0743. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n",
      "Epoch [39/1000] completed, Average Training Loss: 1.6363\n",
      "    Validation Batch [1/1], Loss: 2.0559\n",
      "Validation Loss: 2.0559, Validation Accuracy: 42.22%\n",
      "Validation loss improved from 2.0743 to 2.0559. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 1.6016\n",
      "    Validation Batch [1/1], Loss: 2.0366\n",
      "Validation Loss: 2.0366, Validation Accuracy: 44.44%\n",
      "Validation loss improved from 2.0559 to 2.0366. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 1.5868\n",
      "    Validation Batch [1/1], Loss: 2.0166\n",
      "Validation Loss: 2.0166, Validation Accuracy: 53.33%\n",
      "Validation loss improved from 2.0366 to 2.0166. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 1.5788\n",
      "    Validation Batch [1/1], Loss: 1.9953\n",
      "Validation Loss: 1.9953, Validation Accuracy: 53.33%\n",
      "Validation loss improved from 2.0166 to 1.9953. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 1.5774\n",
      "    Validation Batch [1/1], Loss: 1.9723\n",
      "Validation Loss: 1.9723, Validation Accuracy: 57.78%\n",
      "Validation loss improved from 1.9953 to 1.9723. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 1.5837\n",
      "    Validation Batch [1/1], Loss: 1.9473\n",
      "Validation Loss: 1.9473, Validation Accuracy: 64.44%\n",
      "Validation loss improved from 1.9723 to 1.9473. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 1.5587\n",
      "    Validation Batch [1/1], Loss: 1.9220\n",
      "Validation Loss: 1.9220, Validation Accuracy: 64.44%\n",
      "Validation loss improved from 1.9473 to 1.9220. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 1.5486\n",
      "    Validation Batch [1/1], Loss: 1.8968\n",
      "Validation Loss: 1.8968, Validation Accuracy: 64.44%\n",
      "Validation loss improved from 1.9220 to 1.8968. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 1.5337\n",
      "    Validation Batch [1/1], Loss: 1.8714\n",
      "Validation Loss: 1.8714, Validation Accuracy: 68.89%\n",
      "Validation loss improved from 1.8968 to 1.8714. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 1.5303\n",
      "    Validation Batch [1/1], Loss: 1.8456\n",
      "Validation Loss: 1.8456, Validation Accuracy: 68.89%\n",
      "Validation loss improved from 1.8714 to 1.8456. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 1.5279\n",
      "    Validation Batch [1/1], Loss: 1.8187\n",
      "Validation Loss: 1.8187, Validation Accuracy: 68.89%\n",
      "Validation loss improved from 1.8456 to 1.8187. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 1.5153\n",
      "    Validation Batch [1/1], Loss: 1.7909\n",
      "Validation Loss: 1.7909, Validation Accuracy: 68.89%\n",
      "Validation loss improved from 1.8187 to 1.7909. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 1.4978\n",
      "    Validation Batch [1/1], Loss: 1.7632\n",
      "Validation Loss: 1.7632, Validation Accuracy: 75.56%\n",
      "Validation loss improved from 1.7909 to 1.7632. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 1.4924\n",
      "    Validation Batch [1/1], Loss: 1.7359\n",
      "Validation Loss: 1.7359, Validation Accuracy: 77.78%\n",
      "Validation loss improved from 1.7632 to 1.7359. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 1.4980\n",
      "    Validation Batch [1/1], Loss: 1.7095\n",
      "Validation Loss: 1.7095, Validation Accuracy: 77.78%\n",
      "Validation loss improved from 1.7359 to 1.7095. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 1.4899\n",
      "    Validation Batch [1/1], Loss: 1.6818\n",
      "Validation Loss: 1.6818, Validation Accuracy: 77.78%\n",
      "Validation loss improved from 1.7095 to 1.6818. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 1.4562\n",
      "    Validation Batch [1/1], Loss: 1.6550\n",
      "Validation Loss: 1.6550, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.6818 to 1.6550. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 1.4444\n",
      "    Validation Batch [1/1], Loss: 1.6286\n",
      "Validation Loss: 1.6286, Validation Accuracy: 82.22%\n",
      "Validation loss improved from 1.6550 to 1.6286. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 1.4260\n",
      "    Validation Batch [1/1], Loss: 1.6020\n",
      "Validation Loss: 1.6020, Validation Accuracy: 86.67%\n",
      "Validation loss improved from 1.6286 to 1.6020. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.4424\n",
      "    Validation Batch [1/1], Loss: 1.5786\n",
      "Validation Loss: 1.5786, Validation Accuracy: 84.44%\n",
      "Validation loss improved from 1.6020 to 1.5786. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.4281\n",
      "    Validation Batch [1/1], Loss: 1.5596\n",
      "Validation Loss: 1.5596, Validation Accuracy: 84.44%\n",
      "Validation loss improved from 1.5786 to 1.5596. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 1.4020\n",
      "    Validation Batch [1/1], Loss: 1.5407\n",
      "Validation Loss: 1.5407, Validation Accuracy: 84.44%\n",
      "Validation loss improved from 1.5596 to 1.5407. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 1.3849\n",
      "    Validation Batch [1/1], Loss: 1.5173\n",
      "Validation Loss: 1.5173, Validation Accuracy: 88.89%\n",
      "Validation loss improved from 1.5407 to 1.5173. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.4045\n",
      "    Validation Batch [1/1], Loss: 1.4941\n",
      "Validation Loss: 1.4941, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.5173 to 1.4941. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.3650\n",
      "    Validation Batch [1/1], Loss: 1.4747\n",
      "Validation Loss: 1.4747, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.4941 to 1.4747. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.3581\n",
      "    Validation Batch [1/1], Loss: 1.4582\n",
      "Validation Loss: 1.4582, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.4747 to 1.4582. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.3683\n",
      "    Validation Batch [1/1], Loss: 1.4420\n",
      "Validation Loss: 1.4420, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.4582 to 1.4420. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/1000] completed, Average Training Loss: 1.3285\n",
      "    Validation Batch [1/1], Loss: 1.4261\n",
      "Validation Loss: 1.4261, Validation Accuracy: 91.11%\n",
      "Validation loss improved from 1.4420 to 1.4261. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.3717\n",
      "    Validation Batch [1/1], Loss: 1.4069\n",
      "Validation Loss: 1.4069, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.4261 to 1.4069. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.3172\n",
      "    Validation Batch [1/1], Loss: 1.3898\n",
      "Validation Loss: 1.3898, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.4069 to 1.3898. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.3139\n",
      "    Validation Batch [1/1], Loss: 1.3757\n",
      "Validation Loss: 1.3757, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3898 to 1.3757. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.3049\n",
      "    Validation Batch [1/1], Loss: 1.3631\n",
      "Validation Loss: 1.3631, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3757 to 1.3631. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.3034\n",
      "    Validation Batch [1/1], Loss: 1.3518\n",
      "Validation Loss: 1.3518, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.3631 to 1.3518. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.3001\n",
      "    Validation Batch [1/1], Loss: 1.3399\n",
      "Validation Loss: 1.3399, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3518 to 1.3399. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.3003\n",
      "    Validation Batch [1/1], Loss: 1.3258\n",
      "Validation Loss: 1.3258, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3399 to 1.3258. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.2795\n",
      "    Validation Batch [1/1], Loss: 1.3123\n",
      "Validation Loss: 1.3123, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.3258 to 1.3123. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.2805\n",
      "    Validation Batch [1/1], Loss: 1.3060\n",
      "Validation Loss: 1.3060, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3123 to 1.3060. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.2656\n",
      "    Validation Batch [1/1], Loss: 1.2972\n",
      "Validation Loss: 1.2972, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.3060 to 1.2972. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.2637\n",
      "    Validation Batch [1/1], Loss: 1.2840\n",
      "Validation Loss: 1.2840, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2972 to 1.2840. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.2331\n",
      "    Validation Batch [1/1], Loss: 1.2685\n",
      "Validation Loss: 1.2685, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.2840 to 1.2685. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.2705\n",
      "    Validation Batch [1/1], Loss: 1.2554\n",
      "Validation Loss: 1.2554, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2685 to 1.2554. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.2683\n",
      "    Validation Batch [1/1], Loss: 1.2456\n",
      "Validation Loss: 1.2456, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2554 to 1.2456. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.2151\n",
      "    Validation Batch [1/1], Loss: 1.2348\n",
      "Validation Loss: 1.2348, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2456 to 1.2348. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.2148\n",
      "    Validation Batch [1/1], Loss: 1.2208\n",
      "Validation Loss: 1.2208, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2348 to 1.2208. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.1892\n",
      "    Validation Batch [1/1], Loss: 1.2074\n",
      "Validation Loss: 1.2074, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.2208 to 1.2074. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.2236\n",
      "    Validation Batch [1/1], Loss: 1.2023\n",
      "Validation Loss: 1.2023, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2074 to 1.2023. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.2014\n",
      "    Validation Batch [1/1], Loss: 1.2018\n",
      "Validation Loss: 1.2018, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2023 to 1.2018. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.2121\n",
      "    Validation Batch [1/1], Loss: 1.1944\n",
      "Validation Loss: 1.1944, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.2018 to 1.1944. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.1733\n",
      "    Validation Batch [1/1], Loss: 1.1801\n",
      "Validation Loss: 1.1801, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.1944 to 1.1801. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.2021\n",
      "    Validation Batch [1/1], Loss: 1.1599\n",
      "Validation Loss: 1.1599, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.1801 to 1.1599. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.1709\n",
      "    Validation Batch [1/1], Loss: 1.1505\n",
      "Validation Loss: 1.1505, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.1599 to 1.1505. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.1536\n",
      "    Validation Batch [1/1], Loss: 1.1524\n",
      "Validation Loss: 1.1524, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.1455\n",
      "    Validation Batch [1/1], Loss: 1.1573\n",
      "Validation Loss: 1.1573, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n",
      "Epoch [92/1000] completed, Average Training Loss: 1.1440\n",
      "    Validation Batch [1/1], Loss: 1.1547\n",
      "Validation Loss: 1.1547, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/1000] completed, Average Training Loss: 1.1312\n",
      "    Validation Batch [1/1], Loss: 1.1333\n",
      "Validation Loss: 1.1333, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.1505 to 1.1333. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.1308\n",
      "    Validation Batch [1/1], Loss: 1.1107\n",
      "Validation Loss: 1.1107, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.1333 to 1.1107. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.0992\n",
      "    Validation Batch [1/1], Loss: 1.1094\n",
      "Validation Loss: 1.1094, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.1107 to 1.1094. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.1064\n",
      "    Validation Batch [1/1], Loss: 1.1042\n",
      "Validation Loss: 1.1042, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.1094 to 1.1042. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.1075\n",
      "    Validation Batch [1/1], Loss: 1.1050\n",
      "Validation Loss: 1.1050, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.0824\n",
      "    Validation Batch [1/1], Loss: 1.0875\n",
      "Validation Loss: 1.0875, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.1042 to 1.0875. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.0836\n",
      "    Validation Batch [1/1], Loss: 1.0680\n",
      "Validation Loss: 1.0680, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.0875 to 1.0680. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.0770\n",
      "    Validation Batch [1/1], Loss: 1.0657\n",
      "Validation Loss: 1.0657, Validation Accuracy: 93.33%\n",
      "Validation loss improved from 1.0680 to 1.0657. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.0632\n",
      "    Validation Batch [1/1], Loss: 1.0599\n",
      "Validation Loss: 1.0599, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0657 to 1.0599. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.0462\n",
      "    Validation Batch [1/1], Loss: 1.0656\n",
      "Validation Loss: 1.0656, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.0388\n",
      "    Validation Batch [1/1], Loss: 1.0652\n",
      "Validation Loss: 1.0652, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.0626\n",
      "    Validation Batch [1/1], Loss: 1.0404\n",
      "Validation Loss: 1.0404, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0599 to 1.0404. Saving model...\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.0267\n",
      "    Validation Batch [1/1], Loss: 1.0270\n",
      "Validation Loss: 1.0270, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0404 to 1.0270. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.0215\n",
      "    Validation Batch [1/1], Loss: 1.0157\n",
      "Validation Loss: 1.0157, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0270 to 1.0157. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.0225\n",
      "    Validation Batch [1/1], Loss: 1.0076\n",
      "Validation Loss: 1.0076, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 1.0157 to 1.0076. Saving model...\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.0175\n",
      "    Validation Batch [1/1], Loss: 1.0030\n",
      "Validation Loss: 1.0030, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.0076 to 1.0030. Saving model...\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.0138\n",
      "    Validation Batch [1/1], Loss: 0.9907\n",
      "Validation Loss: 0.9907, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 1.0030 to 0.9907. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 0.9786\n",
      "    Validation Batch [1/1], Loss: 0.9852\n",
      "Validation Loss: 0.9852, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9907 to 0.9852. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 0.9730\n",
      "    Validation Batch [1/1], Loss: 0.9769\n",
      "Validation Loss: 0.9769, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9852 to 0.9769. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 0.9810\n",
      "    Validation Batch [1/1], Loss: 0.9742\n",
      "Validation Loss: 0.9742, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9769 to 0.9742. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 0.9565\n",
      "    Validation Batch [1/1], Loss: 0.9812\n",
      "Validation Loss: 0.9812, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 0.9808\n",
      "    Validation Batch [1/1], Loss: 0.9651\n",
      "Validation Loss: 0.9651, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9742 to 0.9651. Saving model...\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 0.9453\n",
      "    Validation Batch [1/1], Loss: 0.9505\n",
      "Validation Loss: 0.9505, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9651 to 0.9505. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 0.9532\n",
      "    Validation Batch [1/1], Loss: 0.9396\n",
      "Validation Loss: 0.9396, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9505 to 0.9396. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 0.9253\n",
      "    Validation Batch [1/1], Loss: 0.9303\n",
      "Validation Loss: 0.9303, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9396 to 0.9303. Saving model...\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 0.9273\n",
      "    Validation Batch [1/1], Loss: 0.9270\n",
      "Validation Loss: 0.9270, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9303 to 0.9270. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 0.9314\n",
      "    Validation Batch [1/1], Loss: 0.9253\n",
      "Validation Loss: 0.9253, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9270 to 0.9253. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 0.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.9139\n",
      "Validation Loss: 0.9139, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9253 to 0.9139. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 0.9031\n",
      "    Validation Batch [1/1], Loss: 0.9022\n",
      "Validation Loss: 0.9022, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9139 to 0.9022. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 0.8917\n",
      "    Validation Batch [1/1], Loss: 0.8945\n",
      "Validation Loss: 0.8945, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.9022 to 0.8945. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 0.8770\n",
      "    Validation Batch [1/1], Loss: 0.8895\n",
      "Validation Loss: 0.8895, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8945 to 0.8895. Saving model...\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 0.8702\n",
      "    Validation Batch [1/1], Loss: 0.8824\n",
      "Validation Loss: 0.8824, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8895 to 0.8824. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 0.8717\n",
      "    Validation Batch [1/1], Loss: 0.8726\n",
      "Validation Loss: 0.8726, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8824 to 0.8726. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 0.8677\n",
      "    Validation Batch [1/1], Loss: 0.8622\n",
      "Validation Loss: 0.8622, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8726 to 0.8622. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 0.8499\n",
      "    Validation Batch [1/1], Loss: 0.8548\n",
      "Validation Loss: 0.8548, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8622 to 0.8548. Saving model...\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 0.8498\n",
      "    Validation Batch [1/1], Loss: 0.8499\n",
      "Validation Loss: 0.8499, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8548 to 0.8499. Saving model...\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 0.8428\n",
      "    Validation Batch [1/1], Loss: 0.8469\n",
      "Validation Loss: 0.8469, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8499 to 0.8469. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 0.8443\n",
      "    Validation Batch [1/1], Loss: 0.8359\n",
      "Validation Loss: 0.8359, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8469 to 0.8359. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 0.8250\n",
      "    Validation Batch [1/1], Loss: 0.8260\n",
      "Validation Loss: 0.8260, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8359 to 0.8260. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 0.8565\n",
      "    Validation Batch [1/1], Loss: 0.8180\n",
      "Validation Loss: 0.8180, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8260 to 0.8180. Saving model...\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 0.7973\n",
      "    Validation Batch [1/1], Loss: 0.8216\n",
      "Validation Loss: 0.8216, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 0.8215\n",
      "    Validation Batch [1/1], Loss: 0.8161\n",
      "Validation Loss: 0.8161, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8180 to 0.8161. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 0.7815\n",
      "    Validation Batch [1/1], Loss: 0.8008\n",
      "Validation Loss: 0.8008, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8161 to 0.8008. Saving model...\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 0.8154\n",
      "    Validation Batch [1/1], Loss: 0.7781\n",
      "Validation Loss: 0.7781, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.8008 to 0.7781. Saving model...\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 0.7831\n",
      "    Validation Batch [1/1], Loss: 0.7719\n",
      "Validation Loss: 0.7719, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7781 to 0.7719. Saving model...\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 0.7710\n",
      "    Validation Batch [1/1], Loss: 0.7675\n",
      "Validation Loss: 0.7675, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7719 to 0.7675. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 0.7861\n",
      "    Validation Batch [1/1], Loss: 0.7685\n",
      "Validation Loss: 0.7685, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 0.7683\n",
      "    Validation Batch [1/1], Loss: 0.7717\n",
      "Validation Loss: 0.7717, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 0.7581\n",
      "    Validation Batch [1/1], Loss: 0.7533\n",
      "Validation Loss: 0.7533, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7675 to 0.7533. Saving model...\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 0.7614\n",
      "    Validation Batch [1/1], Loss: 0.7470\n",
      "Validation Loss: 0.7470, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7533 to 0.7470. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 0.7619\n",
      "    Validation Batch [1/1], Loss: 0.7362\n",
      "Validation Loss: 0.7362, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7470 to 0.7362. Saving model...\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 0.7298\n",
      "    Validation Batch [1/1], Loss: 0.7309\n",
      "Validation Loss: 0.7309, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.7362 to 0.7309. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 0.7304\n",
      "    Validation Batch [1/1], Loss: 0.7228\n",
      "Validation Loss: 0.7228, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7309 to 0.7228. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 0.7431\n",
      "    Validation Batch [1/1], Loss: 0.7182\n",
      "Validation Loss: 0.7182, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7228 to 0.7182. Saving model...\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 0.7168\n",
      "    Validation Batch [1/1], Loss: 0.7080\n",
      "Validation Loss: 0.7080, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7182 to 0.7080. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 0.7023\n",
      "    Validation Batch [1/1], Loss: 0.7020\n",
      "Validation Loss: 0.7020, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.7080 to 0.7020. Saving model...\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 0.7133\n",
      "    Validation Batch [1/1], Loss: 0.6914\n",
      "Validation Loss: 0.6914, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.7020 to 0.6914. Saving model...\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/1000] completed, Average Training Loss: 0.7004\n",
      "    Validation Batch [1/1], Loss: 0.6883\n",
      "Validation Loss: 0.6883, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6914 to 0.6883. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 0.6788\n",
      "    Validation Batch [1/1], Loss: 0.6846\n",
      "Validation Loss: 0.6846, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6883 to 0.6846. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 0.6886\n",
      "    Validation Batch [1/1], Loss: 0.6791\n",
      "Validation Loss: 0.6791, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.6846 to 0.6791. Saving model...\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 0.6835\n",
      "    Validation Batch [1/1], Loss: 0.6629\n",
      "Validation Loss: 0.6629, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6791 to 0.6629. Saving model...\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 0.6596\n",
      "    Validation Batch [1/1], Loss: 0.6584\n",
      "Validation Loss: 0.6584, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6629 to 0.6584. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 0.6693\n",
      "    Validation Batch [1/1], Loss: 0.6516\n",
      "Validation Loss: 0.6516, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6584 to 0.6516. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 0.6644\n",
      "    Validation Batch [1/1], Loss: 0.6498\n",
      "Validation Loss: 0.6498, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6516 to 0.6498. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 0.6370\n",
      "    Validation Batch [1/1], Loss: 0.6438\n",
      "Validation Loss: 0.6438, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.6498 to 0.6438. Saving model...\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 0.6300\n",
      "    Validation Batch [1/1], Loss: 0.6271\n",
      "Validation Loss: 0.6271, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6438 to 0.6271. Saving model...\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 0.6504\n",
      "    Validation Batch [1/1], Loss: 0.6210\n",
      "Validation Loss: 0.6210, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6271 to 0.6210. Saving model...\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 0.6170\n",
      "    Validation Batch [1/1], Loss: 0.6224\n",
      "Validation Loss: 0.6224, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 0.6448\n",
      "    Validation Batch [1/1], Loss: 0.6252\n",
      "Validation Loss: 0.6252, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 0.6358\n",
      "    Validation Batch [1/1], Loss: 0.6095\n",
      "Validation Loss: 0.6095, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.6210 to 0.6095. Saving model...\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 0.6112\n",
      "    Validation Batch [1/1], Loss: 0.5976\n",
      "Validation Loss: 0.5976, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.6095 to 0.5976. Saving model...\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 0.5921\n",
      "    Validation Batch [1/1], Loss: 0.5913\n",
      "Validation Loss: 0.5913, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5976 to 0.5913. Saving model...\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 0.5695\n",
      "    Validation Batch [1/1], Loss: 0.6005\n",
      "Validation Loss: 0.6005, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 0.5859\n",
      "    Validation Batch [1/1], Loss: 0.5892\n",
      "Validation Loss: 0.5892, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5913 to 0.5892. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 0.5984\n",
      "    Validation Batch [1/1], Loss: 0.5791\n",
      "Validation Loss: 0.5791, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5892 to 0.5791. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 0.5502\n",
      "    Validation Batch [1/1], Loss: 0.5603\n",
      "Validation Loss: 0.5603, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5791 to 0.5603. Saving model...\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 0.5991\n",
      "    Validation Batch [1/1], Loss: 0.5541\n",
      "Validation Loss: 0.5541, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5603 to 0.5541. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 0.5721\n",
      "    Validation Batch [1/1], Loss: 0.5553\n",
      "Validation Loss: 0.5553, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 0.5508\n",
      "    Validation Batch [1/1], Loss: 0.5515\n",
      "Validation Loss: 0.5515, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5541 to 0.5515. Saving model...\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 0.5861\n",
      "    Validation Batch [1/1], Loss: 0.5429\n",
      "Validation Loss: 0.5429, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5515 to 0.5429. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 0.5302\n",
      "    Validation Batch [1/1], Loss: 0.5391\n",
      "Validation Loss: 0.5391, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5429 to 0.5391. Saving model...\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 0.5533\n",
      "    Validation Batch [1/1], Loss: 0.5328\n",
      "Validation Loss: 0.5328, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5391 to 0.5328. Saving model...\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.5108\n",
      "    Validation Batch [1/1], Loss: 0.5377\n",
      "Validation Loss: 0.5377, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 0.5243\n",
      "    Validation Batch [1/1], Loss: 0.5306\n",
      "Validation Loss: 0.5306, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5328 to 0.5306. Saving model...\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 0.5461\n",
      "    Validation Batch [1/1], Loss: 0.5158\n",
      "Validation Loss: 0.5158, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5306 to 0.5158. Saving model...\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.5326\n",
      "    Validation Batch [1/1], Loss: 0.5101\n",
      "Validation Loss: 0.5101, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.5158 to 0.5101. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/1000] completed, Average Training Loss: 0.4990\n",
      "    Validation Batch [1/1], Loss: 0.5073\n",
      "Validation Loss: 0.5073, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5101 to 0.5073. Saving model...\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.5121\n",
      "    Validation Batch [1/1], Loss: 0.4966\n",
      "Validation Loss: 0.4966, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.5073 to 0.4966. Saving model...\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.5047\n",
      "    Validation Batch [1/1], Loss: 0.4893\n",
      "Validation Loss: 0.4893, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4966 to 0.4893. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.4973\n",
      "    Validation Batch [1/1], Loss: 0.4837\n",
      "Validation Loss: 0.4837, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4893 to 0.4837. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 0.4927\n",
      "    Validation Batch [1/1], Loss: 0.4836\n",
      "Validation Loss: 0.4836, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4837 to 0.4836. Saving model...\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.5005\n",
      "    Validation Batch [1/1], Loss: 0.4826\n",
      "Validation Loss: 0.4826, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4836 to 0.4826. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.4797\n",
      "    Validation Batch [1/1], Loss: 0.4833\n",
      "Validation Loss: 0.4833, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.4581\n",
      "    Validation Batch [1/1], Loss: 0.4684\n",
      "Validation Loss: 0.4684, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4826 to 0.4684. Saving model...\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.4661\n",
      "    Validation Batch [1/1], Loss: 0.4579\n",
      "Validation Loss: 0.4579, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4684 to 0.4579. Saving model...\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.4695\n",
      "    Validation Batch [1/1], Loss: 0.4576\n",
      "Validation Loss: 0.4576, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4579 to 0.4576. Saving model...\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.4433\n",
      "    Validation Batch [1/1], Loss: 0.4731\n",
      "Validation Loss: 0.4731, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.4450\n",
      "    Validation Batch [1/1], Loss: 0.4551\n",
      "Validation Loss: 0.4551, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4576 to 0.4551. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.4524\n",
      "    Validation Batch [1/1], Loss: 0.4426\n",
      "Validation Loss: 0.4426, Validation Accuracy: 95.56%\n",
      "Validation loss improved from 0.4551 to 0.4426. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.4762\n",
      "    Validation Batch [1/1], Loss: 0.4313\n",
      "Validation Loss: 0.4313, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4426 to 0.4313. Saving model...\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.4820\n",
      "    Validation Batch [1/1], Loss: 0.4381\n",
      "Validation Loss: 0.4381, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.4221\n",
      "    Validation Batch [1/1], Loss: 0.4319\n",
      "Validation Loss: 0.4319, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.4367\n",
      "    Validation Batch [1/1], Loss: 0.4226\n",
      "Validation Loss: 0.4226, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4313 to 0.4226. Saving model...\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.4172\n",
      "    Validation Batch [1/1], Loss: 0.4185\n",
      "Validation Loss: 0.4185, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4226 to 0.4185. Saving model...\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.4094\n",
      "    Validation Batch [1/1], Loss: 0.4182\n",
      "Validation Loss: 0.4182, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4185 to 0.4182. Saving model...\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.4317\n",
      "    Validation Batch [1/1], Loss: 0.4157\n",
      "Validation Loss: 0.4157, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4182 to 0.4157. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.3997\n",
      "    Validation Batch [1/1], Loss: 0.4006\n",
      "Validation Loss: 0.4006, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4157 to 0.4006. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.3869\n",
      "    Validation Batch [1/1], Loss: 0.3960\n",
      "Validation Loss: 0.3960, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.4006 to 0.3960. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.4360\n",
      "    Validation Batch [1/1], Loss: 0.3898\n",
      "Validation Loss: 0.3898, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3960 to 0.3898. Saving model...\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.3724\n",
      "    Validation Batch [1/1], Loss: 0.3952\n",
      "Validation Loss: 0.3952, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.3988\n",
      "    Validation Batch [1/1], Loss: 0.3877\n",
      "Validation Loss: 0.3877, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3898 to 0.3877. Saving model...\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.3989\n",
      "    Validation Batch [1/1], Loss: 0.3784\n",
      "Validation Loss: 0.3784, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3877 to 0.3784. Saving model...\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.3985\n",
      "    Validation Batch [1/1], Loss: 0.3733\n",
      "Validation Loss: 0.3733, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3784 to 0.3733. Saving model...\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.3809\n",
      "    Validation Batch [1/1], Loss: 0.3747\n",
      "Validation Loss: 0.3747, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.3861\n",
      "    Validation Batch [1/1], Loss: 0.3794\n",
      "Validation Loss: 0.3794, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.4066\n",
      "    Validation Batch [1/1], Loss: 0.3691\n",
      "Validation Loss: 0.3691, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3733 to 0.3691. Saving model...\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [209/1000] completed, Average Training Loss: 0.3589\n",
      "    Validation Batch [1/1], Loss: 0.3544\n",
      "Validation Loss: 0.3544, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3691 to 0.3544. Saving model...\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.3656\n",
      "    Validation Batch [1/1], Loss: 0.3558\n",
      "Validation Loss: 0.3558, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.3542\n",
      "    Validation Batch [1/1], Loss: 0.3572\n",
      "Validation Loss: 0.3572, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.3654\n",
      "    Validation Batch [1/1], Loss: 0.3580\n",
      "Validation Loss: 0.3580, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.3402\n",
      "    Validation Batch [1/1], Loss: 0.3524\n",
      "Validation Loss: 0.3524, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3544 to 0.3524. Saving model...\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.3739\n",
      "    Validation Batch [1/1], Loss: 0.3410\n",
      "Validation Loss: 0.3410, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3524 to 0.3410. Saving model...\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.3515\n",
      "    Validation Batch [1/1], Loss: 0.3377\n",
      "Validation Loss: 0.3377, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3410 to 0.3377. Saving model...\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.3611\n",
      "    Validation Batch [1/1], Loss: 0.3339\n",
      "Validation Loss: 0.3339, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3377 to 0.3339. Saving model...\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.3371\n",
      "    Validation Batch [1/1], Loss: 0.3330\n",
      "Validation Loss: 0.3330, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3339 to 0.3330. Saving model...\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.3425\n",
      "    Validation Batch [1/1], Loss: 0.3279\n",
      "Validation Loss: 0.3279, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3330 to 0.3279. Saving model...\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.3338\n",
      "    Validation Batch [1/1], Loss: 0.3181\n",
      "Validation Loss: 0.3181, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3279 to 0.3181. Saving model...\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.3597\n",
      "    Validation Batch [1/1], Loss: 0.3185\n",
      "Validation Loss: 0.3185, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.3088\n",
      "    Validation Batch [1/1], Loss: 0.3183\n",
      "Validation Loss: 0.3183, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.3238\n",
      "    Validation Batch [1/1], Loss: 0.3262\n",
      "Validation Loss: 0.3262, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.3201\n",
      "    Validation Batch [1/1], Loss: 0.3268\n",
      "Validation Loss: 0.3268, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.3005\n",
      "    Validation Batch [1/1], Loss: 0.3109\n",
      "Validation Loss: 0.3109, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3181 to 0.3109. Saving model...\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n",
      "Epoch [225/1000] completed, Average Training Loss: 0.3119\n",
      "    Validation Batch [1/1], Loss: 0.2976\n",
      "Validation Loss: 0.2976, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.3109 to 0.2976. Saving model...\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.3028\n",
      "    Validation Batch [1/1], Loss: 0.2897\n",
      "Validation Loss: 0.2897, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2976 to 0.2897. Saving model...\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.3085\n",
      "    Validation Batch [1/1], Loss: 0.2862\n",
      "Validation Loss: 0.2862, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2897 to 0.2862. Saving model...\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.3033\n",
      "    Validation Batch [1/1], Loss: 0.3014\n",
      "Validation Loss: 0.3014, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.3027\n",
      "    Validation Batch [1/1], Loss: 0.3130\n",
      "Validation Loss: 0.3130, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.2888\n",
      "    Validation Batch [1/1], Loss: 0.3029\n",
      "Validation Loss: 0.3029, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.3070\n",
      "    Validation Batch [1/1], Loss: 0.2809\n",
      "Validation Loss: 0.2809, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2862 to 0.2809. Saving model...\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.3004\n",
      "    Validation Batch [1/1], Loss: 0.2684\n",
      "Validation Loss: 0.2684, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2809 to 0.2684. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.3086\n",
      "    Validation Batch [1/1], Loss: 0.2756\n",
      "Validation Loss: 0.2756, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.2770\n",
      "    Validation Batch [1/1], Loss: 0.2930\n",
      "Validation Loss: 0.2930, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.2771\n",
      "    Validation Batch [1/1], Loss: 0.2992\n",
      "Validation Loss: 0.2992, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.2752\n",
      "    Validation Batch [1/1], Loss: 0.2882\n",
      "Validation Loss: 0.2882, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.2844\n",
      "    Validation Batch [1/1], Loss: 0.2648\n",
      "Validation Loss: 0.2648, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2684 to 0.2648. Saving model...\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [238/1000] completed, Average Training Loss: 0.2598\n",
      "    Validation Batch [1/1], Loss: 0.2539\n",
      "Validation Loss: 0.2539, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2648 to 0.2539. Saving model...\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.2671\n",
      "    Validation Batch [1/1], Loss: 0.2541\n",
      "Validation Loss: 0.2541, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.2756\n",
      "    Validation Batch [1/1], Loss: 0.2708\n",
      "Validation Loss: 0.2708, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.2641\n",
      "    Validation Batch [1/1], Loss: 0.2766\n",
      "Validation Loss: 0.2766, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.2742\n",
      "    Validation Batch [1/1], Loss: 0.2453\n",
      "Validation Loss: 0.2453, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2539 to 0.2453. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.2452\n",
      "    Validation Batch [1/1], Loss: 0.2342\n",
      "Validation Loss: 0.2342, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2453 to 0.2342. Saving model...\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.2675\n",
      "    Validation Batch [1/1], Loss: 0.2353\n",
      "Validation Loss: 0.2353, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.2193\n",
      "    Validation Batch [1/1], Loss: 0.2502\n",
      "Validation Loss: 0.2502, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.2390\n",
      "    Validation Batch [1/1], Loss: 0.2718\n",
      "Validation Loss: 0.2718, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.2406\n",
      "    Validation Batch [1/1], Loss: 0.2732\n",
      "Validation Loss: 0.2732, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.2552\n",
      "    Validation Batch [1/1], Loss: 0.2418\n",
      "Validation Loss: 0.2418, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.2331\n",
      "    Validation Batch [1/1], Loss: 0.2227\n",
      "Validation Loss: 0.2227, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2342 to 0.2227. Saving model...\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.2426\n",
      "    Validation Batch [1/1], Loss: 0.2205\n",
      "Validation Loss: 0.2205, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2227 to 0.2205. Saving model...\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.2379\n",
      "    Validation Batch [1/1], Loss: 0.2315\n",
      "Validation Loss: 0.2315, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.2469\n",
      "    Validation Batch [1/1], Loss: 0.2376\n",
      "Validation Loss: 0.2376, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.2283\n",
      "    Validation Batch [1/1], Loss: 0.2367\n",
      "Validation Loss: 0.2367, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.2429\n",
      "    Validation Batch [1/1], Loss: 0.2195\n",
      "Validation Loss: 0.2195, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2205 to 0.2195. Saving model...\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.2209\n",
      "    Validation Batch [1/1], Loss: 0.2138\n",
      "Validation Loss: 0.2138, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2195 to 0.2138. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.2321\n",
      "    Validation Batch [1/1], Loss: 0.2110\n",
      "Validation Loss: 0.2110, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2138 to 0.2110. Saving model...\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.2389\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.2140\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.2154\n",
      "    Validation Batch [1/1], Loss: 0.2231\n",
      "Validation Loss: 0.2231, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.1969\n",
      "    Validation Batch [1/1], Loss: 0.2158\n",
      "Validation Loss: 0.2158, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.2495\n",
      "    Validation Batch [1/1], Loss: 0.2098\n",
      "Validation Loss: 0.2098, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2110 to 0.2098. Saving model...\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.2117\n",
      "    Validation Batch [1/1], Loss: 0.2030\n",
      "Validation Loss: 0.2030, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2098 to 0.2030. Saving model...\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.2089\n",
      "    Validation Batch [1/1], Loss: 0.2210\n",
      "Validation Loss: 0.2210, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.2132\n",
      "    Validation Batch [1/1], Loss: 0.2109\n",
      "Validation Loss: 0.2109, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.2178\n",
      "    Validation Batch [1/1], Loss: 0.2039\n",
      "Validation Loss: 0.2039, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.2026\n",
      "    Validation Batch [1/1], Loss: 0.2094\n",
      "Validation Loss: 0.2094, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.2135\n",
      "    Validation Batch [1/1], Loss: 0.2067\n",
      "Validation Loss: 0.2067, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.2149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2078\n",
      "Validation Loss: 0.2078, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.2073\n",
      "    Validation Batch [1/1], Loss: 0.2094\n",
      "Validation Loss: 0.2094, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.1993\n",
      "    Validation Batch [1/1], Loss: 0.1872\n",
      "Validation Loss: 0.1872, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.2030 to 0.1872. Saving model...\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.1862\n",
      "    Validation Batch [1/1], Loss: 0.1996\n",
      "Validation Loss: 0.1996, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.1920\n",
      "    Validation Batch [1/1], Loss: 0.1903\n",
      "Validation Loss: 0.1903, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.2061\n",
      "    Validation Batch [1/1], Loss: 0.2618\n",
      "Validation Loss: 0.2618, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.1988\n",
      "    Validation Batch [1/1], Loss: 0.2572\n",
      "Validation Loss: 0.2572, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.1638\n",
      "    Validation Batch [1/1], Loss: 0.2077\n",
      "Validation Loss: 0.2077, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.1778\n",
      "    Validation Batch [1/1], Loss: 0.2043\n",
      "Validation Loss: 0.2043, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.1847\n",
      "    Validation Batch [1/1], Loss: 0.1796\n",
      "Validation Loss: 0.1796, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1872 to 0.1796. Saving model...\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.1792\n",
      "    Validation Batch [1/1], Loss: 0.1743\n",
      "Validation Loss: 0.1743, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1796 to 0.1743. Saving model...\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.1734\n",
      "    Validation Batch [1/1], Loss: 0.1792\n",
      "Validation Loss: 0.1792, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.1798\n",
      "    Validation Batch [1/1], Loss: 0.1829\n",
      "Validation Loss: 0.1829, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.1853\n",
      "    Validation Batch [1/1], Loss: 0.1929\n",
      "Validation Loss: 0.1929, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.1844\n",
      "    Validation Batch [1/1], Loss: 0.1886\n",
      "Validation Loss: 0.1886, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.1699\n",
      "    Validation Batch [1/1], Loss: 0.1866\n",
      "Validation Loss: 0.1866, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.1704\n",
      "    Validation Batch [1/1], Loss: 0.1998\n",
      "Validation Loss: 0.1998, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.1712\n",
      "    Validation Batch [1/1], Loss: 0.1779\n",
      "Validation Loss: 0.1779, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.1705\n",
      "    Validation Batch [1/1], Loss: 0.1694\n",
      "Validation Loss: 0.1694, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1743 to 0.1694. Saving model...\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.1636\n",
      "    Validation Batch [1/1], Loss: 0.1760\n",
      "Validation Loss: 0.1760, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.1696\n",
      "    Validation Batch [1/1], Loss: 0.1749\n",
      "Validation Loss: 0.1749, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.1640\n",
      "    Validation Batch [1/1], Loss: 0.1643\n",
      "Validation Loss: 0.1643, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1694 to 0.1643. Saving model...\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.1531\n",
      "    Validation Batch [1/1], Loss: 0.1500\n",
      "Validation Loss: 0.1500, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1643 to 0.1500. Saving model...\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.1663\n",
      "    Validation Batch [1/1], Loss: 0.1411\n",
      "Validation Loss: 0.1411, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1500 to 0.1411. Saving model...\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.1511\n",
      "    Validation Batch [1/1], Loss: 0.1390\n",
      "Validation Loss: 0.1390, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1411 to 0.1390. Saving model...\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.1536\n",
      "    Validation Batch [1/1], Loss: 0.1440\n",
      "Validation Loss: 0.1440, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.1590\n",
      "    Validation Batch [1/1], Loss: 0.1513\n",
      "Validation Loss: 0.1513, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.1609\n",
      "    Validation Batch [1/1], Loss: 0.1543\n",
      "Validation Loss: 0.1543, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.1580\n",
      "    Validation Batch [1/1], Loss: 0.1610\n",
      "Validation Loss: 0.1610, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.1471\n",
      "    Validation Batch [1/1], Loss: 0.1568\n",
      "Validation Loss: 0.1568, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [298/1000] completed, Average Training Loss: 0.1496\n",
      "    Validation Batch [1/1], Loss: 0.1619\n",
      "Validation Loss: 0.1619, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.1386\n",
      "    Validation Batch [1/1], Loss: 0.1616\n",
      "Validation Loss: 0.1616, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.1467\n",
      "    Validation Batch [1/1], Loss: 0.1676\n",
      "Validation Loss: 0.1676, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.1645\n",
      "    Validation Batch [1/1], Loss: 0.1655\n",
      "Validation Loss: 0.1655, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.1369\n",
      "    Validation Batch [1/1], Loss: 0.1593\n",
      "Validation Loss: 0.1593, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.1462\n",
      "    Validation Batch [1/1], Loss: 0.1444\n",
      "Validation Loss: 0.1444, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.1427\n",
      "    Validation Batch [1/1], Loss: 0.1372\n",
      "Validation Loss: 0.1372, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1390 to 0.1372. Saving model...\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.1484\n",
      "    Validation Batch [1/1], Loss: 0.1333\n",
      "Validation Loss: 0.1333, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1372 to 0.1333. Saving model...\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.1450\n",
      "    Validation Batch [1/1], Loss: 0.1334\n",
      "Validation Loss: 0.1334, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.1439\n",
      "    Validation Batch [1/1], Loss: 0.1394\n",
      "Validation Loss: 0.1394, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.1348\n",
      "    Validation Batch [1/1], Loss: 0.1597\n",
      "Validation Loss: 0.1597, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.1360\n",
      "    Validation Batch [1/1], Loss: 0.1681\n",
      "Validation Loss: 0.1681, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.1395\n",
      "    Validation Batch [1/1], Loss: 0.1564\n",
      "Validation Loss: 0.1564, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.1466\n",
      "    Validation Batch [1/1], Loss: 0.1404\n",
      "Validation Loss: 0.1404, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.1471\n",
      "    Validation Batch [1/1], Loss: 0.1285\n",
      "Validation Loss: 0.1285, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1333 to 0.1285. Saving model...\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.1311\n",
      "    Validation Batch [1/1], Loss: 0.1304\n",
      "Validation Loss: 0.1304, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.1174\n",
      "    Validation Batch [1/1], Loss: 0.1490\n",
      "Validation Loss: 0.1490, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.1343\n",
      "    Validation Batch [1/1], Loss: 0.1460\n",
      "Validation Loss: 0.1460, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.1234\n",
      "    Validation Batch [1/1], Loss: 0.1529\n",
      "Validation Loss: 0.1529, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.1254\n",
      "    Validation Batch [1/1], Loss: 0.1612\n",
      "Validation Loss: 0.1612, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.1360\n",
      "    Validation Batch [1/1], Loss: 0.1553\n",
      "Validation Loss: 0.1553, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.1440\n",
      "    Validation Batch [1/1], Loss: 0.1371\n",
      "Validation Loss: 0.1371, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.1137\n",
      "    Validation Batch [1/1], Loss: 0.1334\n",
      "Validation Loss: 0.1334, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.1279\n",
      "    Validation Batch [1/1], Loss: 0.1301\n",
      "Validation Loss: 0.1301, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.1277\n",
      "    Validation Batch [1/1], Loss: 0.1408\n",
      "Validation Loss: 0.1408, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.1203\n",
      "    Validation Batch [1/1], Loss: 0.1453\n",
      "Validation Loss: 0.1453, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.1256\n",
      "    Validation Batch [1/1], Loss: 0.1431\n",
      "Validation Loss: 0.1431, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.1233\n",
      "    Validation Batch [1/1], Loss: 0.1464\n",
      "Validation Loss: 0.1464, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1401\n",
      "Validation Loss: 0.1401, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.1134\n",
      "    Validation Batch [1/1], Loss: 0.1226\n",
      "Validation Loss: 0.1226, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1285 to 0.1226. Saving model...\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.1174\n",
      "    Validation Batch [1/1], Loss: 0.1261\n",
      "Validation Loss: 0.1261, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.1220\n",
      "    Validation Batch [1/1], Loss: 0.1290\n",
      "Validation Loss: 0.1290, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.1057\n",
      "    Validation Batch [1/1], Loss: 0.1542\n",
      "Validation Loss: 0.1542, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.1147\n",
      "    Validation Batch [1/1], Loss: 0.1435\n",
      "Validation Loss: 0.1435, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.1127\n",
      "    Validation Batch [1/1], Loss: 0.1177\n",
      "Validation Loss: 0.1177, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1226 to 0.1177. Saving model...\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.1203\n",
      "    Validation Batch [1/1], Loss: 0.1155\n",
      "Validation Loss: 0.1155, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1177 to 0.1155. Saving model...\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.1202\n",
      "    Validation Batch [1/1], Loss: 0.1196\n",
      "Validation Loss: 0.1196, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.1221\n",
      "    Validation Batch [1/1], Loss: 0.1148\n",
      "Validation Loss: 0.1148, Validation Accuracy: 97.78%\n",
      "Validation loss improved from 0.1155 to 0.1148. Saving model...\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.1121\n",
      "    Validation Batch [1/1], Loss: 0.1559\n",
      "Validation Loss: 0.1559, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.0945\n",
      "    Validation Batch [1/1], Loss: 0.1722\n",
      "Validation Loss: 0.1722, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.1160\n",
      "    Validation Batch [1/1], Loss: 0.1171\n",
      "Validation Loss: 0.1171, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.0960\n",
      "    Validation Batch [1/1], Loss: 0.1219\n",
      "Validation Loss: 0.1219, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.1314\n",
      "    Validation Batch [1/1], Loss: 0.1150\n",
      "Validation Loss: 0.1150, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.1183\n",
      "    Validation Batch [1/1], Loss: 0.1013\n",
      "Validation Loss: 0.1013, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1148 to 0.1013. Saving model...\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.1012\n",
      "    Validation Batch [1/1], Loss: 0.1157\n",
      "Validation Loss: 0.1157, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.1068\n",
      "    Validation Batch [1/1], Loss: 0.1335\n",
      "Validation Loss: 0.1335, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.1062\n",
      "    Validation Batch [1/1], Loss: 0.1283\n",
      "Validation Loss: 0.1283, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.0975\n",
      "    Validation Batch [1/1], Loss: 0.1236\n",
      "Validation Loss: 0.1236, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.1088\n",
      "    Validation Batch [1/1], Loss: 0.1143\n",
      "Validation Loss: 0.1143, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.1072\n",
      "    Validation Batch [1/1], Loss: 0.1040\n",
      "Validation Loss: 0.1040, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.0940\n",
      "    Validation Batch [1/1], Loss: 0.0968\n",
      "Validation Loss: 0.0968, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1013 to 0.0968. Saving model...\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.0992\n",
      "    Validation Batch [1/1], Loss: 0.1043\n",
      "Validation Loss: 0.1043, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.0932\n",
      "    Validation Batch [1/1], Loss: 0.1104\n",
      "Validation Loss: 0.1104, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.0989\n",
      "    Validation Batch [1/1], Loss: 0.1121\n",
      "Validation Loss: 0.1121, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.0955\n",
      "    Validation Batch [1/1], Loss: 0.1193\n",
      "Validation Loss: 0.1193, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.0917\n",
      "    Validation Batch [1/1], Loss: 0.1268\n",
      "Validation Loss: 0.1268, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [354/1000] completed, Average Training Loss: 0.0965\n",
      "    Validation Batch [1/1], Loss: 0.1073\n",
      "Validation Loss: 0.1073, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.0822\n",
      "    Validation Batch [1/1], Loss: 0.0945\n",
      "Validation Loss: 0.0945, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0968 to 0.0945. Saving model...\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.0885\n",
      "    Validation Batch [1/1], Loss: 0.1213\n",
      "Validation Loss: 0.1213, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.1000\n",
      "    Validation Batch [1/1], Loss: 0.1284\n",
      "Validation Loss: 0.1284, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.1011\n",
      "    Validation Batch [1/1], Loss: 0.0997\n",
      "Validation Loss: 0.0997, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.0863\n",
      "    Validation Batch [1/1], Loss: 0.1189\n",
      "Validation Loss: 0.1189, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1078\n",
      "    Validation Batch [1/1], Loss: 0.1169\n",
      "Validation Loss: 0.1169, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.0960\n",
      "    Validation Batch [1/1], Loss: 0.1015\n",
      "Validation Loss: 0.1015, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.0955\n",
      "    Validation Batch [1/1], Loss: 0.1569\n",
      "Validation Loss: 0.1569, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.0917\n",
      "    Validation Batch [1/1], Loss: 0.1702\n",
      "Validation Loss: 0.1702, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.0882\n",
      "    Validation Batch [1/1], Loss: 0.1297\n",
      "Validation Loss: 0.1297, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.0905\n",
      "    Validation Batch [1/1], Loss: 0.1201\n",
      "Validation Loss: 0.1201, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.0874\n",
      "    Validation Batch [1/1], Loss: 0.1287\n",
      "Validation Loss: 0.1287, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.0848\n",
      "    Validation Batch [1/1], Loss: 0.1251\n",
      "Validation Loss: 0.1251, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.0959\n",
      "    Validation Batch [1/1], Loss: 0.1091\n",
      "Validation Loss: 0.1091, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.0879\n",
      "    Validation Batch [1/1], Loss: 0.1012\n",
      "Validation Loss: 0.1012, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.0915\n",
      "    Validation Batch [1/1], Loss: 0.1074\n",
      "Validation Loss: 0.1074, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.1108\n",
      "Validation Loss: 0.1108, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.0885\n",
      "    Validation Batch [1/1], Loss: 0.0845\n",
      "Validation Loss: 0.0845, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0945 to 0.0845. Saving model...\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.0981\n",
      "    Validation Batch [1/1], Loss: 0.0848\n",
      "Validation Loss: 0.0848, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.0895\n",
      "    Validation Batch [1/1], Loss: 0.0976\n",
      "Validation Loss: 0.0976, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.0911\n",
      "    Validation Batch [1/1], Loss: 0.1039\n",
      "Validation Loss: 0.1039, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.0878\n",
      "    Validation Batch [1/1], Loss: 0.1267\n",
      "Validation Loss: 0.1267, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.0790\n",
      "    Validation Batch [1/1], Loss: 0.1617\n",
      "Validation Loss: 0.1617, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.0909\n",
      "    Validation Batch [1/1], Loss: 0.1402\n",
      "Validation Loss: 0.1402, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.0845\n",
      "    Validation Batch [1/1], Loss: 0.0936\n",
      "Validation Loss: 0.0936, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.0747\n",
      "    Validation Batch [1/1], Loss: 0.0741\n",
      "Validation Loss: 0.0741, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0845 to 0.0741. Saving model...\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.0875\n",
      "    Validation Batch [1/1], Loss: 0.0819\n",
      "Validation Loss: 0.0819, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [382/1000] completed, Average Training Loss: 0.0956\n",
      "    Validation Batch [1/1], Loss: 0.1001\n",
      "Validation Loss: 0.1001, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.0753\n",
      "    Validation Batch [1/1], Loss: 0.1177\n",
      "Validation Loss: 0.1177, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.0781\n",
      "    Validation Batch [1/1], Loss: 0.1453\n",
      "Validation Loss: 0.1453, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.0823\n",
      "    Validation Batch [1/1], Loss: 0.1574\n",
      "Validation Loss: 0.1574, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.0864\n",
      "    Validation Batch [1/1], Loss: 0.1111\n",
      "Validation Loss: 0.1111, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.0933\n",
      "    Validation Batch [1/1], Loss: 0.0692\n",
      "Validation Loss: 0.0692, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0741 to 0.0692. Saving model...\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.0813\n",
      "    Validation Batch [1/1], Loss: 0.0912\n",
      "Validation Loss: 0.0912, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.0956\n",
      "    Validation Batch [1/1], Loss: 0.0733\n",
      "Validation Loss: 0.0733, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.0803\n",
      "    Validation Batch [1/1], Loss: 0.1390\n",
      "Validation Loss: 0.1390, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.2498\n",
      "Validation Loss: 0.2498, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.0798\n",
      "    Validation Batch [1/1], Loss: 0.1916\n",
      "Validation Loss: 0.1916, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.0889\n",
      "    Validation Batch [1/1], Loss: 0.1193\n",
      "Validation Loss: 0.1193, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.0821\n",
      "    Validation Batch [1/1], Loss: 0.1217\n",
      "Validation Loss: 0.1217, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.0719\n",
      "    Validation Batch [1/1], Loss: 0.1085\n",
      "Validation Loss: 0.1085, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.0796\n",
      "    Validation Batch [1/1], Loss: 0.0774\n",
      "Validation Loss: 0.0774, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.0715\n",
      "    Validation Batch [1/1], Loss: 0.1253\n",
      "Validation Loss: 0.1253, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.0726\n",
      "    Validation Batch [1/1], Loss: 0.2039\n",
      "Validation Loss: 0.2039, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.0670\n",
      "    Validation Batch [1/1], Loss: 0.1562\n",
      "Validation Loss: 0.1562, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.0703\n",
      "    Validation Batch [1/1], Loss: 0.1130\n",
      "Validation Loss: 0.1130, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.0748\n",
      "    Validation Batch [1/1], Loss: 0.1001\n",
      "Validation Loss: 0.1001, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.0675\n",
      "    Validation Batch [1/1], Loss: 0.0900\n",
      "Validation Loss: 0.0900, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.0751\n",
      "    Validation Batch [1/1], Loss: 0.0888\n",
      "Validation Loss: 0.0888, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.0675\n",
      "    Validation Batch [1/1], Loss: 0.0743\n",
      "Validation Loss: 0.0743, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.0629\n",
      "    Validation Batch [1/1], Loss: 0.0734\n",
      "Validation Loss: 0.0734, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.0690\n",
      "    Validation Batch [1/1], Loss: 0.0805\n",
      "Validation Loss: 0.0805, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.0642\n",
      "    Validation Batch [1/1], Loss: 0.0845\n",
      "Validation Loss: 0.0845, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.0828\n",
      "Validation Loss: 0.0828, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.0828\n",
      "Validation Loss: 0.0828, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.0690\n",
      "    Validation Batch [1/1], Loss: 0.0839\n",
      "Validation Loss: 0.0839, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.0625\n",
      "    Validation Batch [1/1], Loss: 0.0879\n",
      "Validation Loss: 0.0879, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.0669\n",
      "    Validation Batch [1/1], Loss: 0.0900\n",
      "Validation Loss: 0.0900, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [413/1000] completed, Average Training Loss: 0.0616\n",
      "    Validation Batch [1/1], Loss: 0.0889\n",
      "Validation Loss: 0.0889, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.0571\n",
      "    Validation Batch [1/1], Loss: 0.0881\n",
      "Validation Loss: 0.0881, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.0614\n",
      "    Validation Batch [1/1], Loss: 0.0809\n",
      "Validation Loss: 0.0809, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.0686\n",
      "    Validation Batch [1/1], Loss: 0.0798\n",
      "Validation Loss: 0.0798, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.0700\n",
      "    Validation Batch [1/1], Loss: 0.0698\n",
      "Validation Loss: 0.0698, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.0671\n",
      "    Validation Batch [1/1], Loss: 0.0643\n",
      "Validation Loss: 0.0643, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0692 to 0.0643. Saving model...\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.0611\n",
      "    Validation Batch [1/1], Loss: 0.0623\n",
      "Validation Loss: 0.0623, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0643 to 0.0623. Saving model...\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.0602\n",
      "    Validation Batch [1/1], Loss: 0.0651\n",
      "Validation Loss: 0.0651, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.0777\n",
      "    Validation Batch [1/1], Loss: 0.0686\n",
      "Validation Loss: 0.0686, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.0694\n",
      "    Validation Batch [1/1], Loss: 0.0704\n",
      "Validation Loss: 0.0704, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n",
      "Epoch [423/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.0693\n",
      "Validation Loss: 0.0693, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.0696\n",
      "    Validation Batch [1/1], Loss: 0.0697\n",
      "Validation Loss: 0.0697, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.0689\n",
      "    Validation Batch [1/1], Loss: 0.0758\n",
      "Validation Loss: 0.0758, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.0613\n",
      "    Validation Batch [1/1], Loss: 0.0662\n",
      "Validation Loss: 0.0662, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.0593\n",
      "    Validation Batch [1/1], Loss: 0.0735\n",
      "Validation Loss: 0.0735, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.0548\n",
      "    Validation Batch [1/1], Loss: 0.0843\n",
      "Validation Loss: 0.0843, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.0637\n",
      "    Validation Batch [1/1], Loss: 0.1017\n",
      "Validation Loss: 0.1017, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.0652\n",
      "    Validation Batch [1/1], Loss: 0.1327\n",
      "Validation Loss: 0.1327, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.1522\n",
      "Validation Loss: 0.1522, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.0588\n",
      "    Validation Batch [1/1], Loss: 0.1385\n",
      "Validation Loss: 0.1385, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.0489\n",
      "    Validation Batch [1/1], Loss: 0.1129\n",
      "Validation Loss: 0.1129, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.0639\n",
      "    Validation Batch [1/1], Loss: 0.0961\n",
      "Validation Loss: 0.0961, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.0680\n",
      "    Validation Batch [1/1], Loss: 0.0772\n",
      "Validation Loss: 0.0772, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.0647\n",
      "    Validation Batch [1/1], Loss: 0.0741\n",
      "Validation Loss: 0.0741, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.0585\n",
      "    Validation Batch [1/1], Loss: 0.0689\n",
      "Validation Loss: 0.0689, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.0521\n",
      "    Validation Batch [1/1], Loss: 0.0656\n",
      "Validation Loss: 0.0656, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.0623\n",
      "    Validation Batch [1/1], Loss: 0.0707\n",
      "Validation Loss: 0.0707, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.0511\n",
      "    Validation Batch [1/1], Loss: 0.0963\n",
      "Validation Loss: 0.0963, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.1254\n",
      "Validation Loss: 0.1254, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [442/1000] completed, Average Training Loss: 0.0480\n",
      "    Validation Batch [1/1], Loss: 0.1169\n",
      "Validation Loss: 0.1169, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.0558\n",
      "    Validation Batch [1/1], Loss: 0.0740\n",
      "Validation Loss: 0.0740, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.0527\n",
      "    Validation Batch [1/1], Loss: 0.0646\n",
      "Validation Loss: 0.0646, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.0628\n",
      "    Validation Batch [1/1], Loss: 0.0577\n",
      "Validation Loss: 0.0577, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0623 to 0.0577. Saving model...\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.0604\n",
      "    Validation Batch [1/1], Loss: 0.0531\n",
      "Validation Loss: 0.0531, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0577 to 0.0531. Saving model...\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.0486\n",
      "Validation Loss: 0.0486, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0531 to 0.0486. Saving model...\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.0582\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0486 to 0.0484. Saving model...\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.0591\n",
      "    Validation Batch [1/1], Loss: 0.0587\n",
      "Validation Loss: 0.0587, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.0528\n",
      "    Validation Batch [1/1], Loss: 0.0844\n",
      "Validation Loss: 0.0844, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.0632\n",
      "    Validation Batch [1/1], Loss: 0.1051\n",
      "Validation Loss: 0.1051, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.0589\n",
      "    Validation Batch [1/1], Loss: 0.1225\n",
      "Validation Loss: 0.1225, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.0659\n",
      "    Validation Batch [1/1], Loss: 0.1096\n",
      "Validation Loss: 0.1096, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.0529\n",
      "    Validation Batch [1/1], Loss: 0.0780\n",
      "Validation Loss: 0.0780, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.0454\n",
      "    Validation Batch [1/1], Loss: 0.0540\n",
      "Validation Loss: 0.0540, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.0544\n",
      "    Validation Batch [1/1], Loss: 0.0479\n",
      "Validation Loss: 0.0479, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0484 to 0.0479. Saving model...\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.0503\n",
      "    Validation Batch [1/1], Loss: 0.0517\n",
      "Validation Loss: 0.0517, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0450\n",
      "    Validation Batch [1/1], Loss: 0.0644\n",
      "Validation Loss: 0.0644, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.0865\n",
      "Validation Loss: 0.0865, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.0589\n",
      "    Validation Batch [1/1], Loss: 0.0959\n",
      "Validation Loss: 0.0959, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.0525\n",
      "    Validation Batch [1/1], Loss: 0.0978\n",
      "Validation Loss: 0.0978, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.0485\n",
      "    Validation Batch [1/1], Loss: 0.0890\n",
      "Validation Loss: 0.0890, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.0722\n",
      "Validation Loss: 0.0722, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.0515\n",
      "    Validation Batch [1/1], Loss: 0.0660\n",
      "Validation Loss: 0.0660, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.0555\n",
      "    Validation Batch [1/1], Loss: 0.0725\n",
      "Validation Loss: 0.0725, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.0809\n",
      "Validation Loss: 0.0809, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.0480\n",
      "    Validation Batch [1/1], Loss: 0.0591\n",
      "Validation Loss: 0.0591, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.0414\n",
      "    Validation Batch [1/1], Loss: 0.0567\n",
      "Validation Loss: 0.0567, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.0697\n",
      "Validation Loss: 0.0697, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [470/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.0804\n",
      "Validation Loss: 0.0804, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.0869\n",
      "Validation Loss: 0.0869, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0374\n",
      "    Validation Batch [1/1], Loss: 0.0839\n",
      "Validation Loss: 0.0839, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0566\n",
      "    Validation Batch [1/1], Loss: 0.0756\n",
      "Validation Loss: 0.0756, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0479\n",
      "    Validation Batch [1/1], Loss: 0.0675\n",
      "Validation Loss: 0.0675, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0479\n",
      "    Validation Batch [1/1], Loss: 0.0646\n",
      "Validation Loss: 0.0646, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.0700\n",
      "Validation Loss: 0.0700, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0490\n",
      "    Validation Batch [1/1], Loss: 0.0707\n",
      "Validation Loss: 0.0707, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.0752\n",
      "Validation Loss: 0.0752, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.0814\n",
      "Validation Loss: 0.0814, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0506\n",
      "    Validation Batch [1/1], Loss: 0.0779\n",
      "Validation Loss: 0.0779, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.0423\n",
      "    Validation Batch [1/1], Loss: 0.0811\n",
      "Validation Loss: 0.0811, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.0515\n",
      "    Validation Batch [1/1], Loss: 0.0794\n",
      "Validation Loss: 0.0794, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0463\n",
      "    Validation Batch [1/1], Loss: 0.0734\n",
      "Validation Loss: 0.0734, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.0445\n",
      "    Validation Batch [1/1], Loss: 0.0660\n",
      "Validation Loss: 0.0660, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0445\n",
      "    Validation Batch [1/1], Loss: 0.0578\n",
      "Validation Loss: 0.0578, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0392\n",
      "    Validation Batch [1/1], Loss: 0.0563\n",
      "Validation Loss: 0.0563, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0453\n",
      "    Validation Batch [1/1], Loss: 0.0622\n",
      "Validation Loss: 0.0622, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0513\n",
      "    Validation Batch [1/1], Loss: 0.0677\n",
      "Validation Loss: 0.0677, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.0734\n",
      "Validation Loss: 0.0734, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0432\n",
      "    Validation Batch [1/1], Loss: 0.0783\n",
      "Validation Loss: 0.0783, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.0803\n",
      "Validation Loss: 0.0803, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0450\n",
      "    Validation Batch [1/1], Loss: 0.0807\n",
      "Validation Loss: 0.0807, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0453\n",
      "    Validation Batch [1/1], Loss: 0.0803\n",
      "Validation Loss: 0.0803, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.0794\n",
      "Validation Loss: 0.0794, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.0642\n",
      "Validation Loss: 0.0642, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0501\n",
      "    Validation Batch [1/1], Loss: 0.0573\n",
      "Validation Loss: 0.0573, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.0553\n",
      "Validation Loss: 0.0553, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0473\n",
      "    Validation Batch [1/1], Loss: 0.0572\n",
      "Validation Loss: 0.0572, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0441\n",
      "    Validation Batch [1/1], Loss: 0.0607\n",
      "Validation Loss: 0.0607, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/1000] completed, Average Training Loss: 0.0393\n",
      "    Validation Batch [1/1], Loss: 0.0644\n",
      "Validation Loss: 0.0644, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.0669\n",
      "Validation Loss: 0.0669, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0475\n",
      "    Validation Batch [1/1], Loss: 0.0749\n",
      "Validation Loss: 0.0749, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0451\n",
      "    Validation Batch [1/1], Loss: 0.0789\n",
      "Validation Loss: 0.0789, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.0644\n",
      "Validation Loss: 0.0644, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0440\n",
      "    Validation Batch [1/1], Loss: 0.0582\n",
      "Validation Loss: 0.0582, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0416\n",
      "    Validation Batch [1/1], Loss: 0.0511\n",
      "Validation Loss: 0.0511, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0371\n",
      "    Validation Batch [1/1], Loss: 0.0474\n",
      "Validation Loss: 0.0474, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0479 to 0.0474. Saving model...\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.0453\n",
      "Validation Loss: 0.0453, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0474 to 0.0453. Saving model...\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0458\n",
      "    Validation Batch [1/1], Loss: 0.0494\n",
      "Validation Loss: 0.0494, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.0600\n",
      "Validation Loss: 0.0600, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.0688\n",
      "Validation Loss: 0.0688, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.0729\n",
      "Validation Loss: 0.0729, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0334\n",
      "    Validation Batch [1/1], Loss: 0.0756\n",
      "Validation Loss: 0.0756, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.0733\n",
      "Validation Loss: 0.0733, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.0578\n",
      "Validation Loss: 0.0578, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0392\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.0375\n",
      "Validation Loss: 0.0375, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0453 to 0.0375. Saving model...\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0377\n",
      "    Validation Batch [1/1], Loss: 0.0339\n",
      "Validation Loss: 0.0339, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0375 to 0.0339. Saving model...\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n",
      "Epoch [519/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0360\n",
      "Validation Loss: 0.0360, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0348\n",
      "    Validation Batch [1/1], Loss: 0.0518\n",
      "Validation Loss: 0.0518, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.0887\n",
      "Validation Loss: 0.0887, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0433\n",
      "    Validation Batch [1/1], Loss: 0.1110\n",
      "Validation Loss: 0.1110, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.1258\n",
      "Validation Loss: 0.1258, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.1079\n",
      "Validation Loss: 0.1079, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0410\n",
      "    Validation Batch [1/1], Loss: 0.0733\n",
      "Validation Loss: 0.0733, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.0524\n",
      "Validation Loss: 0.0524, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.0423\n",
      "Validation Loss: 0.0423, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.0421\n",
      "Validation Loss: 0.0421, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.0483\n",
      "Validation Loss: 0.0483, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0397\n",
      "    Validation Batch [1/1], Loss: 0.0611\n",
      "Validation Loss: 0.0611, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.0715\n",
      "Validation Loss: 0.0715, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.0679\n",
      "Validation Loss: 0.0679, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.0613\n",
      "Validation Loss: 0.0613, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.0506\n",
      "Validation Loss: 0.0506, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0428\n",
      "    Validation Batch [1/1], Loss: 0.0425\n",
      "Validation Loss: 0.0425, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.0410\n",
      "Validation Loss: 0.0410, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.0381\n",
      "Validation Loss: 0.0381, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0440\n",
      "    Validation Batch [1/1], Loss: 0.0353\n",
      "Validation Loss: 0.0353, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.0379\n",
      "Validation Loss: 0.0379, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0547\n",
      "Validation Loss: 0.0547, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.0767\n",
      "Validation Loss: 0.0767, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.0897\n",
      "Validation Loss: 0.0897, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0343\n",
      "    Validation Batch [1/1], Loss: 0.0880\n",
      "Validation Loss: 0.0880, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.0764\n",
      "Validation Loss: 0.0764, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0394\n",
      "    Validation Batch [1/1], Loss: 0.0670\n",
      "Validation Loss: 0.0670, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0389\n",
      "    Validation Batch [1/1], Loss: 0.0550\n",
      "Validation Loss: 0.0550, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.0523\n",
      "Validation Loss: 0.0523, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.0519\n",
      "Validation Loss: 0.0519, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.0546\n",
      "Validation Loss: 0.0546, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0332\n",
      "    Validation Batch [1/1], Loss: 0.0581\n",
      "Validation Loss: 0.0581, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.0615\n",
      "Validation Loss: 0.0615, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.0683\n",
      "Validation Loss: 0.0683, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.0747\n",
      "Validation Loss: 0.0747, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.0719\n",
      "Validation Loss: 0.0719, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0270\n",
      "    Validation Batch [1/1], Loss: 0.0699\n",
      "Validation Loss: 0.0699, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.0735\n",
      "Validation Loss: 0.0735, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.0781\n",
      "Validation Loss: 0.0781, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0801\n",
      "Validation Loss: 0.0801, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.0612\n",
      "Validation Loss: 0.0612, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [562/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.0518\n",
      "Validation Loss: 0.0518, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.0375\n",
      "Validation Loss: 0.0375, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0303\n",
      "Validation Loss: 0.0303, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0339 to 0.0303. Saving model...\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.0283\n",
      "Validation Loss: 0.0283, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0303 to 0.0283. Saving model...\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0288\n",
      "    Validation Batch [1/1], Loss: 0.0290\n",
      "Validation Loss: 0.0290, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.0341\n",
      "Validation Loss: 0.0341, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.0431\n",
      "Validation Loss: 0.0431, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.0576\n",
      "Validation Loss: 0.0576, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.0627\n",
      "Validation Loss: 0.0627, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0638\n",
      "Validation Loss: 0.0638, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.0574\n",
      "Validation Loss: 0.0574, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.0511\n",
      "Validation Loss: 0.0511, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.0452\n",
      "Validation Loss: 0.0452, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.0437\n",
      "Validation Loss: 0.0437, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0496\n",
      "Validation Loss: 0.0496, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.0448\n",
      "Validation Loss: 0.0448, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0449\n",
      "Validation Loss: 0.0449, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.0482\n",
      "Validation Loss: 0.0482, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0489\n",
      "Validation Loss: 0.0489, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0537\n",
      "Validation Loss: 0.0537, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0647\n",
      "Validation Loss: 0.0647, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.0641\n",
      "Validation Loss: 0.0641, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0649\n",
      "Validation Loss: 0.0649, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.0639\n",
      "Validation Loss: 0.0639, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0339\n",
      "    Validation Batch [1/1], Loss: 0.0629\n",
      "Validation Loss: 0.0629, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0281\n",
      "    Validation Batch [1/1], Loss: 0.0699\n",
      "Validation Loss: 0.0699, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0299\n",
      "    Validation Batch [1/1], Loss: 0.0697\n",
      "Validation Loss: 0.0697, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0279\n",
      "    Validation Batch [1/1], Loss: 0.0608\n",
      "Validation Loss: 0.0608, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0335\n",
      "    Validation Batch [1/1], Loss: 0.0420\n",
      "Validation Loss: 0.0420, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [592/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.0391\n",
      "Validation Loss: 0.0391, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.0323\n",
      "Validation Loss: 0.0323, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.0302\n",
      "Validation Loss: 0.0302, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.0323\n",
      "Validation Loss: 0.0323, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.0406\n",
      "Validation Loss: 0.0406, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0299\n",
      "    Validation Batch [1/1], Loss: 0.0566\n",
      "Validation Loss: 0.0566, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0343\n",
      "    Validation Batch [1/1], Loss: 0.0796\n",
      "Validation Loss: 0.0796, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0859\n",
      "Validation Loss: 0.0859, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0796\n",
      "Validation Loss: 0.0796, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0305\n",
      "    Validation Batch [1/1], Loss: 0.0549\n",
      "Validation Loss: 0.0549, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0477\n",
      "Validation Loss: 0.0477, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.0397\n",
      "Validation Loss: 0.0397, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.0292\n",
      "Validation Loss: 0.0292, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.0356\n",
      "Validation Loss: 0.0356, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.0570\n",
      "Validation Loss: 0.0570, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.0486\n",
      "Validation Loss: 0.0486, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.0369\n",
      "Validation Loss: 0.0369, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.0473\n",
      "Validation Loss: 0.0473, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.0769\n",
      "Validation Loss: 0.0769, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0217\n",
      "    Validation Batch [1/1], Loss: 0.0976\n",
      "Validation Loss: 0.0976, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.1011\n",
      "Validation Loss: 0.1011, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0892\n",
      "Validation Loss: 0.0892, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.0634\n",
      "Validation Loss: 0.0634, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.0427\n",
      "Validation Loss: 0.0427, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.0377\n",
      "Validation Loss: 0.0377, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0397\n",
      "Validation Loss: 0.0397, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0467\n",
      "Validation Loss: 0.0467, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0523\n",
      "Validation Loss: 0.0523, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0615\n",
      "Validation Loss: 0.0615, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0757\n",
      "Validation Loss: 0.0757, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0276\n",
      "    Validation Batch [1/1], Loss: 0.0841\n",
      "Validation Loss: 0.0841, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.0933\n",
      "Validation Loss: 0.0933, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.0927\n",
      "Validation Loss: 0.0927, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0884\n",
      "Validation Loss: 0.0884, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0697\n",
      "Validation Loss: 0.0697, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.0629\n",
      "Validation Loss: 0.0629, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0683\n",
      "Validation Loss: 0.0683, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0330\n",
      "    Validation Batch [1/1], Loss: 0.0751\n",
      "Validation Loss: 0.0751, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0339\n",
      "    Validation Batch [1/1], Loss: 0.0597\n",
      "Validation Loss: 0.0597, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.0494\n",
      "Validation Loss: 0.0494, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0528\n",
      "Validation Loss: 0.0528, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.0607\n",
      "Validation Loss: 0.0607, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0694\n",
      "Validation Loss: 0.0694, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.0750\n",
      "Validation Loss: 0.0750, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0744\n",
      "Validation Loss: 0.0744, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0679\n",
      "Validation Loss: 0.0679, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.0631\n",
      "Validation Loss: 0.0631, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.0554\n",
      "Validation Loss: 0.0554, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0427\n",
      "Validation Loss: 0.0427, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0461\n",
      "Validation Loss: 0.0461, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0495\n",
      "Validation Loss: 0.0495, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0180\n",
      "    Validation Batch [1/1], Loss: 0.0583\n",
      "Validation Loss: 0.0583, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.0548\n",
      "Validation Loss: 0.0548, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0386\n",
      "Validation Loss: 0.0386, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0314\n",
      "Validation Loss: 0.0314, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0275\n",
      "Validation Loss: 0.0275, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0283 to 0.0275. Saving model...\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0264\n",
      "Validation Loss: 0.0264, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0275 to 0.0264. Saving model...\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.0300\n",
      "Validation Loss: 0.0300, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0386\n",
      "Validation Loss: 0.0386, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.0579\n",
      "Validation Loss: 0.0579, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0723\n",
      "Validation Loss: 0.0723, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0871\n",
      "Validation Loss: 0.0871, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0942\n",
      "Validation Loss: 0.0942, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.1009\n",
      "Validation Loss: 0.1009, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.0996\n",
      "Validation Loss: 0.0996, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0775\n",
      "Validation Loss: 0.0775, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.0647\n",
      "Validation Loss: 0.0647, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.0726\n",
      "Validation Loss: 0.0726, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0720\n",
      "Validation Loss: 0.0720, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0281\n",
      "    Validation Batch [1/1], Loss: 0.0570\n",
      "Validation Loss: 0.0570, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0533\n",
      "Validation Loss: 0.0533, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.0699\n",
      "Validation Loss: 0.0699, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.1009\n",
      "Validation Loss: 0.1009, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.1329\n",
      "Validation Loss: 0.1329, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.1361\n",
      "Validation Loss: 0.1361, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.1121\n",
      "Validation Loss: 0.1121, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.1004\n",
      "Validation Loss: 0.1004, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.0796\n",
      "Validation Loss: 0.0796, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.0513\n",
      "Validation Loss: 0.0513, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0240\n",
      "    Validation Batch [1/1], Loss: 0.0322\n",
      "Validation Loss: 0.0322, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.0231\n",
      "Validation Loss: 0.0231, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0264 to 0.0231. Saving model...\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0220\n",
      "Validation Loss: 0.0220, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0231 to 0.0220. Saving model...\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0265\n",
      "Validation Loss: 0.0265, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0350\n",
      "Validation Loss: 0.0350, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0220\n",
      "    Validation Batch [1/1], Loss: 0.0580\n",
      "Validation Loss: 0.0580, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.0904\n",
      "Validation Loss: 0.0904, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [680/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.1109\n",
      "Validation Loss: 0.1109, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.1046\n",
      "Validation Loss: 0.1046, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0879\n",
      "Validation Loss: 0.0879, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.0551\n",
      "Validation Loss: 0.0551, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0344\n",
      "Validation Loss: 0.0344, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0276\n",
      "Validation Loss: 0.0276, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0260\n",
      "Validation Loss: 0.0260, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.0232\n",
      "Validation Loss: 0.0232, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.0211\n",
      "Validation Loss: 0.0211, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0220 to 0.0211. Saving model...\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0222\n",
      "    Validation Batch [1/1], Loss: 0.0199\n",
      "Validation Loss: 0.0199, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0211 to 0.0199. Saving model...\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.0254\n",
      "Validation Loss: 0.0254, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0250\n",
      "    Validation Batch [1/1], Loss: 0.0430\n",
      "Validation Loss: 0.0430, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0155\n",
      "    Validation Batch [1/1], Loss: 0.0722\n",
      "Validation Loss: 0.0722, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.1049\n",
      "Validation Loss: 0.1049, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.1228\n",
      "Validation Loss: 0.1228, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.1244\n",
      "Validation Loss: 0.1244, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0196\n",
      "    Validation Batch [1/1], Loss: 0.0933\n",
      "Validation Loss: 0.0933, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0550\n",
      "Validation Loss: 0.0550, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.0327\n",
      "Validation Loss: 0.0327, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0180\n",
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.0214\n",
      "Validation Loss: 0.0214, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.0206\n",
      "Validation Loss: 0.0206, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0249\n",
      "Validation Loss: 0.0249, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0171\n",
      "    Validation Batch [1/1], Loss: 0.0371\n",
      "Validation Loss: 0.0371, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0539\n",
      "Validation Loss: 0.0539, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.0628\n",
      "Validation Loss: 0.0628, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0545\n",
      "Validation Loss: 0.0545, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.0418\n",
      "Validation Loss: 0.0418, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0152\n",
      "    Validation Batch [1/1], Loss: 0.0337\n",
      "Validation Loss: 0.0337, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0326\n",
      "Validation Loss: 0.0326, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.0349\n",
      "Validation Loss: 0.0349, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0422\n",
      "Validation Loss: 0.0422, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0487\n",
      "Validation Loss: 0.0487, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0574\n",
      "Validation Loss: 0.0574, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0590\n",
      "Validation Loss: 0.0590, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0659\n",
      "Validation Loss: 0.0659, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.0767\n",
      "Validation Loss: 0.0767, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.0716\n",
      "Validation Loss: 0.0716, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.0740\n",
      "Validation Loss: 0.0740, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.0731\n",
      "Validation Loss: 0.0731, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0125\n",
      "    Validation Batch [1/1], Loss: 0.0661\n",
      "Validation Loss: 0.0661, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.0582\n",
      "Validation Loss: 0.0582, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0180\n",
      "    Validation Batch [1/1], Loss: 0.0582\n",
      "Validation Loss: 0.0582, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.0589\n",
      "Validation Loss: 0.0589, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0131\n",
      "    Validation Batch [1/1], Loss: 0.0552\n",
      "Validation Loss: 0.0552, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.0480\n",
      "Validation Loss: 0.0480, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0468\n",
      "Validation Loss: 0.0468, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.0481\n",
      "Validation Loss: 0.0481, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0494\n",
      "Validation Loss: 0.0494, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0545\n",
      "Validation Loss: 0.0545, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0433\n",
      "Validation Loss: 0.0433, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0352\n",
      "Validation Loss: 0.0352, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0265\n",
      "Validation Loss: 0.0265, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0165\n",
      "    Validation Batch [1/1], Loss: 0.0208\n",
      "Validation Loss: 0.0208, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0249\n",
      "Validation Loss: 0.0249, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.0497\n",
      "Validation Loss: 0.0497, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.0872\n",
      "Validation Loss: 0.0872, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [739/1000] completed, Average Training Loss: 0.0142\n",
      "    Validation Batch [1/1], Loss: 0.0717\n",
      "Validation Loss: 0.0717, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0577\n",
      "Validation Loss: 0.0577, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.0575\n",
      "Validation Loss: 0.0575, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0147\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0748\n",
      "Validation Loss: 0.0748, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0793\n",
      "Validation Loss: 0.0793, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0817\n",
      "Validation Loss: 0.0817, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n",
      "Epoch [746/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.0819\n",
      "Validation Loss: 0.0819, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0813\n",
      "Validation Loss: 0.0813, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.0860\n",
      "Validation Loss: 0.0860, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.0960\n",
      "Validation Loss: 0.0960, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.0881\n",
      "Validation Loss: 0.0881, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.0826\n",
      "Validation Loss: 0.0826, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0825\n",
      "Validation Loss: 0.0825, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0182\n",
      "    Validation Batch [1/1], Loss: 0.0790\n",
      "Validation Loss: 0.0790, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.0721\n",
      "Validation Loss: 0.0721, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.0710\n",
      "Validation Loss: 0.0710, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0130\n",
      "    Validation Batch [1/1], Loss: 0.0688\n",
      "Validation Loss: 0.0688, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0143\n",
      "    Validation Batch [1/1], Loss: 0.0719\n",
      "Validation Loss: 0.0719, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0169\n",
      "    Validation Batch [1/1], Loss: 0.0750\n",
      "Validation Loss: 0.0750, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0220\n",
      "    Validation Batch [1/1], Loss: 0.0849\n",
      "Validation Loss: 0.0849, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.1079\n",
      "Validation Loss: 0.1079, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.1387\n",
      "Validation Loss: 0.1387, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0145\n",
      "    Validation Batch [1/1], Loss: 0.1616\n",
      "Validation Loss: 0.1616, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.1809\n",
      "Validation Loss: 0.1809, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0185\n",
      "    Validation Batch [1/1], Loss: 0.1846\n",
      "Validation Loss: 0.1846, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0140\n",
      "    Validation Batch [1/1], Loss: 0.1731\n",
      "Validation Loss: 0.1731, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.1644\n",
      "Validation Loss: 0.1644, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.1307\n",
      "Validation Loss: 0.1307, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [768/1000] completed, Average Training Loss: 0.0160\n",
      "    Validation Batch [1/1], Loss: 0.1006\n",
      "Validation Loss: 0.1006, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0152\n",
      "    Validation Batch [1/1], Loss: 0.0685\n",
      "Validation Loss: 0.0685, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0143\n",
      "    Validation Batch [1/1], Loss: 0.0546\n",
      "Validation Loss: 0.0546, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0154\n",
      "    Validation Batch [1/1], Loss: 0.0470\n",
      "Validation Loss: 0.0470, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0134\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0741\n",
      "Validation Loss: 0.0741, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0155\n",
      "    Validation Batch [1/1], Loss: 0.0894\n",
      "Validation Loss: 0.0894, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0180\n",
      "    Validation Batch [1/1], Loss: 0.0872\n",
      "Validation Loss: 0.0872, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n",
      "Epoch [776/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0785\n",
      "Validation Loss: 0.0785, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0169\n",
      "    Validation Batch [1/1], Loss: 0.0652\n",
      "Validation Loss: 0.0652, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.0521\n",
      "Validation Loss: 0.0521, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0381\n",
      "Validation Loss: 0.0381, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n",
      "Epoch [780/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.0260\n",
      "Validation Loss: 0.0260, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n",
      "Epoch [781/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0196\n",
      "Validation Loss: 0.0196, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0199 to 0.0196. Saving model...\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0172\n",
      "Validation Loss: 0.0172, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0196 to 0.0172. Saving model...\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0136\n",
      "    Validation Batch [1/1], Loss: 0.0161\n",
      "Validation Loss: 0.0161, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0172 to 0.0161. Saving model...\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0171\n",
      "    Validation Batch [1/1], Loss: 0.0160\n",
      "Validation Loss: 0.0160, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0161 to 0.0160. Saving model...\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n",
      "Epoch [785/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0177\n",
      "Validation Loss: 0.0177, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0155\n",
      "    Validation Batch [1/1], Loss: 0.0198\n",
      "Validation Loss: 0.0198, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0155\n",
      "    Validation Batch [1/1], Loss: 0.0258\n",
      "Validation Loss: 0.0258, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0379\n",
      "Validation Loss: 0.0379, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.0463\n",
      "Validation Loss: 0.0463, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0579\n",
      "Validation Loss: 0.0579, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0160\n",
      "    Validation Batch [1/1], Loss: 0.0625\n",
      "Validation Loss: 0.0625, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n",
      "Epoch [792/1000] completed, Average Training Loss: 0.0143\n",
      "    Validation Batch [1/1], Loss: 0.0609\n",
      "Validation Loss: 0.0609, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0610\n",
      "Validation Loss: 0.0610, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0490\n",
      "Validation Loss: 0.0490, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0329\n",
      "Validation Loss: 0.0329, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0166\n",
      "    Validation Batch [1/1], Loss: 0.0315\n",
      "Validation Loss: 0.0315, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0167\n",
      "    Validation Batch [1/1], Loss: 0.0329\n",
      "Validation Loss: 0.0329, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.0378\n",
      "Validation Loss: 0.0378, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0376\n",
      "Validation Loss: 0.0376, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n",
      "Epoch [800/1000] completed, Average Training Loss: 0.0144\n",
      "    Validation Batch [1/1], Loss: 0.0364\n",
      "Validation Loss: 0.0364, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.0391\n",
      "Validation Loss: 0.0391, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0460\n",
      "Validation Loss: 0.0460, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n",
      "Epoch [803/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.0573\n",
      "Validation Loss: 0.0573, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0746\n",
      "Validation Loss: 0.0746, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n",
      "Epoch [805/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.0743\n",
      "Validation Loss: 0.0743, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0718\n",
      "Validation Loss: 0.0718, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0133\n",
      "    Validation Batch [1/1], Loss: 0.0693\n",
      "Validation Loss: 0.0693, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0139\n",
      "    Validation Batch [1/1], Loss: 0.0630\n",
      "Validation Loss: 0.0630, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n",
      "Epoch [809/1000] completed, Average Training Loss: 0.0146\n",
      "    Validation Batch [1/1], Loss: 0.0577\n",
      "Validation Loss: 0.0577, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0139\n",
      "    Validation Batch [1/1], Loss: 0.0502\n",
      "Validation Loss: 0.0502, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0444\n",
      "Validation Loss: 0.0444, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0470\n",
      "Validation Loss: 0.0470, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0132\n",
      "    Validation Batch [1/1], Loss: 0.0485\n",
      "Validation Loss: 0.0485, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n",
      "Epoch [814/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0526\n",
      "Validation Loss: 0.0526, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0680\n",
      "Validation Loss: 0.0680, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0122\n",
      "    Validation Batch [1/1], Loss: 0.0843\n",
      "Validation Loss: 0.0843, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0743\n",
      "Validation Loss: 0.0743, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0163\n",
      "    Validation Batch [1/1], Loss: 0.0642\n",
      "Validation Loss: 0.0642, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0531\n",
      "Validation Loss: 0.0531, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0438\n",
      "Validation Loss: 0.0438, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0103\n",
      "    Validation Batch [1/1], Loss: 0.0373\n",
      "Validation Loss: 0.0373, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.0372\n",
      "Validation Loss: 0.0372, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n",
      "Epoch [823/1000] completed, Average Training Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0392\n",
      "Validation Loss: 0.0392, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n",
      "Epoch [824/1000] completed, Average Training Loss: 0.0136\n",
      "    Validation Batch [1/1], Loss: 0.0479\n",
      "Validation Loss: 0.0479, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n",
      "Epoch [825/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0114\n",
      "    Validation Batch [1/1], Loss: 0.0623\n",
      "Validation Loss: 0.0623, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n",
      "Epoch [827/1000] completed, Average Training Loss: 0.0152\n",
      "    Validation Batch [1/1], Loss: 0.0724\n",
      "Validation Loss: 0.0724, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n",
      "Epoch [828/1000] completed, Average Training Loss: 0.0124\n",
      "    Validation Batch [1/1], Loss: 0.0792\n",
      "Validation Loss: 0.0792, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0126\n",
      "    Validation Batch [1/1], Loss: 0.0754\n",
      "Validation Loss: 0.0754, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [830/1000] - Training\n",
      "Epoch [830/1000] completed, Average Training Loss: 0.0125\n",
      "    Validation Batch [1/1], Loss: 0.0706\n",
      "Validation Loss: 0.0706, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [831/1000] - Training\n",
      "Epoch [831/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0642\n",
      "Validation Loss: 0.0642, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [832/1000] - Training\n",
      "Epoch [832/1000] completed, Average Training Loss: 0.0137\n",
      "    Validation Batch [1/1], Loss: 0.0578\n",
      "Validation Loss: 0.0578, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [833/1000] - Training\n",
      "Epoch [833/1000] completed, Average Training Loss: 0.0109\n",
      "    Validation Batch [1/1], Loss: 0.0511\n",
      "Validation Loss: 0.0511, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [834/1000] - Training\n",
      "Epoch [834/1000] completed, Average Training Loss: 0.0121\n",
      "    Validation Batch [1/1], Loss: 0.0446\n",
      "Validation Loss: 0.0446, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [835/1000] - Training\n",
      "Epoch [835/1000] completed, Average Training Loss: 0.0149\n",
      "    Validation Batch [1/1], Loss: 0.0433\n",
      "Validation Loss: 0.0433, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [836/1000] - Training\n",
      "Epoch [836/1000] completed, Average Training Loss: 0.0103\n",
      "    Validation Batch [1/1], Loss: 0.0528\n",
      "Validation Loss: 0.0528, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [837/1000] - Training\n",
      "Epoch [837/1000] completed, Average Training Loss: 0.0146\n",
      "    Validation Batch [1/1], Loss: 0.0840\n",
      "Validation Loss: 0.0840, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [838/1000] - Training\n",
      "Epoch [838/1000] completed, Average Training Loss: 0.0121\n",
      "    Validation Batch [1/1], Loss: 0.1410\n",
      "Validation Loss: 0.1410, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [839/1000] - Training\n",
      "Epoch [839/1000] completed, Average Training Loss: 0.0146\n",
      "    Validation Batch [1/1], Loss: 0.1082\n",
      "Validation Loss: 0.1082, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [840/1000] - Training\n",
      "Epoch [840/1000] completed, Average Training Loss: 0.0141\n",
      "    Validation Batch [1/1], Loss: 0.0993\n",
      "Validation Loss: 0.0993, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [841/1000] - Training\n",
      "Epoch [841/1000] completed, Average Training Loss: 0.0134\n",
      "    Validation Batch [1/1], Loss: 0.0978\n",
      "Validation Loss: 0.0978, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [842/1000] - Training\n",
      "Epoch [842/1000] completed, Average Training Loss: 0.0143\n",
      "    Validation Batch [1/1], Loss: 0.0911\n",
      "Validation Loss: 0.0911, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [843/1000] - Training\n",
      "Epoch [843/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0840\n",
      "Validation Loss: 0.0840, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [844/1000] - Training\n",
      "Epoch [844/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0741\n",
      "Validation Loss: 0.0741, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [845/1000] - Training\n",
      "Epoch [845/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0408\n",
      "Validation Loss: 0.0408, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [846/1000] - Training\n",
      "Epoch [846/1000] completed, Average Training Loss: 0.0128\n",
      "    Validation Batch [1/1], Loss: 0.0227\n",
      "Validation Loss: 0.0227, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [847/1000] - Training\n",
      "Epoch [847/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0161\n",
      "Validation Loss: 0.0161, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [848/1000] - Training\n",
      "Epoch [848/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0165\n",
      "Validation Loss: 0.0165, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [849/1000] - Training\n",
      "Epoch [849/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0205\n",
      "Validation Loss: 0.0205, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [850/1000] - Training\n",
      "Epoch [850/1000] completed, Average Training Loss: 0.0134\n",
      "    Validation Batch [1/1], Loss: 0.0230\n",
      "Validation Loss: 0.0230, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [851/1000] - Training\n",
      "Epoch [851/1000] completed, Average Training Loss: 0.0146\n",
      "    Validation Batch [1/1], Loss: 0.0295\n",
      "Validation Loss: 0.0295, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [852/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [852/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.0379\n",
      "Validation Loss: 0.0379, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [853/1000] - Training\n",
      "Epoch [853/1000] completed, Average Training Loss: 0.0116\n",
      "    Validation Batch [1/1], Loss: 0.0423\n",
      "Validation Loss: 0.0423, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [854/1000] - Training\n",
      "Epoch [854/1000] completed, Average Training Loss: 0.0116\n",
      "    Validation Batch [1/1], Loss: 0.0465\n",
      "Validation Loss: 0.0465, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [855/1000] - Training\n",
      "Epoch [855/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0402\n",
      "Validation Loss: 0.0402, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [856/1000] - Training\n",
      "Epoch [856/1000] completed, Average Training Loss: 0.0136\n",
      "    Validation Batch [1/1], Loss: 0.0342\n",
      "Validation Loss: 0.0342, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [857/1000] - Training\n",
      "Epoch [857/1000] completed, Average Training Loss: 0.0111\n",
      "    Validation Batch [1/1], Loss: 0.0279\n",
      "Validation Loss: 0.0279, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [858/1000] - Training\n",
      "Epoch [858/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0198\n",
      "Validation Loss: 0.0198, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [859/1000] - Training\n",
      "Epoch [859/1000] completed, Average Training Loss: 0.0106\n",
      "    Validation Batch [1/1], Loss: 0.0143\n",
      "Validation Loss: 0.0143, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0160 to 0.0143. Saving model...\n",
      "\n",
      "LOG: Epoch [860/1000] - Training\n",
      "Epoch [860/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.0156\n",
      "Validation Loss: 0.0156, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [861/1000] - Training\n",
      "Epoch [861/1000] completed, Average Training Loss: 0.0122\n",
      "    Validation Batch [1/1], Loss: 0.0236\n",
      "Validation Loss: 0.0236, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [862/1000] - Training\n",
      "Epoch [862/1000] completed, Average Training Loss: 0.0138\n",
      "    Validation Batch [1/1], Loss: 0.0443\n",
      "Validation Loss: 0.0443, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [863/1000] - Training\n",
      "Epoch [863/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0709\n",
      "Validation Loss: 0.0709, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [864/1000] - Training\n",
      "Epoch [864/1000] completed, Average Training Loss: 0.0124\n",
      "    Validation Batch [1/1], Loss: 0.0929\n",
      "Validation Loss: 0.0929, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [865/1000] - Training\n",
      "Epoch [865/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.1020\n",
      "Validation Loss: 0.1020, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [866/1000] - Training\n",
      "Epoch [866/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.1002\n",
      "Validation Loss: 0.1002, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [867/1000] - Training\n",
      "Epoch [867/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0979\n",
      "Validation Loss: 0.0979, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [868/1000] - Training\n",
      "Epoch [868/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0961\n",
      "Validation Loss: 0.0961, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [869/1000] - Training\n",
      "Epoch [869/1000] completed, Average Training Loss: 0.0112\n",
      "    Validation Batch [1/1], Loss: 0.0887\n",
      "Validation Loss: 0.0887, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [870/1000] - Training\n",
      "Epoch [870/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0828\n",
      "Validation Loss: 0.0828, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [871/1000] - Training\n",
      "Epoch [871/1000] completed, Average Training Loss: 0.0112\n",
      "    Validation Batch [1/1], Loss: 0.0723\n",
      "Validation Loss: 0.0723, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [872/1000] - Training\n",
      "Epoch [872/1000] completed, Average Training Loss: 0.0137\n",
      "    Validation Batch [1/1], Loss: 0.0540\n",
      "Validation Loss: 0.0540, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [873/1000] - Training\n",
      "Epoch [873/1000] completed, Average Training Loss: 0.0138\n",
      "    Validation Batch [1/1], Loss: 0.0294\n",
      "Validation Loss: 0.0294, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [874/1000] - Training\n",
      "Epoch [874/1000] completed, Average Training Loss: 0.0131\n",
      "    Validation Batch [1/1], Loss: 0.0179\n",
      "Validation Loss: 0.0179, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [875/1000] - Training\n",
      "Epoch [875/1000] completed, Average Training Loss: 0.0103\n",
      "    Validation Batch [1/1], Loss: 0.0132\n",
      "Validation Loss: 0.0132, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0143 to 0.0132. Saving model...\n",
      "\n",
      "LOG: Epoch [876/1000] - Training\n",
      "Epoch [876/1000] completed, Average Training Loss: 0.0108\n",
      "    Validation Batch [1/1], Loss: 0.0127\n",
      "Validation Loss: 0.0127, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0132 to 0.0127. Saving model...\n",
      "\n",
      "LOG: Epoch [877/1000] - Training\n",
      "Epoch [877/1000] completed, Average Training Loss: 0.0113\n",
      "    Validation Batch [1/1], Loss: 0.0151\n",
      "Validation Loss: 0.0151, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [878/1000] - Training\n",
      "Epoch [878/1000] completed, Average Training Loss: 0.0130\n",
      "    Validation Batch [1/1], Loss: 0.0191\n",
      "Validation Loss: 0.0191, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [879/1000] - Training\n",
      "Epoch [879/1000] completed, Average Training Loss: 0.0136\n",
      "    Validation Batch [1/1], Loss: 0.0406\n",
      "Validation Loss: 0.0406, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [880/1000] - Training\n",
      "Epoch [880/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0716\n",
      "Validation Loss: 0.0716, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [881/1000] - Training\n",
      "Epoch [881/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0971\n",
      "Validation Loss: 0.0971, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [882/1000] - Training\n",
      "Epoch [882/1000] completed, Average Training Loss: 0.0123\n",
      "    Validation Batch [1/1], Loss: 0.1022\n",
      "Validation Loss: 0.1022, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [883/1000] - Training\n",
      "Epoch [883/1000] completed, Average Training Loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1029\n",
      "Validation Loss: 0.1029, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [884/1000] - Training\n",
      "Epoch [884/1000] completed, Average Training Loss: 0.0139\n",
      "    Validation Batch [1/1], Loss: 0.0882\n",
      "Validation Loss: 0.0882, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [885/1000] - Training\n",
      "Epoch [885/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0721\n",
      "Validation Loss: 0.0721, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [886/1000] - Training\n",
      "Epoch [886/1000] completed, Average Training Loss: 0.0116\n",
      "    Validation Batch [1/1], Loss: 0.0518\n",
      "Validation Loss: 0.0518, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [887/1000] - Training\n",
      "Epoch [887/1000] completed, Average Training Loss: 0.0139\n",
      "    Validation Batch [1/1], Loss: 0.0315\n",
      "Validation Loss: 0.0315, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [888/1000] - Training\n",
      "Epoch [888/1000] completed, Average Training Loss: 0.0128\n",
      "    Validation Batch [1/1], Loss: 0.0199\n",
      "Validation Loss: 0.0199, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [889/1000] - Training\n",
      "Epoch [889/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.0161\n",
      "Validation Loss: 0.0161, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [890/1000] - Training\n",
      "Epoch [890/1000] completed, Average Training Loss: 0.0124\n",
      "    Validation Batch [1/1], Loss: 0.0155\n",
      "Validation Loss: 0.0155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [891/1000] - Training\n",
      "Epoch [891/1000] completed, Average Training Loss: 0.0122\n",
      "    Validation Batch [1/1], Loss: 0.0228\n",
      "Validation Loss: 0.0228, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [892/1000] - Training\n",
      "Epoch [892/1000] completed, Average Training Loss: 0.0145\n",
      "    Validation Batch [1/1], Loss: 0.0453\n",
      "Validation Loss: 0.0453, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [893/1000] - Training\n",
      "Epoch [893/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0745\n",
      "Validation Loss: 0.0745, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [894/1000] - Training\n",
      "Epoch [894/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0941\n",
      "Validation Loss: 0.0941, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [895/1000] - Training\n",
      "Epoch [895/1000] completed, Average Training Loss: 0.0126\n",
      "    Validation Batch [1/1], Loss: 0.0959\n",
      "Validation Loss: 0.0959, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [896/1000] - Training\n",
      "Epoch [896/1000] completed, Average Training Loss: 0.0102\n",
      "    Validation Batch [1/1], Loss: 0.0833\n",
      "Validation Loss: 0.0833, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [897/1000] - Training\n",
      "Epoch [897/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0689\n",
      "Validation Loss: 0.0689, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [898/1000] - Training\n",
      "Epoch [898/1000] completed, Average Training Loss: 0.0092\n",
      "    Validation Batch [1/1], Loss: 0.0556\n",
      "Validation Loss: 0.0556, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [899/1000] - Training\n",
      "Epoch [899/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0357\n",
      "Validation Loss: 0.0357, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [900/1000] - Training\n",
      "Epoch [900/1000] completed, Average Training Loss: 0.0130\n",
      "    Validation Batch [1/1], Loss: 0.0254\n",
      "Validation Loss: 0.0254, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [901/1000] - Training\n",
      "Epoch [901/1000] completed, Average Training Loss: 0.0138\n",
      "    Validation Batch [1/1], Loss: 0.0180\n",
      "Validation Loss: 0.0180, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [902/1000] - Training\n",
      "Epoch [902/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0155\n",
      "Validation Loss: 0.0155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [903/1000] - Training\n",
      "Epoch [903/1000] completed, Average Training Loss: 0.0087\n",
      "    Validation Batch [1/1], Loss: 0.0130\n",
      "Validation Loss: 0.0130, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [904/1000] - Training\n",
      "Epoch [904/1000] completed, Average Training Loss: 0.0149\n",
      "    Validation Batch [1/1], Loss: 0.0116\n",
      "Validation Loss: 0.0116, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0127 to 0.0116. Saving model...\n",
      "\n",
      "LOG: Epoch [905/1000] - Training\n",
      "Epoch [905/1000] completed, Average Training Loss: 0.0097\n",
      "    Validation Batch [1/1], Loss: 0.0139\n",
      "Validation Loss: 0.0139, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [906/1000] - Training\n",
      "Epoch [906/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0205\n",
      "Validation Loss: 0.0205, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [907/1000] - Training\n",
      "Epoch [907/1000] completed, Average Training Loss: 0.0089\n",
      "    Validation Batch [1/1], Loss: 0.0314\n",
      "Validation Loss: 0.0314, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [908/1000] - Training\n",
      "Epoch [908/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0405\n",
      "Validation Loss: 0.0405, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [909/1000] - Training\n",
      "Epoch [909/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0415\n",
      "Validation Loss: 0.0415, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [910/1000] - Training\n",
      "Epoch [910/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0397\n",
      "Validation Loss: 0.0397, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [911/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [911/1000] completed, Average Training Loss: 0.0102\n",
      "    Validation Batch [1/1], Loss: 0.0325\n",
      "Validation Loss: 0.0325, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [912/1000] - Training\n",
      "Epoch [912/1000] completed, Average Training Loss: 0.0127\n",
      "    Validation Batch [1/1], Loss: 0.0279\n",
      "Validation Loss: 0.0279, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [913/1000] - Training\n",
      "Epoch [913/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0229\n",
      "Validation Loss: 0.0229, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [914/1000] - Training\n",
      "Epoch [914/1000] completed, Average Training Loss: 0.0096\n",
      "    Validation Batch [1/1], Loss: 0.0205\n",
      "Validation Loss: 0.0205, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [915/1000] - Training\n",
      "Epoch [915/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0190\n",
      "Validation Loss: 0.0190, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [916/1000] - Training\n",
      "Epoch [916/1000] completed, Average Training Loss: 0.0079\n",
      "    Validation Batch [1/1], Loss: 0.0184\n",
      "Validation Loss: 0.0184, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [917/1000] - Training\n",
      "Epoch [917/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0190\n",
      "Validation Loss: 0.0190, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [918/1000] - Training\n",
      "Epoch [918/1000] completed, Average Training Loss: 0.0109\n",
      "    Validation Batch [1/1], Loss: 0.0238\n",
      "Validation Loss: 0.0238, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [919/1000] - Training\n",
      "Epoch [919/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0280\n",
      "Validation Loss: 0.0280, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [920/1000] - Training\n",
      "Epoch [920/1000] completed, Average Training Loss: 0.0126\n",
      "    Validation Batch [1/1], Loss: 0.0289\n",
      "Validation Loss: 0.0289, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [921/1000] - Training\n",
      "Epoch [921/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0321\n",
      "Validation Loss: 0.0321, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [922/1000] - Training\n",
      "Epoch [922/1000] completed, Average Training Loss: 0.0114\n",
      "    Validation Batch [1/1], Loss: 0.0357\n",
      "Validation Loss: 0.0357, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [923/1000] - Training\n",
      "Epoch [923/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0440\n",
      "Validation Loss: 0.0440, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [924/1000] - Training\n",
      "Epoch [924/1000] completed, Average Training Loss: 0.0112\n",
      "    Validation Batch [1/1], Loss: 0.0302\n",
      "Validation Loss: 0.0302, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [925/1000] - Training\n",
      "Epoch [925/1000] completed, Average Training Loss: 0.0069\n",
      "    Validation Batch [1/1], Loss: 0.0238\n",
      "Validation Loss: 0.0238, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [926/1000] - Training\n",
      "Epoch [926/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0215\n",
      "Validation Loss: 0.0215, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [927/1000] - Training\n",
      "Epoch [927/1000] completed, Average Training Loss: 0.0100\n",
      "    Validation Batch [1/1], Loss: 0.0250\n",
      "Validation Loss: 0.0250, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [928/1000] - Training\n",
      "Epoch [928/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0364\n",
      "Validation Loss: 0.0364, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [929/1000] - Training\n",
      "Epoch [929/1000] completed, Average Training Loss: 0.0119\n",
      "    Validation Batch [1/1], Loss: 0.0487\n",
      "Validation Loss: 0.0487, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [930/1000] - Training\n",
      "Epoch [930/1000] completed, Average Training Loss: 0.0117\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [931/1000] - Training\n",
      "Epoch [931/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0678\n",
      "Validation Loss: 0.0678, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [932/1000] - Training\n",
      "Epoch [932/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0658\n",
      "Validation Loss: 0.0658, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [933/1000] - Training\n",
      "Epoch [933/1000] completed, Average Training Loss: 0.0133\n",
      "    Validation Batch [1/1], Loss: 0.0600\n",
      "Validation Loss: 0.0600, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [934/1000] - Training\n",
      "Epoch [934/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0558\n",
      "Validation Loss: 0.0558, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [935/1000] - Training\n",
      "Epoch [935/1000] completed, Average Training Loss: 0.0108\n",
      "    Validation Batch [1/1], Loss: 0.0522\n",
      "Validation Loss: 0.0522, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [936/1000] - Training\n",
      "Epoch [936/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0466\n",
      "Validation Loss: 0.0466, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [937/1000] - Training\n",
      "Epoch [937/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0424\n",
      "Validation Loss: 0.0424, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [938/1000] - Training\n",
      "Epoch [938/1000] completed, Average Training Loss: 0.0068\n",
      "    Validation Batch [1/1], Loss: 0.0402\n",
      "Validation Loss: 0.0402, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [939/1000] - Training\n",
      "Epoch [939/1000] completed, Average Training Loss: 0.0124\n",
      "    Validation Batch [1/1], Loss: 0.0370\n",
      "Validation Loss: 0.0370, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [940/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [940/1000] completed, Average Training Loss: 0.0107\n",
      "    Validation Batch [1/1], Loss: 0.0479\n",
      "Validation Loss: 0.0479, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [941/1000] - Training\n",
      "Epoch [941/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0609\n",
      "Validation Loss: 0.0609, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [942/1000] - Training\n",
      "Epoch [942/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0694\n",
      "Validation Loss: 0.0694, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [943/1000] - Training\n",
      "Epoch [943/1000] completed, Average Training Loss: 0.0123\n",
      "    Validation Batch [1/1], Loss: 0.0788\n",
      "Validation Loss: 0.0788, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [944/1000] - Training\n",
      "Epoch [944/1000] completed, Average Training Loss: 0.0080\n",
      "    Validation Batch [1/1], Loss: 0.0790\n",
      "Validation Loss: 0.0790, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [945/1000] - Training\n",
      "Epoch [945/1000] completed, Average Training Loss: 0.0115\n",
      "    Validation Batch [1/1], Loss: 0.0808\n",
      "Validation Loss: 0.0808, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [946/1000] - Training\n",
      "Epoch [946/1000] completed, Average Training Loss: 0.0129\n",
      "    Validation Batch [1/1], Loss: 0.0830\n",
      "Validation Loss: 0.0830, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [947/1000] - Training\n",
      "Epoch [947/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0769\n",
      "Validation Loss: 0.0769, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [948/1000] - Training\n",
      "Epoch [948/1000] completed, Average Training Loss: 0.0103\n",
      "    Validation Batch [1/1], Loss: 0.0707\n",
      "Validation Loss: 0.0707, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [949/1000] - Training\n",
      "Epoch [949/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0597\n",
      "Validation Loss: 0.0597, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [950/1000] - Training\n",
      "Epoch [950/1000] completed, Average Training Loss: 0.0110\n",
      "    Validation Batch [1/1], Loss: 0.0595\n",
      "Validation Loss: 0.0595, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [951/1000] - Training\n",
      "Epoch [951/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0600\n",
      "Validation Loss: 0.0600, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [952/1000] - Training\n",
      "Epoch [952/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.0423\n",
      "Validation Loss: 0.0423, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [953/1000] - Training\n",
      "Epoch [953/1000] completed, Average Training Loss: 0.0097\n",
      "    Validation Batch [1/1], Loss: 0.0266\n",
      "Validation Loss: 0.0266, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [954/1000] - Training\n",
      "Epoch [954/1000] completed, Average Training Loss: 0.0090\n",
      "    Validation Batch [1/1], Loss: 0.0198\n",
      "Validation Loss: 0.0198, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [955/1000] - Training\n",
      "Epoch [955/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0159\n",
      "Validation Loss: 0.0159, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [956/1000] - Training\n",
      "Epoch [956/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0158\n",
      "Validation Loss: 0.0158, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [957/1000] - Training\n",
      "Epoch [957/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0190\n",
      "Validation Loss: 0.0190, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [958/1000] - Training\n",
      "Epoch [958/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0230\n",
      "Validation Loss: 0.0230, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [959/1000] - Training\n",
      "Epoch [959/1000] completed, Average Training Loss: 0.0131\n",
      "    Validation Batch [1/1], Loss: 0.0255\n",
      "Validation Loss: 0.0255, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [960/1000] - Training\n",
      "Epoch [960/1000] completed, Average Training Loss: 0.0092\n",
      "    Validation Batch [1/1], Loss: 0.0311\n",
      "Validation Loss: 0.0311, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [961/1000] - Training\n",
      "Epoch [961/1000] completed, Average Training Loss: 0.0128\n",
      "    Validation Batch [1/1], Loss: 0.0392\n",
      "Validation Loss: 0.0392, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [962/1000] - Training\n",
      "Epoch [962/1000] completed, Average Training Loss: 0.0108\n",
      "    Validation Batch [1/1], Loss: 0.0486\n",
      "Validation Loss: 0.0486, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [963/1000] - Training\n",
      "Epoch [963/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0597\n",
      "Validation Loss: 0.0597, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [964/1000] - Training\n",
      "Epoch [964/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0666\n",
      "Validation Loss: 0.0666, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [965/1000] - Training\n",
      "Epoch [965/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.0651\n",
      "Validation Loss: 0.0651, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [966/1000] - Training\n",
      "Epoch [966/1000] completed, Average Training Loss: 0.0087\n",
      "    Validation Batch [1/1], Loss: 0.0547\n",
      "Validation Loss: 0.0547, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [967/1000] - Training\n",
      "Epoch [967/1000] completed, Average Training Loss: 0.0093\n",
      "    Validation Batch [1/1], Loss: 0.0451\n",
      "Validation Loss: 0.0451, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [968/1000] - Training\n",
      "Epoch [968/1000] completed, Average Training Loss: 0.0081\n",
      "    Validation Batch [1/1], Loss: 0.0395\n",
      "Validation Loss: 0.0395, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [969/1000] - Training\n",
      "Epoch [969/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0368\n",
      "Validation Loss: 0.0368, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [970/1000] - Training\n",
      "Epoch [970/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0366\n",
      "Validation Loss: 0.0366, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [971/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [971/1000] completed, Average Training Loss: 0.0088\n",
      "    Validation Batch [1/1], Loss: 0.0368\n",
      "Validation Loss: 0.0368, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [972/1000] - Training\n",
      "Epoch [972/1000] completed, Average Training Loss: 0.0101\n",
      "    Validation Batch [1/1], Loss: 0.0373\n",
      "Validation Loss: 0.0373, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [973/1000] - Training\n",
      "Epoch [973/1000] completed, Average Training Loss: 0.0101\n",
      "    Validation Batch [1/1], Loss: 0.0400\n",
      "Validation Loss: 0.0400, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [974/1000] - Training\n",
      "Epoch [974/1000] completed, Average Training Loss: 0.0083\n",
      "    Validation Batch [1/1], Loss: 0.0434\n",
      "Validation Loss: 0.0434, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [975/1000] - Training\n",
      "Epoch [975/1000] completed, Average Training Loss: 0.0101\n",
      "    Validation Batch [1/1], Loss: 0.0441\n",
      "Validation Loss: 0.0441, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [976/1000] - Training\n",
      "Epoch [976/1000] completed, Average Training Loss: 0.0103\n",
      "    Validation Batch [1/1], Loss: 0.0469\n",
      "Validation Loss: 0.0469, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [977/1000] - Training\n",
      "Epoch [977/1000] completed, Average Training Loss: 0.0118\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [978/1000] - Training\n",
      "Epoch [978/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0570\n",
      "Validation Loss: 0.0570, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [979/1000] - Training\n",
      "Epoch [979/1000] completed, Average Training Loss: 0.0079\n",
      "    Validation Batch [1/1], Loss: 0.0662\n",
      "Validation Loss: 0.0662, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [980/1000] - Training\n",
      "Epoch [980/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0736\n",
      "Validation Loss: 0.0736, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [981/1000] - Training\n",
      "Epoch [981/1000] completed, Average Training Loss: 0.0087\n",
      "    Validation Batch [1/1], Loss: 0.0812\n",
      "Validation Loss: 0.0812, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [982/1000] - Training\n",
      "Epoch [982/1000] completed, Average Training Loss: 0.0082\n",
      "    Validation Batch [1/1], Loss: 0.0913\n",
      "Validation Loss: 0.0913, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [983/1000] - Training\n",
      "Epoch [983/1000] completed, Average Training Loss: 0.0105\n",
      "    Validation Batch [1/1], Loss: 0.0970\n",
      "Validation Loss: 0.0970, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [984/1000] - Training\n",
      "Epoch [984/1000] completed, Average Training Loss: 0.0077\n",
      "    Validation Batch [1/1], Loss: 0.0839\n",
      "Validation Loss: 0.0839, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [985/1000] - Training\n",
      "Epoch [985/1000] completed, Average Training Loss: 0.0127\n",
      "    Validation Batch [1/1], Loss: 0.0705\n",
      "Validation Loss: 0.0705, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [986/1000] - Training\n",
      "Epoch [986/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.0674\n",
      "Validation Loss: 0.0674, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [987/1000] - Training\n",
      "Epoch [987/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0776\n",
      "Validation Loss: 0.0776, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [988/1000] - Training\n",
      "Epoch [988/1000] completed, Average Training Loss: 0.0094\n",
      "    Validation Batch [1/1], Loss: 0.0778\n",
      "Validation Loss: 0.0778, Validation Accuracy: 95.56%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [989/1000] - Training\n",
      "Epoch [989/1000] completed, Average Training Loss: 0.0114\n",
      "    Validation Batch [1/1], Loss: 0.0434\n",
      "Validation Loss: 0.0434, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [990/1000] - Training\n",
      "Epoch [990/1000] completed, Average Training Loss: 0.0099\n",
      "    Validation Batch [1/1], Loss: 0.0262\n",
      "Validation Loss: 0.0262, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [991/1000] - Training\n",
      "Epoch [991/1000] completed, Average Training Loss: 0.0108\n",
      "    Validation Batch [1/1], Loss: 0.0188\n",
      "Validation Loss: 0.0188, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [992/1000] - Training\n",
      "Epoch [992/1000] completed, Average Training Loss: 0.0076\n",
      "    Validation Batch [1/1], Loss: 0.0165\n",
      "Validation Loss: 0.0165, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [993/1000] - Training\n",
      "Epoch [993/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.0207\n",
      "Validation Loss: 0.0207, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [994/1000] - Training\n",
      "Epoch [994/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [995/1000] - Training\n",
      "Epoch [995/1000] completed, Average Training Loss: 0.0120\n",
      "    Validation Batch [1/1], Loss: 0.0338\n",
      "Validation Loss: 0.0338, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [996/1000] - Training\n",
      "Epoch [996/1000] completed, Average Training Loss: 0.0121\n",
      "    Validation Batch [1/1], Loss: 0.2733\n",
      "Validation Loss: 0.2733, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [997/1000] - Training\n",
      "Epoch [997/1000] completed, Average Training Loss: 0.0078\n",
      "    Validation Batch [1/1], Loss: 0.3818\n",
      "Validation Loss: 0.3818, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [998/1000] - Training\n",
      "Epoch [998/1000] completed, Average Training Loss: 0.0098\n",
      "    Validation Batch [1/1], Loss: 0.3554\n",
      "Validation Loss: 0.3554, Validation Accuracy: 93.33%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [999/1000] - Training\n",
      "Epoch [999/1000] completed, Average Training Loss: 0.0095\n",
      "    Validation Batch [1/1], Loss: 0.1365\n",
      "Validation Loss: 0.1365, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1000/1000] - Training\n",
      "Epoch [1000/1000] completed, Average Training Loss: 0.0091\n",
      "    Validation Batch [1/1], Loss: 0.1288\n",
      "Validation Loss: 0.1288, Validation Accuracy: 97.78%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/578], Loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.1055, Test Accuracy: 97.80%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:34.070138Z",
     "iopub.status.busy": "2025-05-08T17:29:34.070138Z",
     "iopub.status.idle": "2025-05-08T17:29:36.692730Z",
     "shell.execute_reply": "2025-05-08T17:29:36.692225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/578 for test dataset.\n",
      "  Processed batch 20/578 for test dataset.\n",
      "  Processed batch 30/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 40/578 for test dataset.\n",
      "  Processed batch 50/578 for test dataset.\n",
      "  Processed batch 60/578 for test dataset.\n",
      "  Processed batch 70/578 for test dataset.\n",
      "  Processed batch 80/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 90/578 for test dataset.\n",
      "  Processed batch 100/578 for test dataset.\n",
      "  Processed batch 110/578 for test dataset.\n",
      "  Processed batch 120/578 for test dataset.\n",
      "  Processed batch 130/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 140/578 for test dataset.\n",
      "  Processed batch 150/578 for test dataset.\n",
      "  Processed batch 160/578 for test dataset.\n",
      "  Processed batch 170/578 for test dataset.\n",
      "  Processed batch 180/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 190/578 for test dataset.\n",
      "  Processed batch 200/578 for test dataset.\n",
      "  Processed batch 210/578 for test dataset.\n",
      "  Processed batch 220/578 for test dataset.\n",
      "  Processed batch 230/578 for test dataset.\n",
      "  Processed batch 240/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 250/578 for test dataset.\n",
      "  Processed batch 260/578 for test dataset.\n",
      "  Processed batch 270/578 for test dataset.\n",
      "  Processed batch 280/578 for test dataset.\n",
      "  Processed batch 290/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 300/578 for test dataset.\n",
      "  Processed batch 310/578 for test dataset.\n",
      "  Processed batch 320/578 for test dataset.\n",
      "  Processed batch 330/578 for test dataset.\n",
      "  Processed batch 340/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 350/578 for test dataset.\n",
      "  Processed batch 360/578 for test dataset.\n",
      "  Processed batch 370/578 for test dataset.\n",
      "  Processed batch 380/578 for test dataset.\n",
      "  Processed batch 390/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 400/578 for test dataset.\n",
      "  Processed batch 410/578 for test dataset.\n",
      "  Processed batch 420/578 for test dataset.\n",
      "  Processed batch 430/578 for test dataset.\n",
      "  Processed batch 440/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 450/578 for test dataset.\n",
      "  Processed batch 460/578 for test dataset.\n",
      "  Processed batch 470/578 for test dataset.\n",
      "  Processed batch 480/578 for test dataset.\n",
      "  Processed batch 490/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 500/578 for test dataset.\n",
      "  Processed batch 510/578 for test dataset.\n",
      "  Processed batch 520/578 for test dataset.\n",
      "  Processed batch 530/578 for test dataset.\n",
      "  Processed batch 540/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 550/578 for test dataset.\n",
      "  Processed batch 560/578 for test dataset.\n",
      "  Processed batch 570/578 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:36.696738Z",
     "iopub.status.busy": "2025-05-08T17:29:36.695737Z",
     "iopub.status.idle": "2025-05-08T17:29:36.700756Z",
     "shell.execute_reply": "2025-05-08T17:29:36.700756Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:36.703760Z",
     "iopub.status.busy": "2025-05-08T17:29:36.702760Z",
     "iopub.status.idle": "2025-05-08T17:29:41.986495Z",
     "shell.execute_reply": "2025-05-08T17:29:41.986495Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:41.989510Z",
     "iopub.status.busy": "2025-05-08T17:29:41.989510Z",
     "iopub.status.idle": "2025-05-08T17:29:41.994616Z",
     "shell.execute_reply": "2025-05-08T17:29:41.994616Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:41.996902Z",
     "iopub.status.busy": "2025-05-08T17:29:41.996902Z",
     "iopub.status.idle": "2025-05-08T17:29:46.021802Z",
     "shell.execute_reply": "2025-05-08T17:29:46.021802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "\n",
      "LOG: Training features shape: (180, 64), Training labels shape: (180,)\n",
      "LOG: Validation features shape: (45, 64), Validation labels shape: (45,)\n",
      "LOG: Test features shape: (147927, 64), Test labels shape: (147927,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 97.78%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      0.80      0.89         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       0.83      1.00      0.91         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 96.08%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     65946\n",
      "           1       0.97      0.87      0.91      7573\n",
      "           2       0.69      0.92      0.78      3065\n",
      "           3       0.62      0.90      0.74      2660\n",
      "           4       0.87      0.89      0.88      6559\n",
      "           5       0.84      0.96      0.89      9223\n",
      "           6       0.97      0.81      0.88      7262\n",
      "           7       1.00      0.97      0.98     42801\n",
      "           8       0.99      1.00      1.00      2838\n",
      "\n",
      "    accuracy                           0.96    147927\n",
      "   macro avg       0.88      0.92      0.90    147927\n",
      "weighted avg       0.97      0.96      0.96    147927\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:46.024809Z",
     "iopub.status.busy": "2025-05-08T17:29:46.023808Z",
     "iopub.status.idle": "2025-05-08T17:29:46.028807Z",
     "shell.execute_reply": "2025-05-08T17:29:46.028807Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:46.031025Z",
     "iopub.status.busy": "2025-05-08T17:29:46.031025Z",
     "iopub.status.idle": "2025-05-08T17:29:46.176516Z",
     "shell.execute_reply": "2025-05-08T17:29:46.176011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "Train reps shape: (180, 64)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 64)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 64)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:46.178524Z",
     "iopub.status.busy": "2025-05-08T17:29:46.178524Z",
     "iopub.status.idle": "2025-05-08T17:29:46.188757Z",
     "shell.execute_reply": "2025-05-08T17:29:46.188757Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:46.191763Z",
     "iopub.status.busy": "2025-05-08T17:29:46.191763Z",
     "iopub.status.idle": "2025-05-08T17:29:47.999709Z",
     "shell.execute_reply": "2025-05-08T17:29:47.999709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.1683  |  Val Loss: 2.0363\n",
      "Validation loss improved from inf to 2.0363.\n",
      "[Epoch 2/1000] Train Loss: 1.9992  |  Val Loss: 1.9127\n",
      "Validation loss improved from 2.0363 to 1.9127.\n",
      "[Epoch 3/1000] Train Loss: 1.8752  |  Val Loss: 1.8086\n",
      "Validation loss improved from 1.9127 to 1.8086.\n",
      "[Epoch 4/1000] Train Loss: 1.7676  |  Val Loss: 1.7060\n",
      "Validation loss improved from 1.8086 to 1.7060.\n",
      "[Epoch 5/1000] Train Loss: 1.6637  |  Val Loss: 1.6053\n",
      "Validation loss improved from 1.7060 to 1.6053.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/1000] Train Loss: 1.5671  |  Val Loss: 1.5098\n",
      "Validation loss improved from 1.6053 to 1.5098.\n",
      "[Epoch 7/1000] Train Loss: 1.4788  |  Val Loss: 1.4237\n",
      "Validation loss improved from 1.5098 to 1.4237.\n",
      "[Epoch 8/1000] Train Loss: 1.3940  |  Val Loss: 1.3371\n",
      "Validation loss improved from 1.4237 to 1.3371.\n",
      "[Epoch 9/1000] Train Loss: 1.3124  |  Val Loss: 1.2585\n",
      "Validation loss improved from 1.3371 to 1.2585.\n",
      "[Epoch 10/1000] Train Loss: 1.2314  |  Val Loss: 1.1824\n",
      "Validation loss improved from 1.2585 to 1.1824.\n",
      "[Epoch 11/1000] Train Loss: 1.1556  |  Val Loss: 1.1075\n",
      "Validation loss improved from 1.1824 to 1.1075.\n",
      "[Epoch 12/1000] Train Loss: 1.0761  |  Val Loss: 1.0301\n",
      "Validation loss improved from 1.1075 to 1.0301.\n",
      "[Epoch 13/1000] Train Loss: 0.9959  |  Val Loss: 0.9517\n",
      "Validation loss improved from 1.0301 to 0.9517.\n",
      "[Epoch 14/1000] Train Loss: 0.9188  |  Val Loss: 0.8755\n",
      "Validation loss improved from 0.9517 to 0.8755.\n",
      "[Epoch 15/1000] Train Loss: 0.8446  |  Val Loss: 0.7994\n",
      "Validation loss improved from 0.8755 to 0.7994.\n",
      "[Epoch 16/1000] Train Loss: 0.7646  |  Val Loss: 0.7262\n",
      "Validation loss improved from 0.7994 to 0.7262.\n",
      "[Epoch 17/1000] Train Loss: 0.6935  |  Val Loss: 0.6571\n",
      "Validation loss improved from 0.7262 to 0.6571.\n",
      "[Epoch 18/1000] Train Loss: 0.6227  |  Val Loss: 0.5926\n",
      "Validation loss improved from 0.6571 to 0.5926.\n",
      "[Epoch 19/1000] Train Loss: 0.5626  |  Val Loss: 0.5380\n",
      "Validation loss improved from 0.5926 to 0.5380.\n",
      "[Epoch 20/1000] Train Loss: 0.5036  |  Val Loss: 0.4848\n",
      "Validation loss improved from 0.5380 to 0.4848.\n",
      "[Epoch 21/1000] Train Loss: 0.4496  |  Val Loss: 0.4413\n",
      "Validation loss improved from 0.4848 to 0.4413.\n",
      "[Epoch 22/1000] Train Loss: 0.4033  |  Val Loss: 0.3982\n",
      "Validation loss improved from 0.4413 to 0.3982.\n",
      "[Epoch 23/1000] Train Loss: 0.3623  |  Val Loss: 0.3600\n",
      "Validation loss improved from 0.3982 to 0.3600.\n",
      "[Epoch 24/1000] Train Loss: 0.3280  |  Val Loss: 0.3282\n",
      "Validation loss improved from 0.3600 to 0.3282.\n",
      "[Epoch 25/1000] Train Loss: 0.2925  |  Val Loss: 0.3011\n",
      "Validation loss improved from 0.3282 to 0.3011.\n",
      "[Epoch 26/1000] Train Loss: 0.2698  |  Val Loss: 0.2743\n",
      "Validation loss improved from 0.3011 to 0.2743.\n",
      "[Epoch 27/1000] Train Loss: 0.2417  |  Val Loss: 0.2568\n",
      "Validation loss improved from 0.2743 to 0.2568.\n",
      "[Epoch 28/1000] Train Loss: 0.2234  |  Val Loss: 0.2376\n",
      "Validation loss improved from 0.2568 to 0.2376.\n",
      "[Epoch 29/1000] Train Loss: 0.2042  |  Val Loss: 0.2242\n",
      "Validation loss improved from 0.2376 to 0.2242.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/1000] Train Loss: 0.1872  |  Val Loss: 0.2077\n",
      "Validation loss improved from 0.2242 to 0.2077.\n",
      "[Epoch 31/1000] Train Loss: 0.1783  |  Val Loss: 0.1928\n",
      "Validation loss improved from 0.2077 to 0.1928.\n",
      "[Epoch 32/1000] Train Loss: 0.1650  |  Val Loss: 0.1899\n",
      "Validation loss improved from 0.1928 to 0.1899.\n",
      "[Epoch 33/1000] Train Loss: 0.1539  |  Val Loss: 0.1803\n",
      "Validation loss improved from 0.1899 to 0.1803.\n",
      "[Epoch 34/1000] Train Loss: 0.1502  |  Val Loss: 0.1750\n",
      "Validation loss improved from 0.1803 to 0.1750.\n",
      "[Epoch 35/1000] Train Loss: 0.1476  |  Val Loss: 0.1773\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 36/1000] Train Loss: 0.1303  |  Val Loss: 0.1579\n",
      "Validation loss improved from 0.1750 to 0.1579.\n",
      "[Epoch 37/1000] Train Loss: 0.1275  |  Val Loss: 0.1533\n",
      "Validation loss improved from 0.1579 to 0.1533.\n",
      "[Epoch 38/1000] Train Loss: 0.1266  |  Val Loss: 0.1569\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/1000] Train Loss: 0.1143  |  Val Loss: 0.1504\n",
      "Validation loss improved from 0.1533 to 0.1504.\n",
      "[Epoch 40/1000] Train Loss: 0.1084  |  Val Loss: 0.1425\n",
      "Validation loss improved from 0.1504 to 0.1425.\n",
      "[Epoch 41/1000] Train Loss: 0.1056  |  Val Loss: 0.1343\n",
      "Validation loss improved from 0.1425 to 0.1343.\n",
      "[Epoch 42/1000] Train Loss: 0.0999  |  Val Loss: 0.1358\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 43/1000] Train Loss: 0.1000  |  Val Loss: 0.1335\n",
      "Validation loss improved from 0.1343 to 0.1335.\n",
      "[Epoch 44/1000] Train Loss: 0.0942  |  Val Loss: 0.1326\n",
      "Validation loss improved from 0.1335 to 0.1326.\n",
      "[Epoch 45/1000] Train Loss: 0.0905  |  Val Loss: 0.1338\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 46/1000] Train Loss: 0.0865  |  Val Loss: 0.1283\n",
      "Validation loss improved from 0.1326 to 0.1283.\n",
      "[Epoch 47/1000] Train Loss: 0.0878  |  Val Loss: 0.1238\n",
      "Validation loss improved from 0.1283 to 0.1238.\n",
      "[Epoch 48/1000] Train Loss: 0.0843  |  Val Loss: 0.1291\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 49/1000] Train Loss: 0.0812  |  Val Loss: 0.1200\n",
      "Validation loss improved from 0.1238 to 0.1200.\n",
      "[Epoch 50/1000] Train Loss: 0.0794  |  Val Loss: 0.1187\n",
      "Validation loss improved from 0.1200 to 0.1187.\n",
      "[Epoch 51/1000] Train Loss: 0.0763  |  Val Loss: 0.1213\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 52/1000] Train Loss: 0.0803  |  Val Loss: 0.1166\n",
      "Validation loss improved from 0.1187 to 0.1166.\n",
      "[Epoch 53/1000] Train Loss: 0.0699  |  Val Loss: 0.1164\n",
      "Validation loss improved from 0.1166 to 0.1164.\n",
      "[Epoch 54/1000] Train Loss: 0.0720  |  Val Loss: 0.1166\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 55/1000] Train Loss: 0.0671  |  Val Loss: 0.1167\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 56/1000] Train Loss: 0.0716  |  Val Loss: 0.1119\n",
      "Validation loss improved from 0.1164 to 0.1119.\n",
      "[Epoch 57/1000] Train Loss: 0.0678  |  Val Loss: 0.1104\n",
      "Validation loss improved from 0.1119 to 0.1104.\n",
      "[Epoch 58/1000] Train Loss: 0.0677  |  Val Loss: 0.1118\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/1000] Train Loss: 0.0664  |  Val Loss: 0.1200\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 60/1000] Train Loss: 0.0667  |  Val Loss: 0.1060\n",
      "Validation loss improved from 0.1104 to 0.1060.\n",
      "[Epoch 61/1000] Train Loss: 0.0625  |  Val Loss: 0.1035\n",
      "Validation loss improved from 0.1060 to 0.1035.\n",
      "[Epoch 62/1000] Train Loss: 0.0607  |  Val Loss: 0.1058\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 63/1000] Train Loss: 0.0563  |  Val Loss: 0.1040\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 64/1000] Train Loss: 0.0558  |  Val Loss: 0.1009\n",
      "Validation loss improved from 0.1035 to 0.1009.\n",
      "[Epoch 65/1000] Train Loss: 0.0543  |  Val Loss: 0.1021\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 66/1000] Train Loss: 0.0536  |  Val Loss: 0.1012\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 67/1000] Train Loss: 0.0529  |  Val Loss: 0.1007\n",
      "Validation loss improved from 0.1009 to 0.1007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] Train Loss: 0.0514  |  Val Loss: 0.1021\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 69/1000] Train Loss: 0.0528  |  Val Loss: 0.1041\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 70/1000] Train Loss: 0.0495  |  Val Loss: 0.1015\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 71/1000] Train Loss: 0.0498  |  Val Loss: 0.0990\n",
      "Validation loss improved from 0.1007 to 0.0990.\n",
      "[Epoch 72/1000] Train Loss: 0.0486  |  Val Loss: 0.1008\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 73/1000] Train Loss: 0.0469  |  Val Loss: 0.1009\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 74/1000] Train Loss: 0.0453  |  Val Loss: 0.1007\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 75/1000] Train Loss: 0.0474  |  Val Loss: 0.0993\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 76/1000] Train Loss: 0.0454  |  Val Loss: 0.0979\n",
      "Validation loss improved from 0.0990 to 0.0979.\n",
      "[Epoch 77/1000] Train Loss: 0.0458  |  Val Loss: 0.1010\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 78/1000] Train Loss: 0.0432  |  Val Loss: 0.0973\n",
      "Validation loss improved from 0.0979 to 0.0973.\n",
      "[Epoch 79/1000] Train Loss: 0.0428  |  Val Loss: 0.0975\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 80/1000] Train Loss: 0.0426  |  Val Loss: 0.1005\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 81/1000] Train Loss: 0.0429  |  Val Loss: 0.0952\n",
      "Validation loss improved from 0.0973 to 0.0952.\n",
      "[Epoch 82/1000] Train Loss: 0.0419  |  Val Loss: 0.0951\n",
      "Validation loss improved from 0.0952 to 0.0951.\n",
      "[Epoch 83/1000] Train Loss: 0.0403  |  Val Loss: 0.0945\n",
      "Validation loss improved from 0.0951 to 0.0945.\n",
      "[Epoch 84/1000] Train Loss: 0.0407  |  Val Loss: 0.0927\n",
      "Validation loss improved from 0.0945 to 0.0927.\n",
      "[Epoch 85/1000] Train Loss: 0.0385  |  Val Loss: 0.0934\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 86/1000] Train Loss: 0.0405  |  Val Loss: 0.0975\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 87/1000] Train Loss: 0.0381  |  Val Loss: 0.0940\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 88/1000] Train Loss: 0.0369  |  Val Loss: 0.0923\n",
      "Validation loss improved from 0.0927 to 0.0923.\n",
      "[Epoch 89/1000] Train Loss: 0.0383  |  Val Loss: 0.0914\n",
      "Validation loss improved from 0.0923 to 0.0914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 90/1000] Train Loss: 0.0382  |  Val Loss: 0.0897\n",
      "Validation loss improved from 0.0914 to 0.0897.\n",
      "[Epoch 91/1000] Train Loss: 0.0349  |  Val Loss: 0.0943\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 92/1000] Train Loss: 0.0364  |  Val Loss: 0.1007\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 93/1000] Train Loss: 0.0381  |  Val Loss: 0.0952\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 94/1000] Train Loss: 0.0337  |  Val Loss: 0.0945\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 95/1000] Train Loss: 0.0345  |  Val Loss: 0.0937\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 96/1000] Train Loss: 0.0351  |  Val Loss: 0.0920\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 97/1000] Train Loss: 0.0351  |  Val Loss: 0.0948\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 98/1000] Train Loss: 0.0330  |  Val Loss: 0.0949\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 99/1000] Train Loss: 0.0313  |  Val Loss: 0.0959\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100/1000] Train Loss: 0.0316  |  Val Loss: 0.0959\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 101/1000] Train Loss: 0.0306  |  Val Loss: 0.0945\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 102/1000] Train Loss: 0.0326  |  Val Loss: 0.0918\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 103/1000] Train Loss: 0.0310  |  Val Loss: 0.0910\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 104/1000] Train Loss: 0.0314  |  Val Loss: 0.0958\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 105/1000] Train Loss: 0.0297  |  Val Loss: 0.0931\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 106/1000] Train Loss: 0.0302  |  Val Loss: 0.0915\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 107/1000] Train Loss: 0.0303  |  Val Loss: 0.0917\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 108/1000] Train Loss: 0.0301  |  Val Loss: 0.0904\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 109/1000] Train Loss: 0.0264  |  Val Loss: 0.0951\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 110/1000] Train Loss: 0.0282  |  Val Loss: 0.0974\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 111/1000] Train Loss: 0.0276  |  Val Loss: 0.0938\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 112/1000] Train Loss: 0.0265  |  Val Loss: 0.0944\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 113/1000] Train Loss: 0.0266  |  Val Loss: 0.0938\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 114/1000] Train Loss: 0.0277  |  Val Loss: 0.0924\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 115/1000] Train Loss: 0.0259  |  Val Loss: 0.0940\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 116/1000] Train Loss: 0.0265  |  Val Loss: 0.0954\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 117/1000] Train Loss: 0.0245  |  Val Loss: 0.0948\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 118/1000] Train Loss: 0.0268  |  Val Loss: 0.0917\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 119/1000] Train Loss: 0.0240  |  Val Loss: 0.0908\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 120/1000] Train Loss: 0.0263  |  Val Loss: 0.0904\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 121/1000] Train Loss: 0.0250  |  Val Loss: 0.0936\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 122/1000] Train Loss: 0.0237  |  Val Loss: 0.0921\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 123/1000] Train Loss: 0.0227  |  Val Loss: 0.0933\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 124/1000] Train Loss: 0.0262  |  Val Loss: 0.0934\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 125/1000] Train Loss: 0.0228  |  Val Loss: 0.0921\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 126/1000] Train Loss: 0.0223  |  Val Loss: 0.0929\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 127/1000] Train Loss: 0.0236  |  Val Loss: 0.0904\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 128/1000] Train Loss: 0.0209  |  Val Loss: 0.0903\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 129/1000] Train Loss: 0.0250  |  Val Loss: 0.0905\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 130/1000] Train Loss: 0.0205  |  Val Loss: 0.0948\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 131/1000] Train Loss: 0.0229  |  Val Loss: 0.0980\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 132/1000] Train Loss: 0.0208  |  Val Loss: 0.0980\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 133/1000] Train Loss: 0.0203  |  Val Loss: 0.0911\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 134/1000] Train Loss: 0.0201  |  Val Loss: 0.0905\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 135/1000] Train Loss: 0.0191  |  Val Loss: 0.0914\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 136/1000] Train Loss: 0.0194  |  Val Loss: 0.0944\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 137/1000] Train Loss: 0.0193  |  Val Loss: 0.0954\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 138/1000] Train Loss: 0.0195  |  Val Loss: 0.0959\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 139/1000] Train Loss: 0.0189  |  Val Loss: 0.0970\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 140/1000] Train Loss: 0.0179  |  Val Loss: 0.0996\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 141/1000] Train Loss: 0.0179  |  Val Loss: 0.1003\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 142/1000] Train Loss: 0.0180  |  Val Loss: 0.0964\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 143/1000] Train Loss: 0.0180  |  Val Loss: 0.0938\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 144/1000] Train Loss: 0.0171  |  Val Loss: 0.0933\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 145/1000] Train Loss: 0.0171  |  Val Loss: 0.0948\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 146/1000] Train Loss: 0.0173  |  Val Loss: 0.0960\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 147/1000] Train Loss: 0.0165  |  Val Loss: 0.0961\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 148/1000] Train Loss: 0.0159  |  Val Loss: 0.0950\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 149/1000] Train Loss: 0.0176  |  Val Loss: 0.0946\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 150/1000] Train Loss: 0.0157  |  Val Loss: 0.0957\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 151/1000] Train Loss: 0.0171  |  Val Loss: 0.0948\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 152/1000] Train Loss: 0.0148  |  Val Loss: 0.0927\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 153/1000] Train Loss: 0.0158  |  Val Loss: 0.0921\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 154/1000] Train Loss: 0.0178  |  Val Loss: 0.0923\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 155/1000] Train Loss: 0.0169  |  Val Loss: 0.0955\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 156/1000] Train Loss: 0.0144  |  Val Loss: 0.0965\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 157/1000] Train Loss: 0.0150  |  Val Loss: 0.0926\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 158/1000] Train Loss: 0.0144  |  Val Loss: 0.0886\n",
      "Validation loss improved from 0.0897 to 0.0886.\n",
      "[Epoch 159/1000] Train Loss: 0.0163  |  Val Loss: 0.0906\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 160/1000] Train Loss: 0.0136  |  Val Loss: 0.0924\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 161/1000] Train Loss: 0.0141  |  Val Loss: 0.0963\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 162/1000] Train Loss: 0.0133  |  Val Loss: 0.0970\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 163/1000] Train Loss: 0.0142  |  Val Loss: 0.0943\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 164/1000] Train Loss: 0.0127  |  Val Loss: 0.0916\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 165/1000] Train Loss: 0.0136  |  Val Loss: 0.0939\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 166/1000] Train Loss: 0.0137  |  Val Loss: 0.0946\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 167/1000] Train Loss: 0.0144  |  Val Loss: 0.0970\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 168/1000] Train Loss: 0.0157  |  Val Loss: 0.0944\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 169/1000] Train Loss: 0.0124  |  Val Loss: 0.0923\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 170/1000] Train Loss: 0.0126  |  Val Loss: 0.0922\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 171/1000] Train Loss: 0.0126  |  Val Loss: 0.0904\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 172/1000] Train Loss: 0.0113  |  Val Loss: 0.0948\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 173/1000] Train Loss: 0.0142  |  Val Loss: 0.1000\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 174/1000] Train Loss: 0.0154  |  Val Loss: 0.1033\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 175/1000] Train Loss: 0.0166  |  Val Loss: 0.0936\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 176/1000] Train Loss: 0.0131  |  Val Loss: 0.0951\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 177/1000] Train Loss: 0.0120  |  Val Loss: 0.0988\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 178/1000] Train Loss: 0.0107  |  Val Loss: 0.0985\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 179/1000] Train Loss: 0.0107  |  Val Loss: 0.0977\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 180/1000] Train Loss: 0.0099  |  Val Loss: 0.0929\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 181/1000] Train Loss: 0.0099  |  Val Loss: 0.0947\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 182/1000] Train Loss: 0.0096  |  Val Loss: 0.0970\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 183/1000] Train Loss: 0.0094  |  Val Loss: 0.0991\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 184/1000] Train Loss: 0.0104  |  Val Loss: 0.0999\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 185/1000] Train Loss: 0.0102  |  Val Loss: 0.0974\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 186/1000] Train Loss: 0.0109  |  Val Loss: 0.0997\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 187/1000] Train Loss: 0.0091  |  Val Loss: 0.1007\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 188/1000] Train Loss: 0.0096  |  Val Loss: 0.1011\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 189/1000] Train Loss: 0.0096  |  Val Loss: 0.1038\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 190/1000] Train Loss: 0.0092  |  Val Loss: 0.1060\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 191/1000] Train Loss: 0.0084  |  Val Loss: 0.1031\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 192/1000] Train Loss: 0.0083  |  Val Loss: 0.0974\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 193/1000] Train Loss: 0.0082  |  Val Loss: 0.0961\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 194/1000] Train Loss: 0.0085  |  Val Loss: 0.0983\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 195/1000] Train Loss: 0.0085  |  Val Loss: 0.1022\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 196/1000] Train Loss: 0.0084  |  Val Loss: 0.1072\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 197/1000] Train Loss: 0.0081  |  Val Loss: 0.1056\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 198/1000] Train Loss: 0.0074  |  Val Loss: 0.0991\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 199/1000] Train Loss: 0.0079  |  Val Loss: 0.0965\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 200/1000] Train Loss: 0.0080  |  Val Loss: 0.0984\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 201/1000] Train Loss: 0.0072  |  Val Loss: 0.1051\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 202/1000] Train Loss: 0.0078  |  Val Loss: 0.1118\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 203/1000] Train Loss: 0.0073  |  Val Loss: 0.1036\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 204/1000] Train Loss: 0.0079  |  Val Loss: 0.0926\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 205/1000] Train Loss: 0.0074  |  Val Loss: 0.0930\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 206/1000] Train Loss: 0.0079  |  Val Loss: 0.1054\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 207/1000] Train Loss: 0.0087  |  Val Loss: 0.1143\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 208/1000] Train Loss: 0.0078  |  Val Loss: 0.1091\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 209/1000] Train Loss: 0.0065  |  Val Loss: 0.1023\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 210/1000] Train Loss: 0.0068  |  Val Loss: 0.0967\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 211/1000] Train Loss: 0.0063  |  Val Loss: 0.0985\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 212/1000] Train Loss: 0.0065  |  Val Loss: 0.1031\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 213/1000] Train Loss: 0.0066  |  Val Loss: 0.1103\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 214/1000] Train Loss: 0.0063  |  Val Loss: 0.1078\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 215/1000] Train Loss: 0.0063  |  Val Loss: 0.1029\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 216/1000] Train Loss: 0.0062  |  Val Loss: 0.1057\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 217/1000] Train Loss: 0.0057  |  Val Loss: 0.1039\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 218/1000] Train Loss: 0.0060  |  Val Loss: 0.1024\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 219/1000] Train Loss: 0.0058  |  Val Loss: 0.1023\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 220/1000] Train Loss: 0.0062  |  Val Loss: 0.1043\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 221/1000] Train Loss: 0.0064  |  Val Loss: 0.1091\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 222/1000] Train Loss: 0.0059  |  Val Loss: 0.1076\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 223/1000] Train Loss: 0.0056  |  Val Loss: 0.1037\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 224/1000] Train Loss: 0.0058  |  Val Loss: 0.1053\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 225/1000] Train Loss: 0.0054  |  Val Loss: 0.1050\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 226/1000] Train Loss: 0.0051  |  Val Loss: 0.1040\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 227/1000] Train Loss: 0.0053  |  Val Loss: 0.1042\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 228/1000] Train Loss: 0.0051  |  Val Loss: 0.1078\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 229/1000] Train Loss: 0.0050  |  Val Loss: 0.1078\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 230/1000] Train Loss: 0.0057  |  Val Loss: 0.1092\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 231/1000] Train Loss: 0.0047  |  Val Loss: 0.1061\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 232/1000] Train Loss: 0.0053  |  Val Loss: 0.1070\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 233/1000] Train Loss: 0.0046  |  Val Loss: 0.1077\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 234/1000] Train Loss: 0.0060  |  Val Loss: 0.1049\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 235/1000] Train Loss: 0.0044  |  Val Loss: 0.1032\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 236/1000] Train Loss: 0.0066  |  Val Loss: 0.1054\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 237/1000] Train Loss: 0.0051  |  Val Loss: 0.1112\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 238/1000] Train Loss: 0.0062  |  Val Loss: 0.1100\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 239/1000] Train Loss: 0.0043  |  Val Loss: 0.1056\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 240/1000] Train Loss: 0.0055  |  Val Loss: 0.1039\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 241/1000] Train Loss: 0.0046  |  Val Loss: 0.1072\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 242/1000] Train Loss: 0.0046  |  Val Loss: 0.1141\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 243/1000] Train Loss: 0.0048  |  Val Loss: 0.1129\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 244/1000] Train Loss: 0.0044  |  Val Loss: 0.1078\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 245/1000] Train Loss: 0.0039  |  Val Loss: 0.1019\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 246/1000] Train Loss: 0.0040  |  Val Loss: 0.1000\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 247/1000] Train Loss: 0.0040  |  Val Loss: 0.1051\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 248/1000] Train Loss: 0.0040  |  Val Loss: 0.1047\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 249/1000] Train Loss: 0.0037  |  Val Loss: 0.1080\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 250/1000] Train Loss: 0.0038  |  Val Loss: 0.1088\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 251/1000] Train Loss: 0.0037  |  Val Loss: 0.1068\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 252/1000] Train Loss: 0.0034  |  Val Loss: 0.1051\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 253/1000] Train Loss: 0.0037  |  Val Loss: 0.1056\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 254/1000] Train Loss: 0.0037  |  Val Loss: 0.1088\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 255/1000] Train Loss: 0.0036  |  Val Loss: 0.1043\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 256/1000] Train Loss: 0.0035  |  Val Loss: 0.1052\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 257/1000] Train Loss: 0.0034  |  Val Loss: 0.1054\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 258/1000] Train Loss: 0.0033  |  Val Loss: 0.1060\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 258 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:48.002301Z",
     "iopub.status.busy": "2025-05-08T17:29:48.002301Z",
     "iopub.status.idle": "2025-05-08T17:29:50.116411Z",
     "shell.execute_reply": "2025-05-08T17:29:50.116411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.1516 | Test Accuracy: 96.81%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:50.119716Z",
     "iopub.status.busy": "2025-05-08T17:29:50.119716Z",
     "iopub.status.idle": "2025-05-08T17:29:50.270588Z",
     "shell.execute_reply": "2025-05-08T17:29:50.270588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (180, 64), \n",
      "Train labels shape: (180,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (45, 64), \n",
      "Val labels shape: (45,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (147927, 64), \n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:50.272593Z",
     "iopub.status.busy": "2025-05-08T17:29:50.272593Z",
     "iopub.status.idle": "2025-05-08T17:29:50.311820Z",
     "shell.execute_reply": "2025-05-08T17:29:50.311820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n",
      "Training batch size: 180\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:50.314823Z",
     "iopub.status.busy": "2025-05-08T17:29:50.313823Z",
     "iopub.status.idle": "2025-05-08T17:29:50.318899Z",
     "shell.execute_reply": "2025-05-08T17:29:50.318899Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:50.320902Z",
     "iopub.status.busy": "2025-05-08T17:29:50.320902Z",
     "iopub.status.idle": "2025-05-08T17:29:50.324916Z",
     "shell.execute_reply": "2025-05-08T17:29:50.324916Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:29:50.327131Z",
     "iopub.status.busy": "2025-05-08T17:29:50.327131Z",
     "iopub.status.idle": "2025-05-08T17:30:00.394587Z",
     "shell.execute_reply": "2025-05-08T17:30:00.394587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 8.2696\n",
      "Epoch [1/2000], Avg Train Loss: 8.2696\n",
      "Epoch [1/2000], Avg Val Loss: 3.3544\n",
      "Validation loss improved from inf to 3.3544. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.2404\n",
      "Epoch [2/2000], Avg Train Loss: 8.2404\n",
      "Epoch [2/2000], Avg Val Loss: 3.3175\n",
      "Validation loss improved from 3.3544 to 3.3175. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.2460\n",
      "Epoch [3/2000], Avg Train Loss: 8.2460\n",
      "Epoch [3/2000], Avg Val Loss: 3.2819\n",
      "Validation loss improved from 3.3175 to 3.2819. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.1180\n",
      "Epoch [4/2000], Avg Train Loss: 8.1180\n",
      "Epoch [4/2000], Avg Val Loss: 3.2478\n",
      "Validation loss improved from 3.2819 to 3.2478. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9979\n",
      "Epoch [5/2000], Avg Train Loss: 7.9979\n",
      "Epoch [5/2000], Avg Val Loss: 3.2148\n",
      "Validation loss improved from 3.2478 to 3.2148. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9072\n",
      "Epoch [6/2000], Avg Train Loss: 7.9072\n",
      "Epoch [6/2000], Avg Val Loss: 3.1829\n",
      "Validation loss improved from 3.2148 to 3.1829. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8077\n",
      "Epoch [7/2000], Avg Train Loss: 7.8077\n",
      "Epoch [7/2000], Avg Val Loss: 3.1522\n",
      "Validation loss improved from 3.1829 to 3.1522. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5715\n",
      "Epoch [8/2000], Avg Train Loss: 7.5715\n",
      "Epoch [8/2000], Avg Val Loss: 3.1226\n",
      "Validation loss improved from 3.1522 to 3.1226. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6503\n",
      "Epoch [9/2000], Avg Train Loss: 7.6503\n",
      "Epoch [9/2000], Avg Val Loss: 3.0939\n",
      "Validation loss improved from 3.1226 to 3.0939. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4179\n",
      "Epoch [10/2000], Avg Train Loss: 7.4179\n",
      "Epoch [10/2000], Avg Val Loss: 3.0665\n",
      "Validation loss improved from 3.0939 to 3.0665. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5769\n",
      "Epoch [11/2000], Avg Train Loss: 7.5769\n",
      "Epoch [11/2000], Avg Val Loss: 3.0400\n",
      "Validation loss improved from 3.0665 to 3.0400. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5177\n",
      "Epoch [12/2000], Avg Train Loss: 7.5177\n",
      "Epoch [12/2000], Avg Val Loss: 3.0146\n",
      "Validation loss improved from 3.0400 to 3.0146. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4284\n",
      "Epoch [13/2000], Avg Train Loss: 7.4284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/2000], Avg Val Loss: 2.9901\n",
      "Validation loss improved from 3.0146 to 2.9901. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2016\n",
      "Epoch [14/2000], Avg Train Loss: 7.2016\n",
      "Epoch [14/2000], Avg Val Loss: 2.9665\n",
      "Validation loss improved from 2.9901 to 2.9665. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2148\n",
      "Epoch [15/2000], Avg Train Loss: 7.2148\n",
      "Epoch [15/2000], Avg Val Loss: 2.9438\n",
      "Validation loss improved from 2.9665 to 2.9438. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0687\n",
      "Epoch [16/2000], Avg Train Loss: 7.0687\n",
      "Epoch [16/2000], Avg Val Loss: 2.9221\n",
      "Validation loss improved from 2.9438 to 2.9221. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9759\n",
      "Epoch [17/2000], Avg Train Loss: 6.9759\n",
      "Epoch [17/2000], Avg Val Loss: 2.9012\n",
      "Validation loss improved from 2.9221 to 2.9012. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9576\n",
      "Epoch [18/2000], Avg Train Loss: 6.9576\n",
      "Epoch [18/2000], Avg Val Loss: 2.8813\n",
      "Validation loss improved from 2.9012 to 2.8813. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9844\n",
      "Epoch [19/2000], Avg Train Loss: 6.9844\n",
      "Epoch [19/2000], Avg Val Loss: 2.8621\n",
      "Validation loss improved from 2.8813 to 2.8621. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7750\n",
      "Epoch [20/2000], Avg Train Loss: 6.7750\n",
      "Epoch [20/2000], Avg Val Loss: 2.8437\n",
      "Validation loss improved from 2.8621 to 2.8437. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9398\n",
      "Epoch [21/2000], Avg Train Loss: 6.9398\n",
      "Epoch [21/2000], Avg Val Loss: 2.8260\n",
      "Validation loss improved from 2.8437 to 2.8260. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8778\n",
      "Epoch [22/2000], Avg Train Loss: 6.8778\n",
      "Epoch [22/2000], Avg Val Loss: 2.8091\n",
      "Validation loss improved from 2.8260 to 2.8091. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8231\n",
      "Epoch [23/2000], Avg Train Loss: 6.8231\n",
      "Epoch [23/2000], Avg Val Loss: 2.7930\n",
      "Validation loss improved from 2.8091 to 2.7930. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6967\n",
      "Epoch [24/2000], Avg Train Loss: 6.6967\n",
      "Epoch [24/2000], Avg Val Loss: 2.7775\n",
      "Validation loss improved from 2.7930 to 2.7775. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7397\n",
      "Epoch [25/2000], Avg Train Loss: 6.7397\n",
      "Epoch [25/2000], Avg Val Loss: 2.7628\n",
      "Validation loss improved from 2.7775 to 2.7628. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5348\n",
      "Epoch [26/2000], Avg Train Loss: 6.5348\n",
      "Epoch [26/2000], Avg Val Loss: 2.7487\n",
      "Validation loss improved from 2.7628 to 2.7487. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5212\n",
      "Epoch [27/2000], Avg Train Loss: 6.5212\n",
      "Epoch [27/2000], Avg Val Loss: 2.7353\n",
      "Validation loss improved from 2.7487 to 2.7353. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2749\n",
      "Epoch [28/2000], Avg Train Loss: 6.2749\n",
      "Epoch [28/2000], Avg Val Loss: 2.7224\n",
      "Validation loss improved from 2.7353 to 2.7224. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3063\n",
      "Epoch [29/2000], Avg Train Loss: 6.3063\n",
      "Epoch [29/2000], Avg Val Loss: 2.7102\n",
      "Validation loss improved from 2.7224 to 2.7102. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2844\n",
      "Epoch [30/2000], Avg Train Loss: 6.2844\n",
      "Epoch [30/2000], Avg Val Loss: 2.6985\n",
      "Validation loss improved from 2.7102 to 2.6985. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3317\n",
      "Epoch [31/2000], Avg Train Loss: 6.3317\n",
      "Epoch [31/2000], Avg Val Loss: 2.6873\n",
      "Validation loss improved from 2.6985 to 2.6873. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3207\n",
      "Epoch [32/2000], Avg Train Loss: 6.3207\n",
      "Epoch [32/2000], Avg Val Loss: 2.6766\n",
      "Validation loss improved from 2.6873 to 2.6766. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2055\n",
      "Epoch [33/2000], Avg Train Loss: 6.2055\n",
      "Epoch [33/2000], Avg Val Loss: 2.6664\n",
      "Validation loss improved from 2.6766 to 2.6664. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1762\n",
      "Epoch [34/2000], Avg Train Loss: 6.1762\n",
      "Epoch [34/2000], Avg Val Loss: 2.6567\n",
      "Validation loss improved from 2.6664 to 2.6567. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3005\n",
      "Epoch [35/2000], Avg Train Loss: 6.3005\n",
      "Epoch [35/2000], Avg Val Loss: 2.6474\n",
      "Validation loss improved from 2.6567 to 2.6474. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0036\n",
      "Epoch [36/2000], Avg Train Loss: 6.0036\n",
      "Epoch [36/2000], Avg Val Loss: 2.6385\n",
      "Validation loss improved from 2.6474 to 2.6385. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9989\n",
      "Epoch [37/2000], Avg Train Loss: 5.9989\n",
      "Epoch [37/2000], Avg Val Loss: 2.6301\n",
      "Validation loss improved from 2.6385 to 2.6301. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9649\n",
      "Epoch [38/2000], Avg Train Loss: 5.9649\n",
      "Epoch [38/2000], Avg Val Loss: 2.6221\n",
      "Validation loss improved from 2.6301 to 2.6221. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9611\n",
      "Epoch [39/2000], Avg Train Loss: 5.9611\n",
      "Epoch [39/2000], Avg Val Loss: 2.6144\n",
      "Validation loss improved from 2.6221 to 2.6144. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8884\n",
      "Epoch [40/2000], Avg Train Loss: 5.8884\n",
      "Epoch [40/2000], Avg Val Loss: 2.6070\n",
      "Validation loss improved from 2.6144 to 2.6070. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9045\n",
      "Epoch [41/2000], Avg Train Loss: 5.9045\n",
      "Epoch [41/2000], Avg Val Loss: 2.6000\n",
      "Validation loss improved from 2.6070 to 2.6000. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8397\n",
      "Epoch [42/2000], Avg Train Loss: 5.8397\n",
      "Epoch [42/2000], Avg Val Loss: 2.5933\n",
      "Validation loss improved from 2.6000 to 2.5933. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7315\n",
      "Epoch [43/2000], Avg Train Loss: 5.7315\n",
      "Epoch [43/2000], Avg Val Loss: 2.5870\n",
      "Validation loss improved from 2.5933 to 2.5870. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.5315\n",
      "Epoch [44/2000], Avg Train Loss: 5.5315\n",
      "Epoch [44/2000], Avg Val Loss: 2.5809\n",
      "Validation loss improved from 2.5870 to 2.5809. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7537\n",
      "Epoch [45/2000], Avg Train Loss: 5.7537\n",
      "Epoch [45/2000], Avg Val Loss: 2.5752\n",
      "Validation loss improved from 2.5809 to 2.5752. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6765\n",
      "Epoch [46/2000], Avg Train Loss: 5.6765\n",
      "Epoch [46/2000], Avg Val Loss: 2.5697\n",
      "Validation loss improved from 2.5752 to 2.5697. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5371\n",
      "Epoch [47/2000], Avg Train Loss: 5.5371\n",
      "Epoch [47/2000], Avg Val Loss: 2.5645\n",
      "Validation loss improved from 2.5697 to 2.5645. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7322\n",
      "Epoch [48/2000], Avg Train Loss: 5.7322\n",
      "Epoch [48/2000], Avg Val Loss: 2.5595\n",
      "Validation loss improved from 2.5645 to 2.5595. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6330\n",
      "Epoch [49/2000], Avg Train Loss: 5.6330\n",
      "Epoch [49/2000], Avg Val Loss: 2.5547\n",
      "Validation loss improved from 2.5595 to 2.5547. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6111\n",
      "Epoch [50/2000], Avg Train Loss: 5.6111\n",
      "Epoch [50/2000], Avg Val Loss: 2.5502\n",
      "Validation loss improved from 2.5547 to 2.5502. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.4959\n",
      "Epoch [51/2000], Avg Train Loss: 5.4959\n",
      "Epoch [51/2000], Avg Val Loss: 2.5459\n",
      "Validation loss improved from 2.5502 to 2.5459. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5330\n",
      "Epoch [52/2000], Avg Train Loss: 5.5330\n",
      "Epoch [52/2000], Avg Val Loss: 2.5419\n",
      "Validation loss improved from 2.5459 to 2.5419. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4806\n",
      "Epoch [53/2000], Avg Train Loss: 5.4806\n",
      "Epoch [53/2000], Avg Val Loss: 2.5380\n",
      "Validation loss improved from 2.5419 to 2.5380. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3858\n",
      "Epoch [54/2000], Avg Train Loss: 5.3858\n",
      "Epoch [54/2000], Avg Val Loss: 2.5343\n",
      "Validation loss improved from 2.5380 to 2.5343. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5069\n",
      "Epoch [55/2000], Avg Train Loss: 5.5069\n",
      "Epoch [55/2000], Avg Val Loss: 2.5308\n",
      "Validation loss improved from 2.5343 to 2.5308. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4357\n",
      "Epoch [56/2000], Avg Train Loss: 5.4357\n",
      "Epoch [56/2000], Avg Val Loss: 2.5275\n",
      "Validation loss improved from 2.5308 to 2.5275. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3302\n",
      "Epoch [57/2000], Avg Train Loss: 5.3302\n",
      "Epoch [57/2000], Avg Val Loss: 2.5243\n",
      "Validation loss improved from 2.5275 to 2.5243. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3066\n",
      "Epoch [58/2000], Avg Train Loss: 5.3066\n",
      "Epoch [58/2000], Avg Val Loss: 2.5213\n",
      "Validation loss improved from 2.5243 to 2.5213. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2139\n",
      "Epoch [59/2000], Avg Train Loss: 5.2139\n",
      "Epoch [59/2000], Avg Val Loss: 2.5183\n",
      "Validation loss improved from 2.5213 to 2.5183. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2835\n",
      "Epoch [60/2000], Avg Train Loss: 5.2835\n",
      "Epoch [60/2000], Avg Val Loss: 2.5156\n",
      "Validation loss improved from 2.5183 to 2.5156. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1883\n",
      "Epoch [61/2000], Avg Train Loss: 5.1883\n",
      "Epoch [61/2000], Avg Val Loss: 2.5130\n",
      "Validation loss improved from 2.5156 to 2.5130. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1671\n",
      "Epoch [62/2000], Avg Train Loss: 5.1671\n",
      "Epoch [62/2000], Avg Val Loss: 2.5106\n",
      "Validation loss improved from 2.5130 to 2.5106. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1767\n",
      "Epoch [63/2000], Avg Train Loss: 5.1767\n",
      "Epoch [63/2000], Avg Val Loss: 2.5083\n",
      "Validation loss improved from 2.5106 to 2.5083. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0900\n",
      "Epoch [64/2000], Avg Train Loss: 5.0900\n",
      "Epoch [64/2000], Avg Val Loss: 2.5060\n",
      "Validation loss improved from 2.5083 to 2.5060. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1249\n",
      "Epoch [65/2000], Avg Train Loss: 5.1249\n",
      "Epoch [65/2000], Avg Val Loss: 2.5039\n",
      "Validation loss improved from 2.5060 to 2.5039. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1640\n",
      "Epoch [66/2000], Avg Train Loss: 5.1640\n",
      "Epoch [66/2000], Avg Val Loss: 2.5018\n",
      "Validation loss improved from 2.5039 to 2.5018. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1044\n",
      "Epoch [67/2000], Avg Train Loss: 5.1044\n",
      "Epoch [67/2000], Avg Val Loss: 2.4998\n",
      "Validation loss improved from 2.5018 to 2.4998. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0753\n",
      "Epoch [68/2000], Avg Train Loss: 5.0753\n",
      "Epoch [68/2000], Avg Val Loss: 2.4979\n",
      "Validation loss improved from 2.4998 to 2.4979. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0394\n",
      "Epoch [69/2000], Avg Train Loss: 5.0394\n",
      "Epoch [69/2000], Avg Val Loss: 2.4961\n",
      "Validation loss improved from 2.4979 to 2.4961. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0748\n",
      "Epoch [70/2000], Avg Train Loss: 5.0748\n",
      "Epoch [70/2000], Avg Val Loss: 2.4943\n",
      "Validation loss improved from 2.4961 to 2.4943. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0654\n",
      "Epoch [71/2000], Avg Train Loss: 5.0654\n",
      "Epoch [71/2000], Avg Val Loss: 2.4926\n",
      "Validation loss improved from 2.4943 to 2.4926. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9978\n",
      "Epoch [72/2000], Avg Train Loss: 4.9978\n",
      "Epoch [72/2000], Avg Val Loss: 2.4909\n",
      "Validation loss improved from 2.4926 to 2.4909. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9272\n",
      "Epoch [73/2000], Avg Train Loss: 4.9272\n",
      "Epoch [73/2000], Avg Val Loss: 2.4893\n",
      "Validation loss improved from 2.4909 to 2.4893. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0532\n",
      "Epoch [74/2000], Avg Train Loss: 5.0532\n",
      "Epoch [74/2000], Avg Val Loss: 2.4878\n",
      "Validation loss improved from 2.4893 to 2.4878. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8937\n",
      "Epoch [75/2000], Avg Train Loss: 4.8937\n",
      "Epoch [75/2000], Avg Val Loss: 2.4862\n",
      "Validation loss improved from 2.4878 to 2.4862. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0014\n",
      "Epoch [76/2000], Avg Train Loss: 5.0014\n",
      "Epoch [76/2000], Avg Val Loss: 2.4848\n",
      "Validation loss improved from 2.4862 to 2.4848. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9157\n",
      "Epoch [77/2000], Avg Train Loss: 4.9157\n",
      "Epoch [77/2000], Avg Val Loss: 2.4834\n",
      "Validation loss improved from 2.4848 to 2.4834. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9049\n",
      "Epoch [78/2000], Avg Train Loss: 4.9049\n",
      "Epoch [78/2000], Avg Val Loss: 2.4820\n",
      "Validation loss improved from 2.4834 to 2.4820. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9488\n",
      "Epoch [79/2000], Avg Train Loss: 4.9488\n",
      "Epoch [79/2000], Avg Val Loss: 2.4807\n",
      "Validation loss improved from 2.4820 to 2.4807. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9359\n",
      "Epoch [80/2000], Avg Train Loss: 4.9359\n",
      "Epoch [80/2000], Avg Val Loss: 2.4794\n",
      "Validation loss improved from 2.4807 to 2.4794. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8668\n",
      "Epoch [81/2000], Avg Train Loss: 4.8668\n",
      "Epoch [81/2000], Avg Val Loss: 2.4781\n",
      "Validation loss improved from 2.4794 to 2.4781. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8277\n",
      "Epoch [82/2000], Avg Train Loss: 4.8277\n",
      "Epoch [82/2000], Avg Val Loss: 2.4769\n",
      "Validation loss improved from 2.4781 to 2.4769. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9115\n",
      "Epoch [83/2000], Avg Train Loss: 4.9115\n",
      "Epoch [83/2000], Avg Val Loss: 2.4757\n",
      "Validation loss improved from 2.4769 to 2.4757. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8002\n",
      "Epoch [84/2000], Avg Train Loss: 4.8002\n",
      "Epoch [84/2000], Avg Val Loss: 2.4745\n",
      "Validation loss improved from 2.4757 to 2.4745. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8010\n",
      "Epoch [85/2000], Avg Train Loss: 4.8010\n",
      "Epoch [85/2000], Avg Val Loss: 2.4734\n",
      "Validation loss improved from 2.4745 to 2.4734. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8575\n",
      "Epoch [86/2000], Avg Train Loss: 4.8575\n",
      "Epoch [86/2000], Avg Val Loss: 2.4722\n",
      "Validation loss improved from 2.4734 to 2.4722. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7736\n",
      "Epoch [87/2000], Avg Train Loss: 4.7736\n",
      "Epoch [87/2000], Avg Val Loss: 2.4711\n",
      "Validation loss improved from 2.4722 to 2.4711. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8078\n",
      "Epoch [88/2000], Avg Train Loss: 4.8078\n",
      "Epoch [88/2000], Avg Val Loss: 2.4701\n",
      "Validation loss improved from 2.4711 to 2.4701. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8679\n",
      "Epoch [89/2000], Avg Train Loss: 4.8679\n",
      "Epoch [89/2000], Avg Val Loss: 2.4690\n",
      "Validation loss improved from 2.4701 to 2.4690. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6892\n",
      "Epoch [90/2000], Avg Train Loss: 4.6892\n",
      "Epoch [90/2000], Avg Val Loss: 2.4679\n",
      "Validation loss improved from 2.4690 to 2.4679. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7356\n",
      "Epoch [91/2000], Avg Train Loss: 4.7356\n",
      "Epoch [91/2000], Avg Val Loss: 2.4668\n",
      "Validation loss improved from 2.4679 to 2.4668. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7288\n",
      "Epoch [92/2000], Avg Train Loss: 4.7288\n",
      "Epoch [92/2000], Avg Val Loss: 2.4657\n",
      "Validation loss improved from 2.4668 to 2.4657. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6872\n",
      "Epoch [93/2000], Avg Train Loss: 4.6872\n",
      "Epoch [93/2000], Avg Val Loss: 2.4647\n",
      "Validation loss improved from 2.4657 to 2.4647. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6582\n",
      "Epoch [94/2000], Avg Train Loss: 4.6582\n",
      "Epoch [94/2000], Avg Val Loss: 2.4636\n",
      "Validation loss improved from 2.4647 to 2.4636. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7275\n",
      "Epoch [95/2000], Avg Train Loss: 4.7275\n",
      "Epoch [95/2000], Avg Val Loss: 2.4626\n",
      "Validation loss improved from 2.4636 to 2.4626. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5884\n",
      "Epoch [96/2000], Avg Train Loss: 4.5884\n",
      "Epoch [96/2000], Avg Val Loss: 2.4615\n",
      "Validation loss improved from 2.4626 to 2.4615. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7135\n",
      "Epoch [97/2000], Avg Train Loss: 4.7135\n",
      "Epoch [97/2000], Avg Val Loss: 2.4605\n",
      "Validation loss improved from 2.4615 to 2.4605. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6762\n",
      "Epoch [98/2000], Avg Train Loss: 4.6762\n",
      "Epoch [98/2000], Avg Val Loss: 2.4595\n",
      "Validation loss improved from 2.4605 to 2.4595. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6209\n",
      "Epoch [99/2000], Avg Train Loss: 4.6209\n",
      "Epoch [99/2000], Avg Val Loss: 2.4586\n",
      "Validation loss improved from 2.4595 to 2.4586. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6460\n",
      "Epoch [100/2000], Avg Train Loss: 4.6460\n",
      "Epoch [100/2000], Avg Val Loss: 2.4576\n",
      "Validation loss improved from 2.4586 to 2.4576. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6461\n",
      "Epoch [101/2000], Avg Train Loss: 4.6461\n",
      "Epoch [101/2000], Avg Val Loss: 2.4565\n",
      "Validation loss improved from 2.4576 to 2.4565. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6987\n",
      "Epoch [102/2000], Avg Train Loss: 4.6987\n",
      "Epoch [102/2000], Avg Val Loss: 2.4555\n",
      "Validation loss improved from 2.4565 to 2.4555. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6641\n",
      "Epoch [103/2000], Avg Train Loss: 4.6641\n",
      "Epoch [103/2000], Avg Val Loss: 2.4545\n",
      "Validation loss improved from 2.4555 to 2.4545. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6552\n",
      "Epoch [104/2000], Avg Train Loss: 4.6552\n",
      "Epoch [104/2000], Avg Val Loss: 2.4535\n",
      "Validation loss improved from 2.4545 to 2.4535. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6377\n",
      "Epoch [105/2000], Avg Train Loss: 4.6377\n",
      "Epoch [105/2000], Avg Val Loss: 2.4525\n",
      "Validation loss improved from 2.4535 to 2.4525. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5759\n",
      "Epoch [106/2000], Avg Train Loss: 4.5759\n",
      "Epoch [106/2000], Avg Val Loss: 2.4515\n",
      "Validation loss improved from 2.4525 to 2.4515. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5867\n",
      "Epoch [107/2000], Avg Train Loss: 4.5867\n",
      "Epoch [107/2000], Avg Val Loss: 2.4504\n",
      "Validation loss improved from 2.4515 to 2.4504. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6745\n",
      "Epoch [108/2000], Avg Train Loss: 4.6745\n",
      "Epoch [108/2000], Avg Val Loss: 2.4494\n",
      "Validation loss improved from 2.4504 to 2.4494. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5461\n",
      "Epoch [109/2000], Avg Train Loss: 4.5461\n",
      "Epoch [109/2000], Avg Val Loss: 2.4484\n",
      "Validation loss improved from 2.4494 to 2.4484. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5748\n",
      "Epoch [110/2000], Avg Train Loss: 4.5748\n",
      "Epoch [110/2000], Avg Val Loss: 2.4474\n",
      "Validation loss improved from 2.4484 to 2.4474. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6022\n",
      "Epoch [111/2000], Avg Train Loss: 4.6022\n",
      "Epoch [111/2000], Avg Val Loss: 2.4463\n",
      "Validation loss improved from 2.4474 to 2.4463. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5465\n",
      "Epoch [112/2000], Avg Train Loss: 4.5465\n",
      "Epoch [112/2000], Avg Val Loss: 2.4453\n",
      "Validation loss improved from 2.4463 to 2.4453. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6096\n",
      "Epoch [113/2000], Avg Train Loss: 4.6096\n",
      "Epoch [113/2000], Avg Val Loss: 2.4443\n",
      "Validation loss improved from 2.4453 to 2.4443. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4821\n",
      "Epoch [114/2000], Avg Train Loss: 4.4821\n",
      "Epoch [114/2000], Avg Val Loss: 2.4433\n",
      "Validation loss improved from 2.4443 to 2.4433. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5058\n",
      "Epoch [115/2000], Avg Train Loss: 4.5058\n",
      "Epoch [115/2000], Avg Val Loss: 2.4423\n",
      "Validation loss improved from 2.4433 to 2.4423. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5911\n",
      "Epoch [116/2000], Avg Train Loss: 4.5911\n",
      "Epoch [116/2000], Avg Val Loss: 2.4413\n",
      "Validation loss improved from 2.4423 to 2.4413. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5874\n",
      "Epoch [117/2000], Avg Train Loss: 4.5874\n",
      "Epoch [117/2000], Avg Val Loss: 2.4403\n",
      "Validation loss improved from 2.4413 to 2.4403. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5223\n",
      "Epoch [118/2000], Avg Train Loss: 4.5223\n",
      "Epoch [118/2000], Avg Val Loss: 2.4393\n",
      "Validation loss improved from 2.4403 to 2.4393. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5037\n",
      "Epoch [119/2000], Avg Train Loss: 4.5037\n",
      "Epoch [119/2000], Avg Val Loss: 2.4382\n",
      "Validation loss improved from 2.4393 to 2.4382. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5456\n",
      "Epoch [120/2000], Avg Train Loss: 4.5456\n",
      "Epoch [120/2000], Avg Val Loss: 2.4372\n",
      "Validation loss improved from 2.4382 to 2.4372. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5008\n",
      "Epoch [121/2000], Avg Train Loss: 4.5008\n",
      "Epoch [121/2000], Avg Val Loss: 2.4362\n",
      "Validation loss improved from 2.4372 to 2.4362. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5287\n",
      "Epoch [122/2000], Avg Train Loss: 4.5287\n",
      "Epoch [122/2000], Avg Val Loss: 2.4352\n",
      "Validation loss improved from 2.4362 to 2.4352. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4779\n",
      "Epoch [123/2000], Avg Train Loss: 4.4779\n",
      "Epoch [123/2000], Avg Val Loss: 2.4342\n",
      "Validation loss improved from 2.4352 to 2.4342. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5142\n",
      "Epoch [124/2000], Avg Train Loss: 4.5142\n",
      "Epoch [124/2000], Avg Val Loss: 2.4332\n",
      "Validation loss improved from 2.4342 to 2.4332. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4575\n",
      "Epoch [125/2000], Avg Train Loss: 4.4575\n",
      "Epoch [125/2000], Avg Val Loss: 2.4321\n",
      "Validation loss improved from 2.4332 to 2.4321. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4042\n",
      "Epoch [126/2000], Avg Train Loss: 4.4042\n",
      "Epoch [126/2000], Avg Val Loss: 2.4310\n",
      "Validation loss improved from 2.4321 to 2.4310. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5647\n",
      "Epoch [127/2000], Avg Train Loss: 4.5647\n",
      "Epoch [127/2000], Avg Val Loss: 2.4300\n",
      "Validation loss improved from 2.4310 to 2.4300. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4639\n",
      "Epoch [128/2000], Avg Train Loss: 4.4639\n",
      "Epoch [128/2000], Avg Val Loss: 2.4289\n",
      "Validation loss improved from 2.4300 to 2.4289. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4089\n",
      "Epoch [129/2000], Avg Train Loss: 4.4089\n",
      "Epoch [129/2000], Avg Val Loss: 2.4278\n",
      "Validation loss improved from 2.4289 to 2.4278. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4391\n",
      "Epoch [130/2000], Avg Train Loss: 4.4391\n",
      "Epoch [130/2000], Avg Val Loss: 2.4267\n",
      "Validation loss improved from 2.4278 to 2.4267. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4056\n",
      "Epoch [131/2000], Avg Train Loss: 4.4056\n",
      "Epoch [131/2000], Avg Val Loss: 2.4256\n",
      "Validation loss improved from 2.4267 to 2.4256. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4868\n",
      "Epoch [132/2000], Avg Train Loss: 4.4868\n",
      "Epoch [132/2000], Avg Val Loss: 2.4245\n",
      "Validation loss improved from 2.4256 to 2.4245. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3957\n",
      "Epoch [133/2000], Avg Train Loss: 4.3957\n",
      "Epoch [133/2000], Avg Val Loss: 2.4234\n",
      "Validation loss improved from 2.4245 to 2.4234. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4211\n",
      "Epoch [134/2000], Avg Train Loss: 4.4211\n",
      "Epoch [134/2000], Avg Val Loss: 2.4223\n",
      "Validation loss improved from 2.4234 to 2.4223. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4256\n",
      "Epoch [135/2000], Avg Train Loss: 4.4256\n",
      "Epoch [135/2000], Avg Val Loss: 2.4212\n",
      "Validation loss improved from 2.4223 to 2.4212. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4685\n",
      "Epoch [136/2000], Avg Train Loss: 4.4685\n",
      "Epoch [136/2000], Avg Val Loss: 2.4202\n",
      "Validation loss improved from 2.4212 to 2.4202. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4101\n",
      "Epoch [137/2000], Avg Train Loss: 4.4101\n",
      "Epoch [137/2000], Avg Val Loss: 2.4191\n",
      "Validation loss improved from 2.4202 to 2.4191. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3987\n",
      "Epoch [138/2000], Avg Train Loss: 4.3987\n",
      "Epoch [138/2000], Avg Val Loss: 2.4180\n",
      "Validation loss improved from 2.4191 to 2.4180. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4150\n",
      "Epoch [139/2000], Avg Train Loss: 4.4150\n",
      "Epoch [139/2000], Avg Val Loss: 2.4169\n",
      "Validation loss improved from 2.4180 to 2.4169. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4179\n",
      "Epoch [140/2000], Avg Train Loss: 4.4179\n",
      "Epoch [140/2000], Avg Val Loss: 2.4158\n",
      "Validation loss improved from 2.4169 to 2.4158. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4356\n",
      "Epoch [141/2000], Avg Train Loss: 4.4356\n",
      "Epoch [141/2000], Avg Val Loss: 2.4147\n",
      "Validation loss improved from 2.4158 to 2.4147. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4325\n",
      "Epoch [142/2000], Avg Train Loss: 4.4325\n",
      "Epoch [142/2000], Avg Val Loss: 2.4135\n",
      "Validation loss improved from 2.4147 to 2.4135. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4155\n",
      "Epoch [143/2000], Avg Train Loss: 4.4155\n",
      "Epoch [143/2000], Avg Val Loss: 2.4124\n",
      "Validation loss improved from 2.4135 to 2.4124. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3495\n",
      "Epoch [144/2000], Avg Train Loss: 4.3495\n",
      "Epoch [144/2000], Avg Val Loss: 2.4113\n",
      "Validation loss improved from 2.4124 to 2.4113. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3356\n",
      "Epoch [145/2000], Avg Train Loss: 4.3356\n",
      "Epoch [145/2000], Avg Val Loss: 2.4102\n",
      "Validation loss improved from 2.4113 to 2.4102. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4306\n",
      "Epoch [146/2000], Avg Train Loss: 4.4306\n",
      "Epoch [146/2000], Avg Val Loss: 2.4091\n",
      "Validation loss improved from 2.4102 to 2.4091. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3787\n",
      "Epoch [147/2000], Avg Train Loss: 4.3787\n",
      "Epoch [147/2000], Avg Val Loss: 2.4079\n",
      "Validation loss improved from 2.4091 to 2.4079. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4277\n",
      "Epoch [148/2000], Avg Train Loss: 4.4277\n",
      "Epoch [148/2000], Avg Val Loss: 2.4068\n",
      "Validation loss improved from 2.4079 to 2.4068. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3482\n",
      "Epoch [149/2000], Avg Train Loss: 4.3482\n",
      "Epoch [149/2000], Avg Val Loss: 2.4057\n",
      "Validation loss improved from 2.4068 to 2.4057. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3374\n",
      "Epoch [150/2000], Avg Train Loss: 4.3374\n",
      "Epoch [150/2000], Avg Val Loss: 2.4046\n",
      "Validation loss improved from 2.4057 to 2.4046. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3636\n",
      "Epoch [151/2000], Avg Train Loss: 4.3636\n",
      "Epoch [151/2000], Avg Val Loss: 2.4035\n",
      "Validation loss improved from 2.4046 to 2.4035. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3271\n",
      "Epoch [152/2000], Avg Train Loss: 4.3271\n",
      "Epoch [152/2000], Avg Val Loss: 2.4024\n",
      "Validation loss improved from 2.4035 to 2.4024. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3453\n",
      "Epoch [153/2000], Avg Train Loss: 4.3453\n",
      "Epoch [153/2000], Avg Val Loss: 2.4012\n",
      "Validation loss improved from 2.4024 to 2.4012. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2745\n",
      "Epoch [154/2000], Avg Train Loss: 4.2745\n",
      "Epoch [154/2000], Avg Val Loss: 2.4001\n",
      "Validation loss improved from 2.4012 to 2.4001. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2805\n",
      "Epoch [155/2000], Avg Train Loss: 4.2805\n",
      "Epoch [155/2000], Avg Val Loss: 2.3990\n",
      "Validation loss improved from 2.4001 to 2.3990. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3019\n",
      "Epoch [156/2000], Avg Train Loss: 4.3019\n",
      "Epoch [156/2000], Avg Val Loss: 2.3978\n",
      "Validation loss improved from 2.3990 to 2.3978. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3850\n",
      "Epoch [157/2000], Avg Train Loss: 4.3850\n",
      "Epoch [157/2000], Avg Val Loss: 2.3967\n",
      "Validation loss improved from 2.3978 to 2.3967. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3466\n",
      "Epoch [158/2000], Avg Train Loss: 4.3466\n",
      "Epoch [158/2000], Avg Val Loss: 2.3955\n",
      "Validation loss improved from 2.3967 to 2.3955. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3503\n",
      "Epoch [159/2000], Avg Train Loss: 4.3503\n",
      "Epoch [159/2000], Avg Val Loss: 2.3944\n",
      "Validation loss improved from 2.3955 to 2.3944. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3118\n",
      "Epoch [160/2000], Avg Train Loss: 4.3118\n",
      "Epoch [160/2000], Avg Val Loss: 2.3933\n",
      "Validation loss improved from 2.3944 to 2.3933. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3000\n",
      "Epoch [161/2000], Avg Train Loss: 4.3000\n",
      "Epoch [161/2000], Avg Val Loss: 2.3921\n",
      "Validation loss improved from 2.3933 to 2.3921. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3781\n",
      "Epoch [162/2000], Avg Train Loss: 4.3781\n",
      "Epoch [162/2000], Avg Val Loss: 2.3910\n",
      "Validation loss improved from 2.3921 to 2.3910. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3115\n",
      "Epoch [163/2000], Avg Train Loss: 4.3115\n",
      "Epoch [163/2000], Avg Val Loss: 2.3899\n",
      "Validation loss improved from 2.3910 to 2.3899. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2913\n",
      "Epoch [164/2000], Avg Train Loss: 4.2913\n",
      "Epoch [164/2000], Avg Val Loss: 2.3888\n",
      "Validation loss improved from 2.3899 to 2.3888. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2586\n",
      "Epoch [165/2000], Avg Train Loss: 4.2586\n",
      "Epoch [165/2000], Avg Val Loss: 2.3876\n",
      "Validation loss improved from 2.3888 to 2.3876. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3148\n",
      "Epoch [166/2000], Avg Train Loss: 4.3148\n",
      "Epoch [166/2000], Avg Val Loss: 2.3865\n",
      "Validation loss improved from 2.3876 to 2.3865. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2953\n",
      "Epoch [167/2000], Avg Train Loss: 4.2953\n",
      "Epoch [167/2000], Avg Val Loss: 2.3854\n",
      "Validation loss improved from 2.3865 to 2.3854. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3322\n",
      "Epoch [168/2000], Avg Train Loss: 4.3322\n",
      "Epoch [168/2000], Avg Val Loss: 2.3842\n",
      "Validation loss improved from 2.3854 to 2.3842. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2373\n",
      "Epoch [169/2000], Avg Train Loss: 4.2373\n",
      "Epoch [169/2000], Avg Val Loss: 2.3831\n",
      "Validation loss improved from 2.3842 to 2.3831. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2642\n",
      "Epoch [170/2000], Avg Train Loss: 4.2642\n",
      "Epoch [170/2000], Avg Val Loss: 2.3819\n",
      "Validation loss improved from 2.3831 to 2.3819. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3511\n",
      "Epoch [171/2000], Avg Train Loss: 4.3511\n",
      "Epoch [171/2000], Avg Val Loss: 2.3808\n",
      "Validation loss improved from 2.3819 to 2.3808. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2619\n",
      "Epoch [172/2000], Avg Train Loss: 4.2619\n",
      "Epoch [172/2000], Avg Val Loss: 2.3797\n",
      "Validation loss improved from 2.3808 to 2.3797. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2968\n",
      "Epoch [173/2000], Avg Train Loss: 4.2968\n",
      "Epoch [173/2000], Avg Val Loss: 2.3786\n",
      "Validation loss improved from 2.3797 to 2.3786. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2565\n",
      "Epoch [174/2000], Avg Train Loss: 4.2565\n",
      "Epoch [174/2000], Avg Val Loss: 2.3775\n",
      "Validation loss improved from 2.3786 to 2.3775. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2683\n",
      "Epoch [175/2000], Avg Train Loss: 4.2683\n",
      "Epoch [175/2000], Avg Val Loss: 2.3764\n",
      "Validation loss improved from 2.3775 to 2.3764. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2516\n",
      "Epoch [176/2000], Avg Train Loss: 4.2516\n",
      "Epoch [176/2000], Avg Val Loss: 2.3752\n",
      "Validation loss improved from 2.3764 to 2.3752. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3052\n",
      "Epoch [177/2000], Avg Train Loss: 4.3052\n",
      "Epoch [177/2000], Avg Val Loss: 2.3741\n",
      "Validation loss improved from 2.3752 to 2.3741. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2815\n",
      "Epoch [178/2000], Avg Train Loss: 4.2815\n",
      "Epoch [178/2000], Avg Val Loss: 2.3730\n",
      "Validation loss improved from 2.3741 to 2.3730. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2714\n",
      "Epoch [179/2000], Avg Train Loss: 4.2714\n",
      "Epoch [179/2000], Avg Val Loss: 2.3719\n",
      "Validation loss improved from 2.3730 to 2.3719. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2346\n",
      "Epoch [180/2000], Avg Train Loss: 4.2346\n",
      "Epoch [180/2000], Avg Val Loss: 2.3708\n",
      "Validation loss improved from 2.3719 to 2.3708. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2862\n",
      "Epoch [181/2000], Avg Train Loss: 4.2862\n",
      "Epoch [181/2000], Avg Val Loss: 2.3698\n",
      "Validation loss improved from 2.3708 to 2.3698. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2245\n",
      "Epoch [182/2000], Avg Train Loss: 4.2245\n",
      "Epoch [182/2000], Avg Val Loss: 2.3687\n",
      "Validation loss improved from 2.3698 to 2.3687. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2563\n",
      "Epoch [183/2000], Avg Train Loss: 4.2563\n",
      "Epoch [183/2000], Avg Val Loss: 2.3675\n",
      "Validation loss improved from 2.3687 to 2.3675. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2167\n",
      "Epoch [184/2000], Avg Train Loss: 4.2167\n",
      "Epoch [184/2000], Avg Val Loss: 2.3664\n",
      "Validation loss improved from 2.3675 to 2.3664. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2339\n",
      "Epoch [185/2000], Avg Train Loss: 4.2339\n",
      "Epoch [185/2000], Avg Val Loss: 2.3653\n",
      "Validation loss improved from 2.3664 to 2.3653. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2237\n",
      "Epoch [186/2000], Avg Train Loss: 4.2237\n",
      "Epoch [186/2000], Avg Val Loss: 2.3643\n",
      "Validation loss improved from 2.3653 to 2.3643. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2300\n",
      "Epoch [187/2000], Avg Train Loss: 4.2300\n",
      "Epoch [187/2000], Avg Val Loss: 2.3632\n",
      "Validation loss improved from 2.3643 to 2.3632. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2093\n",
      "Epoch [188/2000], Avg Train Loss: 4.2093\n",
      "Epoch [188/2000], Avg Val Loss: 2.3621\n",
      "Validation loss improved from 2.3632 to 2.3621. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1888\n",
      "Epoch [189/2000], Avg Train Loss: 4.1888\n",
      "Epoch [189/2000], Avg Val Loss: 2.3611\n",
      "Validation loss improved from 2.3621 to 2.3611. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1390\n",
      "Epoch [190/2000], Avg Train Loss: 4.1390\n",
      "Epoch [190/2000], Avg Val Loss: 2.3600\n",
      "Validation loss improved from 2.3611 to 2.3600. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1908\n",
      "Epoch [191/2000], Avg Train Loss: 4.1908\n",
      "Epoch [191/2000], Avg Val Loss: 2.3589\n",
      "Validation loss improved from 2.3600 to 2.3589. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1953\n",
      "Epoch [192/2000], Avg Train Loss: 4.1953\n",
      "Epoch [192/2000], Avg Val Loss: 2.3578\n",
      "Validation loss improved from 2.3589 to 2.3578. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2227\n",
      "Epoch [193/2000], Avg Train Loss: 4.2227\n",
      "Epoch [193/2000], Avg Val Loss: 2.3567\n",
      "Validation loss improved from 2.3578 to 2.3567. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2102\n",
      "Epoch [194/2000], Avg Train Loss: 4.2102\n",
      "Epoch [194/2000], Avg Val Loss: 2.3556\n",
      "Validation loss improved from 2.3567 to 2.3556. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1666\n",
      "Epoch [195/2000], Avg Train Loss: 4.1666\n",
      "Epoch [195/2000], Avg Val Loss: 2.3545\n",
      "Validation loss improved from 2.3556 to 2.3545. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1765\n",
      "Epoch [196/2000], Avg Train Loss: 4.1765\n",
      "Epoch [196/2000], Avg Val Loss: 2.3534\n",
      "Validation loss improved from 2.3545 to 2.3534. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1537\n",
      "Epoch [197/2000], Avg Train Loss: 4.1537\n",
      "Epoch [197/2000], Avg Val Loss: 2.3523\n",
      "Validation loss improved from 2.3534 to 2.3523. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2041\n",
      "Epoch [198/2000], Avg Train Loss: 4.2041\n",
      "Epoch [198/2000], Avg Val Loss: 2.3512\n",
      "Validation loss improved from 2.3523 to 2.3512. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1428\n",
      "Epoch [199/2000], Avg Train Loss: 4.1428\n",
      "Epoch [199/2000], Avg Val Loss: 2.3501\n",
      "Validation loss improved from 2.3512 to 2.3501. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1498\n",
      "Epoch [200/2000], Avg Train Loss: 4.1498\n",
      "Epoch [200/2000], Avg Val Loss: 2.3490\n",
      "Validation loss improved from 2.3501 to 2.3490. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1696\n",
      "Epoch [201/2000], Avg Train Loss: 4.1696\n",
      "Epoch [201/2000], Avg Val Loss: 2.3479\n",
      "Validation loss improved from 2.3490 to 2.3479. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1963\n",
      "Epoch [202/2000], Avg Train Loss: 4.1963\n",
      "Epoch [202/2000], Avg Val Loss: 2.3469\n",
      "Validation loss improved from 2.3479 to 2.3469. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1678\n",
      "Epoch [203/2000], Avg Train Loss: 4.1678\n",
      "Epoch [203/2000], Avg Val Loss: 2.3458\n",
      "Validation loss improved from 2.3469 to 2.3458. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1225\n",
      "Epoch [204/2000], Avg Train Loss: 4.1225\n",
      "Epoch [204/2000], Avg Val Loss: 2.3447\n",
      "Validation loss improved from 2.3458 to 2.3447. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1767\n",
      "Epoch [205/2000], Avg Train Loss: 4.1767\n",
      "Epoch [205/2000], Avg Val Loss: 2.3436\n",
      "Validation loss improved from 2.3447 to 2.3436. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1109\n",
      "Epoch [206/2000], Avg Train Loss: 4.1109\n",
      "Epoch [206/2000], Avg Val Loss: 2.3425\n",
      "Validation loss improved from 2.3436 to 2.3425. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1482\n",
      "Epoch [207/2000], Avg Train Loss: 4.1482\n",
      "Epoch [207/2000], Avg Val Loss: 2.3415\n",
      "Validation loss improved from 2.3425 to 2.3415. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1965\n",
      "Epoch [208/2000], Avg Train Loss: 4.1965\n",
      "Epoch [208/2000], Avg Val Loss: 2.3404\n",
      "Validation loss improved from 2.3415 to 2.3404. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1496\n",
      "Epoch [209/2000], Avg Train Loss: 4.1496\n",
      "Epoch [209/2000], Avg Val Loss: 2.3393\n",
      "Validation loss improved from 2.3404 to 2.3393. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1081\n",
      "Epoch [210/2000], Avg Train Loss: 4.1081\n",
      "Epoch [210/2000], Avg Val Loss: 2.3383\n",
      "Validation loss improved from 2.3393 to 2.3383. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1406\n",
      "Epoch [211/2000], Avg Train Loss: 4.1406\n",
      "Epoch [211/2000], Avg Val Loss: 2.3372\n",
      "Validation loss improved from 2.3383 to 2.3372. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1424\n",
      "Epoch [212/2000], Avg Train Loss: 4.1424\n",
      "Epoch [212/2000], Avg Val Loss: 2.3362\n",
      "Validation loss improved from 2.3372 to 2.3362. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1367\n",
      "Epoch [213/2000], Avg Train Loss: 4.1367\n",
      "Epoch [213/2000], Avg Val Loss: 2.3351\n",
      "Validation loss improved from 2.3362 to 2.3351. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1346\n",
      "Epoch [214/2000], Avg Train Loss: 4.1346\n",
      "Epoch [214/2000], Avg Val Loss: 2.3340\n",
      "Validation loss improved from 2.3351 to 2.3340. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1496\n",
      "Epoch [215/2000], Avg Train Loss: 4.1496\n",
      "Epoch [215/2000], Avg Val Loss: 2.3330\n",
      "Validation loss improved from 2.3340 to 2.3330. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1347\n",
      "Epoch [216/2000], Avg Train Loss: 4.1347\n",
      "Epoch [216/2000], Avg Val Loss: 2.3320\n",
      "Validation loss improved from 2.3330 to 2.3320. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1347\n",
      "Epoch [217/2000], Avg Train Loss: 4.1347\n",
      "Epoch [217/2000], Avg Val Loss: 2.3309\n",
      "Validation loss improved from 2.3320 to 2.3309. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1243\n",
      "Epoch [218/2000], Avg Train Loss: 4.1243\n",
      "Epoch [218/2000], Avg Val Loss: 2.3299\n",
      "Validation loss improved from 2.3309 to 2.3299. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0976\n",
      "Epoch [219/2000], Avg Train Loss: 4.0976\n",
      "Epoch [219/2000], Avg Val Loss: 2.3288\n",
      "Validation loss improved from 2.3299 to 2.3288. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1582\n",
      "Epoch [220/2000], Avg Train Loss: 4.1582\n",
      "Epoch [220/2000], Avg Val Loss: 2.3278\n",
      "Validation loss improved from 2.3288 to 2.3278. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1353\n",
      "Epoch [221/2000], Avg Train Loss: 4.1353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [221/2000], Avg Val Loss: 2.3267\n",
      "Validation loss improved from 2.3278 to 2.3267. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1134\n",
      "Epoch [222/2000], Avg Train Loss: 4.1134\n",
      "Epoch [222/2000], Avg Val Loss: 2.3257\n",
      "Validation loss improved from 2.3267 to 2.3257. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1349\n",
      "Epoch [223/2000], Avg Train Loss: 4.1349\n",
      "Epoch [223/2000], Avg Val Loss: 2.3247\n",
      "Validation loss improved from 2.3257 to 2.3247. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1077\n",
      "Epoch [224/2000], Avg Train Loss: 4.1077\n",
      "Epoch [224/2000], Avg Val Loss: 2.3237\n",
      "Validation loss improved from 2.3247 to 2.3237. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1314\n",
      "Epoch [225/2000], Avg Train Loss: 4.1314\n",
      "Epoch [225/2000], Avg Val Loss: 2.3226\n",
      "Validation loss improved from 2.3237 to 2.3226. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1147\n",
      "Epoch [226/2000], Avg Train Loss: 4.1147\n",
      "Epoch [226/2000], Avg Val Loss: 2.3216\n",
      "Validation loss improved from 2.3226 to 2.3216. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1145\n",
      "Epoch [227/2000], Avg Train Loss: 4.1145\n",
      "Epoch [227/2000], Avg Val Loss: 2.3206\n",
      "Validation loss improved from 2.3216 to 2.3206. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1349\n",
      "Epoch [228/2000], Avg Train Loss: 4.1349\n",
      "Epoch [228/2000], Avg Val Loss: 2.3196\n",
      "Validation loss improved from 2.3206 to 2.3196. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1069\n",
      "Epoch [229/2000], Avg Train Loss: 4.1069\n",
      "Epoch [229/2000], Avg Val Loss: 2.3186\n",
      "Validation loss improved from 2.3196 to 2.3186. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1182\n",
      "Epoch [230/2000], Avg Train Loss: 4.1182\n",
      "Epoch [230/2000], Avg Val Loss: 2.3176\n",
      "Validation loss improved from 2.3186 to 2.3176. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0960\n",
      "Epoch [231/2000], Avg Train Loss: 4.0960\n",
      "Epoch [231/2000], Avg Val Loss: 2.3166\n",
      "Validation loss improved from 2.3176 to 2.3166. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0981\n",
      "Epoch [232/2000], Avg Train Loss: 4.0981\n",
      "Epoch [232/2000], Avg Val Loss: 2.3156\n",
      "Validation loss improved from 2.3166 to 2.3156. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0820\n",
      "Epoch [233/2000], Avg Train Loss: 4.0820\n",
      "Epoch [233/2000], Avg Val Loss: 2.3146\n",
      "Validation loss improved from 2.3156 to 2.3146. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1376\n",
      "Epoch [234/2000], Avg Train Loss: 4.1376\n",
      "Epoch [234/2000], Avg Val Loss: 2.3136\n",
      "Validation loss improved from 2.3146 to 2.3136. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0539\n",
      "Epoch [235/2000], Avg Train Loss: 4.0539\n",
      "Epoch [235/2000], Avg Val Loss: 2.3126\n",
      "Validation loss improved from 2.3136 to 2.3126. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0575\n",
      "Epoch [236/2000], Avg Train Loss: 4.0575\n",
      "Epoch [236/2000], Avg Val Loss: 2.3116\n",
      "Validation loss improved from 2.3126 to 2.3116. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1407\n",
      "Epoch [237/2000], Avg Train Loss: 4.1407\n",
      "Epoch [237/2000], Avg Val Loss: 2.3106\n",
      "Validation loss improved from 2.3116 to 2.3106. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1130\n",
      "Epoch [238/2000], Avg Train Loss: 4.1130\n",
      "Epoch [238/2000], Avg Val Loss: 2.3096\n",
      "Validation loss improved from 2.3106 to 2.3096. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0372\n",
      "Epoch [239/2000], Avg Train Loss: 4.0372\n",
      "Epoch [239/2000], Avg Val Loss: 2.3086\n",
      "Validation loss improved from 2.3096 to 2.3086. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0820\n",
      "Epoch [240/2000], Avg Train Loss: 4.0820\n",
      "Epoch [240/2000], Avg Val Loss: 2.3076\n",
      "Validation loss improved from 2.3086 to 2.3076. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0618\n",
      "Epoch [241/2000], Avg Train Loss: 4.0618\n",
      "Epoch [241/2000], Avg Val Loss: 2.3066\n",
      "Validation loss improved from 2.3076 to 2.3066. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1060\n",
      "Epoch [242/2000], Avg Train Loss: 4.1060\n",
      "Epoch [242/2000], Avg Val Loss: 2.3056\n",
      "Validation loss improved from 2.3066 to 2.3056. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0176\n",
      "Epoch [243/2000], Avg Train Loss: 4.0176\n",
      "Epoch [243/2000], Avg Val Loss: 2.3046\n",
      "Validation loss improved from 2.3056 to 2.3046. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0300\n",
      "Epoch [244/2000], Avg Train Loss: 4.0300\n",
      "Epoch [244/2000], Avg Val Loss: 2.3036\n",
      "Validation loss improved from 2.3046 to 2.3036. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0702\n",
      "Epoch [245/2000], Avg Train Loss: 4.0702\n",
      "Epoch [245/2000], Avg Val Loss: 2.3026\n",
      "Validation loss improved from 2.3036 to 2.3026. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0570\n",
      "Epoch [246/2000], Avg Train Loss: 4.0570\n",
      "Epoch [246/2000], Avg Val Loss: 2.3016\n",
      "Validation loss improved from 2.3026 to 2.3016. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0613\n",
      "Epoch [247/2000], Avg Train Loss: 4.0613\n",
      "Epoch [247/2000], Avg Val Loss: 2.3005\n",
      "Validation loss improved from 2.3016 to 2.3005. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0536\n",
      "Epoch [248/2000], Avg Train Loss: 4.0536\n",
      "Epoch [248/2000], Avg Val Loss: 2.2995\n",
      "Validation loss improved from 2.3005 to 2.2995. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0661\n",
      "Epoch [249/2000], Avg Train Loss: 4.0661\n",
      "Epoch [249/2000], Avg Val Loss: 2.2985\n",
      "Validation loss improved from 2.2995 to 2.2985. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0540\n",
      "Epoch [250/2000], Avg Train Loss: 4.0540\n",
      "Epoch [250/2000], Avg Val Loss: 2.2975\n",
      "Validation loss improved from 2.2985 to 2.2975. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1105\n",
      "Epoch [251/2000], Avg Train Loss: 4.1105\n",
      "Epoch [251/2000], Avg Val Loss: 2.2966\n",
      "Validation loss improved from 2.2975 to 2.2966. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9954\n",
      "Epoch [252/2000], Avg Train Loss: 3.9954\n",
      "Epoch [252/2000], Avg Val Loss: 2.2956\n",
      "Validation loss improved from 2.2966 to 2.2956. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0222\n",
      "Epoch [253/2000], Avg Train Loss: 4.0222\n",
      "Epoch [253/2000], Avg Val Loss: 2.2947\n",
      "Validation loss improved from 2.2956 to 2.2947. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0757\n",
      "Epoch [254/2000], Avg Train Loss: 4.0757\n",
      "Epoch [254/2000], Avg Val Loss: 2.2937\n",
      "Validation loss improved from 2.2947 to 2.2937. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0658\n",
      "Epoch [255/2000], Avg Train Loss: 4.0658\n",
      "Epoch [255/2000], Avg Val Loss: 2.2928\n",
      "Validation loss improved from 2.2937 to 2.2928. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0587\n",
      "Epoch [256/2000], Avg Train Loss: 4.0587\n",
      "Epoch [256/2000], Avg Val Loss: 2.2919\n",
      "Validation loss improved from 2.2928 to 2.2919. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0197\n",
      "Epoch [257/2000], Avg Train Loss: 4.0197\n",
      "Epoch [257/2000], Avg Val Loss: 2.2909\n",
      "Validation loss improved from 2.2919 to 2.2909. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9965\n",
      "Epoch [258/2000], Avg Train Loss: 3.9965\n",
      "Epoch [258/2000], Avg Val Loss: 2.2900\n",
      "Validation loss improved from 2.2909 to 2.2900. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9920\n",
      "Epoch [259/2000], Avg Train Loss: 3.9920\n",
      "Epoch [259/2000], Avg Val Loss: 2.2890\n",
      "Validation loss improved from 2.2900 to 2.2890. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0811\n",
      "Epoch [260/2000], Avg Train Loss: 4.0811\n",
      "Epoch [260/2000], Avg Val Loss: 2.2881\n",
      "Validation loss improved from 2.2890 to 2.2881. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0253\n",
      "Epoch [261/2000], Avg Train Loss: 4.0253\n",
      "Epoch [261/2000], Avg Val Loss: 2.2871\n",
      "Validation loss improved from 2.2881 to 2.2871. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9675\n",
      "Epoch [262/2000], Avg Train Loss: 3.9675\n",
      "Epoch [262/2000], Avg Val Loss: 2.2862\n",
      "Validation loss improved from 2.2871 to 2.2862. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9986\n",
      "Epoch [263/2000], Avg Train Loss: 3.9986\n",
      "Epoch [263/2000], Avg Val Loss: 2.2852\n",
      "Validation loss improved from 2.2862 to 2.2852. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0129\n",
      "Epoch [264/2000], Avg Train Loss: 4.0129\n",
      "Epoch [264/2000], Avg Val Loss: 2.2842\n",
      "Validation loss improved from 2.2852 to 2.2842. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9837\n",
      "Epoch [265/2000], Avg Train Loss: 3.9837\n",
      "Epoch [265/2000], Avg Val Loss: 2.2833\n",
      "Validation loss improved from 2.2842 to 2.2833. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0467\n",
      "Epoch [266/2000], Avg Train Loss: 4.0467\n",
      "Epoch [266/2000], Avg Val Loss: 2.2824\n",
      "Validation loss improved from 2.2833 to 2.2824. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0813\n",
      "Epoch [267/2000], Avg Train Loss: 4.0813\n",
      "Epoch [267/2000], Avg Val Loss: 2.2814\n",
      "Validation loss improved from 2.2824 to 2.2814. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0538\n",
      "Epoch [268/2000], Avg Train Loss: 4.0538\n",
      "Epoch [268/2000], Avg Val Loss: 2.2805\n",
      "Validation loss improved from 2.2814 to 2.2805. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0112\n",
      "Epoch [269/2000], Avg Train Loss: 4.0112\n",
      "Epoch [269/2000], Avg Val Loss: 2.2796\n",
      "Validation loss improved from 2.2805 to 2.2796. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0383\n",
      "Epoch [270/2000], Avg Train Loss: 4.0383\n",
      "Epoch [270/2000], Avg Val Loss: 2.2787\n",
      "Validation loss improved from 2.2796 to 2.2787. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0284\n",
      "Epoch [271/2000], Avg Train Loss: 4.0284\n",
      "Epoch [271/2000], Avg Val Loss: 2.2778\n",
      "Validation loss improved from 2.2787 to 2.2778. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0318\n",
      "Epoch [272/2000], Avg Train Loss: 4.0318\n",
      "Epoch [272/2000], Avg Val Loss: 2.2769\n",
      "Validation loss improved from 2.2778 to 2.2769. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0345\n",
      "Epoch [273/2000], Avg Train Loss: 4.0345\n",
      "Epoch [273/2000], Avg Val Loss: 2.2760\n",
      "Validation loss improved from 2.2769 to 2.2760. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9852\n",
      "Epoch [274/2000], Avg Train Loss: 3.9852\n",
      "Epoch [274/2000], Avg Val Loss: 2.2751\n",
      "Validation loss improved from 2.2760 to 2.2751. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0223\n",
      "Epoch [275/2000], Avg Train Loss: 4.0223\n",
      "Epoch [275/2000], Avg Val Loss: 2.2742\n",
      "Validation loss improved from 2.2751 to 2.2742. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9691\n",
      "Epoch [276/2000], Avg Train Loss: 3.9691\n",
      "Epoch [276/2000], Avg Val Loss: 2.2733\n",
      "Validation loss improved from 2.2742 to 2.2733. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9793\n",
      "Epoch [277/2000], Avg Train Loss: 3.9793\n",
      "Epoch [277/2000], Avg Val Loss: 2.2724\n",
      "Validation loss improved from 2.2733 to 2.2724. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0153\n",
      "Epoch [278/2000], Avg Train Loss: 4.0153\n",
      "Epoch [278/2000], Avg Val Loss: 2.2715\n",
      "Validation loss improved from 2.2724 to 2.2715. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9670\n",
      "Epoch [279/2000], Avg Train Loss: 3.9670\n",
      "Epoch [279/2000], Avg Val Loss: 2.2706\n",
      "Validation loss improved from 2.2715 to 2.2706. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9449\n",
      "Epoch [280/2000], Avg Train Loss: 3.9449\n",
      "Epoch [280/2000], Avg Val Loss: 2.2697\n",
      "Validation loss improved from 2.2706 to 2.2697. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9771\n",
      "Epoch [281/2000], Avg Train Loss: 3.9771\n",
      "Epoch [281/2000], Avg Val Loss: 2.2688\n",
      "Validation loss improved from 2.2697 to 2.2688. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9976\n",
      "Epoch [282/2000], Avg Train Loss: 3.9976\n",
      "Epoch [282/2000], Avg Val Loss: 2.2679\n",
      "Validation loss improved from 2.2688 to 2.2679. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9772\n",
      "Epoch [283/2000], Avg Train Loss: 3.9772\n",
      "Epoch [283/2000], Avg Val Loss: 2.2670\n",
      "Validation loss improved from 2.2679 to 2.2670. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9705\n",
      "Epoch [284/2000], Avg Train Loss: 3.9705\n",
      "Epoch [284/2000], Avg Val Loss: 2.2661\n",
      "Validation loss improved from 2.2670 to 2.2661. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0548\n",
      "Epoch [285/2000], Avg Train Loss: 4.0548\n",
      "Epoch [285/2000], Avg Val Loss: 2.2652\n",
      "Validation loss improved from 2.2661 to 2.2652. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9821\n",
      "Epoch [286/2000], Avg Train Loss: 3.9821\n",
      "Epoch [286/2000], Avg Val Loss: 2.2643\n",
      "Validation loss improved from 2.2652 to 2.2643. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9956\n",
      "Epoch [287/2000], Avg Train Loss: 3.9956\n",
      "Epoch [287/2000], Avg Val Loss: 2.2635\n",
      "Validation loss improved from 2.2643 to 2.2635. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0050\n",
      "Epoch [288/2000], Avg Train Loss: 4.0050\n",
      "Epoch [288/2000], Avg Val Loss: 2.2626\n",
      "Validation loss improved from 2.2635 to 2.2626. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9949\n",
      "Epoch [289/2000], Avg Train Loss: 3.9949\n",
      "Epoch [289/2000], Avg Val Loss: 2.2617\n",
      "Validation loss improved from 2.2626 to 2.2617. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9999\n",
      "Epoch [290/2000], Avg Train Loss: 3.9999\n",
      "Epoch [290/2000], Avg Val Loss: 2.2609\n",
      "Validation loss improved from 2.2617 to 2.2609. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9885\n",
      "Epoch [291/2000], Avg Train Loss: 3.9885\n",
      "Epoch [291/2000], Avg Val Loss: 2.2600\n",
      "Validation loss improved from 2.2609 to 2.2600. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9581\n",
      "Epoch [292/2000], Avg Train Loss: 3.9581\n",
      "Epoch [292/2000], Avg Val Loss: 2.2592\n",
      "Validation loss improved from 2.2600 to 2.2592. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0185\n",
      "Epoch [293/2000], Avg Train Loss: 4.0185\n",
      "Epoch [293/2000], Avg Val Loss: 2.2583\n",
      "Validation loss improved from 2.2592 to 2.2583. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0185\n",
      "Epoch [294/2000], Avg Train Loss: 4.0185\n",
      "Epoch [294/2000], Avg Val Loss: 2.2575\n",
      "Validation loss improved from 2.2583 to 2.2575. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9759\n",
      "Epoch [295/2000], Avg Train Loss: 3.9759\n",
      "Epoch [295/2000], Avg Val Loss: 2.2566\n",
      "Validation loss improved from 2.2575 to 2.2566. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9930\n",
      "Epoch [296/2000], Avg Train Loss: 3.9930\n",
      "Epoch [296/2000], Avg Val Loss: 2.2557\n",
      "Validation loss improved from 2.2566 to 2.2557. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0199\n",
      "Epoch [297/2000], Avg Train Loss: 4.0199\n",
      "Epoch [297/2000], Avg Val Loss: 2.2549\n",
      "Validation loss improved from 2.2557 to 2.2549. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9284\n",
      "Epoch [298/2000], Avg Train Loss: 3.9284\n",
      "Epoch [298/2000], Avg Val Loss: 2.2541\n",
      "Validation loss improved from 2.2549 to 2.2541. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9848\n",
      "Epoch [299/2000], Avg Train Loss: 3.9848\n",
      "Epoch [299/2000], Avg Val Loss: 2.2532\n",
      "Validation loss improved from 2.2541 to 2.2532. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9545\n",
      "Epoch [300/2000], Avg Train Loss: 3.9545\n",
      "Epoch [300/2000], Avg Val Loss: 2.2523\n",
      "Validation loss improved from 2.2532 to 2.2523. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9629\n",
      "Epoch [301/2000], Avg Train Loss: 3.9629\n",
      "Epoch [301/2000], Avg Val Loss: 2.2515\n",
      "Validation loss improved from 2.2523 to 2.2515. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9573\n",
      "Epoch [302/2000], Avg Train Loss: 3.9573\n",
      "Epoch [302/2000], Avg Val Loss: 2.2506\n",
      "Validation loss improved from 2.2515 to 2.2506. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9663\n",
      "Epoch [303/2000], Avg Train Loss: 3.9663\n",
      "Epoch [303/2000], Avg Val Loss: 2.2498\n",
      "Validation loss improved from 2.2506 to 2.2498. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9224\n",
      "Epoch [304/2000], Avg Train Loss: 3.9224\n",
      "Epoch [304/2000], Avg Val Loss: 2.2489\n",
      "Validation loss improved from 2.2498 to 2.2489. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9603\n",
      "Epoch [305/2000], Avg Train Loss: 3.9603\n",
      "Epoch [305/2000], Avg Val Loss: 2.2480\n",
      "Validation loss improved from 2.2489 to 2.2480. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9414\n",
      "Epoch [306/2000], Avg Train Loss: 3.9414\n",
      "Epoch [306/2000], Avg Val Loss: 2.2472\n",
      "Validation loss improved from 2.2480 to 2.2472. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9659\n",
      "Epoch [307/2000], Avg Train Loss: 3.9659\n",
      "Epoch [307/2000], Avg Val Loss: 2.2463\n",
      "Validation loss improved from 2.2472 to 2.2463. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9320\n",
      "Epoch [308/2000], Avg Train Loss: 3.9320\n",
      "Epoch [308/2000], Avg Val Loss: 2.2454\n",
      "Validation loss improved from 2.2463 to 2.2454. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9266\n",
      "Epoch [309/2000], Avg Train Loss: 3.9266\n",
      "Epoch [309/2000], Avg Val Loss: 2.2445\n",
      "Validation loss improved from 2.2454 to 2.2445. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9526\n",
      "Epoch [310/2000], Avg Train Loss: 3.9526\n",
      "Epoch [310/2000], Avg Val Loss: 2.2437\n",
      "Validation loss improved from 2.2445 to 2.2437. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9361\n",
      "Epoch [311/2000], Avg Train Loss: 3.9361\n",
      "Epoch [311/2000], Avg Val Loss: 2.2428\n",
      "Validation loss improved from 2.2437 to 2.2428. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9303\n",
      "Epoch [312/2000], Avg Train Loss: 3.9303\n",
      "Epoch [312/2000], Avg Val Loss: 2.2419\n",
      "Validation loss improved from 2.2428 to 2.2419. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9363\n",
      "Epoch [313/2000], Avg Train Loss: 3.9363\n",
      "Epoch [313/2000], Avg Val Loss: 2.2411\n",
      "Validation loss improved from 2.2419 to 2.2411. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9362\n",
      "Epoch [314/2000], Avg Train Loss: 3.9362\n",
      "Epoch [314/2000], Avg Val Loss: 2.2402\n",
      "Validation loss improved from 2.2411 to 2.2402. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9672\n",
      "Epoch [315/2000], Avg Train Loss: 3.9672\n",
      "Epoch [315/2000], Avg Val Loss: 2.2394\n",
      "Validation loss improved from 2.2402 to 2.2394. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9695\n",
      "Epoch [316/2000], Avg Train Loss: 3.9695\n",
      "Epoch [316/2000], Avg Val Loss: 2.2385\n",
      "Validation loss improved from 2.2394 to 2.2385. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9428\n",
      "Epoch [317/2000], Avg Train Loss: 3.9428\n",
      "Epoch [317/2000], Avg Val Loss: 2.2377\n",
      "Validation loss improved from 2.2385 to 2.2377. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9792\n",
      "Epoch [318/2000], Avg Train Loss: 3.9792\n",
      "Epoch [318/2000], Avg Val Loss: 2.2368\n",
      "Validation loss improved from 2.2377 to 2.2368. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9403\n",
      "Epoch [319/2000], Avg Train Loss: 3.9403\n",
      "Epoch [319/2000], Avg Val Loss: 2.2360\n",
      "Validation loss improved from 2.2368 to 2.2360. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9205\n",
      "Epoch [320/2000], Avg Train Loss: 3.9205\n",
      "Epoch [320/2000], Avg Val Loss: 2.2352\n",
      "Validation loss improved from 2.2360 to 2.2352. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9506\n",
      "Epoch [321/2000], Avg Train Loss: 3.9506\n",
      "Epoch [321/2000], Avg Val Loss: 2.2344\n",
      "Validation loss improved from 2.2352 to 2.2344. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9131\n",
      "Epoch [322/2000], Avg Train Loss: 3.9131\n",
      "Epoch [322/2000], Avg Val Loss: 2.2336\n",
      "Validation loss improved from 2.2344 to 2.2336. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9269\n",
      "Epoch [323/2000], Avg Train Loss: 3.9269\n",
      "Epoch [323/2000], Avg Val Loss: 2.2328\n",
      "Validation loss improved from 2.2336 to 2.2328. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8992\n",
      "Epoch [324/2000], Avg Train Loss: 3.8992\n",
      "Epoch [324/2000], Avg Val Loss: 2.2320\n",
      "Validation loss improved from 2.2328 to 2.2320. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9138\n",
      "Epoch [325/2000], Avg Train Loss: 3.9138\n",
      "Epoch [325/2000], Avg Val Loss: 2.2312\n",
      "Validation loss improved from 2.2320 to 2.2312. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8928\n",
      "Epoch [326/2000], Avg Train Loss: 3.8928\n",
      "Epoch [326/2000], Avg Val Loss: 2.2304\n",
      "Validation loss improved from 2.2312 to 2.2304. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8998\n",
      "Epoch [327/2000], Avg Train Loss: 3.8998\n",
      "Epoch [327/2000], Avg Val Loss: 2.2296\n",
      "Validation loss improved from 2.2304 to 2.2296. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9108\n",
      "Epoch [328/2000], Avg Train Loss: 3.9108\n",
      "Epoch [328/2000], Avg Val Loss: 2.2288\n",
      "Validation loss improved from 2.2296 to 2.2288. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8825\n",
      "Epoch [329/2000], Avg Train Loss: 3.8825\n",
      "Epoch [329/2000], Avg Val Loss: 2.2280\n",
      "Validation loss improved from 2.2288 to 2.2280. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9201\n",
      "Epoch [330/2000], Avg Train Loss: 3.9201\n",
      "Epoch [330/2000], Avg Val Loss: 2.2272\n",
      "Validation loss improved from 2.2280 to 2.2272. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9168\n",
      "Epoch [331/2000], Avg Train Loss: 3.9168\n",
      "Epoch [331/2000], Avg Val Loss: 2.2264\n",
      "Validation loss improved from 2.2272 to 2.2264. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9438\n",
      "Epoch [332/2000], Avg Train Loss: 3.9438\n",
      "Epoch [332/2000], Avg Val Loss: 2.2256\n",
      "Validation loss improved from 2.2264 to 2.2256. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9002\n",
      "Epoch [333/2000], Avg Train Loss: 3.9002\n",
      "Epoch [333/2000], Avg Val Loss: 2.2248\n",
      "Validation loss improved from 2.2256 to 2.2248. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9034\n",
      "Epoch [334/2000], Avg Train Loss: 3.9034\n",
      "Epoch [334/2000], Avg Val Loss: 2.2240\n",
      "Validation loss improved from 2.2248 to 2.2240. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9344\n",
      "Epoch [335/2000], Avg Train Loss: 3.9344\n",
      "Epoch [335/2000], Avg Val Loss: 2.2232\n",
      "Validation loss improved from 2.2240 to 2.2232. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9196\n",
      "Epoch [336/2000], Avg Train Loss: 3.9196\n",
      "Epoch [336/2000], Avg Val Loss: 2.2225\n",
      "Validation loss improved from 2.2232 to 2.2225. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8964\n",
      "Epoch [337/2000], Avg Train Loss: 3.8964\n",
      "Epoch [337/2000], Avg Val Loss: 2.2217\n",
      "Validation loss improved from 2.2225 to 2.2217. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9046\n",
      "Epoch [338/2000], Avg Train Loss: 3.9046\n",
      "Epoch [338/2000], Avg Val Loss: 2.2209\n",
      "Validation loss improved from 2.2217 to 2.2209. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9011\n",
      "Epoch [339/2000], Avg Train Loss: 3.9011\n",
      "Epoch [339/2000], Avg Val Loss: 2.2202\n",
      "Validation loss improved from 2.2209 to 2.2202. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9033\n",
      "Epoch [340/2000], Avg Train Loss: 3.9033\n",
      "Epoch [340/2000], Avg Val Loss: 2.2194\n",
      "Validation loss improved from 2.2202 to 2.2194. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8934\n",
      "Epoch [341/2000], Avg Train Loss: 3.8934\n",
      "Epoch [341/2000], Avg Val Loss: 2.2186\n",
      "Validation loss improved from 2.2194 to 2.2186. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9039\n",
      "Epoch [342/2000], Avg Train Loss: 3.9039\n",
      "Epoch [342/2000], Avg Val Loss: 2.2179\n",
      "Validation loss improved from 2.2186 to 2.2179. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8917\n",
      "Epoch [343/2000], Avg Train Loss: 3.8917\n",
      "Epoch [343/2000], Avg Val Loss: 2.2171\n",
      "Validation loss improved from 2.2179 to 2.2171. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8495\n",
      "Epoch [344/2000], Avg Train Loss: 3.8495\n",
      "Epoch [344/2000], Avg Val Loss: 2.2164\n",
      "Validation loss improved from 2.2171 to 2.2164. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8828\n",
      "Epoch [345/2000], Avg Train Loss: 3.8828\n",
      "Epoch [345/2000], Avg Val Loss: 2.2156\n",
      "Validation loss improved from 2.2164 to 2.2156. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9071\n",
      "Epoch [346/2000], Avg Train Loss: 3.9071\n",
      "Epoch [346/2000], Avg Val Loss: 2.2148\n",
      "Validation loss improved from 2.2156 to 2.2148. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8996\n",
      "Epoch [347/2000], Avg Train Loss: 3.8996\n",
      "Epoch [347/2000], Avg Val Loss: 2.2141\n",
      "Validation loss improved from 2.2148 to 2.2141. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9034\n",
      "Epoch [348/2000], Avg Train Loss: 3.9034\n",
      "Epoch [348/2000], Avg Val Loss: 2.2134\n",
      "Validation loss improved from 2.2141 to 2.2134. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9313\n",
      "Epoch [349/2000], Avg Train Loss: 3.9313\n",
      "Epoch [349/2000], Avg Val Loss: 2.2126\n",
      "Validation loss improved from 2.2134 to 2.2126. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8850\n",
      "Epoch [350/2000], Avg Train Loss: 3.8850\n",
      "Epoch [350/2000], Avg Val Loss: 2.2119\n",
      "Validation loss improved from 2.2126 to 2.2119. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9271\n",
      "Epoch [351/2000], Avg Train Loss: 3.9271\n",
      "Epoch [351/2000], Avg Val Loss: 2.2112\n",
      "Validation loss improved from 2.2119 to 2.2112. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9078\n",
      "Epoch [352/2000], Avg Train Loss: 3.9078\n",
      "Epoch [352/2000], Avg Val Loss: 2.2105\n",
      "Validation loss improved from 2.2112 to 2.2105. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8753\n",
      "Epoch [353/2000], Avg Train Loss: 3.8753\n",
      "Epoch [353/2000], Avg Val Loss: 2.2098\n",
      "Validation loss improved from 2.2105 to 2.2098. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8769\n",
      "Epoch [354/2000], Avg Train Loss: 3.8769\n",
      "Epoch [354/2000], Avg Val Loss: 2.2091\n",
      "Validation loss improved from 2.2098 to 2.2091. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8854\n",
      "Epoch [355/2000], Avg Train Loss: 3.8854\n",
      "Epoch [355/2000], Avg Val Loss: 2.2084\n",
      "Validation loss improved from 2.2091 to 2.2084. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8487\n",
      "Epoch [356/2000], Avg Train Loss: 3.8487\n",
      "Epoch [356/2000], Avg Val Loss: 2.2077\n",
      "Validation loss improved from 2.2084 to 2.2077. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8711\n",
      "Epoch [357/2000], Avg Train Loss: 3.8711\n",
      "Epoch [357/2000], Avg Val Loss: 2.2070\n",
      "Validation loss improved from 2.2077 to 2.2070. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8975\n",
      "Epoch [358/2000], Avg Train Loss: 3.8975\n",
      "Epoch [358/2000], Avg Val Loss: 2.2063\n",
      "Validation loss improved from 2.2070 to 2.2063. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9083\n",
      "Epoch [359/2000], Avg Train Loss: 3.9083\n",
      "Epoch [359/2000], Avg Val Loss: 2.2056\n",
      "Validation loss improved from 2.2063 to 2.2056. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8572\n",
      "Epoch [360/2000], Avg Train Loss: 3.8572\n",
      "Epoch [360/2000], Avg Val Loss: 2.2049\n",
      "Validation loss improved from 2.2056 to 2.2049. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8846\n",
      "Epoch [361/2000], Avg Train Loss: 3.8846\n",
      "Epoch [361/2000], Avg Val Loss: 2.2043\n",
      "Validation loss improved from 2.2049 to 2.2043. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8606\n",
      "Epoch [362/2000], Avg Train Loss: 3.8606\n",
      "Epoch [362/2000], Avg Val Loss: 2.2036\n",
      "Validation loss improved from 2.2043 to 2.2036. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8792\n",
      "Epoch [363/2000], Avg Train Loss: 3.8792\n",
      "Epoch [363/2000], Avg Val Loss: 2.2029\n",
      "Validation loss improved from 2.2036 to 2.2029. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8438\n",
      "Epoch [364/2000], Avg Train Loss: 3.8438\n",
      "Epoch [364/2000], Avg Val Loss: 2.2021\n",
      "Validation loss improved from 2.2029 to 2.2021. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8268\n",
      "Epoch [365/2000], Avg Train Loss: 3.8268\n",
      "Epoch [365/2000], Avg Val Loss: 2.2014\n",
      "Validation loss improved from 2.2021 to 2.2014. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8508\n",
      "Epoch [366/2000], Avg Train Loss: 3.8508\n",
      "Epoch [366/2000], Avg Val Loss: 2.2007\n",
      "Validation loss improved from 2.2014 to 2.2007. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8654\n",
      "Epoch [367/2000], Avg Train Loss: 3.8654\n",
      "Epoch [367/2000], Avg Val Loss: 2.1999\n",
      "Validation loss improved from 2.2007 to 2.1999. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8384\n",
      "Epoch [368/2000], Avg Train Loss: 3.8384\n",
      "Epoch [368/2000], Avg Val Loss: 2.1992\n",
      "Validation loss improved from 2.1999 to 2.1992. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8704\n",
      "Epoch [369/2000], Avg Train Loss: 3.8704\n",
      "Epoch [369/2000], Avg Val Loss: 2.1985\n",
      "Validation loss improved from 2.1992 to 2.1985. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8548\n",
      "Epoch [370/2000], Avg Train Loss: 3.8548\n",
      "Epoch [370/2000], Avg Val Loss: 2.1977\n",
      "Validation loss improved from 2.1985 to 2.1977. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8809\n",
      "Epoch [371/2000], Avg Train Loss: 3.8809\n",
      "Epoch [371/2000], Avg Val Loss: 2.1970\n",
      "Validation loss improved from 2.1977 to 2.1970. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8552\n",
      "Epoch [372/2000], Avg Train Loss: 3.8552\n",
      "Epoch [372/2000], Avg Val Loss: 2.1963\n",
      "Validation loss improved from 2.1970 to 2.1963. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8357\n",
      "Epoch [373/2000], Avg Train Loss: 3.8357\n",
      "Epoch [373/2000], Avg Val Loss: 2.1956\n",
      "Validation loss improved from 2.1963 to 2.1956. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8375\n",
      "Epoch [374/2000], Avg Train Loss: 3.8375\n",
      "Epoch [374/2000], Avg Val Loss: 2.1949\n",
      "Validation loss improved from 2.1956 to 2.1949. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8362\n",
      "Epoch [375/2000], Avg Train Loss: 3.8362\n",
      "Epoch [375/2000], Avg Val Loss: 2.1942\n",
      "Validation loss improved from 2.1949 to 2.1942. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8322\n",
      "Epoch [376/2000], Avg Train Loss: 3.8322\n",
      "Epoch [376/2000], Avg Val Loss: 2.1935\n",
      "Validation loss improved from 2.1942 to 2.1935. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8874\n",
      "Epoch [377/2000], Avg Train Loss: 3.8874\n",
      "Epoch [377/2000], Avg Val Loss: 2.1928\n",
      "Validation loss improved from 2.1935 to 2.1928. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8355\n",
      "Epoch [378/2000], Avg Train Loss: 3.8355\n",
      "Epoch [378/2000], Avg Val Loss: 2.1921\n",
      "Validation loss improved from 2.1928 to 2.1921. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8912\n",
      "Epoch [379/2000], Avg Train Loss: 3.8912\n",
      "Epoch [379/2000], Avg Val Loss: 2.1914\n",
      "Validation loss improved from 2.1921 to 2.1914. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8045\n",
      "Epoch [380/2000], Avg Train Loss: 3.8045\n",
      "Epoch [380/2000], Avg Val Loss: 2.1907\n",
      "Validation loss improved from 2.1914 to 2.1907. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8743\n",
      "Epoch [381/2000], Avg Train Loss: 3.8743\n",
      "Epoch [381/2000], Avg Val Loss: 2.1900\n",
      "Validation loss improved from 2.1907 to 2.1900. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8699\n",
      "Epoch [382/2000], Avg Train Loss: 3.8699\n",
      "Epoch [382/2000], Avg Val Loss: 2.1894\n",
      "Validation loss improved from 2.1900 to 2.1894. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8315\n",
      "Epoch [383/2000], Avg Train Loss: 3.8315\n",
      "Epoch [383/2000], Avg Val Loss: 2.1887\n",
      "Validation loss improved from 2.1894 to 2.1887. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8547\n",
      "Epoch [384/2000], Avg Train Loss: 3.8547\n",
      "Epoch [384/2000], Avg Val Loss: 2.1880\n",
      "Validation loss improved from 2.1887 to 2.1880. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7894\n",
      "Epoch [385/2000], Avg Train Loss: 3.7894\n",
      "Epoch [385/2000], Avg Val Loss: 2.1873\n",
      "Validation loss improved from 2.1880 to 2.1873. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7893\n",
      "Epoch [386/2000], Avg Train Loss: 3.7893\n",
      "Epoch [386/2000], Avg Val Loss: 2.1866\n",
      "Validation loss improved from 2.1873 to 2.1866. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8182\n",
      "Epoch [387/2000], Avg Train Loss: 3.8182\n",
      "Epoch [387/2000], Avg Val Loss: 2.1859\n",
      "Validation loss improved from 2.1866 to 2.1859. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8449\n",
      "Epoch [388/2000], Avg Train Loss: 3.8449\n",
      "Epoch [388/2000], Avg Val Loss: 2.1853\n",
      "Validation loss improved from 2.1859 to 2.1853. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8260\n",
      "Epoch [389/2000], Avg Train Loss: 3.8260\n",
      "Epoch [389/2000], Avg Val Loss: 2.1847\n",
      "Validation loss improved from 2.1853 to 2.1847. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8415\n",
      "Epoch [390/2000], Avg Train Loss: 3.8415\n",
      "Epoch [390/2000], Avg Val Loss: 2.1840\n",
      "Validation loss improved from 2.1847 to 2.1840. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8629\n",
      "Epoch [391/2000], Avg Train Loss: 3.8629\n",
      "Epoch [391/2000], Avg Val Loss: 2.1834\n",
      "Validation loss improved from 2.1840 to 2.1834. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7913\n",
      "Epoch [392/2000], Avg Train Loss: 3.7913\n",
      "Epoch [392/2000], Avg Val Loss: 2.1827\n",
      "Validation loss improved from 2.1834 to 2.1827. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8215\n",
      "Epoch [393/2000], Avg Train Loss: 3.8215\n",
      "Epoch [393/2000], Avg Val Loss: 2.1821\n",
      "Validation loss improved from 2.1827 to 2.1821. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7878\n",
      "Epoch [394/2000], Avg Train Loss: 3.7878\n",
      "Epoch [394/2000], Avg Val Loss: 2.1814\n",
      "Validation loss improved from 2.1821 to 2.1814. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8215\n",
      "Epoch [395/2000], Avg Train Loss: 3.8215\n",
      "Epoch [395/2000], Avg Val Loss: 2.1808\n",
      "Validation loss improved from 2.1814 to 2.1808. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8571\n",
      "Epoch [396/2000], Avg Train Loss: 3.8571\n",
      "Epoch [396/2000], Avg Val Loss: 2.1801\n",
      "Validation loss improved from 2.1808 to 2.1801. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7997\n",
      "Epoch [397/2000], Avg Train Loss: 3.7997\n",
      "Epoch [397/2000], Avg Val Loss: 2.1795\n",
      "Validation loss improved from 2.1801 to 2.1795. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8089\n",
      "Epoch [398/2000], Avg Train Loss: 3.8089\n",
      "Epoch [398/2000], Avg Val Loss: 2.1788\n",
      "Validation loss improved from 2.1795 to 2.1788. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7988\n",
      "Epoch [399/2000], Avg Train Loss: 3.7988\n",
      "Epoch [399/2000], Avg Val Loss: 2.1782\n",
      "Validation loss improved from 2.1788 to 2.1782. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8228\n",
      "Epoch [400/2000], Avg Train Loss: 3.8228\n",
      "Epoch [400/2000], Avg Val Loss: 2.1776\n",
      "Validation loss improved from 2.1782 to 2.1776. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8201\n",
      "Epoch [401/2000], Avg Train Loss: 3.8201\n",
      "Epoch [401/2000], Avg Val Loss: 2.1769\n",
      "Validation loss improved from 2.1776 to 2.1769. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8515\n",
      "Epoch [402/2000], Avg Train Loss: 3.8515\n",
      "Epoch [402/2000], Avg Val Loss: 2.1763\n",
      "Validation loss improved from 2.1769 to 2.1763. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8090\n",
      "Epoch [403/2000], Avg Train Loss: 3.8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [403/2000], Avg Val Loss: 2.1757\n",
      "Validation loss improved from 2.1763 to 2.1757. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7959\n",
      "Epoch [404/2000], Avg Train Loss: 3.7959\n",
      "Epoch [404/2000], Avg Val Loss: 2.1750\n",
      "Validation loss improved from 2.1757 to 2.1750. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7831\n",
      "Epoch [405/2000], Avg Train Loss: 3.7831\n",
      "Epoch [405/2000], Avg Val Loss: 2.1744\n",
      "Validation loss improved from 2.1750 to 2.1744. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8275\n",
      "Epoch [406/2000], Avg Train Loss: 3.8275\n",
      "Epoch [406/2000], Avg Val Loss: 2.1738\n",
      "Validation loss improved from 2.1744 to 2.1738. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8230\n",
      "Epoch [407/2000], Avg Train Loss: 3.8230\n",
      "Epoch [407/2000], Avg Val Loss: 2.1732\n",
      "Validation loss improved from 2.1738 to 2.1732. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8007\n",
      "Epoch [408/2000], Avg Train Loss: 3.8007\n",
      "Epoch [408/2000], Avg Val Loss: 2.1725\n",
      "Validation loss improved from 2.1732 to 2.1725. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7876\n",
      "Epoch [409/2000], Avg Train Loss: 3.7876\n",
      "Epoch [409/2000], Avg Val Loss: 2.1719\n",
      "Validation loss improved from 2.1725 to 2.1719. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8052\n",
      "Epoch [410/2000], Avg Train Loss: 3.8052\n",
      "Epoch [410/2000], Avg Val Loss: 2.1712\n",
      "Validation loss improved from 2.1719 to 2.1712. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8442\n",
      "Epoch [411/2000], Avg Train Loss: 3.8442\n",
      "Epoch [411/2000], Avg Val Loss: 2.1706\n",
      "Validation loss improved from 2.1712 to 2.1706. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8165\n",
      "Epoch [412/2000], Avg Train Loss: 3.8165\n",
      "Epoch [412/2000], Avg Val Loss: 2.1700\n",
      "Validation loss improved from 2.1706 to 2.1700. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8421\n",
      "Epoch [413/2000], Avg Train Loss: 3.8421\n",
      "Epoch [413/2000], Avg Val Loss: 2.1693\n",
      "Validation loss improved from 2.1700 to 2.1693. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7755\n",
      "Epoch [414/2000], Avg Train Loss: 3.7755\n",
      "Epoch [414/2000], Avg Val Loss: 2.1687\n",
      "Validation loss improved from 2.1693 to 2.1687. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7900\n",
      "Epoch [415/2000], Avg Train Loss: 3.7900\n",
      "Epoch [415/2000], Avg Val Loss: 2.1681\n",
      "Validation loss improved from 2.1687 to 2.1681. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7623\n",
      "Epoch [416/2000], Avg Train Loss: 3.7623\n",
      "Epoch [416/2000], Avg Val Loss: 2.1675\n",
      "Validation loss improved from 2.1681 to 2.1675. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8000\n",
      "Epoch [417/2000], Avg Train Loss: 3.8000\n",
      "Epoch [417/2000], Avg Val Loss: 2.1669\n",
      "Validation loss improved from 2.1675 to 2.1669. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7848\n",
      "Epoch [418/2000], Avg Train Loss: 3.7848\n",
      "Epoch [418/2000], Avg Val Loss: 2.1662\n",
      "Validation loss improved from 2.1669 to 2.1662. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7970\n",
      "Epoch [419/2000], Avg Train Loss: 3.7970\n",
      "Epoch [419/2000], Avg Val Loss: 2.1656\n",
      "Validation loss improved from 2.1662 to 2.1656. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8065\n",
      "Epoch [420/2000], Avg Train Loss: 3.8065\n",
      "Epoch [420/2000], Avg Val Loss: 2.1650\n",
      "Validation loss improved from 2.1656 to 2.1650. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8015\n",
      "Epoch [421/2000], Avg Train Loss: 3.8015\n",
      "Epoch [421/2000], Avg Val Loss: 2.1644\n",
      "Validation loss improved from 2.1650 to 2.1644. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8043\n",
      "Epoch [422/2000], Avg Train Loss: 3.8043\n",
      "Epoch [422/2000], Avg Val Loss: 2.1638\n",
      "Validation loss improved from 2.1644 to 2.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7719\n",
      "Epoch [423/2000], Avg Train Loss: 3.7719\n",
      "Epoch [423/2000], Avg Val Loss: 2.1633\n",
      "Validation loss improved from 2.1638 to 2.1633. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7554\n",
      "Epoch [424/2000], Avg Train Loss: 3.7554\n",
      "Epoch [424/2000], Avg Val Loss: 2.1627\n",
      "Validation loss improved from 2.1633 to 2.1627. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7971\n",
      "Epoch [425/2000], Avg Train Loss: 3.7971\n",
      "Epoch [425/2000], Avg Val Loss: 2.1621\n",
      "Validation loss improved from 2.1627 to 2.1621. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7735\n",
      "Epoch [426/2000], Avg Train Loss: 3.7735\n",
      "Epoch [426/2000], Avg Val Loss: 2.1615\n",
      "Validation loss improved from 2.1621 to 2.1615. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7800\n",
      "Epoch [427/2000], Avg Train Loss: 3.7800\n",
      "Epoch [427/2000], Avg Val Loss: 2.1609\n",
      "Validation loss improved from 2.1615 to 2.1609. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7692\n",
      "Epoch [428/2000], Avg Train Loss: 3.7692\n",
      "Epoch [428/2000], Avg Val Loss: 2.1604\n",
      "Validation loss improved from 2.1609 to 2.1604. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7704\n",
      "Epoch [429/2000], Avg Train Loss: 3.7704\n",
      "Epoch [429/2000], Avg Val Loss: 2.1598\n",
      "Validation loss improved from 2.1604 to 2.1598. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7728\n",
      "Epoch [430/2000], Avg Train Loss: 3.7728\n",
      "Epoch [430/2000], Avg Val Loss: 2.1592\n",
      "Validation loss improved from 2.1598 to 2.1592. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7905\n",
      "Epoch [431/2000], Avg Train Loss: 3.7905\n",
      "Epoch [431/2000], Avg Val Loss: 2.1587\n",
      "Validation loss improved from 2.1592 to 2.1587. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7377\n",
      "Epoch [432/2000], Avg Train Loss: 3.7377\n",
      "Epoch [432/2000], Avg Val Loss: 2.1581\n",
      "Validation loss improved from 2.1587 to 2.1581. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8246\n",
      "Epoch [433/2000], Avg Train Loss: 3.8246\n",
      "Epoch [433/2000], Avg Val Loss: 2.1576\n",
      "Validation loss improved from 2.1581 to 2.1576. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7640\n",
      "Epoch [434/2000], Avg Train Loss: 3.7640\n",
      "Epoch [434/2000], Avg Val Loss: 2.1570\n",
      "Validation loss improved from 2.1576 to 2.1570. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8306\n",
      "Epoch [435/2000], Avg Train Loss: 3.8306\n",
      "Epoch [435/2000], Avg Val Loss: 2.1565\n",
      "Validation loss improved from 2.1570 to 2.1565. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7858\n",
      "Epoch [436/2000], Avg Train Loss: 3.7858\n",
      "Epoch [436/2000], Avg Val Loss: 2.1559\n",
      "Validation loss improved from 2.1565 to 2.1559. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7914\n",
      "Epoch [437/2000], Avg Train Loss: 3.7914\n",
      "Epoch [437/2000], Avg Val Loss: 2.1554\n",
      "Validation loss improved from 2.1559 to 2.1554. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7804\n",
      "Epoch [438/2000], Avg Train Loss: 3.7804\n",
      "Epoch [438/2000], Avg Val Loss: 2.1549\n",
      "Validation loss improved from 2.1554 to 2.1549. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7563\n",
      "Epoch [439/2000], Avg Train Loss: 3.7563\n",
      "Epoch [439/2000], Avg Val Loss: 2.1543\n",
      "Validation loss improved from 2.1549 to 2.1543. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7419\n",
      "Epoch [440/2000], Avg Train Loss: 3.7419\n",
      "Epoch [440/2000], Avg Val Loss: 2.1538\n",
      "Validation loss improved from 2.1543 to 2.1538. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7622\n",
      "Epoch [441/2000], Avg Train Loss: 3.7622\n",
      "Epoch [441/2000], Avg Val Loss: 2.1533\n",
      "Validation loss improved from 2.1538 to 2.1533. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8092\n",
      "Epoch [442/2000], Avg Train Loss: 3.8092\n",
      "Epoch [442/2000], Avg Val Loss: 2.1527\n",
      "Validation loss improved from 2.1533 to 2.1527. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7678\n",
      "Epoch [443/2000], Avg Train Loss: 3.7678\n",
      "Epoch [443/2000], Avg Val Loss: 2.1522\n",
      "Validation loss improved from 2.1527 to 2.1522. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7816\n",
      "Epoch [444/2000], Avg Train Loss: 3.7816\n",
      "Epoch [444/2000], Avg Val Loss: 2.1517\n",
      "Validation loss improved from 2.1522 to 2.1517. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7651\n",
      "Epoch [445/2000], Avg Train Loss: 3.7651\n",
      "Epoch [445/2000], Avg Val Loss: 2.1512\n",
      "Validation loss improved from 2.1517 to 2.1512. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7510\n",
      "Epoch [446/2000], Avg Train Loss: 3.7510\n",
      "Epoch [446/2000], Avg Val Loss: 2.1507\n",
      "Validation loss improved from 2.1512 to 2.1507. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7548\n",
      "Epoch [447/2000], Avg Train Loss: 3.7548\n",
      "Epoch [447/2000], Avg Val Loss: 2.1501\n",
      "Validation loss improved from 2.1507 to 2.1501. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7565\n",
      "Epoch [448/2000], Avg Train Loss: 3.7565\n",
      "Epoch [448/2000], Avg Val Loss: 2.1496\n",
      "Validation loss improved from 2.1501 to 2.1496. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7379\n",
      "Epoch [449/2000], Avg Train Loss: 3.7379\n",
      "Epoch [449/2000], Avg Val Loss: 2.1491\n",
      "Validation loss improved from 2.1496 to 2.1491. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7748\n",
      "Epoch [450/2000], Avg Train Loss: 3.7748\n",
      "Epoch [450/2000], Avg Val Loss: 2.1486\n",
      "Validation loss improved from 2.1491 to 2.1486. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7769\n",
      "Epoch [451/2000], Avg Train Loss: 3.7769\n",
      "Epoch [451/2000], Avg Val Loss: 2.1481\n",
      "Validation loss improved from 2.1486 to 2.1481. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7986\n",
      "Epoch [452/2000], Avg Train Loss: 3.7986\n",
      "Epoch [452/2000], Avg Val Loss: 2.1477\n",
      "Validation loss improved from 2.1481 to 2.1477. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7443\n",
      "Epoch [453/2000], Avg Train Loss: 3.7443\n",
      "Epoch [453/2000], Avg Val Loss: 2.1472\n",
      "Validation loss improved from 2.1477 to 2.1472. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7899\n",
      "Epoch [454/2000], Avg Train Loss: 3.7899\n",
      "Epoch [454/2000], Avg Val Loss: 2.1468\n",
      "Validation loss improved from 2.1472 to 2.1468. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7611\n",
      "Epoch [455/2000], Avg Train Loss: 3.7611\n",
      "Epoch [455/2000], Avg Val Loss: 2.1463\n",
      "Validation loss improved from 2.1468 to 2.1463. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7528\n",
      "Epoch [456/2000], Avg Train Loss: 3.7528\n",
      "Epoch [456/2000], Avg Val Loss: 2.1459\n",
      "Validation loss improved from 2.1463 to 2.1459. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7524\n",
      "Epoch [457/2000], Avg Train Loss: 3.7524\n",
      "Epoch [457/2000], Avg Val Loss: 2.1454\n",
      "Validation loss improved from 2.1459 to 2.1454. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7859\n",
      "Epoch [458/2000], Avg Train Loss: 3.7859\n",
      "Epoch [458/2000], Avg Val Loss: 2.1450\n",
      "Validation loss improved from 2.1454 to 2.1450. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7631\n",
      "Epoch [459/2000], Avg Train Loss: 3.7631\n",
      "Epoch [459/2000], Avg Val Loss: 2.1446\n",
      "Validation loss improved from 2.1450 to 2.1446. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7489\n",
      "Epoch [460/2000], Avg Train Loss: 3.7489\n",
      "Epoch [460/2000], Avg Val Loss: 2.1441\n",
      "Validation loss improved from 2.1446 to 2.1441. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7221\n",
      "Epoch [461/2000], Avg Train Loss: 3.7221\n",
      "Epoch [461/2000], Avg Val Loss: 2.1437\n",
      "Validation loss improved from 2.1441 to 2.1437. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7262\n",
      "Epoch [462/2000], Avg Train Loss: 3.7262\n",
      "Epoch [462/2000], Avg Val Loss: 2.1432\n",
      "Validation loss improved from 2.1437 to 2.1432. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7520\n",
      "Epoch [463/2000], Avg Train Loss: 3.7520\n",
      "Epoch [463/2000], Avg Val Loss: 2.1427\n",
      "Validation loss improved from 2.1432 to 2.1427. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7579\n",
      "Epoch [464/2000], Avg Train Loss: 3.7579\n",
      "Epoch [464/2000], Avg Val Loss: 2.1423\n",
      "Validation loss improved from 2.1427 to 2.1423. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7857\n",
      "Epoch [465/2000], Avg Train Loss: 3.7857\n",
      "Epoch [465/2000], Avg Val Loss: 2.1418\n",
      "Validation loss improved from 2.1423 to 2.1418. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7427\n",
      "Epoch [466/2000], Avg Train Loss: 3.7427\n",
      "Epoch [466/2000], Avg Val Loss: 2.1414\n",
      "Validation loss improved from 2.1418 to 2.1414. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7421\n",
      "Epoch [467/2000], Avg Train Loss: 3.7421\n",
      "Epoch [467/2000], Avg Val Loss: 2.1410\n",
      "Validation loss improved from 2.1414 to 2.1410. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7396\n",
      "Epoch [468/2000], Avg Train Loss: 3.7396\n",
      "Epoch [468/2000], Avg Val Loss: 2.1405\n",
      "Validation loss improved from 2.1410 to 2.1405. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7465\n",
      "Epoch [469/2000], Avg Train Loss: 3.7465\n",
      "Epoch [469/2000], Avg Val Loss: 2.1401\n",
      "Validation loss improved from 2.1405 to 2.1401. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7462\n",
      "Epoch [470/2000], Avg Train Loss: 3.7462\n",
      "Epoch [470/2000], Avg Val Loss: 2.1397\n",
      "Validation loss improved from 2.1401 to 2.1397. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7394\n",
      "Epoch [471/2000], Avg Train Loss: 3.7394\n",
      "Epoch [471/2000], Avg Val Loss: 2.1393\n",
      "Validation loss improved from 2.1397 to 2.1393. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7477\n",
      "Epoch [472/2000], Avg Train Loss: 3.7477\n",
      "Epoch [472/2000], Avg Val Loss: 2.1389\n",
      "Validation loss improved from 2.1393 to 2.1389. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7017\n",
      "Epoch [473/2000], Avg Train Loss: 3.7017\n",
      "Epoch [473/2000], Avg Val Loss: 2.1384\n",
      "Validation loss improved from 2.1389 to 2.1384. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7668\n",
      "Epoch [474/2000], Avg Train Loss: 3.7668\n",
      "Epoch [474/2000], Avg Val Loss: 2.1380\n",
      "Validation loss improved from 2.1384 to 2.1380. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7311\n",
      "Epoch [475/2000], Avg Train Loss: 3.7311\n",
      "Epoch [475/2000], Avg Val Loss: 2.1375\n",
      "Validation loss improved from 2.1380 to 2.1375. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7870\n",
      "Epoch [476/2000], Avg Train Loss: 3.7870\n",
      "Epoch [476/2000], Avg Val Loss: 2.1371\n",
      "Validation loss improved from 2.1375 to 2.1371. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7313\n",
      "Epoch [477/2000], Avg Train Loss: 3.7313\n",
      "Epoch [477/2000], Avg Val Loss: 2.1367\n",
      "Validation loss improved from 2.1371 to 2.1367. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7250\n",
      "Epoch [478/2000], Avg Train Loss: 3.7250\n",
      "Epoch [478/2000], Avg Val Loss: 2.1362\n",
      "Validation loss improved from 2.1367 to 2.1362. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7623\n",
      "Epoch [479/2000], Avg Train Loss: 3.7623\n",
      "Epoch [479/2000], Avg Val Loss: 2.1358\n",
      "Validation loss improved from 2.1362 to 2.1358. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6872\n",
      "Epoch [480/2000], Avg Train Loss: 3.6872\n",
      "Epoch [480/2000], Avg Val Loss: 2.1353\n",
      "Validation loss improved from 2.1358 to 2.1353. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7241\n",
      "Epoch [481/2000], Avg Train Loss: 3.7241\n",
      "Epoch [481/2000], Avg Val Loss: 2.1349\n",
      "Validation loss improved from 2.1353 to 2.1349. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7588\n",
      "Epoch [482/2000], Avg Train Loss: 3.7588\n",
      "Epoch [482/2000], Avg Val Loss: 2.1345\n",
      "Validation loss improved from 2.1349 to 2.1345. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7271\n",
      "Epoch [483/2000], Avg Train Loss: 3.7271\n",
      "Epoch [483/2000], Avg Val Loss: 2.1340\n",
      "Validation loss improved from 2.1345 to 2.1340. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7341\n",
      "Epoch [484/2000], Avg Train Loss: 3.7341\n",
      "Epoch [484/2000], Avg Val Loss: 2.1336\n",
      "Validation loss improved from 2.1340 to 2.1336. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7217\n",
      "Epoch [485/2000], Avg Train Loss: 3.7217\n",
      "Epoch [485/2000], Avg Val Loss: 2.1332\n",
      "Validation loss improved from 2.1336 to 2.1332. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7378\n",
      "Epoch [486/2000], Avg Train Loss: 3.7378\n",
      "Epoch [486/2000], Avg Val Loss: 2.1327\n",
      "Validation loss improved from 2.1332 to 2.1327. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7211\n",
      "Epoch [487/2000], Avg Train Loss: 3.7211\n",
      "Epoch [487/2000], Avg Val Loss: 2.1323\n",
      "Validation loss improved from 2.1327 to 2.1323. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7258\n",
      "Epoch [488/2000], Avg Train Loss: 3.7258\n",
      "Epoch [488/2000], Avg Val Loss: 2.1319\n",
      "Validation loss improved from 2.1323 to 2.1319. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7004\n",
      "Epoch [489/2000], Avg Train Loss: 3.7004\n",
      "Epoch [489/2000], Avg Val Loss: 2.1314\n",
      "Validation loss improved from 2.1319 to 2.1314. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7723\n",
      "Epoch [490/2000], Avg Train Loss: 3.7723\n",
      "Epoch [490/2000], Avg Val Loss: 2.1310\n",
      "Validation loss improved from 2.1314 to 2.1310. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7180\n",
      "Epoch [491/2000], Avg Train Loss: 3.7180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [491/2000], Avg Val Loss: 2.1306\n",
      "Validation loss improved from 2.1310 to 2.1306. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7287\n",
      "Epoch [492/2000], Avg Train Loss: 3.7287\n",
      "Epoch [492/2000], Avg Val Loss: 2.1302\n",
      "Validation loss improved from 2.1306 to 2.1302. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7221\n",
      "Epoch [493/2000], Avg Train Loss: 3.7221\n",
      "Epoch [493/2000], Avg Val Loss: 2.1299\n",
      "Validation loss improved from 2.1302 to 2.1299. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7388\n",
      "Epoch [494/2000], Avg Train Loss: 3.7388\n",
      "Epoch [494/2000], Avg Val Loss: 2.1295\n",
      "Validation loss improved from 2.1299 to 2.1295. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7264\n",
      "Epoch [495/2000], Avg Train Loss: 3.7264\n",
      "Epoch [495/2000], Avg Val Loss: 2.1291\n",
      "Validation loss improved from 2.1295 to 2.1291. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7093\n",
      "Epoch [496/2000], Avg Train Loss: 3.7093\n",
      "Epoch [496/2000], Avg Val Loss: 2.1287\n",
      "Validation loss improved from 2.1291 to 2.1287. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7316\n",
      "Epoch [497/2000], Avg Train Loss: 3.7316\n",
      "Epoch [497/2000], Avg Val Loss: 2.1282\n",
      "Validation loss improved from 2.1287 to 2.1282. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6815\n",
      "Epoch [498/2000], Avg Train Loss: 3.6815\n",
      "Epoch [498/2000], Avg Val Loss: 2.1278\n",
      "Validation loss improved from 2.1282 to 2.1278. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7194\n",
      "Epoch [499/2000], Avg Train Loss: 3.7194\n",
      "Epoch [499/2000], Avg Val Loss: 2.1274\n",
      "Validation loss improved from 2.1278 to 2.1274. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6914\n",
      "Epoch [500/2000], Avg Train Loss: 3.6914\n",
      "Epoch [500/2000], Avg Val Loss: 2.1270\n",
      "Validation loss improved from 2.1274 to 2.1270. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6852\n",
      "Epoch [501/2000], Avg Train Loss: 3.6852\n",
      "Epoch [501/2000], Avg Val Loss: 2.1266\n",
      "Validation loss improved from 2.1270 to 2.1266. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7018\n",
      "Epoch [502/2000], Avg Train Loss: 3.7018\n",
      "Epoch [502/2000], Avg Val Loss: 2.1262\n",
      "Validation loss improved from 2.1266 to 2.1262. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7192\n",
      "Epoch [503/2000], Avg Train Loss: 3.7192\n",
      "Epoch [503/2000], Avg Val Loss: 2.1258\n",
      "Validation loss improved from 2.1262 to 2.1258. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6966\n",
      "Epoch [504/2000], Avg Train Loss: 3.6966\n",
      "Epoch [504/2000], Avg Val Loss: 2.1254\n",
      "Validation loss improved from 2.1258 to 2.1254. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6442\n",
      "Epoch [505/2000], Avg Train Loss: 3.6442\n",
      "Epoch [505/2000], Avg Val Loss: 2.1250\n",
      "Validation loss improved from 2.1254 to 2.1250. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7179\n",
      "Epoch [506/2000], Avg Train Loss: 3.7179\n",
      "Epoch [506/2000], Avg Val Loss: 2.1245\n",
      "Validation loss improved from 2.1250 to 2.1245. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6904\n",
      "Epoch [507/2000], Avg Train Loss: 3.6904\n",
      "Epoch [507/2000], Avg Val Loss: 2.1241\n",
      "Validation loss improved from 2.1245 to 2.1241. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6842\n",
      "Epoch [508/2000], Avg Train Loss: 3.6842\n",
      "Epoch [508/2000], Avg Val Loss: 2.1237\n",
      "Validation loss improved from 2.1241 to 2.1237. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6814\n",
      "Epoch [509/2000], Avg Train Loss: 3.6814\n",
      "Epoch [509/2000], Avg Val Loss: 2.1232\n",
      "Validation loss improved from 2.1237 to 2.1232. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7469\n",
      "Epoch [510/2000], Avg Train Loss: 3.7469\n",
      "Epoch [510/2000], Avg Val Loss: 2.1228\n",
      "Validation loss improved from 2.1232 to 2.1228. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6510\n",
      "Epoch [511/2000], Avg Train Loss: 3.6510\n",
      "Epoch [511/2000], Avg Val Loss: 2.1224\n",
      "Validation loss improved from 2.1228 to 2.1224. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6970\n",
      "Epoch [512/2000], Avg Train Loss: 3.6970\n",
      "Epoch [512/2000], Avg Val Loss: 2.1219\n",
      "Validation loss improved from 2.1224 to 2.1219. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7249\n",
      "Epoch [513/2000], Avg Train Loss: 3.7249\n",
      "Epoch [513/2000], Avg Val Loss: 2.1215\n",
      "Validation loss improved from 2.1219 to 2.1215. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7056\n",
      "Epoch [514/2000], Avg Train Loss: 3.7056\n",
      "Epoch [514/2000], Avg Val Loss: 2.1211\n",
      "Validation loss improved from 2.1215 to 2.1211. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6695\n",
      "Epoch [515/2000], Avg Train Loss: 3.6695\n",
      "Epoch [515/2000], Avg Val Loss: 2.1207\n",
      "Validation loss improved from 2.1211 to 2.1207. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6785\n",
      "Epoch [516/2000], Avg Train Loss: 3.6785\n",
      "Epoch [516/2000], Avg Val Loss: 2.1203\n",
      "Validation loss improved from 2.1207 to 2.1203. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6999\n",
      "Epoch [517/2000], Avg Train Loss: 3.6999\n",
      "Epoch [517/2000], Avg Val Loss: 2.1198\n",
      "Validation loss improved from 2.1203 to 2.1198. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7191\n",
      "Epoch [518/2000], Avg Train Loss: 3.7191\n",
      "Epoch [518/2000], Avg Val Loss: 2.1194\n",
      "Validation loss improved from 2.1198 to 2.1194. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7042\n",
      "Epoch [519/2000], Avg Train Loss: 3.7042\n",
      "Epoch [519/2000], Avg Val Loss: 2.1189\n",
      "Validation loss improved from 2.1194 to 2.1189. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7166\n",
      "Epoch [520/2000], Avg Train Loss: 3.7166\n",
      "Epoch [520/2000], Avg Val Loss: 2.1185\n",
      "Validation loss improved from 2.1189 to 2.1185. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6621\n",
      "Epoch [521/2000], Avg Train Loss: 3.6621\n",
      "Epoch [521/2000], Avg Val Loss: 2.1181\n",
      "Validation loss improved from 2.1185 to 2.1181. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7375\n",
      "Epoch [522/2000], Avg Train Loss: 3.7375\n",
      "Epoch [522/2000], Avg Val Loss: 2.1177\n",
      "Validation loss improved from 2.1181 to 2.1177. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7339\n",
      "Epoch [523/2000], Avg Train Loss: 3.7339\n",
      "Epoch [523/2000], Avg Val Loss: 2.1173\n",
      "Validation loss improved from 2.1177 to 2.1173. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6760\n",
      "Epoch [524/2000], Avg Train Loss: 3.6760\n",
      "Epoch [524/2000], Avg Val Loss: 2.1169\n",
      "Validation loss improved from 2.1173 to 2.1169. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6859\n",
      "Epoch [525/2000], Avg Train Loss: 3.6859\n",
      "Epoch [525/2000], Avg Val Loss: 2.1166\n",
      "Validation loss improved from 2.1169 to 2.1166. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6823\n",
      "Epoch [526/2000], Avg Train Loss: 3.6823\n",
      "Epoch [526/2000], Avg Val Loss: 2.1162\n",
      "Validation loss improved from 2.1166 to 2.1162. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7080\n",
      "Epoch [527/2000], Avg Train Loss: 3.7080\n",
      "Epoch [527/2000], Avg Val Loss: 2.1158\n",
      "Validation loss improved from 2.1162 to 2.1158. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7254\n",
      "Epoch [528/2000], Avg Train Loss: 3.7254\n",
      "Epoch [528/2000], Avg Val Loss: 2.1154\n",
      "Validation loss improved from 2.1158 to 2.1154. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7117\n",
      "Epoch [529/2000], Avg Train Loss: 3.7117\n",
      "Epoch [529/2000], Avg Val Loss: 2.1150\n",
      "Validation loss improved from 2.1154 to 2.1150. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6635\n",
      "Epoch [530/2000], Avg Train Loss: 3.6635\n",
      "Epoch [530/2000], Avg Val Loss: 2.1146\n",
      "Validation loss improved from 2.1150 to 2.1146. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6808\n",
      "Epoch [531/2000], Avg Train Loss: 3.6808\n",
      "Epoch [531/2000], Avg Val Loss: 2.1142\n",
      "Validation loss improved from 2.1146 to 2.1142. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6864\n",
      "Epoch [532/2000], Avg Train Loss: 3.6864\n",
      "Epoch [532/2000], Avg Val Loss: 2.1138\n",
      "Validation loss improved from 2.1142 to 2.1138. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6919\n",
      "Epoch [533/2000], Avg Train Loss: 3.6919\n",
      "Epoch [533/2000], Avg Val Loss: 2.1134\n",
      "Validation loss improved from 2.1138 to 2.1134. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6630\n",
      "Epoch [534/2000], Avg Train Loss: 3.6630\n",
      "Epoch [534/2000], Avg Val Loss: 2.1130\n",
      "Validation loss improved from 2.1134 to 2.1130. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6761\n",
      "Epoch [535/2000], Avg Train Loss: 3.6761\n",
      "Epoch [535/2000], Avg Val Loss: 2.1126\n",
      "Validation loss improved from 2.1130 to 2.1126. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6568\n",
      "Epoch [536/2000], Avg Train Loss: 3.6568\n",
      "Epoch [536/2000], Avg Val Loss: 2.1122\n",
      "Validation loss improved from 2.1126 to 2.1122. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6508\n",
      "Epoch [537/2000], Avg Train Loss: 3.6508\n",
      "Epoch [537/2000], Avg Val Loss: 2.1118\n",
      "Validation loss improved from 2.1122 to 2.1118. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6940\n",
      "Epoch [538/2000], Avg Train Loss: 3.6940\n",
      "Epoch [538/2000], Avg Val Loss: 2.1115\n",
      "Validation loss improved from 2.1118 to 2.1115. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6417\n",
      "Epoch [539/2000], Avg Train Loss: 3.6417\n",
      "Epoch [539/2000], Avg Val Loss: 2.1111\n",
      "Validation loss improved from 2.1115 to 2.1111. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6791\n",
      "Epoch [540/2000], Avg Train Loss: 3.6791\n",
      "Epoch [540/2000], Avg Val Loss: 2.1108\n",
      "Validation loss improved from 2.1111 to 2.1108. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6773\n",
      "Epoch [541/2000], Avg Train Loss: 3.6773\n",
      "Epoch [541/2000], Avg Val Loss: 2.1104\n",
      "Validation loss improved from 2.1108 to 2.1104. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6505\n",
      "Epoch [542/2000], Avg Train Loss: 3.6505\n",
      "Epoch [542/2000], Avg Val Loss: 2.1100\n",
      "Validation loss improved from 2.1104 to 2.1100. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6690\n",
      "Epoch [543/2000], Avg Train Loss: 3.6690\n",
      "Epoch [543/2000], Avg Val Loss: 2.1097\n",
      "Validation loss improved from 2.1100 to 2.1097. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6676\n",
      "Epoch [544/2000], Avg Train Loss: 3.6676\n",
      "Epoch [544/2000], Avg Val Loss: 2.1093\n",
      "Validation loss improved from 2.1097 to 2.1093. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6637\n",
      "Epoch [545/2000], Avg Train Loss: 3.6637\n",
      "Epoch [545/2000], Avg Val Loss: 2.1090\n",
      "Validation loss improved from 2.1093 to 2.1090. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6891\n",
      "Epoch [546/2000], Avg Train Loss: 3.6891\n",
      "Epoch [546/2000], Avg Val Loss: 2.1087\n",
      "Validation loss improved from 2.1090 to 2.1087. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6484\n",
      "Epoch [547/2000], Avg Train Loss: 3.6484\n",
      "Epoch [547/2000], Avg Val Loss: 2.1084\n",
      "Validation loss improved from 2.1087 to 2.1084. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6882\n",
      "Epoch [548/2000], Avg Train Loss: 3.6882\n",
      "Epoch [548/2000], Avg Val Loss: 2.1080\n",
      "Validation loss improved from 2.1084 to 2.1080. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6392\n",
      "Epoch [549/2000], Avg Train Loss: 3.6392\n",
      "Epoch [549/2000], Avg Val Loss: 2.1076\n",
      "Validation loss improved from 2.1080 to 2.1076. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6796\n",
      "Epoch [550/2000], Avg Train Loss: 3.6796\n",
      "Epoch [550/2000], Avg Val Loss: 2.1073\n",
      "Validation loss improved from 2.1076 to 2.1073. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7056\n",
      "Epoch [551/2000], Avg Train Loss: 3.7056\n",
      "Epoch [551/2000], Avg Val Loss: 2.1069\n",
      "Validation loss improved from 2.1073 to 2.1069. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6730\n",
      "Epoch [552/2000], Avg Train Loss: 3.6730\n",
      "Epoch [552/2000], Avg Val Loss: 2.1065\n",
      "Validation loss improved from 2.1069 to 2.1065. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6272\n",
      "Epoch [553/2000], Avg Train Loss: 3.6272\n",
      "Epoch [553/2000], Avg Val Loss: 2.1061\n",
      "Validation loss improved from 2.1065 to 2.1061. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6730\n",
      "Epoch [554/2000], Avg Train Loss: 3.6730\n",
      "Epoch [554/2000], Avg Val Loss: 2.1057\n",
      "Validation loss improved from 2.1061 to 2.1057. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6529\n",
      "Epoch [555/2000], Avg Train Loss: 3.6529\n",
      "Epoch [555/2000], Avg Val Loss: 2.1054\n",
      "Validation loss improved from 2.1057 to 2.1054. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6737\n",
      "Epoch [556/2000], Avg Train Loss: 3.6737\n",
      "Epoch [556/2000], Avg Val Loss: 2.1050\n",
      "Validation loss improved from 2.1054 to 2.1050. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6195\n",
      "Epoch [557/2000], Avg Train Loss: 3.6195\n",
      "Epoch [557/2000], Avg Val Loss: 2.1047\n",
      "Validation loss improved from 2.1050 to 2.1047. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6807\n",
      "Epoch [558/2000], Avg Train Loss: 3.6807\n",
      "Epoch [558/2000], Avg Val Loss: 2.1043\n",
      "Validation loss improved from 2.1047 to 2.1043. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6585\n",
      "Epoch [559/2000], Avg Train Loss: 3.6585\n",
      "Epoch [559/2000], Avg Val Loss: 2.1040\n",
      "Validation loss improved from 2.1043 to 2.1040. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6438\n",
      "Epoch [560/2000], Avg Train Loss: 3.6438\n",
      "Epoch [560/2000], Avg Val Loss: 2.1037\n",
      "Validation loss improved from 2.1040 to 2.1037. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6406\n",
      "Epoch [561/2000], Avg Train Loss: 3.6406\n",
      "Epoch [561/2000], Avg Val Loss: 2.1033\n",
      "Validation loss improved from 2.1037 to 2.1033. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6427\n",
      "Epoch [562/2000], Avg Train Loss: 3.6427\n",
      "Epoch [562/2000], Avg Val Loss: 2.1030\n",
      "Validation loss improved from 2.1033 to 2.1030. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6648\n",
      "Epoch [563/2000], Avg Train Loss: 3.6648\n",
      "Epoch [563/2000], Avg Val Loss: 2.1026\n",
      "Validation loss improved from 2.1030 to 2.1026. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6687\n",
      "Epoch [564/2000], Avg Train Loss: 3.6687\n",
      "Epoch [564/2000], Avg Val Loss: 2.1023\n",
      "Validation loss improved from 2.1026 to 2.1023. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6673\n",
      "Epoch [565/2000], Avg Train Loss: 3.6673\n",
      "Epoch [565/2000], Avg Val Loss: 2.1019\n",
      "Validation loss improved from 2.1023 to 2.1019. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6378\n",
      "Epoch [566/2000], Avg Train Loss: 3.6378\n",
      "Epoch [566/2000], Avg Val Loss: 2.1016\n",
      "Validation loss improved from 2.1019 to 2.1016. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6326\n",
      "Epoch [567/2000], Avg Train Loss: 3.6326\n",
      "Epoch [567/2000], Avg Val Loss: 2.1012\n",
      "Validation loss improved from 2.1016 to 2.1012. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6576\n",
      "Epoch [568/2000], Avg Train Loss: 3.6576\n",
      "Epoch [568/2000], Avg Val Loss: 2.1009\n",
      "Validation loss improved from 2.1012 to 2.1009. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6403\n",
      "Epoch [569/2000], Avg Train Loss: 3.6403\n",
      "Epoch [569/2000], Avg Val Loss: 2.1005\n",
      "Validation loss improved from 2.1009 to 2.1005. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6590\n",
      "Epoch [570/2000], Avg Train Loss: 3.6590\n",
      "Epoch [570/2000], Avg Val Loss: 2.1001\n",
      "Validation loss improved from 2.1005 to 2.1001. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6233\n",
      "Epoch [571/2000], Avg Train Loss: 3.6233\n",
      "Epoch [571/2000], Avg Val Loss: 2.0998\n",
      "Validation loss improved from 2.1001 to 2.0998. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6412\n",
      "Epoch [572/2000], Avg Train Loss: 3.6412\n",
      "Epoch [572/2000], Avg Val Loss: 2.0995\n",
      "Validation loss improved from 2.0998 to 2.0995. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6336\n",
      "Epoch [573/2000], Avg Train Loss: 3.6336\n",
      "Epoch [573/2000], Avg Val Loss: 2.0991\n",
      "Validation loss improved from 2.0995 to 2.0991. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6205\n",
      "Epoch [574/2000], Avg Train Loss: 3.6205\n",
      "Epoch [574/2000], Avg Val Loss: 2.0988\n",
      "Validation loss improved from 2.0991 to 2.0988. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6433\n",
      "Epoch [575/2000], Avg Train Loss: 3.6433\n",
      "Epoch [575/2000], Avg Val Loss: 2.0985\n",
      "Validation loss improved from 2.0988 to 2.0985. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6667\n",
      "Epoch [576/2000], Avg Train Loss: 3.6667\n",
      "Epoch [576/2000], Avg Val Loss: 2.0981\n",
      "Validation loss improved from 2.0985 to 2.0981. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6576\n",
      "Epoch [577/2000], Avg Train Loss: 3.6576\n",
      "Epoch [577/2000], Avg Val Loss: 2.0978\n",
      "Validation loss improved from 2.0981 to 2.0978. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6127\n",
      "Epoch [578/2000], Avg Train Loss: 3.6127\n",
      "Epoch [578/2000], Avg Val Loss: 2.0974\n",
      "Validation loss improved from 2.0978 to 2.0974. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6147\n",
      "Epoch [579/2000], Avg Train Loss: 3.6147\n",
      "Epoch [579/2000], Avg Val Loss: 2.0970\n",
      "Validation loss improved from 2.0974 to 2.0970. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6625\n",
      "Epoch [580/2000], Avg Train Loss: 3.6625\n",
      "Epoch [580/2000], Avg Val Loss: 2.0967\n",
      "Validation loss improved from 2.0970 to 2.0967. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6488\n",
      "Epoch [581/2000], Avg Train Loss: 3.6488\n",
      "Epoch [581/2000], Avg Val Loss: 2.0963\n",
      "Validation loss improved from 2.0967 to 2.0963. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6365\n",
      "Epoch [582/2000], Avg Train Loss: 3.6365\n",
      "Epoch [582/2000], Avg Val Loss: 2.0958\n",
      "Validation loss improved from 2.0963 to 2.0958. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6472\n",
      "Epoch [583/2000], Avg Train Loss: 3.6472\n",
      "Epoch [583/2000], Avg Val Loss: 2.0954\n",
      "Validation loss improved from 2.0958 to 2.0954. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6075\n",
      "Epoch [584/2000], Avg Train Loss: 3.6075\n",
      "Epoch [584/2000], Avg Val Loss: 2.0950\n",
      "Validation loss improved from 2.0954 to 2.0950. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6040\n",
      "Epoch [585/2000], Avg Train Loss: 3.6040\n",
      "Epoch [585/2000], Avg Val Loss: 2.0946\n",
      "Validation loss improved from 2.0950 to 2.0946. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6088\n",
      "Epoch [586/2000], Avg Train Loss: 3.6088\n",
      "Epoch [586/2000], Avg Val Loss: 2.0942\n",
      "Validation loss improved from 2.0946 to 2.0942. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6508\n",
      "Epoch [587/2000], Avg Train Loss: 3.6508\n",
      "Epoch [587/2000], Avg Val Loss: 2.0938\n",
      "Validation loss improved from 2.0942 to 2.0938. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6052\n",
      "Epoch [588/2000], Avg Train Loss: 3.6052\n",
      "Epoch [588/2000], Avg Val Loss: 2.0934\n",
      "Validation loss improved from 2.0938 to 2.0934. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6410\n",
      "Epoch [589/2000], Avg Train Loss: 3.6410\n",
      "Epoch [589/2000], Avg Val Loss: 2.0930\n",
      "Validation loss improved from 2.0934 to 2.0930. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6586\n",
      "Epoch [590/2000], Avg Train Loss: 3.6586\n",
      "Epoch [590/2000], Avg Val Loss: 2.0926\n",
      "Validation loss improved from 2.0930 to 2.0926. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6172\n",
      "Epoch [591/2000], Avg Train Loss: 3.6172\n",
      "Epoch [591/2000], Avg Val Loss: 2.0922\n",
      "Validation loss improved from 2.0926 to 2.0922. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6131\n",
      "Epoch [592/2000], Avg Train Loss: 3.6131\n",
      "Epoch [592/2000], Avg Val Loss: 2.0918\n",
      "Validation loss improved from 2.0922 to 2.0918. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6283\n",
      "Epoch [593/2000], Avg Train Loss: 3.6283\n",
      "Epoch [593/2000], Avg Val Loss: 2.0915\n",
      "Validation loss improved from 2.0918 to 2.0915. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6669\n",
      "Epoch [594/2000], Avg Train Loss: 3.6669\n",
      "Epoch [594/2000], Avg Val Loss: 2.0911\n",
      "Validation loss improved from 2.0915 to 2.0911. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6098\n",
      "Epoch [595/2000], Avg Train Loss: 3.6098\n",
      "Epoch [595/2000], Avg Val Loss: 2.0907\n",
      "Validation loss improved from 2.0911 to 2.0907. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6548\n",
      "Epoch [596/2000], Avg Train Loss: 3.6548\n",
      "Epoch [596/2000], Avg Val Loss: 2.0903\n",
      "Validation loss improved from 2.0907 to 2.0903. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6285\n",
      "Epoch [597/2000], Avg Train Loss: 3.6285\n",
      "Epoch [597/2000], Avg Val Loss: 2.0899\n",
      "Validation loss improved from 2.0903 to 2.0899. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6528\n",
      "Epoch [598/2000], Avg Train Loss: 3.6528\n",
      "Epoch [598/2000], Avg Val Loss: 2.0896\n",
      "Validation loss improved from 2.0899 to 2.0896. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6600\n",
      "Epoch [599/2000], Avg Train Loss: 3.6600\n",
      "Epoch [599/2000], Avg Val Loss: 2.0892\n",
      "Validation loss improved from 2.0896 to 2.0892. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5895\n",
      "Epoch [600/2000], Avg Train Loss: 3.5895\n",
      "Epoch [600/2000], Avg Val Loss: 2.0889\n",
      "Validation loss improved from 2.0892 to 2.0889. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6283\n",
      "Epoch [601/2000], Avg Train Loss: 3.6283\n",
      "Epoch [601/2000], Avg Val Loss: 2.0885\n",
      "Validation loss improved from 2.0889 to 2.0885. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6561\n",
      "Epoch [602/2000], Avg Train Loss: 3.6561\n",
      "Epoch [602/2000], Avg Val Loss: 2.0882\n",
      "Validation loss improved from 2.0885 to 2.0882. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6303\n",
      "Epoch [603/2000], Avg Train Loss: 3.6303\n",
      "Epoch [603/2000], Avg Val Loss: 2.0879\n",
      "Validation loss improved from 2.0882 to 2.0879. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5749\n",
      "Epoch [604/2000], Avg Train Loss: 3.5749\n",
      "Epoch [604/2000], Avg Val Loss: 2.0876\n",
      "Validation loss improved from 2.0879 to 2.0876. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6221\n",
      "Epoch [605/2000], Avg Train Loss: 3.6221\n",
      "Epoch [605/2000], Avg Val Loss: 2.0873\n",
      "Validation loss improved from 2.0876 to 2.0873. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6248\n",
      "Epoch [606/2000], Avg Train Loss: 3.6248\n",
      "Epoch [606/2000], Avg Val Loss: 2.0869\n",
      "Validation loss improved from 2.0873 to 2.0869. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6375\n",
      "Epoch [607/2000], Avg Train Loss: 3.6375\n",
      "Epoch [607/2000], Avg Val Loss: 2.0866\n",
      "Validation loss improved from 2.0869 to 2.0866. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6381\n",
      "Epoch [608/2000], Avg Train Loss: 3.6381\n",
      "Epoch [608/2000], Avg Val Loss: 2.0863\n",
      "Validation loss improved from 2.0866 to 2.0863. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6137\n",
      "Epoch [609/2000], Avg Train Loss: 3.6137\n",
      "Epoch [609/2000], Avg Val Loss: 2.0860\n",
      "Validation loss improved from 2.0863 to 2.0860. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6318\n",
      "Epoch [610/2000], Avg Train Loss: 3.6318\n",
      "Epoch [610/2000], Avg Val Loss: 2.0857\n",
      "Validation loss improved from 2.0860 to 2.0857. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6299\n",
      "Epoch [611/2000], Avg Train Loss: 3.6299\n",
      "Epoch [611/2000], Avg Val Loss: 2.0853\n",
      "Validation loss improved from 2.0857 to 2.0853. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6434\n",
      "Epoch [612/2000], Avg Train Loss: 3.6434\n",
      "Epoch [612/2000], Avg Val Loss: 2.0850\n",
      "Validation loss improved from 2.0853 to 2.0850. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5612\n",
      "Epoch [613/2000], Avg Train Loss: 3.5612\n",
      "Epoch [613/2000], Avg Val Loss: 2.0846\n",
      "Validation loss improved from 2.0850 to 2.0846. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6092\n",
      "Epoch [614/2000], Avg Train Loss: 3.6092\n",
      "Epoch [614/2000], Avg Val Loss: 2.0842\n",
      "Validation loss improved from 2.0846 to 2.0842. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6188\n",
      "Epoch [615/2000], Avg Train Loss: 3.6188\n",
      "Epoch [615/2000], Avg Val Loss: 2.0838\n",
      "Validation loss improved from 2.0842 to 2.0838. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6304\n",
      "Epoch [616/2000], Avg Train Loss: 3.6304\n",
      "Epoch [616/2000], Avg Val Loss: 2.0834\n",
      "Validation loss improved from 2.0838 to 2.0834. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6652\n",
      "Epoch [617/2000], Avg Train Loss: 3.6652\n",
      "Epoch [617/2000], Avg Val Loss: 2.0830\n",
      "Validation loss improved from 2.0834 to 2.0830. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6192\n",
      "Epoch [618/2000], Avg Train Loss: 3.6192\n",
      "Epoch [618/2000], Avg Val Loss: 2.0826\n",
      "Validation loss improved from 2.0830 to 2.0826. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5658\n",
      "Epoch [619/2000], Avg Train Loss: 3.5658\n",
      "Epoch [619/2000], Avg Val Loss: 2.0823\n",
      "Validation loss improved from 2.0826 to 2.0823. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5949\n",
      "Epoch [620/2000], Avg Train Loss: 3.5949\n",
      "Epoch [620/2000], Avg Val Loss: 2.0818\n",
      "Validation loss improved from 2.0823 to 2.0818. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6010\n",
      "Epoch [621/2000], Avg Train Loss: 3.6010\n",
      "Epoch [621/2000], Avg Val Loss: 2.0814\n",
      "Validation loss improved from 2.0818 to 2.0814. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6003\n",
      "Epoch [622/2000], Avg Train Loss: 3.6003\n",
      "Epoch [622/2000], Avg Val Loss: 2.0809\n",
      "Validation loss improved from 2.0814 to 2.0809. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6440\n",
      "Epoch [623/2000], Avg Train Loss: 3.6440\n",
      "Epoch [623/2000], Avg Val Loss: 2.0805\n",
      "Validation loss improved from 2.0809 to 2.0805. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6052\n",
      "Epoch [624/2000], Avg Train Loss: 3.6052\n",
      "Epoch [624/2000], Avg Val Loss: 2.0800\n",
      "Validation loss improved from 2.0805 to 2.0800. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6166\n",
      "Epoch [625/2000], Avg Train Loss: 3.6166\n",
      "Epoch [625/2000], Avg Val Loss: 2.0796\n",
      "Validation loss improved from 2.0800 to 2.0796. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6411\n",
      "Epoch [626/2000], Avg Train Loss: 3.6411\n",
      "Epoch [626/2000], Avg Val Loss: 2.0791\n",
      "Validation loss improved from 2.0796 to 2.0791. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6047\n",
      "Epoch [627/2000], Avg Train Loss: 3.6047\n",
      "Epoch [627/2000], Avg Val Loss: 2.0787\n",
      "Validation loss improved from 2.0791 to 2.0787. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6286\n",
      "Epoch [628/2000], Avg Train Loss: 3.6286\n",
      "Epoch [628/2000], Avg Val Loss: 2.0783\n",
      "Validation loss improved from 2.0787 to 2.0783. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6007\n",
      "Epoch [629/2000], Avg Train Loss: 3.6007\n",
      "Epoch [629/2000], Avg Val Loss: 2.0779\n",
      "Validation loss improved from 2.0783 to 2.0779. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6154\n",
      "Epoch [630/2000], Avg Train Loss: 3.6154\n",
      "Epoch [630/2000], Avg Val Loss: 2.0775\n",
      "Validation loss improved from 2.0779 to 2.0775. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6111\n",
      "Epoch [631/2000], Avg Train Loss: 3.6111\n",
      "Epoch [631/2000], Avg Val Loss: 2.0771\n",
      "Validation loss improved from 2.0775 to 2.0771. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5619\n",
      "Epoch [632/2000], Avg Train Loss: 3.5619\n",
      "Epoch [632/2000], Avg Val Loss: 2.0767\n",
      "Validation loss improved from 2.0771 to 2.0767. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5975\n",
      "Epoch [633/2000], Avg Train Loss: 3.5975\n",
      "Epoch [633/2000], Avg Val Loss: 2.0763\n",
      "Validation loss improved from 2.0767 to 2.0763. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6223\n",
      "Epoch [634/2000], Avg Train Loss: 3.6223\n",
      "Epoch [634/2000], Avg Val Loss: 2.0760\n",
      "Validation loss improved from 2.0763 to 2.0760. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6077\n",
      "Epoch [635/2000], Avg Train Loss: 3.6077\n",
      "Epoch [635/2000], Avg Val Loss: 2.0756\n",
      "Validation loss improved from 2.0760 to 2.0756. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5893\n",
      "Epoch [636/2000], Avg Train Loss: 3.5893\n",
      "Epoch [636/2000], Avg Val Loss: 2.0752\n",
      "Validation loss improved from 2.0756 to 2.0752. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6028\n",
      "Epoch [637/2000], Avg Train Loss: 3.6028\n",
      "Epoch [637/2000], Avg Val Loss: 2.0748\n",
      "Validation loss improved from 2.0752 to 2.0748. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6060\n",
      "Epoch [638/2000], Avg Train Loss: 3.6060\n",
      "Epoch [638/2000], Avg Val Loss: 2.0744\n",
      "Validation loss improved from 2.0748 to 2.0744. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6219\n",
      "Epoch [639/2000], Avg Train Loss: 3.6219\n",
      "Epoch [639/2000], Avg Val Loss: 2.0740\n",
      "Validation loss improved from 2.0744 to 2.0740. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6264\n",
      "Epoch [640/2000], Avg Train Loss: 3.6264\n",
      "Epoch [640/2000], Avg Val Loss: 2.0736\n",
      "Validation loss improved from 2.0740 to 2.0736. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6011\n",
      "Epoch [641/2000], Avg Train Loss: 3.6011\n",
      "Epoch [641/2000], Avg Val Loss: 2.0733\n",
      "Validation loss improved from 2.0736 to 2.0733. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6020\n",
      "Epoch [642/2000], Avg Train Loss: 3.6020\n",
      "Epoch [642/2000], Avg Val Loss: 2.0729\n",
      "Validation loss improved from 2.0733 to 2.0729. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6029\n",
      "Epoch [643/2000], Avg Train Loss: 3.6029\n",
      "Epoch [643/2000], Avg Val Loss: 2.0725\n",
      "Validation loss improved from 2.0729 to 2.0725. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5788\n",
      "Epoch [644/2000], Avg Train Loss: 3.5788\n",
      "Epoch [644/2000], Avg Val Loss: 2.0721\n",
      "Validation loss improved from 2.0725 to 2.0721. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6197\n",
      "Epoch [645/2000], Avg Train Loss: 3.6197\n",
      "Epoch [645/2000], Avg Val Loss: 2.0718\n",
      "Validation loss improved from 2.0721 to 2.0718. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6166\n",
      "Epoch [646/2000], Avg Train Loss: 3.6166\n",
      "Epoch [646/2000], Avg Val Loss: 2.0715\n",
      "Validation loss improved from 2.0718 to 2.0715. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6282\n",
      "Epoch [647/2000], Avg Train Loss: 3.6282\n",
      "Epoch [647/2000], Avg Val Loss: 2.0712\n",
      "Validation loss improved from 2.0715 to 2.0712. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5974\n",
      "Epoch [648/2000], Avg Train Loss: 3.5974\n",
      "Epoch [648/2000], Avg Val Loss: 2.0709\n",
      "Validation loss improved from 2.0712 to 2.0709. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5975\n",
      "Epoch [649/2000], Avg Train Loss: 3.5975\n",
      "Epoch [649/2000], Avg Val Loss: 2.0706\n",
      "Validation loss improved from 2.0709 to 2.0706. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5896\n",
      "Epoch [650/2000], Avg Train Loss: 3.5896\n",
      "Epoch [650/2000], Avg Val Loss: 2.0703\n",
      "Validation loss improved from 2.0706 to 2.0703. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5702\n",
      "Epoch [651/2000], Avg Train Loss: 3.5702\n",
      "Epoch [651/2000], Avg Val Loss: 2.0699\n",
      "Validation loss improved from 2.0703 to 2.0699. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6141\n",
      "Epoch [652/2000], Avg Train Loss: 3.6141\n",
      "Epoch [652/2000], Avg Val Loss: 2.0696\n",
      "Validation loss improved from 2.0699 to 2.0696. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6148\n",
      "Epoch [653/2000], Avg Train Loss: 3.6148\n",
      "Epoch [653/2000], Avg Val Loss: 2.0693\n",
      "Validation loss improved from 2.0696 to 2.0693. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5817\n",
      "Epoch [654/2000], Avg Train Loss: 3.5817\n",
      "Epoch [654/2000], Avg Val Loss: 2.0689\n",
      "Validation loss improved from 2.0693 to 2.0689. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5862\n",
      "Epoch [655/2000], Avg Train Loss: 3.5862\n",
      "Epoch [655/2000], Avg Val Loss: 2.0686\n",
      "Validation loss improved from 2.0689 to 2.0686. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5814\n",
      "Epoch [656/2000], Avg Train Loss: 3.5814\n",
      "Epoch [656/2000], Avg Val Loss: 2.0683\n",
      "Validation loss improved from 2.0686 to 2.0683. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5934\n",
      "Epoch [657/2000], Avg Train Loss: 3.5934\n",
      "Epoch [657/2000], Avg Val Loss: 2.0680\n",
      "Validation loss improved from 2.0683 to 2.0680. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6109\n",
      "Epoch [658/2000], Avg Train Loss: 3.6109\n",
      "Epoch [658/2000], Avg Val Loss: 2.0676\n",
      "Validation loss improved from 2.0680 to 2.0676. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5744\n",
      "Epoch [659/2000], Avg Train Loss: 3.5744\n",
      "Epoch [659/2000], Avg Val Loss: 2.0672\n",
      "Validation loss improved from 2.0676 to 2.0672. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6017\n",
      "Epoch [660/2000], Avg Train Loss: 3.6017\n",
      "Epoch [660/2000], Avg Val Loss: 2.0668\n",
      "Validation loss improved from 2.0672 to 2.0668. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6140\n",
      "Epoch [661/2000], Avg Train Loss: 3.6140\n",
      "Epoch [661/2000], Avg Val Loss: 2.0664\n",
      "Validation loss improved from 2.0668 to 2.0664. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5748\n",
      "Epoch [662/2000], Avg Train Loss: 3.5748\n",
      "Epoch [662/2000], Avg Val Loss: 2.0660\n",
      "Validation loss improved from 2.0664 to 2.0660. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5876\n",
      "Epoch [663/2000], Avg Train Loss: 3.5876\n",
      "Epoch [663/2000], Avg Val Loss: 2.0657\n",
      "Validation loss improved from 2.0660 to 2.0657. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6134\n",
      "Epoch [664/2000], Avg Train Loss: 3.6134\n",
      "Epoch [664/2000], Avg Val Loss: 2.0653\n",
      "Validation loss improved from 2.0657 to 2.0653. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5743\n",
      "Epoch [665/2000], Avg Train Loss: 3.5743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [665/2000], Avg Val Loss: 2.0650\n",
      "Validation loss improved from 2.0653 to 2.0650. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5817\n",
      "Epoch [666/2000], Avg Train Loss: 3.5817\n",
      "Epoch [666/2000], Avg Val Loss: 2.0647\n",
      "Validation loss improved from 2.0650 to 2.0647. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5806\n",
      "Epoch [667/2000], Avg Train Loss: 3.5806\n",
      "Epoch [667/2000], Avg Val Loss: 2.0644\n",
      "Validation loss improved from 2.0647 to 2.0644. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5862\n",
      "Epoch [668/2000], Avg Train Loss: 3.5862\n",
      "Epoch [668/2000], Avg Val Loss: 2.0640\n",
      "Validation loss improved from 2.0644 to 2.0640. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5723\n",
      "Epoch [669/2000], Avg Train Loss: 3.5723\n",
      "Epoch [669/2000], Avg Val Loss: 2.0637\n",
      "Validation loss improved from 2.0640 to 2.0637. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6363\n",
      "Epoch [670/2000], Avg Train Loss: 3.6363\n",
      "Epoch [670/2000], Avg Val Loss: 2.0635\n",
      "Validation loss improved from 2.0637 to 2.0635. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5664\n",
      "Epoch [671/2000], Avg Train Loss: 3.5664\n",
      "Epoch [671/2000], Avg Val Loss: 2.0632\n",
      "Validation loss improved from 2.0635 to 2.0632. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5638\n",
      "Epoch [672/2000], Avg Train Loss: 3.5638\n",
      "Epoch [672/2000], Avg Val Loss: 2.0629\n",
      "Validation loss improved from 2.0632 to 2.0629. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6143\n",
      "Epoch [673/2000], Avg Train Loss: 3.6143\n",
      "Epoch [673/2000], Avg Val Loss: 2.0626\n",
      "Validation loss improved from 2.0629 to 2.0626. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5957\n",
      "Epoch [674/2000], Avg Train Loss: 3.5957\n",
      "Epoch [674/2000], Avg Val Loss: 2.0624\n",
      "Validation loss improved from 2.0626 to 2.0624. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5935\n",
      "Epoch [675/2000], Avg Train Loss: 3.5935\n",
      "Epoch [675/2000], Avg Val Loss: 2.0620\n",
      "Validation loss improved from 2.0624 to 2.0620. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5865\n",
      "Epoch [676/2000], Avg Train Loss: 3.5865\n",
      "Epoch [676/2000], Avg Val Loss: 2.0617\n",
      "Validation loss improved from 2.0620 to 2.0617. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5637\n",
      "Epoch [677/2000], Avg Train Loss: 3.5637\n",
      "Epoch [677/2000], Avg Val Loss: 2.0614\n",
      "Validation loss improved from 2.0617 to 2.0614. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5897\n",
      "Epoch [678/2000], Avg Train Loss: 3.5897\n",
      "Epoch [678/2000], Avg Val Loss: 2.0611\n",
      "Validation loss improved from 2.0614 to 2.0611. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5781\n",
      "Epoch [679/2000], Avg Train Loss: 3.5781\n",
      "Epoch [679/2000], Avg Val Loss: 2.0609\n",
      "Validation loss improved from 2.0611 to 2.0609. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5543\n",
      "Epoch [680/2000], Avg Train Loss: 3.5543\n",
      "Epoch [680/2000], Avg Val Loss: 2.0607\n",
      "Validation loss improved from 2.0609 to 2.0607. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5711\n",
      "Epoch [681/2000], Avg Train Loss: 3.5711\n",
      "Epoch [681/2000], Avg Val Loss: 2.0604\n",
      "Validation loss improved from 2.0607 to 2.0604. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5789\n",
      "Epoch [682/2000], Avg Train Loss: 3.5789\n",
      "Epoch [682/2000], Avg Val Loss: 2.0601\n",
      "Validation loss improved from 2.0604 to 2.0601. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5492\n",
      "Epoch [683/2000], Avg Train Loss: 3.5492\n",
      "Epoch [683/2000], Avg Val Loss: 2.0599\n",
      "Validation loss improved from 2.0601 to 2.0599. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5559\n",
      "Epoch [684/2000], Avg Train Loss: 3.5559\n",
      "Epoch [684/2000], Avg Val Loss: 2.0596\n",
      "Validation loss improved from 2.0599 to 2.0596. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5614\n",
      "Epoch [685/2000], Avg Train Loss: 3.5614\n",
      "Epoch [685/2000], Avg Val Loss: 2.0592\n",
      "Validation loss improved from 2.0596 to 2.0592. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5552\n",
      "Epoch [686/2000], Avg Train Loss: 3.5552\n",
      "Epoch [686/2000], Avg Val Loss: 2.0589\n",
      "Validation loss improved from 2.0592 to 2.0589. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5579\n",
      "Epoch [687/2000], Avg Train Loss: 3.5579\n",
      "Epoch [687/2000], Avg Val Loss: 2.0586\n",
      "Validation loss improved from 2.0589 to 2.0586. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5538\n",
      "Epoch [688/2000], Avg Train Loss: 3.5538\n",
      "Epoch [688/2000], Avg Val Loss: 2.0583\n",
      "Validation loss improved from 2.0586 to 2.0583. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5664\n",
      "Epoch [689/2000], Avg Train Loss: 3.5664\n",
      "Epoch [689/2000], Avg Val Loss: 2.0581\n",
      "Validation loss improved from 2.0583 to 2.0581. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5487\n",
      "Epoch [690/2000], Avg Train Loss: 3.5487\n",
      "Epoch [690/2000], Avg Val Loss: 2.0578\n",
      "Validation loss improved from 2.0581 to 2.0578. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5667\n",
      "Epoch [691/2000], Avg Train Loss: 3.5667\n",
      "Epoch [691/2000], Avg Val Loss: 2.0575\n",
      "Validation loss improved from 2.0578 to 2.0575. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5655\n",
      "Epoch [692/2000], Avg Train Loss: 3.5655\n",
      "Epoch [692/2000], Avg Val Loss: 2.0572\n",
      "Validation loss improved from 2.0575 to 2.0572. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5450\n",
      "Epoch [693/2000], Avg Train Loss: 3.5450\n",
      "Epoch [693/2000], Avg Val Loss: 2.0569\n",
      "Validation loss improved from 2.0572 to 2.0569. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5450\n",
      "Epoch [694/2000], Avg Train Loss: 3.5450\n",
      "Epoch [694/2000], Avg Val Loss: 2.0566\n",
      "Validation loss improved from 2.0569 to 2.0566. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5749\n",
      "Epoch [695/2000], Avg Train Loss: 3.5749\n",
      "Epoch [695/2000], Avg Val Loss: 2.0563\n",
      "Validation loss improved from 2.0566 to 2.0563. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5189\n",
      "Epoch [696/2000], Avg Train Loss: 3.5189\n",
      "Epoch [696/2000], Avg Val Loss: 2.0560\n",
      "Validation loss improved from 2.0563 to 2.0560. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5560\n",
      "Epoch [697/2000], Avg Train Loss: 3.5560\n",
      "Epoch [697/2000], Avg Val Loss: 2.0556\n",
      "Validation loss improved from 2.0560 to 2.0556. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5492\n",
      "Epoch [698/2000], Avg Train Loss: 3.5492\n",
      "Epoch [698/2000], Avg Val Loss: 2.0553\n",
      "Validation loss improved from 2.0556 to 2.0553. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5468\n",
      "Epoch [699/2000], Avg Train Loss: 3.5468\n",
      "Epoch [699/2000], Avg Val Loss: 2.0550\n",
      "Validation loss improved from 2.0553 to 2.0550. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5915\n",
      "Epoch [700/2000], Avg Train Loss: 3.5915\n",
      "Epoch [700/2000], Avg Val Loss: 2.0547\n",
      "Validation loss improved from 2.0550 to 2.0547. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5627\n",
      "Epoch [701/2000], Avg Train Loss: 3.5627\n",
      "Epoch [701/2000], Avg Val Loss: 2.0543\n",
      "Validation loss improved from 2.0547 to 2.0543. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5510\n",
      "Epoch [702/2000], Avg Train Loss: 3.5510\n",
      "Epoch [702/2000], Avg Val Loss: 2.0540\n",
      "Validation loss improved from 2.0543 to 2.0540. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5753\n",
      "Epoch [703/2000], Avg Train Loss: 3.5753\n",
      "Epoch [703/2000], Avg Val Loss: 2.0536\n",
      "Validation loss improved from 2.0540 to 2.0536. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5914\n",
      "Epoch [704/2000], Avg Train Loss: 3.5914\n",
      "Epoch [704/2000], Avg Val Loss: 2.0533\n",
      "Validation loss improved from 2.0536 to 2.0533. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5457\n",
      "Epoch [705/2000], Avg Train Loss: 3.5457\n",
      "Epoch [705/2000], Avg Val Loss: 2.0530\n",
      "Validation loss improved from 2.0533 to 2.0530. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5754\n",
      "Epoch [706/2000], Avg Train Loss: 3.5754\n",
      "Epoch [706/2000], Avg Val Loss: 2.0527\n",
      "Validation loss improved from 2.0530 to 2.0527. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5361\n",
      "Epoch [707/2000], Avg Train Loss: 3.5361\n",
      "Epoch [707/2000], Avg Val Loss: 2.0525\n",
      "Validation loss improved from 2.0527 to 2.0525. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5421\n",
      "Epoch [708/2000], Avg Train Loss: 3.5421\n",
      "Epoch [708/2000], Avg Val Loss: 2.0522\n",
      "Validation loss improved from 2.0525 to 2.0522. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5446\n",
      "Epoch [709/2000], Avg Train Loss: 3.5446\n",
      "Epoch [709/2000], Avg Val Loss: 2.0520\n",
      "Validation loss improved from 2.0522 to 2.0520. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5687\n",
      "Epoch [710/2000], Avg Train Loss: 3.5687\n",
      "Epoch [710/2000], Avg Val Loss: 2.0517\n",
      "Validation loss improved from 2.0520 to 2.0517. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5546\n",
      "Epoch [711/2000], Avg Train Loss: 3.5546\n",
      "Epoch [711/2000], Avg Val Loss: 2.0515\n",
      "Validation loss improved from 2.0517 to 2.0515. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5597\n",
      "Epoch [712/2000], Avg Train Loss: 3.5597\n",
      "Epoch [712/2000], Avg Val Loss: 2.0511\n",
      "Validation loss improved from 2.0515 to 2.0511. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5593\n",
      "Epoch [713/2000], Avg Train Loss: 3.5593\n",
      "Epoch [713/2000], Avg Val Loss: 2.0508\n",
      "Validation loss improved from 2.0511 to 2.0508. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5506\n",
      "Epoch [714/2000], Avg Train Loss: 3.5506\n",
      "Epoch [714/2000], Avg Val Loss: 2.0504\n",
      "Validation loss improved from 2.0508 to 2.0504. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5404\n",
      "Epoch [715/2000], Avg Train Loss: 3.5404\n",
      "Epoch [715/2000], Avg Val Loss: 2.0501\n",
      "Validation loss improved from 2.0504 to 2.0501. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5275\n",
      "Epoch [716/2000], Avg Train Loss: 3.5275\n",
      "Epoch [716/2000], Avg Val Loss: 2.0498\n",
      "Validation loss improved from 2.0501 to 2.0498. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5557\n",
      "Epoch [717/2000], Avg Train Loss: 3.5557\n",
      "Epoch [717/2000], Avg Val Loss: 2.0495\n",
      "Validation loss improved from 2.0498 to 2.0495. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5710\n",
      "Epoch [718/2000], Avg Train Loss: 3.5710\n",
      "Epoch [718/2000], Avg Val Loss: 2.0492\n",
      "Validation loss improved from 2.0495 to 2.0492. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5642\n",
      "Epoch [719/2000], Avg Train Loss: 3.5642\n",
      "Epoch [719/2000], Avg Val Loss: 2.0489\n",
      "Validation loss improved from 2.0492 to 2.0489. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5624\n",
      "Epoch [720/2000], Avg Train Loss: 3.5624\n",
      "Epoch [720/2000], Avg Val Loss: 2.0486\n",
      "Validation loss improved from 2.0489 to 2.0486. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5444\n",
      "Epoch [721/2000], Avg Train Loss: 3.5444\n",
      "Epoch [721/2000], Avg Val Loss: 2.0483\n",
      "Validation loss improved from 2.0486 to 2.0483. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5599\n",
      "Epoch [722/2000], Avg Train Loss: 3.5599\n",
      "Epoch [722/2000], Avg Val Loss: 2.0480\n",
      "Validation loss improved from 2.0483 to 2.0480. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5353\n",
      "Epoch [723/2000], Avg Train Loss: 3.5353\n",
      "Epoch [723/2000], Avg Val Loss: 2.0477\n",
      "Validation loss improved from 2.0480 to 2.0477. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5455\n",
      "Epoch [724/2000], Avg Train Loss: 3.5455\n",
      "Epoch [724/2000], Avg Val Loss: 2.0473\n",
      "Validation loss improved from 2.0477 to 2.0473. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [725/2000], Avg Train Loss: 3.5435\n",
      "Epoch [725/2000], Avg Val Loss: 2.0470\n",
      "Validation loss improved from 2.0473 to 2.0470. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5593\n",
      "Epoch [726/2000], Avg Train Loss: 3.5593\n",
      "Epoch [726/2000], Avg Val Loss: 2.0466\n",
      "Validation loss improved from 2.0470 to 2.0466. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5137\n",
      "Epoch [727/2000], Avg Train Loss: 3.5137\n",
      "Epoch [727/2000], Avg Val Loss: 2.0463\n",
      "Validation loss improved from 2.0466 to 2.0463. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5167\n",
      "Epoch [728/2000], Avg Train Loss: 3.5167\n",
      "Epoch [728/2000], Avg Val Loss: 2.0459\n",
      "Validation loss improved from 2.0463 to 2.0459. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5308\n",
      "Epoch [729/2000], Avg Train Loss: 3.5308\n",
      "Epoch [729/2000], Avg Val Loss: 2.0455\n",
      "Validation loss improved from 2.0459 to 2.0455. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [730/2000], Avg Train Loss: 3.5321\n",
      "Epoch [730/2000], Avg Val Loss: 2.0452\n",
      "Validation loss improved from 2.0455 to 2.0452. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5311\n",
      "Epoch [731/2000], Avg Train Loss: 3.5311\n",
      "Epoch [731/2000], Avg Val Loss: 2.0448\n",
      "Validation loss improved from 2.0452 to 2.0448. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5759\n",
      "Epoch [732/2000], Avg Train Loss: 3.5759\n",
      "Epoch [732/2000], Avg Val Loss: 2.0444\n",
      "Validation loss improved from 2.0448 to 2.0444. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5539\n",
      "Epoch [733/2000], Avg Train Loss: 3.5539\n",
      "Epoch [733/2000], Avg Val Loss: 2.0440\n",
      "Validation loss improved from 2.0444 to 2.0440. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5381\n",
      "Epoch [734/2000], Avg Train Loss: 3.5381\n",
      "Epoch [734/2000], Avg Val Loss: 2.0437\n",
      "Validation loss improved from 2.0440 to 2.0437. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5201\n",
      "Epoch [735/2000], Avg Train Loss: 3.5201\n",
      "Epoch [735/2000], Avg Val Loss: 2.0433\n",
      "Validation loss improved from 2.0437 to 2.0433. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5565\n",
      "Epoch [736/2000], Avg Train Loss: 3.5565\n",
      "Epoch [736/2000], Avg Val Loss: 2.0429\n",
      "Validation loss improved from 2.0433 to 2.0429. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5047\n",
      "Epoch [737/2000], Avg Train Loss: 3.5047\n",
      "Epoch [737/2000], Avg Val Loss: 2.0426\n",
      "Validation loss improved from 2.0429 to 2.0426. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5471\n",
      "Epoch [738/2000], Avg Train Loss: 3.5471\n",
      "Epoch [738/2000], Avg Val Loss: 2.0423\n",
      "Validation loss improved from 2.0426 to 2.0423. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5580\n",
      "Epoch [739/2000], Avg Train Loss: 3.5580\n",
      "Epoch [739/2000], Avg Val Loss: 2.0420\n",
      "Validation loss improved from 2.0423 to 2.0420. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5531\n",
      "Epoch [740/2000], Avg Train Loss: 3.5531\n",
      "Epoch [740/2000], Avg Val Loss: 2.0418\n",
      "Validation loss improved from 2.0420 to 2.0418. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5312\n",
      "Epoch [741/2000], Avg Train Loss: 3.5312\n",
      "Epoch [741/2000], Avg Val Loss: 2.0415\n",
      "Validation loss improved from 2.0418 to 2.0415. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5231\n",
      "Epoch [742/2000], Avg Train Loss: 3.5231\n",
      "Epoch [742/2000], Avg Val Loss: 2.0412\n",
      "Validation loss improved from 2.0415 to 2.0412. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5370\n",
      "Epoch [743/2000], Avg Train Loss: 3.5370\n",
      "Epoch [743/2000], Avg Val Loss: 2.0409\n",
      "Validation loss improved from 2.0412 to 2.0409. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5648\n",
      "Epoch [744/2000], Avg Train Loss: 3.5648\n",
      "Epoch [744/2000], Avg Val Loss: 2.0406\n",
      "Validation loss improved from 2.0409 to 2.0406. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5335\n",
      "Epoch [745/2000], Avg Train Loss: 3.5335\n",
      "Epoch [745/2000], Avg Val Loss: 2.0403\n",
      "Validation loss improved from 2.0406 to 2.0403. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5618\n",
      "Epoch [746/2000], Avg Train Loss: 3.5618\n",
      "Epoch [746/2000], Avg Val Loss: 2.0401\n",
      "Validation loss improved from 2.0403 to 2.0401. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5296\n",
      "Epoch [747/2000], Avg Train Loss: 3.5296\n",
      "Epoch [747/2000], Avg Val Loss: 2.0398\n",
      "Validation loss improved from 2.0401 to 2.0398. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5265\n",
      "Epoch [748/2000], Avg Train Loss: 3.5265\n",
      "Epoch [748/2000], Avg Val Loss: 2.0395\n",
      "Validation loss improved from 2.0398 to 2.0395. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5353\n",
      "Epoch [749/2000], Avg Train Loss: 3.5353\n",
      "Epoch [749/2000], Avg Val Loss: 2.0392\n",
      "Validation loss improved from 2.0395 to 2.0392. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5206\n",
      "Epoch [750/2000], Avg Train Loss: 3.5206\n",
      "Epoch [750/2000], Avg Val Loss: 2.0389\n",
      "Validation loss improved from 2.0392 to 2.0389. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5613\n",
      "Epoch [751/2000], Avg Train Loss: 3.5613\n",
      "Epoch [751/2000], Avg Val Loss: 2.0386\n",
      "Validation loss improved from 2.0389 to 2.0386. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5508\n",
      "Epoch [752/2000], Avg Train Loss: 3.5508\n",
      "Epoch [752/2000], Avg Val Loss: 2.0383\n",
      "Validation loss improved from 2.0386 to 2.0383. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5532\n",
      "Epoch [753/2000], Avg Train Loss: 3.5532\n",
      "Epoch [753/2000], Avg Val Loss: 2.0380\n",
      "Validation loss improved from 2.0383 to 2.0380. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5411\n",
      "Epoch [754/2000], Avg Train Loss: 3.5411\n",
      "Epoch [754/2000], Avg Val Loss: 2.0377\n",
      "Validation loss improved from 2.0380 to 2.0377. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5304\n",
      "Epoch [755/2000], Avg Train Loss: 3.5304\n",
      "Epoch [755/2000], Avg Val Loss: 2.0373\n",
      "Validation loss improved from 2.0377 to 2.0373. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5584\n",
      "Epoch [756/2000], Avg Train Loss: 3.5584\n",
      "Epoch [756/2000], Avg Val Loss: 2.0370\n",
      "Validation loss improved from 2.0373 to 2.0370. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5279\n",
      "Epoch [757/2000], Avg Train Loss: 3.5279\n",
      "Epoch [757/2000], Avg Val Loss: 2.0367\n",
      "Validation loss improved from 2.0370 to 2.0367. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [758/2000], Avg Train Loss: 3.5435\n",
      "Epoch [758/2000], Avg Val Loss: 2.0363\n",
      "Validation loss improved from 2.0367 to 2.0363. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5744\n",
      "Epoch [759/2000], Avg Train Loss: 3.5744\n",
      "Epoch [759/2000], Avg Val Loss: 2.0359\n",
      "Validation loss improved from 2.0363 to 2.0359. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5355\n",
      "Epoch [760/2000], Avg Train Loss: 3.5355\n",
      "Epoch [760/2000], Avg Val Loss: 2.0355\n",
      "Validation loss improved from 2.0359 to 2.0355. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5295\n",
      "Epoch [761/2000], Avg Train Loss: 3.5295\n",
      "Epoch [761/2000], Avg Val Loss: 2.0351\n",
      "Validation loss improved from 2.0355 to 2.0351. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [762/2000], Avg Train Loss: 3.5321\n",
      "Epoch [762/2000], Avg Val Loss: 2.0347\n",
      "Validation loss improved from 2.0351 to 2.0347. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5719\n",
      "Epoch [763/2000], Avg Train Loss: 3.5719\n",
      "Epoch [763/2000], Avg Val Loss: 2.0343\n",
      "Validation loss improved from 2.0347 to 2.0343. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5328\n",
      "Epoch [764/2000], Avg Train Loss: 3.5328\n",
      "Epoch [764/2000], Avg Val Loss: 2.0339\n",
      "Validation loss improved from 2.0343 to 2.0339. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5305\n",
      "Epoch [765/2000], Avg Train Loss: 3.5305\n",
      "Epoch [765/2000], Avg Val Loss: 2.0335\n",
      "Validation loss improved from 2.0339 to 2.0335. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5443\n",
      "Epoch [766/2000], Avg Train Loss: 3.5443\n",
      "Epoch [766/2000], Avg Val Loss: 2.0331\n",
      "Validation loss improved from 2.0335 to 2.0331. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5234\n",
      "Epoch [767/2000], Avg Train Loss: 3.5234\n",
      "Epoch [767/2000], Avg Val Loss: 2.0327\n",
      "Validation loss improved from 2.0331 to 2.0327. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5434\n",
      "Epoch [768/2000], Avg Train Loss: 3.5434\n",
      "Epoch [768/2000], Avg Val Loss: 2.0323\n",
      "Validation loss improved from 2.0327 to 2.0323. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5319\n",
      "Epoch [769/2000], Avg Train Loss: 3.5319\n",
      "Epoch [769/2000], Avg Val Loss: 2.0320\n",
      "Validation loss improved from 2.0323 to 2.0320. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5022\n",
      "Epoch [770/2000], Avg Train Loss: 3.5022\n",
      "Epoch [770/2000], Avg Val Loss: 2.0316\n",
      "Validation loss improved from 2.0320 to 2.0316. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4815\n",
      "Epoch [771/2000], Avg Train Loss: 3.4815\n",
      "Epoch [771/2000], Avg Val Loss: 2.0313\n",
      "Validation loss improved from 2.0316 to 2.0313. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5183\n",
      "Epoch [772/2000], Avg Train Loss: 3.5183\n",
      "Epoch [772/2000], Avg Val Loss: 2.0309\n",
      "Validation loss improved from 2.0313 to 2.0309. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [773/2000], Avg Train Loss: 3.5321\n",
      "Epoch [773/2000], Avg Val Loss: 2.0306\n",
      "Validation loss improved from 2.0309 to 2.0306. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5389\n",
      "Epoch [774/2000], Avg Train Loss: 3.5389\n",
      "Epoch [774/2000], Avg Val Loss: 2.0303\n",
      "Validation loss improved from 2.0306 to 2.0303. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5377\n",
      "Epoch [775/2000], Avg Train Loss: 3.5377\n",
      "Epoch [775/2000], Avg Val Loss: 2.0300\n",
      "Validation loss improved from 2.0303 to 2.0300. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5298\n",
      "Epoch [776/2000], Avg Train Loss: 3.5298\n",
      "Epoch [776/2000], Avg Val Loss: 2.0297\n",
      "Validation loss improved from 2.0300 to 2.0297. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5088\n",
      "Epoch [777/2000], Avg Train Loss: 3.5088\n",
      "Epoch [777/2000], Avg Val Loss: 2.0294\n",
      "Validation loss improved from 2.0297 to 2.0294. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4920\n",
      "Epoch [778/2000], Avg Train Loss: 3.4920\n",
      "Epoch [778/2000], Avg Val Loss: 2.0291\n",
      "Validation loss improved from 2.0294 to 2.0291. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5189\n",
      "Epoch [779/2000], Avg Train Loss: 3.5189\n",
      "Epoch [779/2000], Avg Val Loss: 2.0288\n",
      "Validation loss improved from 2.0291 to 2.0288. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5312\n",
      "Epoch [780/2000], Avg Train Loss: 3.5312\n",
      "Epoch [780/2000], Avg Val Loss: 2.0285\n",
      "Validation loss improved from 2.0288 to 2.0285. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5262\n",
      "Epoch [781/2000], Avg Train Loss: 3.5262\n",
      "Epoch [781/2000], Avg Val Loss: 2.0282\n",
      "Validation loss improved from 2.0285 to 2.0282. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5235\n",
      "Epoch [782/2000], Avg Train Loss: 3.5235\n",
      "Epoch [782/2000], Avg Val Loss: 2.0278\n",
      "Validation loss improved from 2.0282 to 2.0278. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5499\n",
      "Epoch [783/2000], Avg Train Loss: 3.5499\n",
      "Epoch [783/2000], Avg Val Loss: 2.0275\n",
      "Validation loss improved from 2.0278 to 2.0275. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5342\n",
      "Epoch [784/2000], Avg Train Loss: 3.5342\n",
      "Epoch [784/2000], Avg Val Loss: 2.0271\n",
      "Validation loss improved from 2.0275 to 2.0271. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5180\n",
      "Epoch [785/2000], Avg Train Loss: 3.5180\n",
      "Epoch [785/2000], Avg Val Loss: 2.0267\n",
      "Validation loss improved from 2.0271 to 2.0267. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5504\n",
      "Epoch [786/2000], Avg Train Loss: 3.5504\n",
      "Epoch [786/2000], Avg Val Loss: 2.0264\n",
      "Validation loss improved from 2.0267 to 2.0264. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4736\n",
      "Epoch [787/2000], Avg Train Loss: 3.4736\n",
      "Epoch [787/2000], Avg Val Loss: 2.0261\n",
      "Validation loss improved from 2.0264 to 2.0261. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5273\n",
      "Epoch [788/2000], Avg Train Loss: 3.5273\n",
      "Epoch [788/2000], Avg Val Loss: 2.0257\n",
      "Validation loss improved from 2.0261 to 2.0257. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5178\n",
      "Epoch [789/2000], Avg Train Loss: 3.5178\n",
      "Epoch [789/2000], Avg Val Loss: 2.0254\n",
      "Validation loss improved from 2.0257 to 2.0254. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5094\n",
      "Epoch [790/2000], Avg Train Loss: 3.5094\n",
      "Epoch [790/2000], Avg Val Loss: 2.0251\n",
      "Validation loss improved from 2.0254 to 2.0251. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5194\n",
      "Epoch [791/2000], Avg Train Loss: 3.5194\n",
      "Epoch [791/2000], Avg Val Loss: 2.0248\n",
      "Validation loss improved from 2.0251 to 2.0248. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4927\n",
      "Epoch [792/2000], Avg Train Loss: 3.4927\n",
      "Epoch [792/2000], Avg Val Loss: 2.0245\n",
      "Validation loss improved from 2.0248 to 2.0245. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5063\n",
      "Epoch [793/2000], Avg Train Loss: 3.5063\n",
      "Epoch [793/2000], Avg Val Loss: 2.0242\n",
      "Validation loss improved from 2.0245 to 2.0242. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5308\n",
      "Epoch [794/2000], Avg Train Loss: 3.5308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [794/2000], Avg Val Loss: 2.0240\n",
      "Validation loss improved from 2.0242 to 2.0240. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4948\n",
      "Epoch [795/2000], Avg Train Loss: 3.4948\n",
      "Epoch [795/2000], Avg Val Loss: 2.0238\n",
      "Validation loss improved from 2.0240 to 2.0238. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5094\n",
      "Epoch [796/2000], Avg Train Loss: 3.5094\n",
      "Epoch [796/2000], Avg Val Loss: 2.0235\n",
      "Validation loss improved from 2.0238 to 2.0235. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5338\n",
      "Epoch [797/2000], Avg Train Loss: 3.5338\n",
      "Epoch [797/2000], Avg Val Loss: 2.0232\n",
      "Validation loss improved from 2.0235 to 2.0232. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5082\n",
      "Epoch [798/2000], Avg Train Loss: 3.5082\n",
      "Epoch [798/2000], Avg Val Loss: 2.0229\n",
      "Validation loss improved from 2.0232 to 2.0229. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4886\n",
      "Epoch [799/2000], Avg Train Loss: 3.4886\n",
      "Epoch [799/2000], Avg Val Loss: 2.0227\n",
      "Validation loss improved from 2.0229 to 2.0227. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5053\n",
      "Epoch [800/2000], Avg Train Loss: 3.5053\n",
      "Epoch [800/2000], Avg Val Loss: 2.0224\n",
      "Validation loss improved from 2.0227 to 2.0224. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5082\n",
      "Epoch [801/2000], Avg Train Loss: 3.5082\n",
      "Epoch [801/2000], Avg Val Loss: 2.0222\n",
      "Validation loss improved from 2.0224 to 2.0222. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5095\n",
      "Epoch [802/2000], Avg Train Loss: 3.5095\n",
      "Epoch [802/2000], Avg Val Loss: 2.0219\n",
      "Validation loss improved from 2.0222 to 2.0219. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4966\n",
      "Epoch [803/2000], Avg Train Loss: 3.4966\n",
      "Epoch [803/2000], Avg Val Loss: 2.0217\n",
      "Validation loss improved from 2.0219 to 2.0217. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4871\n",
      "Epoch [804/2000], Avg Train Loss: 3.4871\n",
      "Epoch [804/2000], Avg Val Loss: 2.0214\n",
      "Validation loss improved from 2.0217 to 2.0214. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5269\n",
      "Epoch [805/2000], Avg Train Loss: 3.5269\n",
      "Epoch [805/2000], Avg Val Loss: 2.0211\n",
      "Validation loss improved from 2.0214 to 2.0211. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4792\n",
      "Epoch [806/2000], Avg Train Loss: 3.4792\n",
      "Epoch [806/2000], Avg Val Loss: 2.0208\n",
      "Validation loss improved from 2.0211 to 2.0208. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5044\n",
      "Epoch [807/2000], Avg Train Loss: 3.5044\n",
      "Epoch [807/2000], Avg Val Loss: 2.0205\n",
      "Validation loss improved from 2.0208 to 2.0205. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5387\n",
      "Epoch [808/2000], Avg Train Loss: 3.5387\n",
      "Epoch [808/2000], Avg Val Loss: 2.0203\n",
      "Validation loss improved from 2.0205 to 2.0203. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4938\n",
      "Epoch [809/2000], Avg Train Loss: 3.4938\n",
      "Epoch [809/2000], Avg Val Loss: 2.0200\n",
      "Validation loss improved from 2.0203 to 2.0200. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4784\n",
      "Epoch [810/2000], Avg Train Loss: 3.4784\n",
      "Epoch [810/2000], Avg Val Loss: 2.0196\n",
      "Validation loss improved from 2.0200 to 2.0196. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5137\n",
      "Epoch [811/2000], Avg Train Loss: 3.5137\n",
      "Epoch [811/2000], Avg Val Loss: 2.0193\n",
      "Validation loss improved from 2.0196 to 2.0193. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4974\n",
      "Epoch [812/2000], Avg Train Loss: 3.4974\n",
      "Epoch [812/2000], Avg Val Loss: 2.0189\n",
      "Validation loss improved from 2.0193 to 2.0189. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4943\n",
      "Epoch [813/2000], Avg Train Loss: 3.4943\n",
      "Epoch [813/2000], Avg Val Loss: 2.0186\n",
      "Validation loss improved from 2.0189 to 2.0186. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5247\n",
      "Epoch [814/2000], Avg Train Loss: 3.5247\n",
      "Epoch [814/2000], Avg Val Loss: 2.0183\n",
      "Validation loss improved from 2.0186 to 2.0183. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5067\n",
      "Epoch [815/2000], Avg Train Loss: 3.5067\n",
      "Epoch [815/2000], Avg Val Loss: 2.0179\n",
      "Validation loss improved from 2.0183 to 2.0179. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5240\n",
      "Epoch [816/2000], Avg Train Loss: 3.5240\n",
      "Epoch [816/2000], Avg Val Loss: 2.0175\n",
      "Validation loss improved from 2.0179 to 2.0175. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4750\n",
      "Epoch [817/2000], Avg Train Loss: 3.4750\n",
      "Epoch [817/2000], Avg Val Loss: 2.0171\n",
      "Validation loss improved from 2.0175 to 2.0171. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5039\n",
      "Epoch [818/2000], Avg Train Loss: 3.5039\n",
      "Epoch [818/2000], Avg Val Loss: 2.0167\n",
      "Validation loss improved from 2.0171 to 2.0167. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4967\n",
      "Epoch [819/2000], Avg Train Loss: 3.4967\n",
      "Epoch [819/2000], Avg Val Loss: 2.0164\n",
      "Validation loss improved from 2.0167 to 2.0164. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5008\n",
      "Epoch [820/2000], Avg Train Loss: 3.5008\n",
      "Epoch [820/2000], Avg Val Loss: 2.0160\n",
      "Validation loss improved from 2.0164 to 2.0160. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5178\n",
      "Epoch [821/2000], Avg Train Loss: 3.5178\n",
      "Epoch [821/2000], Avg Val Loss: 2.0156\n",
      "Validation loss improved from 2.0160 to 2.0156. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5094\n",
      "Epoch [822/2000], Avg Train Loss: 3.5094\n",
      "Epoch [822/2000], Avg Val Loss: 2.0152\n",
      "Validation loss improved from 2.0156 to 2.0152. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5197\n",
      "Epoch [823/2000], Avg Train Loss: 3.5197\n",
      "Epoch [823/2000], Avg Val Loss: 2.0148\n",
      "Validation loss improved from 2.0152 to 2.0148. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4967\n",
      "Epoch [824/2000], Avg Train Loss: 3.4967\n",
      "Epoch [824/2000], Avg Val Loss: 2.0144\n",
      "Validation loss improved from 2.0148 to 2.0144. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4869\n",
      "Epoch [825/2000], Avg Train Loss: 3.4869\n",
      "Epoch [825/2000], Avg Val Loss: 2.0140\n",
      "Validation loss improved from 2.0144 to 2.0140. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4742\n",
      "Epoch [826/2000], Avg Train Loss: 3.4742\n",
      "Epoch [826/2000], Avg Val Loss: 2.0137\n",
      "Validation loss improved from 2.0140 to 2.0137. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5097\n",
      "Epoch [827/2000], Avg Train Loss: 3.5097\n",
      "Epoch [827/2000], Avg Val Loss: 2.0134\n",
      "Validation loss improved from 2.0137 to 2.0134. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5130\n",
      "Epoch [828/2000], Avg Train Loss: 3.5130\n",
      "Epoch [828/2000], Avg Val Loss: 2.0130\n",
      "Validation loss improved from 2.0134 to 2.0130. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5094\n",
      "Epoch [829/2000], Avg Train Loss: 3.5094\n",
      "Epoch [829/2000], Avg Val Loss: 2.0126\n",
      "Validation loss improved from 2.0130 to 2.0126. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5204\n",
      "Epoch [830/2000], Avg Train Loss: 3.5204\n",
      "Epoch [830/2000], Avg Val Loss: 2.0122\n",
      "Validation loss improved from 2.0126 to 2.0122. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4944\n",
      "Epoch [831/2000], Avg Train Loss: 3.4944\n",
      "Epoch [831/2000], Avg Val Loss: 2.0118\n",
      "Validation loss improved from 2.0122 to 2.0118. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4883\n",
      "Epoch [832/2000], Avg Train Loss: 3.4883\n",
      "Epoch [832/2000], Avg Val Loss: 2.0114\n",
      "Validation loss improved from 2.0118 to 2.0114. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5009\n",
      "Epoch [833/2000], Avg Train Loss: 3.5009\n",
      "Epoch [833/2000], Avg Val Loss: 2.0110\n",
      "Validation loss improved from 2.0114 to 2.0110. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5003\n",
      "Epoch [834/2000], Avg Train Loss: 3.5003\n",
      "Epoch [834/2000], Avg Val Loss: 2.0105\n",
      "Validation loss improved from 2.0110 to 2.0105. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4695\n",
      "Epoch [835/2000], Avg Train Loss: 3.4695\n",
      "Epoch [835/2000], Avg Val Loss: 2.0100\n",
      "Validation loss improved from 2.0105 to 2.0100. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5017\n",
      "Epoch [836/2000], Avg Train Loss: 3.5017\n",
      "Epoch [836/2000], Avg Val Loss: 2.0096\n",
      "Validation loss improved from 2.0100 to 2.0096. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4718\n",
      "Epoch [837/2000], Avg Train Loss: 3.4718\n",
      "Epoch [837/2000], Avg Val Loss: 2.0091\n",
      "Validation loss improved from 2.0096 to 2.0091. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4791\n",
      "Epoch [838/2000], Avg Train Loss: 3.4791\n",
      "Epoch [838/2000], Avg Val Loss: 2.0087\n",
      "Validation loss improved from 2.0091 to 2.0087. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5107\n",
      "Epoch [839/2000], Avg Train Loss: 3.5107\n",
      "Epoch [839/2000], Avg Val Loss: 2.0083\n",
      "Validation loss improved from 2.0087 to 2.0083. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5034\n",
      "Epoch [840/2000], Avg Train Loss: 3.5034\n",
      "Epoch [840/2000], Avg Val Loss: 2.0079\n",
      "Validation loss improved from 2.0083 to 2.0079. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5105\n",
      "Epoch [841/2000], Avg Train Loss: 3.5105\n",
      "Epoch [841/2000], Avg Val Loss: 2.0076\n",
      "Validation loss improved from 2.0079 to 2.0076. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4381\n",
      "Epoch [842/2000], Avg Train Loss: 3.4381\n",
      "Epoch [842/2000], Avg Val Loss: 2.0072\n",
      "Validation loss improved from 2.0076 to 2.0072. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4643\n",
      "Epoch [843/2000], Avg Train Loss: 3.4643\n",
      "Epoch [843/2000], Avg Val Loss: 2.0068\n",
      "Validation loss improved from 2.0072 to 2.0068. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4889\n",
      "Epoch [844/2000], Avg Train Loss: 3.4889\n",
      "Epoch [844/2000], Avg Val Loss: 2.0064\n",
      "Validation loss improved from 2.0068 to 2.0064. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4776\n",
      "Epoch [845/2000], Avg Train Loss: 3.4776\n",
      "Epoch [845/2000], Avg Val Loss: 2.0060\n",
      "Validation loss improved from 2.0064 to 2.0060. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5047\n",
      "Epoch [846/2000], Avg Train Loss: 3.5047\n",
      "Epoch [846/2000], Avg Val Loss: 2.0057\n",
      "Validation loss improved from 2.0060 to 2.0057. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4647\n",
      "Epoch [847/2000], Avg Train Loss: 3.4647\n",
      "Epoch [847/2000], Avg Val Loss: 2.0053\n",
      "Validation loss improved from 2.0057 to 2.0053. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4888\n",
      "Epoch [848/2000], Avg Train Loss: 3.4888\n",
      "Epoch [848/2000], Avg Val Loss: 2.0050\n",
      "Validation loss improved from 2.0053 to 2.0050. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4590\n",
      "Epoch [849/2000], Avg Train Loss: 3.4590\n",
      "Epoch [849/2000], Avg Val Loss: 2.0046\n",
      "Validation loss improved from 2.0050 to 2.0046. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4656\n",
      "Epoch [850/2000], Avg Train Loss: 3.4656\n",
      "Epoch [850/2000], Avg Val Loss: 2.0043\n",
      "Validation loss improved from 2.0046 to 2.0043. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4927\n",
      "Epoch [851/2000], Avg Train Loss: 3.4927\n",
      "Epoch [851/2000], Avg Val Loss: 2.0040\n",
      "Validation loss improved from 2.0043 to 2.0040. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5219\n",
      "Epoch [852/2000], Avg Train Loss: 3.5219\n",
      "Epoch [852/2000], Avg Val Loss: 2.0037\n",
      "Validation loss improved from 2.0040 to 2.0037. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4775\n",
      "Epoch [853/2000], Avg Train Loss: 3.4775\n",
      "Epoch [853/2000], Avg Val Loss: 2.0035\n",
      "Validation loss improved from 2.0037 to 2.0035. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5134\n",
      "Epoch [854/2000], Avg Train Loss: 3.5134\n",
      "Epoch [854/2000], Avg Val Loss: 2.0032\n",
      "Validation loss improved from 2.0035 to 2.0032. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4719\n",
      "Epoch [855/2000], Avg Train Loss: 3.4719\n",
      "Epoch [855/2000], Avg Val Loss: 2.0029\n",
      "Validation loss improved from 2.0032 to 2.0029. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4795\n",
      "Epoch [856/2000], Avg Train Loss: 3.4795\n",
      "Epoch [856/2000], Avg Val Loss: 2.0027\n",
      "Validation loss improved from 2.0029 to 2.0027. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4629\n",
      "Epoch [857/2000], Avg Train Loss: 3.4629\n",
      "Epoch [857/2000], Avg Val Loss: 2.0024\n",
      "Validation loss improved from 2.0027 to 2.0024. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5022\n",
      "Epoch [858/2000], Avg Train Loss: 3.5022\n",
      "Epoch [858/2000], Avg Val Loss: 2.0020\n",
      "Validation loss improved from 2.0024 to 2.0020. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4599\n",
      "Epoch [859/2000], Avg Train Loss: 3.4599\n",
      "Epoch [859/2000], Avg Val Loss: 2.0016\n",
      "Validation loss improved from 2.0020 to 2.0016. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4824\n",
      "Epoch [860/2000], Avg Train Loss: 3.4824\n",
      "Epoch [860/2000], Avg Val Loss: 2.0012\n",
      "Validation loss improved from 2.0016 to 2.0012. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4644\n",
      "Epoch [861/2000], Avg Train Loss: 3.4644\n",
      "Epoch [861/2000], Avg Val Loss: 2.0008\n",
      "Validation loss improved from 2.0012 to 2.0008. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4707\n",
      "Epoch [862/2000], Avg Train Loss: 3.4707\n",
      "Epoch [862/2000], Avg Val Loss: 2.0003\n",
      "Validation loss improved from 2.0008 to 2.0003. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4834\n",
      "Epoch [863/2000], Avg Train Loss: 3.4834\n",
      "Epoch [863/2000], Avg Val Loss: 1.9999\n",
      "Validation loss improved from 2.0003 to 1.9999. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4477\n",
      "Epoch [864/2000], Avg Train Loss: 3.4477\n",
      "Epoch [864/2000], Avg Val Loss: 1.9995\n",
      "Validation loss improved from 1.9999 to 1.9995. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4736\n",
      "Epoch [865/2000], Avg Train Loss: 3.4736\n",
      "Epoch [865/2000], Avg Val Loss: 1.9990\n",
      "Validation loss improved from 1.9995 to 1.9990. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4722\n",
      "Epoch [866/2000], Avg Train Loss: 3.4722\n",
      "Epoch [866/2000], Avg Val Loss: 1.9986\n",
      "Validation loss improved from 1.9990 to 1.9986. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4877\n",
      "Epoch [867/2000], Avg Train Loss: 3.4877\n",
      "Epoch [867/2000], Avg Val Loss: 1.9981\n",
      "Validation loss improved from 1.9986 to 1.9981. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4391\n",
      "Epoch [868/2000], Avg Train Loss: 3.4391\n",
      "Epoch [868/2000], Avg Val Loss: 1.9977\n",
      "Validation loss improved from 1.9981 to 1.9977. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4798\n",
      "Epoch [869/2000], Avg Train Loss: 3.4798\n",
      "Epoch [869/2000], Avg Val Loss: 1.9973\n",
      "Validation loss improved from 1.9977 to 1.9973. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4656\n",
      "Epoch [870/2000], Avg Train Loss: 3.4656\n",
      "Epoch [870/2000], Avg Val Loss: 1.9969\n",
      "Validation loss improved from 1.9973 to 1.9969. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4783\n",
      "Epoch [871/2000], Avg Train Loss: 3.4783\n",
      "Epoch [871/2000], Avg Val Loss: 1.9964\n",
      "Validation loss improved from 1.9969 to 1.9964. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4837\n",
      "Epoch [872/2000], Avg Train Loss: 3.4837\n",
      "Epoch [872/2000], Avg Val Loss: 1.9961\n",
      "Validation loss improved from 1.9964 to 1.9961. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4623\n",
      "Epoch [873/2000], Avg Train Loss: 3.4623\n",
      "Epoch [873/2000], Avg Val Loss: 1.9957\n",
      "Validation loss improved from 1.9961 to 1.9957. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4705\n",
      "Epoch [874/2000], Avg Train Loss: 3.4705\n",
      "Epoch [874/2000], Avg Val Loss: 1.9953\n",
      "Validation loss improved from 1.9957 to 1.9953. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4686\n",
      "Epoch [875/2000], Avg Train Loss: 3.4686\n",
      "Epoch [875/2000], Avg Val Loss: 1.9950\n",
      "Validation loss improved from 1.9953 to 1.9950. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4526\n",
      "Epoch [876/2000], Avg Train Loss: 3.4526\n",
      "Epoch [876/2000], Avg Val Loss: 1.9947\n",
      "Validation loss improved from 1.9950 to 1.9947. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5003\n",
      "Epoch [877/2000], Avg Train Loss: 3.5003\n",
      "Epoch [877/2000], Avg Val Loss: 1.9945\n",
      "Validation loss improved from 1.9947 to 1.9945. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4714\n",
      "Epoch [878/2000], Avg Train Loss: 3.4714\n",
      "Epoch [878/2000], Avg Val Loss: 1.9942\n",
      "Validation loss improved from 1.9945 to 1.9942. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4739\n",
      "Epoch [879/2000], Avg Train Loss: 3.4739\n",
      "Epoch [879/2000], Avg Val Loss: 1.9940\n",
      "Validation loss improved from 1.9942 to 1.9940. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4726\n",
      "Epoch [880/2000], Avg Train Loss: 3.4726\n",
      "Epoch [880/2000], Avg Val Loss: 1.9937\n",
      "Validation loss improved from 1.9940 to 1.9937. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4605\n",
      "Epoch [881/2000], Avg Train Loss: 3.4605\n",
      "Epoch [881/2000], Avg Val Loss: 1.9934\n",
      "Validation loss improved from 1.9937 to 1.9934. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4853\n",
      "Epoch [882/2000], Avg Train Loss: 3.4853\n",
      "Epoch [882/2000], Avg Val Loss: 1.9931\n",
      "Validation loss improved from 1.9934 to 1.9931. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4560\n",
      "Epoch [883/2000], Avg Train Loss: 3.4560\n",
      "Epoch [883/2000], Avg Val Loss: 1.9927\n",
      "Validation loss improved from 1.9931 to 1.9927. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4969\n",
      "Epoch [884/2000], Avg Train Loss: 3.4969\n",
      "Epoch [884/2000], Avg Val Loss: 1.9923\n",
      "Validation loss improved from 1.9927 to 1.9923. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4607\n",
      "Epoch [885/2000], Avg Train Loss: 3.4607\n",
      "Epoch [885/2000], Avg Val Loss: 1.9920\n",
      "Validation loss improved from 1.9923 to 1.9920. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4471\n",
      "Epoch [886/2000], Avg Train Loss: 3.4471\n",
      "Epoch [886/2000], Avg Val Loss: 1.9916\n",
      "Validation loss improved from 1.9920 to 1.9916. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4572\n",
      "Epoch [887/2000], Avg Train Loss: 3.4572\n",
      "Epoch [887/2000], Avg Val Loss: 1.9912\n",
      "Validation loss improved from 1.9916 to 1.9912. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4861\n",
      "Epoch [888/2000], Avg Train Loss: 3.4861\n",
      "Epoch [888/2000], Avg Val Loss: 1.9908\n",
      "Validation loss improved from 1.9912 to 1.9908. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5215\n",
      "Epoch [889/2000], Avg Train Loss: 3.5215\n",
      "Epoch [889/2000], Avg Val Loss: 1.9904\n",
      "Validation loss improved from 1.9908 to 1.9904. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4904\n",
      "Epoch [890/2000], Avg Train Loss: 3.4904\n",
      "Epoch [890/2000], Avg Val Loss: 1.9900\n",
      "Validation loss improved from 1.9904 to 1.9900. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4677\n",
      "Epoch [891/2000], Avg Train Loss: 3.4677\n",
      "Epoch [891/2000], Avg Val Loss: 1.9896\n",
      "Validation loss improved from 1.9900 to 1.9896. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4855\n",
      "Epoch [892/2000], Avg Train Loss: 3.4855\n",
      "Epoch [892/2000], Avg Val Loss: 1.9892\n",
      "Validation loss improved from 1.9896 to 1.9892. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4520\n",
      "Epoch [893/2000], Avg Train Loss: 3.4520\n",
      "Epoch [893/2000], Avg Val Loss: 1.9888\n",
      "Validation loss improved from 1.9892 to 1.9888. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4496\n",
      "Epoch [894/2000], Avg Train Loss: 3.4496\n",
      "Epoch [894/2000], Avg Val Loss: 1.9885\n",
      "Validation loss improved from 1.9888 to 1.9885. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4754\n",
      "Epoch [895/2000], Avg Train Loss: 3.4754\n",
      "Epoch [895/2000], Avg Val Loss: 1.9881\n",
      "Validation loss improved from 1.9885 to 1.9881. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4146\n",
      "Epoch [896/2000], Avg Train Loss: 3.4146\n",
      "Epoch [896/2000], Avg Val Loss: 1.9877\n",
      "Validation loss improved from 1.9881 to 1.9877. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4560\n",
      "Epoch [897/2000], Avg Train Loss: 3.4560\n",
      "Epoch [897/2000], Avg Val Loss: 1.9873\n",
      "Validation loss improved from 1.9877 to 1.9873. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4641\n",
      "Epoch [898/2000], Avg Train Loss: 3.4641\n",
      "Epoch [898/2000], Avg Val Loss: 1.9869\n",
      "Validation loss improved from 1.9873 to 1.9869. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4525\n",
      "Epoch [899/2000], Avg Train Loss: 3.4525\n",
      "Epoch [899/2000], Avg Val Loss: 1.9864\n",
      "Validation loss improved from 1.9869 to 1.9864. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4776\n",
      "Epoch [900/2000], Avg Train Loss: 3.4776\n",
      "Epoch [900/2000], Avg Val Loss: 1.9860\n",
      "Validation loss improved from 1.9864 to 1.9860. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4754\n",
      "Epoch [901/2000], Avg Train Loss: 3.4754\n",
      "Epoch [901/2000], Avg Val Loss: 1.9857\n",
      "Validation loss improved from 1.9860 to 1.9857. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4655\n",
      "Epoch [902/2000], Avg Train Loss: 3.4655\n",
      "Epoch [902/2000], Avg Val Loss: 1.9853\n",
      "Validation loss improved from 1.9857 to 1.9853. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5055\n",
      "Epoch [903/2000], Avg Train Loss: 3.5055\n",
      "Epoch [903/2000], Avg Val Loss: 1.9850\n",
      "Validation loss improved from 1.9853 to 1.9850. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4810\n",
      "Epoch [904/2000], Avg Train Loss: 3.4810\n",
      "Epoch [904/2000], Avg Val Loss: 1.9847\n",
      "Validation loss improved from 1.9850 to 1.9847. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4288\n",
      "Epoch [905/2000], Avg Train Loss: 3.4288\n",
      "Epoch [905/2000], Avg Val Loss: 1.9843\n",
      "Validation loss improved from 1.9847 to 1.9843. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4712\n",
      "Epoch [906/2000], Avg Train Loss: 3.4712\n",
      "Epoch [906/2000], Avg Val Loss: 1.9840\n",
      "Validation loss improved from 1.9843 to 1.9840. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4599\n",
      "Epoch [907/2000], Avg Train Loss: 3.4599\n",
      "Epoch [907/2000], Avg Val Loss: 1.9836\n",
      "Validation loss improved from 1.9840 to 1.9836. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4724\n",
      "Epoch [908/2000], Avg Train Loss: 3.4724\n",
      "Epoch [908/2000], Avg Val Loss: 1.9832\n",
      "Validation loss improved from 1.9836 to 1.9832. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4612\n",
      "Epoch [909/2000], Avg Train Loss: 3.4612\n",
      "Epoch [909/2000], Avg Val Loss: 1.9828\n",
      "Validation loss improved from 1.9832 to 1.9828. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4657\n",
      "Epoch [910/2000], Avg Train Loss: 3.4657\n",
      "Epoch [910/2000], Avg Val Loss: 1.9824\n",
      "Validation loss improved from 1.9828 to 1.9824. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4354\n",
      "Epoch [911/2000], Avg Train Loss: 3.4354\n",
      "Epoch [911/2000], Avg Val Loss: 1.9819\n",
      "Validation loss improved from 1.9824 to 1.9819. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4715\n",
      "Epoch [912/2000], Avg Train Loss: 3.4715\n",
      "Epoch [912/2000], Avg Val Loss: 1.9815\n",
      "Validation loss improved from 1.9819 to 1.9815. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4657\n",
      "Epoch [913/2000], Avg Train Loss: 3.4657\n",
      "Epoch [913/2000], Avg Val Loss: 1.9812\n",
      "Validation loss improved from 1.9815 to 1.9812. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4461\n",
      "Epoch [914/2000], Avg Train Loss: 3.4461\n",
      "Epoch [914/2000], Avg Val Loss: 1.9808\n",
      "Validation loss improved from 1.9812 to 1.9808. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4570\n",
      "Epoch [915/2000], Avg Train Loss: 3.4570\n",
      "Epoch [915/2000], Avg Val Loss: 1.9804\n",
      "Validation loss improved from 1.9808 to 1.9804. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4334\n",
      "Epoch [916/2000], Avg Train Loss: 3.4334\n",
      "Epoch [916/2000], Avg Val Loss: 1.9800\n",
      "Validation loss improved from 1.9804 to 1.9800. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4473\n",
      "Epoch [917/2000], Avg Train Loss: 3.4473\n",
      "Epoch [917/2000], Avg Val Loss: 1.9795\n",
      "Validation loss improved from 1.9800 to 1.9795. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4656\n",
      "Epoch [918/2000], Avg Train Loss: 3.4656\n",
      "Epoch [918/2000], Avg Val Loss: 1.9791\n",
      "Validation loss improved from 1.9795 to 1.9791. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4622\n",
      "Epoch [919/2000], Avg Train Loss: 3.4622\n",
      "Epoch [919/2000], Avg Val Loss: 1.9788\n",
      "Validation loss improved from 1.9791 to 1.9788. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4303\n",
      "Epoch [920/2000], Avg Train Loss: 3.4303\n",
      "Epoch [920/2000], Avg Val Loss: 1.9784\n",
      "Validation loss improved from 1.9788 to 1.9784. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4562\n",
      "Epoch [921/2000], Avg Train Loss: 3.4562\n",
      "Epoch [921/2000], Avg Val Loss: 1.9781\n",
      "Validation loss improved from 1.9784 to 1.9781. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4158\n",
      "Epoch [922/2000], Avg Train Loss: 3.4158\n",
      "Epoch [922/2000], Avg Val Loss: 1.9778\n",
      "Validation loss improved from 1.9781 to 1.9778. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4720\n",
      "Epoch [923/2000], Avg Train Loss: 3.4720\n",
      "Epoch [923/2000], Avg Val Loss: 1.9775\n",
      "Validation loss improved from 1.9778 to 1.9775. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4548\n",
      "Epoch [924/2000], Avg Train Loss: 3.4548\n",
      "Epoch [924/2000], Avg Val Loss: 1.9772\n",
      "Validation loss improved from 1.9775 to 1.9772. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4856\n",
      "Epoch [925/2000], Avg Train Loss: 3.4856\n",
      "Epoch [925/2000], Avg Val Loss: 1.9769\n",
      "Validation loss improved from 1.9772 to 1.9769. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4369\n",
      "Epoch [926/2000], Avg Train Loss: 3.4369\n",
      "Epoch [926/2000], Avg Val Loss: 1.9766\n",
      "Validation loss improved from 1.9769 to 1.9766. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4712\n",
      "Epoch [927/2000], Avg Train Loss: 3.4712\n",
      "Epoch [927/2000], Avg Val Loss: 1.9764\n",
      "Validation loss improved from 1.9766 to 1.9764. Saving model...\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4666\n",
      "Epoch [928/2000], Avg Train Loss: 3.4666\n",
      "Epoch [928/2000], Avg Val Loss: 1.9761\n",
      "Validation loss improved from 1.9764 to 1.9761. Saving model...\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4281\n",
      "Epoch [929/2000], Avg Train Loss: 3.4281\n",
      "Epoch [929/2000], Avg Val Loss: 1.9757\n",
      "Validation loss improved from 1.9761 to 1.9757. Saving model...\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4273\n",
      "Epoch [930/2000], Avg Train Loss: 3.4273\n",
      "Epoch [930/2000], Avg Val Loss: 1.9754\n",
      "Validation loss improved from 1.9757 to 1.9754. Saving model...\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4493\n",
      "Epoch [931/2000], Avg Train Loss: 3.4493\n",
      "Epoch [931/2000], Avg Val Loss: 1.9750\n",
      "Validation loss improved from 1.9754 to 1.9750. Saving model...\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4369\n",
      "Epoch [932/2000], Avg Train Loss: 3.4369\n",
      "Epoch [932/2000], Avg Val Loss: 1.9747\n",
      "Validation loss improved from 1.9750 to 1.9747. Saving model...\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4687\n",
      "Epoch [933/2000], Avg Train Loss: 3.4687\n",
      "Epoch [933/2000], Avg Val Loss: 1.9743\n",
      "Validation loss improved from 1.9747 to 1.9743. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4150\n",
      "Epoch [934/2000], Avg Train Loss: 3.4150\n",
      "Epoch [934/2000], Avg Val Loss: 1.9739\n",
      "Validation loss improved from 1.9743 to 1.9739. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4372\n",
      "Epoch [935/2000], Avg Train Loss: 3.4372\n",
      "Epoch [935/2000], Avg Val Loss: 1.9735\n",
      "Validation loss improved from 1.9739 to 1.9735. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4772\n",
      "Epoch [936/2000], Avg Train Loss: 3.4772\n",
      "Epoch [936/2000], Avg Val Loss: 1.9731\n",
      "Validation loss improved from 1.9735 to 1.9731. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3954\n",
      "Epoch [937/2000], Avg Train Loss: 3.3954\n",
      "Epoch [937/2000], Avg Val Loss: 1.9726\n",
      "Validation loss improved from 1.9731 to 1.9726. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4716\n",
      "Epoch [938/2000], Avg Train Loss: 3.4716\n",
      "Epoch [938/2000], Avg Val Loss: 1.9722\n",
      "Validation loss improved from 1.9726 to 1.9722. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4653\n",
      "Epoch [939/2000], Avg Train Loss: 3.4653\n",
      "Epoch [939/2000], Avg Val Loss: 1.9719\n",
      "Validation loss improved from 1.9722 to 1.9719. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4362\n",
      "Epoch [940/2000], Avg Train Loss: 3.4362\n",
      "Epoch [940/2000], Avg Val Loss: 1.9715\n",
      "Validation loss improved from 1.9719 to 1.9715. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4249\n",
      "Epoch [941/2000], Avg Train Loss: 3.4249\n",
      "Epoch [941/2000], Avg Val Loss: 1.9712\n",
      "Validation loss improved from 1.9715 to 1.9712. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4481\n",
      "Epoch [942/2000], Avg Train Loss: 3.4481\n",
      "Epoch [942/2000], Avg Val Loss: 1.9709\n",
      "Validation loss improved from 1.9712 to 1.9709. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4466\n",
      "Epoch [943/2000], Avg Train Loss: 3.4466\n",
      "Epoch [943/2000], Avg Val Loss: 1.9705\n",
      "Validation loss improved from 1.9709 to 1.9705. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4596\n",
      "Epoch [944/2000], Avg Train Loss: 3.4596\n",
      "Epoch [944/2000], Avg Val Loss: 1.9702\n",
      "Validation loss improved from 1.9705 to 1.9702. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4433\n",
      "Epoch [945/2000], Avg Train Loss: 3.4433\n",
      "Epoch [945/2000], Avg Val Loss: 1.9698\n",
      "Validation loss improved from 1.9702 to 1.9698. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4453\n",
      "Epoch [946/2000], Avg Train Loss: 3.4453\n",
      "Epoch [946/2000], Avg Val Loss: 1.9695\n",
      "Validation loss improved from 1.9698 to 1.9695. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4331\n",
      "Epoch [947/2000], Avg Train Loss: 3.4331\n",
      "Epoch [947/2000], Avg Val Loss: 1.9692\n",
      "Validation loss improved from 1.9695 to 1.9692. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4662\n",
      "Epoch [948/2000], Avg Train Loss: 3.4662\n",
      "Epoch [948/2000], Avg Val Loss: 1.9689\n",
      "Validation loss improved from 1.9692 to 1.9689. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4564\n",
      "Epoch [949/2000], Avg Train Loss: 3.4564\n",
      "Epoch [949/2000], Avg Val Loss: 1.9686\n",
      "Validation loss improved from 1.9689 to 1.9686. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4907\n",
      "Epoch [950/2000], Avg Train Loss: 3.4907\n",
      "Epoch [950/2000], Avg Val Loss: 1.9682\n",
      "Validation loss improved from 1.9686 to 1.9682. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4477\n",
      "Epoch [951/2000], Avg Train Loss: 3.4477\n",
      "Epoch [951/2000], Avg Val Loss: 1.9679\n",
      "Validation loss improved from 1.9682 to 1.9679. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4465\n",
      "Epoch [952/2000], Avg Train Loss: 3.4465\n",
      "Epoch [952/2000], Avg Val Loss: 1.9676\n",
      "Validation loss improved from 1.9679 to 1.9676. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4410\n",
      "Epoch [953/2000], Avg Train Loss: 3.4410\n",
      "Epoch [953/2000], Avg Val Loss: 1.9673\n",
      "Validation loss improved from 1.9676 to 1.9673. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4417\n",
      "Epoch [954/2000], Avg Train Loss: 3.4417\n",
      "Epoch [954/2000], Avg Val Loss: 1.9670\n",
      "Validation loss improved from 1.9673 to 1.9670. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4305\n",
      "Epoch [955/2000], Avg Train Loss: 3.4305\n",
      "Epoch [955/2000], Avg Val Loss: 1.9667\n",
      "Validation loss improved from 1.9670 to 1.9667. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4445\n",
      "Epoch [956/2000], Avg Train Loss: 3.4445\n",
      "Epoch [956/2000], Avg Val Loss: 1.9664\n",
      "Validation loss improved from 1.9667 to 1.9664. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4571\n",
      "Epoch [957/2000], Avg Train Loss: 3.4571\n",
      "Epoch [957/2000], Avg Val Loss: 1.9660\n",
      "Validation loss improved from 1.9664 to 1.9660. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4805\n",
      "Epoch [958/2000], Avg Train Loss: 3.4805\n",
      "Epoch [958/2000], Avg Val Loss: 1.9657\n",
      "Validation loss improved from 1.9660 to 1.9657. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4362\n",
      "Epoch [959/2000], Avg Train Loss: 3.4362\n",
      "Epoch [959/2000], Avg Val Loss: 1.9653\n",
      "Validation loss improved from 1.9657 to 1.9653. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4886\n",
      "Epoch [960/2000], Avg Train Loss: 3.4886\n",
      "Epoch [960/2000], Avg Val Loss: 1.9650\n",
      "Validation loss improved from 1.9653 to 1.9650. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4563\n",
      "Epoch [961/2000], Avg Train Loss: 3.4563\n",
      "Epoch [961/2000], Avg Val Loss: 1.9646\n",
      "Validation loss improved from 1.9650 to 1.9646. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4106\n",
      "Epoch [962/2000], Avg Train Loss: 3.4106\n",
      "Epoch [962/2000], Avg Val Loss: 1.9643\n",
      "Validation loss improved from 1.9646 to 1.9643. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4477\n",
      "Epoch [963/2000], Avg Train Loss: 3.4477\n",
      "Epoch [963/2000], Avg Val Loss: 1.9640\n",
      "Validation loss improved from 1.9643 to 1.9640. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4314\n",
      "Epoch [964/2000], Avg Train Loss: 3.4314\n",
      "Epoch [964/2000], Avg Val Loss: 1.9636\n",
      "Validation loss improved from 1.9640 to 1.9636. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4797\n",
      "Epoch [965/2000], Avg Train Loss: 3.4797\n",
      "Epoch [965/2000], Avg Val Loss: 1.9634\n",
      "Validation loss improved from 1.9636 to 1.9634. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4241\n",
      "Epoch [966/2000], Avg Train Loss: 3.4241\n",
      "Epoch [966/2000], Avg Val Loss: 1.9631\n",
      "Validation loss improved from 1.9634 to 1.9631. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4394\n",
      "Epoch [967/2000], Avg Train Loss: 3.4394\n",
      "Epoch [967/2000], Avg Val Loss: 1.9628\n",
      "Validation loss improved from 1.9631 to 1.9628. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4584\n",
      "Epoch [968/2000], Avg Train Loss: 3.4584\n",
      "Epoch [968/2000], Avg Val Loss: 1.9626\n",
      "Validation loss improved from 1.9628 to 1.9626. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4434\n",
      "Epoch [969/2000], Avg Train Loss: 3.4434\n",
      "Epoch [969/2000], Avg Val Loss: 1.9623\n",
      "Validation loss improved from 1.9626 to 1.9623. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4113\n",
      "Epoch [970/2000], Avg Train Loss: 3.4113\n",
      "Epoch [970/2000], Avg Val Loss: 1.9620\n",
      "Validation loss improved from 1.9623 to 1.9620. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4066\n",
      "Epoch [971/2000], Avg Train Loss: 3.4066\n",
      "Epoch [971/2000], Avg Val Loss: 1.9618\n",
      "Validation loss improved from 1.9620 to 1.9618. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4490\n",
      "Epoch [972/2000], Avg Train Loss: 3.4490\n",
      "Epoch [972/2000], Avg Val Loss: 1.9615\n",
      "Validation loss improved from 1.9618 to 1.9615. Saving model...\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4626\n",
      "Epoch [973/2000], Avg Train Loss: 3.4626\n",
      "Epoch [973/2000], Avg Val Loss: 1.9612\n",
      "Validation loss improved from 1.9615 to 1.9612. Saving model...\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4371\n",
      "Epoch [974/2000], Avg Train Loss: 3.4371\n",
      "Epoch [974/2000], Avg Val Loss: 1.9609\n",
      "Validation loss improved from 1.9612 to 1.9609. Saving model...\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4249\n",
      "Epoch [975/2000], Avg Train Loss: 3.4249\n",
      "Epoch [975/2000], Avg Val Loss: 1.9607\n",
      "Validation loss improved from 1.9609 to 1.9607. Saving model...\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4390\n",
      "Epoch [976/2000], Avg Train Loss: 3.4390\n",
      "Epoch [976/2000], Avg Val Loss: 1.9604\n",
      "Validation loss improved from 1.9607 to 1.9604. Saving model...\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4509\n",
      "Epoch [977/2000], Avg Train Loss: 3.4509\n",
      "Epoch [977/2000], Avg Val Loss: 1.9602\n",
      "Validation loss improved from 1.9604 to 1.9602. Saving model...\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4608\n",
      "Epoch [978/2000], Avg Train Loss: 3.4608\n",
      "Epoch [978/2000], Avg Val Loss: 1.9600\n",
      "Validation loss improved from 1.9602 to 1.9600. Saving model...\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4249\n",
      "Epoch [979/2000], Avg Train Loss: 3.4249\n",
      "Epoch [979/2000], Avg Val Loss: 1.9598\n",
      "Validation loss improved from 1.9600 to 1.9598. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3996\n",
      "Epoch [980/2000], Avg Train Loss: 3.3996\n",
      "Epoch [980/2000], Avg Val Loss: 1.9595\n",
      "Validation loss improved from 1.9598 to 1.9595. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4369\n",
      "Epoch [981/2000], Avg Train Loss: 3.4369\n",
      "Epoch [981/2000], Avg Val Loss: 1.9593\n",
      "Validation loss improved from 1.9595 to 1.9593. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4184\n",
      "Epoch [982/2000], Avg Train Loss: 3.4184\n",
      "Epoch [982/2000], Avg Val Loss: 1.9591\n",
      "Validation loss improved from 1.9593 to 1.9591. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4411\n",
      "Epoch [983/2000], Avg Train Loss: 3.4411\n",
      "Epoch [983/2000], Avg Val Loss: 1.9589\n",
      "Validation loss improved from 1.9591 to 1.9589. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4247\n",
      "Epoch [984/2000], Avg Train Loss: 3.4247\n",
      "Epoch [984/2000], Avg Val Loss: 1.9586\n",
      "Validation loss improved from 1.9589 to 1.9586. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4501\n",
      "Epoch [985/2000], Avg Train Loss: 3.4501\n",
      "Epoch [985/2000], Avg Val Loss: 1.9584\n",
      "Validation loss improved from 1.9586 to 1.9584. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4003\n",
      "Epoch [986/2000], Avg Train Loss: 3.4003\n",
      "Epoch [986/2000], Avg Val Loss: 1.9581\n",
      "Validation loss improved from 1.9584 to 1.9581. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4939\n",
      "Epoch [987/2000], Avg Train Loss: 3.4939\n",
      "Epoch [987/2000], Avg Val Loss: 1.9579\n",
      "Validation loss improved from 1.9581 to 1.9579. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4418\n",
      "Epoch [988/2000], Avg Train Loss: 3.4418\n",
      "Epoch [988/2000], Avg Val Loss: 1.9577\n",
      "Validation loss improved from 1.9579 to 1.9577. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4169\n",
      "Epoch [989/2000], Avg Train Loss: 3.4169\n",
      "Epoch [989/2000], Avg Val Loss: 1.9575\n",
      "Validation loss improved from 1.9577 to 1.9575. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4287\n",
      "Epoch [990/2000], Avg Train Loss: 3.4287\n",
      "Epoch [990/2000], Avg Val Loss: 1.9572\n",
      "Validation loss improved from 1.9575 to 1.9572. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4502\n",
      "Epoch [991/2000], Avg Train Loss: 3.4502\n",
      "Epoch [991/2000], Avg Val Loss: 1.9570\n",
      "Validation loss improved from 1.9572 to 1.9570. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4198\n",
      "Epoch [992/2000], Avg Train Loss: 3.4198\n",
      "Epoch [992/2000], Avg Val Loss: 1.9568\n",
      "Validation loss improved from 1.9570 to 1.9568. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4133\n",
      "Epoch [993/2000], Avg Train Loss: 3.4133\n",
      "Epoch [993/2000], Avg Val Loss: 1.9565\n",
      "Validation loss improved from 1.9568 to 1.9565. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4274\n",
      "Epoch [994/2000], Avg Train Loss: 3.4274\n",
      "Epoch [994/2000], Avg Val Loss: 1.9562\n",
      "Validation loss improved from 1.9565 to 1.9562. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4292\n",
      "Epoch [995/2000], Avg Train Loss: 3.4292\n",
      "Epoch [995/2000], Avg Val Loss: 1.9560\n",
      "Validation loss improved from 1.9562 to 1.9560. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4334\n",
      "Epoch [996/2000], Avg Train Loss: 3.4334\n",
      "Epoch [996/2000], Avg Val Loss: 1.9557\n",
      "Validation loss improved from 1.9560 to 1.9557. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4605\n",
      "Epoch [997/2000], Avg Train Loss: 3.4605\n",
      "Epoch [997/2000], Avg Val Loss: 1.9555\n",
      "Validation loss improved from 1.9557 to 1.9555. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4099\n",
      "Epoch [998/2000], Avg Train Loss: 3.4099\n",
      "Epoch [998/2000], Avg Val Loss: 1.9552\n",
      "Validation loss improved from 1.9555 to 1.9552. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4171\n",
      "Epoch [999/2000], Avg Train Loss: 3.4171\n",
      "Epoch [999/2000], Avg Val Loss: 1.9549\n",
      "Validation loss improved from 1.9552 to 1.9549. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3596\n",
      "Epoch [1000/2000], Avg Train Loss: 3.3596\n",
      "Epoch [1000/2000], Avg Val Loss: 1.9547\n",
      "Validation loss improved from 1.9549 to 1.9547. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4460\n",
      "Epoch [1001/2000], Avg Train Loss: 3.4460\n",
      "Epoch [1001/2000], Avg Val Loss: 1.9544\n",
      "Validation loss improved from 1.9547 to 1.9544. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4188\n",
      "Epoch [1002/2000], Avg Train Loss: 3.4188\n",
      "Epoch [1002/2000], Avg Val Loss: 1.9541\n",
      "Validation loss improved from 1.9544 to 1.9541. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3943\n",
      "Epoch [1003/2000], Avg Train Loss: 3.3943\n",
      "Epoch [1003/2000], Avg Val Loss: 1.9538\n",
      "Validation loss improved from 1.9541 to 1.9538. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4579\n",
      "Epoch [1004/2000], Avg Train Loss: 3.4579\n",
      "Epoch [1004/2000], Avg Val Loss: 1.9535\n",
      "Validation loss improved from 1.9538 to 1.9535. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4623\n",
      "Epoch [1005/2000], Avg Train Loss: 3.4623\n",
      "Epoch [1005/2000], Avg Val Loss: 1.9532\n",
      "Validation loss improved from 1.9535 to 1.9532. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4027\n",
      "Epoch [1006/2000], Avg Train Loss: 3.4027\n",
      "Epoch [1006/2000], Avg Val Loss: 1.9529\n",
      "Validation loss improved from 1.9532 to 1.9529. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4320\n",
      "Epoch [1007/2000], Avg Train Loss: 3.4320\n",
      "Epoch [1007/2000], Avg Val Loss: 1.9527\n",
      "Validation loss improved from 1.9529 to 1.9527. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4075\n",
      "Epoch [1008/2000], Avg Train Loss: 3.4075\n",
      "Epoch [1008/2000], Avg Val Loss: 1.9524\n",
      "Validation loss improved from 1.9527 to 1.9524. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3870\n",
      "Epoch [1009/2000], Avg Train Loss: 3.3870\n",
      "Epoch [1009/2000], Avg Val Loss: 1.9521\n",
      "Validation loss improved from 1.9524 to 1.9521. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3761\n",
      "Epoch [1010/2000], Avg Train Loss: 3.3761\n",
      "Epoch [1010/2000], Avg Val Loss: 1.9518\n",
      "Validation loss improved from 1.9521 to 1.9518. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4497\n",
      "Epoch [1011/2000], Avg Train Loss: 3.4497\n",
      "Epoch [1011/2000], Avg Val Loss: 1.9515\n",
      "Validation loss improved from 1.9518 to 1.9515. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4503\n",
      "Epoch [1012/2000], Avg Train Loss: 3.4503\n",
      "Epoch [1012/2000], Avg Val Loss: 1.9511\n",
      "Validation loss improved from 1.9515 to 1.9511. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4486\n",
      "Epoch [1013/2000], Avg Train Loss: 3.4486\n",
      "Epoch [1013/2000], Avg Val Loss: 1.9508\n",
      "Validation loss improved from 1.9511 to 1.9508. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4143\n",
      "Epoch [1014/2000], Avg Train Loss: 3.4143\n",
      "Epoch [1014/2000], Avg Val Loss: 1.9505\n",
      "Validation loss improved from 1.9508 to 1.9505. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4086\n",
      "Epoch [1015/2000], Avg Train Loss: 3.4086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1015/2000], Avg Val Loss: 1.9502\n",
      "Validation loss improved from 1.9505 to 1.9502. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3969\n",
      "Epoch [1016/2000], Avg Train Loss: 3.3969\n",
      "Epoch [1016/2000], Avg Val Loss: 1.9499\n",
      "Validation loss improved from 1.9502 to 1.9499. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3713\n",
      "Epoch [1017/2000], Avg Train Loss: 3.3713\n",
      "Epoch [1017/2000], Avg Val Loss: 1.9496\n",
      "Validation loss improved from 1.9499 to 1.9496. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4037\n",
      "Epoch [1018/2000], Avg Train Loss: 3.4037\n",
      "Epoch [1018/2000], Avg Val Loss: 1.9493\n",
      "Validation loss improved from 1.9496 to 1.9493. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4004\n",
      "Epoch [1019/2000], Avg Train Loss: 3.4004\n",
      "Epoch [1019/2000], Avg Val Loss: 1.9489\n",
      "Validation loss improved from 1.9493 to 1.9489. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4168\n",
      "Epoch [1020/2000], Avg Train Loss: 3.4168\n",
      "Epoch [1020/2000], Avg Val Loss: 1.9486\n",
      "Validation loss improved from 1.9489 to 1.9486. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4191\n",
      "Epoch [1021/2000], Avg Train Loss: 3.4191\n",
      "Epoch [1021/2000], Avg Val Loss: 1.9482\n",
      "Validation loss improved from 1.9486 to 1.9482. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4207\n",
      "Epoch [1022/2000], Avg Train Loss: 3.4207\n",
      "Epoch [1022/2000], Avg Val Loss: 1.9479\n",
      "Validation loss improved from 1.9482 to 1.9479. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4179\n",
      "Epoch [1023/2000], Avg Train Loss: 3.4179\n",
      "Epoch [1023/2000], Avg Val Loss: 1.9476\n",
      "Validation loss improved from 1.9479 to 1.9476. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4030\n",
      "Epoch [1024/2000], Avg Train Loss: 3.4030\n",
      "Epoch [1024/2000], Avg Val Loss: 1.9472\n",
      "Validation loss improved from 1.9476 to 1.9472. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4318\n",
      "Epoch [1025/2000], Avg Train Loss: 3.4318\n",
      "Epoch [1025/2000], Avg Val Loss: 1.9468\n",
      "Validation loss improved from 1.9472 to 1.9468. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4020\n",
      "Epoch [1026/2000], Avg Train Loss: 3.4020\n",
      "Epoch [1026/2000], Avg Val Loss: 1.9465\n",
      "Validation loss improved from 1.9468 to 1.9465. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4218\n",
      "Epoch [1027/2000], Avg Train Loss: 3.4218\n",
      "Epoch [1027/2000], Avg Val Loss: 1.9462\n",
      "Validation loss improved from 1.9465 to 1.9462. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3875\n",
      "Epoch [1028/2000], Avg Train Loss: 3.3875\n",
      "Epoch [1028/2000], Avg Val Loss: 1.9459\n",
      "Validation loss improved from 1.9462 to 1.9459. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4289\n",
      "Epoch [1029/2000], Avg Train Loss: 3.4289\n",
      "Epoch [1029/2000], Avg Val Loss: 1.9457\n",
      "Validation loss improved from 1.9459 to 1.9457. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4607\n",
      "Epoch [1030/2000], Avg Train Loss: 3.4607\n",
      "Epoch [1030/2000], Avg Val Loss: 1.9454\n",
      "Validation loss improved from 1.9457 to 1.9454. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4339\n",
      "Epoch [1031/2000], Avg Train Loss: 3.4339\n",
      "Epoch [1031/2000], Avg Val Loss: 1.9451\n",
      "Validation loss improved from 1.9454 to 1.9451. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4015\n",
      "Epoch [1032/2000], Avg Train Loss: 3.4015\n",
      "Epoch [1032/2000], Avg Val Loss: 1.9448\n",
      "Validation loss improved from 1.9451 to 1.9448. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3949\n",
      "Epoch [1033/2000], Avg Train Loss: 3.3949\n",
      "Epoch [1033/2000], Avg Val Loss: 1.9445\n",
      "Validation loss improved from 1.9448 to 1.9445. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3748\n",
      "Epoch [1034/2000], Avg Train Loss: 3.3748\n",
      "Epoch [1034/2000], Avg Val Loss: 1.9442\n",
      "Validation loss improved from 1.9445 to 1.9442. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3898\n",
      "Epoch [1035/2000], Avg Train Loss: 3.3898\n",
      "Epoch [1035/2000], Avg Val Loss: 1.9439\n",
      "Validation loss improved from 1.9442 to 1.9439. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4093\n",
      "Epoch [1036/2000], Avg Train Loss: 3.4093\n",
      "Epoch [1036/2000], Avg Val Loss: 1.9435\n",
      "Validation loss improved from 1.9439 to 1.9435. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4069\n",
      "Epoch [1037/2000], Avg Train Loss: 3.4069\n",
      "Epoch [1037/2000], Avg Val Loss: 1.9431\n",
      "Validation loss improved from 1.9435 to 1.9431. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4135\n",
      "Epoch [1038/2000], Avg Train Loss: 3.4135\n",
      "Epoch [1038/2000], Avg Val Loss: 1.9428\n",
      "Validation loss improved from 1.9431 to 1.9428. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4165\n",
      "Epoch [1039/2000], Avg Train Loss: 3.4165\n",
      "Epoch [1039/2000], Avg Val Loss: 1.9424\n",
      "Validation loss improved from 1.9428 to 1.9424. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4442\n",
      "Epoch [1040/2000], Avg Train Loss: 3.4442\n",
      "Epoch [1040/2000], Avg Val Loss: 1.9421\n",
      "Validation loss improved from 1.9424 to 1.9421. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4343\n",
      "Epoch [1041/2000], Avg Train Loss: 3.4343\n",
      "Epoch [1041/2000], Avg Val Loss: 1.9417\n",
      "Validation loss improved from 1.9421 to 1.9417. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4182\n",
      "Epoch [1042/2000], Avg Train Loss: 3.4182\n",
      "Epoch [1042/2000], Avg Val Loss: 1.9414\n",
      "Validation loss improved from 1.9417 to 1.9414. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4125\n",
      "Epoch [1043/2000], Avg Train Loss: 3.4125\n",
      "Epoch [1043/2000], Avg Val Loss: 1.9410\n",
      "Validation loss improved from 1.9414 to 1.9410. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3856\n",
      "Epoch [1044/2000], Avg Train Loss: 3.3856\n",
      "Epoch [1044/2000], Avg Val Loss: 1.9406\n",
      "Validation loss improved from 1.9410 to 1.9406. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4271\n",
      "Epoch [1045/2000], Avg Train Loss: 3.4271\n",
      "Epoch [1045/2000], Avg Val Loss: 1.9403\n",
      "Validation loss improved from 1.9406 to 1.9403. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4103\n",
      "Epoch [1046/2000], Avg Train Loss: 3.4103\n",
      "Epoch [1046/2000], Avg Val Loss: 1.9399\n",
      "Validation loss improved from 1.9403 to 1.9399. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4053\n",
      "Epoch [1047/2000], Avg Train Loss: 3.4053\n",
      "Epoch [1047/2000], Avg Val Loss: 1.9396\n",
      "Validation loss improved from 1.9399 to 1.9396. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4015\n",
      "Epoch [1048/2000], Avg Train Loss: 3.4015\n",
      "Epoch [1048/2000], Avg Val Loss: 1.9392\n",
      "Validation loss improved from 1.9396 to 1.9392. Saving model...\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4225\n",
      "Epoch [1049/2000], Avg Train Loss: 3.4225\n",
      "Epoch [1049/2000], Avg Val Loss: 1.9388\n",
      "Validation loss improved from 1.9392 to 1.9388. Saving model...\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4296\n",
      "Epoch [1050/2000], Avg Train Loss: 3.4296\n",
      "Epoch [1050/2000], Avg Val Loss: 1.9385\n",
      "Validation loss improved from 1.9388 to 1.9385. Saving model...\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4047\n",
      "Epoch [1051/2000], Avg Train Loss: 3.4047\n",
      "Epoch [1051/2000], Avg Val Loss: 1.9382\n",
      "Validation loss improved from 1.9385 to 1.9382. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3984\n",
      "Epoch [1052/2000], Avg Train Loss: 3.3984\n",
      "Epoch [1052/2000], Avg Val Loss: 1.9379\n",
      "Validation loss improved from 1.9382 to 1.9379. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3835\n",
      "Epoch [1053/2000], Avg Train Loss: 3.3835\n",
      "Epoch [1053/2000], Avg Val Loss: 1.9376\n",
      "Validation loss improved from 1.9379 to 1.9376. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4223\n",
      "Epoch [1054/2000], Avg Train Loss: 3.4223\n",
      "Epoch [1054/2000], Avg Val Loss: 1.9373\n",
      "Validation loss improved from 1.9376 to 1.9373. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4263\n",
      "Epoch [1055/2000], Avg Train Loss: 3.4263\n",
      "Epoch [1055/2000], Avg Val Loss: 1.9370\n",
      "Validation loss improved from 1.9373 to 1.9370. Saving model...\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3961\n",
      "Epoch [1056/2000], Avg Train Loss: 3.3961\n",
      "Epoch [1056/2000], Avg Val Loss: 1.9367\n",
      "Validation loss improved from 1.9370 to 1.9367. Saving model...\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4037\n",
      "Epoch [1057/2000], Avg Train Loss: 3.4037\n",
      "Epoch [1057/2000], Avg Val Loss: 1.9364\n",
      "Validation loss improved from 1.9367 to 1.9364. Saving model...\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3862\n",
      "Epoch [1058/2000], Avg Train Loss: 3.3862\n",
      "Epoch [1058/2000], Avg Val Loss: 1.9361\n",
      "Validation loss improved from 1.9364 to 1.9361. Saving model...\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3889\n",
      "Epoch [1059/2000], Avg Train Loss: 3.3889\n",
      "Epoch [1059/2000], Avg Val Loss: 1.9358\n",
      "Validation loss improved from 1.9361 to 1.9358. Saving model...\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3865\n",
      "Epoch [1060/2000], Avg Train Loss: 3.3865\n",
      "Epoch [1060/2000], Avg Val Loss: 1.9356\n",
      "Validation loss improved from 1.9358 to 1.9356. Saving model...\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4015\n",
      "Epoch [1061/2000], Avg Train Loss: 3.4015\n",
      "Epoch [1061/2000], Avg Val Loss: 1.9355\n",
      "Validation loss improved from 1.9356 to 1.9355. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3896\n",
      "Epoch [1062/2000], Avg Train Loss: 3.3896\n",
      "Epoch [1062/2000], Avg Val Loss: 1.9354\n",
      "Validation loss improved from 1.9355 to 1.9354. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3900\n",
      "Epoch [1063/2000], Avg Train Loss: 3.3900\n",
      "Epoch [1063/2000], Avg Val Loss: 1.9351\n",
      "Validation loss improved from 1.9354 to 1.9351. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4144\n",
      "Epoch [1064/2000], Avg Train Loss: 3.4144\n",
      "Epoch [1064/2000], Avg Val Loss: 1.9349\n",
      "Validation loss improved from 1.9351 to 1.9349. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3963\n",
      "Epoch [1065/2000], Avg Train Loss: 3.3963\n",
      "Epoch [1065/2000], Avg Val Loss: 1.9348\n",
      "Validation loss improved from 1.9349 to 1.9348. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4067\n",
      "Epoch [1066/2000], Avg Train Loss: 3.4067\n",
      "Epoch [1066/2000], Avg Val Loss: 1.9346\n",
      "Validation loss improved from 1.9348 to 1.9346. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4146\n",
      "Epoch [1067/2000], Avg Train Loss: 3.4146\n",
      "Epoch [1067/2000], Avg Val Loss: 1.9345\n",
      "Validation loss improved from 1.9346 to 1.9345. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3983\n",
      "Epoch [1068/2000], Avg Train Loss: 3.3983\n",
      "Epoch [1068/2000], Avg Val Loss: 1.9343\n",
      "Validation loss improved from 1.9345 to 1.9343. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4185\n",
      "Epoch [1069/2000], Avg Train Loss: 3.4185\n",
      "Epoch [1069/2000], Avg Val Loss: 1.9340\n",
      "Validation loss improved from 1.9343 to 1.9340. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4251\n",
      "Epoch [1070/2000], Avg Train Loss: 3.4251\n",
      "Epoch [1070/2000], Avg Val Loss: 1.9337\n",
      "Validation loss improved from 1.9340 to 1.9337. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3848\n",
      "Epoch [1071/2000], Avg Train Loss: 3.3848\n",
      "Epoch [1071/2000], Avg Val Loss: 1.9335\n",
      "Validation loss improved from 1.9337 to 1.9335. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4004\n",
      "Epoch [1072/2000], Avg Train Loss: 3.4004\n",
      "Epoch [1072/2000], Avg Val Loss: 1.9333\n",
      "Validation loss improved from 1.9335 to 1.9333. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3866\n",
      "Epoch [1073/2000], Avg Train Loss: 3.3866\n",
      "Epoch [1073/2000], Avg Val Loss: 1.9331\n",
      "Validation loss improved from 1.9333 to 1.9331. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4042\n",
      "Epoch [1074/2000], Avg Train Loss: 3.4042\n",
      "Epoch [1074/2000], Avg Val Loss: 1.9328\n",
      "Validation loss improved from 1.9331 to 1.9328. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4026\n",
      "Epoch [1075/2000], Avg Train Loss: 3.4026\n",
      "Epoch [1075/2000], Avg Val Loss: 1.9326\n",
      "Validation loss improved from 1.9328 to 1.9326. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3909\n",
      "Epoch [1076/2000], Avg Train Loss: 3.3909\n",
      "Epoch [1076/2000], Avg Val Loss: 1.9324\n",
      "Validation loss improved from 1.9326 to 1.9324. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3836\n",
      "Epoch [1077/2000], Avg Train Loss: 3.3836\n",
      "Epoch [1077/2000], Avg Val Loss: 1.9322\n",
      "Validation loss improved from 1.9324 to 1.9322. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3686\n",
      "Epoch [1078/2000], Avg Train Loss: 3.3686\n",
      "Epoch [1078/2000], Avg Val Loss: 1.9320\n",
      "Validation loss improved from 1.9322 to 1.9320. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3760\n",
      "Epoch [1079/2000], Avg Train Loss: 3.3760\n",
      "Epoch [1079/2000], Avg Val Loss: 1.9318\n",
      "Validation loss improved from 1.9320 to 1.9318. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3935\n",
      "Epoch [1080/2000], Avg Train Loss: 3.3935\n",
      "Epoch [1080/2000], Avg Val Loss: 1.9315\n",
      "Validation loss improved from 1.9318 to 1.9315. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3778\n",
      "Epoch [1081/2000], Avg Train Loss: 3.3778\n",
      "Epoch [1081/2000], Avg Val Loss: 1.9313\n",
      "Validation loss improved from 1.9315 to 1.9313. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4066\n",
      "Epoch [1082/2000], Avg Train Loss: 3.4066\n",
      "Epoch [1082/2000], Avg Val Loss: 1.9310\n",
      "Validation loss improved from 1.9313 to 1.9310. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4150\n",
      "Epoch [1083/2000], Avg Train Loss: 3.4150\n",
      "Epoch [1083/2000], Avg Val Loss: 1.9308\n",
      "Validation loss improved from 1.9310 to 1.9308. Saving model...\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4322\n",
      "Epoch [1084/2000], Avg Train Loss: 3.4322\n",
      "Epoch [1084/2000], Avg Val Loss: 1.9306\n",
      "Validation loss improved from 1.9308 to 1.9306. Saving model...\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3963\n",
      "Epoch [1085/2000], Avg Train Loss: 3.3963\n",
      "Epoch [1085/2000], Avg Val Loss: 1.9304\n",
      "Validation loss improved from 1.9306 to 1.9304. Saving model...\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4045\n",
      "Epoch [1086/2000], Avg Train Loss: 3.4045\n",
      "Epoch [1086/2000], Avg Val Loss: 1.9301\n",
      "Validation loss improved from 1.9304 to 1.9301. Saving model...\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4039\n",
      "Epoch [1087/2000], Avg Train Loss: 3.4039\n",
      "Epoch [1087/2000], Avg Val Loss: 1.9298\n",
      "Validation loss improved from 1.9301 to 1.9298. Saving model...\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3966\n",
      "Epoch [1088/2000], Avg Train Loss: 3.3966\n",
      "Epoch [1088/2000], Avg Val Loss: 1.9295\n",
      "Validation loss improved from 1.9298 to 1.9295. Saving model...\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4044\n",
      "Epoch [1089/2000], Avg Train Loss: 3.4044\n",
      "Epoch [1089/2000], Avg Val Loss: 1.9291\n",
      "Validation loss improved from 1.9295 to 1.9291. Saving model...\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3905\n",
      "Epoch [1090/2000], Avg Train Loss: 3.3905\n",
      "Epoch [1090/2000], Avg Val Loss: 1.9287\n",
      "Validation loss improved from 1.9291 to 1.9287. Saving model...\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3917\n",
      "Epoch [1091/2000], Avg Train Loss: 3.3917\n",
      "Epoch [1091/2000], Avg Val Loss: 1.9284\n",
      "Validation loss improved from 1.9287 to 1.9284. Saving model...\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4412\n",
      "Epoch [1092/2000], Avg Train Loss: 3.4412\n",
      "Epoch [1092/2000], Avg Val Loss: 1.9281\n",
      "Validation loss improved from 1.9284 to 1.9281. Saving model...\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3840\n",
      "Epoch [1093/2000], Avg Train Loss: 3.3840\n",
      "Epoch [1093/2000], Avg Val Loss: 1.9277\n",
      "Validation loss improved from 1.9281 to 1.9277. Saving model...\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4040\n",
      "Epoch [1094/2000], Avg Train Loss: 3.4040\n",
      "Epoch [1094/2000], Avg Val Loss: 1.9274\n",
      "Validation loss improved from 1.9277 to 1.9274. Saving model...\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3545\n",
      "Epoch [1095/2000], Avg Train Loss: 3.3545\n",
      "Epoch [1095/2000], Avg Val Loss: 1.9271\n",
      "Validation loss improved from 1.9274 to 1.9271. Saving model...\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4167\n",
      "Epoch [1096/2000], Avg Train Loss: 3.4167\n",
      "Epoch [1096/2000], Avg Val Loss: 1.9267\n",
      "Validation loss improved from 1.9271 to 1.9267. Saving model...\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3733\n",
      "Epoch [1097/2000], Avg Train Loss: 3.3733\n",
      "Epoch [1097/2000], Avg Val Loss: 1.9264\n",
      "Validation loss improved from 1.9267 to 1.9264. Saving model...\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3562\n",
      "Epoch [1098/2000], Avg Train Loss: 3.3562\n",
      "Epoch [1098/2000], Avg Val Loss: 1.9261\n",
      "Validation loss improved from 1.9264 to 1.9261. Saving model...\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3749\n",
      "Epoch [1099/2000], Avg Train Loss: 3.3749\n",
      "Epoch [1099/2000], Avg Val Loss: 1.9258\n",
      "Validation loss improved from 1.9261 to 1.9258. Saving model...\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3737\n",
      "Epoch [1100/2000], Avg Train Loss: 3.3737\n",
      "Epoch [1100/2000], Avg Val Loss: 1.9255\n",
      "Validation loss improved from 1.9258 to 1.9255. Saving model...\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3773\n",
      "Epoch [1101/2000], Avg Train Loss: 3.3773\n",
      "Epoch [1101/2000], Avg Val Loss: 1.9253\n",
      "Validation loss improved from 1.9255 to 1.9253. Saving model...\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4081\n",
      "Epoch [1102/2000], Avg Train Loss: 3.4081\n",
      "Epoch [1102/2000], Avg Val Loss: 1.9250\n",
      "Validation loss improved from 1.9253 to 1.9250. Saving model...\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4132\n",
      "Epoch [1103/2000], Avg Train Loss: 3.4132\n",
      "Epoch [1103/2000], Avg Val Loss: 1.9248\n",
      "Validation loss improved from 1.9250 to 1.9248. Saving model...\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3743\n",
      "Epoch [1104/2000], Avg Train Loss: 3.3743\n",
      "Epoch [1104/2000], Avg Val Loss: 1.9246\n",
      "Validation loss improved from 1.9248 to 1.9246. Saving model...\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3744\n",
      "Epoch [1105/2000], Avg Train Loss: 3.3744\n",
      "Epoch [1105/2000], Avg Val Loss: 1.9243\n",
      "Validation loss improved from 1.9246 to 1.9243. Saving model...\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4077\n",
      "Epoch [1106/2000], Avg Train Loss: 3.4077\n",
      "Epoch [1106/2000], Avg Val Loss: 1.9241\n",
      "Validation loss improved from 1.9243 to 1.9241. Saving model...\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3924\n",
      "Epoch [1107/2000], Avg Train Loss: 3.3924\n",
      "Epoch [1107/2000], Avg Val Loss: 1.9239\n",
      "Validation loss improved from 1.9241 to 1.9239. Saving model...\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3802\n",
      "Epoch [1108/2000], Avg Train Loss: 3.3802\n",
      "Epoch [1108/2000], Avg Val Loss: 1.9237\n",
      "Validation loss improved from 1.9239 to 1.9237. Saving model...\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4051\n",
      "Epoch [1109/2000], Avg Train Loss: 3.4051\n",
      "Epoch [1109/2000], Avg Val Loss: 1.9235\n",
      "Validation loss improved from 1.9237 to 1.9235. Saving model...\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3914\n",
      "Epoch [1110/2000], Avg Train Loss: 3.3914\n",
      "Epoch [1110/2000], Avg Val Loss: 1.9233\n",
      "Validation loss improved from 1.9235 to 1.9233. Saving model...\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4238\n",
      "Epoch [1111/2000], Avg Train Loss: 3.4238\n",
      "Epoch [1111/2000], Avg Val Loss: 1.9231\n",
      "Validation loss improved from 1.9233 to 1.9231. Saving model...\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3658\n",
      "Epoch [1112/2000], Avg Train Loss: 3.3658\n",
      "Epoch [1112/2000], Avg Val Loss: 1.9230\n",
      "Validation loss improved from 1.9231 to 1.9230. Saving model...\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4030\n",
      "Epoch [1113/2000], Avg Train Loss: 3.4030\n",
      "Epoch [1113/2000], Avg Val Loss: 1.9228\n",
      "Validation loss improved from 1.9230 to 1.9228. Saving model...\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3581\n",
      "Epoch [1114/2000], Avg Train Loss: 3.3581\n",
      "Epoch [1114/2000], Avg Val Loss: 1.9227\n",
      "Validation loss improved from 1.9228 to 1.9227. Saving model...\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4071\n",
      "Epoch [1115/2000], Avg Train Loss: 3.4071\n",
      "Epoch [1115/2000], Avg Val Loss: 1.9225\n",
      "Validation loss improved from 1.9227 to 1.9225. Saving model...\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3803\n",
      "Epoch [1116/2000], Avg Train Loss: 3.3803\n",
      "Epoch [1116/2000], Avg Val Loss: 1.9224\n",
      "Validation loss improved from 1.9225 to 1.9224. Saving model...\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3986\n",
      "Epoch [1117/2000], Avg Train Loss: 3.3986\n",
      "Epoch [1117/2000], Avg Val Loss: 1.9222\n",
      "Validation loss improved from 1.9224 to 1.9222. Saving model...\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3941\n",
      "Epoch [1118/2000], Avg Train Loss: 3.3941\n",
      "Epoch [1118/2000], Avg Val Loss: 1.9221\n",
      "Validation loss improved from 1.9222 to 1.9221. Saving model...\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3610\n",
      "Epoch [1119/2000], Avg Train Loss: 3.3610\n",
      "Epoch [1119/2000], Avg Val Loss: 1.9219\n",
      "Validation loss improved from 1.9221 to 1.9219. Saving model...\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3872\n",
      "Epoch [1120/2000], Avg Train Loss: 3.3872\n",
      "Epoch [1120/2000], Avg Val Loss: 1.9218\n",
      "Validation loss improved from 1.9219 to 1.9218. Saving model...\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3766\n",
      "Epoch [1121/2000], Avg Train Loss: 3.3766\n",
      "Epoch [1121/2000], Avg Val Loss: 1.9216\n",
      "Validation loss improved from 1.9218 to 1.9216. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3800\n",
      "Epoch [1122/2000], Avg Train Loss: 3.3800\n",
      "Epoch [1122/2000], Avg Val Loss: 1.9215\n",
      "Validation loss improved from 1.9216 to 1.9215. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3574\n",
      "Epoch [1123/2000], Avg Train Loss: 3.3574\n",
      "Epoch [1123/2000], Avg Val Loss: 1.9213\n",
      "Validation loss improved from 1.9215 to 1.9213. Saving model...\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3772\n",
      "Epoch [1124/2000], Avg Train Loss: 3.3772\n",
      "Epoch [1124/2000], Avg Val Loss: 1.9211\n",
      "Validation loss improved from 1.9213 to 1.9211. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3895\n",
      "Epoch [1125/2000], Avg Train Loss: 3.3895\n",
      "Epoch [1125/2000], Avg Val Loss: 1.9209\n",
      "Validation loss improved from 1.9211 to 1.9209. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3885\n",
      "Epoch [1126/2000], Avg Train Loss: 3.3885\n",
      "Epoch [1126/2000], Avg Val Loss: 1.9207\n",
      "Validation loss improved from 1.9209 to 1.9207. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3786\n",
      "Epoch [1127/2000], Avg Train Loss: 3.3786\n",
      "Epoch [1127/2000], Avg Val Loss: 1.9205\n",
      "Validation loss improved from 1.9207 to 1.9205. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3573\n",
      "Epoch [1128/2000], Avg Train Loss: 3.3573\n",
      "Epoch [1128/2000], Avg Val Loss: 1.9202\n",
      "Validation loss improved from 1.9205 to 1.9202. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3880\n",
      "Epoch [1129/2000], Avg Train Loss: 3.3880\n",
      "Epoch [1129/2000], Avg Val Loss: 1.9199\n",
      "Validation loss improved from 1.9202 to 1.9199. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3843\n",
      "Epoch [1130/2000], Avg Train Loss: 3.3843\n",
      "Epoch [1130/2000], Avg Val Loss: 1.9197\n",
      "Validation loss improved from 1.9199 to 1.9197. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3638\n",
      "Epoch [1131/2000], Avg Train Loss: 3.3638\n",
      "Epoch [1131/2000], Avg Val Loss: 1.9194\n",
      "Validation loss improved from 1.9197 to 1.9194. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3597\n",
      "Epoch [1132/2000], Avg Train Loss: 3.3597\n",
      "Epoch [1132/2000], Avg Val Loss: 1.9190\n",
      "Validation loss improved from 1.9194 to 1.9190. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3725\n",
      "Epoch [1133/2000], Avg Train Loss: 3.3725\n",
      "Epoch [1133/2000], Avg Val Loss: 1.9187\n",
      "Validation loss improved from 1.9190 to 1.9187. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3746\n",
      "Epoch [1134/2000], Avg Train Loss: 3.3746\n",
      "Epoch [1134/2000], Avg Val Loss: 1.9185\n",
      "Validation loss improved from 1.9187 to 1.9185. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3826\n",
      "Epoch [1135/2000], Avg Train Loss: 3.3826\n",
      "Epoch [1135/2000], Avg Val Loss: 1.9182\n",
      "Validation loss improved from 1.9185 to 1.9182. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3844\n",
      "Epoch [1136/2000], Avg Train Loss: 3.3844\n",
      "Epoch [1136/2000], Avg Val Loss: 1.9180\n",
      "Validation loss improved from 1.9182 to 1.9180. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3539\n",
      "Epoch [1137/2000], Avg Train Loss: 3.3539\n",
      "Epoch [1137/2000], Avg Val Loss: 1.9178\n",
      "Validation loss improved from 1.9180 to 1.9178. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3892\n",
      "Epoch [1138/2000], Avg Train Loss: 3.3892\n",
      "Epoch [1138/2000], Avg Val Loss: 1.9176\n",
      "Validation loss improved from 1.9178 to 1.9176. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3678\n",
      "Epoch [1139/2000], Avg Train Loss: 3.3678\n",
      "Epoch [1139/2000], Avg Val Loss: 1.9174\n",
      "Validation loss improved from 1.9176 to 1.9174. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3987\n",
      "Epoch [1140/2000], Avg Train Loss: 3.3987\n",
      "Epoch [1140/2000], Avg Val Loss: 1.9172\n",
      "Validation loss improved from 1.9174 to 1.9172. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3613\n",
      "Epoch [1141/2000], Avg Train Loss: 3.3613\n",
      "Epoch [1141/2000], Avg Val Loss: 1.9170\n",
      "Validation loss improved from 1.9172 to 1.9170. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3994\n",
      "Epoch [1142/2000], Avg Train Loss: 3.3994\n",
      "Epoch [1142/2000], Avg Val Loss: 1.9167\n",
      "Validation loss improved from 1.9170 to 1.9167. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3553\n",
      "Epoch [1143/2000], Avg Train Loss: 3.3553\n",
      "Epoch [1143/2000], Avg Val Loss: 1.9165\n",
      "Validation loss improved from 1.9167 to 1.9165. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3983\n",
      "Epoch [1144/2000], Avg Train Loss: 3.3983\n",
      "Epoch [1144/2000], Avg Val Loss: 1.9164\n",
      "Validation loss improved from 1.9165 to 1.9164. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3720\n",
      "Epoch [1145/2000], Avg Train Loss: 3.3720\n",
      "Epoch [1145/2000], Avg Val Loss: 1.9162\n",
      "Validation loss improved from 1.9164 to 1.9162. Saving model...\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3649\n",
      "Epoch [1146/2000], Avg Train Loss: 3.3649\n",
      "Epoch [1146/2000], Avg Val Loss: 1.9161\n",
      "Validation loss improved from 1.9162 to 1.9161. Saving model...\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3875\n",
      "Epoch [1147/2000], Avg Train Loss: 3.3875\n",
      "Epoch [1147/2000], Avg Val Loss: 1.9159\n",
      "Validation loss improved from 1.9161 to 1.9159. Saving model...\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3889\n",
      "Epoch [1148/2000], Avg Train Loss: 3.3889\n",
      "Epoch [1148/2000], Avg Val Loss: 1.9159\n",
      "Validation loss improved from 1.9159 to 1.9159. Saving model...\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3663\n",
      "Epoch [1149/2000], Avg Train Loss: 3.3663\n",
      "Epoch [1149/2000], Avg Val Loss: 1.9158\n",
      "Validation loss improved from 1.9159 to 1.9158. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3777\n",
      "Epoch [1150/2000], Avg Train Loss: 3.3777\n",
      "Epoch [1150/2000], Avg Val Loss: 1.9157\n",
      "Validation loss improved from 1.9158 to 1.9157. Saving model...\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3603\n",
      "Epoch [1151/2000], Avg Train Loss: 3.3603\n",
      "Epoch [1151/2000], Avg Val Loss: 1.9155\n",
      "Validation loss improved from 1.9157 to 1.9155. Saving model...\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3676\n",
      "Epoch [1152/2000], Avg Train Loss: 3.3676\n",
      "Epoch [1152/2000], Avg Val Loss: 1.9153\n",
      "Validation loss improved from 1.9155 to 1.9153. Saving model...\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3300\n",
      "Epoch [1153/2000], Avg Train Loss: 3.3300\n",
      "Epoch [1153/2000], Avg Val Loss: 1.9151\n",
      "Validation loss improved from 1.9153 to 1.9151. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3769\n",
      "Epoch [1154/2000], Avg Train Loss: 3.3769\n",
      "Epoch [1154/2000], Avg Val Loss: 1.9149\n",
      "Validation loss improved from 1.9151 to 1.9149. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3892\n",
      "Epoch [1155/2000], Avg Train Loss: 3.3892\n",
      "Epoch [1155/2000], Avg Val Loss: 1.9146\n",
      "Validation loss improved from 1.9149 to 1.9146. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3623\n",
      "Epoch [1156/2000], Avg Train Loss: 3.3623\n",
      "Epoch [1156/2000], Avg Val Loss: 1.9144\n",
      "Validation loss improved from 1.9146 to 1.9144. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3635\n",
      "Epoch [1157/2000], Avg Train Loss: 3.3635\n",
      "Epoch [1157/2000], Avg Val Loss: 1.9141\n",
      "Validation loss improved from 1.9144 to 1.9141. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3641\n",
      "Epoch [1158/2000], Avg Train Loss: 3.3641\n",
      "Epoch [1158/2000], Avg Val Loss: 1.9138\n",
      "Validation loss improved from 1.9141 to 1.9138. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3553\n",
      "Epoch [1159/2000], Avg Train Loss: 3.3553\n",
      "Epoch [1159/2000], Avg Val Loss: 1.9135\n",
      "Validation loss improved from 1.9138 to 1.9135. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3705\n",
      "Epoch [1160/2000], Avg Train Loss: 3.3705\n",
      "Epoch [1160/2000], Avg Val Loss: 1.9133\n",
      "Validation loss improved from 1.9135 to 1.9133. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3534\n",
      "Epoch [1161/2000], Avg Train Loss: 3.3534\n",
      "Epoch [1161/2000], Avg Val Loss: 1.9130\n",
      "Validation loss improved from 1.9133 to 1.9130. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4085\n",
      "Epoch [1162/2000], Avg Train Loss: 3.4085\n",
      "Epoch [1162/2000], Avg Val Loss: 1.9128\n",
      "Validation loss improved from 1.9130 to 1.9128. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3722\n",
      "Epoch [1163/2000], Avg Train Loss: 3.3722\n",
      "Epoch [1163/2000], Avg Val Loss: 1.9126\n",
      "Validation loss improved from 1.9128 to 1.9126. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3692\n",
      "Epoch [1164/2000], Avg Train Loss: 3.3692\n",
      "Epoch [1164/2000], Avg Val Loss: 1.9123\n",
      "Validation loss improved from 1.9126 to 1.9123. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3921\n",
      "Epoch [1165/2000], Avg Train Loss: 3.3921\n",
      "Epoch [1165/2000], Avg Val Loss: 1.9121\n",
      "Validation loss improved from 1.9123 to 1.9121. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3717\n",
      "Epoch [1166/2000], Avg Train Loss: 3.3717\n",
      "Epoch [1166/2000], Avg Val Loss: 1.9118\n",
      "Validation loss improved from 1.9121 to 1.9118. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3570\n",
      "Epoch [1167/2000], Avg Train Loss: 3.3570\n",
      "Epoch [1167/2000], Avg Val Loss: 1.9114\n",
      "Validation loss improved from 1.9118 to 1.9114. Saving model...\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3791\n",
      "Epoch [1168/2000], Avg Train Loss: 3.3791\n",
      "Epoch [1168/2000], Avg Val Loss: 1.9110\n",
      "Validation loss improved from 1.9114 to 1.9110. Saving model...\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3653\n",
      "Epoch [1169/2000], Avg Train Loss: 3.3653\n",
      "Epoch [1169/2000], Avg Val Loss: 1.9107\n",
      "Validation loss improved from 1.9110 to 1.9107. Saving model...\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3428\n",
      "Epoch [1170/2000], Avg Train Loss: 3.3428\n",
      "Epoch [1170/2000], Avg Val Loss: 1.9103\n",
      "Validation loss improved from 1.9107 to 1.9103. Saving model...\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3848\n",
      "Epoch [1171/2000], Avg Train Loss: 3.3848\n",
      "Epoch [1171/2000], Avg Val Loss: 1.9099\n",
      "Validation loss improved from 1.9103 to 1.9099. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3439\n",
      "Epoch [1172/2000], Avg Train Loss: 3.3439\n",
      "Epoch [1172/2000], Avg Val Loss: 1.9095\n",
      "Validation loss improved from 1.9099 to 1.9095. Saving model...\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3835\n",
      "Epoch [1173/2000], Avg Train Loss: 3.3835\n",
      "Epoch [1173/2000], Avg Val Loss: 1.9093\n",
      "Validation loss improved from 1.9095 to 1.9093. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3575\n",
      "Epoch [1174/2000], Avg Train Loss: 3.3575\n",
      "Epoch [1174/2000], Avg Val Loss: 1.9090\n",
      "Validation loss improved from 1.9093 to 1.9090. Saving model...\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3850\n",
      "Epoch [1175/2000], Avg Train Loss: 3.3850\n",
      "Epoch [1175/2000], Avg Val Loss: 1.9087\n",
      "Validation loss improved from 1.9090 to 1.9087. Saving model...\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3567\n",
      "Epoch [1176/2000], Avg Train Loss: 3.3567\n",
      "Epoch [1176/2000], Avg Val Loss: 1.9085\n",
      "Validation loss improved from 1.9087 to 1.9085. Saving model...\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3491\n",
      "Epoch [1177/2000], Avg Train Loss: 3.3491\n",
      "Epoch [1177/2000], Avg Val Loss: 1.9082\n",
      "Validation loss improved from 1.9085 to 1.9082. Saving model...\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3617\n",
      "Epoch [1178/2000], Avg Train Loss: 3.3617\n",
      "Epoch [1178/2000], Avg Val Loss: 1.9079\n",
      "Validation loss improved from 1.9082 to 1.9079. Saving model...\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3486\n",
      "Epoch [1179/2000], Avg Train Loss: 3.3486\n",
      "Epoch [1179/2000], Avg Val Loss: 1.9077\n",
      "Validation loss improved from 1.9079 to 1.9077. Saving model...\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3361\n",
      "Epoch [1180/2000], Avg Train Loss: 3.3361\n",
      "Epoch [1180/2000], Avg Val Loss: 1.9074\n",
      "Validation loss improved from 1.9077 to 1.9074. Saving model...\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3962\n",
      "Epoch [1181/2000], Avg Train Loss: 3.3962\n",
      "Epoch [1181/2000], Avg Val Loss: 1.9071\n",
      "Validation loss improved from 1.9074 to 1.9071. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3257\n",
      "Epoch [1182/2000], Avg Train Loss: 3.3257\n",
      "Epoch [1182/2000], Avg Val Loss: 1.9069\n",
      "Validation loss improved from 1.9071 to 1.9069. Saving model...\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3690\n",
      "Epoch [1183/2000], Avg Train Loss: 3.3690\n",
      "Epoch [1183/2000], Avg Val Loss: 1.9066\n",
      "Validation loss improved from 1.9069 to 1.9066. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3443\n",
      "Epoch [1184/2000], Avg Train Loss: 3.3443\n",
      "Epoch [1184/2000], Avg Val Loss: 1.9064\n",
      "Validation loss improved from 1.9066 to 1.9064. Saving model...\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3951\n",
      "Epoch [1185/2000], Avg Train Loss: 3.3951\n",
      "Epoch [1185/2000], Avg Val Loss: 1.9062\n",
      "Validation loss improved from 1.9064 to 1.9062. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3676\n",
      "Epoch [1186/2000], Avg Train Loss: 3.3676\n",
      "Epoch [1186/2000], Avg Val Loss: 1.9061\n",
      "Validation loss improved from 1.9062 to 1.9061. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3886\n",
      "Epoch [1187/2000], Avg Train Loss: 3.3886\n",
      "Epoch [1187/2000], Avg Val Loss: 1.9059\n",
      "Validation loss improved from 1.9061 to 1.9059. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3942\n",
      "Epoch [1188/2000], Avg Train Loss: 3.3942\n",
      "Epoch [1188/2000], Avg Val Loss: 1.9057\n",
      "Validation loss improved from 1.9059 to 1.9057. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3875\n",
      "Epoch [1189/2000], Avg Train Loss: 3.3875\n",
      "Epoch [1189/2000], Avg Val Loss: 1.9056\n",
      "Validation loss improved from 1.9057 to 1.9056. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3495\n",
      "Epoch [1190/2000], Avg Train Loss: 3.3495\n",
      "Epoch [1190/2000], Avg Val Loss: 1.9054\n",
      "Validation loss improved from 1.9056 to 1.9054. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3209\n",
      "Epoch [1191/2000], Avg Train Loss: 3.3209\n",
      "Epoch [1191/2000], Avg Val Loss: 1.9051\n",
      "Validation loss improved from 1.9054 to 1.9051. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3504\n",
      "Epoch [1192/2000], Avg Train Loss: 3.3504\n",
      "Epoch [1192/2000], Avg Val Loss: 1.9049\n",
      "Validation loss improved from 1.9051 to 1.9049. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3430\n",
      "Epoch [1193/2000], Avg Train Loss: 3.3430\n",
      "Epoch [1193/2000], Avg Val Loss: 1.9047\n",
      "Validation loss improved from 1.9049 to 1.9047. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3403\n",
      "Epoch [1194/2000], Avg Train Loss: 3.3403\n",
      "Epoch [1194/2000], Avg Val Loss: 1.9046\n",
      "Validation loss improved from 1.9047 to 1.9046. Saving model...\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3678\n",
      "Epoch [1195/2000], Avg Train Loss: 3.3678\n",
      "Epoch [1195/2000], Avg Val Loss: 1.9045\n",
      "Validation loss improved from 1.9046 to 1.9045. Saving model...\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3710\n",
      "Epoch [1196/2000], Avg Train Loss: 3.3710\n",
      "Epoch [1196/2000], Avg Val Loss: 1.9044\n",
      "Validation loss improved from 1.9045 to 1.9044. Saving model...\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3495\n",
      "Epoch [1197/2000], Avg Train Loss: 3.3495\n",
      "Epoch [1197/2000], Avg Val Loss: 1.9043\n",
      "Validation loss improved from 1.9044 to 1.9043. Saving model...\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3822\n",
      "Epoch [1198/2000], Avg Train Loss: 3.3822\n",
      "Epoch [1198/2000], Avg Val Loss: 1.9041\n",
      "Validation loss improved from 1.9043 to 1.9041. Saving model...\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3328\n",
      "Epoch [1199/2000], Avg Train Loss: 3.3328\n",
      "Epoch [1199/2000], Avg Val Loss: 1.9040\n",
      "Validation loss improved from 1.9041 to 1.9040. Saving model...\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3547\n",
      "Epoch [1200/2000], Avg Train Loss: 3.3547\n",
      "Epoch [1200/2000], Avg Val Loss: 1.9039\n",
      "Validation loss improved from 1.9040 to 1.9039. Saving model...\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3434\n",
      "Epoch [1201/2000], Avg Train Loss: 3.3434\n",
      "Epoch [1201/2000], Avg Val Loss: 1.9038\n",
      "Validation loss improved from 1.9039 to 1.9038. Saving model...\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3923\n",
      "Epoch [1202/2000], Avg Train Loss: 3.3923\n",
      "Epoch [1202/2000], Avg Val Loss: 1.9037\n",
      "Validation loss improved from 1.9038 to 1.9037. Saving model...\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3812\n",
      "Epoch [1203/2000], Avg Train Loss: 3.3812\n",
      "Epoch [1203/2000], Avg Val Loss: 1.9035\n",
      "Validation loss improved from 1.9037 to 1.9035. Saving model...\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3451\n",
      "Epoch [1204/2000], Avg Train Loss: 3.3451\n",
      "Epoch [1204/2000], Avg Val Loss: 1.9033\n",
      "Validation loss improved from 1.9035 to 1.9033. Saving model...\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3700\n",
      "Epoch [1205/2000], Avg Train Loss: 3.3700\n",
      "Epoch [1205/2000], Avg Val Loss: 1.9030\n",
      "Validation loss improved from 1.9033 to 1.9030. Saving model...\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3505\n",
      "Epoch [1206/2000], Avg Train Loss: 3.3505\n",
      "Epoch [1206/2000], Avg Val Loss: 1.9027\n",
      "Validation loss improved from 1.9030 to 1.9027. Saving model...\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3452\n",
      "Epoch [1207/2000], Avg Train Loss: 3.3452\n",
      "Epoch [1207/2000], Avg Val Loss: 1.9025\n",
      "Validation loss improved from 1.9027 to 1.9025. Saving model...\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3629\n",
      "Epoch [1208/2000], Avg Train Loss: 3.3629\n",
      "Epoch [1208/2000], Avg Val Loss: 1.9022\n",
      "Validation loss improved from 1.9025 to 1.9022. Saving model...\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3618\n",
      "Epoch [1209/2000], Avg Train Loss: 3.3618\n",
      "Epoch [1209/2000], Avg Val Loss: 1.9020\n",
      "Validation loss improved from 1.9022 to 1.9020. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3516\n",
      "Epoch [1210/2000], Avg Train Loss: 3.3516\n",
      "Epoch [1210/2000], Avg Val Loss: 1.9018\n",
      "Validation loss improved from 1.9020 to 1.9018. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3583\n",
      "Epoch [1211/2000], Avg Train Loss: 3.3583\n",
      "Epoch [1211/2000], Avg Val Loss: 1.9016\n",
      "Validation loss improved from 1.9018 to 1.9016. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3830\n",
      "Epoch [1212/2000], Avg Train Loss: 3.3830\n",
      "Epoch [1212/2000], Avg Val Loss: 1.9015\n",
      "Validation loss improved from 1.9016 to 1.9015. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3429\n",
      "Epoch [1213/2000], Avg Train Loss: 3.3429\n",
      "Epoch [1213/2000], Avg Val Loss: 1.9013\n",
      "Validation loss improved from 1.9015 to 1.9013. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3318\n",
      "Epoch [1214/2000], Avg Train Loss: 3.3318\n",
      "Epoch [1214/2000], Avg Val Loss: 1.9011\n",
      "Validation loss improved from 1.9013 to 1.9011. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3592\n",
      "Epoch [1215/2000], Avg Train Loss: 3.3592\n",
      "Epoch [1215/2000], Avg Val Loss: 1.9008\n",
      "Validation loss improved from 1.9011 to 1.9008. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3651\n",
      "Epoch [1216/2000], Avg Train Loss: 3.3651\n",
      "Epoch [1216/2000], Avg Val Loss: 1.9006\n",
      "Validation loss improved from 1.9008 to 1.9006. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3284\n",
      "Epoch [1217/2000], Avg Train Loss: 3.3284\n",
      "Epoch [1217/2000], Avg Val Loss: 1.9004\n",
      "Validation loss improved from 1.9006 to 1.9004. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3332\n",
      "Epoch [1218/2000], Avg Train Loss: 3.3332\n",
      "Epoch [1218/2000], Avg Val Loss: 1.9002\n",
      "Validation loss improved from 1.9004 to 1.9002. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3407\n",
      "Epoch [1219/2000], Avg Train Loss: 3.3407\n",
      "Epoch [1219/2000], Avg Val Loss: 1.9000\n",
      "Validation loss improved from 1.9002 to 1.9000. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2928\n",
      "Epoch [1220/2000], Avg Train Loss: 3.2928\n",
      "Epoch [1220/2000], Avg Val Loss: 1.8998\n",
      "Validation loss improved from 1.9000 to 1.8998. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3619\n",
      "Epoch [1221/2000], Avg Train Loss: 3.3619\n",
      "Epoch [1221/2000], Avg Val Loss: 1.8995\n",
      "Validation loss improved from 1.8998 to 1.8995. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3864\n",
      "Epoch [1222/2000], Avg Train Loss: 3.3864\n",
      "Epoch [1222/2000], Avg Val Loss: 1.8994\n",
      "Validation loss improved from 1.8995 to 1.8994. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3418\n",
      "Epoch [1223/2000], Avg Train Loss: 3.3418\n",
      "Epoch [1223/2000], Avg Val Loss: 1.8992\n",
      "Validation loss improved from 1.8994 to 1.8992. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3540\n",
      "Epoch [1224/2000], Avg Train Loss: 3.3540\n",
      "Epoch [1224/2000], Avg Val Loss: 1.8990\n",
      "Validation loss improved from 1.8992 to 1.8990. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3377\n",
      "Epoch [1225/2000], Avg Train Loss: 3.3377\n",
      "Epoch [1225/2000], Avg Val Loss: 1.8988\n",
      "Validation loss improved from 1.8990 to 1.8988. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3619\n",
      "Epoch [1226/2000], Avg Train Loss: 3.3619\n",
      "Epoch [1226/2000], Avg Val Loss: 1.8986\n",
      "Validation loss improved from 1.8988 to 1.8986. Saving model...\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3124\n",
      "Epoch [1227/2000], Avg Train Loss: 3.3124\n",
      "Epoch [1227/2000], Avg Val Loss: 1.8984\n",
      "Validation loss improved from 1.8986 to 1.8984. Saving model...\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3209\n",
      "Epoch [1228/2000], Avg Train Loss: 3.3209\n",
      "Epoch [1228/2000], Avg Val Loss: 1.8982\n",
      "Validation loss improved from 1.8984 to 1.8982. Saving model...\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3242\n",
      "Epoch [1229/2000], Avg Train Loss: 3.3242\n",
      "Epoch [1229/2000], Avg Val Loss: 1.8980\n",
      "Validation loss improved from 1.8982 to 1.8980. Saving model...\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3489\n",
      "Epoch [1230/2000], Avg Train Loss: 3.3489\n",
      "Epoch [1230/2000], Avg Val Loss: 1.8979\n",
      "Validation loss improved from 1.8980 to 1.8979. Saving model...\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3743\n",
      "Epoch [1231/2000], Avg Train Loss: 3.3743\n",
      "Epoch [1231/2000], Avg Val Loss: 1.8977\n",
      "Validation loss improved from 1.8979 to 1.8977. Saving model...\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3239\n",
      "Epoch [1232/2000], Avg Train Loss: 3.3239\n",
      "Epoch [1232/2000], Avg Val Loss: 1.8975\n",
      "Validation loss improved from 1.8977 to 1.8975. Saving model...\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3533\n",
      "Epoch [1233/2000], Avg Train Loss: 3.3533\n",
      "Epoch [1233/2000], Avg Val Loss: 1.8972\n",
      "Validation loss improved from 1.8975 to 1.8972. Saving model...\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3369\n",
      "Epoch [1234/2000], Avg Train Loss: 3.3369\n",
      "Epoch [1234/2000], Avg Val Loss: 1.8970\n",
      "Validation loss improved from 1.8972 to 1.8970. Saving model...\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3722\n",
      "Epoch [1235/2000], Avg Train Loss: 3.3722\n",
      "Epoch [1235/2000], Avg Val Loss: 1.8967\n",
      "Validation loss improved from 1.8970 to 1.8967. Saving model...\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3679\n",
      "Epoch [1236/2000], Avg Train Loss: 3.3679\n",
      "Epoch [1236/2000], Avg Val Loss: 1.8964\n",
      "Validation loss improved from 1.8967 to 1.8964. Saving model...\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3489\n",
      "Epoch [1237/2000], Avg Train Loss: 3.3489\n",
      "Epoch [1237/2000], Avg Val Loss: 1.8961\n",
      "Validation loss improved from 1.8964 to 1.8961. Saving model...\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3109\n",
      "Epoch [1238/2000], Avg Train Loss: 3.3109\n",
      "Epoch [1238/2000], Avg Val Loss: 1.8959\n",
      "Validation loss improved from 1.8961 to 1.8959. Saving model...\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4052\n",
      "Epoch [1239/2000], Avg Train Loss: 3.4052\n",
      "Epoch [1239/2000], Avg Val Loss: 1.8956\n",
      "Validation loss improved from 1.8959 to 1.8956. Saving model...\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3623\n",
      "Epoch [1240/2000], Avg Train Loss: 3.3623\n",
      "Epoch [1240/2000], Avg Val Loss: 1.8953\n",
      "Validation loss improved from 1.8956 to 1.8953. Saving model...\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3421\n",
      "Epoch [1241/2000], Avg Train Loss: 3.3421\n",
      "Epoch [1241/2000], Avg Val Loss: 1.8950\n",
      "Validation loss improved from 1.8953 to 1.8950. Saving model...\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3509\n",
      "Epoch [1242/2000], Avg Train Loss: 3.3509\n",
      "Epoch [1242/2000], Avg Val Loss: 1.8947\n",
      "Validation loss improved from 1.8950 to 1.8947. Saving model...\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3646\n",
      "Epoch [1243/2000], Avg Train Loss: 3.3646\n",
      "Epoch [1243/2000], Avg Val Loss: 1.8944\n",
      "Validation loss improved from 1.8947 to 1.8944. Saving model...\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3463\n",
      "Epoch [1244/2000], Avg Train Loss: 3.3463\n",
      "Epoch [1244/2000], Avg Val Loss: 1.8942\n",
      "Validation loss improved from 1.8944 to 1.8942. Saving model...\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3414\n",
      "Epoch [1245/2000], Avg Train Loss: 3.3414\n",
      "Epoch [1245/2000], Avg Val Loss: 1.8939\n",
      "Validation loss improved from 1.8942 to 1.8939. Saving model...\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3563\n",
      "Epoch [1246/2000], Avg Train Loss: 3.3563\n",
      "Epoch [1246/2000], Avg Val Loss: 1.8937\n",
      "Validation loss improved from 1.8939 to 1.8937. Saving model...\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3387\n",
      "Epoch [1247/2000], Avg Train Loss: 3.3387\n",
      "Epoch [1247/2000], Avg Val Loss: 1.8935\n",
      "Validation loss improved from 1.8937 to 1.8935. Saving model...\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3426\n",
      "Epoch [1248/2000], Avg Train Loss: 3.3426\n",
      "Epoch [1248/2000], Avg Val Loss: 1.8932\n",
      "Validation loss improved from 1.8935 to 1.8932. Saving model...\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3463\n",
      "Epoch [1249/2000], Avg Train Loss: 3.3463\n",
      "Epoch [1249/2000], Avg Val Loss: 1.8929\n",
      "Validation loss improved from 1.8932 to 1.8929. Saving model...\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3274\n",
      "Epoch [1250/2000], Avg Train Loss: 3.3274\n",
      "Epoch [1250/2000], Avg Val Loss: 1.8927\n",
      "Validation loss improved from 1.8929 to 1.8927. Saving model...\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3557\n",
      "Epoch [1251/2000], Avg Train Loss: 3.3557\n",
      "Epoch [1251/2000], Avg Val Loss: 1.8925\n",
      "Validation loss improved from 1.8927 to 1.8925. Saving model...\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3360\n",
      "Epoch [1252/2000], Avg Train Loss: 3.3360\n",
      "Epoch [1252/2000], Avg Val Loss: 1.8923\n",
      "Validation loss improved from 1.8925 to 1.8923. Saving model...\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3435\n",
      "Epoch [1253/2000], Avg Train Loss: 3.3435\n",
      "Epoch [1253/2000], Avg Val Loss: 1.8921\n",
      "Validation loss improved from 1.8923 to 1.8921. Saving model...\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3425\n",
      "Epoch [1254/2000], Avg Train Loss: 3.3425\n",
      "Epoch [1254/2000], Avg Val Loss: 1.8919\n",
      "Validation loss improved from 1.8921 to 1.8919. Saving model...\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3619\n",
      "Epoch [1255/2000], Avg Train Loss: 3.3619\n",
      "Epoch [1255/2000], Avg Val Loss: 1.8918\n",
      "Validation loss improved from 1.8919 to 1.8918. Saving model...\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3440\n",
      "Epoch [1256/2000], Avg Train Loss: 3.3440\n",
      "Epoch [1256/2000], Avg Val Loss: 1.8916\n",
      "Validation loss improved from 1.8918 to 1.8916. Saving model...\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3637\n",
      "Epoch [1257/2000], Avg Train Loss: 3.3637\n",
      "Epoch [1257/2000], Avg Val Loss: 1.8914\n",
      "Validation loss improved from 1.8916 to 1.8914. Saving model...\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3286\n",
      "Epoch [1258/2000], Avg Train Loss: 3.3286\n",
      "Epoch [1258/2000], Avg Val Loss: 1.8912\n",
      "Validation loss improved from 1.8914 to 1.8912. Saving model...\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3553\n",
      "Epoch [1259/2000], Avg Train Loss: 3.3553\n",
      "Epoch [1259/2000], Avg Val Loss: 1.8910\n",
      "Validation loss improved from 1.8912 to 1.8910. Saving model...\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3250\n",
      "Epoch [1260/2000], Avg Train Loss: 3.3250\n",
      "Epoch [1260/2000], Avg Val Loss: 1.8907\n",
      "Validation loss improved from 1.8910 to 1.8907. Saving model...\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3731\n",
      "Epoch [1261/2000], Avg Train Loss: 3.3731\n",
      "Epoch [1261/2000], Avg Val Loss: 1.8905\n",
      "Validation loss improved from 1.8907 to 1.8905. Saving model...\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3613\n",
      "Epoch [1262/2000], Avg Train Loss: 3.3613\n",
      "Epoch [1262/2000], Avg Val Loss: 1.8903\n",
      "Validation loss improved from 1.8905 to 1.8903. Saving model...\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3294\n",
      "Epoch [1263/2000], Avg Train Loss: 3.3294\n",
      "Epoch [1263/2000], Avg Val Loss: 1.8901\n",
      "Validation loss improved from 1.8903 to 1.8901. Saving model...\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3613\n",
      "Epoch [1264/2000], Avg Train Loss: 3.3613\n",
      "Epoch [1264/2000], Avg Val Loss: 1.8899\n",
      "Validation loss improved from 1.8901 to 1.8899. Saving model...\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3464\n",
      "Epoch [1265/2000], Avg Train Loss: 3.3464\n",
      "Epoch [1265/2000], Avg Val Loss: 1.8898\n",
      "Validation loss improved from 1.8899 to 1.8898. Saving model...\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3369\n",
      "Epoch [1266/2000], Avg Train Loss: 3.3369\n",
      "Epoch [1266/2000], Avg Val Loss: 1.8896\n",
      "Validation loss improved from 1.8898 to 1.8896. Saving model...\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3512\n",
      "Epoch [1267/2000], Avg Train Loss: 3.3512\n",
      "Epoch [1267/2000], Avg Val Loss: 1.8894\n",
      "Validation loss improved from 1.8896 to 1.8894. Saving model...\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3895\n",
      "Epoch [1268/2000], Avg Train Loss: 3.3895\n",
      "Epoch [1268/2000], Avg Val Loss: 1.8892\n",
      "Validation loss improved from 1.8894 to 1.8892. Saving model...\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3686\n",
      "Epoch [1269/2000], Avg Train Loss: 3.3686\n",
      "Epoch [1269/2000], Avg Val Loss: 1.8889\n",
      "Validation loss improved from 1.8892 to 1.8889. Saving model...\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3571\n",
      "Epoch [1270/2000], Avg Train Loss: 3.3571\n",
      "Epoch [1270/2000], Avg Val Loss: 1.8887\n",
      "Validation loss improved from 1.8889 to 1.8887. Saving model...\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3512\n",
      "Epoch [1271/2000], Avg Train Loss: 3.3512\n",
      "Epoch [1271/2000], Avg Val Loss: 1.8884\n",
      "Validation loss improved from 1.8887 to 1.8884. Saving model...\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3518\n",
      "Epoch [1272/2000], Avg Train Loss: 3.3518\n",
      "Epoch [1272/2000], Avg Val Loss: 1.8882\n",
      "Validation loss improved from 1.8884 to 1.8882. Saving model...\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3581\n",
      "Epoch [1273/2000], Avg Train Loss: 3.3581\n",
      "Epoch [1273/2000], Avg Val Loss: 1.8879\n",
      "Validation loss improved from 1.8882 to 1.8879. Saving model...\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3555\n",
      "Epoch [1274/2000], Avg Train Loss: 3.3555\n",
      "Epoch [1274/2000], Avg Val Loss: 1.8877\n",
      "Validation loss improved from 1.8879 to 1.8877. Saving model...\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3330\n",
      "Epoch [1275/2000], Avg Train Loss: 3.3330\n",
      "Epoch [1275/2000], Avg Val Loss: 1.8875\n",
      "Validation loss improved from 1.8877 to 1.8875. Saving model...\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3516\n",
      "Epoch [1276/2000], Avg Train Loss: 3.3516\n",
      "Epoch [1276/2000], Avg Val Loss: 1.8873\n",
      "Validation loss improved from 1.8875 to 1.8873. Saving model...\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3421\n",
      "Epoch [1277/2000], Avg Train Loss: 3.3421\n",
      "Epoch [1277/2000], Avg Val Loss: 1.8871\n",
      "Validation loss improved from 1.8873 to 1.8871. Saving model...\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3652\n",
      "Epoch [1278/2000], Avg Train Loss: 3.3652\n",
      "Epoch [1278/2000], Avg Val Loss: 1.8870\n",
      "Validation loss improved from 1.8871 to 1.8870. Saving model...\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3666\n",
      "Epoch [1279/2000], Avg Train Loss: 3.3666\n",
      "Epoch [1279/2000], Avg Val Loss: 1.8868\n",
      "Validation loss improved from 1.8870 to 1.8868. Saving model...\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3094\n",
      "Epoch [1280/2000], Avg Train Loss: 3.3094\n",
      "Epoch [1280/2000], Avg Val Loss: 1.8866\n",
      "Validation loss improved from 1.8868 to 1.8866. Saving model...\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3864\n",
      "Epoch [1281/2000], Avg Train Loss: 3.3864\n",
      "Epoch [1281/2000], Avg Val Loss: 1.8865\n",
      "Validation loss improved from 1.8866 to 1.8865. Saving model...\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3337\n",
      "Epoch [1282/2000], Avg Train Loss: 3.3337\n",
      "Epoch [1282/2000], Avg Val Loss: 1.8863\n",
      "Validation loss improved from 1.8865 to 1.8863. Saving model...\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3473\n",
      "Epoch [1283/2000], Avg Train Loss: 3.3473\n",
      "Epoch [1283/2000], Avg Val Loss: 1.8862\n",
      "Validation loss improved from 1.8863 to 1.8862. Saving model...\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3167\n",
      "Epoch [1284/2000], Avg Train Loss: 3.3167\n",
      "Epoch [1284/2000], Avg Val Loss: 1.8860\n",
      "Validation loss improved from 1.8862 to 1.8860. Saving model...\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3147\n",
      "Epoch [1285/2000], Avg Train Loss: 3.3147\n",
      "Epoch [1285/2000], Avg Val Loss: 1.8859\n",
      "Validation loss improved from 1.8860 to 1.8859. Saving model...\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3093\n",
      "Epoch [1286/2000], Avg Train Loss: 3.3093\n",
      "Epoch [1286/2000], Avg Val Loss: 1.8857\n",
      "Validation loss improved from 1.8859 to 1.8857. Saving model...\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3482\n",
      "Epoch [1287/2000], Avg Train Loss: 3.3482\n",
      "Epoch [1287/2000], Avg Val Loss: 1.8855\n",
      "Validation loss improved from 1.8857 to 1.8855. Saving model...\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3636\n",
      "Epoch [1288/2000], Avg Train Loss: 3.3636\n",
      "Epoch [1288/2000], Avg Val Loss: 1.8854\n",
      "Validation loss improved from 1.8855 to 1.8854. Saving model...\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3293\n",
      "Epoch [1289/2000], Avg Train Loss: 3.3293\n",
      "Epoch [1289/2000], Avg Val Loss: 1.8852\n",
      "Validation loss improved from 1.8854 to 1.8852. Saving model...\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3629\n",
      "Epoch [1290/2000], Avg Train Loss: 3.3629\n",
      "Epoch [1290/2000], Avg Val Loss: 1.8850\n",
      "Validation loss improved from 1.8852 to 1.8850. Saving model...\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3299\n",
      "Epoch [1291/2000], Avg Train Loss: 3.3299\n",
      "Epoch [1291/2000], Avg Val Loss: 1.8849\n",
      "Validation loss improved from 1.8850 to 1.8849. Saving model...\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3611\n",
      "Epoch [1292/2000], Avg Train Loss: 3.3611\n",
      "Epoch [1292/2000], Avg Val Loss: 1.8848\n",
      "Validation loss improved from 1.8849 to 1.8848. Saving model...\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3597\n",
      "Epoch [1293/2000], Avg Train Loss: 3.3597\n",
      "Epoch [1293/2000], Avg Val Loss: 1.8847\n",
      "Validation loss improved from 1.8848 to 1.8847. Saving model...\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3240\n",
      "Epoch [1294/2000], Avg Train Loss: 3.3240\n",
      "Epoch [1294/2000], Avg Val Loss: 1.8845\n",
      "Validation loss improved from 1.8847 to 1.8845. Saving model...\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3253\n",
      "Epoch [1295/2000], Avg Train Loss: 3.3253\n",
      "Epoch [1295/2000], Avg Val Loss: 1.8844\n",
      "Validation loss improved from 1.8845 to 1.8844. Saving model...\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3238\n",
      "Epoch [1296/2000], Avg Train Loss: 3.3238\n",
      "Epoch [1296/2000], Avg Val Loss: 1.8842\n",
      "Validation loss improved from 1.8844 to 1.8842. Saving model...\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3388\n",
      "Epoch [1297/2000], Avg Train Loss: 3.3388\n",
      "Epoch [1297/2000], Avg Val Loss: 1.8840\n",
      "Validation loss improved from 1.8842 to 1.8840. Saving model...\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3426\n",
      "Epoch [1298/2000], Avg Train Loss: 3.3426\n",
      "Epoch [1298/2000], Avg Val Loss: 1.8838\n",
      "Validation loss improved from 1.8840 to 1.8838. Saving model...\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3548\n",
      "Epoch [1299/2000], Avg Train Loss: 3.3548\n",
      "Epoch [1299/2000], Avg Val Loss: 1.8837\n",
      "Validation loss improved from 1.8838 to 1.8837. Saving model...\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3464\n",
      "Epoch [1300/2000], Avg Train Loss: 3.3464\n",
      "Epoch [1300/2000], Avg Val Loss: 1.8834\n",
      "Validation loss improved from 1.8837 to 1.8834. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3306\n",
      "Epoch [1301/2000], Avg Train Loss: 3.3306\n",
      "Epoch [1301/2000], Avg Val Loss: 1.8833\n",
      "Validation loss improved from 1.8834 to 1.8833. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3365\n",
      "Epoch [1302/2000], Avg Train Loss: 3.3365\n",
      "Epoch [1302/2000], Avg Val Loss: 1.8832\n",
      "Validation loss improved from 1.8833 to 1.8832. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3297\n",
      "Epoch [1303/2000], Avg Train Loss: 3.3297\n",
      "Epoch [1303/2000], Avg Val Loss: 1.8831\n",
      "Validation loss improved from 1.8832 to 1.8831. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3455\n",
      "Epoch [1304/2000], Avg Train Loss: 3.3455\n",
      "Epoch [1304/2000], Avg Val Loss: 1.8830\n",
      "Validation loss improved from 1.8831 to 1.8830. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3250\n",
      "Epoch [1305/2000], Avg Train Loss: 3.3250\n",
      "Epoch [1305/2000], Avg Val Loss: 1.8829\n",
      "Validation loss improved from 1.8830 to 1.8829. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3348\n",
      "Epoch [1306/2000], Avg Train Loss: 3.3348\n",
      "Epoch [1306/2000], Avg Val Loss: 1.8827\n",
      "Validation loss improved from 1.8829 to 1.8827. Saving model...\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3158\n",
      "Epoch [1307/2000], Avg Train Loss: 3.3158\n",
      "Epoch [1307/2000], Avg Val Loss: 1.8826\n",
      "Validation loss improved from 1.8827 to 1.8826. Saving model...\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3069\n",
      "Epoch [1308/2000], Avg Train Loss: 3.3069\n",
      "Epoch [1308/2000], Avg Val Loss: 1.8825\n",
      "Validation loss improved from 1.8826 to 1.8825. Saving model...\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3295\n",
      "Epoch [1309/2000], Avg Train Loss: 3.3295\n",
      "Epoch [1309/2000], Avg Val Loss: 1.8824\n",
      "Validation loss improved from 1.8825 to 1.8824. Saving model...\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3306\n",
      "Epoch [1310/2000], Avg Train Loss: 3.3306\n",
      "Epoch [1310/2000], Avg Val Loss: 1.8824\n",
      "Validation loss improved from 1.8824 to 1.8824. Saving model...\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3207\n",
      "Epoch [1311/2000], Avg Train Loss: 3.3207\n",
      "Epoch [1311/2000], Avg Val Loss: 1.8823\n",
      "Validation loss improved from 1.8824 to 1.8823. Saving model...\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3504\n",
      "Epoch [1312/2000], Avg Train Loss: 3.3504\n",
      "Epoch [1312/2000], Avg Val Loss: 1.8821\n",
      "Validation loss improved from 1.8823 to 1.8821. Saving model...\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3212\n",
      "Epoch [1313/2000], Avg Train Loss: 3.3212\n",
      "Epoch [1313/2000], Avg Val Loss: 1.8820\n",
      "Validation loss improved from 1.8821 to 1.8820. Saving model...\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3489\n",
      "Epoch [1314/2000], Avg Train Loss: 3.3489\n",
      "Epoch [1314/2000], Avg Val Loss: 1.8819\n",
      "Validation loss improved from 1.8820 to 1.8819. Saving model...\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3360\n",
      "Epoch [1315/2000], Avg Train Loss: 3.3360\n",
      "Epoch [1315/2000], Avg Val Loss: 1.8818\n",
      "Validation loss improved from 1.8819 to 1.8818. Saving model...\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3114\n",
      "Epoch [1316/2000], Avg Train Loss: 3.3114\n",
      "Epoch [1316/2000], Avg Val Loss: 1.8816\n",
      "Validation loss improved from 1.8818 to 1.8816. Saving model...\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3203\n",
      "Epoch [1317/2000], Avg Train Loss: 3.3203\n",
      "Epoch [1317/2000], Avg Val Loss: 1.8815\n",
      "Validation loss improved from 1.8816 to 1.8815. Saving model...\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3239\n",
      "Epoch [1318/2000], Avg Train Loss: 3.3239\n",
      "Epoch [1318/2000], Avg Val Loss: 1.8814\n",
      "Validation loss improved from 1.8815 to 1.8814. Saving model...\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3425\n",
      "Epoch [1319/2000], Avg Train Loss: 3.3425\n",
      "Epoch [1319/2000], Avg Val Loss: 1.8812\n",
      "Validation loss improved from 1.8814 to 1.8812. Saving model...\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3025\n",
      "Epoch [1320/2000], Avg Train Loss: 3.3025\n",
      "Epoch [1320/2000], Avg Val Loss: 1.8810\n",
      "Validation loss improved from 1.8812 to 1.8810. Saving model...\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3113\n",
      "Epoch [1321/2000], Avg Train Loss: 3.3113\n",
      "Epoch [1321/2000], Avg Val Loss: 1.8808\n",
      "Validation loss improved from 1.8810 to 1.8808. Saving model...\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3486\n",
      "Epoch [1322/2000], Avg Train Loss: 3.3486\n",
      "Epoch [1322/2000], Avg Val Loss: 1.8805\n",
      "Validation loss improved from 1.8808 to 1.8805. Saving model...\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2914\n",
      "Epoch [1323/2000], Avg Train Loss: 3.2914\n",
      "Epoch [1323/2000], Avg Val Loss: 1.8803\n",
      "Validation loss improved from 1.8805 to 1.8803. Saving model...\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3260\n",
      "Epoch [1324/2000], Avg Train Loss: 3.3260\n",
      "Epoch [1324/2000], Avg Val Loss: 1.8801\n",
      "Validation loss improved from 1.8803 to 1.8801. Saving model...\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3458\n",
      "Epoch [1325/2000], Avg Train Loss: 3.3458\n",
      "Epoch [1325/2000], Avg Val Loss: 1.8799\n",
      "Validation loss improved from 1.8801 to 1.8799. Saving model...\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3220\n",
      "Epoch [1326/2000], Avg Train Loss: 3.3220\n",
      "Epoch [1326/2000], Avg Val Loss: 1.8798\n",
      "Validation loss improved from 1.8799 to 1.8798. Saving model...\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2961\n",
      "Epoch [1327/2000], Avg Train Loss: 3.2961\n",
      "Epoch [1327/2000], Avg Val Loss: 1.8795\n",
      "Validation loss improved from 1.8798 to 1.8795. Saving model...\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3160\n",
      "Epoch [1328/2000], Avg Train Loss: 3.3160\n",
      "Epoch [1328/2000], Avg Val Loss: 1.8793\n",
      "Validation loss improved from 1.8795 to 1.8793. Saving model...\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3205\n",
      "Epoch [1329/2000], Avg Train Loss: 3.3205\n",
      "Epoch [1329/2000], Avg Val Loss: 1.8791\n",
      "Validation loss improved from 1.8793 to 1.8791. Saving model...\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3124\n",
      "Epoch [1330/2000], Avg Train Loss: 3.3124\n",
      "Epoch [1330/2000], Avg Val Loss: 1.8789\n",
      "Validation loss improved from 1.8791 to 1.8789. Saving model...\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3176\n",
      "Epoch [1331/2000], Avg Train Loss: 3.3176\n",
      "Epoch [1331/2000], Avg Val Loss: 1.8787\n",
      "Validation loss improved from 1.8789 to 1.8787. Saving model...\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3172\n",
      "Epoch [1332/2000], Avg Train Loss: 3.3172\n",
      "Epoch [1332/2000], Avg Val Loss: 1.8786\n",
      "Validation loss improved from 1.8787 to 1.8786. Saving model...\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3190\n",
      "Epoch [1333/2000], Avg Train Loss: 3.3190\n",
      "Epoch [1333/2000], Avg Val Loss: 1.8785\n",
      "Validation loss improved from 1.8786 to 1.8785. Saving model...\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2970\n",
      "Epoch [1334/2000], Avg Train Loss: 3.2970\n",
      "Epoch [1334/2000], Avg Val Loss: 1.8784\n",
      "Validation loss improved from 1.8785 to 1.8784. Saving model...\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3061\n",
      "Epoch [1335/2000], Avg Train Loss: 3.3061\n",
      "Epoch [1335/2000], Avg Val Loss: 1.8782\n",
      "Validation loss improved from 1.8784 to 1.8782. Saving model...\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3229\n",
      "Epoch [1336/2000], Avg Train Loss: 3.3229\n",
      "Epoch [1336/2000], Avg Val Loss: 1.8780\n",
      "Validation loss improved from 1.8782 to 1.8780. Saving model...\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3168\n",
      "Epoch [1337/2000], Avg Train Loss: 3.3168\n",
      "Epoch [1337/2000], Avg Val Loss: 1.8779\n",
      "Validation loss improved from 1.8780 to 1.8779. Saving model...\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3488\n",
      "Epoch [1338/2000], Avg Train Loss: 3.3488\n",
      "Epoch [1338/2000], Avg Val Loss: 1.8778\n",
      "Validation loss improved from 1.8779 to 1.8778. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3240\n",
      "Epoch [1339/2000], Avg Train Loss: 3.3240\n",
      "Epoch [1339/2000], Avg Val Loss: 1.8777\n",
      "Validation loss improved from 1.8778 to 1.8777. Saving model...\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3352\n",
      "Epoch [1340/2000], Avg Train Loss: 3.3352\n",
      "Epoch [1340/2000], Avg Val Loss: 1.8775\n",
      "Validation loss improved from 1.8777 to 1.8775. Saving model...\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3231\n",
      "Epoch [1341/2000], Avg Train Loss: 3.3231\n",
      "Epoch [1341/2000], Avg Val Loss: 1.8774\n",
      "Validation loss improved from 1.8775 to 1.8774. Saving model...\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3064\n",
      "Epoch [1342/2000], Avg Train Loss: 3.3064\n",
      "Epoch [1342/2000], Avg Val Loss: 1.8773\n",
      "Validation loss improved from 1.8774 to 1.8773. Saving model...\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3156\n",
      "Epoch [1343/2000], Avg Train Loss: 3.3156\n",
      "Epoch [1343/2000], Avg Val Loss: 1.8771\n",
      "Validation loss improved from 1.8773 to 1.8771. Saving model...\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3419\n",
      "Epoch [1344/2000], Avg Train Loss: 3.3419\n",
      "Epoch [1344/2000], Avg Val Loss: 1.8770\n",
      "Validation loss improved from 1.8771 to 1.8770. Saving model...\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3122\n",
      "Epoch [1345/2000], Avg Train Loss: 3.3122\n",
      "Epoch [1345/2000], Avg Val Loss: 1.8769\n",
      "Validation loss improved from 1.8770 to 1.8769. Saving model...\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3135\n",
      "Epoch [1346/2000], Avg Train Loss: 3.3135\n",
      "Epoch [1346/2000], Avg Val Loss: 1.8769\n",
      "Validation loss improved from 1.8769 to 1.8769. Saving model...\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3371\n",
      "Epoch [1347/2000], Avg Train Loss: 3.3371\n",
      "Epoch [1347/2000], Avg Val Loss: 1.8768\n",
      "Validation loss improved from 1.8769 to 1.8768. Saving model...\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3534\n",
      "Epoch [1348/2000], Avg Train Loss: 3.3534\n",
      "Epoch [1348/2000], Avg Val Loss: 1.8767\n",
      "Validation loss improved from 1.8768 to 1.8767. Saving model...\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3189\n",
      "Epoch [1349/2000], Avg Train Loss: 3.3189\n",
      "Epoch [1349/2000], Avg Val Loss: 1.8765\n",
      "Validation loss improved from 1.8767 to 1.8765. Saving model...\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3154\n",
      "Epoch [1350/2000], Avg Train Loss: 3.3154\n",
      "Epoch [1350/2000], Avg Val Loss: 1.8763\n",
      "Validation loss improved from 1.8765 to 1.8763. Saving model...\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3171\n",
      "Epoch [1351/2000], Avg Train Loss: 3.3171\n",
      "Epoch [1351/2000], Avg Val Loss: 1.8762\n",
      "Validation loss improved from 1.8763 to 1.8762. Saving model...\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2988\n",
      "Epoch [1352/2000], Avg Train Loss: 3.2988\n",
      "Epoch [1352/2000], Avg Val Loss: 1.8760\n",
      "Validation loss improved from 1.8762 to 1.8760. Saving model...\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3089\n",
      "Epoch [1353/2000], Avg Train Loss: 3.3089\n",
      "Epoch [1353/2000], Avg Val Loss: 1.8758\n",
      "Validation loss improved from 1.8760 to 1.8758. Saving model...\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3210\n",
      "Epoch [1354/2000], Avg Train Loss: 3.3210\n",
      "Epoch [1354/2000], Avg Val Loss: 1.8757\n",
      "Validation loss improved from 1.8758 to 1.8757. Saving model...\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3499\n",
      "Epoch [1355/2000], Avg Train Loss: 3.3499\n",
      "Epoch [1355/2000], Avg Val Loss: 1.8755\n",
      "Validation loss improved from 1.8757 to 1.8755. Saving model...\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2915\n",
      "Epoch [1356/2000], Avg Train Loss: 3.2915\n",
      "Epoch [1356/2000], Avg Val Loss: 1.8753\n",
      "Validation loss improved from 1.8755 to 1.8753. Saving model...\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2989\n",
      "Epoch [1357/2000], Avg Train Loss: 3.2989\n",
      "Epoch [1357/2000], Avg Val Loss: 1.8751\n",
      "Validation loss improved from 1.8753 to 1.8751. Saving model...\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3324\n",
      "Epoch [1358/2000], Avg Train Loss: 3.3324\n",
      "Epoch [1358/2000], Avg Val Loss: 1.8749\n",
      "Validation loss improved from 1.8751 to 1.8749. Saving model...\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2942\n",
      "Epoch [1359/2000], Avg Train Loss: 3.2942\n",
      "Epoch [1359/2000], Avg Val Loss: 1.8747\n",
      "Validation loss improved from 1.8749 to 1.8747. Saving model...\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3285\n",
      "Epoch [1360/2000], Avg Train Loss: 3.3285\n",
      "Epoch [1360/2000], Avg Val Loss: 1.8746\n",
      "Validation loss improved from 1.8747 to 1.8746. Saving model...\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2992\n",
      "Epoch [1361/2000], Avg Train Loss: 3.2992\n",
      "Epoch [1361/2000], Avg Val Loss: 1.8744\n",
      "Validation loss improved from 1.8746 to 1.8744. Saving model...\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3118\n",
      "Epoch [1362/2000], Avg Train Loss: 3.3118\n",
      "Epoch [1362/2000], Avg Val Loss: 1.8742\n",
      "Validation loss improved from 1.8744 to 1.8742. Saving model...\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3300\n",
      "Epoch [1363/2000], Avg Train Loss: 3.3300\n",
      "Epoch [1363/2000], Avg Val Loss: 1.8740\n",
      "Validation loss improved from 1.8742 to 1.8740. Saving model...\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3208\n",
      "Epoch [1364/2000], Avg Train Loss: 3.3208\n",
      "Epoch [1364/2000], Avg Val Loss: 1.8739\n",
      "Validation loss improved from 1.8740 to 1.8739. Saving model...\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3418\n",
      "Epoch [1365/2000], Avg Train Loss: 3.3418\n",
      "Epoch [1365/2000], Avg Val Loss: 1.8737\n",
      "Validation loss improved from 1.8739 to 1.8737. Saving model...\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3123\n",
      "Epoch [1366/2000], Avg Train Loss: 3.3123\n",
      "Epoch [1366/2000], Avg Val Loss: 1.8735\n",
      "Validation loss improved from 1.8737 to 1.8735. Saving model...\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3086\n",
      "Epoch [1367/2000], Avg Train Loss: 3.3086\n",
      "Epoch [1367/2000], Avg Val Loss: 1.8733\n",
      "Validation loss improved from 1.8735 to 1.8733. Saving model...\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2781\n",
      "Epoch [1368/2000], Avg Train Loss: 3.2781\n",
      "Epoch [1368/2000], Avg Val Loss: 1.8731\n",
      "Validation loss improved from 1.8733 to 1.8731. Saving model...\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3085\n",
      "Epoch [1369/2000], Avg Train Loss: 3.3085\n",
      "Epoch [1369/2000], Avg Val Loss: 1.8728\n",
      "Validation loss improved from 1.8731 to 1.8728. Saving model...\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3187\n",
      "Epoch [1370/2000], Avg Train Loss: 3.3187\n",
      "Epoch [1370/2000], Avg Val Loss: 1.8726\n",
      "Validation loss improved from 1.8728 to 1.8726. Saving model...\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3228\n",
      "Epoch [1371/2000], Avg Train Loss: 3.3228\n",
      "Epoch [1371/2000], Avg Val Loss: 1.8724\n",
      "Validation loss improved from 1.8726 to 1.8724. Saving model...\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3132\n",
      "Epoch [1372/2000], Avg Train Loss: 3.3132\n",
      "Epoch [1372/2000], Avg Val Loss: 1.8722\n",
      "Validation loss improved from 1.8724 to 1.8722. Saving model...\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3327\n",
      "Epoch [1373/2000], Avg Train Loss: 3.3327\n",
      "Epoch [1373/2000], Avg Val Loss: 1.8719\n",
      "Validation loss improved from 1.8722 to 1.8719. Saving model...\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2954\n",
      "Epoch [1374/2000], Avg Train Loss: 3.2954\n",
      "Epoch [1374/2000], Avg Val Loss: 1.8717\n",
      "Validation loss improved from 1.8719 to 1.8717. Saving model...\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3190\n",
      "Epoch [1375/2000], Avg Train Loss: 3.3190\n",
      "Epoch [1375/2000], Avg Val Loss: 1.8715\n",
      "Validation loss improved from 1.8717 to 1.8715. Saving model...\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3317\n",
      "Epoch [1376/2000], Avg Train Loss: 3.3317\n",
      "Epoch [1376/2000], Avg Val Loss: 1.8713\n",
      "Validation loss improved from 1.8715 to 1.8713. Saving model...\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3363\n",
      "Epoch [1377/2000], Avg Train Loss: 3.3363\n",
      "Epoch [1377/2000], Avg Val Loss: 1.8712\n",
      "Validation loss improved from 1.8713 to 1.8712. Saving model...\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3421\n",
      "Epoch [1378/2000], Avg Train Loss: 3.3421\n",
      "Epoch [1378/2000], Avg Val Loss: 1.8711\n",
      "Validation loss improved from 1.8712 to 1.8711. Saving model...\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2752\n",
      "Epoch [1379/2000], Avg Train Loss: 3.2752\n",
      "Epoch [1379/2000], Avg Val Loss: 1.8709\n",
      "Validation loss improved from 1.8711 to 1.8709. Saving model...\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3178\n",
      "Epoch [1380/2000], Avg Train Loss: 3.3178\n",
      "Epoch [1380/2000], Avg Val Loss: 1.8707\n",
      "Validation loss improved from 1.8709 to 1.8707. Saving model...\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3035\n",
      "Epoch [1381/2000], Avg Train Loss: 3.3035\n",
      "Epoch [1381/2000], Avg Val Loss: 1.8705\n",
      "Validation loss improved from 1.8707 to 1.8705. Saving model...\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3197\n",
      "Epoch [1382/2000], Avg Train Loss: 3.3197\n",
      "Epoch [1382/2000], Avg Val Loss: 1.8704\n",
      "Validation loss improved from 1.8705 to 1.8704. Saving model...\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3408\n",
      "Epoch [1383/2000], Avg Train Loss: 3.3408\n",
      "Epoch [1383/2000], Avg Val Loss: 1.8702\n",
      "Validation loss improved from 1.8704 to 1.8702. Saving model...\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3136\n",
      "Epoch [1384/2000], Avg Train Loss: 3.3136\n",
      "Epoch [1384/2000], Avg Val Loss: 1.8700\n",
      "Validation loss improved from 1.8702 to 1.8700. Saving model...\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3234\n",
      "Epoch [1385/2000], Avg Train Loss: 3.3234\n",
      "Epoch [1385/2000], Avg Val Loss: 1.8698\n",
      "Validation loss improved from 1.8700 to 1.8698. Saving model...\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2965\n",
      "Epoch [1386/2000], Avg Train Loss: 3.2965\n",
      "Epoch [1386/2000], Avg Val Loss: 1.8696\n",
      "Validation loss improved from 1.8698 to 1.8696. Saving model...\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2939\n",
      "Epoch [1387/2000], Avg Train Loss: 3.2939\n",
      "Epoch [1387/2000], Avg Val Loss: 1.8694\n",
      "Validation loss improved from 1.8696 to 1.8694. Saving model...\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3085\n",
      "Epoch [1388/2000], Avg Train Loss: 3.3085\n",
      "Epoch [1388/2000], Avg Val Loss: 1.8692\n",
      "Validation loss improved from 1.8694 to 1.8692. Saving model...\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3271\n",
      "Epoch [1389/2000], Avg Train Loss: 3.3271\n",
      "Epoch [1389/2000], Avg Val Loss: 1.8690\n",
      "Validation loss improved from 1.8692 to 1.8690. Saving model...\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3497\n",
      "Epoch [1390/2000], Avg Train Loss: 3.3497\n",
      "Epoch [1390/2000], Avg Val Loss: 1.8687\n",
      "Validation loss improved from 1.8690 to 1.8687. Saving model...\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3455\n",
      "Epoch [1391/2000], Avg Train Loss: 3.3455\n",
      "Epoch [1391/2000], Avg Val Loss: 1.8685\n",
      "Validation loss improved from 1.8687 to 1.8685. Saving model...\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3069\n",
      "Epoch [1392/2000], Avg Train Loss: 3.3069\n",
      "Epoch [1392/2000], Avg Val Loss: 1.8683\n",
      "Validation loss improved from 1.8685 to 1.8683. Saving model...\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3030\n",
      "Epoch [1393/2000], Avg Train Loss: 3.3030\n",
      "Epoch [1393/2000], Avg Val Loss: 1.8681\n",
      "Validation loss improved from 1.8683 to 1.8681. Saving model...\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2961\n",
      "Epoch [1394/2000], Avg Train Loss: 3.2961\n",
      "Epoch [1394/2000], Avg Val Loss: 1.8680\n",
      "Validation loss improved from 1.8681 to 1.8680. Saving model...\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3308\n",
      "Epoch [1395/2000], Avg Train Loss: 3.3308\n",
      "Epoch [1395/2000], Avg Val Loss: 1.8678\n",
      "Validation loss improved from 1.8680 to 1.8678. Saving model...\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2819\n",
      "Epoch [1396/2000], Avg Train Loss: 3.2819\n",
      "Epoch [1396/2000], Avg Val Loss: 1.8678\n",
      "Validation loss improved from 1.8678 to 1.8678. Saving model...\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3509\n",
      "Epoch [1397/2000], Avg Train Loss: 3.3509\n",
      "Epoch [1397/2000], Avg Val Loss: 1.8676\n",
      "Validation loss improved from 1.8678 to 1.8676. Saving model...\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3151\n",
      "Epoch [1398/2000], Avg Train Loss: 3.3151\n",
      "Epoch [1398/2000], Avg Val Loss: 1.8676\n",
      "Validation loss improved from 1.8676 to 1.8676. Saving model...\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2852\n",
      "Epoch [1399/2000], Avg Train Loss: 3.2852\n",
      "Epoch [1399/2000], Avg Val Loss: 1.8675\n",
      "Validation loss improved from 1.8676 to 1.8675. Saving model...\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3137\n",
      "Epoch [1400/2000], Avg Train Loss: 3.3137\n",
      "Epoch [1400/2000], Avg Val Loss: 1.8675\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3113\n",
      "Epoch [1401/2000], Avg Train Loss: 3.3113\n",
      "Epoch [1401/2000], Avg Val Loss: 1.8675\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2917\n",
      "Epoch [1402/2000], Avg Train Loss: 3.2917\n",
      "Epoch [1402/2000], Avg Val Loss: 1.8676\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3045\n",
      "Epoch [1403/2000], Avg Train Loss: 3.3045\n",
      "Epoch [1403/2000], Avg Val Loss: 1.8676\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3479\n",
      "Epoch [1404/2000], Avg Train Loss: 3.3479\n",
      "Epoch [1404/2000], Avg Val Loss: 1.8677\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3086\n",
      "Epoch [1405/2000], Avg Train Loss: 3.3086\n",
      "Epoch [1405/2000], Avg Val Loss: 1.8677\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3059\n",
      "Epoch [1406/2000], Avg Train Loss: 3.3059\n",
      "Epoch [1406/2000], Avg Val Loss: 1.8678\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3101\n",
      "Epoch [1407/2000], Avg Train Loss: 3.3101\n",
      "Epoch [1407/2000], Avg Val Loss: 1.8678\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3287\n",
      "Epoch [1408/2000], Avg Train Loss: 3.3287\n",
      "Epoch [1408/2000], Avg Val Loss: 1.8678\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3135\n",
      "Epoch [1409/2000], Avg Train Loss: 3.3135\n",
      "Epoch [1409/2000], Avg Val Loss: 1.8679\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3100\n",
      "Epoch [1410/2000], Avg Train Loss: 3.3100\n",
      "Epoch [1410/2000], Avg Val Loss: 1.8680\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3071\n",
      "Epoch [1411/2000], Avg Train Loss: 3.3071\n",
      "Epoch [1411/2000], Avg Val Loss: 1.8680\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3537\n",
      "Epoch [1412/2000], Avg Train Loss: 3.3537\n",
      "Epoch [1412/2000], Avg Val Loss: 1.8681\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3109\n",
      "Epoch [1413/2000], Avg Train Loss: 3.3109\n",
      "Epoch [1413/2000], Avg Val Loss: 1.8681\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3371\n",
      "Epoch [1414/2000], Avg Train Loss: 3.3371\n",
      "Epoch [1414/2000], Avg Val Loss: 1.8681\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3395\n",
      "Epoch [1415/2000], Avg Train Loss: 3.3395\n",
      "Epoch [1415/2000], Avg Val Loss: 1.8681\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3106\n",
      "Epoch [1416/2000], Avg Train Loss: 3.3106\n",
      "Epoch [1416/2000], Avg Val Loss: 1.8680\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3113\n",
      "Epoch [1417/2000], Avg Train Loss: 3.3113\n",
      "Epoch [1417/2000], Avg Val Loss: 1.8680\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2946\n",
      "Epoch [1418/2000], Avg Train Loss: 3.2946\n",
      "Epoch [1418/2000], Avg Val Loss: 1.8679\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2868\n",
      "Epoch [1419/2000], Avg Train Loss: 3.2868\n",
      "Epoch [1419/2000], Avg Val Loss: 1.8677\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3217\n",
      "Epoch [1420/2000], Avg Train Loss: 3.3217\n",
      "Epoch [1420/2000], Avg Val Loss: 1.8675\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3074\n",
      "Epoch [1421/2000], Avg Train Loss: 3.3074\n",
      "Epoch [1421/2000], Avg Val Loss: 1.8673\n",
      "Validation loss improved from 1.8675 to 1.8673. Saving model...\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2886\n",
      "Epoch [1422/2000], Avg Train Loss: 3.2886\n",
      "Epoch [1422/2000], Avg Val Loss: 1.8672\n",
      "Validation loss improved from 1.8673 to 1.8672. Saving model...\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3341\n",
      "Epoch [1423/2000], Avg Train Loss: 3.3341\n",
      "Epoch [1423/2000], Avg Val Loss: 1.8670\n",
      "Validation loss improved from 1.8672 to 1.8670. Saving model...\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3013\n",
      "Epoch [1424/2000], Avg Train Loss: 3.3013\n",
      "Epoch [1424/2000], Avg Val Loss: 1.8669\n",
      "Validation loss improved from 1.8670 to 1.8669. Saving model...\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2931\n",
      "Epoch [1425/2000], Avg Train Loss: 3.2931\n",
      "Epoch [1425/2000], Avg Val Loss: 1.8667\n",
      "Validation loss improved from 1.8669 to 1.8667. Saving model...\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3323\n",
      "Epoch [1426/2000], Avg Train Loss: 3.3323\n",
      "Epoch [1426/2000], Avg Val Loss: 1.8665\n",
      "Validation loss improved from 1.8667 to 1.8665. Saving model...\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3253\n",
      "Epoch [1427/2000], Avg Train Loss: 3.3253\n",
      "Epoch [1427/2000], Avg Val Loss: 1.8664\n",
      "Validation loss improved from 1.8665 to 1.8664. Saving model...\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3006\n",
      "Epoch [1428/2000], Avg Train Loss: 3.3006\n",
      "Epoch [1428/2000], Avg Val Loss: 1.8662\n",
      "Validation loss improved from 1.8664 to 1.8662. Saving model...\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3014\n",
      "Epoch [1429/2000], Avg Train Loss: 3.3014\n",
      "Epoch [1429/2000], Avg Val Loss: 1.8660\n",
      "Validation loss improved from 1.8662 to 1.8660. Saving model...\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3219\n",
      "Epoch [1430/2000], Avg Train Loss: 3.3219\n",
      "Epoch [1430/2000], Avg Val Loss: 1.8658\n",
      "Validation loss improved from 1.8660 to 1.8658. Saving model...\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3005\n",
      "Epoch [1431/2000], Avg Train Loss: 3.3005\n",
      "Epoch [1431/2000], Avg Val Loss: 1.8656\n",
      "Validation loss improved from 1.8658 to 1.8656. Saving model...\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3317\n",
      "Epoch [1432/2000], Avg Train Loss: 3.3317\n",
      "Epoch [1432/2000], Avg Val Loss: 1.8655\n",
      "Validation loss improved from 1.8656 to 1.8655. Saving model...\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3264\n",
      "Epoch [1433/2000], Avg Train Loss: 3.3264\n",
      "Epoch [1433/2000], Avg Val Loss: 1.8653\n",
      "Validation loss improved from 1.8655 to 1.8653. Saving model...\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3166\n",
      "Epoch [1434/2000], Avg Train Loss: 3.3166\n",
      "Epoch [1434/2000], Avg Val Loss: 1.8651\n",
      "Validation loss improved from 1.8653 to 1.8651. Saving model...\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3086\n",
      "Epoch [1435/2000], Avg Train Loss: 3.3086\n",
      "Epoch [1435/2000], Avg Val Loss: 1.8650\n",
      "Validation loss improved from 1.8651 to 1.8650. Saving model...\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2959\n",
      "Epoch [1436/2000], Avg Train Loss: 3.2959\n",
      "Epoch [1436/2000], Avg Val Loss: 1.8649\n",
      "Validation loss improved from 1.8650 to 1.8649. Saving model...\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3041\n",
      "Epoch [1437/2000], Avg Train Loss: 3.3041\n",
      "Epoch [1437/2000], Avg Val Loss: 1.8647\n",
      "Validation loss improved from 1.8649 to 1.8647. Saving model...\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3156\n",
      "Epoch [1438/2000], Avg Train Loss: 3.3156\n",
      "Epoch [1438/2000], Avg Val Loss: 1.8647\n",
      "Validation loss improved from 1.8647 to 1.8647. Saving model...\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3131\n",
      "Epoch [1439/2000], Avg Train Loss: 3.3131\n",
      "Epoch [1439/2000], Avg Val Loss: 1.8646\n",
      "Validation loss improved from 1.8647 to 1.8646. Saving model...\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3127\n",
      "Epoch [1440/2000], Avg Train Loss: 3.3127\n",
      "Epoch [1440/2000], Avg Val Loss: 1.8644\n",
      "Validation loss improved from 1.8646 to 1.8644. Saving model...\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3236\n",
      "Epoch [1441/2000], Avg Train Loss: 3.3236\n",
      "Epoch [1441/2000], Avg Val Loss: 1.8643\n",
      "Validation loss improved from 1.8644 to 1.8643. Saving model...\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3129\n",
      "Epoch [1442/2000], Avg Train Loss: 3.3129\n",
      "Epoch [1442/2000], Avg Val Loss: 1.8642\n",
      "Validation loss improved from 1.8643 to 1.8642. Saving model...\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2830\n",
      "Epoch [1443/2000], Avg Train Loss: 3.2830\n",
      "Epoch [1443/2000], Avg Val Loss: 1.8641\n",
      "Validation loss improved from 1.8642 to 1.8641. Saving model...\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3385\n",
      "Epoch [1444/2000], Avg Train Loss: 3.3385\n",
      "Epoch [1444/2000], Avg Val Loss: 1.8639\n",
      "Validation loss improved from 1.8641 to 1.8639. Saving model...\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3016\n",
      "Epoch [1445/2000], Avg Train Loss: 3.3016\n",
      "Epoch [1445/2000], Avg Val Loss: 1.8639\n",
      "Validation loss improved from 1.8639 to 1.8639. Saving model...\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3072\n",
      "Epoch [1446/2000], Avg Train Loss: 3.3072\n",
      "Epoch [1446/2000], Avg Val Loss: 1.8638\n",
      "Validation loss improved from 1.8639 to 1.8638. Saving model...\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2804\n",
      "Epoch [1447/2000], Avg Train Loss: 3.2804\n",
      "Epoch [1447/2000], Avg Val Loss: 1.8637\n",
      "Validation loss improved from 1.8638 to 1.8637. Saving model...\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3215\n",
      "Epoch [1448/2000], Avg Train Loss: 3.3215\n",
      "Epoch [1448/2000], Avg Val Loss: 1.8636\n",
      "Validation loss improved from 1.8637 to 1.8636. Saving model...\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3000\n",
      "Epoch [1449/2000], Avg Train Loss: 3.3000\n",
      "Epoch [1449/2000], Avg Val Loss: 1.8636\n",
      "Validation loss improved from 1.8636 to 1.8636. Saving model...\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2928\n",
      "Epoch [1450/2000], Avg Train Loss: 3.2928\n",
      "Epoch [1450/2000], Avg Val Loss: 1.8636\n",
      "Validation loss improved from 1.8636 to 1.8636. Saving model...\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3359\n",
      "Epoch [1451/2000], Avg Train Loss: 3.3359\n",
      "Epoch [1451/2000], Avg Val Loss: 1.8635\n",
      "Validation loss improved from 1.8636 to 1.8635. Saving model...\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2996\n",
      "Epoch [1452/2000], Avg Train Loss: 3.2996\n",
      "Epoch [1452/2000], Avg Val Loss: 1.8635\n",
      "Validation loss improved from 1.8635 to 1.8635. Saving model...\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3026\n",
      "Epoch [1453/2000], Avg Train Loss: 3.3026\n",
      "Epoch [1453/2000], Avg Val Loss: 1.8635\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2768\n",
      "Epoch [1454/2000], Avg Train Loss: 3.2768\n",
      "Epoch [1454/2000], Avg Val Loss: 1.8635\n",
      "Validation loss improved from 1.8635 to 1.8635. Saving model...\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3048\n",
      "Epoch [1455/2000], Avg Train Loss: 3.3048\n",
      "Epoch [1455/2000], Avg Val Loss: 1.8634\n",
      "Validation loss improved from 1.8635 to 1.8634. Saving model...\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3383\n",
      "Epoch [1456/2000], Avg Train Loss: 3.3383\n",
      "Epoch [1456/2000], Avg Val Loss: 1.8632\n",
      "Validation loss improved from 1.8634 to 1.8632. Saving model...\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3248\n",
      "Epoch [1457/2000], Avg Train Loss: 3.3248\n",
      "Epoch [1457/2000], Avg Val Loss: 1.8631\n",
      "Validation loss improved from 1.8632 to 1.8631. Saving model...\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3133\n",
      "Epoch [1458/2000], Avg Train Loss: 3.3133\n",
      "Epoch [1458/2000], Avg Val Loss: 1.8629\n",
      "Validation loss improved from 1.8631 to 1.8629. Saving model...\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2706\n",
      "Epoch [1459/2000], Avg Train Loss: 3.2706\n",
      "Epoch [1459/2000], Avg Val Loss: 1.8628\n",
      "Validation loss improved from 1.8629 to 1.8628. Saving model...\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3336\n",
      "Epoch [1460/2000], Avg Train Loss: 3.3336\n",
      "Epoch [1460/2000], Avg Val Loss: 1.8627\n",
      "Validation loss improved from 1.8628 to 1.8627. Saving model...\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3198\n",
      "Epoch [1461/2000], Avg Train Loss: 3.3198\n",
      "Epoch [1461/2000], Avg Val Loss: 1.8626\n",
      "Validation loss improved from 1.8627 to 1.8626. Saving model...\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3181\n",
      "Epoch [1462/2000], Avg Train Loss: 3.3181\n",
      "Epoch [1462/2000], Avg Val Loss: 1.8624\n",
      "Validation loss improved from 1.8626 to 1.8624. Saving model...\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2956\n",
      "Epoch [1463/2000], Avg Train Loss: 3.2956\n",
      "Epoch [1463/2000], Avg Val Loss: 1.8623\n",
      "Validation loss improved from 1.8624 to 1.8623. Saving model...\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3112\n",
      "Epoch [1464/2000], Avg Train Loss: 3.3112\n",
      "Epoch [1464/2000], Avg Val Loss: 1.8621\n",
      "Validation loss improved from 1.8623 to 1.8621. Saving model...\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2855\n",
      "Epoch [1465/2000], Avg Train Loss: 3.2855\n",
      "Epoch [1465/2000], Avg Val Loss: 1.8619\n",
      "Validation loss improved from 1.8621 to 1.8619. Saving model...\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3134\n",
      "Epoch [1466/2000], Avg Train Loss: 3.3134\n",
      "Epoch [1466/2000], Avg Val Loss: 1.8618\n",
      "Validation loss improved from 1.8619 to 1.8618. Saving model...\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2841\n",
      "Epoch [1467/2000], Avg Train Loss: 3.2841\n",
      "Epoch [1467/2000], Avg Val Loss: 1.8617\n",
      "Validation loss improved from 1.8618 to 1.8617. Saving model...\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3111\n",
      "Epoch [1468/2000], Avg Train Loss: 3.3111\n",
      "Epoch [1468/2000], Avg Val Loss: 1.8615\n",
      "Validation loss improved from 1.8617 to 1.8615. Saving model...\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3115\n",
      "Epoch [1469/2000], Avg Train Loss: 3.3115\n",
      "Epoch [1469/2000], Avg Val Loss: 1.8614\n",
      "Validation loss improved from 1.8615 to 1.8614. Saving model...\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3355\n",
      "Epoch [1470/2000], Avg Train Loss: 3.3355\n",
      "Epoch [1470/2000], Avg Val Loss: 1.8613\n",
      "Validation loss improved from 1.8614 to 1.8613. Saving model...\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2900\n",
      "Epoch [1471/2000], Avg Train Loss: 3.2900\n",
      "Epoch [1471/2000], Avg Val Loss: 1.8611\n",
      "Validation loss improved from 1.8613 to 1.8611. Saving model...\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2847\n",
      "Epoch [1472/2000], Avg Train Loss: 3.2847\n",
      "Epoch [1472/2000], Avg Val Loss: 1.8609\n",
      "Validation loss improved from 1.8611 to 1.8609. Saving model...\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3093\n",
      "Epoch [1473/2000], Avg Train Loss: 3.3093\n",
      "Epoch [1473/2000], Avg Val Loss: 1.8607\n",
      "Validation loss improved from 1.8609 to 1.8607. Saving model...\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2988\n",
      "Epoch [1474/2000], Avg Train Loss: 3.2988\n",
      "Epoch [1474/2000], Avg Val Loss: 1.8606\n",
      "Validation loss improved from 1.8607 to 1.8606. Saving model...\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2654\n",
      "Epoch [1475/2000], Avg Train Loss: 3.2654\n",
      "Epoch [1475/2000], Avg Val Loss: 1.8604\n",
      "Validation loss improved from 1.8606 to 1.8604. Saving model...\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3097\n",
      "Epoch [1476/2000], Avg Train Loss: 3.3097\n",
      "Epoch [1476/2000], Avg Val Loss: 1.8603\n",
      "Validation loss improved from 1.8604 to 1.8603. Saving model...\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3113\n",
      "Epoch [1477/2000], Avg Train Loss: 3.3113\n",
      "Epoch [1477/2000], Avg Val Loss: 1.8601\n",
      "Validation loss improved from 1.8603 to 1.8601. Saving model...\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3096\n",
      "Epoch [1478/2000], Avg Train Loss: 3.3096\n",
      "Epoch [1478/2000], Avg Val Loss: 1.8600\n",
      "Validation loss improved from 1.8601 to 1.8600. Saving model...\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2605\n",
      "Epoch [1479/2000], Avg Train Loss: 3.2605\n",
      "Epoch [1479/2000], Avg Val Loss: 1.8598\n",
      "Validation loss improved from 1.8600 to 1.8598. Saving model...\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2677\n",
      "Epoch [1480/2000], Avg Train Loss: 3.2677\n",
      "Epoch [1480/2000], Avg Val Loss: 1.8597\n",
      "Validation loss improved from 1.8598 to 1.8597. Saving model...\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2814\n",
      "Epoch [1481/2000], Avg Train Loss: 3.2814\n",
      "Epoch [1481/2000], Avg Val Loss: 1.8596\n",
      "Validation loss improved from 1.8597 to 1.8596. Saving model...\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2787\n",
      "Epoch [1482/2000], Avg Train Loss: 3.2787\n",
      "Epoch [1482/2000], Avg Val Loss: 1.8595\n",
      "Validation loss improved from 1.8596 to 1.8595. Saving model...\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2691\n",
      "Epoch [1483/2000], Avg Train Loss: 3.2691\n",
      "Epoch [1483/2000], Avg Val Loss: 1.8595\n",
      "Validation loss improved from 1.8595 to 1.8595. Saving model...\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2885\n",
      "Epoch [1484/2000], Avg Train Loss: 3.2885\n",
      "Epoch [1484/2000], Avg Val Loss: 1.8594\n",
      "Validation loss improved from 1.8595 to 1.8594. Saving model...\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2825\n",
      "Epoch [1485/2000], Avg Train Loss: 3.2825\n",
      "Epoch [1485/2000], Avg Val Loss: 1.8594\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3219\n",
      "Epoch [1486/2000], Avg Train Loss: 3.3219\n",
      "Epoch [1486/2000], Avg Val Loss: 1.8595\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3222\n",
      "Epoch [1487/2000], Avg Train Loss: 3.3222\n",
      "Epoch [1487/2000], Avg Val Loss: 1.8595\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2890\n",
      "Epoch [1488/2000], Avg Train Loss: 3.2890\n",
      "Epoch [1488/2000], Avg Val Loss: 1.8596\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2856\n",
      "Epoch [1489/2000], Avg Train Loss: 3.2856\n",
      "Epoch [1489/2000], Avg Val Loss: 1.8597\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2622\n",
      "Epoch [1490/2000], Avg Train Loss: 3.2622\n",
      "Epoch [1490/2000], Avg Val Loss: 1.8597\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2988\n",
      "Epoch [1491/2000], Avg Train Loss: 3.2988\n",
      "Epoch [1491/2000], Avg Val Loss: 1.8598\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3248\n",
      "Epoch [1492/2000], Avg Train Loss: 3.3248\n",
      "Epoch [1492/2000], Avg Val Loss: 1.8598\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2901\n",
      "Epoch [1493/2000], Avg Train Loss: 3.2901\n",
      "Epoch [1493/2000], Avg Val Loss: 1.8598\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2841\n",
      "Epoch [1494/2000], Avg Train Loss: 3.2841\n",
      "Epoch [1494/2000], Avg Val Loss: 1.8599\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2762\n",
      "Epoch [1495/2000], Avg Train Loss: 3.2762\n",
      "Epoch [1495/2000], Avg Val Loss: 1.8599\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2977\n",
      "Epoch [1496/2000], Avg Train Loss: 3.2977\n",
      "Epoch [1496/2000], Avg Val Loss: 1.8598\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3387\n",
      "Epoch [1497/2000], Avg Train Loss: 3.3387\n",
      "Epoch [1497/2000], Avg Val Loss: 1.8598\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2846\n",
      "Epoch [1498/2000], Avg Train Loss: 3.2846\n",
      "Epoch [1498/2000], Avg Val Loss: 1.8597\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3077\n",
      "Epoch [1499/2000], Avg Train Loss: 3.3077\n",
      "Epoch [1499/2000], Avg Val Loss: 1.8596\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2888\n",
      "Epoch [1500/2000], Avg Train Loss: 3.2888\n",
      "Epoch [1500/2000], Avg Val Loss: 1.8595\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2585\n",
      "Epoch [1501/2000], Avg Train Loss: 3.2585\n",
      "Epoch [1501/2000], Avg Val Loss: 1.8593\n",
      "Validation loss improved from 1.8594 to 1.8593. Saving model...\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2609\n",
      "Epoch [1502/2000], Avg Train Loss: 3.2609\n",
      "Epoch [1502/2000], Avg Val Loss: 1.8592\n",
      "Validation loss improved from 1.8593 to 1.8592. Saving model...\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2895\n",
      "Epoch [1503/2000], Avg Train Loss: 3.2895\n",
      "Epoch [1503/2000], Avg Val Loss: 1.8591\n",
      "Validation loss improved from 1.8592 to 1.8591. Saving model...\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3219\n",
      "Epoch [1504/2000], Avg Train Loss: 3.3219\n",
      "Epoch [1504/2000], Avg Val Loss: 1.8589\n",
      "Validation loss improved from 1.8591 to 1.8589. Saving model...\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3149\n",
      "Epoch [1505/2000], Avg Train Loss: 3.3149\n",
      "Epoch [1505/2000], Avg Val Loss: 1.8588\n",
      "Validation loss improved from 1.8589 to 1.8588. Saving model...\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3120\n",
      "Epoch [1506/2000], Avg Train Loss: 3.3120\n",
      "Epoch [1506/2000], Avg Val Loss: 1.8586\n",
      "Validation loss improved from 1.8588 to 1.8586. Saving model...\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2849\n",
      "Epoch [1507/2000], Avg Train Loss: 3.2849\n",
      "Epoch [1507/2000], Avg Val Loss: 1.8585\n",
      "Validation loss improved from 1.8586 to 1.8585. Saving model...\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2742\n",
      "Epoch [1508/2000], Avg Train Loss: 3.2742\n",
      "Epoch [1508/2000], Avg Val Loss: 1.8583\n",
      "Validation loss improved from 1.8585 to 1.8583. Saving model...\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2811\n",
      "Epoch [1509/2000], Avg Train Loss: 3.2811\n",
      "Epoch [1509/2000], Avg Val Loss: 1.8581\n",
      "Validation loss improved from 1.8583 to 1.8581. Saving model...\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3157\n",
      "Epoch [1510/2000], Avg Train Loss: 3.3157\n",
      "Epoch [1510/2000], Avg Val Loss: 1.8578\n",
      "Validation loss improved from 1.8581 to 1.8578. Saving model...\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3272\n",
      "Epoch [1511/2000], Avg Train Loss: 3.3272\n",
      "Epoch [1511/2000], Avg Val Loss: 1.8576\n",
      "Validation loss improved from 1.8578 to 1.8576. Saving model...\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2678\n",
      "Epoch [1512/2000], Avg Train Loss: 3.2678\n",
      "Epoch [1512/2000], Avg Val Loss: 1.8573\n",
      "Validation loss improved from 1.8576 to 1.8573. Saving model...\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2735\n",
      "Epoch [1513/2000], Avg Train Loss: 3.2735\n",
      "Epoch [1513/2000], Avg Val Loss: 1.8570\n",
      "Validation loss improved from 1.8573 to 1.8570. Saving model...\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2581\n",
      "Epoch [1514/2000], Avg Train Loss: 3.2581\n",
      "Epoch [1514/2000], Avg Val Loss: 1.8568\n",
      "Validation loss improved from 1.8570 to 1.8568. Saving model...\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2659\n",
      "Epoch [1515/2000], Avg Train Loss: 3.2659\n",
      "Epoch [1515/2000], Avg Val Loss: 1.8566\n",
      "Validation loss improved from 1.8568 to 1.8566. Saving model...\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3112\n",
      "Epoch [1516/2000], Avg Train Loss: 3.3112\n",
      "Epoch [1516/2000], Avg Val Loss: 1.8564\n",
      "Validation loss improved from 1.8566 to 1.8564. Saving model...\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3016\n",
      "Epoch [1517/2000], Avg Train Loss: 3.3016\n",
      "Epoch [1517/2000], Avg Val Loss: 1.8562\n",
      "Validation loss improved from 1.8564 to 1.8562. Saving model...\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2971\n",
      "Epoch [1518/2000], Avg Train Loss: 3.2971\n",
      "Epoch [1518/2000], Avg Val Loss: 1.8560\n",
      "Validation loss improved from 1.8562 to 1.8560. Saving model...\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2995\n",
      "Epoch [1519/2000], Avg Train Loss: 3.2995\n",
      "Epoch [1519/2000], Avg Val Loss: 1.8558\n",
      "Validation loss improved from 1.8560 to 1.8558. Saving model...\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2893\n",
      "Epoch [1520/2000], Avg Train Loss: 3.2893\n",
      "Epoch [1520/2000], Avg Val Loss: 1.8556\n",
      "Validation loss improved from 1.8558 to 1.8556. Saving model...\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2889\n",
      "Epoch [1521/2000], Avg Train Loss: 3.2889\n",
      "Epoch [1521/2000], Avg Val Loss: 1.8554\n",
      "Validation loss improved from 1.8556 to 1.8554. Saving model...\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2808\n",
      "Epoch [1522/2000], Avg Train Loss: 3.2808\n",
      "Epoch [1522/2000], Avg Val Loss: 1.8552\n",
      "Validation loss improved from 1.8554 to 1.8552. Saving model...\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3002\n",
      "Epoch [1523/2000], Avg Train Loss: 3.3002\n",
      "Epoch [1523/2000], Avg Val Loss: 1.8551\n",
      "Validation loss improved from 1.8552 to 1.8551. Saving model...\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2850\n",
      "Epoch [1524/2000], Avg Train Loss: 3.2850\n",
      "Epoch [1524/2000], Avg Val Loss: 1.8549\n",
      "Validation loss improved from 1.8551 to 1.8549. Saving model...\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2654\n",
      "Epoch [1525/2000], Avg Train Loss: 3.2654\n",
      "Epoch [1525/2000], Avg Val Loss: 1.8548\n",
      "Validation loss improved from 1.8549 to 1.8548. Saving model...\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2816\n",
      "Epoch [1526/2000], Avg Train Loss: 3.2816\n",
      "Epoch [1526/2000], Avg Val Loss: 1.8547\n",
      "Validation loss improved from 1.8548 to 1.8547. Saving model...\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2752\n",
      "Epoch [1527/2000], Avg Train Loss: 3.2752\n",
      "Epoch [1527/2000], Avg Val Loss: 1.8545\n",
      "Validation loss improved from 1.8547 to 1.8545. Saving model...\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2674\n",
      "Epoch [1528/2000], Avg Train Loss: 3.2674\n",
      "Epoch [1528/2000], Avg Val Loss: 1.8544\n",
      "Validation loss improved from 1.8545 to 1.8544. Saving model...\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2877\n",
      "Epoch [1529/2000], Avg Train Loss: 3.2877\n",
      "Epoch [1529/2000], Avg Val Loss: 1.8543\n",
      "Validation loss improved from 1.8544 to 1.8543. Saving model...\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3072\n",
      "Epoch [1530/2000], Avg Train Loss: 3.3072\n",
      "Epoch [1530/2000], Avg Val Loss: 1.8542\n",
      "Validation loss improved from 1.8543 to 1.8542. Saving model...\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2767\n",
      "Epoch [1531/2000], Avg Train Loss: 3.2767\n",
      "Epoch [1531/2000], Avg Val Loss: 1.8541\n",
      "Validation loss improved from 1.8542 to 1.8541. Saving model...\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2911\n",
      "Epoch [1532/2000], Avg Train Loss: 3.2911\n",
      "Epoch [1532/2000], Avg Val Loss: 1.8540\n",
      "Validation loss improved from 1.8541 to 1.8540. Saving model...\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3215\n",
      "Epoch [1533/2000], Avg Train Loss: 3.3215\n",
      "Epoch [1533/2000], Avg Val Loss: 1.8538\n",
      "Validation loss improved from 1.8540 to 1.8538. Saving model...\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2708\n",
      "Epoch [1534/2000], Avg Train Loss: 3.2708\n",
      "Epoch [1534/2000], Avg Val Loss: 1.8537\n",
      "Validation loss improved from 1.8538 to 1.8537. Saving model...\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2606\n",
      "Epoch [1535/2000], Avg Train Loss: 3.2606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1535/2000], Avg Val Loss: 1.8536\n",
      "Validation loss improved from 1.8537 to 1.8536. Saving model...\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2915\n",
      "Epoch [1536/2000], Avg Train Loss: 3.2915\n",
      "Epoch [1536/2000], Avg Val Loss: 1.8534\n",
      "Validation loss improved from 1.8536 to 1.8534. Saving model...\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2769\n",
      "Epoch [1537/2000], Avg Train Loss: 3.2769\n",
      "Epoch [1537/2000], Avg Val Loss: 1.8533\n",
      "Validation loss improved from 1.8534 to 1.8533. Saving model...\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3295\n",
      "Epoch [1538/2000], Avg Train Loss: 3.3295\n",
      "Epoch [1538/2000], Avg Val Loss: 1.8532\n",
      "Validation loss improved from 1.8533 to 1.8532. Saving model...\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2811\n",
      "Epoch [1539/2000], Avg Train Loss: 3.2811\n",
      "Epoch [1539/2000], Avg Val Loss: 1.8531\n",
      "Validation loss improved from 1.8532 to 1.8531. Saving model...\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3000\n",
      "Epoch [1540/2000], Avg Train Loss: 3.3000\n",
      "Epoch [1540/2000], Avg Val Loss: 1.8528\n",
      "Validation loss improved from 1.8531 to 1.8528. Saving model...\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2756\n",
      "Epoch [1541/2000], Avg Train Loss: 3.2756\n",
      "Epoch [1541/2000], Avg Val Loss: 1.8526\n",
      "Validation loss improved from 1.8528 to 1.8526. Saving model...\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2954\n",
      "Epoch [1542/2000], Avg Train Loss: 3.2954\n",
      "Epoch [1542/2000], Avg Val Loss: 1.8522\n",
      "Validation loss improved from 1.8526 to 1.8522. Saving model...\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2916\n",
      "Epoch [1543/2000], Avg Train Loss: 3.2916\n",
      "Epoch [1543/2000], Avg Val Loss: 1.8519\n",
      "Validation loss improved from 1.8522 to 1.8519. Saving model...\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2861\n",
      "Epoch [1544/2000], Avg Train Loss: 3.2861\n",
      "Epoch [1544/2000], Avg Val Loss: 1.8516\n",
      "Validation loss improved from 1.8519 to 1.8516. Saving model...\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2816\n",
      "Epoch [1545/2000], Avg Train Loss: 3.2816\n",
      "Epoch [1545/2000], Avg Val Loss: 1.8513\n",
      "Validation loss improved from 1.8516 to 1.8513. Saving model...\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2944\n",
      "Epoch [1546/2000], Avg Train Loss: 3.2944\n",
      "Epoch [1546/2000], Avg Val Loss: 1.8511\n",
      "Validation loss improved from 1.8513 to 1.8511. Saving model...\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3037\n",
      "Epoch [1547/2000], Avg Train Loss: 3.3037\n",
      "Epoch [1547/2000], Avg Val Loss: 1.8508\n",
      "Validation loss improved from 1.8511 to 1.8508. Saving model...\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2753\n",
      "Epoch [1548/2000], Avg Train Loss: 3.2753\n",
      "Epoch [1548/2000], Avg Val Loss: 1.8505\n",
      "Validation loss improved from 1.8508 to 1.8505. Saving model...\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2692\n",
      "Epoch [1549/2000], Avg Train Loss: 3.2692\n",
      "Epoch [1549/2000], Avg Val Loss: 1.8503\n",
      "Validation loss improved from 1.8505 to 1.8503. Saving model...\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3090\n",
      "Epoch [1550/2000], Avg Train Loss: 3.3090\n",
      "Epoch [1550/2000], Avg Val Loss: 1.8501\n",
      "Validation loss improved from 1.8503 to 1.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2800\n",
      "Epoch [1551/2000], Avg Train Loss: 3.2800\n",
      "Epoch [1551/2000], Avg Val Loss: 1.8499\n",
      "Validation loss improved from 1.8501 to 1.8499. Saving model...\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3178\n",
      "Epoch [1552/2000], Avg Train Loss: 3.3178\n",
      "Epoch [1552/2000], Avg Val Loss: 1.8498\n",
      "Validation loss improved from 1.8499 to 1.8498. Saving model...\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3116\n",
      "Epoch [1553/2000], Avg Train Loss: 3.3116\n",
      "Epoch [1553/2000], Avg Val Loss: 1.8496\n",
      "Validation loss improved from 1.8498 to 1.8496. Saving model...\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3028\n",
      "Epoch [1554/2000], Avg Train Loss: 3.3028\n",
      "Epoch [1554/2000], Avg Val Loss: 1.8494\n",
      "Validation loss improved from 1.8496 to 1.8494. Saving model...\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2944\n",
      "Epoch [1555/2000], Avg Train Loss: 3.2944\n",
      "Epoch [1555/2000], Avg Val Loss: 1.8493\n",
      "Validation loss improved from 1.8494 to 1.8493. Saving model...\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2928\n",
      "Epoch [1556/2000], Avg Train Loss: 3.2928\n",
      "Epoch [1556/2000], Avg Val Loss: 1.8491\n",
      "Validation loss improved from 1.8493 to 1.8491. Saving model...\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2750\n",
      "Epoch [1557/2000], Avg Train Loss: 3.2750\n",
      "Epoch [1557/2000], Avg Val Loss: 1.8489\n",
      "Validation loss improved from 1.8491 to 1.8489. Saving model...\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2672\n",
      "Epoch [1558/2000], Avg Train Loss: 3.2672\n",
      "Epoch [1558/2000], Avg Val Loss: 1.8487\n",
      "Validation loss improved from 1.8489 to 1.8487. Saving model...\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2776\n",
      "Epoch [1559/2000], Avg Train Loss: 3.2776\n",
      "Epoch [1559/2000], Avg Val Loss: 1.8485\n",
      "Validation loss improved from 1.8487 to 1.8485. Saving model...\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2757\n",
      "Epoch [1560/2000], Avg Train Loss: 3.2757\n",
      "Epoch [1560/2000], Avg Val Loss: 1.8483\n",
      "Validation loss improved from 1.8485 to 1.8483. Saving model...\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2746\n",
      "Epoch [1561/2000], Avg Train Loss: 3.2746\n",
      "Epoch [1561/2000], Avg Val Loss: 1.8482\n",
      "Validation loss improved from 1.8483 to 1.8482. Saving model...\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2817\n",
      "Epoch [1562/2000], Avg Train Loss: 3.2817\n",
      "Epoch [1562/2000], Avg Val Loss: 1.8481\n",
      "Validation loss improved from 1.8482 to 1.8481. Saving model...\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2973\n",
      "Epoch [1563/2000], Avg Train Loss: 3.2973\n",
      "Epoch [1563/2000], Avg Val Loss: 1.8479\n",
      "Validation loss improved from 1.8481 to 1.8479. Saving model...\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3169\n",
      "Epoch [1564/2000], Avg Train Loss: 3.3169\n",
      "Epoch [1564/2000], Avg Val Loss: 1.8478\n",
      "Validation loss improved from 1.8479 to 1.8478. Saving model...\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2774\n",
      "Epoch [1565/2000], Avg Train Loss: 3.2774\n",
      "Epoch [1565/2000], Avg Val Loss: 1.8476\n",
      "Validation loss improved from 1.8478 to 1.8476. Saving model...\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2754\n",
      "Epoch [1566/2000], Avg Train Loss: 3.2754\n",
      "Epoch [1566/2000], Avg Val Loss: 1.8474\n",
      "Validation loss improved from 1.8476 to 1.8474. Saving model...\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2980\n",
      "Epoch [1567/2000], Avg Train Loss: 3.2980\n",
      "Epoch [1567/2000], Avg Val Loss: 1.8472\n",
      "Validation loss improved from 1.8474 to 1.8472. Saving model...\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2872\n",
      "Epoch [1568/2000], Avg Train Loss: 3.2872\n",
      "Epoch [1568/2000], Avg Val Loss: 1.8470\n",
      "Validation loss improved from 1.8472 to 1.8470. Saving model...\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2868\n",
      "Epoch [1569/2000], Avg Train Loss: 3.2868\n",
      "Epoch [1569/2000], Avg Val Loss: 1.8469\n",
      "Validation loss improved from 1.8470 to 1.8469. Saving model...\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2667\n",
      "Epoch [1570/2000], Avg Train Loss: 3.2667\n",
      "Epoch [1570/2000], Avg Val Loss: 1.8467\n",
      "Validation loss improved from 1.8469 to 1.8467. Saving model...\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2953\n",
      "Epoch [1571/2000], Avg Train Loss: 3.2953\n",
      "Epoch [1571/2000], Avg Val Loss: 1.8466\n",
      "Validation loss improved from 1.8467 to 1.8466. Saving model...\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2836\n",
      "Epoch [1572/2000], Avg Train Loss: 3.2836\n",
      "Epoch [1572/2000], Avg Val Loss: 1.8465\n",
      "Validation loss improved from 1.8466 to 1.8465. Saving model...\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2547\n",
      "Epoch [1573/2000], Avg Train Loss: 3.2547\n",
      "Epoch [1573/2000], Avg Val Loss: 1.8464\n",
      "Validation loss improved from 1.8465 to 1.8464. Saving model...\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2836\n",
      "Epoch [1574/2000], Avg Train Loss: 3.2836\n",
      "Epoch [1574/2000], Avg Val Loss: 1.8463\n",
      "Validation loss improved from 1.8464 to 1.8463. Saving model...\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2727\n",
      "Epoch [1575/2000], Avg Train Loss: 3.2727\n",
      "Epoch [1575/2000], Avg Val Loss: 1.8463\n",
      "Validation loss improved from 1.8463 to 1.8463. Saving model...\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3262\n",
      "Epoch [1576/2000], Avg Train Loss: 3.3262\n",
      "Epoch [1576/2000], Avg Val Loss: 1.8464\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2573\n",
      "Epoch [1577/2000], Avg Train Loss: 3.2573\n",
      "Epoch [1577/2000], Avg Val Loss: 1.8464\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2635\n",
      "Epoch [1578/2000], Avg Train Loss: 3.2635\n",
      "Epoch [1578/2000], Avg Val Loss: 1.8464\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3183\n",
      "Epoch [1579/2000], Avg Train Loss: 3.3183\n",
      "Epoch [1579/2000], Avg Val Loss: 1.8465\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2643\n",
      "Epoch [1580/2000], Avg Train Loss: 3.2643\n",
      "Epoch [1580/2000], Avg Val Loss: 1.8466\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2658\n",
      "Epoch [1581/2000], Avg Train Loss: 3.2658\n",
      "Epoch [1581/2000], Avg Val Loss: 1.8466\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2894\n",
      "Epoch [1582/2000], Avg Train Loss: 3.2894\n",
      "Epoch [1582/2000], Avg Val Loss: 1.8465\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3097\n",
      "Epoch [1583/2000], Avg Train Loss: 3.3097\n",
      "Epoch [1583/2000], Avg Val Loss: 1.8464\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2713\n",
      "Epoch [1584/2000], Avg Train Loss: 3.2713\n",
      "Epoch [1584/2000], Avg Val Loss: 1.8464\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3133\n",
      "Epoch [1585/2000], Avg Train Loss: 3.3133\n",
      "Epoch [1585/2000], Avg Val Loss: 1.8464\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2850\n",
      "Epoch [1586/2000], Avg Train Loss: 3.2850\n",
      "Epoch [1586/2000], Avg Val Loss: 1.8463\n",
      "Validation loss improved from 1.8463 to 1.8463. Saving model...\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2933\n",
      "Epoch [1587/2000], Avg Train Loss: 3.2933\n",
      "Epoch [1587/2000], Avg Val Loss: 1.8462\n",
      "Validation loss improved from 1.8463 to 1.8462. Saving model...\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3123\n",
      "Epoch [1588/2000], Avg Train Loss: 3.3123\n",
      "Epoch [1588/2000], Avg Val Loss: 1.8461\n",
      "Validation loss improved from 1.8462 to 1.8461. Saving model...\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2894\n",
      "Epoch [1589/2000], Avg Train Loss: 3.2894\n",
      "Epoch [1589/2000], Avg Val Loss: 1.8459\n",
      "Validation loss improved from 1.8461 to 1.8459. Saving model...\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2531\n",
      "Epoch [1590/2000], Avg Train Loss: 3.2531\n",
      "Epoch [1590/2000], Avg Val Loss: 1.8458\n",
      "Validation loss improved from 1.8459 to 1.8458. Saving model...\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2823\n",
      "Epoch [1591/2000], Avg Train Loss: 3.2823\n",
      "Epoch [1591/2000], Avg Val Loss: 1.8457\n",
      "Validation loss improved from 1.8458 to 1.8457. Saving model...\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2980\n",
      "Epoch [1592/2000], Avg Train Loss: 3.2980\n",
      "Epoch [1592/2000], Avg Val Loss: 1.8455\n",
      "Validation loss improved from 1.8457 to 1.8455. Saving model...\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2597\n",
      "Epoch [1593/2000], Avg Train Loss: 3.2597\n",
      "Epoch [1593/2000], Avg Val Loss: 1.8454\n",
      "Validation loss improved from 1.8455 to 1.8454. Saving model...\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3041\n",
      "Epoch [1594/2000], Avg Train Loss: 3.3041\n",
      "Epoch [1594/2000], Avg Val Loss: 1.8452\n",
      "Validation loss improved from 1.8454 to 1.8452. Saving model...\n",
      "\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3042\n",
      "Epoch [1595/2000], Avg Train Loss: 3.3042\n",
      "Epoch [1595/2000], Avg Val Loss: 1.8450\n",
      "Validation loss improved from 1.8452 to 1.8450. Saving model...\n",
      "\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2678\n",
      "Epoch [1596/2000], Avg Train Loss: 3.2678\n",
      "Epoch [1596/2000], Avg Val Loss: 1.8448\n",
      "Validation loss improved from 1.8450 to 1.8448. Saving model...\n",
      "\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3020\n",
      "Epoch [1597/2000], Avg Train Loss: 3.3020\n",
      "Epoch [1597/2000], Avg Val Loss: 1.8445\n",
      "Validation loss improved from 1.8448 to 1.8445. Saving model...\n",
      "\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2771\n",
      "Epoch [1598/2000], Avg Train Loss: 3.2771\n",
      "Epoch [1598/2000], Avg Val Loss: 1.8443\n",
      "Validation loss improved from 1.8445 to 1.8443. Saving model...\n",
      "\n",
      "LOG: Epoch [1599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2906\n",
      "Epoch [1599/2000], Avg Train Loss: 3.2906\n",
      "Epoch [1599/2000], Avg Val Loss: 1.8441\n",
      "Validation loss improved from 1.8443 to 1.8441. Saving model...\n",
      "\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2901\n",
      "Epoch [1600/2000], Avg Train Loss: 3.2901\n",
      "Epoch [1600/2000], Avg Val Loss: 1.8439\n",
      "Validation loss improved from 1.8441 to 1.8439. Saving model...\n",
      "\n",
      "LOG: Epoch [1601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2700\n",
      "Epoch [1601/2000], Avg Train Loss: 3.2700\n",
      "Epoch [1601/2000], Avg Val Loss: 1.8437\n",
      "Validation loss improved from 1.8439 to 1.8437. Saving model...\n",
      "\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2743\n",
      "Epoch [1602/2000], Avg Train Loss: 3.2743\n",
      "Epoch [1602/2000], Avg Val Loss: 1.8436\n",
      "Validation loss improved from 1.8437 to 1.8436. Saving model...\n",
      "\n",
      "LOG: Epoch [1603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2810\n",
      "Epoch [1603/2000], Avg Train Loss: 3.2810\n",
      "Epoch [1603/2000], Avg Val Loss: 1.8435\n",
      "Validation loss improved from 1.8436 to 1.8435. Saving model...\n",
      "\n",
      "LOG: Epoch [1604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2679\n",
      "Epoch [1604/2000], Avg Train Loss: 3.2679\n",
      "Epoch [1604/2000], Avg Val Loss: 1.8433\n",
      "Validation loss improved from 1.8435 to 1.8433. Saving model...\n",
      "\n",
      "LOG: Epoch [1605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2579\n",
      "Epoch [1605/2000], Avg Train Loss: 3.2579\n",
      "Epoch [1605/2000], Avg Val Loss: 1.8433\n",
      "Validation loss improved from 1.8433 to 1.8433. Saving model...\n",
      "\n",
      "LOG: Epoch [1606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2928\n",
      "Epoch [1606/2000], Avg Train Loss: 3.2928\n",
      "Epoch [1606/2000], Avg Val Loss: 1.8431\n",
      "Validation loss improved from 1.8433 to 1.8431. Saving model...\n",
      "\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2594\n",
      "Epoch [1607/2000], Avg Train Loss: 3.2594\n",
      "Epoch [1607/2000], Avg Val Loss: 1.8430\n",
      "Validation loss improved from 1.8431 to 1.8430. Saving model...\n",
      "\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2475\n",
      "Epoch [1608/2000], Avg Train Loss: 3.2475\n",
      "Epoch [1608/2000], Avg Val Loss: 1.8429\n",
      "Validation loss improved from 1.8430 to 1.8429. Saving model...\n",
      "\n",
      "LOG: Epoch [1609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2925\n",
      "Epoch [1609/2000], Avg Train Loss: 3.2925\n",
      "Epoch [1609/2000], Avg Val Loss: 1.8428\n",
      "Validation loss improved from 1.8429 to 1.8428. Saving model...\n",
      "\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2638\n",
      "Epoch [1610/2000], Avg Train Loss: 3.2638\n",
      "Epoch [1610/2000], Avg Val Loss: 1.8427\n",
      "Validation loss improved from 1.8428 to 1.8427. Saving model...\n",
      "\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2542\n",
      "Epoch [1611/2000], Avg Train Loss: 3.2542\n",
      "Epoch [1611/2000], Avg Val Loss: 1.8425\n",
      "Validation loss improved from 1.8427 to 1.8425. Saving model...\n",
      "\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2923\n",
      "Epoch [1612/2000], Avg Train Loss: 3.2923\n",
      "Epoch [1612/2000], Avg Val Loss: 1.8423\n",
      "Validation loss improved from 1.8425 to 1.8423. Saving model...\n",
      "\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2805\n",
      "Epoch [1613/2000], Avg Train Loss: 3.2805\n",
      "Epoch [1613/2000], Avg Val Loss: 1.8421\n",
      "Validation loss improved from 1.8423 to 1.8421. Saving model...\n",
      "\n",
      "LOG: Epoch [1614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2742\n",
      "Epoch [1614/2000], Avg Train Loss: 3.2742\n",
      "Epoch [1614/2000], Avg Val Loss: 1.8419\n",
      "Validation loss improved from 1.8421 to 1.8419. Saving model...\n",
      "\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2633\n",
      "Epoch [1615/2000], Avg Train Loss: 3.2633\n",
      "Epoch [1615/2000], Avg Val Loss: 1.8417\n",
      "Validation loss improved from 1.8419 to 1.8417. Saving model...\n",
      "\n",
      "LOG: Epoch [1616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2640\n",
      "Epoch [1616/2000], Avg Train Loss: 3.2640\n",
      "Epoch [1616/2000], Avg Val Loss: 1.8415\n",
      "Validation loss improved from 1.8417 to 1.8415. Saving model...\n",
      "\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2310\n",
      "Epoch [1617/2000], Avg Train Loss: 3.2310\n",
      "Epoch [1617/2000], Avg Val Loss: 1.8414\n",
      "Validation loss improved from 1.8415 to 1.8414. Saving model...\n",
      "\n",
      "LOG: Epoch [1618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2790\n",
      "Epoch [1618/2000], Avg Train Loss: 3.2790\n",
      "Epoch [1618/2000], Avg Val Loss: 1.8412\n",
      "Validation loss improved from 1.8414 to 1.8412. Saving model...\n",
      "\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3209\n",
      "Epoch [1619/2000], Avg Train Loss: 3.3209\n",
      "Epoch [1619/2000], Avg Val Loss: 1.8410\n",
      "Validation loss improved from 1.8412 to 1.8410. Saving model...\n",
      "\n",
      "LOG: Epoch [1620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2463\n",
      "Epoch [1620/2000], Avg Train Loss: 3.2463\n",
      "Epoch [1620/2000], Avg Val Loss: 1.8409\n",
      "Validation loss improved from 1.8410 to 1.8409. Saving model...\n",
      "\n",
      "LOG: Epoch [1621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2780\n",
      "Epoch [1621/2000], Avg Train Loss: 3.2780\n",
      "Epoch [1621/2000], Avg Val Loss: 1.8408\n",
      "Validation loss improved from 1.8409 to 1.8408. Saving model...\n",
      "\n",
      "LOG: Epoch [1622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2440\n",
      "Epoch [1622/2000], Avg Train Loss: 3.2440\n",
      "Epoch [1622/2000], Avg Val Loss: 1.8408\n",
      "Validation loss improved from 1.8408 to 1.8408. Saving model...\n",
      "\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2720\n",
      "Epoch [1623/2000], Avg Train Loss: 3.2720\n",
      "Epoch [1623/2000], Avg Val Loss: 1.8407\n",
      "Validation loss improved from 1.8408 to 1.8407. Saving model...\n",
      "\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2656\n",
      "Epoch [1624/2000], Avg Train Loss: 3.2656\n",
      "Epoch [1624/2000], Avg Val Loss: 1.8406\n",
      "Validation loss improved from 1.8407 to 1.8406. Saving model...\n",
      "\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2564\n",
      "Epoch [1625/2000], Avg Train Loss: 3.2564\n",
      "Epoch [1625/2000], Avg Val Loss: 1.8406\n",
      "Validation loss improved from 1.8406 to 1.8406. Saving model...\n",
      "\n",
      "LOG: Epoch [1626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2797\n",
      "Epoch [1626/2000], Avg Train Loss: 3.2797\n",
      "Epoch [1626/2000], Avg Val Loss: 1.8406\n",
      "Validation loss improved from 1.8406 to 1.8406. Saving model...\n",
      "\n",
      "LOG: Epoch [1627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2683\n",
      "Epoch [1627/2000], Avg Train Loss: 3.2683\n",
      "Epoch [1627/2000], Avg Val Loss: 1.8405\n",
      "Validation loss improved from 1.8406 to 1.8405. Saving model...\n",
      "\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2710\n",
      "Epoch [1628/2000], Avg Train Loss: 3.2710\n",
      "Epoch [1628/2000], Avg Val Loss: 1.8404\n",
      "Validation loss improved from 1.8405 to 1.8404. Saving model...\n",
      "\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2578\n",
      "Epoch [1629/2000], Avg Train Loss: 3.2578\n",
      "Epoch [1629/2000], Avg Val Loss: 1.8404\n",
      "Validation loss improved from 1.8404 to 1.8404. Saving model...\n",
      "\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2696\n",
      "Epoch [1630/2000], Avg Train Loss: 3.2696\n",
      "Epoch [1630/2000], Avg Val Loss: 1.8403\n",
      "Validation loss improved from 1.8404 to 1.8403. Saving model...\n",
      "\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2817\n",
      "Epoch [1631/2000], Avg Train Loss: 3.2817\n",
      "Epoch [1631/2000], Avg Val Loss: 1.8402\n",
      "Validation loss improved from 1.8403 to 1.8402. Saving model...\n",
      "\n",
      "LOG: Epoch [1632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2673\n",
      "Epoch [1632/2000], Avg Train Loss: 3.2673\n",
      "Epoch [1632/2000], Avg Val Loss: 1.8401\n",
      "Validation loss improved from 1.8402 to 1.8401. Saving model...\n",
      "\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2719\n",
      "Epoch [1633/2000], Avg Train Loss: 3.2719\n",
      "Epoch [1633/2000], Avg Val Loss: 1.8401\n",
      "Validation loss improved from 1.8401 to 1.8401. Saving model...\n",
      "\n",
      "LOG: Epoch [1634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2856\n",
      "Epoch [1634/2000], Avg Train Loss: 3.2856\n",
      "Epoch [1634/2000], Avg Val Loss: 1.8399\n",
      "Validation loss improved from 1.8401 to 1.8399. Saving model...\n",
      "\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2674\n",
      "Epoch [1635/2000], Avg Train Loss: 3.2674\n",
      "Epoch [1635/2000], Avg Val Loss: 1.8398\n",
      "Validation loss improved from 1.8399 to 1.8398. Saving model...\n",
      "\n",
      "LOG: Epoch [1636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2588\n",
      "Epoch [1636/2000], Avg Train Loss: 3.2588\n",
      "Epoch [1636/2000], Avg Val Loss: 1.8396\n",
      "Validation loss improved from 1.8398 to 1.8396. Saving model...\n",
      "\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2997\n",
      "Epoch [1637/2000], Avg Train Loss: 3.2997\n",
      "Epoch [1637/2000], Avg Val Loss: 1.8394\n",
      "Validation loss improved from 1.8396 to 1.8394. Saving model...\n",
      "\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2804\n",
      "Epoch [1638/2000], Avg Train Loss: 3.2804\n",
      "Epoch [1638/2000], Avg Val Loss: 1.8393\n",
      "Validation loss improved from 1.8394 to 1.8393. Saving model...\n",
      "\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2665\n",
      "Epoch [1639/2000], Avg Train Loss: 3.2665\n",
      "Epoch [1639/2000], Avg Val Loss: 1.8392\n",
      "Validation loss improved from 1.8393 to 1.8392. Saving model...\n",
      "\n",
      "LOG: Epoch [1640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2821\n",
      "Epoch [1640/2000], Avg Train Loss: 3.2821\n",
      "Epoch [1640/2000], Avg Val Loss: 1.8391\n",
      "Validation loss improved from 1.8392 to 1.8391. Saving model...\n",
      "\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3083\n",
      "Epoch [1641/2000], Avg Train Loss: 3.3083\n",
      "Epoch [1641/2000], Avg Val Loss: 1.8391\n",
      "Validation loss improved from 1.8391 to 1.8391. Saving model...\n",
      "\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2548\n",
      "Epoch [1642/2000], Avg Train Loss: 3.2548\n",
      "Epoch [1642/2000], Avg Val Loss: 1.8391\n",
      "Validation loss improved from 1.8391 to 1.8391. Saving model...\n",
      "\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2759\n",
      "Epoch [1643/2000], Avg Train Loss: 3.2759\n",
      "Epoch [1643/2000], Avg Val Loss: 1.8390\n",
      "Validation loss improved from 1.8391 to 1.8390. Saving model...\n",
      "\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2733\n",
      "Epoch [1644/2000], Avg Train Loss: 3.2733\n",
      "Epoch [1644/2000], Avg Val Loss: 1.8389\n",
      "Validation loss improved from 1.8390 to 1.8389. Saving model...\n",
      "\n",
      "LOG: Epoch [1645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2719\n",
      "Epoch [1645/2000], Avg Train Loss: 3.2719\n",
      "Epoch [1645/2000], Avg Val Loss: 1.8388\n",
      "Validation loss improved from 1.8389 to 1.8388. Saving model...\n",
      "\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2671\n",
      "Epoch [1646/2000], Avg Train Loss: 3.2671\n",
      "Epoch [1646/2000], Avg Val Loss: 1.8388\n",
      "Validation loss improved from 1.8388 to 1.8388. Saving model...\n",
      "\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2462\n",
      "Epoch [1647/2000], Avg Train Loss: 3.2462\n",
      "Epoch [1647/2000], Avg Val Loss: 1.8388\n",
      "Validation loss improved from 1.8388 to 1.8388. Saving model...\n",
      "\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2638\n",
      "Epoch [1648/2000], Avg Train Loss: 3.2638\n",
      "Epoch [1648/2000], Avg Val Loss: 1.8387\n",
      "Validation loss improved from 1.8388 to 1.8387. Saving model...\n",
      "\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2801\n",
      "Epoch [1649/2000], Avg Train Loss: 3.2801\n",
      "Epoch [1649/2000], Avg Val Loss: 1.8387\n",
      "Validation loss improved from 1.8387 to 1.8387. Saving model...\n",
      "\n",
      "LOG: Epoch [1650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2500\n",
      "Epoch [1650/2000], Avg Train Loss: 3.2500\n",
      "Epoch [1650/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2682\n",
      "Epoch [1651/2000], Avg Train Loss: 3.2682\n",
      "Epoch [1651/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2680\n",
      "Epoch [1652/2000], Avg Train Loss: 3.2680\n",
      "Epoch [1652/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2788\n",
      "Epoch [1653/2000], Avg Train Loss: 3.2788\n",
      "Epoch [1653/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2606\n",
      "Epoch [1654/2000], Avg Train Loss: 3.2606\n",
      "Epoch [1654/2000], Avg Val Loss: 1.8388\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2675\n",
      "Epoch [1655/2000], Avg Train Loss: 3.2675\n",
      "Epoch [1655/2000], Avg Val Loss: 1.8388\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2350\n",
      "Epoch [1656/2000], Avg Train Loss: 3.2350\n",
      "Epoch [1656/2000], Avg Val Loss: 1.8388\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2960\n",
      "Epoch [1657/2000], Avg Train Loss: 3.2960\n",
      "Epoch [1657/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2738\n",
      "Epoch [1658/2000], Avg Train Loss: 3.2738\n",
      "Epoch [1658/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2798\n",
      "Epoch [1659/2000], Avg Train Loss: 3.2798\n",
      "Epoch [1659/2000], Avg Val Loss: 1.8387\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3004\n",
      "Epoch [1660/2000], Avg Train Loss: 3.3004\n",
      "Epoch [1660/2000], Avg Val Loss: 1.8386\n",
      "Validation loss improved from 1.8387 to 1.8386. Saving model...\n",
      "\n",
      "LOG: Epoch [1661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2634\n",
      "Epoch [1661/2000], Avg Train Loss: 3.2634\n",
      "Epoch [1661/2000], Avg Val Loss: 1.8384\n",
      "Validation loss improved from 1.8386 to 1.8384. Saving model...\n",
      "\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2485\n",
      "Epoch [1662/2000], Avg Train Loss: 3.2485\n",
      "Epoch [1662/2000], Avg Val Loss: 1.8382\n",
      "Validation loss improved from 1.8384 to 1.8382. Saving model...\n",
      "\n",
      "LOG: Epoch [1663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3168\n",
      "Epoch [1663/2000], Avg Train Loss: 3.3168\n",
      "Epoch [1663/2000], Avg Val Loss: 1.8380\n",
      "Validation loss improved from 1.8382 to 1.8380. Saving model...\n",
      "\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2613\n",
      "Epoch [1664/2000], Avg Train Loss: 3.2613\n",
      "Epoch [1664/2000], Avg Val Loss: 1.8378\n",
      "Validation loss improved from 1.8380 to 1.8378. Saving model...\n",
      "\n",
      "LOG: Epoch [1665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2554\n",
      "Epoch [1665/2000], Avg Train Loss: 3.2554\n",
      "Epoch [1665/2000], Avg Val Loss: 1.8376\n",
      "Validation loss improved from 1.8378 to 1.8376. Saving model...\n",
      "\n",
      "LOG: Epoch [1666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2724\n",
      "Epoch [1666/2000], Avg Train Loss: 3.2724\n",
      "Epoch [1666/2000], Avg Val Loss: 1.8374\n",
      "Validation loss improved from 1.8376 to 1.8374. Saving model...\n",
      "\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2749\n",
      "Epoch [1667/2000], Avg Train Loss: 3.2749\n",
      "Epoch [1667/2000], Avg Val Loss: 1.8373\n",
      "Validation loss improved from 1.8374 to 1.8373. Saving model...\n",
      "\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2975\n",
      "Epoch [1668/2000], Avg Train Loss: 3.2975\n",
      "Epoch [1668/2000], Avg Val Loss: 1.8372\n",
      "Validation loss improved from 1.8373 to 1.8372. Saving model...\n",
      "\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2581\n",
      "Epoch [1669/2000], Avg Train Loss: 3.2581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1669/2000], Avg Val Loss: 1.8370\n",
      "Validation loss improved from 1.8372 to 1.8370. Saving model...\n",
      "\n",
      "LOG: Epoch [1670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2714\n",
      "Epoch [1670/2000], Avg Train Loss: 3.2714\n",
      "Epoch [1670/2000], Avg Val Loss: 1.8370\n",
      "Validation loss improved from 1.8370 to 1.8370. Saving model...\n",
      "\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2788\n",
      "Epoch [1671/2000], Avg Train Loss: 3.2788\n",
      "Epoch [1671/2000], Avg Val Loss: 1.8370\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2415\n",
      "Epoch [1672/2000], Avg Train Loss: 3.2415\n",
      "Epoch [1672/2000], Avg Val Loss: 1.8370\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2615\n",
      "Epoch [1673/2000], Avg Train Loss: 3.2615\n",
      "Epoch [1673/2000], Avg Val Loss: 1.8369\n",
      "Validation loss improved from 1.8370 to 1.8369. Saving model...\n",
      "\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2426\n",
      "Epoch [1674/2000], Avg Train Loss: 3.2426\n",
      "Epoch [1674/2000], Avg Val Loss: 1.8368\n",
      "Validation loss improved from 1.8369 to 1.8368. Saving model...\n",
      "\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2796\n",
      "Epoch [1675/2000], Avg Train Loss: 3.2796\n",
      "Epoch [1675/2000], Avg Val Loss: 1.8367\n",
      "Validation loss improved from 1.8368 to 1.8367. Saving model...\n",
      "\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2637\n",
      "Epoch [1676/2000], Avg Train Loss: 3.2637\n",
      "Epoch [1676/2000], Avg Val Loss: 1.8365\n",
      "Validation loss improved from 1.8367 to 1.8365. Saving model...\n",
      "\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2342\n",
      "Epoch [1677/2000], Avg Train Loss: 3.2342\n",
      "Epoch [1677/2000], Avg Val Loss: 1.8364\n",
      "Validation loss improved from 1.8365 to 1.8364. Saving model...\n",
      "\n",
      "LOG: Epoch [1678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2707\n",
      "Epoch [1678/2000], Avg Train Loss: 3.2707\n",
      "Epoch [1678/2000], Avg Val Loss: 1.8363\n",
      "Validation loss improved from 1.8364 to 1.8363. Saving model...\n",
      "\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2292\n",
      "Epoch [1679/2000], Avg Train Loss: 3.2292\n",
      "Epoch [1679/2000], Avg Val Loss: 1.8362\n",
      "Validation loss improved from 1.8363 to 1.8362. Saving model...\n",
      "\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2361\n",
      "Epoch [1680/2000], Avg Train Loss: 3.2361\n",
      "Epoch [1680/2000], Avg Val Loss: 1.8362\n",
      "Validation loss improved from 1.8362 to 1.8362. Saving model...\n",
      "\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2440\n",
      "Epoch [1681/2000], Avg Train Loss: 3.2440\n",
      "Epoch [1681/2000], Avg Val Loss: 1.8361\n",
      "Validation loss improved from 1.8362 to 1.8361. Saving model...\n",
      "\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2552\n",
      "Epoch [1682/2000], Avg Train Loss: 3.2552\n",
      "Epoch [1682/2000], Avg Val Loss: 1.8361\n",
      "Validation loss improved from 1.8361 to 1.8361. Saving model...\n",
      "\n",
      "LOG: Epoch [1683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2441\n",
      "Epoch [1683/2000], Avg Train Loss: 3.2441\n",
      "Epoch [1683/2000], Avg Val Loss: 1.8361\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2240\n",
      "Epoch [1684/2000], Avg Train Loss: 3.2240\n",
      "Epoch [1684/2000], Avg Val Loss: 1.8361\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2477\n",
      "Epoch [1685/2000], Avg Train Loss: 3.2477\n",
      "Epoch [1685/2000], Avg Val Loss: 1.8361\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2496\n",
      "Epoch [1686/2000], Avg Train Loss: 3.2496\n",
      "Epoch [1686/2000], Avg Val Loss: 1.8360\n",
      "Validation loss improved from 1.8361 to 1.8360. Saving model...\n",
      "\n",
      "LOG: Epoch [1687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2133\n",
      "Epoch [1687/2000], Avg Train Loss: 3.2133\n",
      "Epoch [1687/2000], Avg Val Loss: 1.8359\n",
      "Validation loss improved from 1.8360 to 1.8359. Saving model...\n",
      "\n",
      "LOG: Epoch [1688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2657\n",
      "Epoch [1688/2000], Avg Train Loss: 3.2657\n",
      "Epoch [1688/2000], Avg Val Loss: 1.8359\n",
      "Validation loss improved from 1.8359 to 1.8359. Saving model...\n",
      "\n",
      "LOG: Epoch [1689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2819\n",
      "Epoch [1689/2000], Avg Train Loss: 3.2819\n",
      "Epoch [1689/2000], Avg Val Loss: 1.8358\n",
      "Validation loss improved from 1.8359 to 1.8358. Saving model...\n",
      "\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2694\n",
      "Epoch [1690/2000], Avg Train Loss: 3.2694\n",
      "Epoch [1690/2000], Avg Val Loss: 1.8358\n",
      "Validation loss improved from 1.8358 to 1.8358. Saving model...\n",
      "\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2676\n",
      "Epoch [1691/2000], Avg Train Loss: 3.2676\n",
      "Epoch [1691/2000], Avg Val Loss: 1.8356\n",
      "Validation loss improved from 1.8358 to 1.8356. Saving model...\n",
      "\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2691\n",
      "Epoch [1692/2000], Avg Train Loss: 3.2691\n",
      "Epoch [1692/2000], Avg Val Loss: 1.8354\n",
      "Validation loss improved from 1.8356 to 1.8354. Saving model...\n",
      "\n",
      "LOG: Epoch [1693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3033\n",
      "Epoch [1693/2000], Avg Train Loss: 3.3033\n",
      "Epoch [1693/2000], Avg Val Loss: 1.8353\n",
      "Validation loss improved from 1.8354 to 1.8353. Saving model...\n",
      "\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2701\n",
      "Epoch [1694/2000], Avg Train Loss: 3.2701\n",
      "Epoch [1694/2000], Avg Val Loss: 1.8352\n",
      "Validation loss improved from 1.8353 to 1.8352. Saving model...\n",
      "\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2624\n",
      "Epoch [1695/2000], Avg Train Loss: 3.2624\n",
      "Epoch [1695/2000], Avg Val Loss: 1.8350\n",
      "Validation loss improved from 1.8352 to 1.8350. Saving model...\n",
      "\n",
      "LOG: Epoch [1696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2853\n",
      "Epoch [1696/2000], Avg Train Loss: 3.2853\n",
      "Epoch [1696/2000], Avg Val Loss: 1.8349\n",
      "Validation loss improved from 1.8350 to 1.8349. Saving model...\n",
      "\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3092\n",
      "Epoch [1697/2000], Avg Train Loss: 3.3092\n",
      "Epoch [1697/2000], Avg Val Loss: 1.8347\n",
      "Validation loss improved from 1.8349 to 1.8347. Saving model...\n",
      "\n",
      "LOG: Epoch [1698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2659\n",
      "Epoch [1698/2000], Avg Train Loss: 3.2659\n",
      "Epoch [1698/2000], Avg Val Loss: 1.8346\n",
      "Validation loss improved from 1.8347 to 1.8346. Saving model...\n",
      "\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2616\n",
      "Epoch [1699/2000], Avg Train Loss: 3.2616\n",
      "Epoch [1699/2000], Avg Val Loss: 1.8345\n",
      "Validation loss improved from 1.8346 to 1.8345. Saving model...\n",
      "\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2469\n",
      "Epoch [1700/2000], Avg Train Loss: 3.2469\n",
      "Epoch [1700/2000], Avg Val Loss: 1.8344\n",
      "Validation loss improved from 1.8345 to 1.8344. Saving model...\n",
      "\n",
      "LOG: Epoch [1701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2533\n",
      "Epoch [1701/2000], Avg Train Loss: 3.2533\n",
      "Epoch [1701/2000], Avg Val Loss: 1.8342\n",
      "Validation loss improved from 1.8344 to 1.8342. Saving model...\n",
      "\n",
      "LOG: Epoch [1702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2285\n",
      "Epoch [1702/2000], Avg Train Loss: 3.2285\n",
      "Epoch [1702/2000], Avg Val Loss: 1.8341\n",
      "Validation loss improved from 1.8342 to 1.8341. Saving model...\n",
      "\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2957\n",
      "Epoch [1703/2000], Avg Train Loss: 3.2957\n",
      "Epoch [1703/2000], Avg Val Loss: 1.8339\n",
      "Validation loss improved from 1.8341 to 1.8339. Saving model...\n",
      "\n",
      "LOG: Epoch [1704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2458\n",
      "Epoch [1704/2000], Avg Train Loss: 3.2458\n",
      "Epoch [1704/2000], Avg Val Loss: 1.8338\n",
      "Validation loss improved from 1.8339 to 1.8338. Saving model...\n",
      "\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2660\n",
      "Epoch [1705/2000], Avg Train Loss: 3.2660\n",
      "Epoch [1705/2000], Avg Val Loss: 1.8336\n",
      "Validation loss improved from 1.8338 to 1.8336. Saving model...\n",
      "\n",
      "LOG: Epoch [1706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2804\n",
      "Epoch [1706/2000], Avg Train Loss: 3.2804\n",
      "Epoch [1706/2000], Avg Val Loss: 1.8335\n",
      "Validation loss improved from 1.8336 to 1.8335. Saving model...\n",
      "\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2686\n",
      "Epoch [1707/2000], Avg Train Loss: 3.2686\n",
      "Epoch [1707/2000], Avg Val Loss: 1.8334\n",
      "Validation loss improved from 1.8335 to 1.8334. Saving model...\n",
      "\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2449\n",
      "Epoch [1708/2000], Avg Train Loss: 3.2449\n",
      "Epoch [1708/2000], Avg Val Loss: 1.8333\n",
      "Validation loss improved from 1.8334 to 1.8333. Saving model...\n",
      "\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2540\n",
      "Epoch [1709/2000], Avg Train Loss: 3.2540\n",
      "Epoch [1709/2000], Avg Val Loss: 1.8332\n",
      "Validation loss improved from 1.8333 to 1.8332. Saving model...\n",
      "\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2737\n",
      "Epoch [1710/2000], Avg Train Loss: 3.2737\n",
      "Epoch [1710/2000], Avg Val Loss: 1.8331\n",
      "Validation loss improved from 1.8332 to 1.8331. Saving model...\n",
      "\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2493\n",
      "Epoch [1711/2000], Avg Train Loss: 3.2493\n",
      "Epoch [1711/2000], Avg Val Loss: 1.8330\n",
      "Validation loss improved from 1.8331 to 1.8330. Saving model...\n",
      "\n",
      "LOG: Epoch [1712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2598\n",
      "Epoch [1712/2000], Avg Train Loss: 3.2598\n",
      "Epoch [1712/2000], Avg Val Loss: 1.8328\n",
      "Validation loss improved from 1.8330 to 1.8328. Saving model...\n",
      "\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2612\n",
      "Epoch [1713/2000], Avg Train Loss: 3.2612\n",
      "Epoch [1713/2000], Avg Val Loss: 1.8327\n",
      "Validation loss improved from 1.8328 to 1.8327. Saving model...\n",
      "\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2851\n",
      "Epoch [1714/2000], Avg Train Loss: 3.2851\n",
      "Epoch [1714/2000], Avg Val Loss: 1.8325\n",
      "Validation loss improved from 1.8327 to 1.8325. Saving model...\n",
      "\n",
      "LOG: Epoch [1715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2442\n",
      "Epoch [1715/2000], Avg Train Loss: 3.2442\n",
      "Epoch [1715/2000], Avg Val Loss: 1.8323\n",
      "Validation loss improved from 1.8325 to 1.8323. Saving model...\n",
      "\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2875\n",
      "Epoch [1716/2000], Avg Train Loss: 3.2875\n",
      "Epoch [1716/2000], Avg Val Loss: 1.8323\n",
      "Validation loss improved from 1.8323 to 1.8323. Saving model...\n",
      "\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2461\n",
      "Epoch [1717/2000], Avg Train Loss: 3.2461\n",
      "Epoch [1717/2000], Avg Val Loss: 1.8322\n",
      "Validation loss improved from 1.8323 to 1.8322. Saving model...\n",
      "\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2595\n",
      "Epoch [1718/2000], Avg Train Loss: 3.2595\n",
      "Epoch [1718/2000], Avg Val Loss: 1.8321\n",
      "Validation loss improved from 1.8322 to 1.8321. Saving model...\n",
      "\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2537\n",
      "Epoch [1719/2000], Avg Train Loss: 3.2537\n",
      "Epoch [1719/2000], Avg Val Loss: 1.8320\n",
      "Validation loss improved from 1.8321 to 1.8320. Saving model...\n",
      "\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2599\n",
      "Epoch [1720/2000], Avg Train Loss: 3.2599\n",
      "Epoch [1720/2000], Avg Val Loss: 1.8319\n",
      "Validation loss improved from 1.8320 to 1.8319. Saving model...\n",
      "\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2761\n",
      "Epoch [1721/2000], Avg Train Loss: 3.2761\n",
      "Epoch [1721/2000], Avg Val Loss: 1.8320\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2337\n",
      "Epoch [1722/2000], Avg Train Loss: 3.2337\n",
      "Epoch [1722/2000], Avg Val Loss: 1.8320\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2726\n",
      "Epoch [1723/2000], Avg Train Loss: 3.2726\n",
      "Epoch [1723/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2810\n",
      "Epoch [1724/2000], Avg Train Loss: 3.2810\n",
      "Epoch [1724/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2577\n",
      "Epoch [1725/2000], Avg Train Loss: 3.2577\n",
      "Epoch [1725/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2490\n",
      "Epoch [1726/2000], Avg Train Loss: 3.2490\n",
      "Epoch [1726/2000], Avg Val Loss: 1.8322\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2415\n",
      "Epoch [1727/2000], Avg Train Loss: 3.2415\n",
      "Epoch [1727/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2504\n",
      "Epoch [1728/2000], Avg Train Loss: 3.2504\n",
      "Epoch [1728/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2563\n",
      "Epoch [1729/2000], Avg Train Loss: 3.2563\n",
      "Epoch [1729/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2603\n",
      "Epoch [1730/2000], Avg Train Loss: 3.2603\n",
      "Epoch [1730/2000], Avg Val Loss: 1.8320\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2710\n",
      "Epoch [1731/2000], Avg Train Loss: 3.2710\n",
      "Epoch [1731/2000], Avg Val Loss: 1.8319\n",
      "Validation loss improved from 1.8319 to 1.8319. Saving model...\n",
      "\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2296\n",
      "Epoch [1732/2000], Avg Train Loss: 3.2296\n",
      "Epoch [1732/2000], Avg Val Loss: 1.8318\n",
      "Validation loss improved from 1.8319 to 1.8318. Saving model...\n",
      "\n",
      "LOG: Epoch [1733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2492\n",
      "Epoch [1733/2000], Avg Train Loss: 3.2492\n",
      "Epoch [1733/2000], Avg Val Loss: 1.8317\n",
      "Validation loss improved from 1.8318 to 1.8317. Saving model...\n",
      "\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2688\n",
      "Epoch [1734/2000], Avg Train Loss: 3.2688\n",
      "Epoch [1734/2000], Avg Val Loss: 1.8316\n",
      "Validation loss improved from 1.8317 to 1.8316. Saving model...\n",
      "\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2258\n",
      "Epoch [1735/2000], Avg Train Loss: 3.2258\n",
      "Epoch [1735/2000], Avg Val Loss: 1.8316\n",
      "Validation loss improved from 1.8316 to 1.8316. Saving model...\n",
      "\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3015\n",
      "Epoch [1736/2000], Avg Train Loss: 3.3015\n",
      "Epoch [1736/2000], Avg Val Loss: 1.8316\n",
      "Validation loss improved from 1.8316 to 1.8316. Saving model...\n",
      "\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2739\n",
      "Epoch [1737/2000], Avg Train Loss: 3.2739\n",
      "Epoch [1737/2000], Avg Val Loss: 1.8316\n",
      "Validation loss improved from 1.8316 to 1.8316. Saving model...\n",
      "\n",
      "LOG: Epoch [1738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2414\n",
      "Epoch [1738/2000], Avg Train Loss: 3.2414\n",
      "Epoch [1738/2000], Avg Val Loss: 1.8315\n",
      "Validation loss improved from 1.8316 to 1.8315. Saving model...\n",
      "\n",
      "LOG: Epoch [1739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2672\n",
      "Epoch [1739/2000], Avg Train Loss: 3.2672\n",
      "Epoch [1739/2000], Avg Val Loss: 1.8315\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2551\n",
      "Epoch [1740/2000], Avg Train Loss: 3.2551\n",
      "Epoch [1740/2000], Avg Val Loss: 1.8316\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2733\n",
      "Epoch [1741/2000], Avg Train Loss: 3.2733\n",
      "Epoch [1741/2000], Avg Val Loss: 1.8316\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2109\n",
      "Epoch [1742/2000], Avg Train Loss: 3.2109\n",
      "Epoch [1742/2000], Avg Val Loss: 1.8317\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2518\n",
      "Epoch [1743/2000], Avg Train Loss: 3.2518\n",
      "Epoch [1743/2000], Avg Val Loss: 1.8317\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2591\n",
      "Epoch [1744/2000], Avg Train Loss: 3.2591\n",
      "Epoch [1744/2000], Avg Val Loss: 1.8317\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2498\n",
      "Epoch [1745/2000], Avg Train Loss: 3.2498\n",
      "Epoch [1745/2000], Avg Val Loss: 1.8317\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2612\n",
      "Epoch [1746/2000], Avg Train Loss: 3.2612\n",
      "Epoch [1746/2000], Avg Val Loss: 1.8318\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2323\n",
      "Epoch [1747/2000], Avg Train Loss: 3.2323\n",
      "Epoch [1747/2000], Avg Val Loss: 1.8318\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2525\n",
      "Epoch [1748/2000], Avg Train Loss: 3.2525\n",
      "Epoch [1748/2000], Avg Val Loss: 1.8319\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2532\n",
      "Epoch [1749/2000], Avg Train Loss: 3.2532\n",
      "Epoch [1749/2000], Avg Val Loss: 1.8320\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2488\n",
      "Epoch [1750/2000], Avg Train Loss: 3.2488\n",
      "Epoch [1750/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2537\n",
      "Epoch [1751/2000], Avg Train Loss: 3.2537\n",
      "Epoch [1751/2000], Avg Val Loss: 1.8321\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2650\n",
      "Epoch [1752/2000], Avg Train Loss: 3.2650\n",
      "Epoch [1752/2000], Avg Val Loss: 1.8320\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2495\n",
      "Epoch [1753/2000], Avg Train Loss: 3.2495\n",
      "Epoch [1753/2000], Avg Val Loss: 1.8319\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2748\n",
      "Epoch [1754/2000], Avg Train Loss: 3.2748\n",
      "Epoch [1754/2000], Avg Val Loss: 1.8317\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2337\n",
      "Epoch [1755/2000], Avg Train Loss: 3.2337\n",
      "Epoch [1755/2000], Avg Val Loss: 1.8316\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2690\n",
      "Epoch [1756/2000], Avg Train Loss: 3.2690\n",
      "Epoch [1756/2000], Avg Val Loss: 1.8315\n",
      "Validation loss improved from 1.8315 to 1.8315. Saving model...\n",
      "\n",
      "LOG: Epoch [1757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2551\n",
      "Epoch [1757/2000], Avg Train Loss: 3.2551\n",
      "Epoch [1757/2000], Avg Val Loss: 1.8314\n",
      "Validation loss improved from 1.8315 to 1.8314. Saving model...\n",
      "\n",
      "LOG: Epoch [1758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2271\n",
      "Epoch [1758/2000], Avg Train Loss: 3.2271\n",
      "Epoch [1758/2000], Avg Val Loss: 1.8313\n",
      "Validation loss improved from 1.8314 to 1.8313. Saving model...\n",
      "\n",
      "LOG: Epoch [1759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2506\n",
      "Epoch [1759/2000], Avg Train Loss: 3.2506\n",
      "Epoch [1759/2000], Avg Val Loss: 1.8312\n",
      "Validation loss improved from 1.8313 to 1.8312. Saving model...\n",
      "\n",
      "LOG: Epoch [1760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2430\n",
      "Epoch [1760/2000], Avg Train Loss: 3.2430\n",
      "Epoch [1760/2000], Avg Val Loss: 1.8312\n",
      "Validation loss improved from 1.8312 to 1.8312. Saving model...\n",
      "\n",
      "LOG: Epoch [1761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2505\n",
      "Epoch [1761/2000], Avg Train Loss: 3.2505\n",
      "Epoch [1761/2000], Avg Val Loss: 1.8313\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2525\n",
      "Epoch [1762/2000], Avg Train Loss: 3.2525\n",
      "Epoch [1762/2000], Avg Val Loss: 1.8313\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2434\n",
      "Epoch [1763/2000], Avg Train Loss: 3.2434\n",
      "Epoch [1763/2000], Avg Val Loss: 1.8313\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2713\n",
      "Epoch [1764/2000], Avg Train Loss: 3.2713\n",
      "Epoch [1764/2000], Avg Val Loss: 1.8314\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2350\n",
      "Epoch [1765/2000], Avg Train Loss: 3.2350\n",
      "Epoch [1765/2000], Avg Val Loss: 1.8314\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2397\n",
      "Epoch [1766/2000], Avg Train Loss: 3.2397\n",
      "Epoch [1766/2000], Avg Val Loss: 1.8314\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2266\n",
      "Epoch [1767/2000], Avg Train Loss: 3.2266\n",
      "Epoch [1767/2000], Avg Val Loss: 1.8313\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2755\n",
      "Epoch [1768/2000], Avg Train Loss: 3.2755\n",
      "Epoch [1768/2000], Avg Val Loss: 1.8312\n",
      "Validation loss improved from 1.8312 to 1.8312. Saving model...\n",
      "\n",
      "LOG: Epoch [1769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2452\n",
      "Epoch [1769/2000], Avg Train Loss: 3.2452\n",
      "Epoch [1769/2000], Avg Val Loss: 1.8311\n",
      "Validation loss improved from 1.8312 to 1.8311. Saving model...\n",
      "\n",
      "LOG: Epoch [1770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2662\n",
      "Epoch [1770/2000], Avg Train Loss: 3.2662\n",
      "Epoch [1770/2000], Avg Val Loss: 1.8310\n",
      "Validation loss improved from 1.8311 to 1.8310. Saving model...\n",
      "\n",
      "LOG: Epoch [1771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2455\n",
      "Epoch [1771/2000], Avg Train Loss: 3.2455\n",
      "Epoch [1771/2000], Avg Val Loss: 1.8309\n",
      "Validation loss improved from 1.8310 to 1.8309. Saving model...\n",
      "\n",
      "LOG: Epoch [1772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2453\n",
      "Epoch [1772/2000], Avg Train Loss: 3.2453\n",
      "Epoch [1772/2000], Avg Val Loss: 1.8308\n",
      "Validation loss improved from 1.8309 to 1.8308. Saving model...\n",
      "\n",
      "LOG: Epoch [1773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2245\n",
      "Epoch [1773/2000], Avg Train Loss: 3.2245\n",
      "Epoch [1773/2000], Avg Val Loss: 1.8307\n",
      "Validation loss improved from 1.8308 to 1.8307. Saving model...\n",
      "\n",
      "LOG: Epoch [1774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2620\n",
      "Epoch [1774/2000], Avg Train Loss: 3.2620\n",
      "Epoch [1774/2000], Avg Val Loss: 1.8306\n",
      "Validation loss improved from 1.8307 to 1.8306. Saving model...\n",
      "\n",
      "LOG: Epoch [1775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2504\n",
      "Epoch [1775/2000], Avg Train Loss: 3.2504\n",
      "Epoch [1775/2000], Avg Val Loss: 1.8305\n",
      "Validation loss improved from 1.8306 to 1.8305. Saving model...\n",
      "\n",
      "LOG: Epoch [1776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2500\n",
      "Epoch [1776/2000], Avg Train Loss: 3.2500\n",
      "Epoch [1776/2000], Avg Val Loss: 1.8303\n",
      "Validation loss improved from 1.8305 to 1.8303. Saving model...\n",
      "\n",
      "LOG: Epoch [1777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2596\n",
      "Epoch [1777/2000], Avg Train Loss: 3.2596\n",
      "Epoch [1777/2000], Avg Val Loss: 1.8301\n",
      "Validation loss improved from 1.8303 to 1.8301. Saving model...\n",
      "\n",
      "LOG: Epoch [1778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2243\n",
      "Epoch [1778/2000], Avg Train Loss: 3.2243\n",
      "Epoch [1778/2000], Avg Val Loss: 1.8299\n",
      "Validation loss improved from 1.8301 to 1.8299. Saving model...\n",
      "\n",
      "LOG: Epoch [1779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2463\n",
      "Epoch [1779/2000], Avg Train Loss: 3.2463\n",
      "Epoch [1779/2000], Avg Val Loss: 1.8296\n",
      "Validation loss improved from 1.8299 to 1.8296. Saving model...\n",
      "\n",
      "LOG: Epoch [1780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2222\n",
      "Epoch [1780/2000], Avg Train Loss: 3.2222\n",
      "Epoch [1780/2000], Avg Val Loss: 1.8294\n",
      "Validation loss improved from 1.8296 to 1.8294. Saving model...\n",
      "\n",
      "LOG: Epoch [1781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2226\n",
      "Epoch [1781/2000], Avg Train Loss: 3.2226\n",
      "Epoch [1781/2000], Avg Val Loss: 1.8292\n",
      "Validation loss improved from 1.8294 to 1.8292. Saving model...\n",
      "\n",
      "LOG: Epoch [1782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2534\n",
      "Epoch [1782/2000], Avg Train Loss: 3.2534\n",
      "Epoch [1782/2000], Avg Val Loss: 1.8289\n",
      "Validation loss improved from 1.8292 to 1.8289. Saving model...\n",
      "\n",
      "LOG: Epoch [1783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2410\n",
      "Epoch [1783/2000], Avg Train Loss: 3.2410\n",
      "Epoch [1783/2000], Avg Val Loss: 1.8287\n",
      "Validation loss improved from 1.8289 to 1.8287. Saving model...\n",
      "\n",
      "LOG: Epoch [1784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2604\n",
      "Epoch [1784/2000], Avg Train Loss: 3.2604\n",
      "Epoch [1784/2000], Avg Val Loss: 1.8283\n",
      "Validation loss improved from 1.8287 to 1.8283. Saving model...\n",
      "\n",
      "LOG: Epoch [1785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2362\n",
      "Epoch [1785/2000], Avg Train Loss: 3.2362\n",
      "Epoch [1785/2000], Avg Val Loss: 1.8280\n",
      "Validation loss improved from 1.8283 to 1.8280. Saving model...\n",
      "\n",
      "LOG: Epoch [1786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2441\n",
      "Epoch [1786/2000], Avg Train Loss: 3.2441\n",
      "Epoch [1786/2000], Avg Val Loss: 1.8277\n",
      "Validation loss improved from 1.8280 to 1.8277. Saving model...\n",
      "\n",
      "LOG: Epoch [1787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2446\n",
      "Epoch [1787/2000], Avg Train Loss: 3.2446\n",
      "Epoch [1787/2000], Avg Val Loss: 1.8274\n",
      "Validation loss improved from 1.8277 to 1.8274. Saving model...\n",
      "\n",
      "LOG: Epoch [1788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2370\n",
      "Epoch [1788/2000], Avg Train Loss: 3.2370\n",
      "Epoch [1788/2000], Avg Val Loss: 1.8272\n",
      "Validation loss improved from 1.8274 to 1.8272. Saving model...\n",
      "\n",
      "LOG: Epoch [1789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2474\n",
      "Epoch [1789/2000], Avg Train Loss: 3.2474\n",
      "Epoch [1789/2000], Avg Val Loss: 1.8270\n",
      "Validation loss improved from 1.8272 to 1.8270. Saving model...\n",
      "\n",
      "LOG: Epoch [1790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2340\n",
      "Epoch [1790/2000], Avg Train Loss: 3.2340\n",
      "Epoch [1790/2000], Avg Val Loss: 1.8269\n",
      "Validation loss improved from 1.8270 to 1.8269. Saving model...\n",
      "\n",
      "LOG: Epoch [1791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2728\n",
      "Epoch [1791/2000], Avg Train Loss: 3.2728\n",
      "Epoch [1791/2000], Avg Val Loss: 1.8268\n",
      "Validation loss improved from 1.8269 to 1.8268. Saving model...\n",
      "\n",
      "LOG: Epoch [1792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2469\n",
      "Epoch [1792/2000], Avg Train Loss: 3.2469\n",
      "Epoch [1792/2000], Avg Val Loss: 1.8267\n",
      "Validation loss improved from 1.8268 to 1.8267. Saving model...\n",
      "\n",
      "LOG: Epoch [1793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2345\n",
      "Epoch [1793/2000], Avg Train Loss: 3.2345\n",
      "Epoch [1793/2000], Avg Val Loss: 1.8266\n",
      "Validation loss improved from 1.8267 to 1.8266. Saving model...\n",
      "\n",
      "LOG: Epoch [1794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2467\n",
      "Epoch [1794/2000], Avg Train Loss: 3.2467\n",
      "Epoch [1794/2000], Avg Val Loss: 1.8267\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2467\n",
      "Epoch [1795/2000], Avg Train Loss: 3.2467\n",
      "Epoch [1795/2000], Avg Val Loss: 1.8267\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2320\n",
      "Epoch [1796/2000], Avg Train Loss: 3.2320\n",
      "Epoch [1796/2000], Avg Val Loss: 1.8268\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2640\n",
      "Epoch [1797/2000], Avg Train Loss: 3.2640\n",
      "Epoch [1797/2000], Avg Val Loss: 1.8269\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2494\n",
      "Epoch [1798/2000], Avg Train Loss: 3.2494\n",
      "Epoch [1798/2000], Avg Val Loss: 1.8269\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2153\n",
      "Epoch [1799/2000], Avg Train Loss: 3.2153\n",
      "Epoch [1799/2000], Avg Val Loss: 1.8270\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2889\n",
      "Epoch [1800/2000], Avg Train Loss: 3.2889\n",
      "Epoch [1800/2000], Avg Val Loss: 1.8269\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2440\n",
      "Epoch [1801/2000], Avg Train Loss: 3.2440\n",
      "Epoch [1801/2000], Avg Val Loss: 1.8268\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2553\n",
      "Epoch [1802/2000], Avg Train Loss: 3.2553\n",
      "Epoch [1802/2000], Avg Val Loss: 1.8268\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2151\n",
      "Epoch [1803/2000], Avg Train Loss: 3.2151\n",
      "Epoch [1803/2000], Avg Val Loss: 1.8267\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2376\n",
      "Epoch [1804/2000], Avg Train Loss: 3.2376\n",
      "Epoch [1804/2000], Avg Val Loss: 1.8266\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2178\n",
      "Epoch [1805/2000], Avg Train Loss: 3.2178\n",
      "Epoch [1805/2000], Avg Val Loss: 1.8266\n",
      "Validation loss improved from 1.8266 to 1.8266. Saving model...\n",
      "\n",
      "LOG: Epoch [1806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2577\n",
      "Epoch [1806/2000], Avg Train Loss: 3.2577\n",
      "Epoch [1806/2000], Avg Val Loss: 1.8265\n",
      "Validation loss improved from 1.8266 to 1.8265. Saving model...\n",
      "\n",
      "LOG: Epoch [1807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2347\n",
      "Epoch [1807/2000], Avg Train Loss: 3.2347\n",
      "Epoch [1807/2000], Avg Val Loss: 1.8265\n",
      "Validation loss improved from 1.8265 to 1.8265. Saving model...\n",
      "\n",
      "LOG: Epoch [1808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2586\n",
      "Epoch [1808/2000], Avg Train Loss: 3.2586\n",
      "Epoch [1808/2000], Avg Val Loss: 1.8264\n",
      "Validation loss improved from 1.8265 to 1.8264. Saving model...\n",
      "\n",
      "LOG: Epoch [1809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2323\n",
      "Epoch [1809/2000], Avg Train Loss: 3.2323\n",
      "Epoch [1809/2000], Avg Val Loss: 1.8264\n",
      "Validation loss improved from 1.8264 to 1.8264. Saving model...\n",
      "\n",
      "LOG: Epoch [1810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2105\n",
      "Epoch [1810/2000], Avg Train Loss: 3.2105\n",
      "Epoch [1810/2000], Avg Val Loss: 1.8264\n",
      "Validation loss improved from 1.8264 to 1.8264. Saving model...\n",
      "\n",
      "LOG: Epoch [1811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2511\n",
      "Epoch [1811/2000], Avg Train Loss: 3.2511\n",
      "Epoch [1811/2000], Avg Val Loss: 1.8263\n",
      "Validation loss improved from 1.8264 to 1.8263. Saving model...\n",
      "\n",
      "LOG: Epoch [1812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2395\n",
      "Epoch [1812/2000], Avg Train Loss: 3.2395\n",
      "Epoch [1812/2000], Avg Val Loss: 1.8264\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2472\n",
      "Epoch [1813/2000], Avg Train Loss: 3.2472\n",
      "Epoch [1813/2000], Avg Val Loss: 1.8263\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2308\n",
      "Epoch [1814/2000], Avg Train Loss: 3.2308\n",
      "Epoch [1814/2000], Avg Val Loss: 1.8263\n",
      "Validation loss improved from 1.8263 to 1.8263. Saving model...\n",
      "\n",
      "LOG: Epoch [1815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2358\n",
      "Epoch [1815/2000], Avg Train Loss: 3.2358\n",
      "Epoch [1815/2000], Avg Val Loss: 1.8262\n",
      "Validation loss improved from 1.8263 to 1.8262. Saving model...\n",
      "\n",
      "LOG: Epoch [1816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2466\n",
      "Epoch [1816/2000], Avg Train Loss: 3.2466\n",
      "Epoch [1816/2000], Avg Val Loss: 1.8261\n",
      "Validation loss improved from 1.8262 to 1.8261. Saving model...\n",
      "\n",
      "LOG: Epoch [1817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2867\n",
      "Epoch [1817/2000], Avg Train Loss: 3.2867\n",
      "Epoch [1817/2000], Avg Val Loss: 1.8260\n",
      "Validation loss improved from 1.8261 to 1.8260. Saving model...\n",
      "\n",
      "LOG: Epoch [1818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2027\n",
      "Epoch [1818/2000], Avg Train Loss: 3.2027\n",
      "Epoch [1818/2000], Avg Val Loss: 1.8259\n",
      "Validation loss improved from 1.8260 to 1.8259. Saving model...\n",
      "\n",
      "LOG: Epoch [1819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2525\n",
      "Epoch [1819/2000], Avg Train Loss: 3.2525\n",
      "Epoch [1819/2000], Avg Val Loss: 1.8258\n",
      "Validation loss improved from 1.8259 to 1.8258. Saving model...\n",
      "\n",
      "LOG: Epoch [1820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2484\n",
      "Epoch [1820/2000], Avg Train Loss: 3.2484\n",
      "Epoch [1820/2000], Avg Val Loss: 1.8257\n",
      "Validation loss improved from 1.8258 to 1.8257. Saving model...\n",
      "\n",
      "LOG: Epoch [1821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2243\n",
      "Epoch [1821/2000], Avg Train Loss: 3.2243\n",
      "Epoch [1821/2000], Avg Val Loss: 1.8256\n",
      "Validation loss improved from 1.8257 to 1.8256. Saving model...\n",
      "\n",
      "LOG: Epoch [1822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2281\n",
      "Epoch [1822/2000], Avg Train Loss: 3.2281\n",
      "Epoch [1822/2000], Avg Val Loss: 1.8256\n",
      "Validation loss improved from 1.8256 to 1.8256. Saving model...\n",
      "\n",
      "LOG: Epoch [1823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2345\n",
      "Epoch [1823/2000], Avg Train Loss: 3.2345\n",
      "Epoch [1823/2000], Avg Val Loss: 1.8255\n",
      "Validation loss improved from 1.8256 to 1.8255. Saving model...\n",
      "\n",
      "LOG: Epoch [1824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2149\n",
      "Epoch [1824/2000], Avg Train Loss: 3.2149\n",
      "Epoch [1824/2000], Avg Val Loss: 1.8254\n",
      "Validation loss improved from 1.8255 to 1.8254. Saving model...\n",
      "\n",
      "LOG: Epoch [1825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2234\n",
      "Epoch [1825/2000], Avg Train Loss: 3.2234\n",
      "Epoch [1825/2000], Avg Val Loss: 1.8254\n",
      "Validation loss improved from 1.8254 to 1.8254. Saving model...\n",
      "\n",
      "LOG: Epoch [1826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2852\n",
      "Epoch [1826/2000], Avg Train Loss: 3.2852\n",
      "Epoch [1826/2000], Avg Val Loss: 1.8253\n",
      "Validation loss improved from 1.8254 to 1.8253. Saving model...\n",
      "\n",
      "LOG: Epoch [1827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2348\n",
      "Epoch [1827/2000], Avg Train Loss: 3.2348\n",
      "Epoch [1827/2000], Avg Val Loss: 1.8251\n",
      "Validation loss improved from 1.8253 to 1.8251. Saving model...\n",
      "\n",
      "LOG: Epoch [1828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2309\n",
      "Epoch [1828/2000], Avg Train Loss: 3.2309\n",
      "Epoch [1828/2000], Avg Val Loss: 1.8250\n",
      "Validation loss improved from 1.8251 to 1.8250. Saving model...\n",
      "\n",
      "LOG: Epoch [1829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2354\n",
      "Epoch [1829/2000], Avg Train Loss: 3.2354\n",
      "Epoch [1829/2000], Avg Val Loss: 1.8250\n",
      "Validation loss improved from 1.8250 to 1.8250. Saving model...\n",
      "\n",
      "LOG: Epoch [1830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2429\n",
      "Epoch [1830/2000], Avg Train Loss: 3.2429\n",
      "Epoch [1830/2000], Avg Val Loss: 1.8250\n",
      "Validation loss improved from 1.8250 to 1.8250. Saving model...\n",
      "\n",
      "LOG: Epoch [1831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2727\n",
      "Epoch [1831/2000], Avg Train Loss: 3.2727\n",
      "Epoch [1831/2000], Avg Val Loss: 1.8249\n",
      "Validation loss improved from 1.8250 to 1.8249. Saving model...\n",
      "\n",
      "LOG: Epoch [1832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2409\n",
      "Epoch [1832/2000], Avg Train Loss: 3.2409\n",
      "Epoch [1832/2000], Avg Val Loss: 1.8248\n",
      "Validation loss improved from 1.8249 to 1.8248. Saving model...\n",
      "\n",
      "LOG: Epoch [1833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2561\n",
      "Epoch [1833/2000], Avg Train Loss: 3.2561\n",
      "Epoch [1833/2000], Avg Val Loss: 1.8246\n",
      "Validation loss improved from 1.8248 to 1.8246. Saving model...\n",
      "\n",
      "LOG: Epoch [1834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2811\n",
      "Epoch [1834/2000], Avg Train Loss: 3.2811\n",
      "Epoch [1834/2000], Avg Val Loss: 1.8246\n",
      "Validation loss improved from 1.8246 to 1.8246. Saving model...\n",
      "\n",
      "LOG: Epoch [1835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2311\n",
      "Epoch [1835/2000], Avg Train Loss: 3.2311\n",
      "Epoch [1835/2000], Avg Val Loss: 1.8245\n",
      "Validation loss improved from 1.8246 to 1.8245. Saving model...\n",
      "\n",
      "LOG: Epoch [1836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2097\n",
      "Epoch [1836/2000], Avg Train Loss: 3.2097\n",
      "Epoch [1836/2000], Avg Val Loss: 1.8244\n",
      "Validation loss improved from 1.8245 to 1.8244. Saving model...\n",
      "\n",
      "LOG: Epoch [1837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2256\n",
      "Epoch [1837/2000], Avg Train Loss: 3.2256\n",
      "Epoch [1837/2000], Avg Val Loss: 1.8243\n",
      "Validation loss improved from 1.8244 to 1.8243. Saving model...\n",
      "\n",
      "LOG: Epoch [1838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2470\n",
      "Epoch [1838/2000], Avg Train Loss: 3.2470\n",
      "Epoch [1838/2000], Avg Val Loss: 1.8242\n",
      "Validation loss improved from 1.8243 to 1.8242. Saving model...\n",
      "\n",
      "LOG: Epoch [1839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2522\n",
      "Epoch [1839/2000], Avg Train Loss: 3.2522\n",
      "Epoch [1839/2000], Avg Val Loss: 1.8240\n",
      "Validation loss improved from 1.8242 to 1.8240. Saving model...\n",
      "\n",
      "LOG: Epoch [1840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2291\n",
      "Epoch [1840/2000], Avg Train Loss: 3.2291\n",
      "Epoch [1840/2000], Avg Val Loss: 1.8238\n",
      "Validation loss improved from 1.8240 to 1.8238. Saving model...\n",
      "\n",
      "LOG: Epoch [1841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2495\n",
      "Epoch [1841/2000], Avg Train Loss: 3.2495\n",
      "Epoch [1841/2000], Avg Val Loss: 1.8237\n",
      "Validation loss improved from 1.8238 to 1.8237. Saving model...\n",
      "\n",
      "LOG: Epoch [1842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2141\n",
      "Epoch [1842/2000], Avg Train Loss: 3.2141\n",
      "Epoch [1842/2000], Avg Val Loss: 1.8235\n",
      "Validation loss improved from 1.8237 to 1.8235. Saving model...\n",
      "\n",
      "LOG: Epoch [1843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2211\n",
      "Epoch [1843/2000], Avg Train Loss: 3.2211\n",
      "Epoch [1843/2000], Avg Val Loss: 1.8234\n",
      "Validation loss improved from 1.8235 to 1.8234. Saving model...\n",
      "\n",
      "LOG: Epoch [1844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2554\n",
      "Epoch [1844/2000], Avg Train Loss: 3.2554\n",
      "Epoch [1844/2000], Avg Val Loss: 1.8233\n",
      "Validation loss improved from 1.8234 to 1.8233. Saving model...\n",
      "\n",
      "LOG: Epoch [1845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2594\n",
      "Epoch [1845/2000], Avg Train Loss: 3.2594\n",
      "Epoch [1845/2000], Avg Val Loss: 1.8231\n",
      "Validation loss improved from 1.8233 to 1.8231. Saving model...\n",
      "\n",
      "LOG: Epoch [1846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2472\n",
      "Epoch [1846/2000], Avg Train Loss: 3.2472\n",
      "Epoch [1846/2000], Avg Val Loss: 1.8230\n",
      "Validation loss improved from 1.8231 to 1.8230. Saving model...\n",
      "\n",
      "LOG: Epoch [1847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2172\n",
      "Epoch [1847/2000], Avg Train Loss: 3.2172\n",
      "Epoch [1847/2000], Avg Val Loss: 1.8228\n",
      "Validation loss improved from 1.8230 to 1.8228. Saving model...\n",
      "\n",
      "LOG: Epoch [1848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2313\n",
      "Epoch [1848/2000], Avg Train Loss: 3.2313\n",
      "Epoch [1848/2000], Avg Val Loss: 1.8227\n",
      "Validation loss improved from 1.8228 to 1.8227. Saving model...\n",
      "\n",
      "LOG: Epoch [1849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2336\n",
      "Epoch [1849/2000], Avg Train Loss: 3.2336\n",
      "Epoch [1849/2000], Avg Val Loss: 1.8227\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2647\n",
      "Epoch [1850/2000], Avg Train Loss: 3.2647\n",
      "Epoch [1850/2000], Avg Val Loss: 1.8228\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2352\n",
      "Epoch [1851/2000], Avg Train Loss: 3.2352\n",
      "Epoch [1851/2000], Avg Val Loss: 1.8229\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2396\n",
      "Epoch [1852/2000], Avg Train Loss: 3.2396\n",
      "Epoch [1852/2000], Avg Val Loss: 1.8230\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2488\n",
      "Epoch [1853/2000], Avg Train Loss: 3.2488\n",
      "Epoch [1853/2000], Avg Val Loss: 1.8231\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2256\n",
      "Epoch [1854/2000], Avg Train Loss: 3.2256\n",
      "Epoch [1854/2000], Avg Val Loss: 1.8232\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2383\n",
      "Epoch [1855/2000], Avg Train Loss: 3.2383\n",
      "Epoch [1855/2000], Avg Val Loss: 1.8234\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2182\n",
      "Epoch [1856/2000], Avg Train Loss: 3.2182\n",
      "Epoch [1856/2000], Avg Val Loss: 1.8235\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2104\n",
      "Epoch [1857/2000], Avg Train Loss: 3.2104\n",
      "Epoch [1857/2000], Avg Val Loss: 1.8236\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2339\n",
      "Epoch [1858/2000], Avg Train Loss: 3.2339\n",
      "Epoch [1858/2000], Avg Val Loss: 1.8237\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2379\n",
      "Epoch [1859/2000], Avg Train Loss: 3.2379\n",
      "Epoch [1859/2000], Avg Val Loss: 1.8239\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2436\n",
      "Epoch [1860/2000], Avg Train Loss: 3.2436\n",
      "Epoch [1860/2000], Avg Val Loss: 1.8240\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2291\n",
      "Epoch [1861/2000], Avg Train Loss: 3.2291\n",
      "Epoch [1861/2000], Avg Val Loss: 1.8241\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2249\n",
      "Epoch [1862/2000], Avg Train Loss: 3.2249\n",
      "Epoch [1862/2000], Avg Val Loss: 1.8242\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2485\n",
      "Epoch [1863/2000], Avg Train Loss: 3.2485\n",
      "Epoch [1863/2000], Avg Val Loss: 1.8242\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2541\n",
      "Epoch [1864/2000], Avg Train Loss: 3.2541\n",
      "Epoch [1864/2000], Avg Val Loss: 1.8242\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2282\n",
      "Epoch [1865/2000], Avg Train Loss: 3.2282\n",
      "Epoch [1865/2000], Avg Val Loss: 1.8242\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2170\n",
      "Epoch [1866/2000], Avg Train Loss: 3.2170\n",
      "Epoch [1866/2000], Avg Val Loss: 1.8240\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2164\n",
      "Epoch [1867/2000], Avg Train Loss: 3.2164\n",
      "Epoch [1867/2000], Avg Val Loss: 1.8240\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2517\n",
      "Epoch [1868/2000], Avg Train Loss: 3.2517\n",
      "Epoch [1868/2000], Avg Val Loss: 1.8240\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2356\n",
      "Epoch [1869/2000], Avg Train Loss: 3.2356\n",
      "Epoch [1869/2000], Avg Val Loss: 1.8240\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2185\n",
      "Epoch [1870/2000], Avg Train Loss: 3.2185\n",
      "Epoch [1870/2000], Avg Val Loss: 1.8239\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2242\n",
      "Epoch [1871/2000], Avg Train Loss: 3.2242\n",
      "Epoch [1871/2000], Avg Val Loss: 1.8239\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2321\n",
      "Epoch [1872/2000], Avg Train Loss: 3.2321\n",
      "Epoch [1872/2000], Avg Val Loss: 1.8239\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2009\n",
      "Epoch [1873/2000], Avg Train Loss: 3.2009\n",
      "Epoch [1873/2000], Avg Val Loss: 1.8238\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2046\n",
      "Epoch [1874/2000], Avg Train Loss: 3.2046\n",
      "Epoch [1874/2000], Avg Val Loss: 1.8237\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2341\n",
      "Epoch [1875/2000], Avg Train Loss: 3.2341\n",
      "Epoch [1875/2000], Avg Val Loss: 1.8236\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2249\n",
      "Epoch [1876/2000], Avg Train Loss: 3.2249\n",
      "Epoch [1876/2000], Avg Val Loss: 1.8234\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2318\n",
      "Epoch [1877/2000], Avg Train Loss: 3.2318\n",
      "Epoch [1877/2000], Avg Val Loss: 1.8232\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2527\n",
      "Epoch [1878/2000], Avg Train Loss: 3.2527\n",
      "Epoch [1878/2000], Avg Val Loss: 1.8230\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2394\n",
      "Epoch [1879/2000], Avg Train Loss: 3.2394\n",
      "Epoch [1879/2000], Avg Val Loss: 1.8230\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2208\n",
      "Epoch [1880/2000], Avg Train Loss: 3.2208\n",
      "Epoch [1880/2000], Avg Val Loss: 1.8229\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2395\n",
      "Epoch [1881/2000], Avg Train Loss: 3.2395\n",
      "Epoch [1881/2000], Avg Val Loss: 1.8228\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2278\n",
      "Epoch [1882/2000], Avg Train Loss: 3.2278\n",
      "Epoch [1882/2000], Avg Val Loss: 1.8228\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2538\n",
      "Epoch [1883/2000], Avg Train Loss: 3.2538\n",
      "Epoch [1883/2000], Avg Val Loss: 1.8227\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2434\n",
      "Epoch [1884/2000], Avg Train Loss: 3.2434\n",
      "Epoch [1884/2000], Avg Val Loss: 1.8226\n",
      "Validation loss improved from 1.8227 to 1.8226. Saving model...\n",
      "\n",
      "LOG: Epoch [1885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2526\n",
      "Epoch [1885/2000], Avg Train Loss: 3.2526\n",
      "Epoch [1885/2000], Avg Val Loss: 1.8225\n",
      "Validation loss improved from 1.8226 to 1.8225. Saving model...\n",
      "\n",
      "LOG: Epoch [1886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2533\n",
      "Epoch [1886/2000], Avg Train Loss: 3.2533\n",
      "Epoch [1886/2000], Avg Val Loss: 1.8224\n",
      "Validation loss improved from 1.8225 to 1.8224. Saving model...\n",
      "\n",
      "LOG: Epoch [1887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2328\n",
      "Epoch [1887/2000], Avg Train Loss: 3.2328\n",
      "Epoch [1887/2000], Avg Val Loss: 1.8223\n",
      "Validation loss improved from 1.8224 to 1.8223. Saving model...\n",
      "\n",
      "LOG: Epoch [1888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2211\n",
      "Epoch [1888/2000], Avg Train Loss: 3.2211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1888/2000], Avg Val Loss: 1.8221\n",
      "Validation loss improved from 1.8223 to 1.8221. Saving model...\n",
      "\n",
      "LOG: Epoch [1889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2208\n",
      "Epoch [1889/2000], Avg Train Loss: 3.2208\n",
      "Epoch [1889/2000], Avg Val Loss: 1.8220\n",
      "Validation loss improved from 1.8221 to 1.8220. Saving model...\n",
      "\n",
      "LOG: Epoch [1890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2258\n",
      "Epoch [1890/2000], Avg Train Loss: 3.2258\n",
      "Epoch [1890/2000], Avg Val Loss: 1.8218\n",
      "Validation loss improved from 1.8220 to 1.8218. Saving model...\n",
      "\n",
      "LOG: Epoch [1891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2602\n",
      "Epoch [1891/2000], Avg Train Loss: 3.2602\n",
      "Epoch [1891/2000], Avg Val Loss: 1.8216\n",
      "Validation loss improved from 1.8218 to 1.8216. Saving model...\n",
      "\n",
      "LOG: Epoch [1892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2354\n",
      "Epoch [1892/2000], Avg Train Loss: 3.2354\n",
      "Epoch [1892/2000], Avg Val Loss: 1.8215\n",
      "Validation loss improved from 1.8216 to 1.8215. Saving model...\n",
      "\n",
      "LOG: Epoch [1893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2246\n",
      "Epoch [1893/2000], Avg Train Loss: 3.2246\n",
      "Epoch [1893/2000], Avg Val Loss: 1.8212\n",
      "Validation loss improved from 1.8215 to 1.8212. Saving model...\n",
      "\n",
      "LOG: Epoch [1894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2381\n",
      "Epoch [1894/2000], Avg Train Loss: 3.2381\n",
      "Epoch [1894/2000], Avg Val Loss: 1.8209\n",
      "Validation loss improved from 1.8212 to 1.8209. Saving model...\n",
      "\n",
      "LOG: Epoch [1895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2443\n",
      "Epoch [1895/2000], Avg Train Loss: 3.2443\n",
      "Epoch [1895/2000], Avg Val Loss: 1.8206\n",
      "Validation loss improved from 1.8209 to 1.8206. Saving model...\n",
      "\n",
      "LOG: Epoch [1896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2576\n",
      "Epoch [1896/2000], Avg Train Loss: 3.2576\n",
      "Epoch [1896/2000], Avg Val Loss: 1.8203\n",
      "Validation loss improved from 1.8206 to 1.8203. Saving model...\n",
      "\n",
      "LOG: Epoch [1897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2452\n",
      "Epoch [1897/2000], Avg Train Loss: 3.2452\n",
      "Epoch [1897/2000], Avg Val Loss: 1.8201\n",
      "Validation loss improved from 1.8203 to 1.8201. Saving model...\n",
      "\n",
      "LOG: Epoch [1898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2413\n",
      "Epoch [1898/2000], Avg Train Loss: 3.2413\n",
      "Epoch [1898/2000], Avg Val Loss: 1.8198\n",
      "Validation loss improved from 1.8201 to 1.8198. Saving model...\n",
      "\n",
      "LOG: Epoch [1899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2410\n",
      "Epoch [1899/2000], Avg Train Loss: 3.2410\n",
      "Epoch [1899/2000], Avg Val Loss: 1.8196\n",
      "Validation loss improved from 1.8198 to 1.8196. Saving model...\n",
      "\n",
      "LOG: Epoch [1900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2500\n",
      "Epoch [1900/2000], Avg Train Loss: 3.2500\n",
      "Epoch [1900/2000], Avg Val Loss: 1.8194\n",
      "Validation loss improved from 1.8196 to 1.8194. Saving model...\n",
      "\n",
      "LOG: Epoch [1901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2342\n",
      "Epoch [1901/2000], Avg Train Loss: 3.2342\n",
      "Epoch [1901/2000], Avg Val Loss: 1.8191\n",
      "Validation loss improved from 1.8194 to 1.8191. Saving model...\n",
      "\n",
      "LOG: Epoch [1902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2417\n",
      "Epoch [1902/2000], Avg Train Loss: 3.2417\n",
      "Epoch [1902/2000], Avg Val Loss: 1.8189\n",
      "Validation loss improved from 1.8191 to 1.8189. Saving model...\n",
      "\n",
      "LOG: Epoch [1903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2610\n",
      "Epoch [1903/2000], Avg Train Loss: 3.2610\n",
      "Epoch [1903/2000], Avg Val Loss: 1.8187\n",
      "Validation loss improved from 1.8189 to 1.8187. Saving model...\n",
      "\n",
      "LOG: Epoch [1904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2400\n",
      "Epoch [1904/2000], Avg Train Loss: 3.2400\n",
      "Epoch [1904/2000], Avg Val Loss: 1.8186\n",
      "Validation loss improved from 1.8187 to 1.8186. Saving model...\n",
      "\n",
      "LOG: Epoch [1905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2231\n",
      "Epoch [1905/2000], Avg Train Loss: 3.2231\n",
      "Epoch [1905/2000], Avg Val Loss: 1.8185\n",
      "Validation loss improved from 1.8186 to 1.8185. Saving model...\n",
      "\n",
      "LOG: Epoch [1906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2583\n",
      "Epoch [1906/2000], Avg Train Loss: 3.2583\n",
      "Epoch [1906/2000], Avg Val Loss: 1.8184\n",
      "Validation loss improved from 1.8185 to 1.8184. Saving model...\n",
      "\n",
      "LOG: Epoch [1907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2238\n",
      "Epoch [1907/2000], Avg Train Loss: 3.2238\n",
      "Epoch [1907/2000], Avg Val Loss: 1.8184\n",
      "Validation loss improved from 1.8184 to 1.8184. Saving model...\n",
      "\n",
      "LOG: Epoch [1908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2285\n",
      "Epoch [1908/2000], Avg Train Loss: 3.2285\n",
      "Epoch [1908/2000], Avg Val Loss: 1.8183\n",
      "Validation loss improved from 1.8184 to 1.8183. Saving model...\n",
      "\n",
      "LOG: Epoch [1909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2269\n",
      "Epoch [1909/2000], Avg Train Loss: 3.2269\n",
      "Epoch [1909/2000], Avg Val Loss: 1.8183\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2166\n",
      "Epoch [1910/2000], Avg Train Loss: 3.2166\n",
      "Epoch [1910/2000], Avg Val Loss: 1.8183\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2379\n",
      "Epoch [1911/2000], Avg Train Loss: 3.2379\n",
      "Epoch [1911/2000], Avg Val Loss: 1.8184\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2228\n",
      "Epoch [1912/2000], Avg Train Loss: 3.2228\n",
      "Epoch [1912/2000], Avg Val Loss: 1.8184\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2246\n",
      "Epoch [1913/2000], Avg Train Loss: 3.2246\n",
      "Epoch [1913/2000], Avg Val Loss: 1.8185\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2350\n",
      "Epoch [1914/2000], Avg Train Loss: 3.2350\n",
      "Epoch [1914/2000], Avg Val Loss: 1.8185\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2093\n",
      "Epoch [1915/2000], Avg Train Loss: 3.2093\n",
      "Epoch [1915/2000], Avg Val Loss: 1.8185\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2233\n",
      "Epoch [1916/2000], Avg Train Loss: 3.2233\n",
      "Epoch [1916/2000], Avg Val Loss: 1.8185\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2330\n",
      "Epoch [1917/2000], Avg Train Loss: 3.2330\n",
      "Epoch [1917/2000], Avg Val Loss: 1.8186\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2379\n",
      "Epoch [1918/2000], Avg Train Loss: 3.2379\n",
      "Epoch [1918/2000], Avg Val Loss: 1.8187\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2080\n",
      "Epoch [1919/2000], Avg Train Loss: 3.2080\n",
      "Epoch [1919/2000], Avg Val Loss: 1.8188\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2147\n",
      "Epoch [1920/2000], Avg Train Loss: 3.2147\n",
      "Epoch [1920/2000], Avg Val Loss: 1.8189\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2315\n",
      "Epoch [1921/2000], Avg Train Loss: 3.2315\n",
      "Epoch [1921/2000], Avg Val Loss: 1.8190\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2090\n",
      "Epoch [1922/2000], Avg Train Loss: 3.2090\n",
      "Epoch [1922/2000], Avg Val Loss: 1.8191\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1871\n",
      "Epoch [1923/2000], Avg Train Loss: 3.1871\n",
      "Epoch [1923/2000], Avg Val Loss: 1.8192\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2131\n",
      "Epoch [1924/2000], Avg Train Loss: 3.2131\n",
      "Epoch [1924/2000], Avg Val Loss: 1.8192\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2367\n",
      "Epoch [1925/2000], Avg Train Loss: 3.2367\n",
      "Epoch [1925/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2466\n",
      "Epoch [1926/2000], Avg Train Loss: 3.2466\n",
      "Epoch [1926/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2491\n",
      "Epoch [1927/2000], Avg Train Loss: 3.2491\n",
      "Epoch [1927/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2002\n",
      "Epoch [1928/2000], Avg Train Loss: 3.2002\n",
      "Epoch [1928/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2214\n",
      "Epoch [1929/2000], Avg Train Loss: 3.2214\n",
      "Epoch [1929/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2333\n",
      "Epoch [1930/2000], Avg Train Loss: 3.2333\n",
      "Epoch [1930/2000], Avg Val Loss: 1.8192\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2291\n",
      "Epoch [1931/2000], Avg Train Loss: 3.2291\n",
      "Epoch [1931/2000], Avg Val Loss: 1.8191\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2159\n",
      "Epoch [1932/2000], Avg Train Loss: 3.2159\n",
      "Epoch [1932/2000], Avg Val Loss: 1.8190\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2159\n",
      "Epoch [1933/2000], Avg Train Loss: 3.2159\n",
      "Epoch [1933/2000], Avg Val Loss: 1.8190\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2266\n",
      "Epoch [1934/2000], Avg Train Loss: 3.2266\n",
      "Epoch [1934/2000], Avg Val Loss: 1.8189\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2337\n",
      "Epoch [1935/2000], Avg Train Loss: 3.2337\n",
      "Epoch [1935/2000], Avg Val Loss: 1.8188\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2193\n",
      "Epoch [1936/2000], Avg Train Loss: 3.2193\n",
      "Epoch [1936/2000], Avg Val Loss: 1.8188\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2132\n",
      "Epoch [1937/2000], Avg Train Loss: 3.2132\n",
      "Epoch [1937/2000], Avg Val Loss: 1.8188\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2081\n",
      "Epoch [1938/2000], Avg Train Loss: 3.2081\n",
      "Epoch [1938/2000], Avg Val Loss: 1.8188\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2364\n",
      "Epoch [1939/2000], Avg Train Loss: 3.2364\n",
      "Epoch [1939/2000], Avg Val Loss: 1.8190\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2096\n",
      "Epoch [1940/2000], Avg Train Loss: 3.2096\n",
      "Epoch [1940/2000], Avg Val Loss: 1.8192\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2436\n",
      "Epoch [1941/2000], Avg Train Loss: 3.2436\n",
      "Epoch [1941/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2351\n",
      "Epoch [1942/2000], Avg Train Loss: 3.2351\n",
      "Epoch [1942/2000], Avg Val Loss: 1.8194\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2317\n",
      "Epoch [1943/2000], Avg Train Loss: 3.2317\n",
      "Epoch [1943/2000], Avg Val Loss: 1.8196\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2127\n",
      "Epoch [1944/2000], Avg Train Loss: 3.2127\n",
      "Epoch [1944/2000], Avg Val Loss: 1.8197\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2137\n",
      "Epoch [1945/2000], Avg Train Loss: 3.2137\n",
      "Epoch [1945/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2224\n",
      "Epoch [1946/2000], Avg Train Loss: 3.2224\n",
      "Epoch [1946/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2185\n",
      "Epoch [1947/2000], Avg Train Loss: 3.2185\n",
      "Epoch [1947/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2113\n",
      "Epoch [1948/2000], Avg Train Loss: 3.2113\n",
      "Epoch [1948/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2073\n",
      "Epoch [1949/2000], Avg Train Loss: 3.2073\n",
      "Epoch [1949/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2180\n",
      "Epoch [1950/2000], Avg Train Loss: 3.2180\n",
      "Epoch [1950/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2063\n",
      "Epoch [1951/2000], Avg Train Loss: 3.2063\n",
      "Epoch [1951/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2239\n",
      "Epoch [1952/2000], Avg Train Loss: 3.2239\n",
      "Epoch [1952/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2208\n",
      "Epoch [1953/2000], Avg Train Loss: 3.2208\n",
      "Epoch [1953/2000], Avg Val Loss: 1.8198\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2285\n",
      "Epoch [1954/2000], Avg Train Loss: 3.2285\n",
      "Epoch [1954/2000], Avg Val Loss: 1.8197\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2233\n",
      "Epoch [1955/2000], Avg Train Loss: 3.2233\n",
      "Epoch [1955/2000], Avg Val Loss: 1.8196\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2288\n",
      "Epoch [1956/2000], Avg Train Loss: 3.2288\n",
      "Epoch [1956/2000], Avg Val Loss: 1.8195\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2106\n",
      "Epoch [1957/2000], Avg Train Loss: 3.2106\n",
      "Epoch [1957/2000], Avg Val Loss: 1.8194\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2251\n",
      "Epoch [1958/2000], Avg Train Loss: 3.2251\n",
      "Epoch [1958/2000], Avg Val Loss: 1.8193\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2019\n",
      "Epoch [1959/2000], Avg Train Loss: 3.2019\n",
      "Epoch [1959/2000], Avg Val Loss: 1.8192\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2262\n",
      "Epoch [1960/2000], Avg Train Loss: 3.2262\n",
      "Epoch [1960/2000], Avg Val Loss: 1.8191\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2492\n",
      "Epoch [1961/2000], Avg Train Loss: 3.2492\n",
      "Epoch [1961/2000], Avg Val Loss: 1.8191\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2030\n",
      "Epoch [1962/2000], Avg Train Loss: 3.2030\n",
      "Epoch [1962/2000], Avg Val Loss: 1.8191\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2289\n",
      "Epoch [1963/2000], Avg Train Loss: 3.2289\n",
      "Epoch [1963/2000], Avg Val Loss: 1.8191\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2173\n",
      "Epoch [1964/2000], Avg Train Loss: 3.2173\n",
      "Epoch [1964/2000], Avg Val Loss: 1.8190\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2127\n",
      "Epoch [1965/2000], Avg Train Loss: 3.2127\n",
      "Epoch [1965/2000], Avg Val Loss: 1.8190\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2206\n",
      "Epoch [1966/2000], Avg Train Loss: 3.2206\n",
      "Epoch [1966/2000], Avg Val Loss: 1.8189\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1994\n",
      "Epoch [1967/2000], Avg Train Loss: 3.1994\n",
      "Epoch [1967/2000], Avg Val Loss: 1.8188\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2384\n",
      "Epoch [1968/2000], Avg Train Loss: 3.2384\n",
      "Epoch [1968/2000], Avg Val Loss: 1.8187\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2029\n",
      "Epoch [1969/2000], Avg Train Loss: 3.2029\n",
      "Epoch [1969/2000], Avg Val Loss: 1.8186\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2346\n",
      "Epoch [1970/2000], Avg Train Loss: 3.2346\n",
      "Epoch [1970/2000], Avg Val Loss: 1.8185\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2200\n",
      "Epoch [1971/2000], Avg Train Loss: 3.2200\n",
      "Epoch [1971/2000], Avg Val Loss: 1.8184\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2173\n",
      "Epoch [1972/2000], Avg Train Loss: 3.2173\n",
      "Epoch [1972/2000], Avg Val Loss: 1.8183\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2229\n",
      "Epoch [1973/2000], Avg Train Loss: 3.2229\n",
      "Epoch [1973/2000], Avg Val Loss: 1.8182\n",
      "Validation loss improved from 1.8183 to 1.8182. Saving model...\n",
      "\n",
      "LOG: Epoch [1974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2359\n",
      "Epoch [1974/2000], Avg Train Loss: 3.2359\n",
      "Epoch [1974/2000], Avg Val Loss: 1.8180\n",
      "Validation loss improved from 1.8182 to 1.8180. Saving model...\n",
      "\n",
      "LOG: Epoch [1975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2263\n",
      "Epoch [1975/2000], Avg Train Loss: 3.2263\n",
      "Epoch [1975/2000], Avg Val Loss: 1.8179\n",
      "Validation loss improved from 1.8180 to 1.8179. Saving model...\n",
      "\n",
      "LOG: Epoch [1976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2199\n",
      "Epoch [1976/2000], Avg Train Loss: 3.2199\n",
      "Epoch [1976/2000], Avg Val Loss: 1.8178\n",
      "Validation loss improved from 1.8179 to 1.8178. Saving model...\n",
      "\n",
      "LOG: Epoch [1977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2656\n",
      "Epoch [1977/2000], Avg Train Loss: 3.2656\n",
      "Epoch [1977/2000], Avg Val Loss: 1.8177\n",
      "Validation loss improved from 1.8178 to 1.8177. Saving model...\n",
      "\n",
      "LOG: Epoch [1978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2126\n",
      "Epoch [1978/2000], Avg Train Loss: 3.2126\n",
      "Epoch [1978/2000], Avg Val Loss: 1.8177\n",
      "Validation loss improved from 1.8177 to 1.8177. Saving model...\n",
      "\n",
      "LOG: Epoch [1979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2075\n",
      "Epoch [1979/2000], Avg Train Loss: 3.2075\n",
      "Epoch [1979/2000], Avg Val Loss: 1.8176\n",
      "Validation loss improved from 1.8177 to 1.8176. Saving model...\n",
      "\n",
      "LOG: Epoch [1980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2253\n",
      "Epoch [1980/2000], Avg Train Loss: 3.2253\n",
      "Epoch [1980/2000], Avg Val Loss: 1.8175\n",
      "Validation loss improved from 1.8176 to 1.8175. Saving model...\n",
      "\n",
      "LOG: Epoch [1981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2281\n",
      "Epoch [1981/2000], Avg Train Loss: 3.2281\n",
      "Epoch [1981/2000], Avg Val Loss: 1.8175\n",
      "Validation loss improved from 1.8175 to 1.8175. Saving model...\n",
      "\n",
      "LOG: Epoch [1982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2179\n",
      "Epoch [1982/2000], Avg Train Loss: 3.2179\n",
      "Epoch [1982/2000], Avg Val Loss: 1.8175\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1976\n",
      "Epoch [1983/2000], Avg Train Loss: 3.1976\n",
      "Epoch [1983/2000], Avg Val Loss: 1.8176\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2076\n",
      "Epoch [1984/2000], Avg Train Loss: 3.2076\n",
      "Epoch [1984/2000], Avg Val Loss: 1.8176\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2338\n",
      "Epoch [1985/2000], Avg Train Loss: 3.2338\n",
      "Epoch [1985/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2320\n",
      "Epoch [1986/2000], Avg Train Loss: 3.2320\n",
      "Epoch [1986/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2131\n",
      "Epoch [1987/2000], Avg Train Loss: 3.2131\n",
      "Epoch [1987/2000], Avg Val Loss: 1.8178\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2115\n",
      "Epoch [1988/2000], Avg Train Loss: 3.2115\n",
      "Epoch [1988/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2006\n",
      "Epoch [1989/2000], Avg Train Loss: 3.2006\n",
      "Epoch [1989/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2170\n",
      "Epoch [1990/2000], Avg Train Loss: 3.2170\n",
      "Epoch [1990/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2795\n",
      "Epoch [1991/2000], Avg Train Loss: 3.2795\n",
      "Epoch [1991/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2307\n",
      "Epoch [1992/2000], Avg Train Loss: 3.2307\n",
      "Epoch [1992/2000], Avg Val Loss: 1.8177\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2193\n",
      "Epoch [1993/2000], Avg Train Loss: 3.2193\n",
      "Epoch [1993/2000], Avg Val Loss: 1.8178\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2343\n",
      "Epoch [1994/2000], Avg Train Loss: 3.2343\n",
      "Epoch [1994/2000], Avg Val Loss: 1.8179\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2079\n",
      "Epoch [1995/2000], Avg Train Loss: 3.2079\n",
      "Epoch [1995/2000], Avg Val Loss: 1.8180\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2233\n",
      "Epoch [1996/2000], Avg Train Loss: 3.2233\n",
      "Epoch [1996/2000], Avg Val Loss: 1.8181\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2244\n",
      "Epoch [1997/2000], Avg Train Loss: 3.2244\n",
      "Epoch [1997/2000], Avg Val Loss: 1.8183\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2259\n",
      "Epoch [1998/2000], Avg Train Loss: 3.2259\n",
      "Epoch [1998/2000], Avg Val Loss: 1.8184\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1999\n",
      "Epoch [1999/2000], Avg Train Loss: 3.1999\n",
      "Epoch [1999/2000], Avg Val Loss: 1.8185\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [2000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2065\n",
      "Epoch [2000/2000], Avg Train Loss: 3.2065\n",
      "Epoch [2000/2000], Avg Val Loss: 1.8186\n",
      "Validation loss did not improve. Patience: 19/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:00.396809Z",
     "iopub.status.busy": "2025-05-08T17:30:00.396809Z",
     "iopub.status.idle": "2025-05-08T17:30:01.424958Z",
     "shell.execute_reply": "2025-05-08T17:30:01.424958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/578], Loss: 5.9878\n",
      "Test Batch [20/578], Loss: 6.0814\n",
      "Test Batch [30/578], Loss: 6.0117\n",
      "Test Batch [40/578], Loss: 5.8126\n",
      "Test Batch [50/578], Loss: 5.8342\n",
      "Test Batch [60/578], Loss: 5.9006\n",
      "Test Batch [70/578], Loss: 6.0074\n",
      "Test Batch [80/578], Loss: 5.6688\n",
      "Test Batch [90/578], Loss: 5.9534\n",
      "Test Batch [100/578], Loss: 5.9872\n",
      "Test Batch [110/578], Loss: 5.9908\n",
      "Test Batch [120/578], Loss: 5.9870\n",
      "Test Batch [130/578], Loss: 5.9229\n",
      "Test Batch [140/578], Loss: 6.0154\n",
      "Test Batch [150/578], Loss: 6.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [160/578], Loss: 6.0125\n",
      "Test Batch [170/578], Loss: 6.1141\n",
      "Test Batch [180/578], Loss: 6.2395\n",
      "Test Batch [190/578], Loss: 5.7620\n",
      "Test Batch [200/578], Loss: 5.8174\n",
      "Test Batch [210/578], Loss: 5.8410\n",
      "Test Batch [220/578], Loss: 5.7059\n",
      "Test Batch [230/578], Loss: 5.7766\n",
      "Test Batch [240/578], Loss: 5.6703\n",
      "Test Batch [250/578], Loss: 5.7704\n",
      "Test Batch [260/578], Loss: 5.9086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [270/578], Loss: 5.9611\n",
      "Test Batch [280/578], Loss: 6.1518\n",
      "Test Batch [290/578], Loss: 5.7993\n",
      "Test Batch [300/578], Loss: 5.7234\n",
      "Test Batch [310/578], Loss: 5.6890\n",
      "Test Batch [320/578], Loss: 5.4008\n",
      "Test Batch [330/578], Loss: 5.3408\n",
      "Test Batch [340/578], Loss: 5.3709\n",
      "Test Batch [350/578], Loss: 5.3835\n",
      "Test Batch [360/578], Loss: 5.3658\n",
      "Test Batch [370/578], Loss: 5.8010\n",
      "Test Batch [380/578], Loss: 6.1432\n",
      "Test Batch [390/578], Loss: 5.4278\n",
      "Test Batch [400/578], Loss: 5.3634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [410/578], Loss: 5.4084\n",
      "Test Batch [420/578], Loss: 5.4041\n",
      "Test Batch [430/578], Loss: 5.5044\n",
      "Test Batch [440/578], Loss: 5.4795\n",
      "Test Batch [450/578], Loss: 5.3866\n",
      "Test Batch [460/578], Loss: 5.6405\n",
      "Test Batch [470/578], Loss: 5.3850\n",
      "Test Batch [480/578], Loss: 6.1086\n",
      "Test Batch [490/578], Loss: 5.1266\n",
      "Test Batch [500/578], Loss: 5.1988\n",
      "Test Batch [510/578], Loss: 5.1151\n",
      "Test Batch [520/578], Loss: 4.7403\n",
      "Test Batch [530/578], Loss: 4.9104\n",
      "Test Batch [540/578], Loss: 6.2960\n",
      "Test Batch [550/578], Loss: 6.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [560/578], Loss: 6.2275\n",
      "Test Batch [570/578], Loss: 6.1521\n",
      "\n",
      "Test Loss: 5.7645\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:01.426966Z",
     "iopub.status.busy": "2025-05-08T17:30:01.426966Z",
     "iopub.status.idle": "2025-05-08T17:30:03.349210Z",
     "shell.execute_reply": "2025-05-08T17:30:03.349210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 20/578 for test dataset.\n",
      "  Processed batch 30/578 for test dataset.\n",
      "  Processed batch 40/578 for test dataset.\n",
      "  Processed batch 50/578 for test dataset.\n",
      "  Processed batch 60/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 70/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 80/578 for test dataset.\n",
      "  Processed batch 90/578 for test dataset.\n",
      "  Processed batch 100/578 for test dataset.\n",
      "  Processed batch 110/578 for test dataset.\n",
      "  Processed batch 120/578 for test dataset.\n",
      "  Processed batch 130/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 140/578 for test dataset.\n",
      "  Processed batch 150/578 for test dataset.\n",
      "  Processed batch 160/578 for test dataset.\n",
      "  Processed batch 170/578 for test dataset.\n",
      "  Processed batch 180/578 for test dataset.\n",
      "  Processed batch 190/578 for test dataset.\n",
      "  Processed batch 200/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 210/578 for test dataset.\n",
      "  Processed batch 220/578 for test dataset.\n",
      "  Processed batch 230/578 for test dataset.\n",
      "  Processed batch 240/578 for test dataset.\n",
      "  Processed batch 250/578 for test dataset.\n",
      "  Processed batch 260/578 for test dataset.\n",
      "  Processed batch 270/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 280/578 for test dataset.\n",
      "  Processed batch 290/578 for test dataset.\n",
      "  Processed batch 300/578 for test dataset.\n",
      "  Processed batch 310/578 for test dataset.\n",
      "  Processed batch 320/578 for test dataset.\n",
      "  Processed batch 330/578 for test dataset.\n",
      "  Processed batch 340/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 350/578 for test dataset.\n",
      "  Processed batch 360/578 for test dataset.\n",
      "  Processed batch 370/578 for test dataset.\n",
      "  Processed batch 380/578 for test dataset.\n",
      "  Processed batch 390/578 for test dataset.\n",
      "  Processed batch 400/578 for test dataset.\n",
      "  Processed batch 410/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 420/578 for test dataset.\n",
      "  Processed batch 430/578 for test dataset.\n",
      "  Processed batch 440/578 for test dataset.\n",
      "  Processed batch 450/578 for test dataset.\n",
      "  Processed batch 460/578 for test dataset.\n",
      "  Processed batch 470/578 for test dataset.\n",
      "  Processed batch 480/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 490/578 for test dataset.\n",
      "  Processed batch 500/578 for test dataset.\n",
      "  Processed batch 510/578 for test dataset.\n",
      "  Processed batch 520/578 for test dataset.\n",
      "  Processed batch 530/578 for test dataset.\n",
      "  Processed batch 540/578 for test dataset.\n",
      "  Processed batch 550/578 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 560/578 for test dataset.\n",
      "  Processed batch 570/578 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:03.351214Z",
     "iopub.status.busy": "2025-05-08T17:30:03.351214Z",
     "iopub.status.idle": "2025-05-08T17:30:03.355225Z",
     "shell.execute_reply": "2025-05-08T17:30:03.355225Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:03.357475Z",
     "iopub.status.busy": "2025-05-08T17:30:03.357475Z",
     "iopub.status.idle": "2025-05-08T17:30:07.634846Z",
     "shell.execute_reply": "2025-05-08T17:30:07.634846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:07.637092Z",
     "iopub.status.busy": "2025-05-08T17:30:07.637092Z",
     "iopub.status.idle": "2025-05-08T17:30:07.864071Z",
     "shell.execute_reply": "2025-05-08T17:30:07.864071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 97.78%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       0.83      1.00      0.91         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 96.00%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     65946\n",
      "           1       0.96      0.88      0.92      7573\n",
      "           2       0.75      0.88      0.81      3065\n",
      "           3       0.59      0.87      0.70      2660\n",
      "           4       0.84      0.89      0.86      6559\n",
      "           5       0.84      0.93      0.88      9223\n",
      "           6       0.98      0.80      0.88      7262\n",
      "           7       1.00      0.98      0.99     42801\n",
      "           8       0.99      1.00      1.00      2838\n",
      "\n",
      "    accuracy                           0.96    147927\n",
      "   macro avg       0.88      0.91      0.89    147927\n",
      "weighted avg       0.97      0.96      0.96    147927\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:07.866296Z",
     "iopub.status.busy": "2025-05-08T17:30:07.866296Z",
     "iopub.status.idle": "2025-05-08T17:30:07.870687Z",
     "shell.execute_reply": "2025-05-08T17:30:07.870687Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:07.872698Z",
     "iopub.status.busy": "2025-05-08T17:30:07.872698Z",
     "iopub.status.idle": "2025-05-08T17:30:08.065181Z",
     "shell.execute_reply": "2025-05-08T17:30:08.064656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:08.067234Z",
     "iopub.status.busy": "2025-05-08T17:30:08.067234Z",
     "iopub.status.idle": "2025-05-08T17:30:08.081734Z",
     "shell.execute_reply": "2025-05-08T17:30:08.081232Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:08.083738Z",
     "iopub.status.busy": "2025-05-08T17:30:08.083738Z",
     "iopub.status.idle": "2025-05-08T17:30:13.797021Z",
     "shell.execute_reply": "2025-05-08T17:30:13.797021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.3672  |  Val Loss: 2.3066\n",
      "Validation loss improved from inf to 2.3066.\n",
      "[Epoch 2/1000] Train Loss: 2.3049  |  Val Loss: 2.2530\n",
      "Validation loss improved from 2.3066 to 2.2530.\n",
      "[Epoch 3/1000] Train Loss: 2.2466  |  Val Loss: 2.2011\n",
      "Validation loss improved from 2.2530 to 2.2011.\n",
      "[Epoch 4/1000] Train Loss: 2.1904  |  Val Loss: 2.1534\n",
      "Validation loss improved from 2.2011 to 2.1534.\n",
      "[Epoch 5/1000] Train Loss: 2.1420  |  Val Loss: 2.1094\n",
      "Validation loss improved from 2.1534 to 2.1094.\n",
      "[Epoch 6/1000] Train Loss: 2.0965  |  Val Loss: 2.0681\n",
      "Validation loss improved from 2.1094 to 2.0681.\n",
      "[Epoch 7/1000] Train Loss: 2.0508  |  Val Loss: 2.0292\n",
      "Validation loss improved from 2.0681 to 2.0292.\n",
      "[Epoch 8/1000] Train Loss: 2.0110  |  Val Loss: 1.9919\n",
      "Validation loss improved from 2.0292 to 1.9919.\n",
      "[Epoch 9/1000] Train Loss: 1.9703  |  Val Loss: 1.9562\n",
      "Validation loss improved from 1.9919 to 1.9562.\n",
      "[Epoch 10/1000] Train Loss: 1.9321  |  Val Loss: 1.9217\n",
      "Validation loss improved from 1.9562 to 1.9217.\n",
      "[Epoch 11/1000] Train Loss: 1.8963  |  Val Loss: 1.8892\n",
      "Validation loss improved from 1.9217 to 1.8892.\n",
      "[Epoch 12/1000] Train Loss: 1.8609  |  Val Loss: 1.8585\n",
      "Validation loss improved from 1.8892 to 1.8585.\n",
      "[Epoch 13/1000] Train Loss: 1.8280  |  Val Loss: 1.8282\n",
      "Validation loss improved from 1.8585 to 1.8282.\n",
      "[Epoch 14/1000] Train Loss: 1.7952  |  Val Loss: 1.7992\n",
      "Validation loss improved from 1.8282 to 1.7992.\n",
      "[Epoch 15/1000] Train Loss: 1.7651  |  Val Loss: 1.7712\n",
      "Validation loss improved from 1.7992 to 1.7712.\n",
      "[Epoch 16/1000] Train Loss: 1.7343  |  Val Loss: 1.7446\n",
      "Validation loss improved from 1.7712 to 1.7446.\n",
      "[Epoch 17/1000] Train Loss: 1.7070  |  Val Loss: 1.7192\n",
      "Validation loss improved from 1.7446 to 1.7192.\n",
      "[Epoch 18/1000] Train Loss: 1.6801  |  Val Loss: 1.6949\n",
      "Validation loss improved from 1.7192 to 1.6949.\n",
      "[Epoch 19/1000] Train Loss: 1.6537  |  Val Loss: 1.6712\n",
      "Validation loss improved from 1.6949 to 1.6712.\n",
      "[Epoch 20/1000] Train Loss: 1.6290  |  Val Loss: 1.6480\n",
      "Validation loss improved from 1.6712 to 1.6480.\n",
      "[Epoch 21/1000] Train Loss: 1.6057  |  Val Loss: 1.6255\n",
      "Validation loss improved from 1.6480 to 1.6255.\n",
      "[Epoch 22/1000] Train Loss: 1.5830  |  Val Loss: 1.6036\n",
      "Validation loss improved from 1.6255 to 1.6036.\n",
      "[Epoch 23/1000] Train Loss: 1.5615  |  Val Loss: 1.5826\n",
      "Validation loss improved from 1.6036 to 1.5826.\n",
      "[Epoch 24/1000] Train Loss: 1.5398  |  Val Loss: 1.5624\n",
      "Validation loss improved from 1.5826 to 1.5624.\n",
      "[Epoch 25/1000] Train Loss: 1.5186  |  Val Loss: 1.5428\n",
      "Validation loss improved from 1.5624 to 1.5428.\n",
      "[Epoch 26/1000] Train Loss: 1.4985  |  Val Loss: 1.5234\n",
      "Validation loss improved from 1.5428 to 1.5234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/1000] Train Loss: 1.4780  |  Val Loss: 1.5043\n",
      "Validation loss improved from 1.5234 to 1.5043.\n",
      "[Epoch 28/1000] Train Loss: 1.4584  |  Val Loss: 1.4854\n",
      "Validation loss improved from 1.5043 to 1.4854.\n",
      "[Epoch 29/1000] Train Loss: 1.4391  |  Val Loss: 1.4667\n",
      "Validation loss improved from 1.4854 to 1.4667.\n",
      "[Epoch 30/1000] Train Loss: 1.4194  |  Val Loss: 1.4482\n",
      "Validation loss improved from 1.4667 to 1.4482.\n",
      "[Epoch 31/1000] Train Loss: 1.4007  |  Val Loss: 1.4298\n",
      "Validation loss improved from 1.4482 to 1.4298.\n",
      "[Epoch 32/1000] Train Loss: 1.3813  |  Val Loss: 1.4117\n",
      "Validation loss improved from 1.4298 to 1.4117.\n",
      "[Epoch 33/1000] Train Loss: 1.3628  |  Val Loss: 1.3937\n",
      "Validation loss improved from 1.4117 to 1.3937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 1.3437  |  Val Loss: 1.3757\n",
      "Validation loss improved from 1.3937 to 1.3757.\n",
      "[Epoch 35/1000] Train Loss: 1.3253  |  Val Loss: 1.3577\n",
      "Validation loss improved from 1.3757 to 1.3577.\n",
      "[Epoch 36/1000] Train Loss: 1.3066  |  Val Loss: 1.3399\n",
      "Validation loss improved from 1.3577 to 1.3399.\n",
      "[Epoch 37/1000] Train Loss: 1.2878  |  Val Loss: 1.3222\n",
      "Validation loss improved from 1.3399 to 1.3222.\n",
      "[Epoch 38/1000] Train Loss: 1.2691  |  Val Loss: 1.3046\n",
      "Validation loss improved from 1.3222 to 1.3046.\n",
      "[Epoch 39/1000] Train Loss: 1.2509  |  Val Loss: 1.2872\n",
      "Validation loss improved from 1.3046 to 1.2872.\n",
      "[Epoch 40/1000] Train Loss: 1.2323  |  Val Loss: 1.2699\n",
      "Validation loss improved from 1.2872 to 1.2699.\n",
      "[Epoch 41/1000] Train Loss: 1.2142  |  Val Loss: 1.2528\n",
      "Validation loss improved from 1.2699 to 1.2528.\n",
      "[Epoch 42/1000] Train Loss: 1.1959  |  Val Loss: 1.2360\n",
      "Validation loss improved from 1.2528 to 1.2360.\n",
      "[Epoch 43/1000] Train Loss: 1.1781  |  Val Loss: 1.2195\n",
      "Validation loss improved from 1.2360 to 1.2195.\n",
      "[Epoch 44/1000] Train Loss: 1.1605  |  Val Loss: 1.2032\n",
      "Validation loss improved from 1.2195 to 1.2032.\n",
      "[Epoch 45/1000] Train Loss: 1.1432  |  Val Loss: 1.1872\n",
      "Validation loss improved from 1.2032 to 1.1872.\n",
      "[Epoch 46/1000] Train Loss: 1.1262  |  Val Loss: 1.1712\n",
      "Validation loss improved from 1.1872 to 1.1712.\n",
      "[Epoch 47/1000] Train Loss: 1.1095  |  Val Loss: 1.1553\n",
      "Validation loss improved from 1.1712 to 1.1553.\n",
      "[Epoch 48/1000] Train Loss: 1.0928  |  Val Loss: 1.1397\n",
      "Validation loss improved from 1.1553 to 1.1397.\n",
      "[Epoch 49/1000] Train Loss: 1.0764  |  Val Loss: 1.1244\n",
      "Validation loss improved from 1.1397 to 1.1244.\n",
      "[Epoch 50/1000] Train Loss: 1.0602  |  Val Loss: 1.1092\n",
      "Validation loss improved from 1.1244 to 1.1092.\n",
      "[Epoch 51/1000] Train Loss: 1.0441  |  Val Loss: 1.0944\n",
      "Validation loss improved from 1.1092 to 1.0944.\n",
      "[Epoch 52/1000] Train Loss: 1.0284  |  Val Loss: 1.0799\n",
      "Validation loss improved from 1.0944 to 1.0799.\n",
      "[Epoch 53/1000] Train Loss: 1.0130  |  Val Loss: 1.0658\n",
      "Validation loss improved from 1.0799 to 1.0658.\n",
      "[Epoch 54/1000] Train Loss: 0.9978  |  Val Loss: 1.0518\n",
      "Validation loss improved from 1.0658 to 1.0518.\n",
      "[Epoch 55/1000] Train Loss: 0.9826  |  Val Loss: 1.0381\n",
      "Validation loss improved from 1.0518 to 1.0381.\n",
      "[Epoch 56/1000] Train Loss: 0.9680  |  Val Loss: 1.0248\n",
      "Validation loss improved from 1.0381 to 1.0248.\n",
      "[Epoch 57/1000] Train Loss: 0.9539  |  Val Loss: 1.0117\n",
      "Validation loss improved from 1.0248 to 1.0117.\n",
      "[Epoch 58/1000] Train Loss: 0.9401  |  Val Loss: 0.9987\n",
      "Validation loss improved from 1.0117 to 0.9987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/1000] Train Loss: 0.9260  |  Val Loss: 0.9859\n",
      "Validation loss improved from 0.9987 to 0.9859.\n",
      "[Epoch 60/1000] Train Loss: 0.9125  |  Val Loss: 0.9731\n",
      "Validation loss improved from 0.9859 to 0.9731.\n",
      "[Epoch 61/1000] Train Loss: 0.8995  |  Val Loss: 0.9605\n",
      "Validation loss improved from 0.9731 to 0.9605.\n",
      "[Epoch 62/1000] Train Loss: 0.8861  |  Val Loss: 0.9482\n",
      "Validation loss improved from 0.9605 to 0.9482.\n",
      "[Epoch 63/1000] Train Loss: 0.8727  |  Val Loss: 0.9362\n",
      "Validation loss improved from 0.9482 to 0.9362.\n",
      "[Epoch 64/1000] Train Loss: 0.8598  |  Val Loss: 0.9241\n",
      "Validation loss improved from 0.9362 to 0.9241.\n",
      "[Epoch 65/1000] Train Loss: 0.8471  |  Val Loss: 0.9125\n",
      "Validation loss improved from 0.9241 to 0.9125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/1000] Train Loss: 0.8352  |  Val Loss: 0.9011\n",
      "Validation loss improved from 0.9125 to 0.9011.\n",
      "[Epoch 67/1000] Train Loss: 0.8226  |  Val Loss: 0.8899\n",
      "Validation loss improved from 0.9011 to 0.8899.\n",
      "[Epoch 68/1000] Train Loss: 0.8109  |  Val Loss: 0.8789\n",
      "Validation loss improved from 0.8899 to 0.8789.\n",
      "[Epoch 69/1000] Train Loss: 0.7990  |  Val Loss: 0.8680\n",
      "Validation loss improved from 0.8789 to 0.8680.\n",
      "[Epoch 70/1000] Train Loss: 0.7874  |  Val Loss: 0.8573\n",
      "Validation loss improved from 0.8680 to 0.8573.\n",
      "[Epoch 71/1000] Train Loss: 0.7761  |  Val Loss: 0.8467\n",
      "Validation loss improved from 0.8573 to 0.8467.\n",
      "[Epoch 72/1000] Train Loss: 0.7653  |  Val Loss: 0.8363\n",
      "Validation loss improved from 0.8467 to 0.8363.\n",
      "[Epoch 73/1000] Train Loss: 0.7542  |  Val Loss: 0.8260\n",
      "Validation loss improved from 0.8363 to 0.8260.\n",
      "[Epoch 74/1000] Train Loss: 0.7433  |  Val Loss: 0.8158\n",
      "Validation loss improved from 0.8260 to 0.8158.\n",
      "[Epoch 75/1000] Train Loss: 0.7327  |  Val Loss: 0.8058\n",
      "Validation loss improved from 0.8158 to 0.8058.\n",
      "[Epoch 76/1000] Train Loss: 0.7225  |  Val Loss: 0.7959\n",
      "Validation loss improved from 0.8058 to 0.7959.\n",
      "[Epoch 77/1000] Train Loss: 0.7123  |  Val Loss: 0.7862\n",
      "Validation loss improved from 0.7959 to 0.7862.\n",
      "[Epoch 78/1000] Train Loss: 0.7021  |  Val Loss: 0.7769\n",
      "Validation loss improved from 0.7862 to 0.7769.\n",
      "[Epoch 79/1000] Train Loss: 0.6920  |  Val Loss: 0.7677\n",
      "Validation loss improved from 0.7769 to 0.7677.\n",
      "[Epoch 80/1000] Train Loss: 0.6825  |  Val Loss: 0.7586\n",
      "Validation loss improved from 0.7677 to 0.7586.\n",
      "[Epoch 81/1000] Train Loss: 0.6728  |  Val Loss: 0.7497\n",
      "Validation loss improved from 0.7586 to 0.7497.\n",
      "[Epoch 82/1000] Train Loss: 0.6630  |  Val Loss: 0.7408\n",
      "Validation loss improved from 0.7497 to 0.7408.\n",
      "[Epoch 83/1000] Train Loss: 0.6541  |  Val Loss: 0.7319\n",
      "Validation loss improved from 0.7408 to 0.7319.\n",
      "[Epoch 84/1000] Train Loss: 0.6446  |  Val Loss: 0.7233\n",
      "Validation loss improved from 0.7319 to 0.7233.\n",
      "[Epoch 85/1000] Train Loss: 0.6352  |  Val Loss: 0.7148\n",
      "Validation loss improved from 0.7233 to 0.7148.\n",
      "[Epoch 86/1000] Train Loss: 0.6265  |  Val Loss: 0.7065\n",
      "Validation loss improved from 0.7148 to 0.7065.\n",
      "[Epoch 87/1000] Train Loss: 0.6176  |  Val Loss: 0.6980\n",
      "Validation loss improved from 0.7065 to 0.6980.\n",
      "[Epoch 88/1000] Train Loss: 0.6088  |  Val Loss: 0.6899\n",
      "Validation loss improved from 0.6980 to 0.6899.\n",
      "[Epoch 89/1000] Train Loss: 0.6002  |  Val Loss: 0.6821\n",
      "Validation loss improved from 0.6899 to 0.6821.\n",
      "[Epoch 90/1000] Train Loss: 0.5917  |  Val Loss: 0.6741\n",
      "Validation loss improved from 0.6821 to 0.6741.\n",
      "[Epoch 91/1000] Train Loss: 0.5834  |  Val Loss: 0.6664\n",
      "Validation loss improved from 0.6741 to 0.6664.\n",
      "[Epoch 92/1000] Train Loss: 0.5755  |  Val Loss: 0.6585\n",
      "Validation loss improved from 0.6664 to 0.6585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 93/1000] Train Loss: 0.5674  |  Val Loss: 0.6509\n",
      "Validation loss improved from 0.6585 to 0.6509.\n",
      "[Epoch 94/1000] Train Loss: 0.5595  |  Val Loss: 0.6435\n",
      "Validation loss improved from 0.6509 to 0.6435.\n",
      "[Epoch 95/1000] Train Loss: 0.5519  |  Val Loss: 0.6360\n",
      "Validation loss improved from 0.6435 to 0.6360.\n",
      "[Epoch 96/1000] Train Loss: 0.5445  |  Val Loss: 0.6286\n",
      "Validation loss improved from 0.6360 to 0.6286.\n",
      "[Epoch 97/1000] Train Loss: 0.5369  |  Val Loss: 0.6215\n",
      "Validation loss improved from 0.6286 to 0.6215.\n",
      "[Epoch 98/1000] Train Loss: 0.5299  |  Val Loss: 0.6144\n",
      "Validation loss improved from 0.6215 to 0.6144.\n",
      "[Epoch 99/1000] Train Loss: 0.5226  |  Val Loss: 0.6075\n",
      "Validation loss improved from 0.6144 to 0.6075.\n",
      "[Epoch 100/1000] Train Loss: 0.5157  |  Val Loss: 0.6006\n",
      "Validation loss improved from 0.6075 to 0.6006.\n",
      "[Epoch 101/1000] Train Loss: 0.5088  |  Val Loss: 0.5940\n",
      "Validation loss improved from 0.6006 to 0.5940.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 102/1000] Train Loss: 0.5022  |  Val Loss: 0.5875\n",
      "Validation loss improved from 0.5940 to 0.5875.\n",
      "[Epoch 103/1000] Train Loss: 0.4955  |  Val Loss: 0.5809\n",
      "Validation loss improved from 0.5875 to 0.5809.\n",
      "[Epoch 104/1000] Train Loss: 0.4891  |  Val Loss: 0.5745\n",
      "Validation loss improved from 0.5809 to 0.5745.\n",
      "[Epoch 105/1000] Train Loss: 0.4828  |  Val Loss: 0.5681\n",
      "Validation loss improved from 0.5745 to 0.5681.\n",
      "[Epoch 106/1000] Train Loss: 0.4764  |  Val Loss: 0.5619\n",
      "Validation loss improved from 0.5681 to 0.5619.\n",
      "[Epoch 107/1000] Train Loss: 0.4703  |  Val Loss: 0.5560\n",
      "Validation loss improved from 0.5619 to 0.5560.\n",
      "[Epoch 108/1000] Train Loss: 0.4644  |  Val Loss: 0.5500\n",
      "Validation loss improved from 0.5560 to 0.5500.\n",
      "[Epoch 109/1000] Train Loss: 0.4585  |  Val Loss: 0.5443\n",
      "Validation loss improved from 0.5500 to 0.5443.\n",
      "[Epoch 110/1000] Train Loss: 0.4527  |  Val Loss: 0.5386\n",
      "Validation loss improved from 0.5443 to 0.5386.\n",
      "[Epoch 111/1000] Train Loss: 0.4472  |  Val Loss: 0.5329\n",
      "Validation loss improved from 0.5386 to 0.5329.\n",
      "[Epoch 112/1000] Train Loss: 0.4416  |  Val Loss: 0.5272\n",
      "Validation loss improved from 0.5329 to 0.5272.\n",
      "[Epoch 113/1000] Train Loss: 0.4360  |  Val Loss: 0.5216\n",
      "Validation loss improved from 0.5272 to 0.5216.\n",
      "[Epoch 114/1000] Train Loss: 0.4307  |  Val Loss: 0.5163\n",
      "Validation loss improved from 0.5216 to 0.5163.\n",
      "[Epoch 115/1000] Train Loss: 0.4257  |  Val Loss: 0.5110\n",
      "Validation loss improved from 0.5163 to 0.5110.\n",
      "[Epoch 116/1000] Train Loss: 0.4207  |  Val Loss: 0.5058\n",
      "Validation loss improved from 0.5110 to 0.5058.\n",
      "[Epoch 117/1000] Train Loss: 0.4156  |  Val Loss: 0.5007\n",
      "Validation loss improved from 0.5058 to 0.5007.\n",
      "[Epoch 118/1000] Train Loss: 0.4107  |  Val Loss: 0.4957\n",
      "Validation loss improved from 0.5007 to 0.4957.\n",
      "[Epoch 119/1000] Train Loss: 0.4060  |  Val Loss: 0.4909\n",
      "Validation loss improved from 0.4957 to 0.4909.\n",
      "[Epoch 120/1000] Train Loss: 0.4013  |  Val Loss: 0.4861\n",
      "Validation loss improved from 0.4909 to 0.4861.\n",
      "[Epoch 121/1000] Train Loss: 0.3967  |  Val Loss: 0.4813\n",
      "Validation loss improved from 0.4861 to 0.4813.\n",
      "[Epoch 122/1000] Train Loss: 0.3922  |  Val Loss: 0.4766\n",
      "Validation loss improved from 0.4813 to 0.4766.\n",
      "[Epoch 123/1000] Train Loss: 0.3877  |  Val Loss: 0.4720\n",
      "Validation loss improved from 0.4766 to 0.4720.\n",
      "[Epoch 124/1000] Train Loss: 0.3835  |  Val Loss: 0.4674\n",
      "Validation loss improved from 0.4720 to 0.4674.\n",
      "[Epoch 125/1000] Train Loss: 0.3792  |  Val Loss: 0.4630\n",
      "Validation loss improved from 0.4674 to 0.4630.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/1000] Train Loss: 0.3749  |  Val Loss: 0.4587\n",
      "Validation loss improved from 0.4630 to 0.4587.\n",
      "[Epoch 127/1000] Train Loss: 0.3710  |  Val Loss: 0.4545\n",
      "Validation loss improved from 0.4587 to 0.4545.\n",
      "[Epoch 128/1000] Train Loss: 0.3669  |  Val Loss: 0.4501\n",
      "Validation loss improved from 0.4545 to 0.4501.\n",
      "[Epoch 129/1000] Train Loss: 0.3630  |  Val Loss: 0.4461\n",
      "Validation loss improved from 0.4501 to 0.4461.\n",
      "[Epoch 130/1000] Train Loss: 0.3592  |  Val Loss: 0.4419\n",
      "Validation loss improved from 0.4461 to 0.4419.\n",
      "[Epoch 131/1000] Train Loss: 0.3551  |  Val Loss: 0.4378\n",
      "Validation loss improved from 0.4419 to 0.4378.\n",
      "[Epoch 132/1000] Train Loss: 0.3514  |  Val Loss: 0.4337\n",
      "Validation loss improved from 0.4378 to 0.4337.\n",
      "[Epoch 133/1000] Train Loss: 0.3479  |  Val Loss: 0.4295\n",
      "Validation loss improved from 0.4337 to 0.4295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 134/1000] Train Loss: 0.3442  |  Val Loss: 0.4255\n",
      "Validation loss improved from 0.4295 to 0.4255.\n",
      "[Epoch 135/1000] Train Loss: 0.3405  |  Val Loss: 0.4216\n",
      "Validation loss improved from 0.4255 to 0.4216.\n",
      "[Epoch 136/1000] Train Loss: 0.3371  |  Val Loss: 0.4178\n",
      "Validation loss improved from 0.4216 to 0.4178.\n",
      "[Epoch 137/1000] Train Loss: 0.3335  |  Val Loss: 0.4139\n",
      "Validation loss improved from 0.4178 to 0.4139.\n",
      "[Epoch 138/1000] Train Loss: 0.3301  |  Val Loss: 0.4101\n",
      "Validation loss improved from 0.4139 to 0.4101.\n",
      "[Epoch 139/1000] Train Loss: 0.3267  |  Val Loss: 0.4063\n",
      "Validation loss improved from 0.4101 to 0.4063.\n",
      "[Epoch 140/1000] Train Loss: 0.3233  |  Val Loss: 0.4026\n",
      "Validation loss improved from 0.4063 to 0.4026.\n",
      "[Epoch 141/1000] Train Loss: 0.3199  |  Val Loss: 0.3991\n",
      "Validation loss improved from 0.4026 to 0.3991.\n",
      "[Epoch 142/1000] Train Loss: 0.3167  |  Val Loss: 0.3955\n",
      "Validation loss improved from 0.3991 to 0.3955.\n",
      "[Epoch 143/1000] Train Loss: 0.3136  |  Val Loss: 0.3919\n",
      "Validation loss improved from 0.3955 to 0.3919.\n",
      "[Epoch 144/1000] Train Loss: 0.3104  |  Val Loss: 0.3885\n",
      "Validation loss improved from 0.3919 to 0.3885.\n",
      "[Epoch 145/1000] Train Loss: 0.3074  |  Val Loss: 0.3851\n",
      "Validation loss improved from 0.3885 to 0.3851.\n",
      "[Epoch 146/1000] Train Loss: 0.3043  |  Val Loss: 0.3817\n",
      "Validation loss improved from 0.3851 to 0.3817.\n",
      "[Epoch 147/1000] Train Loss: 0.3014  |  Val Loss: 0.3784\n",
      "Validation loss improved from 0.3817 to 0.3784.\n",
      "[Epoch 148/1000] Train Loss: 0.2985  |  Val Loss: 0.3752\n",
      "Validation loss improved from 0.3784 to 0.3752.\n",
      "[Epoch 149/1000] Train Loss: 0.2954  |  Val Loss: 0.3719\n",
      "Validation loss improved from 0.3752 to 0.3719.\n",
      "[Epoch 150/1000] Train Loss: 0.2927  |  Val Loss: 0.3686\n",
      "Validation loss improved from 0.3719 to 0.3686.\n",
      "[Epoch 151/1000] Train Loss: 0.2897  |  Val Loss: 0.3657\n",
      "Validation loss improved from 0.3686 to 0.3657.\n",
      "[Epoch 152/1000] Train Loss: 0.2869  |  Val Loss: 0.3626\n",
      "Validation loss improved from 0.3657 to 0.3626.\n",
      "[Epoch 153/1000] Train Loss: 0.2843  |  Val Loss: 0.3596\n",
      "Validation loss improved from 0.3626 to 0.3596.\n",
      "[Epoch 154/1000] Train Loss: 0.2815  |  Val Loss: 0.3568\n",
      "Validation loss improved from 0.3596 to 0.3568.\n",
      "[Epoch 155/1000] Train Loss: 0.2788  |  Val Loss: 0.3538\n",
      "Validation loss improved from 0.3568 to 0.3538.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 156/1000] Train Loss: 0.2761  |  Val Loss: 0.3507\n",
      "Validation loss improved from 0.3538 to 0.3507.\n",
      "[Epoch 157/1000] Train Loss: 0.2735  |  Val Loss: 0.3477\n",
      "Validation loss improved from 0.3507 to 0.3477.\n",
      "[Epoch 158/1000] Train Loss: 0.2710  |  Val Loss: 0.3448\n",
      "Validation loss improved from 0.3477 to 0.3448.\n",
      "[Epoch 159/1000] Train Loss: 0.2683  |  Val Loss: 0.3420\n",
      "Validation loss improved from 0.3448 to 0.3420.\n",
      "[Epoch 160/1000] Train Loss: 0.2658  |  Val Loss: 0.3391\n",
      "Validation loss improved from 0.3420 to 0.3391.\n",
      "[Epoch 161/1000] Train Loss: 0.2632  |  Val Loss: 0.3360\n",
      "Validation loss improved from 0.3391 to 0.3360.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 162/1000] Train Loss: 0.2607  |  Val Loss: 0.3332\n",
      "Validation loss improved from 0.3360 to 0.3332.\n",
      "[Epoch 163/1000] Train Loss: 0.2582  |  Val Loss: 0.3304\n",
      "Validation loss improved from 0.3332 to 0.3304.\n",
      "[Epoch 164/1000] Train Loss: 0.2557  |  Val Loss: 0.3277\n",
      "Validation loss improved from 0.3304 to 0.3277.\n",
      "[Epoch 165/1000] Train Loss: 0.2532  |  Val Loss: 0.3248\n",
      "Validation loss improved from 0.3277 to 0.3248.\n",
      "[Epoch 166/1000] Train Loss: 0.2508  |  Val Loss: 0.3218\n",
      "Validation loss improved from 0.3248 to 0.3218.\n",
      "[Epoch 167/1000] Train Loss: 0.2482  |  Val Loss: 0.3191\n",
      "Validation loss improved from 0.3218 to 0.3191.\n",
      "[Epoch 168/1000] Train Loss: 0.2460  |  Val Loss: 0.3162\n",
      "Validation loss improved from 0.3191 to 0.3162.\n",
      "[Epoch 169/1000] Train Loss: 0.2435  |  Val Loss: 0.3134\n",
      "Validation loss improved from 0.3162 to 0.3134.\n",
      "[Epoch 170/1000] Train Loss: 0.2412  |  Val Loss: 0.3109\n",
      "Validation loss improved from 0.3134 to 0.3109.\n",
      "[Epoch 171/1000] Train Loss: 0.2387  |  Val Loss: 0.3083\n",
      "Validation loss improved from 0.3109 to 0.3083.\n",
      "[Epoch 172/1000] Train Loss: 0.2366  |  Val Loss: 0.3055\n",
      "Validation loss improved from 0.3083 to 0.3055.\n",
      "[Epoch 173/1000] Train Loss: 0.2342  |  Val Loss: 0.3028\n",
      "Validation loss improved from 0.3055 to 0.3028.\n",
      "[Epoch 174/1000] Train Loss: 0.2320  |  Val Loss: 0.3001\n",
      "Validation loss improved from 0.3028 to 0.3001.\n",
      "[Epoch 175/1000] Train Loss: 0.2297  |  Val Loss: 0.2975\n",
      "Validation loss improved from 0.3001 to 0.2975.\n",
      "[Epoch 176/1000] Train Loss: 0.2274  |  Val Loss: 0.2948\n",
      "Validation loss improved from 0.2975 to 0.2948.\n",
      "[Epoch 177/1000] Train Loss: 0.2254  |  Val Loss: 0.2921\n",
      "Validation loss improved from 0.2948 to 0.2921.\n",
      "[Epoch 178/1000] Train Loss: 0.2230  |  Val Loss: 0.2896\n",
      "Validation loss improved from 0.2921 to 0.2896.\n",
      "[Epoch 179/1000] Train Loss: 0.2208  |  Val Loss: 0.2871\n",
      "Validation loss improved from 0.2896 to 0.2871.\n",
      "[Epoch 180/1000] Train Loss: 0.2187  |  Val Loss: 0.2846\n",
      "Validation loss improved from 0.2871 to 0.2846.\n",
      "[Epoch 181/1000] Train Loss: 0.2165  |  Val Loss: 0.2821\n",
      "Validation loss improved from 0.2846 to 0.2821.\n",
      "[Epoch 182/1000] Train Loss: 0.2143  |  Val Loss: 0.2798\n",
      "Validation loss improved from 0.2821 to 0.2798.\n",
      "[Epoch 183/1000] Train Loss: 0.2124  |  Val Loss: 0.2773\n",
      "Validation loss improved from 0.2798 to 0.2773.\n",
      "[Epoch 184/1000] Train Loss: 0.2103  |  Val Loss: 0.2748\n",
      "Validation loss improved from 0.2773 to 0.2748.\n",
      "[Epoch 185/1000] Train Loss: 0.2082  |  Val Loss: 0.2725\n",
      "Validation loss improved from 0.2748 to 0.2725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 186/1000] Train Loss: 0.2062  |  Val Loss: 0.2701\n",
      "Validation loss improved from 0.2725 to 0.2701.\n",
      "[Epoch 187/1000] Train Loss: 0.2040  |  Val Loss: 0.2678\n",
      "Validation loss improved from 0.2701 to 0.2678.\n",
      "[Epoch 188/1000] Train Loss: 0.2020  |  Val Loss: 0.2655\n",
      "Validation loss improved from 0.2678 to 0.2655.\n",
      "[Epoch 189/1000] Train Loss: 0.2001  |  Val Loss: 0.2633\n",
      "Validation loss improved from 0.2655 to 0.2633.\n",
      "[Epoch 190/1000] Train Loss: 0.1980  |  Val Loss: 0.2608\n",
      "Validation loss improved from 0.2633 to 0.2608.\n",
      "[Epoch 191/1000] Train Loss: 0.1961  |  Val Loss: 0.2585\n",
      "Validation loss improved from 0.2608 to 0.2585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 192/1000] Train Loss: 0.1942  |  Val Loss: 0.2563\n",
      "Validation loss improved from 0.2585 to 0.2563.\n",
      "[Epoch 193/1000] Train Loss: 0.1921  |  Val Loss: 0.2542\n",
      "Validation loss improved from 0.2563 to 0.2542.\n",
      "[Epoch 194/1000] Train Loss: 0.1903  |  Val Loss: 0.2521\n",
      "Validation loss improved from 0.2542 to 0.2521.\n",
      "[Epoch 195/1000] Train Loss: 0.1883  |  Val Loss: 0.2497\n",
      "Validation loss improved from 0.2521 to 0.2497.\n",
      "[Epoch 196/1000] Train Loss: 0.1865  |  Val Loss: 0.2474\n",
      "Validation loss improved from 0.2497 to 0.2474.\n",
      "[Epoch 197/1000] Train Loss: 0.1845  |  Val Loss: 0.2451\n",
      "Validation loss improved from 0.2474 to 0.2451.\n",
      "[Epoch 198/1000] Train Loss: 0.1827  |  Val Loss: 0.2429\n",
      "Validation loss improved from 0.2451 to 0.2429.\n",
      "[Epoch 199/1000] Train Loss: 0.1809  |  Val Loss: 0.2407\n",
      "Validation loss improved from 0.2429 to 0.2407.\n",
      "[Epoch 200/1000] Train Loss: 0.1790  |  Val Loss: 0.2388\n",
      "Validation loss improved from 0.2407 to 0.2388.\n",
      "[Epoch 201/1000] Train Loss: 0.1772  |  Val Loss: 0.2369\n",
      "Validation loss improved from 0.2388 to 0.2369.\n",
      "[Epoch 202/1000] Train Loss: 0.1754  |  Val Loss: 0.2347\n",
      "Validation loss improved from 0.2369 to 0.2347.\n",
      "[Epoch 203/1000] Train Loss: 0.1734  |  Val Loss: 0.2327\n",
      "Validation loss improved from 0.2347 to 0.2327.\n",
      "[Epoch 204/1000] Train Loss: 0.1718  |  Val Loss: 0.2305\n",
      "Validation loss improved from 0.2327 to 0.2305.\n",
      "[Epoch 205/1000] Train Loss: 0.1700  |  Val Loss: 0.2284\n",
      "Validation loss improved from 0.2305 to 0.2284.\n",
      "[Epoch 206/1000] Train Loss: 0.1682  |  Val Loss: 0.2266\n",
      "Validation loss improved from 0.2284 to 0.2266.\n",
      "[Epoch 207/1000] Train Loss: 0.1664  |  Val Loss: 0.2246\n",
      "Validation loss improved from 0.2266 to 0.2246.\n",
      "[Epoch 208/1000] Train Loss: 0.1648  |  Val Loss: 0.2228\n",
      "Validation loss improved from 0.2246 to 0.2228.\n",
      "[Epoch 209/1000] Train Loss: 0.1630  |  Val Loss: 0.2209\n",
      "Validation loss improved from 0.2228 to 0.2209.\n",
      "[Epoch 210/1000] Train Loss: 0.1614  |  Val Loss: 0.2189\n",
      "Validation loss improved from 0.2209 to 0.2189.\n",
      "[Epoch 211/1000] Train Loss: 0.1597  |  Val Loss: 0.2171\n",
      "Validation loss improved from 0.2189 to 0.2171.\n",
      "[Epoch 212/1000] Train Loss: 0.1580  |  Val Loss: 0.2151\n",
      "Validation loss improved from 0.2171 to 0.2151.\n",
      "[Epoch 213/1000] Train Loss: 0.1563  |  Val Loss: 0.2130\n",
      "Validation loss improved from 0.2151 to 0.2130.\n",
      "[Epoch 214/1000] Train Loss: 0.1547  |  Val Loss: 0.2111\n",
      "Validation loss improved from 0.2130 to 0.2111.\n",
      "[Epoch 215/1000] Train Loss: 0.1530  |  Val Loss: 0.2092\n",
      "Validation loss improved from 0.2111 to 0.2092.\n",
      "[Epoch 216/1000] Train Loss: 0.1516  |  Val Loss: 0.2072\n",
      "Validation loss improved from 0.2092 to 0.2072.\n",
      "[Epoch 217/1000] Train Loss: 0.1499  |  Val Loss: 0.2053\n",
      "Validation loss improved from 0.2072 to 0.2053.\n",
      "[Epoch 218/1000] Train Loss: 0.1482  |  Val Loss: 0.2034\n",
      "Validation loss improved from 0.2053 to 0.2034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 219/1000] Train Loss: 0.1467  |  Val Loss: 0.2016\n",
      "Validation loss improved from 0.2034 to 0.2016.\n",
      "[Epoch 220/1000] Train Loss: 0.1453  |  Val Loss: 0.1996\n",
      "Validation loss improved from 0.2016 to 0.1996.\n",
      "[Epoch 221/1000] Train Loss: 0.1436  |  Val Loss: 0.1980\n",
      "Validation loss improved from 0.1996 to 0.1980.\n",
      "[Epoch 222/1000] Train Loss: 0.1421  |  Val Loss: 0.1964\n",
      "Validation loss improved from 0.1980 to 0.1964.\n",
      "[Epoch 223/1000] Train Loss: 0.1407  |  Val Loss: 0.1946\n",
      "Validation loss improved from 0.1964 to 0.1946.\n",
      "[Epoch 224/1000] Train Loss: 0.1391  |  Val Loss: 0.1930\n",
      "Validation loss improved from 0.1946 to 0.1930.\n",
      "[Epoch 225/1000] Train Loss: 0.1378  |  Val Loss: 0.1913\n",
      "Validation loss improved from 0.1930 to 0.1913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 226/1000] Train Loss: 0.1364  |  Val Loss: 0.1895\n",
      "Validation loss improved from 0.1913 to 0.1895.\n",
      "[Epoch 227/1000] Train Loss: 0.1348  |  Val Loss: 0.1879\n",
      "Validation loss improved from 0.1895 to 0.1879.\n",
      "[Epoch 228/1000] Train Loss: 0.1334  |  Val Loss: 0.1865\n",
      "Validation loss improved from 0.1879 to 0.1865.\n",
      "[Epoch 229/1000] Train Loss: 0.1321  |  Val Loss: 0.1849\n",
      "Validation loss improved from 0.1865 to 0.1849.\n",
      "[Epoch 230/1000] Train Loss: 0.1306  |  Val Loss: 0.1834\n",
      "Validation loss improved from 0.1849 to 0.1834.\n",
      "[Epoch 231/1000] Train Loss: 0.1292  |  Val Loss: 0.1817\n",
      "Validation loss improved from 0.1834 to 0.1817.\n",
      "[Epoch 232/1000] Train Loss: 0.1278  |  Val Loss: 0.1801\n",
      "Validation loss improved from 0.1817 to 0.1801.\n",
      "[Epoch 233/1000] Train Loss: 0.1266  |  Val Loss: 0.1785\n",
      "Validation loss improved from 0.1801 to 0.1785.\n",
      "[Epoch 234/1000] Train Loss: 0.1252  |  Val Loss: 0.1769\n",
      "Validation loss improved from 0.1785 to 0.1769.\n",
      "[Epoch 235/1000] Train Loss: 0.1240  |  Val Loss: 0.1753\n",
      "Validation loss improved from 0.1769 to 0.1753.\n",
      "[Epoch 236/1000] Train Loss: 0.1226  |  Val Loss: 0.1739\n",
      "Validation loss improved from 0.1753 to 0.1739.\n",
      "[Epoch 237/1000] Train Loss: 0.1212  |  Val Loss: 0.1726\n",
      "Validation loss improved from 0.1739 to 0.1726.\n",
      "[Epoch 238/1000] Train Loss: 0.1200  |  Val Loss: 0.1712\n",
      "Validation loss improved from 0.1726 to 0.1712.\n",
      "[Epoch 239/1000] Train Loss: 0.1188  |  Val Loss: 0.1698\n",
      "Validation loss improved from 0.1712 to 0.1698.\n",
      "[Epoch 240/1000] Train Loss: 0.1174  |  Val Loss: 0.1684\n",
      "Validation loss improved from 0.1698 to 0.1684.\n",
      "[Epoch 241/1000] Train Loss: 0.1163  |  Val Loss: 0.1669\n",
      "Validation loss improved from 0.1684 to 0.1669.\n",
      "[Epoch 242/1000] Train Loss: 0.1151  |  Val Loss: 0.1655\n",
      "Validation loss improved from 0.1669 to 0.1655.\n",
      "[Epoch 243/1000] Train Loss: 0.1138  |  Val Loss: 0.1640\n",
      "Validation loss improved from 0.1655 to 0.1640.\n",
      "[Epoch 244/1000] Train Loss: 0.1128  |  Val Loss: 0.1627\n",
      "Validation loss improved from 0.1640 to 0.1627.\n",
      "[Epoch 245/1000] Train Loss: 0.1116  |  Val Loss: 0.1613\n",
      "Validation loss improved from 0.1627 to 0.1613.\n",
      "[Epoch 246/1000] Train Loss: 0.1103  |  Val Loss: 0.1600\n",
      "Validation loss improved from 0.1613 to 0.1600.\n",
      "[Epoch 247/1000] Train Loss: 0.1093  |  Val Loss: 0.1588\n",
      "Validation loss improved from 0.1600 to 0.1588.\n",
      "[Epoch 248/1000] Train Loss: 0.1080  |  Val Loss: 0.1576\n",
      "Validation loss improved from 0.1588 to 0.1576.\n",
      "[Epoch 249/1000] Train Loss: 0.1071  |  Val Loss: 0.1565\n",
      "Validation loss improved from 0.1576 to 0.1565.\n",
      "[Epoch 250/1000] Train Loss: 0.1058  |  Val Loss: 0.1553\n",
      "Validation loss improved from 0.1565 to 0.1553.\n",
      "[Epoch 251/1000] Train Loss: 0.1049  |  Val Loss: 0.1542\n",
      "Validation loss improved from 0.1553 to 0.1542.\n",
      "[Epoch 252/1000] Train Loss: 0.1037  |  Val Loss: 0.1529\n",
      "Validation loss improved from 0.1542 to 0.1529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 253/1000] Train Loss: 0.1027  |  Val Loss: 0.1516\n",
      "Validation loss improved from 0.1529 to 0.1516.\n",
      "[Epoch 254/1000] Train Loss: 0.1017  |  Val Loss: 0.1505\n",
      "Validation loss improved from 0.1516 to 0.1505.\n",
      "[Epoch 255/1000] Train Loss: 0.1006  |  Val Loss: 0.1492\n",
      "Validation loss improved from 0.1505 to 0.1492.\n",
      "[Epoch 256/1000] Train Loss: 0.0996  |  Val Loss: 0.1480\n",
      "Validation loss improved from 0.1492 to 0.1480.\n",
      "[Epoch 257/1000] Train Loss: 0.0986  |  Val Loss: 0.1468\n",
      "Validation loss improved from 0.1480 to 0.1468.\n",
      "[Epoch 258/1000] Train Loss: 0.0975  |  Val Loss: 0.1456\n",
      "Validation loss improved from 0.1468 to 0.1456.\n",
      "[Epoch 259/1000] Train Loss: 0.0966  |  Val Loss: 0.1444\n",
      "Validation loss improved from 0.1456 to 0.1444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 260/1000] Train Loss: 0.0956  |  Val Loss: 0.1433\n",
      "Validation loss improved from 0.1444 to 0.1433.\n",
      "[Epoch 261/1000] Train Loss: 0.0947  |  Val Loss: 0.1423\n",
      "Validation loss improved from 0.1433 to 0.1423.\n",
      "[Epoch 262/1000] Train Loss: 0.0938  |  Val Loss: 0.1413\n",
      "Validation loss improved from 0.1423 to 0.1413.\n",
      "[Epoch 263/1000] Train Loss: 0.0929  |  Val Loss: 0.1400\n",
      "Validation loss improved from 0.1413 to 0.1400.\n",
      "[Epoch 264/1000] Train Loss: 0.0919  |  Val Loss: 0.1390\n",
      "Validation loss improved from 0.1400 to 0.1390.\n",
      "[Epoch 265/1000] Train Loss: 0.0910  |  Val Loss: 0.1381\n",
      "Validation loss improved from 0.1390 to 0.1381.\n",
      "[Epoch 266/1000] Train Loss: 0.0902  |  Val Loss: 0.1370\n",
      "Validation loss improved from 0.1381 to 0.1370.\n",
      "[Epoch 267/1000] Train Loss: 0.0894  |  Val Loss: 0.1361\n",
      "Validation loss improved from 0.1370 to 0.1361.\n",
      "[Epoch 268/1000] Train Loss: 0.0885  |  Val Loss: 0.1351\n",
      "Validation loss improved from 0.1361 to 0.1351.\n",
      "[Epoch 269/1000] Train Loss: 0.0876  |  Val Loss: 0.1341\n",
      "Validation loss improved from 0.1351 to 0.1341.\n",
      "[Epoch 270/1000] Train Loss: 0.0867  |  Val Loss: 0.1332\n",
      "Validation loss improved from 0.1341 to 0.1332.\n",
      "[Epoch 271/1000] Train Loss: 0.0859  |  Val Loss: 0.1322\n",
      "Validation loss improved from 0.1332 to 0.1322.\n",
      "[Epoch 272/1000] Train Loss: 0.0851  |  Val Loss: 0.1313\n",
      "Validation loss improved from 0.1322 to 0.1313.\n",
      "[Epoch 273/1000] Train Loss: 0.0843  |  Val Loss: 0.1304\n",
      "Validation loss improved from 0.1313 to 0.1304.\n",
      "[Epoch 274/1000] Train Loss: 0.0835  |  Val Loss: 0.1296\n",
      "Validation loss improved from 0.1304 to 0.1296.\n",
      "[Epoch 275/1000] Train Loss: 0.0827  |  Val Loss: 0.1286\n",
      "Validation loss improved from 0.1296 to 0.1286.\n",
      "[Epoch 276/1000] Train Loss: 0.0820  |  Val Loss: 0.1277\n",
      "Validation loss improved from 0.1286 to 0.1277.\n",
      "[Epoch 277/1000] Train Loss: 0.0812  |  Val Loss: 0.1268\n",
      "Validation loss improved from 0.1277 to 0.1268.\n",
      "[Epoch 278/1000] Train Loss: 0.0804  |  Val Loss: 0.1260\n",
      "Validation loss improved from 0.1268 to 0.1260.\n",
      "[Epoch 279/1000] Train Loss: 0.0797  |  Val Loss: 0.1252\n",
      "Validation loss improved from 0.1260 to 0.1252.\n",
      "[Epoch 280/1000] Train Loss: 0.0789  |  Val Loss: 0.1243\n",
      "Validation loss improved from 0.1252 to 0.1243.\n",
      "[Epoch 281/1000] Train Loss: 0.0783  |  Val Loss: 0.1234\n",
      "Validation loss improved from 0.1243 to 0.1234.\n",
      "[Epoch 282/1000] Train Loss: 0.0775  |  Val Loss: 0.1226\n",
      "Validation loss improved from 0.1234 to 0.1226.\n",
      "[Epoch 283/1000] Train Loss: 0.0768  |  Val Loss: 0.1219\n",
      "Validation loss improved from 0.1226 to 0.1219.\n",
      "[Epoch 284/1000] Train Loss: 0.0761  |  Val Loss: 0.1213\n",
      "Validation loss improved from 0.1219 to 0.1213.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 285/1000] Train Loss: 0.0755  |  Val Loss: 0.1206\n",
      "Validation loss improved from 0.1213 to 0.1206.\n",
      "[Epoch 286/1000] Train Loss: 0.0747  |  Val Loss: 0.1199\n",
      "Validation loss improved from 0.1206 to 0.1199.\n",
      "[Epoch 287/1000] Train Loss: 0.0741  |  Val Loss: 0.1190\n",
      "Validation loss improved from 0.1199 to 0.1190.\n",
      "[Epoch 288/1000] Train Loss: 0.0734  |  Val Loss: 0.1182\n",
      "Validation loss improved from 0.1190 to 0.1182.\n",
      "[Epoch 289/1000] Train Loss: 0.0728  |  Val Loss: 0.1176\n",
      "Validation loss improved from 0.1182 to 0.1176.\n",
      "[Epoch 290/1000] Train Loss: 0.0721  |  Val Loss: 0.1168\n",
      "Validation loss improved from 0.1176 to 0.1168.\n",
      "[Epoch 291/1000] Train Loss: 0.0716  |  Val Loss: 0.1160\n",
      "Validation loss improved from 0.1168 to 0.1160.\n",
      "[Epoch 292/1000] Train Loss: 0.0710  |  Val Loss: 0.1153\n",
      "Validation loss improved from 0.1160 to 0.1153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 293/1000] Train Loss: 0.0704  |  Val Loss: 0.1145\n",
      "Validation loss improved from 0.1153 to 0.1145.\n",
      "[Epoch 294/1000] Train Loss: 0.0697  |  Val Loss: 0.1139\n",
      "Validation loss improved from 0.1145 to 0.1139.\n",
      "[Epoch 295/1000] Train Loss: 0.0691  |  Val Loss: 0.1133\n",
      "Validation loss improved from 0.1139 to 0.1133.\n",
      "[Epoch 296/1000] Train Loss: 0.0685  |  Val Loss: 0.1126\n",
      "Validation loss improved from 0.1133 to 0.1126.\n",
      "[Epoch 297/1000] Train Loss: 0.0680  |  Val Loss: 0.1121\n",
      "Validation loss improved from 0.1126 to 0.1121.\n",
      "[Epoch 298/1000] Train Loss: 0.0675  |  Val Loss: 0.1113\n",
      "Validation loss improved from 0.1121 to 0.1113.\n",
      "[Epoch 299/1000] Train Loss: 0.0668  |  Val Loss: 0.1106\n",
      "Validation loss improved from 0.1113 to 0.1106.\n",
      "[Epoch 300/1000] Train Loss: 0.0664  |  Val Loss: 0.1101\n",
      "Validation loss improved from 0.1106 to 0.1101.\n",
      "[Epoch 301/1000] Train Loss: 0.0658  |  Val Loss: 0.1094\n",
      "Validation loss improved from 0.1101 to 0.1094.\n",
      "[Epoch 302/1000] Train Loss: 0.0652  |  Val Loss: 0.1087\n",
      "Validation loss improved from 0.1094 to 0.1087.\n",
      "[Epoch 303/1000] Train Loss: 0.0647  |  Val Loss: 0.1081\n",
      "Validation loss improved from 0.1087 to 0.1081.\n",
      "[Epoch 304/1000] Train Loss: 0.0642  |  Val Loss: 0.1074\n",
      "Validation loss improved from 0.1081 to 0.1074.\n",
      "[Epoch 305/1000] Train Loss: 0.0638  |  Val Loss: 0.1068\n",
      "Validation loss improved from 0.1074 to 0.1068.\n",
      "[Epoch 306/1000] Train Loss: 0.0632  |  Val Loss: 0.1063\n",
      "Validation loss improved from 0.1068 to 0.1063.\n",
      "[Epoch 307/1000] Train Loss: 0.0628  |  Val Loss: 0.1058\n",
      "Validation loss improved from 0.1063 to 0.1058.\n",
      "[Epoch 308/1000] Train Loss: 0.0622  |  Val Loss: 0.1053\n",
      "Validation loss improved from 0.1058 to 0.1053.\n",
      "[Epoch 309/1000] Train Loss: 0.0618  |  Val Loss: 0.1046\n",
      "Validation loss improved from 0.1053 to 0.1046.\n",
      "[Epoch 310/1000] Train Loss: 0.0612  |  Val Loss: 0.1040\n",
      "Validation loss improved from 0.1046 to 0.1040.\n",
      "[Epoch 311/1000] Train Loss: 0.0609  |  Val Loss: 0.1034\n",
      "Validation loss improved from 0.1040 to 0.1034.\n",
      "[Epoch 312/1000] Train Loss: 0.0604  |  Val Loss: 0.1029\n",
      "Validation loss improved from 0.1034 to 0.1029.\n",
      "[Epoch 313/1000] Train Loss: 0.0599  |  Val Loss: 0.1024\n",
      "Validation loss improved from 0.1029 to 0.1024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 314/1000] Train Loss: 0.0594  |  Val Loss: 0.1019\n",
      "Validation loss improved from 0.1024 to 0.1019.\n",
      "[Epoch 315/1000] Train Loss: 0.0589  |  Val Loss: 0.1015\n",
      "Validation loss improved from 0.1019 to 0.1015.\n",
      "[Epoch 316/1000] Train Loss: 0.0586  |  Val Loss: 0.1010\n",
      "Validation loss improved from 0.1015 to 0.1010.\n",
      "[Epoch 317/1000] Train Loss: 0.0581  |  Val Loss: 0.1005\n",
      "Validation loss improved from 0.1010 to 0.1005.\n",
      "[Epoch 318/1000] Train Loss: 0.0576  |  Val Loss: 0.1000\n",
      "Validation loss improved from 0.1005 to 0.1000.\n",
      "[Epoch 319/1000] Train Loss: 0.0572  |  Val Loss: 0.0994\n",
      "Validation loss improved from 0.1000 to 0.0994.\n",
      "[Epoch 320/1000] Train Loss: 0.0568  |  Val Loss: 0.0989\n",
      "Validation loss improved from 0.0994 to 0.0989.\n",
      "[Epoch 321/1000] Train Loss: 0.0565  |  Val Loss: 0.0984\n",
      "Validation loss improved from 0.0989 to 0.0984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 322/1000] Train Loss: 0.0560  |  Val Loss: 0.0979\n",
      "Validation loss improved from 0.0984 to 0.0979.\n",
      "[Epoch 323/1000] Train Loss: 0.0556  |  Val Loss: 0.0973\n",
      "Validation loss improved from 0.0979 to 0.0973.\n",
      "[Epoch 324/1000] Train Loss: 0.0553  |  Val Loss: 0.0968\n",
      "Validation loss improved from 0.0973 to 0.0968.\n",
      "[Epoch 325/1000] Train Loss: 0.0548  |  Val Loss: 0.0963\n",
      "Validation loss improved from 0.0968 to 0.0963.\n",
      "[Epoch 326/1000] Train Loss: 0.0544  |  Val Loss: 0.0958\n",
      "Validation loss improved from 0.0963 to 0.0958.\n",
      "[Epoch 327/1000] Train Loss: 0.0541  |  Val Loss: 0.0953\n",
      "Validation loss improved from 0.0958 to 0.0953.\n",
      "[Epoch 328/1000] Train Loss: 0.0537  |  Val Loss: 0.0948\n",
      "Validation loss improved from 0.0953 to 0.0948.\n",
      "[Epoch 329/1000] Train Loss: 0.0534  |  Val Loss: 0.0944\n",
      "Validation loss improved from 0.0948 to 0.0944.\n",
      "[Epoch 330/1000] Train Loss: 0.0529  |  Val Loss: 0.0940\n",
      "Validation loss improved from 0.0944 to 0.0940.\n",
      "[Epoch 331/1000] Train Loss: 0.0528  |  Val Loss: 0.0937\n",
      "Validation loss improved from 0.0940 to 0.0937.\n",
      "[Epoch 332/1000] Train Loss: 0.0523  |  Val Loss: 0.0932\n",
      "Validation loss improved from 0.0937 to 0.0932.\n",
      "[Epoch 333/1000] Train Loss: 0.0520  |  Val Loss: 0.0930\n",
      "Validation loss improved from 0.0932 to 0.0930.\n",
      "[Epoch 334/1000] Train Loss: 0.0516  |  Val Loss: 0.0926\n",
      "Validation loss improved from 0.0930 to 0.0926.\n",
      "[Epoch 335/1000] Train Loss: 0.0512  |  Val Loss: 0.0921\n",
      "Validation loss improved from 0.0926 to 0.0921.\n",
      "[Epoch 336/1000] Train Loss: 0.0510  |  Val Loss: 0.0918\n",
      "Validation loss improved from 0.0921 to 0.0918.\n",
      "[Epoch 337/1000] Train Loss: 0.0506  |  Val Loss: 0.0913\n",
      "Validation loss improved from 0.0918 to 0.0913.\n",
      "[Epoch 338/1000] Train Loss: 0.0503  |  Val Loss: 0.0909\n",
      "Validation loss improved from 0.0913 to 0.0909.\n",
      "[Epoch 339/1000] Train Loss: 0.0500  |  Val Loss: 0.0906\n",
      "Validation loss improved from 0.0909 to 0.0906.\n",
      "[Epoch 340/1000] Train Loss: 0.0496  |  Val Loss: 0.0903\n",
      "Validation loss improved from 0.0906 to 0.0903.\n",
      "[Epoch 341/1000] Train Loss: 0.0493  |  Val Loss: 0.0900\n",
      "Validation loss improved from 0.0903 to 0.0900.\n",
      "[Epoch 342/1000] Train Loss: 0.0491  |  Val Loss: 0.0897\n",
      "Validation loss improved from 0.0900 to 0.0897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 343/1000] Train Loss: 0.0487  |  Val Loss: 0.0893\n",
      "Validation loss improved from 0.0897 to 0.0893.\n",
      "[Epoch 344/1000] Train Loss: 0.0484  |  Val Loss: 0.0889\n",
      "Validation loss improved from 0.0893 to 0.0889.\n",
      "[Epoch 345/1000] Train Loss: 0.0482  |  Val Loss: 0.0887\n",
      "Validation loss improved from 0.0889 to 0.0887.\n",
      "[Epoch 346/1000] Train Loss: 0.0478  |  Val Loss: 0.0882\n",
      "Validation loss improved from 0.0887 to 0.0882.\n",
      "[Epoch 347/1000] Train Loss: 0.0477  |  Val Loss: 0.0878\n",
      "Validation loss improved from 0.0882 to 0.0878.\n",
      "[Epoch 348/1000] Train Loss: 0.0474  |  Val Loss: 0.0875\n",
      "Validation loss improved from 0.0878 to 0.0875.\n",
      "[Epoch 349/1000] Train Loss: 0.0471  |  Val Loss: 0.0872\n",
      "Validation loss improved from 0.0875 to 0.0872.\n",
      "[Epoch 350/1000] Train Loss: 0.0468  |  Val Loss: 0.0869\n",
      "Validation loss improved from 0.0872 to 0.0869.\n",
      "[Epoch 351/1000] Train Loss: 0.0466  |  Val Loss: 0.0866\n",
      "Validation loss improved from 0.0869 to 0.0866.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 352/1000] Train Loss: 0.0462  |  Val Loss: 0.0863\n",
      "Validation loss improved from 0.0866 to 0.0863.\n",
      "[Epoch 353/1000] Train Loss: 0.0460  |  Val Loss: 0.0860\n",
      "Validation loss improved from 0.0863 to 0.0860.\n",
      "[Epoch 354/1000] Train Loss: 0.0457  |  Val Loss: 0.0858\n",
      "Validation loss improved from 0.0860 to 0.0858.\n",
      "[Epoch 355/1000] Train Loss: 0.0455  |  Val Loss: 0.0854\n",
      "Validation loss improved from 0.0858 to 0.0854.\n",
      "[Epoch 356/1000] Train Loss: 0.0452  |  Val Loss: 0.0851\n",
      "Validation loss improved from 0.0854 to 0.0851.\n",
      "[Epoch 357/1000] Train Loss: 0.0450  |  Val Loss: 0.0848\n",
      "Validation loss improved from 0.0851 to 0.0848.\n",
      "[Epoch 358/1000] Train Loss: 0.0449  |  Val Loss: 0.0844\n",
      "Validation loss improved from 0.0848 to 0.0844.\n",
      "[Epoch 359/1000] Train Loss: 0.0446  |  Val Loss: 0.0843\n",
      "Validation loss improved from 0.0844 to 0.0843.\n",
      "[Epoch 360/1000] Train Loss: 0.0442  |  Val Loss: 0.0840\n",
      "Validation loss improved from 0.0843 to 0.0840.\n",
      "[Epoch 361/1000] Train Loss: 0.0440  |  Val Loss: 0.0837\n",
      "Validation loss improved from 0.0840 to 0.0837.\n",
      "[Epoch 362/1000] Train Loss: 0.0438  |  Val Loss: 0.0833\n",
      "Validation loss improved from 0.0837 to 0.0833.\n",
      "[Epoch 363/1000] Train Loss: 0.0436  |  Val Loss: 0.0829\n",
      "Validation loss improved from 0.0833 to 0.0829.\n",
      "[Epoch 364/1000] Train Loss: 0.0433  |  Val Loss: 0.0826\n",
      "Validation loss improved from 0.0829 to 0.0826.\n",
      "[Epoch 365/1000] Train Loss: 0.0432  |  Val Loss: 0.0826\n",
      "Validation loss improved from 0.0826 to 0.0826.\n",
      "[Epoch 366/1000] Train Loss: 0.0428  |  Val Loss: 0.0824\n",
      "Validation loss improved from 0.0826 to 0.0824.\n",
      "[Epoch 367/1000] Train Loss: 0.0426  |  Val Loss: 0.0821\n",
      "Validation loss improved from 0.0824 to 0.0821.\n",
      "[Epoch 368/1000] Train Loss: 0.0424  |  Val Loss: 0.0819\n",
      "Validation loss improved from 0.0821 to 0.0819.\n",
      "[Epoch 369/1000] Train Loss: 0.0422  |  Val Loss: 0.0816\n",
      "Validation loss improved from 0.0819 to 0.0816.\n",
      "[Epoch 370/1000] Train Loss: 0.0420  |  Val Loss: 0.0815\n",
      "Validation loss improved from 0.0816 to 0.0815.\n",
      "[Epoch 371/1000] Train Loss: 0.0418  |  Val Loss: 0.0813\n",
      "Validation loss improved from 0.0815 to 0.0813.\n",
      "[Epoch 372/1000] Train Loss: 0.0416  |  Val Loss: 0.0812\n",
      "Validation loss improved from 0.0813 to 0.0812.\n",
      "[Epoch 373/1000] Train Loss: 0.0414  |  Val Loss: 0.0809\n",
      "Validation loss improved from 0.0812 to 0.0809.\n",
      "[Epoch 374/1000] Train Loss: 0.0411  |  Val Loss: 0.0806\n",
      "Validation loss improved from 0.0809 to 0.0806.\n",
      "[Epoch 375/1000] Train Loss: 0.0410  |  Val Loss: 0.0804\n",
      "Validation loss improved from 0.0806 to 0.0804.\n",
      "[Epoch 376/1000] Train Loss: 0.0407  |  Val Loss: 0.0802\n",
      "Validation loss improved from 0.0804 to 0.0802.\n",
      "[Epoch 377/1000] Train Loss: 0.0405  |  Val Loss: 0.0800\n",
      "Validation loss improved from 0.0802 to 0.0800.\n",
      "[Epoch 378/1000] Train Loss: 0.0403  |  Val Loss: 0.0798\n",
      "Validation loss improved from 0.0800 to 0.0798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 379/1000] Train Loss: 0.0401  |  Val Loss: 0.0795\n",
      "Validation loss improved from 0.0798 to 0.0795.\n",
      "[Epoch 380/1000] Train Loss: 0.0399  |  Val Loss: 0.0792\n",
      "Validation loss improved from 0.0795 to 0.0792.\n",
      "[Epoch 381/1000] Train Loss: 0.0398  |  Val Loss: 0.0791\n",
      "Validation loss improved from 0.0792 to 0.0791.\n",
      "[Epoch 382/1000] Train Loss: 0.0396  |  Val Loss: 0.0789\n",
      "Validation loss improved from 0.0791 to 0.0789.\n",
      "[Epoch 383/1000] Train Loss: 0.0394  |  Val Loss: 0.0788\n",
      "Validation loss improved from 0.0789 to 0.0788.\n",
      "[Epoch 384/1000] Train Loss: 0.0392  |  Val Loss: 0.0786\n",
      "Validation loss improved from 0.0788 to 0.0786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 385/1000] Train Loss: 0.0392  |  Val Loss: 0.0782\n",
      "Validation loss improved from 0.0786 to 0.0782.\n",
      "[Epoch 386/1000] Train Loss: 0.0389  |  Val Loss: 0.0780\n",
      "Validation loss improved from 0.0782 to 0.0780.\n",
      "[Epoch 387/1000] Train Loss: 0.0387  |  Val Loss: 0.0778\n",
      "Validation loss improved from 0.0780 to 0.0778.\n",
      "[Epoch 388/1000] Train Loss: 0.0386  |  Val Loss: 0.0777\n",
      "Validation loss improved from 0.0778 to 0.0777.\n",
      "[Epoch 389/1000] Train Loss: 0.0383  |  Val Loss: 0.0775\n",
      "Validation loss improved from 0.0777 to 0.0775.\n",
      "[Epoch 390/1000] Train Loss: 0.0382  |  Val Loss: 0.0774\n",
      "Validation loss improved from 0.0775 to 0.0774.\n",
      "[Epoch 391/1000] Train Loss: 0.0381  |  Val Loss: 0.0772\n",
      "Validation loss improved from 0.0774 to 0.0772.\n",
      "[Epoch 392/1000] Train Loss: 0.0378  |  Val Loss: 0.0772\n",
      "Validation loss improved from 0.0772 to 0.0772.\n",
      "[Epoch 393/1000] Train Loss: 0.0377  |  Val Loss: 0.0770\n",
      "Validation loss improved from 0.0772 to 0.0770.\n",
      "[Epoch 394/1000] Train Loss: 0.0375  |  Val Loss: 0.0770\n",
      "Validation loss improved from 0.0770 to 0.0770.\n",
      "[Epoch 395/1000] Train Loss: 0.0373  |  Val Loss: 0.0768\n",
      "Validation loss improved from 0.0770 to 0.0768.\n",
      "[Epoch 396/1000] Train Loss: 0.0372  |  Val Loss: 0.0767\n",
      "Validation loss improved from 0.0768 to 0.0767.\n",
      "[Epoch 397/1000] Train Loss: 0.0370  |  Val Loss: 0.0765\n",
      "Validation loss improved from 0.0767 to 0.0765.\n",
      "[Epoch 398/1000] Train Loss: 0.0370  |  Val Loss: 0.0762\n",
      "Validation loss improved from 0.0765 to 0.0762.\n",
      "[Epoch 399/1000] Train Loss: 0.0368  |  Val Loss: 0.0761\n",
      "Validation loss improved from 0.0762 to 0.0761.\n",
      "[Epoch 400/1000] Train Loss: 0.0366  |  Val Loss: 0.0759\n",
      "Validation loss improved from 0.0761 to 0.0759.\n",
      "[Epoch 401/1000] Train Loss: 0.0364  |  Val Loss: 0.0757\n",
      "Validation loss improved from 0.0759 to 0.0757.\n",
      "[Epoch 402/1000] Train Loss: 0.0363  |  Val Loss: 0.0756\n",
      "Validation loss improved from 0.0757 to 0.0756.\n",
      "[Epoch 403/1000] Train Loss: 0.0361  |  Val Loss: 0.0755\n",
      "Validation loss improved from 0.0756 to 0.0755.\n",
      "[Epoch 404/1000] Train Loss: 0.0360  |  Val Loss: 0.0753\n",
      "Validation loss improved from 0.0755 to 0.0753.\n",
      "[Epoch 405/1000] Train Loss: 0.0359  |  Val Loss: 0.0752\n",
      "Validation loss improved from 0.0753 to 0.0752.\n",
      "[Epoch 406/1000] Train Loss: 0.0357  |  Val Loss: 0.0749\n",
      "Validation loss improved from 0.0752 to 0.0749.\n",
      "[Epoch 407/1000] Train Loss: 0.0355  |  Val Loss: 0.0747\n",
      "Validation loss improved from 0.0749 to 0.0747.\n",
      "[Epoch 408/1000] Train Loss: 0.0356  |  Val Loss: 0.0744\n",
      "Validation loss improved from 0.0747 to 0.0744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 409/1000] Train Loss: 0.0354  |  Val Loss: 0.0744\n",
      "Validation loss improved from 0.0744 to 0.0744.\n",
      "[Epoch 410/1000] Train Loss: 0.0352  |  Val Loss: 0.0743\n",
      "Validation loss improved from 0.0744 to 0.0743.\n",
      "[Epoch 411/1000] Train Loss: 0.0351  |  Val Loss: 0.0741\n",
      "Validation loss improved from 0.0743 to 0.0741.\n",
      "[Epoch 412/1000] Train Loss: 0.0350  |  Val Loss: 0.0741\n",
      "Validation loss improved from 0.0741 to 0.0741.\n",
      "[Epoch 413/1000] Train Loss: 0.0349  |  Val Loss: 0.0743\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 414/1000] Train Loss: 0.0347  |  Val Loss: 0.0742\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 415/1000] Train Loss: 0.0346  |  Val Loss: 0.0743\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 416/1000] Train Loss: 0.0344  |  Val Loss: 0.0742\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 417/1000] Train Loss: 0.0343  |  Val Loss: 0.0740\n",
      "Validation loss improved from 0.0741 to 0.0740.\n",
      "[Epoch 418/1000] Train Loss: 0.0341  |  Val Loss: 0.0739\n",
      "Validation loss improved from 0.0740 to 0.0739.\n",
      "[Epoch 419/1000] Train Loss: 0.0340  |  Val Loss: 0.0736\n",
      "Validation loss improved from 0.0739 to 0.0736.\n",
      "[Epoch 420/1000] Train Loss: 0.0340  |  Val Loss: 0.0734\n",
      "Validation loss improved from 0.0736 to 0.0734.\n",
      "[Epoch 421/1000] Train Loss: 0.0338  |  Val Loss: 0.0732\n",
      "Validation loss improved from 0.0734 to 0.0732.\n",
      "[Epoch 422/1000] Train Loss: 0.0338  |  Val Loss: 0.0731\n",
      "Validation loss improved from 0.0732 to 0.0731.\n",
      "[Epoch 423/1000] Train Loss: 0.0337  |  Val Loss: 0.0726\n",
      "Validation loss improved from 0.0731 to 0.0726.\n",
      "[Epoch 424/1000] Train Loss: 0.0335  |  Val Loss: 0.0725\n",
      "Validation loss improved from 0.0726 to 0.0725.\n",
      "[Epoch 425/1000] Train Loss: 0.0334  |  Val Loss: 0.0722\n",
      "Validation loss improved from 0.0725 to 0.0722.\n",
      "[Epoch 426/1000] Train Loss: 0.0333  |  Val Loss: 0.0720\n",
      "Validation loss improved from 0.0722 to 0.0720.\n",
      "[Epoch 427/1000] Train Loss: 0.0333  |  Val Loss: 0.0721\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 428/1000] Train Loss: 0.0331  |  Val Loss: 0.0721\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 429/1000] Train Loss: 0.0331  |  Val Loss: 0.0722\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 430/1000] Train Loss: 0.0329  |  Val Loss: 0.0721\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 431/1000] Train Loss: 0.0327  |  Val Loss: 0.0720\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 432/1000] Train Loss: 0.0327  |  Val Loss: 0.0721\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 433/1000] Train Loss: 0.0326  |  Val Loss: 0.0722\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 434/1000] Train Loss: 0.0326  |  Val Loss: 0.0720\n",
      "Validation loss improved from 0.0720 to 0.0720.\n",
      "[Epoch 435/1000] Train Loss: 0.0323  |  Val Loss: 0.0720\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 436/1000] Train Loss: 0.0324  |  Val Loss: 0.0718\n",
      "Validation loss improved from 0.0720 to 0.0718.\n",
      "[Epoch 437/1000] Train Loss: 0.0321  |  Val Loss: 0.0715\n",
      "Validation loss improved from 0.0718 to 0.0715.\n",
      "[Epoch 438/1000] Train Loss: 0.0321  |  Val Loss: 0.0713\n",
      "Validation loss improved from 0.0715 to 0.0713.\n",
      "[Epoch 439/1000] Train Loss: 0.0320  |  Val Loss: 0.0712\n",
      "Validation loss improved from 0.0713 to 0.0712.\n",
      "[Epoch 440/1000] Train Loss: 0.0319  |  Val Loss: 0.0710\n",
      "Validation loss improved from 0.0712 to 0.0710.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 441/1000] Train Loss: 0.0317  |  Val Loss: 0.0710\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 442/1000] Train Loss: 0.0316  |  Val Loss: 0.0712\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 443/1000] Train Loss: 0.0315  |  Val Loss: 0.0710\n",
      "Validation loss improved from 0.0710 to 0.0710.\n",
      "[Epoch 444/1000] Train Loss: 0.0315  |  Val Loss: 0.0710\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 445/1000] Train Loss: 0.0314  |  Val Loss: 0.0709\n",
      "Validation loss improved from 0.0710 to 0.0709.\n",
      "[Epoch 446/1000] Train Loss: 0.0315  |  Val Loss: 0.0705\n",
      "Validation loss improved from 0.0709 to 0.0705.\n",
      "[Epoch 447/1000] Train Loss: 0.0312  |  Val Loss: 0.0703\n",
      "Validation loss improved from 0.0705 to 0.0703.\n",
      "[Epoch 448/1000] Train Loss: 0.0311  |  Val Loss: 0.0703\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 449/1000] Train Loss: 0.0311  |  Val Loss: 0.0704\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 450/1000] Train Loss: 0.0309  |  Val Loss: 0.0705\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 451/1000] Train Loss: 0.0308  |  Val Loss: 0.0705\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 452/1000] Train Loss: 0.0309  |  Val Loss: 0.0706\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 453/1000] Train Loss: 0.0307  |  Val Loss: 0.0705\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 454/1000] Train Loss: 0.0306  |  Val Loss: 0.0703\n",
      "Validation loss improved from 0.0703 to 0.0703.\n",
      "[Epoch 455/1000] Train Loss: 0.0306  |  Val Loss: 0.0700\n",
      "Validation loss improved from 0.0703 to 0.0700.\n",
      "[Epoch 456/1000] Train Loss: 0.0304  |  Val Loss: 0.0695\n",
      "Validation loss improved from 0.0700 to 0.0695.\n",
      "[Epoch 457/1000] Train Loss: 0.0304  |  Val Loss: 0.0691\n",
      "Validation loss improved from 0.0695 to 0.0691.\n",
      "[Epoch 458/1000] Train Loss: 0.0303  |  Val Loss: 0.0691\n",
      "Validation loss improved from 0.0691 to 0.0691.\n",
      "[Epoch 459/1000] Train Loss: 0.0301  |  Val Loss: 0.0690\n",
      "Validation loss improved from 0.0691 to 0.0690.\n",
      "[Epoch 460/1000] Train Loss: 0.0303  |  Val Loss: 0.0692\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 461/1000] Train Loss: 0.0300  |  Val Loss: 0.0691\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 462/1000] Train Loss: 0.0300  |  Val Loss: 0.0690\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 463/1000] Train Loss: 0.0298  |  Val Loss: 0.0688\n",
      "Validation loss improved from 0.0690 to 0.0688.\n",
      "[Epoch 464/1000] Train Loss: 0.0298  |  Val Loss: 0.0685\n",
      "Validation loss improved from 0.0688 to 0.0685.\n",
      "[Epoch 465/1000] Train Loss: 0.0298  |  Val Loss: 0.0681\n",
      "Validation loss improved from 0.0685 to 0.0681.\n",
      "[Epoch 466/1000] Train Loss: 0.0297  |  Val Loss: 0.0680\n",
      "Validation loss improved from 0.0681 to 0.0680.\n",
      "[Epoch 467/1000] Train Loss: 0.0296  |  Val Loss: 0.0682\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 468/1000] Train Loss: 0.0296  |  Val Loss: 0.0683\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 469/1000] Train Loss: 0.0294  |  Val Loss: 0.0681\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 470/1000] Train Loss: 0.0295  |  Val Loss: 0.0679\n",
      "Validation loss improved from 0.0680 to 0.0679.\n",
      "[Epoch 471/1000] Train Loss: 0.0292  |  Val Loss: 0.0680\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 472/1000] Train Loss: 0.0292  |  Val Loss: 0.0680\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 473/1000] Train Loss: 0.0292  |  Val Loss: 0.0680\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 474/1000] Train Loss: 0.0291  |  Val Loss: 0.0680\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 475/1000] Train Loss: 0.0290  |  Val Loss: 0.0680\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 476/1000] Train Loss: 0.0290  |  Val Loss: 0.0682\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 477/1000] Train Loss: 0.0289  |  Val Loss: 0.0681\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 478/1000] Train Loss: 0.0289  |  Val Loss: 0.0677\n",
      "Validation loss improved from 0.0679 to 0.0677.\n",
      "[Epoch 479/1000] Train Loss: 0.0287  |  Val Loss: 0.0674\n",
      "Validation loss improved from 0.0677 to 0.0674.\n",
      "[Epoch 480/1000] Train Loss: 0.0288  |  Val Loss: 0.0671\n",
      "Validation loss improved from 0.0674 to 0.0671.\n",
      "[Epoch 481/1000] Train Loss: 0.0286  |  Val Loss: 0.0671\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 482/1000] Train Loss: 0.0286  |  Val Loss: 0.0669\n",
      "Validation loss improved from 0.0671 to 0.0669.\n",
      "[Epoch 483/1000] Train Loss: 0.0285  |  Val Loss: 0.0667\n",
      "Validation loss improved from 0.0669 to 0.0667.\n",
      "[Epoch 484/1000] Train Loss: 0.0285  |  Val Loss: 0.0668\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 485/1000] Train Loss: 0.0284  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 486/1000] Train Loss: 0.0284  |  Val Loss: 0.0666\n",
      "Validation loss improved from 0.0667 to 0.0666.\n",
      "[Epoch 487/1000] Train Loss: 0.0283  |  Val Loss: 0.0664\n",
      "Validation loss improved from 0.0666 to 0.0664.\n",
      "[Epoch 488/1000] Train Loss: 0.0281  |  Val Loss: 0.0666\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 489/1000] Train Loss: 0.0281  |  Val Loss: 0.0666\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 490/1000] Train Loss: 0.0281  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 491/1000] Train Loss: 0.0280  |  Val Loss: 0.0667\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 492/1000] Train Loss: 0.0280  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 493/1000] Train Loss: 0.0280  |  Val Loss: 0.0668\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 494/1000] Train Loss: 0.0278  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 495/1000] Train Loss: 0.0277  |  Val Loss: 0.0670\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 496/1000] Train Loss: 0.0276  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 497/1000] Train Loss: 0.0276  |  Val Loss: 0.0668\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 498/1000] Train Loss: 0.0277  |  Val Loss: 0.0670\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 499/1000] Train Loss: 0.0275  |  Val Loss: 0.0670\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 500/1000] Train Loss: 0.0274  |  Val Loss: 0.0668\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 501/1000] Train Loss: 0.0275  |  Val Loss: 0.0666\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 502/1000] Train Loss: 0.0274  |  Val Loss: 0.0665\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 503/1000] Train Loss: 0.0273  |  Val Loss: 0.0663\n",
      "Validation loss improved from 0.0664 to 0.0663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 504/1000] Train Loss: 0.0272  |  Val Loss: 0.0665\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 505/1000] Train Loss: 0.0272  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 506/1000] Train Loss: 0.0271  |  Val Loss: 0.0669\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 507/1000] Train Loss: 0.0272  |  Val Loss: 0.0670\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 508/1000] Train Loss: 0.0272  |  Val Loss: 0.0665\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 509/1000] Train Loss: 0.0269  |  Val Loss: 0.0661\n",
      "Validation loss improved from 0.0663 to 0.0661.\n",
      "[Epoch 510/1000] Train Loss: 0.0270  |  Val Loss: 0.0657\n",
      "Validation loss improved from 0.0661 to 0.0657.\n",
      "[Epoch 511/1000] Train Loss: 0.0269  |  Val Loss: 0.0654\n",
      "Validation loss improved from 0.0657 to 0.0654.\n",
      "[Epoch 512/1000] Train Loss: 0.0271  |  Val Loss: 0.0646\n",
      "Validation loss improved from 0.0654 to 0.0646.\n",
      "[Epoch 513/1000] Train Loss: 0.0267  |  Val Loss: 0.0646\n",
      "Validation loss improved from 0.0646 to 0.0646.\n",
      "[Epoch 514/1000] Train Loss: 0.0267  |  Val Loss: 0.0646\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 515/1000] Train Loss: 0.0267  |  Val Loss: 0.0647\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 516/1000] Train Loss: 0.0266  |  Val Loss: 0.0648\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 517/1000] Train Loss: 0.0267  |  Val Loss: 0.0650\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 518/1000] Train Loss: 0.0265  |  Val Loss: 0.0648\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 519/1000] Train Loss: 0.0264  |  Val Loss: 0.0649\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 520/1000] Train Loss: 0.0264  |  Val Loss: 0.0653\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 521/1000] Train Loss: 0.0264  |  Val Loss: 0.0656\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 522/1000] Train Loss: 0.0264  |  Val Loss: 0.0659\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 523/1000] Train Loss: 0.0263  |  Val Loss: 0.0657\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 524/1000] Train Loss: 0.0262  |  Val Loss: 0.0655\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 525/1000] Train Loss: 0.0262  |  Val Loss: 0.0656\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 526/1000] Train Loss: 0.0262  |  Val Loss: 0.0651\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 527/1000] Train Loss: 0.0261  |  Val Loss: 0.0650\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 528/1000] Train Loss: 0.0260  |  Val Loss: 0.0650\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 529/1000] Train Loss: 0.0259  |  Val Loss: 0.0650\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 530/1000] Train Loss: 0.0260  |  Val Loss: 0.0646\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 531/1000] Train Loss: 0.0259  |  Val Loss: 0.0647\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 532/1000] Train Loss: 0.0258  |  Val Loss: 0.0650\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 533/1000] Train Loss: 0.0257  |  Val Loss: 0.0651\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 534/1000] Train Loss: 0.0258  |  Val Loss: 0.0647\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 535/1000] Train Loss: 0.0256  |  Val Loss: 0.0649\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 536/1000] Train Loss: 0.0256  |  Val Loss: 0.0647\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 537/1000] Train Loss: 0.0256  |  Val Loss: 0.0649\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 538/1000] Train Loss: 0.0258  |  Val Loss: 0.0651\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 539/1000] Train Loss: 0.0256  |  Val Loss: 0.0649\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 540/1000] Train Loss: 0.0255  |  Val Loss: 0.0648\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 541/1000] Train Loss: 0.0254  |  Val Loss: 0.0647\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 542/1000] Train Loss: 0.0253  |  Val Loss: 0.0646\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 543/1000] Train Loss: 0.0254  |  Val Loss: 0.0642\n",
      "Validation loss improved from 0.0646 to 0.0642.\n",
      "[Epoch 544/1000] Train Loss: 0.0254  |  Val Loss: 0.0640\n",
      "Validation loss improved from 0.0642 to 0.0640.\n",
      "[Epoch 545/1000] Train Loss: 0.0252  |  Val Loss: 0.0639\n",
      "Validation loss improved from 0.0640 to 0.0639.\n",
      "[Epoch 546/1000] Train Loss: 0.0251  |  Val Loss: 0.0638\n",
      "Validation loss improved from 0.0639 to 0.0638.\n",
      "[Epoch 547/1000] Train Loss: 0.0252  |  Val Loss: 0.0640\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 548/1000] Train Loss: 0.0254  |  Val Loss: 0.0634\n",
      "Validation loss improved from 0.0638 to 0.0634.\n",
      "[Epoch 549/1000] Train Loss: 0.0250  |  Val Loss: 0.0635\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 550/1000] Train Loss: 0.0250  |  Val Loss: 0.0634\n",
      "Validation loss improved from 0.0634 to 0.0634.\n",
      "[Epoch 551/1000] Train Loss: 0.0250  |  Val Loss: 0.0637\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 552/1000] Train Loss: 0.0248  |  Val Loss: 0.0638\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 553/1000] Train Loss: 0.0248  |  Val Loss: 0.0641\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 554/1000] Train Loss: 0.0248  |  Val Loss: 0.0644\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 555/1000] Train Loss: 0.0248  |  Val Loss: 0.0644\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 556/1000] Train Loss: 0.0248  |  Val Loss: 0.0644\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 557/1000] Train Loss: 0.0247  |  Val Loss: 0.0647\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 558/1000] Train Loss: 0.0248  |  Val Loss: 0.0649\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 559/1000] Train Loss: 0.0246  |  Val Loss: 0.0648\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 560/1000] Train Loss: 0.0246  |  Val Loss: 0.0643\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 561/1000] Train Loss: 0.0246  |  Val Loss: 0.0642\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 562/1000] Train Loss: 0.0245  |  Val Loss: 0.0637\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 563/1000] Train Loss: 0.0244  |  Val Loss: 0.0635\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 564/1000] Train Loss: 0.0245  |  Val Loss: 0.0638\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 565/1000] Train Loss: 0.0244  |  Val Loss: 0.0637\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 566/1000] Train Loss: 0.0243  |  Val Loss: 0.0636\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 567/1000] Train Loss: 0.0244  |  Val Loss: 0.0635\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 568/1000] Train Loss: 0.0244  |  Val Loss: 0.0630\n",
      "Validation loss improved from 0.0634 to 0.0630.\n",
      "[Epoch 569/1000] Train Loss: 0.0243  |  Val Loss: 0.0630\n",
      "Validation loss improved from 0.0630 to 0.0630.\n",
      "[Epoch 570/1000] Train Loss: 0.0243  |  Val Loss: 0.0630\n",
      "Validation loss improved from 0.0630 to 0.0630.\n",
      "[Epoch 571/1000] Train Loss: 0.0242  |  Val Loss: 0.0631\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 572/1000] Train Loss: 0.0242  |  Val Loss: 0.0639\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 573/1000] Train Loss: 0.0242  |  Val Loss: 0.0645\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 574/1000] Train Loss: 0.0242  |  Val Loss: 0.0642\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 575/1000] Train Loss: 0.0240  |  Val Loss: 0.0646\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 576/1000] Train Loss: 0.0241  |  Val Loss: 0.0650\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 577/1000] Train Loss: 0.0240  |  Val Loss: 0.0643\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 578/1000] Train Loss: 0.0241  |  Val Loss: 0.0636\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 579/1000] Train Loss: 0.0239  |  Val Loss: 0.0634\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 580/1000] Train Loss: 0.0239  |  Val Loss: 0.0631\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 581/1000] Train Loss: 0.0238  |  Val Loss: 0.0636\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 582/1000] Train Loss: 0.0240  |  Val Loss: 0.0640\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 583/1000] Train Loss: 0.0238  |  Val Loss: 0.0639\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 584/1000] Train Loss: 0.0237  |  Val Loss: 0.0637\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 585/1000] Train Loss: 0.0237  |  Val Loss: 0.0637\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 586/1000] Train Loss: 0.0235  |  Val Loss: 0.0633\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 587/1000] Train Loss: 0.0236  |  Val Loss: 0.0631\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 588/1000] Train Loss: 0.0235  |  Val Loss: 0.0626\n",
      "Validation loss improved from 0.0630 to 0.0626.\n",
      "[Epoch 589/1000] Train Loss: 0.0235  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 590/1000] Train Loss: 0.0234  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 591/1000] Train Loss: 0.0235  |  Val Loss: 0.0624\n",
      "Validation loss improved from 0.0626 to 0.0624.\n",
      "[Epoch 592/1000] Train Loss: 0.0234  |  Val Loss: 0.0624\n",
      "Validation loss improved from 0.0624 to 0.0624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 593/1000] Train Loss: 0.0234  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 594/1000] Train Loss: 0.0234  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 595/1000] Train Loss: 0.0234  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 596/1000] Train Loss: 0.0233  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 597/1000] Train Loss: 0.0232  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 598/1000] Train Loss: 0.0232  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 599/1000] Train Loss: 0.0232  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 600/1000] Train Loss: 0.0232  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 601/1000] Train Loss: 0.0232  |  Val Loss: 0.0622\n",
      "Validation loss improved from 0.0624 to 0.0622.\n",
      "[Epoch 602/1000] Train Loss: 0.0232  |  Val Loss: 0.0621\n",
      "Validation loss improved from 0.0622 to 0.0621.\n",
      "[Epoch 603/1000] Train Loss: 0.0231  |  Val Loss: 0.0620\n",
      "Validation loss improved from 0.0621 to 0.0620.\n",
      "[Epoch 604/1000] Train Loss: 0.0232  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 605/1000] Train Loss: 0.0230  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 606/1000] Train Loss: 0.0230  |  Val Loss: 0.0630\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 607/1000] Train Loss: 0.0229  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 608/1000] Train Loss: 0.0230  |  Val Loss: 0.0630\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 609/1000] Train Loss: 0.0230  |  Val Loss: 0.0632\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 610/1000] Train Loss: 0.0229  |  Val Loss: 0.0633\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 611/1000] Train Loss: 0.0229  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 612/1000] Train Loss: 0.0228  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 613/1000] Train Loss: 0.0228  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 614/1000] Train Loss: 0.0229  |  Val Loss: 0.0616\n",
      "Validation loss improved from 0.0620 to 0.0616.\n",
      "[Epoch 615/1000] Train Loss: 0.0227  |  Val Loss: 0.0615\n",
      "Validation loss improved from 0.0616 to 0.0615.\n",
      "[Epoch 616/1000] Train Loss: 0.0228  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 617/1000] Train Loss: 0.0228  |  Val Loss: 0.0614\n",
      "Validation loss improved from 0.0615 to 0.0614.\n",
      "[Epoch 618/1000] Train Loss: 0.0226  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 619/1000] Train Loss: 0.0226  |  Val Loss: 0.0619\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 620/1000] Train Loss: 0.0225  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 621/1000] Train Loss: 0.0225  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 622/1000] Train Loss: 0.0226  |  Val Loss: 0.0632\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 623/1000] Train Loss: 0.0225  |  Val Loss: 0.0630\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 624/1000] Train Loss: 0.0225  |  Val Loss: 0.0631\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 625/1000] Train Loss: 0.0224  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 626/1000] Train Loss: 0.0224  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 627/1000] Train Loss: 0.0224  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 628/1000] Train Loss: 0.0224  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 629/1000] Train Loss: 0.0223  |  Val Loss: 0.0630\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 630/1000] Train Loss: 0.0225  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 631/1000] Train Loss: 0.0224  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 632/1000] Train Loss: 0.0222  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 633/1000] Train Loss: 0.0223  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 634/1000] Train Loss: 0.0223  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 635/1000] Train Loss: 0.0222  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 636/1000] Train Loss: 0.0221  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 637/1000] Train Loss: 0.0221  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 638/1000] Train Loss: 0.0222  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 639/1000] Train Loss: 0.0222  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 640/1000] Train Loss: 0.0221  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 641/1000] Train Loss: 0.0221  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 642/1000] Train Loss: 0.0223  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 643/1000] Train Loss: 0.0219  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 644/1000] Train Loss: 0.0221  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 645/1000] Train Loss: 0.0220  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 646/1000] Train Loss: 0.0219  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 647/1000] Train Loss: 0.0218  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 648/1000] Train Loss: 0.0218  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 649/1000] Train Loss: 0.0217  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 650/1000] Train Loss: 0.0218  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 651/1000] Train Loss: 0.0217  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 652/1000] Train Loss: 0.0217  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 653/1000] Train Loss: 0.0217  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 654/1000] Train Loss: 0.0216  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 655/1000] Train Loss: 0.0219  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 656/1000] Train Loss: 0.0218  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 657/1000] Train Loss: 0.0217  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 658/1000] Train Loss: 0.0217  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 659/1000] Train Loss: 0.0217  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 660/1000] Train Loss: 0.0216  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 661/1000] Train Loss: 0.0216  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 662/1000] Train Loss: 0.0214  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 663/1000] Train Loss: 0.0215  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 664/1000] Train Loss: 0.0215  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 665/1000] Train Loss: 0.0216  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 666/1000] Train Loss: 0.0214  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 667/1000] Train Loss: 0.0215  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 668/1000] Train Loss: 0.0213  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 669/1000] Train Loss: 0.0213  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 670/1000] Train Loss: 0.0213  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 671/1000] Train Loss: 0.0214  |  Val Loss: 0.0628\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 672/1000] Train Loss: 0.0213  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 673/1000] Train Loss: 0.0212  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 674/1000] Train Loss: 0.0215  |  Val Loss: 0.0611\n",
      "Validation loss improved from 0.0614 to 0.0611.\n",
      "[Epoch 675/1000] Train Loss: 0.0213  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 676/1000] Train Loss: 0.0213  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 677/1000] Train Loss: 0.0213  |  Val Loss: 0.0613\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 678/1000] Train Loss: 0.0212  |  Val Loss: 0.0611\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 679/1000] Train Loss: 0.0211  |  Val Loss: 0.0613\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 680/1000] Train Loss: 0.0210  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 681/1000] Train Loss: 0.0213  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 682/1000] Train Loss: 0.0210  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 683/1000] Train Loss: 0.0210  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 684/1000] Train Loss: 0.0211  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 685/1000] Train Loss: 0.0211  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 686/1000] Train Loss: 0.0211  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 687/1000] Train Loss: 0.0209  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 688/1000] Train Loss: 0.0209  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 689/1000] Train Loss: 0.0208  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 690/1000] Train Loss: 0.0212  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 691/1000] Train Loss: 0.0210  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 692/1000] Train Loss: 0.0210  |  Val Loss: 0.0611\n",
      "Validation loss improved from 0.0611 to 0.0611.\n",
      "[Epoch 693/1000] Train Loss: 0.0211  |  Val Loss: 0.0603\n",
      "Validation loss improved from 0.0611 to 0.0603.\n",
      "[Epoch 694/1000] Train Loss: 0.0208  |  Val Loss: 0.0604\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 695/1000] Train Loss: 0.0209  |  Val Loss: 0.0608\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 696/1000] Train Loss: 0.0207  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 697/1000] Train Loss: 0.0206  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 698/1000] Train Loss: 0.0207  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 699/1000] Train Loss: 0.0206  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 700/1000] Train Loss: 0.0209  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 701/1000] Train Loss: 0.0209  |  Val Loss: 0.0638\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 702/1000] Train Loss: 0.0206  |  Val Loss: 0.0638\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 703/1000] Train Loss: 0.0207  |  Val Loss: 0.0638\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 704/1000] Train Loss: 0.0209  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 705/1000] Train Loss: 0.0205  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 706/1000] Train Loss: 0.0206  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 707/1000] Train Loss: 0.0204  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 708/1000] Train Loss: 0.0205  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 709/1000] Train Loss: 0.0206  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 710/1000] Train Loss: 0.0206  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 711/1000] Train Loss: 0.0205  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 712/1000] Train Loss: 0.0205  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 713/1000] Train Loss: 0.0204  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 714/1000] Train Loss: 0.0204  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 715/1000] Train Loss: 0.0203  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 716/1000] Train Loss: 0.0203  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 717/1000] Train Loss: 0.0204  |  Val Loss: 0.0613\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 718/1000] Train Loss: 0.0203  |  Val Loss: 0.0609\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 719/1000] Train Loss: 0.0204  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 720/1000] Train Loss: 0.0203  |  Val Loss: 0.0604\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 721/1000] Train Loss: 0.0202  |  Val Loss: 0.0601\n",
      "Validation loss improved from 0.0603 to 0.0601.\n",
      "[Epoch 722/1000] Train Loss: 0.0203  |  Val Loss: 0.0602\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 723/1000] Train Loss: 0.0202  |  Val Loss: 0.0607\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 724/1000] Train Loss: 0.0202  |  Val Loss: 0.0611\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 725/1000] Train Loss: 0.0202  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 726/1000] Train Loss: 0.0203  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 727/1000] Train Loss: 0.0201  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 728/1000] Train Loss: 0.0202  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 729/1000] Train Loss: 0.0201  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 730/1000] Train Loss: 0.0201  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 731/1000] Train Loss: 0.0201  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 732/1000] Train Loss: 0.0202  |  Val Loss: 0.0605\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 733/1000] Train Loss: 0.0201  |  Val Loss: 0.0602\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 734/1000] Train Loss: 0.0201  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 735/1000] Train Loss: 0.0200  |  Val Loss: 0.0613\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 736/1000] Train Loss: 0.0199  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 737/1000] Train Loss: 0.0199  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 738/1000] Train Loss: 0.0199  |  Val Loss: 0.0619\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 739/1000] Train Loss: 0.0199  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 740/1000] Train Loss: 0.0200  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 741/1000] Train Loss: 0.0199  |  Val Loss: 0.0632\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 742/1000] Train Loss: 0.0201  |  Val Loss: 0.0634\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 743/1000] Train Loss: 0.0199  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 744/1000] Train Loss: 0.0199  |  Val Loss: 0.0619\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 745/1000] Train Loss: 0.0198  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 746/1000] Train Loss: 0.0198  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 747/1000] Train Loss: 0.0200  |  Val Loss: 0.0613\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 748/1000] Train Loss: 0.0197  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 749/1000] Train Loss: 0.0198  |  Val Loss: 0.0619\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 750/1000] Train Loss: 0.0197  |  Val Loss: 0.0619\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 751/1000] Train Loss: 0.0198  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 752/1000] Train Loss: 0.0198  |  Val Loss: 0.0630\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 753/1000] Train Loss: 0.0196  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 754/1000] Train Loss: 0.0196  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 755/1000] Train Loss: 0.0195  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 756/1000] Train Loss: 0.0197  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 757/1000] Train Loss: 0.0197  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 758/1000] Train Loss: 0.0196  |  Val Loss: 0.0610\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 759/1000] Train Loss: 0.0197  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 760/1000] Train Loss: 0.0195  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 761/1000] Train Loss: 0.0195  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 762/1000] Train Loss: 0.0195  |  Val Loss: 0.0611\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 763/1000] Train Loss: 0.0195  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 764/1000] Train Loss: 0.0194  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 765/1000] Train Loss: 0.0193  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 766/1000] Train Loss: 0.0194  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 767/1000] Train Loss: 0.0195  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 768/1000] Train Loss: 0.0193  |  Val Loss: 0.0618\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 769/1000] Train Loss: 0.0196  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 770/1000] Train Loss: 0.0195  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 771/1000] Train Loss: 0.0192  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 772/1000] Train Loss: 0.0195  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 773/1000] Train Loss: 0.0192  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 774/1000] Train Loss: 0.0193  |  Val Loss: 0.0610\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 775/1000] Train Loss: 0.0193  |  Val Loss: 0.0602\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 776/1000] Train Loss: 0.0194  |  Val Loss: 0.0601\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 777/1000] Train Loss: 0.0194  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 778/1000] Train Loss: 0.0192  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 779/1000] Train Loss: 0.0193  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 780/1000] Train Loss: 0.0191  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 781/1000] Train Loss: 0.0192  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 782/1000] Train Loss: 0.0191  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 783/1000] Train Loss: 0.0191  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 784/1000] Train Loss: 0.0190  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 785/1000] Train Loss: 0.0192  |  Val Loss: 0.0631\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 786/1000] Train Loss: 0.0190  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 787/1000] Train Loss: 0.0191  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 788/1000] Train Loss: 0.0191  |  Val Loss: 0.0615\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 789/1000] Train Loss: 0.0190  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 790/1000] Train Loss: 0.0192  |  Val Loss: 0.0606\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 791/1000] Train Loss: 0.0191  |  Val Loss: 0.0611\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 792/1000] Train Loss: 0.0189  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 793/1000] Train Loss: 0.0190  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 794/1000] Train Loss: 0.0188  |  Val Loss: 0.0616\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 795/1000] Train Loss: 0.0189  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 796/1000] Train Loss: 0.0189  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 797/1000] Train Loss: 0.0190  |  Val Loss: 0.0622\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 798/1000] Train Loss: 0.0188  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 799/1000] Train Loss: 0.0189  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 800/1000] Train Loss: 0.0188  |  Val Loss: 0.0626\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 801/1000] Train Loss: 0.0188  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 802/1000] Train Loss: 0.0187  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 803/1000] Train Loss: 0.0187  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 804/1000] Train Loss: 0.0189  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 805/1000] Train Loss: 0.0190  |  Val Loss: 0.0620\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 806/1000] Train Loss: 0.0187  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 807/1000] Train Loss: 0.0189  |  Val Loss: 0.0631\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 808/1000] Train Loss: 0.0188  |  Val Loss: 0.0623\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 809/1000] Train Loss: 0.0188  |  Val Loss: 0.0627\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 810/1000] Train Loss: 0.0187  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 811/1000] Train Loss: 0.0188  |  Val Loss: 0.0624\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 812/1000] Train Loss: 0.0187  |  Val Loss: 0.0625\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 813/1000] Train Loss: 0.0186  |  Val Loss: 0.0617\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 814/1000] Train Loss: 0.0186  |  Val Loss: 0.0613\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 815/1000] Train Loss: 0.0187  |  Val Loss: 0.0614\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 816/1000] Train Loss: 0.0188  |  Val Loss: 0.0607\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 817/1000] Train Loss: 0.0186  |  Val Loss: 0.0610\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 818/1000] Train Loss: 0.0185  |  Val Loss: 0.0609\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 819/1000] Train Loss: 0.0185  |  Val Loss: 0.0612\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 820/1000] Train Loss: 0.0184  |  Val Loss: 0.0621\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 821/1000] Train Loss: 0.0186  |  Val Loss: 0.0629\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 821 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:13.800025Z",
     "iopub.status.busy": "2025-05-08T17:30:13.800025Z",
     "iopub.status.idle": "2025-05-08T17:30:15.976075Z",
     "shell.execute_reply": "2025-05-08T17:30:15.976075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.2196 | Test Accuracy: 95.41%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:15.979081Z",
     "iopub.status.busy": "2025-05-08T17:30:15.978080Z",
     "iopub.status.idle": "2025-05-08T17:30:16.143122Z",
     "shell.execute_reply": "2025-05-08T17:30:16.143122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 180 samples with 64 features each\n",
      "LOG: Labels shape: (180,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 45 samples with 64 features each\n",
      "LOG: Labels shape: (45,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loaded 147927 samples with 64 features each\n",
      "LOG: Labels shape: (147927,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (180, 64), \n",
      "Train labels shape: (180,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (45, 64), \n",
      "Val labels shape: (45,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (147927, 64), \n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:16.145125Z",
     "iopub.status.busy": "2025-05-08T17:30:16.145125Z",
     "iopub.status.idle": "2025-05-08T17:30:16.159131Z",
     "shell.execute_reply": "2025-05-08T17:30:16.159131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n",
      "Training batch size: 180\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:16.162136Z",
     "iopub.status.busy": "2025-05-08T17:30:16.161137Z",
     "iopub.status.idle": "2025-05-08T17:30:16.165355Z",
     "shell.execute_reply": "2025-05-08T17:30:16.165355Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:16.168364Z",
     "iopub.status.busy": "2025-05-08T17:30:16.168364Z",
     "iopub.status.idle": "2025-05-08T17:30:16.174446Z",
     "shell.execute_reply": "2025-05-08T17:30:16.174446Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:30:16.176449Z",
     "iopub.status.busy": "2025-05-08T17:30:16.176449Z",
     "iopub.status.idle": "2025-05-08T17:32:01.374222Z",
     "shell.execute_reply": "2025-05-08T17:32:01.374222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4444\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3578\n",
      "Epoch [1/2000], Avg Train Loss: 0.4444, Avg Val Loss: 0.3578\n",
      "\n",
      "Validation loss improved from inf to 0.3578. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4431\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3577\n",
      "Epoch [2/2000], Avg Train Loss: 0.4431, Avg Val Loss: 0.3577\n",
      "\n",
      "Validation loss improved from 0.3578 to 0.3577. Saving model...\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4396\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3579\n",
      "Epoch [3/2000], Avg Train Loss: 0.4396, Avg Val Loss: 0.3579\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4321\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3583\n",
      "Epoch [4/2000], Avg Train Loss: 0.4321, Avg Val Loss: 0.3583\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4326\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3587\n",
      "Epoch [5/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.3587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4383\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3586\n",
      "Epoch [6/2000], Avg Train Loss: 0.4383, Avg Val Loss: 0.3586\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4309\n",
      "LOG: Epoch [7/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3587\n",
      "Epoch [7/2000], Avg Train Loss: 0.4309, Avg Val Loss: 0.3587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4294\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3582\n",
      "Epoch [8/2000], Avg Train Loss: 0.4294, Avg Val Loss: 0.3582\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4274\n",
      "LOG: Epoch [9/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3573\n",
      "Epoch [9/2000], Avg Train Loss: 0.4274, Avg Val Loss: 0.3573\n",
      "\n",
      "Validation loss improved from 0.3577 to 0.3573. Saving model...\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4357\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3560\n",
      "Epoch [10/2000], Avg Train Loss: 0.4357, Avg Val Loss: 0.3560\n",
      "\n",
      "Validation loss improved from 0.3573 to 0.3560. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [11/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3546\n",
      "Epoch [11/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.3546\n",
      "\n",
      "Validation loss improved from 0.3560 to 0.3546. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3532\n",
      "Epoch [12/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.3532\n",
      "\n",
      "Validation loss improved from 0.3546 to 0.3532. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [13/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3520\n",
      "Epoch [13/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.3520\n",
      "\n",
      "Validation loss improved from 0.3532 to 0.3520. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3509\n",
      "Epoch [14/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.3509\n",
      "\n",
      "Validation loss improved from 0.3520 to 0.3509. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3498\n",
      "Epoch [15/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.3498\n",
      "\n",
      "Validation loss improved from 0.3509 to 0.3498. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3486\n",
      "Epoch [16/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.3486\n",
      "\n",
      "Validation loss improved from 0.3498 to 0.3486. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3477\n",
      "Epoch [17/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.3477\n",
      "\n",
      "Validation loss improved from 0.3486 to 0.3477. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3469\n",
      "Epoch [18/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.3469\n",
      "\n",
      "Validation loss improved from 0.3477 to 0.3469. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4201\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3458\n",
      "Epoch [19/2000], Avg Train Loss: 0.4201, Avg Val Loss: 0.3458\n",
      "\n",
      "Validation loss improved from 0.3469 to 0.3458. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4170\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3447\n",
      "Epoch [20/2000], Avg Train Loss: 0.4170, Avg Val Loss: 0.3447\n",
      "\n",
      "Validation loss improved from 0.3458 to 0.3447. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3435\n",
      "Epoch [21/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.3435\n",
      "\n",
      "Validation loss improved from 0.3447 to 0.3435. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3423\n",
      "Epoch [22/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.3423\n",
      "\n",
      "Validation loss improved from 0.3435 to 0.3423. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3410\n",
      "Epoch [23/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.3410\n",
      "\n",
      "Validation loss improved from 0.3423 to 0.3410. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4154\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3397\n",
      "Epoch [24/2000], Avg Train Loss: 0.4154, Avg Val Loss: 0.3397\n",
      "\n",
      "Validation loss improved from 0.3410 to 0.3397. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [25/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3383\n",
      "Epoch [25/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.3383\n",
      "\n",
      "Validation loss improved from 0.3397 to 0.3383. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3370\n",
      "Epoch [26/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.3370\n",
      "\n",
      "Validation loss improved from 0.3383 to 0.3370. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [27/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3358\n",
      "Epoch [27/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.3358\n",
      "\n",
      "Validation loss improved from 0.3370 to 0.3358. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3345\n",
      "Epoch [28/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.3345\n",
      "\n",
      "Validation loss improved from 0.3358 to 0.3345. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [29/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3333\n",
      "Epoch [29/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.3333\n",
      "\n",
      "Validation loss improved from 0.3345 to 0.3333. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3321\n",
      "Epoch [30/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.3321\n",
      "\n",
      "Validation loss improved from 0.3333 to 0.3321. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3309\n",
      "Epoch [31/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.3309\n",
      "\n",
      "Validation loss improved from 0.3321 to 0.3309. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3297\n",
      "Epoch [32/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.3297\n",
      "\n",
      "Validation loss improved from 0.3309 to 0.3297. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3286\n",
      "Epoch [33/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.3286\n",
      "\n",
      "Validation loss improved from 0.3297 to 0.3286. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3275\n",
      "Epoch [34/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.3275\n",
      "\n",
      "Validation loss improved from 0.3286 to 0.3275. Saving model...\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3263\n",
      "Epoch [35/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.3263\n",
      "\n",
      "Validation loss improved from 0.3275 to 0.3263. Saving model...\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3251\n",
      "Epoch [36/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.3251\n",
      "\n",
      "Validation loss improved from 0.3263 to 0.3251. Saving model...\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3240\n",
      "Epoch [37/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.3240\n",
      "\n",
      "Validation loss improved from 0.3251 to 0.3240. Saving model...\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3228\n",
      "Epoch [38/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.3228\n",
      "\n",
      "Validation loss improved from 0.3240 to 0.3228. Saving model...\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3979\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3216\n",
      "Epoch [39/2000], Avg Train Loss: 0.3979, Avg Val Loss: 0.3216\n",
      "\n",
      "Validation loss improved from 0.3228 to 0.3216. Saving model...\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [40/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3205\n",
      "Epoch [40/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.3205\n",
      "\n",
      "Validation loss improved from 0.3216 to 0.3205. Saving model...\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3193\n",
      "Epoch [41/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.3193\n",
      "\n",
      "Validation loss improved from 0.3205 to 0.3193. Saving model...\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [42/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3181\n",
      "Epoch [42/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.3181\n",
      "\n",
      "Validation loss improved from 0.3193 to 0.3181. Saving model...\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3169\n",
      "Epoch [43/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.3169\n",
      "\n",
      "Validation loss improved from 0.3181 to 0.3169. Saving model...\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [44/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3157\n",
      "Epoch [44/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.3157\n",
      "\n",
      "Validation loss improved from 0.3169 to 0.3157. Saving model...\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3145\n",
      "Epoch [45/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.3145\n",
      "\n",
      "Validation loss improved from 0.3157 to 0.3145. Saving model...\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [46/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3134\n",
      "Epoch [46/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.3134\n",
      "\n",
      "Validation loss improved from 0.3145 to 0.3134. Saving model...\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3122\n",
      "Epoch [47/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.3122\n",
      "\n",
      "Validation loss improved from 0.3134 to 0.3122. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [48/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3110\n",
      "Epoch [48/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.3110\n",
      "\n",
      "Validation loss improved from 0.3122 to 0.3110. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3099\n",
      "Epoch [49/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.3099\n",
      "\n",
      "Validation loss improved from 0.3110 to 0.3099. Saving model...\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3087\n",
      "Epoch [50/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.3087\n",
      "\n",
      "Validation loss improved from 0.3099 to 0.3087. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3854\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3076\n",
      "Epoch [51/2000], Avg Train Loss: 0.3854, Avg Val Loss: 0.3076\n",
      "\n",
      "Validation loss improved from 0.3087 to 0.3076. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3065\n",
      "Epoch [52/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.3065\n",
      "\n",
      "Validation loss improved from 0.3076 to 0.3065. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3832\n",
      "LOG: Epoch [53/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3054\n",
      "Epoch [53/2000], Avg Train Loss: 0.3832, Avg Val Loss: 0.3054\n",
      "\n",
      "Validation loss improved from 0.3065 to 0.3054. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3854\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3043\n",
      "Epoch [54/2000], Avg Train Loss: 0.3854, Avg Val Loss: 0.3043\n",
      "\n",
      "Validation loss improved from 0.3054 to 0.3043. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3778\n",
      "LOG: Epoch [55/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3032\n",
      "Epoch [55/2000], Avg Train Loss: 0.3778, Avg Val Loss: 0.3032\n",
      "\n",
      "Validation loss improved from 0.3043 to 0.3032. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3861\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.3020\n",
      "Epoch [56/2000], Avg Train Loss: 0.3861, Avg Val Loss: 0.3020\n",
      "\n",
      "Validation loss improved from 0.3032 to 0.3020. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3840\n",
      "LOG: Epoch [57/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.3009\n",
      "Epoch [57/2000], Avg Train Loss: 0.3840, Avg Val Loss: 0.3009\n",
      "\n",
      "Validation loss improved from 0.3020 to 0.3009. Saving model...\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2998\n",
      "Epoch [58/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2998\n",
      "\n",
      "Validation loss improved from 0.3009 to 0.2998. Saving model...\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3779\n",
      "LOG: Epoch [59/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2988\n",
      "Epoch [59/2000], Avg Train Loss: 0.3779, Avg Val Loss: 0.2988\n",
      "\n",
      "Validation loss improved from 0.2998 to 0.2988. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3825\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2977\n",
      "Epoch [60/2000], Avg Train Loss: 0.3825, Avg Val Loss: 0.2977\n",
      "\n",
      "Validation loss improved from 0.2988 to 0.2977. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3733\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2966\n",
      "Epoch [61/2000], Avg Train Loss: 0.3733, Avg Val Loss: 0.2966\n",
      "\n",
      "Validation loss improved from 0.2977 to 0.2966. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3762\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2955\n",
      "Epoch [62/2000], Avg Train Loss: 0.3762, Avg Val Loss: 0.2955\n",
      "\n",
      "Validation loss improved from 0.2966 to 0.2955. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3797\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2944\n",
      "Epoch [63/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2944\n",
      "\n",
      "Validation loss improved from 0.2955 to 0.2944. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3743\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2933\n",
      "Epoch [64/2000], Avg Train Loss: 0.3743, Avg Val Loss: 0.2933\n",
      "\n",
      "Validation loss improved from 0.2944 to 0.2933. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3702\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2922\n",
      "Epoch [65/2000], Avg Train Loss: 0.3702, Avg Val Loss: 0.2922\n",
      "\n",
      "Validation loss improved from 0.2933 to 0.2922. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3727\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2911\n",
      "Epoch [66/2000], Avg Train Loss: 0.3727, Avg Val Loss: 0.2911\n",
      "\n",
      "Validation loss improved from 0.2922 to 0.2911. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3728\n",
      "LOG: Epoch [67/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2900\n",
      "Epoch [67/2000], Avg Train Loss: 0.3728, Avg Val Loss: 0.2900\n",
      "\n",
      "Validation loss improved from 0.2911 to 0.2900. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3749\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2889\n",
      "Epoch [68/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2889\n",
      "\n",
      "Validation loss improved from 0.2900 to 0.2889. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3734\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2878\n",
      "Epoch [69/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2878\n",
      "\n",
      "Validation loss improved from 0.2889 to 0.2878. Saving model...\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3638\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2867\n",
      "Epoch [70/2000], Avg Train Loss: 0.3638, Avg Val Loss: 0.2867\n",
      "\n",
      "Validation loss improved from 0.2878 to 0.2867. Saving model...\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3704\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2857\n",
      "Epoch [71/2000], Avg Train Loss: 0.3704, Avg Val Loss: 0.2857\n",
      "\n",
      "Validation loss improved from 0.2867 to 0.2857. Saving model...\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3725\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2847\n",
      "Epoch [72/2000], Avg Train Loss: 0.3725, Avg Val Loss: 0.2847\n",
      "\n",
      "Validation loss improved from 0.2857 to 0.2847. Saving model...\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3651\n",
      "LOG: Epoch [73/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2836\n",
      "Epoch [73/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2836\n",
      "\n",
      "Validation loss improved from 0.2847 to 0.2836. Saving model...\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3651\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2826\n",
      "Epoch [74/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2826\n",
      "\n",
      "Validation loss improved from 0.2836 to 0.2826. Saving model...\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3594\n",
      "LOG: Epoch [75/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2816\n",
      "Epoch [75/2000], Avg Train Loss: 0.3594, Avg Val Loss: 0.2816\n",
      "\n",
      "Validation loss improved from 0.2826 to 0.2816. Saving model...\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3597\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2806\n",
      "Epoch [76/2000], Avg Train Loss: 0.3597, Avg Val Loss: 0.2806\n",
      "\n",
      "Validation loss improved from 0.2816 to 0.2806. Saving model...\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3650\n",
      "LOG: Epoch [77/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2797\n",
      "Epoch [77/2000], Avg Train Loss: 0.3650, Avg Val Loss: 0.2797\n",
      "\n",
      "Validation loss improved from 0.2806 to 0.2797. Saving model...\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3617\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2787\n",
      "Epoch [78/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.2787\n",
      "\n",
      "Validation loss improved from 0.2797 to 0.2787. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3632\n",
      "LOG: Epoch [79/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2778\n",
      "Epoch [79/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2787 to 0.2778. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3624\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2768\n",
      "Epoch [80/2000], Avg Train Loss: 0.3624, Avg Val Loss: 0.2768\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2768. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3609\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2759\n",
      "Epoch [81/2000], Avg Train Loss: 0.3609, Avg Val Loss: 0.2759\n",
      "\n",
      "Validation loss improved from 0.2768 to 0.2759. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3596\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2750\n",
      "Epoch [82/2000], Avg Train Loss: 0.3596, Avg Val Loss: 0.2750\n",
      "\n",
      "Validation loss improved from 0.2759 to 0.2750. Saving model...\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3577\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2740\n",
      "Epoch [83/2000], Avg Train Loss: 0.3577, Avg Val Loss: 0.2740\n",
      "\n",
      "Validation loss improved from 0.2750 to 0.2740. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3557\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2731\n",
      "Epoch [84/2000], Avg Train Loss: 0.3557, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2740 to 0.2731. Saving model...\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2722\n",
      "Epoch [85/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2722\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2722. Saving model...\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3549\n",
      "LOG: Epoch [86/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2713\n",
      "Epoch [86/2000], Avg Train Loss: 0.3549, Avg Val Loss: 0.2713\n",
      "\n",
      "Validation loss improved from 0.2722 to 0.2713. Saving model...\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2703\n",
      "Epoch [87/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2703\n",
      "\n",
      "Validation loss improved from 0.2713 to 0.2703. Saving model...\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [88/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2694\n",
      "Epoch [88/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2694\n",
      "\n",
      "Validation loss improved from 0.2703 to 0.2694. Saving model...\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2685\n",
      "Epoch [89/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2685\n",
      "\n",
      "Validation loss improved from 0.2694 to 0.2685. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [90/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2676\n",
      "Epoch [90/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2676\n",
      "\n",
      "Validation loss improved from 0.2685 to 0.2676. Saving model...\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2666\n",
      "Epoch [91/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2676 to 0.2666. Saving model...\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [92/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2657\n",
      "Epoch [92/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2657\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2657. Saving model...\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2649\n",
      "Epoch [93/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2649\n",
      "\n",
      "Validation loss improved from 0.2657 to 0.2649. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [94/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2640\n",
      "Epoch [94/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2640\n",
      "\n",
      "Validation loss improved from 0.2649 to 0.2640. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2632\n",
      "Epoch [95/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2640 to 0.2632. Saving model...\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [96/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2623\n",
      "Epoch [96/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2623. Saving model...\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3377\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2615\n",
      "Epoch [97/2000], Avg Train Loss: 0.3377, Avg Val Loss: 0.2615\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2615. Saving model...\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [98/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2607\n",
      "Epoch [98/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2607\n",
      "\n",
      "Validation loss improved from 0.2615 to 0.2607. Saving model...\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2599\n",
      "Epoch [99/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2599\n",
      "\n",
      "Validation loss improved from 0.2607 to 0.2599. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3390\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2591\n",
      "Epoch [100/2000], Avg Train Loss: 0.3390, Avg Val Loss: 0.2591\n",
      "\n",
      "Validation loss improved from 0.2599 to 0.2591. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2584\n",
      "Epoch [101/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2591 to 0.2584. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2576\n",
      "Epoch [102/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2576. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [103/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2568\n",
      "Epoch [103/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2568. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3381\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2561\n",
      "Epoch [104/2000], Avg Train Loss: 0.3381, Avg Val Loss: 0.2561\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2561. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3389\n",
      "LOG: Epoch [105/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2553\n",
      "Epoch [105/2000], Avg Train Loss: 0.3389, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2561 to 0.2553. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3335\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2546\n",
      "Epoch [106/2000], Avg Train Loss: 0.3335, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2546. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3379\n",
      "LOG: Epoch [107/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2538\n",
      "Epoch [107/2000], Avg Train Loss: 0.3379, Avg Val Loss: 0.2538\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2538. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3334\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2531\n",
      "Epoch [108/2000], Avg Train Loss: 0.3334, Avg Val Loss: 0.2531\n",
      "\n",
      "Validation loss improved from 0.2538 to 0.2531. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3301\n",
      "LOG: Epoch [109/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2524\n",
      "Epoch [109/2000], Avg Train Loss: 0.3301, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2531 to 0.2524. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3230\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2517\n",
      "Epoch [110/2000], Avg Train Loss: 0.3230, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2517. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3330\n",
      "LOG: Epoch [111/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2509\n",
      "Epoch [111/2000], Avg Train Loss: 0.3330, Avg Val Loss: 0.2509\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2509. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3320\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2502\n",
      "Epoch [112/2000], Avg Train Loss: 0.3320, Avg Val Loss: 0.2502\n",
      "\n",
      "Validation loss improved from 0.2509 to 0.2502. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3346\n",
      "LOG: Epoch [113/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2495\n",
      "Epoch [113/2000], Avg Train Loss: 0.3346, Avg Val Loss: 0.2495\n",
      "\n",
      "Validation loss improved from 0.2502 to 0.2495. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3318\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2488\n",
      "Epoch [114/2000], Avg Train Loss: 0.3318, Avg Val Loss: 0.2488\n",
      "\n",
      "Validation loss improved from 0.2495 to 0.2488. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3314\n",
      "LOG: Epoch [115/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2481\n",
      "Epoch [115/2000], Avg Train Loss: 0.3314, Avg Val Loss: 0.2481\n",
      "\n",
      "Validation loss improved from 0.2488 to 0.2481. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3254\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2474\n",
      "Epoch [116/2000], Avg Train Loss: 0.3254, Avg Val Loss: 0.2474\n",
      "\n",
      "Validation loss improved from 0.2481 to 0.2474. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3258\n",
      "LOG: Epoch [117/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2467\n",
      "Epoch [117/2000], Avg Train Loss: 0.3258, Avg Val Loss: 0.2467\n",
      "\n",
      "Validation loss improved from 0.2474 to 0.2467. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3251\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2460\n",
      "Epoch [118/2000], Avg Train Loss: 0.3251, Avg Val Loss: 0.2460\n",
      "\n",
      "Validation loss improved from 0.2467 to 0.2460. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3316\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2453\n",
      "Epoch [119/2000], Avg Train Loss: 0.3316, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2460 to 0.2453. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3301\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2446\n",
      "Epoch [120/2000], Avg Train Loss: 0.3301, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2446. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3299\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2440\n",
      "Epoch [121/2000], Avg Train Loss: 0.3299, Avg Val Loss: 0.2440\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2440. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3260\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2433\n",
      "Epoch [122/2000], Avg Train Loss: 0.3260, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2440 to 0.2433. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3242\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2426\n",
      "Epoch [123/2000], Avg Train Loss: 0.3242, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2426. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3220\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2419\n",
      "Epoch [124/2000], Avg Train Loss: 0.3220, Avg Val Loss: 0.2419\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2419. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3205\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2412\n",
      "Epoch [125/2000], Avg Train Loss: 0.3205, Avg Val Loss: 0.2412\n",
      "\n",
      "Validation loss improved from 0.2419 to 0.2412. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3226\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2405\n",
      "Epoch [126/2000], Avg Train Loss: 0.3226, Avg Val Loss: 0.2405\n",
      "\n",
      "Validation loss improved from 0.2412 to 0.2405. Saving model...\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3181\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2398\n",
      "Epoch [127/2000], Avg Train Loss: 0.3181, Avg Val Loss: 0.2398\n",
      "\n",
      "Validation loss improved from 0.2405 to 0.2398. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3255\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2391\n",
      "Epoch [128/2000], Avg Train Loss: 0.3255, Avg Val Loss: 0.2391\n",
      "\n",
      "Validation loss improved from 0.2398 to 0.2391. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3231\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2385\n",
      "Epoch [129/2000], Avg Train Loss: 0.3231, Avg Val Loss: 0.2385\n",
      "\n",
      "Validation loss improved from 0.2391 to 0.2385. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3166\n",
      "LOG: Epoch [130/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2378\n",
      "Epoch [130/2000], Avg Train Loss: 0.3166, Avg Val Loss: 0.2378\n",
      "\n",
      "Validation loss improved from 0.2385 to 0.2378. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3102\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2371\n",
      "Epoch [131/2000], Avg Train Loss: 0.3102, Avg Val Loss: 0.2371\n",
      "\n",
      "Validation loss improved from 0.2378 to 0.2371. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3174\n",
      "LOG: Epoch [132/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2365\n",
      "Epoch [132/2000], Avg Train Loss: 0.3174, Avg Val Loss: 0.2365\n",
      "\n",
      "Validation loss improved from 0.2371 to 0.2365. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3160\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2358\n",
      "Epoch [133/2000], Avg Train Loss: 0.3160, Avg Val Loss: 0.2358\n",
      "\n",
      "Validation loss improved from 0.2365 to 0.2358. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3145\n",
      "LOG: Epoch [134/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2352\n",
      "Epoch [134/2000], Avg Train Loss: 0.3145, Avg Val Loss: 0.2352\n",
      "\n",
      "Validation loss improved from 0.2358 to 0.2352. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3170\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2346\n",
      "Epoch [135/2000], Avg Train Loss: 0.3170, Avg Val Loss: 0.2346\n",
      "\n",
      "Validation loss improved from 0.2352 to 0.2346. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3172\n",
      "LOG: Epoch [136/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2339\n",
      "Epoch [136/2000], Avg Train Loss: 0.3172, Avg Val Loss: 0.2339\n",
      "\n",
      "Validation loss improved from 0.2346 to 0.2339. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3124\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2333\n",
      "Epoch [137/2000], Avg Train Loss: 0.3124, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2339 to 0.2333. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3060\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2326\n",
      "Epoch [138/2000], Avg Train Loss: 0.3060, Avg Val Loss: 0.2326\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2326. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3128\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2320\n",
      "Epoch [139/2000], Avg Train Loss: 0.3128, Avg Val Loss: 0.2320\n",
      "\n",
      "Validation loss improved from 0.2326 to 0.2320. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3137\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2314\n",
      "Epoch [140/2000], Avg Train Loss: 0.3137, Avg Val Loss: 0.2314\n",
      "\n",
      "Validation loss improved from 0.2320 to 0.2314. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3037\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2308\n",
      "Epoch [141/2000], Avg Train Loss: 0.3037, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2314 to 0.2308. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3072\n",
      "LOG: Epoch [142/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2302\n",
      "Epoch [142/2000], Avg Train Loss: 0.3072, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2302. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3055\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2296\n",
      "Epoch [143/2000], Avg Train Loss: 0.3055, Avg Val Loss: 0.2296\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2296. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3042\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2290\n",
      "Epoch [144/2000], Avg Train Loss: 0.3042, Avg Val Loss: 0.2290\n",
      "\n",
      "Validation loss improved from 0.2296 to 0.2290. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2991\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2284\n",
      "Epoch [145/2000], Avg Train Loss: 0.2991, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2290 to 0.2284. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3038\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2278\n",
      "Epoch [146/2000], Avg Train Loss: 0.3038, Avg Val Loss: 0.2278\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2278. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3056\n",
      "LOG: Epoch [147/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2272\n",
      "Epoch [147/2000], Avg Train Loss: 0.3056, Avg Val Loss: 0.2272\n",
      "\n",
      "Validation loss improved from 0.2278 to 0.2272. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3038\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2266\n",
      "Epoch [148/2000], Avg Train Loss: 0.3038, Avg Val Loss: 0.2266\n",
      "\n",
      "Validation loss improved from 0.2272 to 0.2266. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3008\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2260\n",
      "Epoch [149/2000], Avg Train Loss: 0.3008, Avg Val Loss: 0.2260\n",
      "\n",
      "Validation loss improved from 0.2266 to 0.2260. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3044\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2255\n",
      "Epoch [150/2000], Avg Train Loss: 0.3044, Avg Val Loss: 0.2255\n",
      "\n",
      "Validation loss improved from 0.2260 to 0.2255. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3000\n",
      "LOG: Epoch [151/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2249\n",
      "Epoch [151/2000], Avg Train Loss: 0.3000, Avg Val Loss: 0.2249\n",
      "\n",
      "Validation loss improved from 0.2255 to 0.2249. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3012\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2243\n",
      "Epoch [152/2000], Avg Train Loss: 0.3012, Avg Val Loss: 0.2243\n",
      "\n",
      "Validation loss improved from 0.2249 to 0.2243. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3007\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2237\n",
      "Epoch [153/2000], Avg Train Loss: 0.3007, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2243 to 0.2237. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3046\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2232\n",
      "Epoch [154/2000], Avg Train Loss: 0.3046, Avg Val Loss: 0.2232\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2232. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.3020\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2227\n",
      "Epoch [155/2000], Avg Train Loss: 0.3020, Avg Val Loss: 0.2227\n",
      "\n",
      "Validation loss improved from 0.2232 to 0.2227. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2967\n",
      "LOG: Epoch [156/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2221\n",
      "Epoch [156/2000], Avg Train Loss: 0.2967, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2227 to 0.2221. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2948\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2216\n",
      "Epoch [157/2000], Avg Train Loss: 0.2948, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2216. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2963\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2210\n",
      "Epoch [158/2000], Avg Train Loss: 0.2963, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2210. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2993\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2205\n",
      "Epoch [159/2000], Avg Train Loss: 0.2993, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2205. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2990\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2200\n",
      "Epoch [160/2000], Avg Train Loss: 0.2990, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2200. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2948\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2195\n",
      "Epoch [161/2000], Avg Train Loss: 0.2948, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2195. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2937\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2190\n",
      "Epoch [162/2000], Avg Train Loss: 0.2937, Avg Val Loss: 0.2190\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2190. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2934\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2185\n",
      "Epoch [163/2000], Avg Train Loss: 0.2934, Avg Val Loss: 0.2185\n",
      "\n",
      "Validation loss improved from 0.2190 to 0.2185. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2939\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2180\n",
      "Epoch [164/2000], Avg Train Loss: 0.2939, Avg Val Loss: 0.2180\n",
      "\n",
      "Validation loss improved from 0.2185 to 0.2180. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [165/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2176\n",
      "Epoch [165/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2176\n",
      "\n",
      "Validation loss improved from 0.2180 to 0.2176. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2888\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2171\n",
      "Epoch [166/2000], Avg Train Loss: 0.2888, Avg Val Loss: 0.2171\n",
      "\n",
      "Validation loss improved from 0.2176 to 0.2171. Saving model...\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2965\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2166\n",
      "Epoch [167/2000], Avg Train Loss: 0.2965, Avg Val Loss: 0.2166\n",
      "\n",
      "Validation loss improved from 0.2171 to 0.2166. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2895\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2162\n",
      "Epoch [168/2000], Avg Train Loss: 0.2895, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2166 to 0.2162. Saving model...\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2910\n",
      "LOG: Epoch [169/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2157\n",
      "Epoch [169/2000], Avg Train Loss: 0.2910, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2157. Saving model...\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2917\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2153\n",
      "Epoch [170/2000], Avg Train Loss: 0.2917, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2153. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2924\n",
      "LOG: Epoch [171/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2148\n",
      "Epoch [171/2000], Avg Train Loss: 0.2924, Avg Val Loss: 0.2148\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2148. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2900\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2144\n",
      "Epoch [172/2000], Avg Train Loss: 0.2900, Avg Val Loss: 0.2144\n",
      "\n",
      "Validation loss improved from 0.2148 to 0.2144. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2139\n",
      "Epoch [173/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2139\n",
      "\n",
      "Validation loss improved from 0.2144 to 0.2139. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2865\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2134\n",
      "Epoch [174/2000], Avg Train Loss: 0.2865, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2139 to 0.2134. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2865\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2130\n",
      "Epoch [175/2000], Avg Train Loss: 0.2865, Avg Val Loss: 0.2130\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2130. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2854\n",
      "LOG: Epoch [176/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2125\n",
      "Epoch [176/2000], Avg Train Loss: 0.2854, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2130 to 0.2125. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2120\n",
      "Epoch [177/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2120\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2120. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2840\n",
      "LOG: Epoch [178/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2115\n",
      "Epoch [178/2000], Avg Train Loss: 0.2840, Avg Val Loss: 0.2115\n",
      "\n",
      "Validation loss improved from 0.2120 to 0.2115. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2110\n",
      "Epoch [179/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2110\n",
      "\n",
      "Validation loss improved from 0.2115 to 0.2110. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [180/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2106\n",
      "Epoch [180/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2106\n",
      "\n",
      "Validation loss improved from 0.2110 to 0.2106. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2100\n",
      "Epoch [181/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2100\n",
      "\n",
      "Validation loss improved from 0.2106 to 0.2100. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2849\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2096\n",
      "Epoch [182/2000], Avg Train Loss: 0.2849, Avg Val Loss: 0.2096\n",
      "\n",
      "Validation loss improved from 0.2100 to 0.2096. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2091\n",
      "Epoch [183/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2096 to 0.2091. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2732\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2086\n",
      "Epoch [184/2000], Avg Train Loss: 0.2732, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2086. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [185/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2082\n",
      "Epoch [185/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2082\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2082. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2077\n",
      "Epoch [186/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2077\n",
      "\n",
      "Validation loss improved from 0.2082 to 0.2077. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2073\n",
      "Epoch [187/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2073\n",
      "\n",
      "Validation loss improved from 0.2077 to 0.2073. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2068\n",
      "Epoch [188/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2068\n",
      "\n",
      "Validation loss improved from 0.2073 to 0.2068. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2064\n",
      "Epoch [189/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2064\n",
      "\n",
      "Validation loss improved from 0.2068 to 0.2064. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2060\n",
      "Epoch [190/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2060\n",
      "\n",
      "Validation loss improved from 0.2064 to 0.2060. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2738\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2056\n",
      "Epoch [191/2000], Avg Train Loss: 0.2738, Avg Val Loss: 0.2056\n",
      "\n",
      "Validation loss improved from 0.2060 to 0.2056. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [192/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2051\n",
      "Epoch [192/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2051\n",
      "\n",
      "Validation loss improved from 0.2056 to 0.2051. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2734\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2047\n",
      "Epoch [193/2000], Avg Train Loss: 0.2734, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2051 to 0.2047. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2742\n",
      "LOG: Epoch [194/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2043\n",
      "Epoch [194/2000], Avg Train Loss: 0.2742, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2043. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2718\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2039\n",
      "Epoch [195/2000], Avg Train Loss: 0.2718, Avg Val Loss: 0.2039\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2039. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2642\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2035\n",
      "Epoch [196/2000], Avg Train Loss: 0.2642, Avg Val Loss: 0.2035\n",
      "\n",
      "Validation loss improved from 0.2039 to 0.2035. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2667\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2031\n",
      "Epoch [197/2000], Avg Train Loss: 0.2667, Avg Val Loss: 0.2031\n",
      "\n",
      "Validation loss improved from 0.2035 to 0.2031. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2691\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2027\n",
      "Epoch [198/2000], Avg Train Loss: 0.2691, Avg Val Loss: 0.2027\n",
      "\n",
      "Validation loss improved from 0.2031 to 0.2027. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2685\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2023\n",
      "Epoch [199/2000], Avg Train Loss: 0.2685, Avg Val Loss: 0.2023\n",
      "\n",
      "Validation loss improved from 0.2027 to 0.2023. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2683\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2019\n",
      "Epoch [200/2000], Avg Train Loss: 0.2683, Avg Val Loss: 0.2019\n",
      "\n",
      "Validation loss improved from 0.2023 to 0.2019. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2656\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2015\n",
      "Epoch [201/2000], Avg Train Loss: 0.2656, Avg Val Loss: 0.2015\n",
      "\n",
      "Validation loss improved from 0.2019 to 0.2015. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2699\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2011\n",
      "Epoch [202/2000], Avg Train Loss: 0.2699, Avg Val Loss: 0.2011\n",
      "\n",
      "Validation loss improved from 0.2015 to 0.2011. Saving model...\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2702\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.2006\n",
      "Epoch [203/2000], Avg Train Loss: 0.2702, Avg Val Loss: 0.2006\n",
      "\n",
      "Validation loss improved from 0.2011 to 0.2006. Saving model...\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2651\n",
      "LOG: Epoch [204/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.2002\n",
      "Epoch [204/2000], Avg Train Loss: 0.2651, Avg Val Loss: 0.2002\n",
      "\n",
      "Validation loss improved from 0.2006 to 0.2002. Saving model...\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2655\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1998\n",
      "Epoch [205/2000], Avg Train Loss: 0.2655, Avg Val Loss: 0.1998\n",
      "\n",
      "Validation loss improved from 0.2002 to 0.1998. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2635\n",
      "LOG: Epoch [206/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1994\n",
      "Epoch [206/2000], Avg Train Loss: 0.2635, Avg Val Loss: 0.1994\n",
      "\n",
      "Validation loss improved from 0.1998 to 0.1994. Saving model...\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2600\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1990\n",
      "Epoch [207/2000], Avg Train Loss: 0.2600, Avg Val Loss: 0.1990\n",
      "\n",
      "Validation loss improved from 0.1994 to 0.1990. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2702\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1986\n",
      "Epoch [208/2000], Avg Train Loss: 0.2702, Avg Val Loss: 0.1986\n",
      "\n",
      "Validation loss improved from 0.1990 to 0.1986. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2611\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1982\n",
      "Epoch [209/2000], Avg Train Loss: 0.2611, Avg Val Loss: 0.1982\n",
      "\n",
      "Validation loss improved from 0.1986 to 0.1982. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2622\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1978\n",
      "Epoch [210/2000], Avg Train Loss: 0.2622, Avg Val Loss: 0.1978\n",
      "\n",
      "Validation loss improved from 0.1982 to 0.1978. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2672\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1974\n",
      "Epoch [211/2000], Avg Train Loss: 0.2672, Avg Val Loss: 0.1974\n",
      "\n",
      "Validation loss improved from 0.1978 to 0.1974. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2639\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1970\n",
      "Epoch [212/2000], Avg Train Loss: 0.2639, Avg Val Loss: 0.1970\n",
      "\n",
      "Validation loss improved from 0.1974 to 0.1970. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2666\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1967\n",
      "Epoch [213/2000], Avg Train Loss: 0.2666, Avg Val Loss: 0.1967\n",
      "\n",
      "Validation loss improved from 0.1970 to 0.1967. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2663\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1963\n",
      "Epoch [214/2000], Avg Train Loss: 0.2663, Avg Val Loss: 0.1963\n",
      "\n",
      "Validation loss improved from 0.1967 to 0.1963. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2575\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1959\n",
      "Epoch [215/2000], Avg Train Loss: 0.2575, Avg Val Loss: 0.1959\n",
      "\n",
      "Validation loss improved from 0.1963 to 0.1959. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2591\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1956\n",
      "Epoch [216/2000], Avg Train Loss: 0.2591, Avg Val Loss: 0.1956\n",
      "\n",
      "Validation loss improved from 0.1959 to 0.1956. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2513\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1952\n",
      "Epoch [217/2000], Avg Train Loss: 0.2513, Avg Val Loss: 0.1952\n",
      "\n",
      "Validation loss improved from 0.1956 to 0.1952. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2600\n",
      "LOG: Epoch [218/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1949\n",
      "Epoch [218/2000], Avg Train Loss: 0.2600, Avg Val Loss: 0.1949\n",
      "\n",
      "Validation loss improved from 0.1952 to 0.1949. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2583\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1946\n",
      "Epoch [219/2000], Avg Train Loss: 0.2583, Avg Val Loss: 0.1946\n",
      "\n",
      "Validation loss improved from 0.1949 to 0.1946. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2629\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1942\n",
      "Epoch [220/2000], Avg Train Loss: 0.2629, Avg Val Loss: 0.1942\n",
      "\n",
      "Validation loss improved from 0.1946 to 0.1942. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2649\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1939\n",
      "Epoch [221/2000], Avg Train Loss: 0.2649, Avg Val Loss: 0.1939\n",
      "\n",
      "Validation loss improved from 0.1942 to 0.1939. Saving model...\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2680\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1936\n",
      "Epoch [222/2000], Avg Train Loss: 0.2680, Avg Val Loss: 0.1936\n",
      "\n",
      "Validation loss improved from 0.1939 to 0.1936. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2591\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1933\n",
      "Epoch [223/2000], Avg Train Loss: 0.2591, Avg Val Loss: 0.1933\n",
      "\n",
      "Validation loss improved from 0.1936 to 0.1933. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2623\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1929\n",
      "Epoch [224/2000], Avg Train Loss: 0.2623, Avg Val Loss: 0.1929\n",
      "\n",
      "Validation loss improved from 0.1933 to 0.1929. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2634\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1926\n",
      "Epoch [225/2000], Avg Train Loss: 0.2634, Avg Val Loss: 0.1926\n",
      "\n",
      "Validation loss improved from 0.1929 to 0.1926. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2518\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1923\n",
      "Epoch [226/2000], Avg Train Loss: 0.2518, Avg Val Loss: 0.1923\n",
      "\n",
      "Validation loss improved from 0.1926 to 0.1923. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2518\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1919\n",
      "Epoch [227/2000], Avg Train Loss: 0.2518, Avg Val Loss: 0.1919\n",
      "\n",
      "Validation loss improved from 0.1923 to 0.1919. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2541\n",
      "LOG: Epoch [228/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1916\n",
      "Epoch [228/2000], Avg Train Loss: 0.2541, Avg Val Loss: 0.1916\n",
      "\n",
      "Validation loss improved from 0.1919 to 0.1916. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2596\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1913\n",
      "Epoch [229/2000], Avg Train Loss: 0.2596, Avg Val Loss: 0.1913\n",
      "\n",
      "Validation loss improved from 0.1916 to 0.1913. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2522\n",
      "LOG: Epoch [230/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1909\n",
      "Epoch [230/2000], Avg Train Loss: 0.2522, Avg Val Loss: 0.1909\n",
      "\n",
      "Validation loss improved from 0.1913 to 0.1909. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2497\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1906\n",
      "Epoch [231/2000], Avg Train Loss: 0.2497, Avg Val Loss: 0.1906\n",
      "\n",
      "Validation loss improved from 0.1909 to 0.1906. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2473\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1903\n",
      "Epoch [232/2000], Avg Train Loss: 0.2473, Avg Val Loss: 0.1903\n",
      "\n",
      "Validation loss improved from 0.1906 to 0.1903. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2466\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1900\n",
      "Epoch [233/2000], Avg Train Loss: 0.2466, Avg Val Loss: 0.1900\n",
      "\n",
      "Validation loss improved from 0.1903 to 0.1900. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2599\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1898\n",
      "Epoch [234/2000], Avg Train Loss: 0.2599, Avg Val Loss: 0.1898\n",
      "\n",
      "Validation loss improved from 0.1900 to 0.1898. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2500\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1895\n",
      "Epoch [235/2000], Avg Train Loss: 0.2500, Avg Val Loss: 0.1895\n",
      "\n",
      "Validation loss improved from 0.1898 to 0.1895. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2565\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1891\n",
      "Epoch [236/2000], Avg Train Loss: 0.2565, Avg Val Loss: 0.1891\n",
      "\n",
      "Validation loss improved from 0.1895 to 0.1891. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2500\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1888\n",
      "Epoch [237/2000], Avg Train Loss: 0.2500, Avg Val Loss: 0.1888\n",
      "\n",
      "Validation loss improved from 0.1891 to 0.1888. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2546\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1885\n",
      "Epoch [238/2000], Avg Train Loss: 0.2546, Avg Val Loss: 0.1885\n",
      "\n",
      "Validation loss improved from 0.1888 to 0.1885. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2475\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1881\n",
      "Epoch [239/2000], Avg Train Loss: 0.2475, Avg Val Loss: 0.1881\n",
      "\n",
      "Validation loss improved from 0.1885 to 0.1881. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2451\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1878\n",
      "Epoch [240/2000], Avg Train Loss: 0.2451, Avg Val Loss: 0.1878\n",
      "\n",
      "Validation loss improved from 0.1881 to 0.1878. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2505\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1875\n",
      "Epoch [241/2000], Avg Train Loss: 0.2505, Avg Val Loss: 0.1875\n",
      "\n",
      "Validation loss improved from 0.1878 to 0.1875. Saving model...\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2480\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1872\n",
      "Epoch [242/2000], Avg Train Loss: 0.2480, Avg Val Loss: 0.1872\n",
      "\n",
      "Validation loss improved from 0.1875 to 0.1872. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2533\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1869\n",
      "Epoch [243/2000], Avg Train Loss: 0.2533, Avg Val Loss: 0.1869\n",
      "\n",
      "Validation loss improved from 0.1872 to 0.1869. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2462\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1866\n",
      "Epoch [244/2000], Avg Train Loss: 0.2462, Avg Val Loss: 0.1866\n",
      "\n",
      "Validation loss improved from 0.1869 to 0.1866. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2502\n",
      "LOG: Epoch [245/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1864\n",
      "Epoch [245/2000], Avg Train Loss: 0.2502, Avg Val Loss: 0.1864\n",
      "\n",
      "Validation loss improved from 0.1866 to 0.1864. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2500\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1861\n",
      "Epoch [246/2000], Avg Train Loss: 0.2500, Avg Val Loss: 0.1861\n",
      "\n",
      "Validation loss improved from 0.1864 to 0.1861. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2410\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1859\n",
      "Epoch [247/2000], Avg Train Loss: 0.2410, Avg Val Loss: 0.1859\n",
      "\n",
      "Validation loss improved from 0.1861 to 0.1859. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2466\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1856\n",
      "Epoch [248/2000], Avg Train Loss: 0.2466, Avg Val Loss: 0.1856\n",
      "\n",
      "Validation loss improved from 0.1859 to 0.1856. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2461\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1854\n",
      "Epoch [249/2000], Avg Train Loss: 0.2461, Avg Val Loss: 0.1854\n",
      "\n",
      "Validation loss improved from 0.1856 to 0.1854. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2456\n",
      "LOG: Epoch [250/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1851\n",
      "Epoch [250/2000], Avg Train Loss: 0.2456, Avg Val Loss: 0.1851\n",
      "\n",
      "Validation loss improved from 0.1854 to 0.1851. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2430\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1849\n",
      "Epoch [251/2000], Avg Train Loss: 0.2430, Avg Val Loss: 0.1849\n",
      "\n",
      "Validation loss improved from 0.1851 to 0.1849. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2427\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1846\n",
      "Epoch [252/2000], Avg Train Loss: 0.2427, Avg Val Loss: 0.1846\n",
      "\n",
      "Validation loss improved from 0.1849 to 0.1846. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2438\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1844\n",
      "Epoch [253/2000], Avg Train Loss: 0.2438, Avg Val Loss: 0.1844\n",
      "\n",
      "Validation loss improved from 0.1846 to 0.1844. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2455\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1842\n",
      "Epoch [254/2000], Avg Train Loss: 0.2455, Avg Val Loss: 0.1842\n",
      "\n",
      "Validation loss improved from 0.1844 to 0.1842. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2468\n",
      "LOG: Epoch [255/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1840\n",
      "Epoch [255/2000], Avg Train Loss: 0.2468, Avg Val Loss: 0.1840\n",
      "\n",
      "Validation loss improved from 0.1842 to 0.1840. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2422\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1838\n",
      "Epoch [256/2000], Avg Train Loss: 0.2422, Avg Val Loss: 0.1838\n",
      "\n",
      "Validation loss improved from 0.1840 to 0.1838. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2453\n",
      "LOG: Epoch [257/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1836\n",
      "Epoch [257/2000], Avg Train Loss: 0.2453, Avg Val Loss: 0.1836\n",
      "\n",
      "Validation loss improved from 0.1838 to 0.1836. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2425\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1833\n",
      "Epoch [258/2000], Avg Train Loss: 0.2425, Avg Val Loss: 0.1833\n",
      "\n",
      "Validation loss improved from 0.1836 to 0.1833. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2448\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1831\n",
      "Epoch [259/2000], Avg Train Loss: 0.2448, Avg Val Loss: 0.1831\n",
      "\n",
      "Validation loss improved from 0.1833 to 0.1831. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2372\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1828\n",
      "Epoch [260/2000], Avg Train Loss: 0.2372, Avg Val Loss: 0.1828\n",
      "\n",
      "Validation loss improved from 0.1831 to 0.1828. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2373\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1826\n",
      "Epoch [261/2000], Avg Train Loss: 0.2373, Avg Val Loss: 0.1826\n",
      "\n",
      "Validation loss improved from 0.1828 to 0.1826. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2419\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1823\n",
      "Epoch [262/2000], Avg Train Loss: 0.2419, Avg Val Loss: 0.1823\n",
      "\n",
      "Validation loss improved from 0.1826 to 0.1823. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2386\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1820\n",
      "Epoch [263/2000], Avg Train Loss: 0.2386, Avg Val Loss: 0.1820\n",
      "\n",
      "Validation loss improved from 0.1823 to 0.1820. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2401\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1817\n",
      "Epoch [264/2000], Avg Train Loss: 0.2401, Avg Val Loss: 0.1817\n",
      "\n",
      "Validation loss improved from 0.1820 to 0.1817. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2356\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1814\n",
      "Epoch [265/2000], Avg Train Loss: 0.2356, Avg Val Loss: 0.1814\n",
      "\n",
      "Validation loss improved from 0.1817 to 0.1814. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2323\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1812\n",
      "Epoch [266/2000], Avg Train Loss: 0.2323, Avg Val Loss: 0.1812\n",
      "\n",
      "Validation loss improved from 0.1814 to 0.1812. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2388\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1809\n",
      "Epoch [267/2000], Avg Train Loss: 0.2388, Avg Val Loss: 0.1809\n",
      "\n",
      "Validation loss improved from 0.1812 to 0.1809. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2361\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1806\n",
      "Epoch [268/2000], Avg Train Loss: 0.2361, Avg Val Loss: 0.1806\n",
      "\n",
      "Validation loss improved from 0.1809 to 0.1806. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2359\n",
      "LOG: Epoch [269/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1803\n",
      "Epoch [269/2000], Avg Train Loss: 0.2359, Avg Val Loss: 0.1803\n",
      "\n",
      "Validation loss improved from 0.1806 to 0.1803. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2304\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1800\n",
      "Epoch [270/2000], Avg Train Loss: 0.2304, Avg Val Loss: 0.1800\n",
      "\n",
      "Validation loss improved from 0.1803 to 0.1800. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2337\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1797\n",
      "Epoch [271/2000], Avg Train Loss: 0.2337, Avg Val Loss: 0.1797\n",
      "\n",
      "Validation loss improved from 0.1800 to 0.1797. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2347\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1795\n",
      "Epoch [272/2000], Avg Train Loss: 0.2347, Avg Val Loss: 0.1795\n",
      "\n",
      "Validation loss improved from 0.1797 to 0.1795. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2317\n",
      "LOG: Epoch [273/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1792\n",
      "Epoch [273/2000], Avg Train Loss: 0.2317, Avg Val Loss: 0.1792\n",
      "\n",
      "Validation loss improved from 0.1795 to 0.1792. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2349\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1789\n",
      "Epoch [274/2000], Avg Train Loss: 0.2349, Avg Val Loss: 0.1789\n",
      "\n",
      "Validation loss improved from 0.1792 to 0.1789. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2317\n",
      "LOG: Epoch [275/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1787\n",
      "Epoch [275/2000], Avg Train Loss: 0.2317, Avg Val Loss: 0.1787\n",
      "\n",
      "Validation loss improved from 0.1789 to 0.1787. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2345\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1785\n",
      "Epoch [276/2000], Avg Train Loss: 0.2345, Avg Val Loss: 0.1785\n",
      "\n",
      "Validation loss improved from 0.1787 to 0.1785. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2334\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1782\n",
      "Epoch [277/2000], Avg Train Loss: 0.2334, Avg Val Loss: 0.1782\n",
      "\n",
      "Validation loss improved from 0.1785 to 0.1782. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2285\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1779\n",
      "Epoch [278/2000], Avg Train Loss: 0.2285, Avg Val Loss: 0.1779\n",
      "\n",
      "Validation loss improved from 0.1782 to 0.1779. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2240\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1777\n",
      "Epoch [279/2000], Avg Train Loss: 0.2240, Avg Val Loss: 0.1777\n",
      "\n",
      "Validation loss improved from 0.1779 to 0.1777. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2280\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1775\n",
      "Epoch [280/2000], Avg Train Loss: 0.2280, Avg Val Loss: 0.1775\n",
      "\n",
      "Validation loss improved from 0.1777 to 0.1775. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2320\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1772\n",
      "Epoch [281/2000], Avg Train Loss: 0.2320, Avg Val Loss: 0.1772\n",
      "\n",
      "Validation loss improved from 0.1775 to 0.1772. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2326\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1770\n",
      "Epoch [282/2000], Avg Train Loss: 0.2326, Avg Val Loss: 0.1770\n",
      "\n",
      "Validation loss improved from 0.1772 to 0.1770. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2279\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1767\n",
      "Epoch [283/2000], Avg Train Loss: 0.2279, Avg Val Loss: 0.1767\n",
      "\n",
      "Validation loss improved from 0.1770 to 0.1767. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2318\n",
      "LOG: Epoch [284/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1765\n",
      "Epoch [284/2000], Avg Train Loss: 0.2318, Avg Val Loss: 0.1765\n",
      "\n",
      "Validation loss improved from 0.1767 to 0.1765. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2255\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1762\n",
      "Epoch [285/2000], Avg Train Loss: 0.2255, Avg Val Loss: 0.1762\n",
      "\n",
      "Validation loss improved from 0.1765 to 0.1762. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2248\n",
      "LOG: Epoch [286/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1760\n",
      "Epoch [286/2000], Avg Train Loss: 0.2248, Avg Val Loss: 0.1760\n",
      "\n",
      "Validation loss improved from 0.1762 to 0.1760. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2349\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1757\n",
      "Epoch [287/2000], Avg Train Loss: 0.2349, Avg Val Loss: 0.1757\n",
      "\n",
      "Validation loss improved from 0.1760 to 0.1757. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2306\n",
      "LOG: Epoch [288/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1755\n",
      "Epoch [288/2000], Avg Train Loss: 0.2306, Avg Val Loss: 0.1755\n",
      "\n",
      "Validation loss improved from 0.1757 to 0.1755. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2287\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1752\n",
      "Epoch [289/2000], Avg Train Loss: 0.2287, Avg Val Loss: 0.1752\n",
      "\n",
      "Validation loss improved from 0.1755 to 0.1752. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2262\n",
      "LOG: Epoch [290/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1749\n",
      "Epoch [290/2000], Avg Train Loss: 0.2262, Avg Val Loss: 0.1749\n",
      "\n",
      "Validation loss improved from 0.1752 to 0.1749. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2297\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1747\n",
      "Epoch [291/2000], Avg Train Loss: 0.2297, Avg Val Loss: 0.1747\n",
      "\n",
      "Validation loss improved from 0.1749 to 0.1747. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2256\n",
      "LOG: Epoch [292/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1744\n",
      "Epoch [292/2000], Avg Train Loss: 0.2256, Avg Val Loss: 0.1744\n",
      "\n",
      "Validation loss improved from 0.1747 to 0.1744. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2259\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1742\n",
      "Epoch [293/2000], Avg Train Loss: 0.2259, Avg Val Loss: 0.1742\n",
      "\n",
      "Validation loss improved from 0.1744 to 0.1742. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2307\n",
      "LOG: Epoch [294/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1739\n",
      "Epoch [294/2000], Avg Train Loss: 0.2307, Avg Val Loss: 0.1739\n",
      "\n",
      "Validation loss improved from 0.1742 to 0.1739. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2259\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1737\n",
      "Epoch [295/2000], Avg Train Loss: 0.2259, Avg Val Loss: 0.1737\n",
      "\n",
      "Validation loss improved from 0.1739 to 0.1737. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2199\n",
      "LOG: Epoch [296/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1734\n",
      "Epoch [296/2000], Avg Train Loss: 0.2199, Avg Val Loss: 0.1734\n",
      "\n",
      "Validation loss improved from 0.1737 to 0.1734. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2257\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1732\n",
      "Epoch [297/2000], Avg Train Loss: 0.2257, Avg Val Loss: 0.1732\n",
      "\n",
      "Validation loss improved from 0.1734 to 0.1732. Saving model...\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2254\n",
      "LOG: Epoch [298/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1729\n",
      "Epoch [298/2000], Avg Train Loss: 0.2254, Avg Val Loss: 0.1729\n",
      "\n",
      "Validation loss improved from 0.1732 to 0.1729. Saving model...\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2222\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1727\n",
      "Epoch [299/2000], Avg Train Loss: 0.2222, Avg Val Loss: 0.1727\n",
      "\n",
      "Validation loss improved from 0.1729 to 0.1727. Saving model...\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2144\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1724\n",
      "Epoch [300/2000], Avg Train Loss: 0.2144, Avg Val Loss: 0.1724\n",
      "\n",
      "Validation loss improved from 0.1727 to 0.1724. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2221\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1721\n",
      "Epoch [301/2000], Avg Train Loss: 0.2221, Avg Val Loss: 0.1721\n",
      "\n",
      "Validation loss improved from 0.1724 to 0.1721. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2206\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1719\n",
      "Epoch [302/2000], Avg Train Loss: 0.2206, Avg Val Loss: 0.1719\n",
      "\n",
      "Validation loss improved from 0.1721 to 0.1719. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2223\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1717\n",
      "Epoch [303/2000], Avg Train Loss: 0.2223, Avg Val Loss: 0.1717\n",
      "\n",
      "Validation loss improved from 0.1719 to 0.1717. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2251\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1714\n",
      "Epoch [304/2000], Avg Train Loss: 0.2251, Avg Val Loss: 0.1714\n",
      "\n",
      "Validation loss improved from 0.1717 to 0.1714. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2195\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1712\n",
      "Epoch [305/2000], Avg Train Loss: 0.2195, Avg Val Loss: 0.1712\n",
      "\n",
      "Validation loss improved from 0.1714 to 0.1712. Saving model...\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2230\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1710\n",
      "Epoch [306/2000], Avg Train Loss: 0.2230, Avg Val Loss: 0.1710\n",
      "\n",
      "Validation loss improved from 0.1712 to 0.1710. Saving model...\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2247\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1708\n",
      "Epoch [307/2000], Avg Train Loss: 0.2247, Avg Val Loss: 0.1708\n",
      "\n",
      "Validation loss improved from 0.1710 to 0.1708. Saving model...\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2202\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1707\n",
      "Epoch [308/2000], Avg Train Loss: 0.2202, Avg Val Loss: 0.1707\n",
      "\n",
      "Validation loss improved from 0.1708 to 0.1707. Saving model...\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2250\n",
      "LOG: Epoch [309/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1705\n",
      "Epoch [309/2000], Avg Train Loss: 0.2250, Avg Val Loss: 0.1705\n",
      "\n",
      "Validation loss improved from 0.1707 to 0.1705. Saving model...\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2201\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1703\n",
      "Epoch [310/2000], Avg Train Loss: 0.2201, Avg Val Loss: 0.1703\n",
      "\n",
      "Validation loss improved from 0.1705 to 0.1703. Saving model...\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2233\n",
      "LOG: Epoch [311/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1701\n",
      "Epoch [311/2000], Avg Train Loss: 0.2233, Avg Val Loss: 0.1701\n",
      "\n",
      "Validation loss improved from 0.1703 to 0.1701. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2146\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1699\n",
      "Epoch [312/2000], Avg Train Loss: 0.2146, Avg Val Loss: 0.1699\n",
      "\n",
      "Validation loss improved from 0.1701 to 0.1699. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2194\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1697\n",
      "Epoch [313/2000], Avg Train Loss: 0.2194, Avg Val Loss: 0.1697\n",
      "\n",
      "Validation loss improved from 0.1699 to 0.1697. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2186\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1695\n",
      "Epoch [314/2000], Avg Train Loss: 0.2186, Avg Val Loss: 0.1695\n",
      "\n",
      "Validation loss improved from 0.1697 to 0.1695. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2152\n",
      "LOG: Epoch [315/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1693\n",
      "Epoch [315/2000], Avg Train Loss: 0.2152, Avg Val Loss: 0.1693\n",
      "\n",
      "Validation loss improved from 0.1695 to 0.1693. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2121\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1690\n",
      "Epoch [316/2000], Avg Train Loss: 0.2121, Avg Val Loss: 0.1690\n",
      "\n",
      "Validation loss improved from 0.1693 to 0.1690. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2166\n",
      "LOG: Epoch [317/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1688\n",
      "Epoch [317/2000], Avg Train Loss: 0.2166, Avg Val Loss: 0.1688\n",
      "\n",
      "Validation loss improved from 0.1690 to 0.1688. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2120\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1686\n",
      "Epoch [318/2000], Avg Train Loss: 0.2120, Avg Val Loss: 0.1686\n",
      "\n",
      "Validation loss improved from 0.1688 to 0.1686. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2124\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1684\n",
      "Epoch [319/2000], Avg Train Loss: 0.2124, Avg Val Loss: 0.1684\n",
      "\n",
      "Validation loss improved from 0.1686 to 0.1684. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2213\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1683\n",
      "Epoch [320/2000], Avg Train Loss: 0.2213, Avg Val Loss: 0.1683\n",
      "\n",
      "Validation loss improved from 0.1684 to 0.1683. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2197\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1681\n",
      "Epoch [321/2000], Avg Train Loss: 0.2197, Avg Val Loss: 0.1681\n",
      "\n",
      "Validation loss improved from 0.1683 to 0.1681. Saving model...\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2231\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1680\n",
      "Epoch [322/2000], Avg Train Loss: 0.2231, Avg Val Loss: 0.1680\n",
      "\n",
      "Validation loss improved from 0.1681 to 0.1680. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2111\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1678\n",
      "Epoch [323/2000], Avg Train Loss: 0.2111, Avg Val Loss: 0.1678\n",
      "\n",
      "Validation loss improved from 0.1680 to 0.1678. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2163\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1677\n",
      "Epoch [324/2000], Avg Train Loss: 0.2163, Avg Val Loss: 0.1677\n",
      "\n",
      "Validation loss improved from 0.1678 to 0.1677. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2217\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1675\n",
      "Epoch [325/2000], Avg Train Loss: 0.2217, Avg Val Loss: 0.1675\n",
      "\n",
      "Validation loss improved from 0.1677 to 0.1675. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2082\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1674\n",
      "Epoch [326/2000], Avg Train Loss: 0.2082, Avg Val Loss: 0.1674\n",
      "\n",
      "Validation loss improved from 0.1675 to 0.1674. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2119\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1672\n",
      "Epoch [327/2000], Avg Train Loss: 0.2119, Avg Val Loss: 0.1672\n",
      "\n",
      "Validation loss improved from 0.1674 to 0.1672. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2117\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1671\n",
      "Epoch [328/2000], Avg Train Loss: 0.2117, Avg Val Loss: 0.1671\n",
      "\n",
      "Validation loss improved from 0.1672 to 0.1671. Saving model...\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2178\n",
      "LOG: Epoch [329/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1669\n",
      "Epoch [329/2000], Avg Train Loss: 0.2178, Avg Val Loss: 0.1669\n",
      "\n",
      "Validation loss improved from 0.1671 to 0.1669. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2136\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1667\n",
      "Epoch [330/2000], Avg Train Loss: 0.2136, Avg Val Loss: 0.1667\n",
      "\n",
      "Validation loss improved from 0.1669 to 0.1667. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2147\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1665\n",
      "Epoch [331/2000], Avg Train Loss: 0.2147, Avg Val Loss: 0.1665\n",
      "\n",
      "Validation loss improved from 0.1667 to 0.1665. Saving model...\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2114\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1664\n",
      "Epoch [332/2000], Avg Train Loss: 0.2114, Avg Val Loss: 0.1664\n",
      "\n",
      "Validation loss improved from 0.1665 to 0.1664. Saving model...\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2066\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1662\n",
      "Epoch [333/2000], Avg Train Loss: 0.2066, Avg Val Loss: 0.1662\n",
      "\n",
      "Validation loss improved from 0.1664 to 0.1662. Saving model...\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2104\n",
      "LOG: Epoch [334/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1660\n",
      "Epoch [334/2000], Avg Train Loss: 0.2104, Avg Val Loss: 0.1660\n",
      "\n",
      "Validation loss improved from 0.1662 to 0.1660. Saving model...\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2125\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1658\n",
      "Epoch [335/2000], Avg Train Loss: 0.2125, Avg Val Loss: 0.1658\n",
      "\n",
      "Validation loss improved from 0.1660 to 0.1658. Saving model...\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2117\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1656\n",
      "Epoch [336/2000], Avg Train Loss: 0.2117, Avg Val Loss: 0.1656\n",
      "\n",
      "Validation loss improved from 0.1658 to 0.1656. Saving model...\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2144\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1655\n",
      "Epoch [337/2000], Avg Train Loss: 0.2144, Avg Val Loss: 0.1655\n",
      "\n",
      "Validation loss improved from 0.1656 to 0.1655. Saving model...\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2168\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1653\n",
      "Epoch [338/2000], Avg Train Loss: 0.2168, Avg Val Loss: 0.1653\n",
      "\n",
      "Validation loss improved from 0.1655 to 0.1653. Saving model...\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2167\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1652\n",
      "Epoch [339/2000], Avg Train Loss: 0.2167, Avg Val Loss: 0.1652\n",
      "\n",
      "Validation loss improved from 0.1653 to 0.1652. Saving model...\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2079\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1650\n",
      "Epoch [340/2000], Avg Train Loss: 0.2079, Avg Val Loss: 0.1650\n",
      "\n",
      "Validation loss improved from 0.1652 to 0.1650. Saving model...\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2088\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1648\n",
      "Epoch [341/2000], Avg Train Loss: 0.2088, Avg Val Loss: 0.1648\n",
      "\n",
      "Validation loss improved from 0.1650 to 0.1648. Saving model...\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2044\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1647\n",
      "Epoch [342/2000], Avg Train Loss: 0.2044, Avg Val Loss: 0.1647\n",
      "\n",
      "Validation loss improved from 0.1648 to 0.1647. Saving model...\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2075\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1645\n",
      "Epoch [343/2000], Avg Train Loss: 0.2075, Avg Val Loss: 0.1645\n",
      "\n",
      "Validation loss improved from 0.1647 to 0.1645. Saving model...\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2082\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1644\n",
      "Epoch [344/2000], Avg Train Loss: 0.2082, Avg Val Loss: 0.1644\n",
      "\n",
      "Validation loss improved from 0.1645 to 0.1644. Saving model...\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2096\n",
      "LOG: Epoch [345/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1643\n",
      "Epoch [345/2000], Avg Train Loss: 0.2096, Avg Val Loss: 0.1643\n",
      "\n",
      "Validation loss improved from 0.1644 to 0.1643. Saving model...\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2016\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1641\n",
      "Epoch [346/2000], Avg Train Loss: 0.2016, Avg Val Loss: 0.1641\n",
      "\n",
      "Validation loss improved from 0.1643 to 0.1641. Saving model...\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2005\n",
      "LOG: Epoch [347/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1640\n",
      "Epoch [347/2000], Avg Train Loss: 0.2005, Avg Val Loss: 0.1640\n",
      "\n",
      "Validation loss improved from 0.1641 to 0.1640. Saving model...\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2105\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1639\n",
      "Epoch [348/2000], Avg Train Loss: 0.2105, Avg Val Loss: 0.1639\n",
      "\n",
      "Validation loss improved from 0.1640 to 0.1639. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2040\n",
      "LOG: Epoch [349/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1637\n",
      "Epoch [349/2000], Avg Train Loss: 0.2040, Avg Val Loss: 0.1637\n",
      "\n",
      "Validation loss improved from 0.1639 to 0.1637. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2032\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1636\n",
      "Epoch [350/2000], Avg Train Loss: 0.2032, Avg Val Loss: 0.1636\n",
      "\n",
      "Validation loss improved from 0.1637 to 0.1636. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2051\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1635\n",
      "Epoch [351/2000], Avg Train Loss: 0.2051, Avg Val Loss: 0.1635\n",
      "\n",
      "Validation loss improved from 0.1636 to 0.1635. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2096\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1634\n",
      "Epoch [352/2000], Avg Train Loss: 0.2096, Avg Val Loss: 0.1634\n",
      "\n",
      "Validation loss improved from 0.1635 to 0.1634. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2039\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1633\n",
      "Epoch [353/2000], Avg Train Loss: 0.2039, Avg Val Loss: 0.1633\n",
      "\n",
      "Validation loss improved from 0.1634 to 0.1633. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2041\n",
      "LOG: Epoch [354/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1632\n",
      "Epoch [354/2000], Avg Train Loss: 0.2041, Avg Val Loss: 0.1632\n",
      "\n",
      "Validation loss improved from 0.1633 to 0.1632. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2068\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1631\n",
      "Epoch [355/2000], Avg Train Loss: 0.2068, Avg Val Loss: 0.1631\n",
      "\n",
      "Validation loss improved from 0.1632 to 0.1631. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2012\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1630\n",
      "Epoch [356/2000], Avg Train Loss: 0.2012, Avg Val Loss: 0.1630\n",
      "\n",
      "Validation loss improved from 0.1631 to 0.1630. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2016\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1629\n",
      "Epoch [357/2000], Avg Train Loss: 0.2016, Avg Val Loss: 0.1629\n",
      "\n",
      "Validation loss improved from 0.1630 to 0.1629. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1994\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1628\n",
      "Epoch [358/2000], Avg Train Loss: 0.1994, Avg Val Loss: 0.1628\n",
      "\n",
      "Validation loss improved from 0.1629 to 0.1628. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1980\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1627\n",
      "Epoch [359/2000], Avg Train Loss: 0.1980, Avg Val Loss: 0.1627\n",
      "\n",
      "Validation loss improved from 0.1628 to 0.1627. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2037\n",
      "LOG: Epoch [360/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1626\n",
      "Epoch [360/2000], Avg Train Loss: 0.2037, Avg Val Loss: 0.1626\n",
      "\n",
      "Validation loss improved from 0.1627 to 0.1626. Saving model...\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2009\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1625\n",
      "Epoch [361/2000], Avg Train Loss: 0.2009, Avg Val Loss: 0.1625\n",
      "\n",
      "Validation loss improved from 0.1626 to 0.1625. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2017\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1624\n",
      "Epoch [362/2000], Avg Train Loss: 0.2017, Avg Val Loss: 0.1624\n",
      "\n",
      "Validation loss improved from 0.1625 to 0.1624. Saving model...\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2026\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1623\n",
      "Epoch [363/2000], Avg Train Loss: 0.2026, Avg Val Loss: 0.1623\n",
      "\n",
      "Validation loss improved from 0.1624 to 0.1623. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1979\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1622\n",
      "Epoch [364/2000], Avg Train Loss: 0.1979, Avg Val Loss: 0.1622\n",
      "\n",
      "Validation loss improved from 0.1623 to 0.1622. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1956\n",
      "LOG: Epoch [365/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1621\n",
      "Epoch [365/2000], Avg Train Loss: 0.1956, Avg Val Loss: 0.1621\n",
      "\n",
      "Validation loss improved from 0.1622 to 0.1621. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2032\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1620\n",
      "Epoch [366/2000], Avg Train Loss: 0.2032, Avg Val Loss: 0.1620\n",
      "\n",
      "Validation loss improved from 0.1621 to 0.1620. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1952\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1620\n",
      "Epoch [367/2000], Avg Train Loss: 0.1952, Avg Val Loss: 0.1620\n",
      "\n",
      "Validation loss improved from 0.1620 to 0.1620. Saving model...\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2046\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1619\n",
      "Epoch [368/2000], Avg Train Loss: 0.2046, Avg Val Loss: 0.1619\n",
      "\n",
      "Validation loss improved from 0.1620 to 0.1619. Saving model...\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1949\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1617\n",
      "Epoch [369/2000], Avg Train Loss: 0.1949, Avg Val Loss: 0.1617\n",
      "\n",
      "Validation loss improved from 0.1619 to 0.1617. Saving model...\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2039\n",
      "LOG: Epoch [370/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1616\n",
      "Epoch [370/2000], Avg Train Loss: 0.2039, Avg Val Loss: 0.1616\n",
      "\n",
      "Validation loss improved from 0.1617 to 0.1616. Saving model...\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1975\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1615\n",
      "Epoch [371/2000], Avg Train Loss: 0.1975, Avg Val Loss: 0.1615\n",
      "\n",
      "Validation loss improved from 0.1616 to 0.1615. Saving model...\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1992\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1614\n",
      "Epoch [372/2000], Avg Train Loss: 0.1992, Avg Val Loss: 0.1614\n",
      "\n",
      "Validation loss improved from 0.1615 to 0.1614. Saving model...\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1974\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1613\n",
      "Epoch [373/2000], Avg Train Loss: 0.1974, Avg Val Loss: 0.1613\n",
      "\n",
      "Validation loss improved from 0.1614 to 0.1613. Saving model...\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1986\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1612\n",
      "Epoch [374/2000], Avg Train Loss: 0.1986, Avg Val Loss: 0.1612\n",
      "\n",
      "Validation loss improved from 0.1613 to 0.1612. Saving model...\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1968\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1610\n",
      "Epoch [375/2000], Avg Train Loss: 0.1968, Avg Val Loss: 0.1610\n",
      "\n",
      "Validation loss improved from 0.1612 to 0.1610. Saving model...\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1987\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1609\n",
      "Epoch [376/2000], Avg Train Loss: 0.1987, Avg Val Loss: 0.1609\n",
      "\n",
      "Validation loss improved from 0.1610 to 0.1609. Saving model...\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1999\n",
      "LOG: Epoch [377/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1608\n",
      "Epoch [377/2000], Avg Train Loss: 0.1999, Avg Val Loss: 0.1608\n",
      "\n",
      "Validation loss improved from 0.1609 to 0.1608. Saving model...\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1965\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1606\n",
      "Epoch [378/2000], Avg Train Loss: 0.1965, Avg Val Loss: 0.1606\n",
      "\n",
      "Validation loss improved from 0.1608 to 0.1606. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2014\n",
      "LOG: Epoch [379/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1605\n",
      "Epoch [379/2000], Avg Train Loss: 0.2014, Avg Val Loss: 0.1605\n",
      "\n",
      "Validation loss improved from 0.1606 to 0.1605. Saving model...\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1604\n",
      "Epoch [380/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.1604\n",
      "\n",
      "Validation loss improved from 0.1605 to 0.1604. Saving model...\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1996\n",
      "LOG: Epoch [381/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1602\n",
      "Epoch [381/2000], Avg Train Loss: 0.1996, Avg Val Loss: 0.1602\n",
      "\n",
      "Validation loss improved from 0.1604 to 0.1602. Saving model...\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1893\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1601\n",
      "Epoch [382/2000], Avg Train Loss: 0.1893, Avg Val Loss: 0.1601\n",
      "\n",
      "Validation loss improved from 0.1602 to 0.1601. Saving model...\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2003\n",
      "LOG: Epoch [383/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1600\n",
      "Epoch [383/2000], Avg Train Loss: 0.2003, Avg Val Loss: 0.1600\n",
      "\n",
      "Validation loss improved from 0.1601 to 0.1600. Saving model...\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2039\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1600\n",
      "Epoch [384/2000], Avg Train Loss: 0.2039, Avg Val Loss: 0.1600\n",
      "\n",
      "Validation loss improved from 0.1600 to 0.1600. Saving model...\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1959\n",
      "LOG: Epoch [385/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1599\n",
      "Epoch [385/2000], Avg Train Loss: 0.1959, Avg Val Loss: 0.1599\n",
      "\n",
      "Validation loss improved from 0.1600 to 0.1599. Saving model...\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1984\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1598\n",
      "Epoch [386/2000], Avg Train Loss: 0.1984, Avg Val Loss: 0.1598\n",
      "\n",
      "Validation loss improved from 0.1599 to 0.1598. Saving model...\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1931\n",
      "LOG: Epoch [387/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1596\n",
      "Epoch [387/2000], Avg Train Loss: 0.1931, Avg Val Loss: 0.1596\n",
      "\n",
      "Validation loss improved from 0.1598 to 0.1596. Saving model...\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1878\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1595\n",
      "Epoch [388/2000], Avg Train Loss: 0.1878, Avg Val Loss: 0.1595\n",
      "\n",
      "Validation loss improved from 0.1596 to 0.1595. Saving model...\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1929\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1593\n",
      "Epoch [389/2000], Avg Train Loss: 0.1929, Avg Val Loss: 0.1593\n",
      "\n",
      "Validation loss improved from 0.1595 to 0.1593. Saving model...\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1916\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1592\n",
      "Epoch [390/2000], Avg Train Loss: 0.1916, Avg Val Loss: 0.1592\n",
      "\n",
      "Validation loss improved from 0.1593 to 0.1592. Saving model...\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1590\n",
      "Epoch [391/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1590\n",
      "\n",
      "Validation loss improved from 0.1592 to 0.1590. Saving model...\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1947\n",
      "LOG: Epoch [392/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1588\n",
      "Epoch [392/2000], Avg Train Loss: 0.1947, Avg Val Loss: 0.1588\n",
      "\n",
      "Validation loss improved from 0.1590 to 0.1588. Saving model...\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.2000\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1586\n",
      "Epoch [393/2000], Avg Train Loss: 0.2000, Avg Val Loss: 0.1586\n",
      "\n",
      "Validation loss improved from 0.1588 to 0.1586. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1973\n",
      "LOG: Epoch [394/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1584\n",
      "Epoch [394/2000], Avg Train Loss: 0.1973, Avg Val Loss: 0.1584\n",
      "\n",
      "Validation loss improved from 0.1586 to 0.1584. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1866\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1582\n",
      "Epoch [395/2000], Avg Train Loss: 0.1866, Avg Val Loss: 0.1582\n",
      "\n",
      "Validation loss improved from 0.1584 to 0.1582. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1921\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1580\n",
      "Epoch [396/2000], Avg Train Loss: 0.1921, Avg Val Loss: 0.1580\n",
      "\n",
      "Validation loss improved from 0.1582 to 0.1580. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1998\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1578\n",
      "Epoch [397/2000], Avg Train Loss: 0.1998, Avg Val Loss: 0.1578\n",
      "\n",
      "Validation loss improved from 0.1580 to 0.1578. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1865\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1577\n",
      "Epoch [398/2000], Avg Train Loss: 0.1865, Avg Val Loss: 0.1577\n",
      "\n",
      "Validation loss improved from 0.1578 to 0.1577. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1576\n",
      "Epoch [399/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.1576\n",
      "\n",
      "Validation loss improved from 0.1577 to 0.1576. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1925\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1575\n",
      "Epoch [400/2000], Avg Train Loss: 0.1925, Avg Val Loss: 0.1575\n",
      "\n",
      "Validation loss improved from 0.1576 to 0.1575. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1866\n",
      "LOG: Epoch [401/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1574\n",
      "Epoch [401/2000], Avg Train Loss: 0.1866, Avg Val Loss: 0.1574\n",
      "\n",
      "Validation loss improved from 0.1575 to 0.1574. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1884\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1573\n",
      "Epoch [402/2000], Avg Train Loss: 0.1884, Avg Val Loss: 0.1573\n",
      "\n",
      "Validation loss improved from 0.1574 to 0.1573. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1572\n",
      "Epoch [403/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1572\n",
      "\n",
      "Validation loss improved from 0.1573 to 0.1572. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1850\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1571\n",
      "Epoch [404/2000], Avg Train Loss: 0.1850, Avg Val Loss: 0.1571\n",
      "\n",
      "Validation loss improved from 0.1572 to 0.1571. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1935\n",
      "LOG: Epoch [405/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1571\n",
      "Epoch [405/2000], Avg Train Loss: 0.1935, Avg Val Loss: 0.1571\n",
      "\n",
      "Validation loss improved from 0.1571 to 0.1571. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1831\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1570\n",
      "Epoch [406/2000], Avg Train Loss: 0.1831, Avg Val Loss: 0.1570\n",
      "\n",
      "Validation loss improved from 0.1571 to 0.1570. Saving model...\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1862\n",
      "LOG: Epoch [407/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1569\n",
      "Epoch [407/2000], Avg Train Loss: 0.1862, Avg Val Loss: 0.1569\n",
      "\n",
      "Validation loss improved from 0.1570 to 0.1569. Saving model...\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1891\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1568\n",
      "Epoch [408/2000], Avg Train Loss: 0.1891, Avg Val Loss: 0.1568\n",
      "\n",
      "Validation loss improved from 0.1569 to 0.1568. Saving model...\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1864\n",
      "LOG: Epoch [409/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1566\n",
      "Epoch [409/2000], Avg Train Loss: 0.1864, Avg Val Loss: 0.1566\n",
      "\n",
      "Validation loss improved from 0.1568 to 0.1566. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1923\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1565\n",
      "Epoch [410/2000], Avg Train Loss: 0.1923, Avg Val Loss: 0.1565\n",
      "\n",
      "Validation loss improved from 0.1566 to 0.1565. Saving model...\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1841\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1564\n",
      "Epoch [411/2000], Avg Train Loss: 0.1841, Avg Val Loss: 0.1564\n",
      "\n",
      "Validation loss improved from 0.1565 to 0.1564. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1877\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1563\n",
      "Epoch [412/2000], Avg Train Loss: 0.1877, Avg Val Loss: 0.1563\n",
      "\n",
      "Validation loss improved from 0.1564 to 0.1563. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1898\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1562\n",
      "Epoch [413/2000], Avg Train Loss: 0.1898, Avg Val Loss: 0.1562\n",
      "\n",
      "Validation loss improved from 0.1563 to 0.1562. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1889\n",
      "LOG: Epoch [414/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1560\n",
      "Epoch [414/2000], Avg Train Loss: 0.1889, Avg Val Loss: 0.1560\n",
      "\n",
      "Validation loss improved from 0.1562 to 0.1560. Saving model...\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1901\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1559\n",
      "Epoch [415/2000], Avg Train Loss: 0.1901, Avg Val Loss: 0.1559\n",
      "\n",
      "Validation loss improved from 0.1560 to 0.1559. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1937\n",
      "LOG: Epoch [416/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1559\n",
      "Epoch [416/2000], Avg Train Loss: 0.1937, Avg Val Loss: 0.1559\n",
      "\n",
      "Validation loss improved from 0.1559 to 0.1559. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1803\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1557\n",
      "Epoch [417/2000], Avg Train Loss: 0.1803, Avg Val Loss: 0.1557\n",
      "\n",
      "Validation loss improved from 0.1559 to 0.1557. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1899\n",
      "LOG: Epoch [418/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1556\n",
      "Epoch [418/2000], Avg Train Loss: 0.1899, Avg Val Loss: 0.1556\n",
      "\n",
      "Validation loss improved from 0.1557 to 0.1556. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1840\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1555\n",
      "Epoch [419/2000], Avg Train Loss: 0.1840, Avg Val Loss: 0.1555\n",
      "\n",
      "Validation loss improved from 0.1556 to 0.1555. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1874\n",
      "LOG: Epoch [420/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1553\n",
      "Epoch [420/2000], Avg Train Loss: 0.1874, Avg Val Loss: 0.1553\n",
      "\n",
      "Validation loss improved from 0.1555 to 0.1553. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1814\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1552\n",
      "Epoch [421/2000], Avg Train Loss: 0.1814, Avg Val Loss: 0.1552\n",
      "\n",
      "Validation loss improved from 0.1553 to 0.1552. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1551\n",
      "Epoch [422/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.1551\n",
      "\n",
      "Validation loss improved from 0.1552 to 0.1551. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1865\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1550\n",
      "Epoch [423/2000], Avg Train Loss: 0.1865, Avg Val Loss: 0.1550\n",
      "\n",
      "Validation loss improved from 0.1551 to 0.1550. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1918\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1549\n",
      "Epoch [424/2000], Avg Train Loss: 0.1918, Avg Val Loss: 0.1549\n",
      "\n",
      "Validation loss improved from 0.1550 to 0.1549. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1873\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1549\n",
      "Epoch [425/2000], Avg Train Loss: 0.1873, Avg Val Loss: 0.1549\n",
      "\n",
      "Validation loss improved from 0.1549 to 0.1549. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1842\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1549\n",
      "Epoch [426/2000], Avg Train Loss: 0.1842, Avg Val Loss: 0.1549\n",
      "\n",
      "Validation loss improved from 0.1549 to 0.1549. Saving model...\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1842\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1549\n",
      "Epoch [427/2000], Avg Train Loss: 0.1842, Avg Val Loss: 0.1549\n",
      "\n",
      "Validation loss improved from 0.1549 to 0.1549. Saving model...\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1776\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1548\n",
      "Epoch [428/2000], Avg Train Loss: 0.1776, Avg Val Loss: 0.1548\n",
      "\n",
      "Validation loss improved from 0.1549 to 0.1548. Saving model...\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1863\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1548\n",
      "Epoch [429/2000], Avg Train Loss: 0.1863, Avg Val Loss: 0.1548\n",
      "\n",
      "Validation loss improved from 0.1548 to 0.1548. Saving model...\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1794\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1548\n",
      "Epoch [430/2000], Avg Train Loss: 0.1794, Avg Val Loss: 0.1548\n",
      "\n",
      "Validation loss improved from 0.1548 to 0.1548. Saving model...\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1824\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1547\n",
      "Epoch [431/2000], Avg Train Loss: 0.1824, Avg Val Loss: 0.1547\n",
      "\n",
      "Validation loss improved from 0.1548 to 0.1547. Saving model...\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1848\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1547\n",
      "Epoch [432/2000], Avg Train Loss: 0.1848, Avg Val Loss: 0.1547\n",
      "\n",
      "Validation loss improved from 0.1547 to 0.1547. Saving model...\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1870\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1546\n",
      "Epoch [433/2000], Avg Train Loss: 0.1870, Avg Val Loss: 0.1546\n",
      "\n",
      "Validation loss improved from 0.1547 to 0.1546. Saving model...\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1825\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1545\n",
      "Epoch [434/2000], Avg Train Loss: 0.1825, Avg Val Loss: 0.1545\n",
      "\n",
      "Validation loss improved from 0.1546 to 0.1545. Saving model...\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1867\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1544\n",
      "Epoch [435/2000], Avg Train Loss: 0.1867, Avg Val Loss: 0.1544\n",
      "\n",
      "Validation loss improved from 0.1545 to 0.1544. Saving model...\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1887\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1543\n",
      "Epoch [436/2000], Avg Train Loss: 0.1887, Avg Val Loss: 0.1543\n",
      "\n",
      "Validation loss improved from 0.1544 to 0.1543. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1821\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1542\n",
      "Epoch [437/2000], Avg Train Loss: 0.1821, Avg Val Loss: 0.1542\n",
      "\n",
      "Validation loss improved from 0.1543 to 0.1542. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1762\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1541\n",
      "Epoch [438/2000], Avg Train Loss: 0.1762, Avg Val Loss: 0.1541\n",
      "\n",
      "Validation loss improved from 0.1542 to 0.1541. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1773\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1540\n",
      "Epoch [439/2000], Avg Train Loss: 0.1773, Avg Val Loss: 0.1540\n",
      "\n",
      "Validation loss improved from 0.1541 to 0.1540. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1799\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1539\n",
      "Epoch [440/2000], Avg Train Loss: 0.1799, Avg Val Loss: 0.1539\n",
      "\n",
      "Validation loss improved from 0.1540 to 0.1539. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1795\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1537\n",
      "Epoch [441/2000], Avg Train Loss: 0.1795, Avg Val Loss: 0.1537\n",
      "\n",
      "Validation loss improved from 0.1539 to 0.1537. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1762\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1536\n",
      "Epoch [442/2000], Avg Train Loss: 0.1762, Avg Val Loss: 0.1536\n",
      "\n",
      "Validation loss improved from 0.1537 to 0.1536. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1822\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1535\n",
      "Epoch [443/2000], Avg Train Loss: 0.1822, Avg Val Loss: 0.1535\n",
      "\n",
      "Validation loss improved from 0.1536 to 0.1535. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1757\n",
      "LOG: Epoch [444/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1533\n",
      "Epoch [444/2000], Avg Train Loss: 0.1757, Avg Val Loss: 0.1533\n",
      "\n",
      "Validation loss improved from 0.1535 to 0.1533. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1831\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1532\n",
      "Epoch [445/2000], Avg Train Loss: 0.1831, Avg Val Loss: 0.1532\n",
      "\n",
      "Validation loss improved from 0.1533 to 0.1532. Saving model...\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1854\n",
      "LOG: Epoch [446/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1531\n",
      "Epoch [446/2000], Avg Train Loss: 0.1854, Avg Val Loss: 0.1531\n",
      "\n",
      "Validation loss improved from 0.1532 to 0.1531. Saving model...\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1761\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1530\n",
      "Epoch [447/2000], Avg Train Loss: 0.1761, Avg Val Loss: 0.1530\n",
      "\n",
      "Validation loss improved from 0.1531 to 0.1530. Saving model...\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1843\n",
      "LOG: Epoch [448/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1529\n",
      "Epoch [448/2000], Avg Train Loss: 0.1843, Avg Val Loss: 0.1529\n",
      "\n",
      "Validation loss improved from 0.1530 to 0.1529. Saving model...\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1798\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1528\n",
      "Epoch [449/2000], Avg Train Loss: 0.1798, Avg Val Loss: 0.1528\n",
      "\n",
      "Validation loss improved from 0.1529 to 0.1528. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1770\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1527\n",
      "Epoch [450/2000], Avg Train Loss: 0.1770, Avg Val Loss: 0.1527\n",
      "\n",
      "Validation loss improved from 0.1528 to 0.1527. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1768\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1525\n",
      "Epoch [451/2000], Avg Train Loss: 0.1768, Avg Val Loss: 0.1525\n",
      "\n",
      "Validation loss improved from 0.1527 to 0.1525. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1716\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1524\n",
      "Epoch [452/2000], Avg Train Loss: 0.1716, Avg Val Loss: 0.1524\n",
      "\n",
      "Validation loss improved from 0.1525 to 0.1524. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1727\n",
      "LOG: Epoch [453/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1522\n",
      "Epoch [453/2000], Avg Train Loss: 0.1727, Avg Val Loss: 0.1522\n",
      "\n",
      "Validation loss improved from 0.1524 to 0.1522. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1800\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1520\n",
      "Epoch [454/2000], Avg Train Loss: 0.1800, Avg Val Loss: 0.1520\n",
      "\n",
      "Validation loss improved from 0.1522 to 0.1520. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1678\n",
      "LOG: Epoch [455/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1519\n",
      "Epoch [455/2000], Avg Train Loss: 0.1678, Avg Val Loss: 0.1519\n",
      "\n",
      "Validation loss improved from 0.1520 to 0.1519. Saving model...\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1794\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1517\n",
      "Epoch [456/2000], Avg Train Loss: 0.1794, Avg Val Loss: 0.1517\n",
      "\n",
      "Validation loss improved from 0.1519 to 0.1517. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1754\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1516\n",
      "Epoch [457/2000], Avg Train Loss: 0.1754, Avg Val Loss: 0.1516\n",
      "\n",
      "Validation loss improved from 0.1517 to 0.1516. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1714\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1515\n",
      "Epoch [458/2000], Avg Train Loss: 0.1714, Avg Val Loss: 0.1515\n",
      "\n",
      "Validation loss improved from 0.1516 to 0.1515. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1793\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1515\n",
      "Epoch [459/2000], Avg Train Loss: 0.1793, Avg Val Loss: 0.1515\n",
      "\n",
      "Validation loss improved from 0.1515 to 0.1515. Saving model...\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1742\n",
      "LOG: Epoch [460/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1514\n",
      "Epoch [460/2000], Avg Train Loss: 0.1742, Avg Val Loss: 0.1514\n",
      "\n",
      "Validation loss improved from 0.1515 to 0.1514. Saving model...\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1754\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1514\n",
      "Epoch [461/2000], Avg Train Loss: 0.1754, Avg Val Loss: 0.1514\n",
      "\n",
      "Validation loss improved from 0.1514 to 0.1514. Saving model...\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1740\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1513\n",
      "Epoch [462/2000], Avg Train Loss: 0.1740, Avg Val Loss: 0.1513\n",
      "\n",
      "Validation loss improved from 0.1514 to 0.1513. Saving model...\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1704\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1512\n",
      "Epoch [463/2000], Avg Train Loss: 0.1704, Avg Val Loss: 0.1512\n",
      "\n",
      "Validation loss improved from 0.1513 to 0.1512. Saving model...\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1716\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1512\n",
      "Epoch [464/2000], Avg Train Loss: 0.1716, Avg Val Loss: 0.1512\n",
      "\n",
      "Validation loss improved from 0.1512 to 0.1512. Saving model...\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1769\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1511\n",
      "Epoch [465/2000], Avg Train Loss: 0.1769, Avg Val Loss: 0.1511\n",
      "\n",
      "Validation loss improved from 0.1512 to 0.1511. Saving model...\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1707\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1510\n",
      "Epoch [466/2000], Avg Train Loss: 0.1707, Avg Val Loss: 0.1510\n",
      "\n",
      "Validation loss improved from 0.1511 to 0.1510. Saving model...\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1717\n",
      "LOG: Epoch [467/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1510\n",
      "Epoch [467/2000], Avg Train Loss: 0.1717, Avg Val Loss: 0.1510\n",
      "\n",
      "Validation loss improved from 0.1510 to 0.1510. Saving model...\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1735\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1510\n",
      "Epoch [468/2000], Avg Train Loss: 0.1735, Avg Val Loss: 0.1510\n",
      "\n",
      "Validation loss improved from 0.1510 to 0.1510. Saving model...\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1712\n",
      "LOG: Epoch [469/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1509\n",
      "Epoch [469/2000], Avg Train Loss: 0.1712, Avg Val Loss: 0.1509\n",
      "\n",
      "Validation loss improved from 0.1510 to 0.1509. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1794\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1509\n",
      "Epoch [470/2000], Avg Train Loss: 0.1794, Avg Val Loss: 0.1509\n",
      "\n",
      "Validation loss improved from 0.1509 to 0.1509. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1756\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1508\n",
      "Epoch [471/2000], Avg Train Loss: 0.1756, Avg Val Loss: 0.1508\n",
      "\n",
      "Validation loss improved from 0.1509 to 0.1508. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1778\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1508\n",
      "Epoch [472/2000], Avg Train Loss: 0.1778, Avg Val Loss: 0.1508\n",
      "\n",
      "Validation loss improved from 0.1508 to 0.1508. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1702\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1507\n",
      "Epoch [473/2000], Avg Train Loss: 0.1702, Avg Val Loss: 0.1507\n",
      "\n",
      "Validation loss improved from 0.1508 to 0.1507. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1748\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [474/2000], Avg Train Loss: 0.1748, Avg Val Loss: 0.1506\n",
      "\n",
      "Validation loss improved from 0.1507 to 0.1506. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1757\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [475/2000], Avg Train Loss: 0.1757, Avg Val Loss: 0.1506\n",
      "\n",
      "Validation loss improved from 0.1506 to 0.1506. Saving model...\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1751\n",
      "LOG: Epoch [476/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [476/2000], Avg Train Loss: 0.1751, Avg Val Loss: 0.1506\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1673\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [477/2000], Avg Train Loss: 0.1673, Avg Val Loss: 0.1506\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1708\n",
      "LOG: Epoch [478/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [478/2000], Avg Train Loss: 0.1708, Avg Val Loss: 0.1506\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1740\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1507\n",
      "Epoch [479/2000], Avg Train Loss: 0.1740, Avg Val Loss: 0.1507\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1735\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [480/2000], Avg Train Loss: 0.1735, Avg Val Loss: 0.1506\n",
      "\n",
      "Validation loss improved from 0.1506 to 0.1506. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1696\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1506\n",
      "Epoch [481/2000], Avg Train Loss: 0.1696, Avg Val Loss: 0.1506\n",
      "\n",
      "Validation loss improved from 0.1506 to 0.1506. Saving model...\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1664\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1505\n",
      "Epoch [482/2000], Avg Train Loss: 0.1664, Avg Val Loss: 0.1505\n",
      "\n",
      "Validation loss improved from 0.1506 to 0.1505. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1767\n",
      "LOG: Epoch [483/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1505\n",
      "Epoch [483/2000], Avg Train Loss: 0.1767, Avg Val Loss: 0.1505\n",
      "\n",
      "Validation loss improved from 0.1505 to 0.1505. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1695\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1504\n",
      "Epoch [484/2000], Avg Train Loss: 0.1695, Avg Val Loss: 0.1504\n",
      "\n",
      "Validation loss improved from 0.1505 to 0.1504. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1681\n",
      "LOG: Epoch [485/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1504\n",
      "Epoch [485/2000], Avg Train Loss: 0.1681, Avg Val Loss: 0.1504\n",
      "\n",
      "Validation loss improved from 0.1504 to 0.1504. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1678\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1504\n",
      "Epoch [486/2000], Avg Train Loss: 0.1678, Avg Val Loss: 0.1504\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1709\n",
      "LOG: Epoch [487/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1504\n",
      "Epoch [487/2000], Avg Train Loss: 0.1709, Avg Val Loss: 0.1504\n",
      "\n",
      "Validation loss improved from 0.1504 to 0.1504. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1700\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1504\n",
      "Epoch [488/2000], Avg Train Loss: 0.1700, Avg Val Loss: 0.1504\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1716\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1504\n",
      "Epoch [489/2000], Avg Train Loss: 0.1716, Avg Val Loss: 0.1504\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1661\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1503\n",
      "Epoch [490/2000], Avg Train Loss: 0.1661, Avg Val Loss: 0.1503\n",
      "\n",
      "Validation loss improved from 0.1504 to 0.1503. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1640\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1503\n",
      "Epoch [491/2000], Avg Train Loss: 0.1640, Avg Val Loss: 0.1503\n",
      "\n",
      "Validation loss improved from 0.1503 to 0.1503. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1652\n",
      "LOG: Epoch [492/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1502\n",
      "Epoch [492/2000], Avg Train Loss: 0.1652, Avg Val Loss: 0.1502\n",
      "\n",
      "Validation loss improved from 0.1503 to 0.1502. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1669\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1502\n",
      "Epoch [493/2000], Avg Train Loss: 0.1669, Avg Val Loss: 0.1502\n",
      "\n",
      "Validation loss improved from 0.1502 to 0.1502. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1713\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1500\n",
      "Epoch [494/2000], Avg Train Loss: 0.1713, Avg Val Loss: 0.1500\n",
      "\n",
      "Validation loss improved from 0.1502 to 0.1500. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1735\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1499\n",
      "Epoch [495/2000], Avg Train Loss: 0.1735, Avg Val Loss: 0.1499\n",
      "\n",
      "Validation loss improved from 0.1500 to 0.1499. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1676\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1497\n",
      "Epoch [496/2000], Avg Train Loss: 0.1676, Avg Val Loss: 0.1497\n",
      "\n",
      "Validation loss improved from 0.1499 to 0.1497. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1657\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1495\n",
      "Epoch [497/2000], Avg Train Loss: 0.1657, Avg Val Loss: 0.1495\n",
      "\n",
      "Validation loss improved from 0.1497 to 0.1495. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1647\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1494\n",
      "Epoch [498/2000], Avg Train Loss: 0.1647, Avg Val Loss: 0.1494\n",
      "\n",
      "Validation loss improved from 0.1495 to 0.1494. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1617\n",
      "LOG: Epoch [499/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1493\n",
      "Epoch [499/2000], Avg Train Loss: 0.1617, Avg Val Loss: 0.1493\n",
      "\n",
      "Validation loss improved from 0.1494 to 0.1493. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1616\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1492\n",
      "Epoch [500/2000], Avg Train Loss: 0.1616, Avg Val Loss: 0.1492\n",
      "\n",
      "Validation loss improved from 0.1493 to 0.1492. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1694\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1491\n",
      "Epoch [501/2000], Avg Train Loss: 0.1694, Avg Val Loss: 0.1491\n",
      "\n",
      "Validation loss improved from 0.1492 to 0.1491. Saving model...\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1638\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1491\n",
      "Epoch [502/2000], Avg Train Loss: 0.1638, Avg Val Loss: 0.1491\n",
      "\n",
      "Validation loss improved from 0.1491 to 0.1491. Saving model...\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1701\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1490\n",
      "Epoch [503/2000], Avg Train Loss: 0.1701, Avg Val Loss: 0.1490\n",
      "\n",
      "Validation loss improved from 0.1491 to 0.1490. Saving model...\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1649\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1490\n",
      "Epoch [504/2000], Avg Train Loss: 0.1649, Avg Val Loss: 0.1490\n",
      "\n",
      "Validation loss improved from 0.1490 to 0.1490. Saving model...\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1658\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [505/2000], Avg Train Loss: 0.1658, Avg Val Loss: 0.1489\n",
      "\n",
      "Validation loss improved from 0.1490 to 0.1489. Saving model...\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1586\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [506/2000], Avg Train Loss: 0.1586, Avg Val Loss: 0.1489\n",
      "\n",
      "Validation loss improved from 0.1489 to 0.1489. Saving model...\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1630\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [507/2000], Avg Train Loss: 0.1630, Avg Val Loss: 0.1489\n",
      "\n",
      "Validation loss improved from 0.1489 to 0.1489. Saving model...\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1645\n",
      "LOG: Epoch [508/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [508/2000], Avg Train Loss: 0.1645, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1650\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [509/2000], Avg Train Loss: 0.1650, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1629\n",
      "LOG: Epoch [510/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [510/2000], Avg Train Loss: 0.1629, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1662\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1488\n",
      "Epoch [511/2000], Avg Train Loss: 0.1662, Avg Val Loss: 0.1488\n",
      "\n",
      "Validation loss improved from 0.1489 to 0.1488. Saving model...\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1646\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [512/2000], Avg Train Loss: 0.1646, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1632\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [513/2000], Avg Train Loss: 0.1632, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1628\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [514/2000], Avg Train Loss: 0.1628, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1627\n",
      "LOG: Epoch [515/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1490\n",
      "Epoch [515/2000], Avg Train Loss: 0.1627, Avg Val Loss: 0.1490\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1658\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1490\n",
      "Epoch [516/2000], Avg Train Loss: 0.1658, Avg Val Loss: 0.1490\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1632\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1489\n",
      "Epoch [517/2000], Avg Train Loss: 0.1632, Avg Val Loss: 0.1489\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1643\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1488\n",
      "Epoch [518/2000], Avg Train Loss: 0.1643, Avg Val Loss: 0.1488\n",
      "\n",
      "Validation loss improved from 0.1488 to 0.1488. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1629\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1487\n",
      "Epoch [519/2000], Avg Train Loss: 0.1629, Avg Val Loss: 0.1487\n",
      "\n",
      "Validation loss improved from 0.1488 to 0.1487. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1654\n",
      "LOG: Epoch [520/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1485\n",
      "Epoch [520/2000], Avg Train Loss: 0.1654, Avg Val Loss: 0.1485\n",
      "\n",
      "Validation loss improved from 0.1487 to 0.1485. Saving model...\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1626\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1483\n",
      "Epoch [521/2000], Avg Train Loss: 0.1626, Avg Val Loss: 0.1483\n",
      "\n",
      "Validation loss improved from 0.1485 to 0.1483. Saving model...\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1621\n",
      "LOG: Epoch [522/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1481\n",
      "Epoch [522/2000], Avg Train Loss: 0.1621, Avg Val Loss: 0.1481\n",
      "\n",
      "Validation loss improved from 0.1483 to 0.1481. Saving model...\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1645\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1479\n",
      "Epoch [523/2000], Avg Train Loss: 0.1645, Avg Val Loss: 0.1479\n",
      "\n",
      "Validation loss improved from 0.1481 to 0.1479. Saving model...\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1628\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1477\n",
      "Epoch [524/2000], Avg Train Loss: 0.1628, Avg Val Loss: 0.1477\n",
      "\n",
      "Validation loss improved from 0.1479 to 0.1477. Saving model...\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1607\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1475\n",
      "Epoch [525/2000], Avg Train Loss: 0.1607, Avg Val Loss: 0.1475\n",
      "\n",
      "Validation loss improved from 0.1477 to 0.1475. Saving model...\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1579\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1474\n",
      "Epoch [526/2000], Avg Train Loss: 0.1579, Avg Val Loss: 0.1474\n",
      "\n",
      "Validation loss improved from 0.1475 to 0.1474. Saving model...\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1577\n",
      "LOG: Epoch [527/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1473\n",
      "Epoch [527/2000], Avg Train Loss: 0.1577, Avg Val Loss: 0.1473\n",
      "\n",
      "Validation loss improved from 0.1474 to 0.1473. Saving model...\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1632\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1473\n",
      "Epoch [528/2000], Avg Train Loss: 0.1632, Avg Val Loss: 0.1473\n",
      "\n",
      "Validation loss improved from 0.1473 to 0.1473. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1617\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1472\n",
      "Epoch [529/2000], Avg Train Loss: 0.1617, Avg Val Loss: 0.1472\n",
      "\n",
      "Validation loss improved from 0.1473 to 0.1472. Saving model...\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1586\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1472\n",
      "Epoch [530/2000], Avg Train Loss: 0.1586, Avg Val Loss: 0.1472\n",
      "\n",
      "Validation loss improved from 0.1472 to 0.1472. Saving model...\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1559\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1471\n",
      "Epoch [531/2000], Avg Train Loss: 0.1559, Avg Val Loss: 0.1471\n",
      "\n",
      "Validation loss improved from 0.1472 to 0.1471. Saving model...\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1604\n",
      "LOG: Epoch [532/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1470\n",
      "Epoch [532/2000], Avg Train Loss: 0.1604, Avg Val Loss: 0.1470\n",
      "\n",
      "Validation loss improved from 0.1471 to 0.1470. Saving model...\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1592\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1468\n",
      "Epoch [533/2000], Avg Train Loss: 0.1592, Avg Val Loss: 0.1468\n",
      "\n",
      "Validation loss improved from 0.1470 to 0.1468. Saving model...\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1573\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1467\n",
      "Epoch [534/2000], Avg Train Loss: 0.1573, Avg Val Loss: 0.1467\n",
      "\n",
      "Validation loss improved from 0.1468 to 0.1467. Saving model...\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1545\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1467\n",
      "Epoch [535/2000], Avg Train Loss: 0.1545, Avg Val Loss: 0.1467\n",
      "\n",
      "Validation loss improved from 0.1467 to 0.1467. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1575\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1466\n",
      "Epoch [536/2000], Avg Train Loss: 0.1575, Avg Val Loss: 0.1466\n",
      "\n",
      "Validation loss improved from 0.1467 to 0.1466. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1594\n",
      "LOG: Epoch [537/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1466\n",
      "Epoch [537/2000], Avg Train Loss: 0.1594, Avg Val Loss: 0.1466\n",
      "\n",
      "Validation loss improved from 0.1466 to 0.1466. Saving model...\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1586\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1466\n",
      "Epoch [538/2000], Avg Train Loss: 0.1586, Avg Val Loss: 0.1466\n",
      "\n",
      "Validation loss improved from 0.1466 to 0.1466. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1583\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1465\n",
      "Epoch [539/2000], Avg Train Loss: 0.1583, Avg Val Loss: 0.1465\n",
      "\n",
      "Validation loss improved from 0.1466 to 0.1465. Saving model...\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1593\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1465\n",
      "Epoch [540/2000], Avg Train Loss: 0.1593, Avg Val Loss: 0.1465\n",
      "\n",
      "Validation loss improved from 0.1465 to 0.1465. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1568\n",
      "LOG: Epoch [541/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1465\n",
      "Epoch [541/2000], Avg Train Loss: 0.1568, Avg Val Loss: 0.1465\n",
      "\n",
      "Validation loss improved from 0.1465 to 0.1465. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1579\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1465\n",
      "Epoch [542/2000], Avg Train Loss: 0.1579, Avg Val Loss: 0.1465\n",
      "\n",
      "Validation loss improved from 0.1465 to 0.1465. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1548\n",
      "LOG: Epoch [543/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1464\n",
      "Epoch [543/2000], Avg Train Loss: 0.1548, Avg Val Loss: 0.1464\n",
      "\n",
      "Validation loss improved from 0.1465 to 0.1464. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1548\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1463\n",
      "Epoch [544/2000], Avg Train Loss: 0.1548, Avg Val Loss: 0.1463\n",
      "\n",
      "Validation loss improved from 0.1464 to 0.1463. Saving model...\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1559\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1462\n",
      "Epoch [545/2000], Avg Train Loss: 0.1559, Avg Val Loss: 0.1462\n",
      "\n",
      "Validation loss improved from 0.1463 to 0.1462. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1544\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1460\n",
      "Epoch [546/2000], Avg Train Loss: 0.1544, Avg Val Loss: 0.1460\n",
      "\n",
      "Validation loss improved from 0.1462 to 0.1460. Saving model...\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1547\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1459\n",
      "Epoch [547/2000], Avg Train Loss: 0.1547, Avg Val Loss: 0.1459\n",
      "\n",
      "Validation loss improved from 0.1460 to 0.1459. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1621\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1458\n",
      "Epoch [548/2000], Avg Train Loss: 0.1621, Avg Val Loss: 0.1458\n",
      "\n",
      "Validation loss improved from 0.1459 to 0.1458. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1575\n",
      "LOG: Epoch [549/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1456\n",
      "Epoch [549/2000], Avg Train Loss: 0.1575, Avg Val Loss: 0.1456\n",
      "\n",
      "Validation loss improved from 0.1458 to 0.1456. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1608\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1455\n",
      "Epoch [550/2000], Avg Train Loss: 0.1608, Avg Val Loss: 0.1455\n",
      "\n",
      "Validation loss improved from 0.1456 to 0.1455. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1597\n",
      "LOG: Epoch [551/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1454\n",
      "Epoch [551/2000], Avg Train Loss: 0.1597, Avg Val Loss: 0.1454\n",
      "\n",
      "Validation loss improved from 0.1455 to 0.1454. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1551\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1453\n",
      "Epoch [552/2000], Avg Train Loss: 0.1551, Avg Val Loss: 0.1453\n",
      "\n",
      "Validation loss improved from 0.1454 to 0.1453. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1520\n",
      "LOG: Epoch [553/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1451\n",
      "Epoch [553/2000], Avg Train Loss: 0.1520, Avg Val Loss: 0.1451\n",
      "\n",
      "Validation loss improved from 0.1453 to 0.1451. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1559\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1450\n",
      "Epoch [554/2000], Avg Train Loss: 0.1559, Avg Val Loss: 0.1450\n",
      "\n",
      "Validation loss improved from 0.1451 to 0.1450. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1541\n",
      "LOG: Epoch [555/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1449\n",
      "Epoch [555/2000], Avg Train Loss: 0.1541, Avg Val Loss: 0.1449\n",
      "\n",
      "Validation loss improved from 0.1450 to 0.1449. Saving model...\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1567\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1448\n",
      "Epoch [556/2000], Avg Train Loss: 0.1567, Avg Val Loss: 0.1448\n",
      "\n",
      "Validation loss improved from 0.1449 to 0.1448. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1527\n",
      "LOG: Epoch [557/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1447\n",
      "Epoch [557/2000], Avg Train Loss: 0.1527, Avg Val Loss: 0.1447\n",
      "\n",
      "Validation loss improved from 0.1448 to 0.1447. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1515\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1446\n",
      "Epoch [558/2000], Avg Train Loss: 0.1515, Avg Val Loss: 0.1446\n",
      "\n",
      "Validation loss improved from 0.1447 to 0.1446. Saving model...\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1548\n",
      "LOG: Epoch [559/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1446\n",
      "Epoch [559/2000], Avg Train Loss: 0.1548, Avg Val Loss: 0.1446\n",
      "\n",
      "Validation loss improved from 0.1446 to 0.1446. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1557\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1446\n",
      "Epoch [560/2000], Avg Train Loss: 0.1557, Avg Val Loss: 0.1446\n",
      "\n",
      "Validation loss improved from 0.1446 to 0.1446. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1549\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1446\n",
      "Epoch [561/2000], Avg Train Loss: 0.1549, Avg Val Loss: 0.1446\n",
      "\n",
      "Validation loss improved from 0.1446 to 0.1446. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1521\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1445\n",
      "Epoch [562/2000], Avg Train Loss: 0.1521, Avg Val Loss: 0.1445\n",
      "\n",
      "Validation loss improved from 0.1446 to 0.1445. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1501\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1445\n",
      "Epoch [563/2000], Avg Train Loss: 0.1501, Avg Val Loss: 0.1445\n",
      "\n",
      "Validation loss improved from 0.1445 to 0.1445. Saving model...\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1492\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1446\n",
      "Epoch [564/2000], Avg Train Loss: 0.1492, Avg Val Loss: 0.1446\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1545\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1445\n",
      "Epoch [565/2000], Avg Train Loss: 0.1545, Avg Val Loss: 0.1445\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1486\n",
      "LOG: Epoch [566/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1445\n",
      "Epoch [566/2000], Avg Train Loss: 0.1486, Avg Val Loss: 0.1445\n",
      "\n",
      "Validation loss improved from 0.1445 to 0.1445. Saving model...\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1558\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1444\n",
      "Epoch [567/2000], Avg Train Loss: 0.1558, Avg Val Loss: 0.1444\n",
      "\n",
      "Validation loss improved from 0.1445 to 0.1444. Saving model...\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1486\n",
      "LOG: Epoch [568/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1443\n",
      "Epoch [568/2000], Avg Train Loss: 0.1486, Avg Val Loss: 0.1443\n",
      "\n",
      "Validation loss improved from 0.1444 to 0.1443. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1546\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1441\n",
      "Epoch [569/2000], Avg Train Loss: 0.1546, Avg Val Loss: 0.1441\n",
      "\n",
      "Validation loss improved from 0.1443 to 0.1441. Saving model...\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1492\n",
      "LOG: Epoch [570/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1440\n",
      "Epoch [570/2000], Avg Train Loss: 0.1492, Avg Val Loss: 0.1440\n",
      "\n",
      "Validation loss improved from 0.1441 to 0.1440. Saving model...\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1503\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1439\n",
      "Epoch [571/2000], Avg Train Loss: 0.1503, Avg Val Loss: 0.1439\n",
      "\n",
      "Validation loss improved from 0.1440 to 0.1439. Saving model...\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1526\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1438\n",
      "Epoch [572/2000], Avg Train Loss: 0.1526, Avg Val Loss: 0.1438\n",
      "\n",
      "Validation loss improved from 0.1439 to 0.1438. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1543\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1436\n",
      "Epoch [573/2000], Avg Train Loss: 0.1543, Avg Val Loss: 0.1436\n",
      "\n",
      "Validation loss improved from 0.1438 to 0.1436. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1496\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1435\n",
      "Epoch [574/2000], Avg Train Loss: 0.1496, Avg Val Loss: 0.1435\n",
      "\n",
      "Validation loss improved from 0.1436 to 0.1435. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1476\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1434\n",
      "Epoch [575/2000], Avg Train Loss: 0.1476, Avg Val Loss: 0.1434\n",
      "\n",
      "Validation loss improved from 0.1435 to 0.1434. Saving model...\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1532\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [576/2000], Avg Train Loss: 0.1532, Avg Val Loss: 0.1433\n",
      "\n",
      "Validation loss improved from 0.1434 to 0.1433. Saving model...\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1488\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [577/2000], Avg Train Loss: 0.1488, Avg Val Loss: 0.1433\n",
      "\n",
      "Validation loss improved from 0.1433 to 0.1433. Saving model...\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1476\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [578/2000], Avg Train Loss: 0.1476, Avg Val Loss: 0.1432\n",
      "\n",
      "Validation loss improved from 0.1433 to 0.1432. Saving model...\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1503\n",
      "LOG: Epoch [579/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [579/2000], Avg Train Loss: 0.1503, Avg Val Loss: 0.1432\n",
      "\n",
      "Validation loss improved from 0.1432 to 0.1432. Saving model...\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1479\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [580/2000], Avg Train Loss: 0.1479, Avg Val Loss: 0.1432\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1516\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [581/2000], Avg Train Loss: 0.1516, Avg Val Loss: 0.1432\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1474\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [582/2000], Avg Train Loss: 0.1474, Avg Val Loss: 0.1433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1429\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [583/2000], Avg Train Loss: 0.1429, Avg Val Loss: 0.1433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1478\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [584/2000], Avg Train Loss: 0.1478, Avg Val Loss: 0.1433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1513\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [585/2000], Avg Train Loss: 0.1513, Avg Val Loss: 0.1433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1486\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1433\n",
      "Epoch [586/2000], Avg Train Loss: 0.1486, Avg Val Loss: 0.1433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1476\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [587/2000], Avg Train Loss: 0.1476, Avg Val Loss: 0.1432\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1525\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [588/2000], Avg Train Loss: 0.1525, Avg Val Loss: 0.1432\n",
      "\n",
      "Validation loss improved from 0.1432 to 0.1432. Saving model...\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1454\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [589/2000], Avg Train Loss: 0.1454, Avg Val Loss: 0.1432\n",
      "\n",
      "Validation loss improved from 0.1432 to 0.1432. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1471\n",
      "LOG: Epoch [590/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1431\n",
      "Epoch [590/2000], Avg Train Loss: 0.1471, Avg Val Loss: 0.1431\n",
      "\n",
      "Validation loss improved from 0.1432 to 0.1431. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1484\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1432\n",
      "Epoch [591/2000], Avg Train Loss: 0.1484, Avg Val Loss: 0.1432\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1531\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1431\n",
      "Epoch [592/2000], Avg Train Loss: 0.1531, Avg Val Loss: 0.1431\n",
      "\n",
      "Validation loss improved from 0.1431 to 0.1431. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1536\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1430\n",
      "Epoch [593/2000], Avg Train Loss: 0.1536, Avg Val Loss: 0.1430\n",
      "\n",
      "Validation loss improved from 0.1431 to 0.1430. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1472\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1429\n",
      "Epoch [594/2000], Avg Train Loss: 0.1472, Avg Val Loss: 0.1429\n",
      "\n",
      "Validation loss improved from 0.1430 to 0.1429. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1445\n",
      "LOG: Epoch [595/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1429\n",
      "Epoch [595/2000], Avg Train Loss: 0.1445, Avg Val Loss: 0.1429\n",
      "\n",
      "Validation loss improved from 0.1429 to 0.1429. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1558\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1428\n",
      "Epoch [596/2000], Avg Train Loss: 0.1558, Avg Val Loss: 0.1428\n",
      "\n",
      "Validation loss improved from 0.1429 to 0.1428. Saving model...\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1499\n",
      "LOG: Epoch [597/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1427\n",
      "Epoch [597/2000], Avg Train Loss: 0.1499, Avg Val Loss: 0.1427\n",
      "\n",
      "Validation loss improved from 0.1428 to 0.1427. Saving model...\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1451\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1426\n",
      "Epoch [598/2000], Avg Train Loss: 0.1451, Avg Val Loss: 0.1426\n",
      "\n",
      "Validation loss improved from 0.1427 to 0.1426. Saving model...\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1429\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1424\n",
      "Epoch [599/2000], Avg Train Loss: 0.1429, Avg Val Loss: 0.1424\n",
      "\n",
      "Validation loss improved from 0.1426 to 0.1424. Saving model...\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1478\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1423\n",
      "Epoch [600/2000], Avg Train Loss: 0.1478, Avg Val Loss: 0.1423\n",
      "\n",
      "Validation loss improved from 0.1424 to 0.1423. Saving model...\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1500\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1422\n",
      "Epoch [601/2000], Avg Train Loss: 0.1500, Avg Val Loss: 0.1422\n",
      "\n",
      "Validation loss improved from 0.1423 to 0.1422. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1512\n",
      "LOG: Epoch [602/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1421\n",
      "Epoch [602/2000], Avg Train Loss: 0.1512, Avg Val Loss: 0.1421\n",
      "\n",
      "Validation loss improved from 0.1422 to 0.1421. Saving model...\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1445\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1420\n",
      "Epoch [603/2000], Avg Train Loss: 0.1445, Avg Val Loss: 0.1420\n",
      "\n",
      "Validation loss improved from 0.1421 to 0.1420. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1555\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1420\n",
      "Epoch [604/2000], Avg Train Loss: 0.1555, Avg Val Loss: 0.1420\n",
      "\n",
      "Validation loss improved from 0.1420 to 0.1420. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1482\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1419\n",
      "Epoch [605/2000], Avg Train Loss: 0.1482, Avg Val Loss: 0.1419\n",
      "\n",
      "Validation loss improved from 0.1420 to 0.1419. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1436\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1418\n",
      "Epoch [606/2000], Avg Train Loss: 0.1436, Avg Val Loss: 0.1418\n",
      "\n",
      "Validation loss improved from 0.1419 to 0.1418. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1486\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1417\n",
      "Epoch [607/2000], Avg Train Loss: 0.1486, Avg Val Loss: 0.1417\n",
      "\n",
      "Validation loss improved from 0.1418 to 0.1417. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1492\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1416\n",
      "Epoch [608/2000], Avg Train Loss: 0.1492, Avg Val Loss: 0.1416\n",
      "\n",
      "Validation loss improved from 0.1417 to 0.1416. Saving model...\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1501\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1416\n",
      "Epoch [609/2000], Avg Train Loss: 0.1501, Avg Val Loss: 0.1416\n",
      "\n",
      "Validation loss improved from 0.1416 to 0.1416. Saving model...\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1428\n",
      "LOG: Epoch [610/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1416\n",
      "Epoch [610/2000], Avg Train Loss: 0.1428, Avg Val Loss: 0.1416\n",
      "\n",
      "Validation loss improved from 0.1416 to 0.1416. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1473\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1416\n",
      "Epoch [611/2000], Avg Train Loss: 0.1473, Avg Val Loss: 0.1416\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1465\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1415\n",
      "Epoch [612/2000], Avg Train Loss: 0.1465, Avg Val Loss: 0.1415\n",
      "\n",
      "Validation loss improved from 0.1416 to 0.1415. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1508\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1415\n",
      "Epoch [613/2000], Avg Train Loss: 0.1508, Avg Val Loss: 0.1415\n",
      "\n",
      "Validation loss improved from 0.1415 to 0.1415. Saving model...\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1461\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1415\n",
      "Epoch [614/2000], Avg Train Loss: 0.1461, Avg Val Loss: 0.1415\n",
      "\n",
      "Validation loss improved from 0.1415 to 0.1415. Saving model...\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1474\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1415\n",
      "Epoch [615/2000], Avg Train Loss: 0.1474, Avg Val Loss: 0.1415\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1458\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1415\n",
      "Epoch [616/2000], Avg Train Loss: 0.1458, Avg Val Loss: 0.1415\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1453\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1414\n",
      "Epoch [617/2000], Avg Train Loss: 0.1453, Avg Val Loss: 0.1414\n",
      "\n",
      "Validation loss improved from 0.1415 to 0.1414. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1471\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1414\n",
      "Epoch [618/2000], Avg Train Loss: 0.1471, Avg Val Loss: 0.1414\n",
      "\n",
      "Validation loss improved from 0.1414 to 0.1414. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1442\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1414\n",
      "Epoch [619/2000], Avg Train Loss: 0.1442, Avg Val Loss: 0.1414\n",
      "\n",
      "Validation loss improved from 0.1414 to 0.1414. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1448\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1413\n",
      "Epoch [620/2000], Avg Train Loss: 0.1448, Avg Val Loss: 0.1413\n",
      "\n",
      "Validation loss improved from 0.1414 to 0.1413. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1417\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1412\n",
      "Epoch [621/2000], Avg Train Loss: 0.1417, Avg Val Loss: 0.1412\n",
      "\n",
      "Validation loss improved from 0.1413 to 0.1412. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1431\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1411\n",
      "Epoch [622/2000], Avg Train Loss: 0.1431, Avg Val Loss: 0.1411\n",
      "\n",
      "Validation loss improved from 0.1412 to 0.1411. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1402\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1410\n",
      "Epoch [623/2000], Avg Train Loss: 0.1402, Avg Val Loss: 0.1410\n",
      "\n",
      "Validation loss improved from 0.1411 to 0.1410. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1440\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [624/2000], Avg Train Loss: 0.1440, Avg Val Loss: 0.1409\n",
      "\n",
      "Validation loss improved from 0.1410 to 0.1409. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1477\n",
      "LOG: Epoch [625/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1408\n",
      "Epoch [625/2000], Avg Train Loss: 0.1477, Avg Val Loss: 0.1408\n",
      "\n",
      "Validation loss improved from 0.1409 to 0.1408. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1406\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1406\n",
      "Epoch [626/2000], Avg Train Loss: 0.1406, Avg Val Loss: 0.1406\n",
      "\n",
      "Validation loss improved from 0.1408 to 0.1406. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1410\n",
      "LOG: Epoch [627/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1406\n",
      "Epoch [627/2000], Avg Train Loss: 0.1410, Avg Val Loss: 0.1406\n",
      "\n",
      "Validation loss improved from 0.1406 to 0.1406. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1396\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1406\n",
      "Epoch [628/2000], Avg Train Loss: 0.1396, Avg Val Loss: 0.1406\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1411\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1407\n",
      "Epoch [629/2000], Avg Train Loss: 0.1411, Avg Val Loss: 0.1407\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1413\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1407\n",
      "Epoch [630/2000], Avg Train Loss: 0.1413, Avg Val Loss: 0.1407\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1462\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1408\n",
      "Epoch [631/2000], Avg Train Loss: 0.1462, Avg Val Loss: 0.1408\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1438\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [632/2000], Avg Train Loss: 0.1438, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1420\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [633/2000], Avg Train Loss: 0.1420, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1435\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [634/2000], Avg Train Loss: 0.1435, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1418\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [635/2000], Avg Train Loss: 0.1418, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1415\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [636/2000], Avg Train Loss: 0.1415, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1437\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1408\n",
      "Epoch [637/2000], Avg Train Loss: 0.1437, Avg Val Loss: 0.1408\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1463\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1408\n",
      "Epoch [638/2000], Avg Train Loss: 0.1463, Avg Val Loss: 0.1408\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1481\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [639/2000], Avg Train Loss: 0.1481, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1427\n",
      "LOG: Epoch [640/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1408\n",
      "Epoch [640/2000], Avg Train Loss: 0.1427, Avg Val Loss: 0.1408\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1439\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [641/2000], Avg Train Loss: 0.1439, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1403\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [642/2000], Avg Train Loss: 0.1403, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1443\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [643/2000], Avg Train Loss: 0.1443, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1393\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1409\n",
      "Epoch [644/2000], Avg Train Loss: 0.1393, Avg Val Loss: 0.1409\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1387\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1408\n",
      "Epoch [645/2000], Avg Train Loss: 0.1387, Avg Val Loss: 0.1408\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1426\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1406\n",
      "Epoch [646/2000], Avg Train Loss: 0.1426, Avg Val Loss: 0.1406\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1371\n",
      "LOG: Epoch [647/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1405\n",
      "Epoch [647/2000], Avg Train Loss: 0.1371, Avg Val Loss: 0.1405\n",
      "\n",
      "Validation loss improved from 0.1406 to 0.1405. Saving model...\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1354\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1403\n",
      "Epoch [648/2000], Avg Train Loss: 0.1354, Avg Val Loss: 0.1403\n",
      "\n",
      "Validation loss improved from 0.1405 to 0.1403. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1399\n",
      "LOG: Epoch [649/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1402\n",
      "Epoch [649/2000], Avg Train Loss: 0.1399, Avg Val Loss: 0.1402\n",
      "\n",
      "Validation loss improved from 0.1403 to 0.1402. Saving model...\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1338\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1401\n",
      "Epoch [650/2000], Avg Train Loss: 0.1338, Avg Val Loss: 0.1401\n",
      "\n",
      "Validation loss improved from 0.1402 to 0.1401. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1411\n",
      "LOG: Epoch [651/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1400\n",
      "Epoch [651/2000], Avg Train Loss: 0.1411, Avg Val Loss: 0.1400\n",
      "\n",
      "Validation loss improved from 0.1401 to 0.1400. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1382\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1400\n",
      "Epoch [652/2000], Avg Train Loss: 0.1382, Avg Val Loss: 0.1400\n",
      "\n",
      "Validation loss improved from 0.1400 to 0.1400. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1413\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1399\n",
      "Epoch [653/2000], Avg Train Loss: 0.1413, Avg Val Loss: 0.1399\n",
      "\n",
      "Validation loss improved from 0.1400 to 0.1399. Saving model...\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1404\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1399\n",
      "Epoch [654/2000], Avg Train Loss: 0.1404, Avg Val Loss: 0.1399\n",
      "\n",
      "Validation loss improved from 0.1399 to 0.1399. Saving model...\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1393\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1398\n",
      "Epoch [655/2000], Avg Train Loss: 0.1393, Avg Val Loss: 0.1398\n",
      "\n",
      "Validation loss improved from 0.1399 to 0.1398. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1423\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1398\n",
      "Epoch [656/2000], Avg Train Loss: 0.1423, Avg Val Loss: 0.1398\n",
      "\n",
      "Validation loss improved from 0.1398 to 0.1398. Saving model...\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1380\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1397\n",
      "Epoch [657/2000], Avg Train Loss: 0.1380, Avg Val Loss: 0.1397\n",
      "\n",
      "Validation loss improved from 0.1398 to 0.1397. Saving model...\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1349\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1397\n",
      "Epoch [658/2000], Avg Train Loss: 0.1349, Avg Val Loss: 0.1397\n",
      "\n",
      "Validation loss improved from 0.1397 to 0.1397. Saving model...\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1401\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1396\n",
      "Epoch [659/2000], Avg Train Loss: 0.1401, Avg Val Loss: 0.1396\n",
      "\n",
      "Validation loss improved from 0.1397 to 0.1396. Saving model...\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1405\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1394\n",
      "Epoch [660/2000], Avg Train Loss: 0.1405, Avg Val Loss: 0.1394\n",
      "\n",
      "Validation loss improved from 0.1396 to 0.1394. Saving model...\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1385\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1393\n",
      "Epoch [661/2000], Avg Train Loss: 0.1385, Avg Val Loss: 0.1393\n",
      "\n",
      "Validation loss improved from 0.1394 to 0.1393. Saving model...\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1323\n",
      "LOG: Epoch [662/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1393\n",
      "Epoch [662/2000], Avg Train Loss: 0.1323, Avg Val Loss: 0.1393\n",
      "\n",
      "Validation loss improved from 0.1393 to 0.1393. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1406\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1392\n",
      "Epoch [663/2000], Avg Train Loss: 0.1406, Avg Val Loss: 0.1392\n",
      "\n",
      "Validation loss improved from 0.1393 to 0.1392. Saving model...\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1422\n",
      "LOG: Epoch [664/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1390\n",
      "Epoch [664/2000], Avg Train Loss: 0.1422, Avg Val Loss: 0.1390\n",
      "\n",
      "Validation loss improved from 0.1392 to 0.1390. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1339\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1389\n",
      "Epoch [665/2000], Avg Train Loss: 0.1339, Avg Val Loss: 0.1389\n",
      "\n",
      "Validation loss improved from 0.1390 to 0.1389. Saving model...\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1340\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1388\n",
      "Epoch [666/2000], Avg Train Loss: 0.1340, Avg Val Loss: 0.1388\n",
      "\n",
      "Validation loss improved from 0.1389 to 0.1388. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1390\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1387\n",
      "Epoch [667/2000], Avg Train Loss: 0.1390, Avg Val Loss: 0.1387\n",
      "\n",
      "Validation loss improved from 0.1388 to 0.1387. Saving model...\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1376\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1386\n",
      "Epoch [668/2000], Avg Train Loss: 0.1376, Avg Val Loss: 0.1386\n",
      "\n",
      "Validation loss improved from 0.1387 to 0.1386. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1402\n",
      "LOG: Epoch [669/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1385\n",
      "Epoch [669/2000], Avg Train Loss: 0.1402, Avg Val Loss: 0.1385\n",
      "\n",
      "Validation loss improved from 0.1386 to 0.1385. Saving model...\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1367\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1385\n",
      "Epoch [670/2000], Avg Train Loss: 0.1367, Avg Val Loss: 0.1385\n",
      "\n",
      "Validation loss improved from 0.1385 to 0.1385. Saving model...\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1339\n",
      "LOG: Epoch [671/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1385\n",
      "Epoch [671/2000], Avg Train Loss: 0.1339, Avg Val Loss: 0.1385\n",
      "\n",
      "Validation loss improved from 0.1385 to 0.1385. Saving model...\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1419\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1384\n",
      "Epoch [672/2000], Avg Train Loss: 0.1419, Avg Val Loss: 0.1384\n",
      "\n",
      "Validation loss improved from 0.1385 to 0.1384. Saving model...\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1370\n",
      "LOG: Epoch [673/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1382\n",
      "Epoch [673/2000], Avg Train Loss: 0.1370, Avg Val Loss: 0.1382\n",
      "\n",
      "Validation loss improved from 0.1384 to 0.1382. Saving model...\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1313\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1381\n",
      "Epoch [674/2000], Avg Train Loss: 0.1313, Avg Val Loss: 0.1381\n",
      "\n",
      "Validation loss improved from 0.1382 to 0.1381. Saving model...\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1332\n",
      "LOG: Epoch [675/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1381\n",
      "Epoch [675/2000], Avg Train Loss: 0.1332, Avg Val Loss: 0.1381\n",
      "\n",
      "Validation loss improved from 0.1381 to 0.1381. Saving model...\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1343\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1380\n",
      "Epoch [676/2000], Avg Train Loss: 0.1343, Avg Val Loss: 0.1380\n",
      "\n",
      "Validation loss improved from 0.1381 to 0.1380. Saving model...\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1355\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1379\n",
      "Epoch [677/2000], Avg Train Loss: 0.1355, Avg Val Loss: 0.1379\n",
      "\n",
      "Validation loss improved from 0.1380 to 0.1379. Saving model...\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1351\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1378\n",
      "Epoch [678/2000], Avg Train Loss: 0.1351, Avg Val Loss: 0.1378\n",
      "\n",
      "Validation loss improved from 0.1379 to 0.1378. Saving model...\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1421\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1377\n",
      "Epoch [679/2000], Avg Train Loss: 0.1421, Avg Val Loss: 0.1377\n",
      "\n",
      "Validation loss improved from 0.1378 to 0.1377. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1387\n",
      "LOG: Epoch [680/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1376\n",
      "Epoch [680/2000], Avg Train Loss: 0.1387, Avg Val Loss: 0.1376\n",
      "\n",
      "Validation loss improved from 0.1377 to 0.1376. Saving model...\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1376\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1375\n",
      "Epoch [681/2000], Avg Train Loss: 0.1376, Avg Val Loss: 0.1375\n",
      "\n",
      "Validation loss improved from 0.1376 to 0.1375. Saving model...\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1306\n",
      "LOG: Epoch [682/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1375\n",
      "Epoch [682/2000], Avg Train Loss: 0.1306, Avg Val Loss: 0.1375\n",
      "\n",
      "Validation loss improved from 0.1375 to 0.1375. Saving model...\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1438\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1374\n",
      "Epoch [683/2000], Avg Train Loss: 0.1438, Avg Val Loss: 0.1374\n",
      "\n",
      "Validation loss improved from 0.1375 to 0.1374. Saving model...\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1350\n",
      "LOG: Epoch [684/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1373\n",
      "Epoch [684/2000], Avg Train Loss: 0.1350, Avg Val Loss: 0.1373\n",
      "\n",
      "Validation loss improved from 0.1374 to 0.1373. Saving model...\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1357\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [685/2000], Avg Train Loss: 0.1357, Avg Val Loss: 0.1372\n",
      "\n",
      "Validation loss improved from 0.1373 to 0.1372. Saving model...\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1383\n",
      "LOG: Epoch [686/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [686/2000], Avg Train Loss: 0.1383, Avg Val Loss: 0.1372\n",
      "\n",
      "Validation loss improved from 0.1372 to 0.1372. Saving model...\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1357\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [687/2000], Avg Train Loss: 0.1357, Avg Val Loss: 0.1371\n",
      "\n",
      "Validation loss improved from 0.1372 to 0.1371. Saving model...\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1328\n",
      "LOG: Epoch [688/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [688/2000], Avg Train Loss: 0.1328, Avg Val Loss: 0.1371\n",
      "\n",
      "Validation loss improved from 0.1371 to 0.1371. Saving model...\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [689/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.1371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1318\n",
      "LOG: Epoch [690/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [690/2000], Avg Train Loss: 0.1318, Avg Val Loss: 0.1371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1312\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [691/2000], Avg Train Loss: 0.1312, Avg Val Loss: 0.1371\n",
      "\n",
      "Validation loss improved from 0.1371 to 0.1371. Saving model...\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1285\n",
      "LOG: Epoch [692/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [692/2000], Avg Train Loss: 0.1285, Avg Val Loss: 0.1371\n",
      "\n",
      "Validation loss improved from 0.1371 to 0.1371. Saving model...\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [693/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.1371\n",
      "\n",
      "Validation loss improved from 0.1371 to 0.1371. Saving model...\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1330\n",
      "LOG: Epoch [694/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [694/2000], Avg Train Loss: 0.1330, Avg Val Loss: 0.1371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [695/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.1371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1352\n",
      "LOG: Epoch [696/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [696/2000], Avg Train Loss: 0.1352, Avg Val Loss: 0.1371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1344\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1371\n",
      "Epoch [697/2000], Avg Train Loss: 0.1344, Avg Val Loss: 0.1371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [698/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [698/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [699/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1350\n",
      "LOG: Epoch [700/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1373\n",
      "Epoch [700/2000], Avg Train Loss: 0.1350, Avg Val Loss: 0.1373\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1374\n",
      "Epoch [701/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.1374\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [702/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1374\n",
      "Epoch [702/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.1374\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1375\n",
      "Epoch [703/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.1375\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1341\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1375\n",
      "Epoch [704/2000], Avg Train Loss: 0.1341, Avg Val Loss: 0.1375\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1345\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1375\n",
      "Epoch [705/2000], Avg Train Loss: 0.1345, Avg Val Loss: 0.1375\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1336\n",
      "LOG: Epoch [706/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1375\n",
      "Epoch [706/2000], Avg Train Loss: 0.1336, Avg Val Loss: 0.1375\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1347\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1374\n",
      "Epoch [707/2000], Avg Train Loss: 0.1347, Avg Val Loss: 0.1374\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1356\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1374\n",
      "Epoch [708/2000], Avg Train Loss: 0.1356, Avg Val Loss: 0.1374\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1291\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1373\n",
      "Epoch [709/2000], Avg Train Loss: 0.1291, Avg Val Loss: 0.1373\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1316\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1373\n",
      "Epoch [710/2000], Avg Train Loss: 0.1316, Avg Val Loss: 0.1373\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1320\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1373\n",
      "Epoch [711/2000], Avg Train Loss: 0.1320, Avg Val Loss: 0.1373\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1303\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [712/2000], Avg Train Loss: 0.1303, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1312\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [713/2000], Avg Train Loss: 0.1312, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [714/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [715/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1270\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1372\n",
      "Epoch [716/2000], Avg Train Loss: 0.1270, Avg Val Loss: 0.1372\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1324\n",
      "LOG: Epoch [717/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1370\n",
      "Epoch [717/2000], Avg Train Loss: 0.1324, Avg Val Loss: 0.1370\n",
      "\n",
      "Validation loss improved from 0.1371 to 0.1370. Saving model...\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1314\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1369\n",
      "Epoch [718/2000], Avg Train Loss: 0.1314, Avg Val Loss: 0.1369\n",
      "\n",
      "Validation loss improved from 0.1370 to 0.1369. Saving model...\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1308\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1367\n",
      "Epoch [719/2000], Avg Train Loss: 0.1308, Avg Val Loss: 0.1367\n",
      "\n",
      "Validation loss improved from 0.1369 to 0.1367. Saving model...\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1277\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1366\n",
      "Epoch [720/2000], Avg Train Loss: 0.1277, Avg Val Loss: 0.1366\n",
      "\n",
      "Validation loss improved from 0.1367 to 0.1366. Saving model...\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1364\n",
      "Epoch [721/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.1364\n",
      "\n",
      "Validation loss improved from 0.1366 to 0.1364. Saving model...\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1348\n",
      "LOG: Epoch [722/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1362\n",
      "Epoch [722/2000], Avg Train Loss: 0.1348, Avg Val Loss: 0.1362\n",
      "\n",
      "Validation loss improved from 0.1364 to 0.1362. Saving model...\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1361\n",
      "Epoch [723/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.1361\n",
      "\n",
      "Validation loss improved from 0.1362 to 0.1361. Saving model...\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [724/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.1359\n",
      "\n",
      "Validation loss improved from 0.1361 to 0.1359. Saving model...\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1302\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [725/2000], Avg Train Loss: 0.1302, Avg Val Loss: 0.1358\n",
      "\n",
      "Validation loss improved from 0.1359 to 0.1358. Saving model...\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1302\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [726/2000], Avg Train Loss: 0.1302, Avg Val Loss: 0.1357\n",
      "\n",
      "Validation loss improved from 0.1358 to 0.1357. Saving model...\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1299\n",
      "LOG: Epoch [727/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1356\n",
      "Epoch [727/2000], Avg Train Loss: 0.1299, Avg Val Loss: 0.1356\n",
      "\n",
      "Validation loss improved from 0.1357 to 0.1356. Saving model...\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1281\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1356\n",
      "Epoch [728/2000], Avg Train Loss: 0.1281, Avg Val Loss: 0.1356\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [729/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.1357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [730/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1304\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [731/2000], Avg Train Loss: 0.1304, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [732/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1284\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [733/2000], Avg Train Loss: 0.1284, Avg Val Loss: 0.1359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1290\n",
      "LOG: Epoch [734/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [734/2000], Avg Train Loss: 0.1290, Avg Val Loss: 0.1359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [735/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.1359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1241\n",
      "LOG: Epoch [736/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [736/2000], Avg Train Loss: 0.1241, Avg Val Loss: 0.1359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1286\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [737/2000], Avg Train Loss: 0.1286, Avg Val Loss: 0.1359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1239\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1360\n",
      "Epoch [738/2000], Avg Train Loss: 0.1239, Avg Val Loss: 0.1360\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1361\n",
      "Epoch [739/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.1361\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1237\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1361\n",
      "Epoch [740/2000], Avg Train Loss: 0.1237, Avg Val Loss: 0.1361\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1265\n",
      "LOG: Epoch [741/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1361\n",
      "Epoch [741/2000], Avg Train Loss: 0.1265, Avg Val Loss: 0.1361\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1360\n",
      "Epoch [742/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.1360\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1282\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1359\n",
      "Epoch [743/2000], Avg Train Loss: 0.1282, Avg Val Loss: 0.1359\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1252\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [744/2000], Avg Train Loss: 0.1252, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1263\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [745/2000], Avg Train Loss: 0.1263, Avg Val Loss: 0.1357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1254\n",
      "LOG: Epoch [746/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1356\n",
      "Epoch [746/2000], Avg Train Loss: 0.1254, Avg Val Loss: 0.1356\n",
      "\n",
      "Validation loss improved from 0.1356 to 0.1356. Saving model...\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1355\n",
      "Epoch [747/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.1355\n",
      "\n",
      "Validation loss improved from 0.1356 to 0.1355. Saving model...\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1315\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1354\n",
      "Epoch [748/2000], Avg Train Loss: 0.1315, Avg Val Loss: 0.1354\n",
      "\n",
      "Validation loss improved from 0.1355 to 0.1354. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [749/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.1353\n",
      "\n",
      "Validation loss improved from 0.1354 to 0.1353. Saving model...\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [750/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.1353\n",
      "\n",
      "Validation loss improved from 0.1353 to 0.1353. Saving model...\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [751/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [751/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.1353\n",
      "\n",
      "Validation loss improved from 0.1353 to 0.1353. Saving model...\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1261\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [752/2000], Avg Train Loss: 0.1261, Avg Val Loss: 0.1352\n",
      "\n",
      "Validation loss improved from 0.1353 to 0.1352. Saving model...\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1296\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [753/2000], Avg Train Loss: 0.1296, Avg Val Loss: 0.1352\n",
      "\n",
      "Validation loss improved from 0.1352 to 0.1352. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [754/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.1352\n",
      "\n",
      "Validation loss improved from 0.1352 to 0.1352. Saving model...\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1275\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [755/2000], Avg Train Loss: 0.1275, Avg Val Loss: 0.1352\n",
      "\n",
      "Validation loss improved from 0.1352 to 0.1352. Saving model...\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1347\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [756/2000], Avg Train Loss: 0.1347, Avg Val Loss: 0.1351\n",
      "\n",
      "Validation loss improved from 0.1352 to 0.1351. Saving model...\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1215\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [757/2000], Avg Train Loss: 0.1215, Avg Val Loss: 0.1351\n",
      "\n",
      "Validation loss improved from 0.1351 to 0.1351. Saving model...\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [758/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.1352\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1293\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [759/2000], Avg Train Loss: 0.1293, Avg Val Loss: 0.1351\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [760/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.1351\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [761/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.1351\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [762/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.1351\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [763/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.1352\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [764/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [764/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.1352\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1243\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [765/2000], Avg Train Loss: 0.1243, Avg Val Loss: 0.1353\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1294\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1354\n",
      "Epoch [766/2000], Avg Train Loss: 0.1294, Avg Val Loss: 0.1354\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1184\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1355\n",
      "Epoch [767/2000], Avg Train Loss: 0.1184, Avg Val Loss: 0.1355\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1235\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [768/2000], Avg Train Loss: 0.1235, Avg Val Loss: 0.1357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1255\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [769/2000], Avg Train Loss: 0.1255, Avg Val Loss: 0.1357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [770/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [771/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1358\n",
      "Epoch [772/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.1358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [773/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.1357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1245\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1357\n",
      "Epoch [774/2000], Avg Train Loss: 0.1245, Avg Val Loss: 0.1357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1192\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1356\n",
      "Epoch [775/2000], Avg Train Loss: 0.1192, Avg Val Loss: 0.1356\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1355\n",
      "Epoch [776/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.1355\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1230\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1354\n",
      "Epoch [777/2000], Avg Train Loss: 0.1230, Avg Val Loss: 0.1354\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1354\n",
      "Epoch [778/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.1354\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1201\n",
      "LOG: Epoch [779/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [779/2000], Avg Train Loss: 0.1201, Avg Val Loss: 0.1353\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [780/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.1353\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1197\n",
      "LOG: Epoch [781/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [781/2000], Avg Train Loss: 0.1197, Avg Val Loss: 0.1353\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1159\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1353\n",
      "Epoch [782/2000], Avg Train Loss: 0.1159, Avg Val Loss: 0.1353\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [783/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.1352\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1208\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1352\n",
      "Epoch [784/2000], Avg Train Loss: 0.1208, Avg Val Loss: 0.1352\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1274\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [785/2000], Avg Train Loss: 0.1274, Avg Val Loss: 0.1351\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1280\n",
      "LOG: Epoch [786/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [786/2000], Avg Train Loss: 0.1280, Avg Val Loss: 0.1351\n",
      "\n",
      "Validation loss improved from 0.1351 to 0.1351. Saving model...\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1191\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [787/2000], Avg Train Loss: 0.1191, Avg Val Loss: 0.1351\n",
      "\n",
      "Validation loss improved from 0.1351 to 0.1351. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1250\n",
      "LOG: Epoch [788/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1351\n",
      "Epoch [788/2000], Avg Train Loss: 0.1250, Avg Val Loss: 0.1351\n",
      "\n",
      "Validation loss improved from 0.1351 to 0.1351. Saving model...\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1184\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1350\n",
      "Epoch [789/2000], Avg Train Loss: 0.1184, Avg Val Loss: 0.1350\n",
      "\n",
      "Validation loss improved from 0.1351 to 0.1350. Saving model...\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1262\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1350\n",
      "Epoch [790/2000], Avg Train Loss: 0.1262, Avg Val Loss: 0.1350\n",
      "\n",
      "Validation loss improved from 0.1350 to 0.1350. Saving model...\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1350\n",
      "Epoch [791/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.1350\n",
      "\n",
      "Validation loss improved from 0.1350 to 0.1350. Saving model...\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1349\n",
      "Epoch [792/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.1349\n",
      "\n",
      "Validation loss improved from 0.1350 to 0.1349. Saving model...\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1170\n",
      "LOG: Epoch [793/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1349\n",
      "Epoch [793/2000], Avg Train Loss: 0.1170, Avg Val Loss: 0.1349\n",
      "\n",
      "Validation loss improved from 0.1349 to 0.1349. Saving model...\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1224\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1349\n",
      "Epoch [794/2000], Avg Train Loss: 0.1224, Avg Val Loss: 0.1349\n",
      "\n",
      "Validation loss improved from 0.1349 to 0.1349. Saving model...\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [795/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1349\n",
      "Epoch [795/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.1349\n",
      "\n",
      "Validation loss improved from 0.1349 to 0.1349. Saving model...\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1348\n",
      "Epoch [796/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.1348\n",
      "\n",
      "Validation loss improved from 0.1349 to 0.1348. Saving model...\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1215\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1348\n",
      "Epoch [797/2000], Avg Train Loss: 0.1215, Avg Val Loss: 0.1348\n",
      "\n",
      "Validation loss improved from 0.1348 to 0.1348. Saving model...\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1179\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1348\n",
      "Epoch [798/2000], Avg Train Loss: 0.1179, Avg Val Loss: 0.1348\n",
      "\n",
      "Validation loss improved from 0.1348 to 0.1348. Saving model...\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1347\n",
      "Epoch [799/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.1347\n",
      "\n",
      "Validation loss improved from 0.1348 to 0.1347. Saving model...\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [800/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1347\n",
      "Epoch [800/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.1347\n",
      "\n",
      "Validation loss improved from 0.1347 to 0.1347. Saving model...\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1347\n",
      "Epoch [801/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.1347\n",
      "\n",
      "Validation loss improved from 0.1347 to 0.1347. Saving model...\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1164\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1347\n",
      "Epoch [802/2000], Avg Train Loss: 0.1164, Avg Val Loss: 0.1347\n",
      "\n",
      "Validation loss improved from 0.1347 to 0.1347. Saving model...\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1346\n",
      "Epoch [803/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.1346\n",
      "\n",
      "Validation loss improved from 0.1347 to 0.1346. Saving model...\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1346\n",
      "Epoch [804/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.1346\n",
      "\n",
      "Validation loss improved from 0.1346 to 0.1346. Saving model...\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1346\n",
      "Epoch [805/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.1346\n",
      "\n",
      "Validation loss improved from 0.1346 to 0.1346. Saving model...\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1346\n",
      "Epoch [806/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.1346\n",
      "\n",
      "Validation loss improved from 0.1346 to 0.1346. Saving model...\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1345\n",
      "Epoch [807/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.1345\n",
      "\n",
      "Validation loss improved from 0.1346 to 0.1345. Saving model...\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1200\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1345\n",
      "Epoch [808/2000], Avg Train Loss: 0.1200, Avg Val Loss: 0.1345\n",
      "\n",
      "Validation loss improved from 0.1345 to 0.1345. Saving model...\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1345\n",
      "Epoch [809/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.1345\n",
      "\n",
      "Validation loss improved from 0.1345 to 0.1345. Saving model...\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1225\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1345\n",
      "Epoch [810/2000], Avg Train Loss: 0.1225, Avg Val Loss: 0.1345\n",
      "\n",
      "Validation loss improved from 0.1345 to 0.1345. Saving model...\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1197\n",
      "LOG: Epoch [811/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1344\n",
      "Epoch [811/2000], Avg Train Loss: 0.1197, Avg Val Loss: 0.1344\n",
      "\n",
      "Validation loss improved from 0.1345 to 0.1344. Saving model...\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1192\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1344\n",
      "Epoch [812/2000], Avg Train Loss: 0.1192, Avg Val Loss: 0.1344\n",
      "\n",
      "Validation loss improved from 0.1344 to 0.1344. Saving model...\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1200\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1344\n",
      "Epoch [813/2000], Avg Train Loss: 0.1200, Avg Val Loss: 0.1344\n",
      "\n",
      "Validation loss improved from 0.1344 to 0.1344. Saving model...\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1210\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1344\n",
      "Epoch [814/2000], Avg Train Loss: 0.1210, Avg Val Loss: 0.1344\n",
      "\n",
      "Validation loss improved from 0.1344 to 0.1344. Saving model...\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1343\n",
      "Epoch [815/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.1343\n",
      "\n",
      "Validation loss improved from 0.1344 to 0.1343. Saving model...\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1343\n",
      "Epoch [816/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.1343\n",
      "\n",
      "Validation loss improved from 0.1343 to 0.1343. Saving model...\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1343\n",
      "Epoch [817/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.1343\n",
      "\n",
      "Validation loss improved from 0.1343 to 0.1343. Saving model...\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1343\n",
      "Epoch [818/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.1343\n",
      "\n",
      "Validation loss improved from 0.1343 to 0.1343. Saving model...\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1173\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1343\n",
      "Epoch [819/2000], Avg Train Loss: 0.1173, Avg Val Loss: 0.1343\n",
      "\n",
      "Validation loss improved from 0.1343 to 0.1343. Saving model...\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1343\n",
      "Epoch [820/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.1343\n",
      "\n",
      "Validation loss improved from 0.1343 to 0.1343. Saving model...\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [821/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1343 to 0.1342. Saving model...\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1164\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [822/2000], Avg Train Loss: 0.1164, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [823/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1236\n",
      "LOG: Epoch [824/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [824/2000], Avg Train Loss: 0.1236, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1192\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [825/2000], Avg Train Loss: 0.1192, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [826/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [827/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [828/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [829/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [829/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1260\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [830/2000], Avg Train Loss: 0.1260, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1231\n",
      "LOG: Epoch [831/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [831/2000], Avg Train Loss: 0.1231, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1131\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [832/2000], Avg Train Loss: 0.1131, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1215\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [833/2000], Avg Train Loss: 0.1215, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1342\n",
      "Epoch [834/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.1342\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1342. Saving model...\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [835/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1342 to 0.1341. Saving model...\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [836/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [836/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [837/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1155\n",
      "LOG: Epoch [838/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [838/2000], Avg Train Loss: 0.1155, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1169\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [839/2000], Avg Train Loss: 0.1169, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1221\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [840/2000], Avg Train Loss: 0.1221, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1172\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [841/2000], Avg Train Loss: 0.1172, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1198\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [842/2000], Avg Train Loss: 0.1198, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1223\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [843/2000], Avg Train Loss: 0.1223, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1242\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1341\n",
      "Epoch [844/2000], Avg Train Loss: 0.1242, Avg Val Loss: 0.1341\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1341. Saving model...\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1170\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [845/2000], Avg Train Loss: 0.1170, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1341 to 0.1340. Saving model...\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1157\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [846/2000], Avg Train Loss: 0.1157, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1340. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1247\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [847/2000], Avg Train Loss: 0.1247, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1340. Saving model...\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1165\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [848/2000], Avg Train Loss: 0.1165, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1340. Saving model...\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [849/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1340. Saving model...\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [850/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1340. Saving model...\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1340\n",
      "Epoch [851/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.1340\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1340. Saving model...\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1185\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1339\n",
      "Epoch [852/2000], Avg Train Loss: 0.1185, Avg Val Loss: 0.1339\n",
      "\n",
      "Validation loss improved from 0.1340 to 0.1339. Saving model...\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1339\n",
      "Epoch [853/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.1339\n",
      "\n",
      "Validation loss improved from 0.1339 to 0.1339. Saving model...\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1208\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1339\n",
      "Epoch [854/2000], Avg Train Loss: 0.1208, Avg Val Loss: 0.1339\n",
      "\n",
      "Validation loss improved from 0.1339 to 0.1339. Saving model...\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1196\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1339\n",
      "Epoch [855/2000], Avg Train Loss: 0.1196, Avg Val Loss: 0.1339\n",
      "\n",
      "Validation loss improved from 0.1339 to 0.1339. Saving model...\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [856/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1339\n",
      "Epoch [856/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.1339\n",
      "\n",
      "Validation loss improved from 0.1339 to 0.1339. Saving model...\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [857/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1339 to 0.1338. Saving model...\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [858/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [858/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1152\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [859/2000], Avg Train Loss: 0.1152, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1229\n",
      "LOG: Epoch [860/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [860/2000], Avg Train Loss: 0.1229, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [861/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1173\n",
      "LOG: Epoch [862/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [862/2000], Avg Train Loss: 0.1173, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1163\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [863/2000], Avg Train Loss: 0.1163, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1217\n",
      "LOG: Epoch [864/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [864/2000], Avg Train Loss: 0.1217, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1160\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1338\n",
      "Epoch [865/2000], Avg Train Loss: 0.1160, Avg Val Loss: 0.1338\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1338. Saving model...\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [866/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1338 to 0.1337. Saving model...\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1171\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [867/2000], Avg Train Loss: 0.1171, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [868/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [868/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1137\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [869/2000], Avg Train Loss: 0.1137, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1174\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [870/2000], Avg Train Loss: 0.1174, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1177\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [871/2000], Avg Train Loss: 0.1177, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1215\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [872/2000], Avg Train Loss: 0.1215, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1181\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [873/2000], Avg Train Loss: 0.1181, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [874/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1234\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [875/2000], Avg Train Loss: 0.1234, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1125\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [876/2000], Avg Train Loss: 0.1125, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [877/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [877/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1165\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [878/2000], Avg Train Loss: 0.1165, Avg Val Loss: 0.1337\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1337. Saving model...\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1204\n",
      "LOG: Epoch [879/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [879/2000], Avg Train Loss: 0.1204, Avg Val Loss: 0.1336\n",
      "\n",
      "Validation loss improved from 0.1337 to 0.1336. Saving model...\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1179\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [880/2000], Avg Train Loss: 0.1179, Avg Val Loss: 0.1336\n",
      "\n",
      "Validation loss improved from 0.1336 to 0.1336. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1188\n",
      "LOG: Epoch [881/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [881/2000], Avg Train Loss: 0.1188, Avg Val Loss: 0.1336\n",
      "\n",
      "Validation loss improved from 0.1336 to 0.1336. Saving model...\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1222\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [882/2000], Avg Train Loss: 0.1222, Avg Val Loss: 0.1336\n",
      "\n",
      "Validation loss improved from 0.1336 to 0.1336. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1196\n",
      "LOG: Epoch [883/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [883/2000], Avg Train Loss: 0.1196, Avg Val Loss: 0.1336\n",
      "\n",
      "Validation loss improved from 0.1336 to 0.1336. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [884/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.1336\n",
      "\n",
      "Validation loss improved from 0.1336 to 0.1336. Saving model...\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1157\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [885/2000], Avg Train Loss: 0.1157, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [886/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1156\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [887/2000], Avg Train Loss: 0.1156, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1188\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [888/2000], Avg Train Loss: 0.1188, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [889/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [890/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1142\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [891/2000], Avg Train Loss: 0.1142, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [892/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1165\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [893/2000], Avg Train Loss: 0.1165, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1158\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [894/2000], Avg Train Loss: 0.1158, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1128\n",
      "LOG: Epoch [895/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [895/2000], Avg Train Loss: 0.1128, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1214\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [896/2000], Avg Train Loss: 0.1214, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1202\n",
      "LOG: Epoch [897/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [897/2000], Avg Train Loss: 0.1202, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [898/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [899/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [899/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1220\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [900/2000], Avg Train Loss: 0.1220, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1177\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [901/2000], Avg Train Loss: 0.1177, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1209\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [902/2000], Avg Train Loss: 0.1209, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [903/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [904/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1256\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [905/2000], Avg Train Loss: 0.1256, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [906/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1162\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [907/2000], Avg Train Loss: 0.1162, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1226\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [908/2000], Avg Train Loss: 0.1226, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1193\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [909/2000], Avg Train Loss: 0.1193, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1149\n",
      "LOG: Epoch [910/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [910/2000], Avg Train Loss: 0.1149, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [911/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1123\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [912/2000], Avg Train Loss: 0.1123, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1181\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [913/2000], Avg Train Loss: 0.1181, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1161\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [914/2000], Avg Train Loss: 0.1161, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1190\n",
      "LOG: Epoch [915/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1337\n",
      "Epoch [915/2000], Avg Train Loss: 0.1190, Avg Val Loss: 0.1337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1172\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [916/2000], Avg Train Loss: 0.1172, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1168\n",
      "LOG: Epoch [917/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [917/2000], Avg Train Loss: 0.1168, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1218\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [918/2000], Avg Train Loss: 0.1218, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1146\n",
      "LOG: Epoch [919/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [919/2000], Avg Train Loss: 0.1146, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1174\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [920/2000], Avg Train Loss: 0.1174, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1149\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [921/2000], Avg Train Loss: 0.1149, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1170\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [922/2000], Avg Train Loss: 0.1170, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1196\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [923/2000], Avg Train Loss: 0.1196, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1200\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [924/2000], Avg Train Loss: 0.1200, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1144\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [925/2000], Avg Train Loss: 0.1144, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1183\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [926/2000], Avg Train Loss: 0.1183, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1147\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [927/2000], Avg Train Loss: 0.1147, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1179\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [928/2000], Avg Train Loss: 0.1179, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1149\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [929/2000], Avg Train Loss: 0.1149, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1173\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [930/2000], Avg Train Loss: 0.1173, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1246\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [931/2000], Avg Train Loss: 0.1246, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1201\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [932/2000], Avg Train Loss: 0.1201, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1227\n",
      "LOG: Epoch [933/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [933/2000], Avg Train Loss: 0.1227, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [934/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1172\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [935/2000], Avg Train Loss: 0.1172, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1191\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [936/2000], Avg Train Loss: 0.1191, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1181\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [937/2000], Avg Train Loss: 0.1181, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [938/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1205\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [939/2000], Avg Train Loss: 0.1205, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [940/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1162\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [941/2000], Avg Train Loss: 0.1162, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1199\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [942/2000], Avg Train Loss: 0.1199, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1174\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [943/2000], Avg Train Loss: 0.1174, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1175\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [944/2000], Avg Train Loss: 0.1175, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1181\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [945/2000], Avg Train Loss: 0.1181, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1212\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [946/2000], Avg Train Loss: 0.1212, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1159\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [947/2000], Avg Train Loss: 0.1159, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1170\n",
      "LOG: Epoch [948/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [948/2000], Avg Train Loss: 0.1170, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1152\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [949/2000], Avg Train Loss: 0.1152, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [950/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [950/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1211\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [951/2000], Avg Train Loss: 0.1211, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1150\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [952/2000], Avg Train Loss: 0.1150, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1203\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [953/2000], Avg Train Loss: 0.1203, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1195\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [954/2000], Avg Train Loss: 0.1195, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1139\n",
      "LOG: Epoch [955/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [955/2000], Avg Train Loss: 0.1139, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1165\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [956/2000], Avg Train Loss: 0.1165, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1206\n",
      "LOG: Epoch [957/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [957/2000], Avg Train Loss: 0.1206, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1174\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [958/2000], Avg Train Loss: 0.1174, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1210\n",
      "LOG: Epoch [959/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [959/2000], Avg Train Loss: 0.1210, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1185\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [960/2000], Avg Train Loss: 0.1185, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1176\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [961/2000], Avg Train Loss: 0.1176, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1194\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [962/2000], Avg Train Loss: 0.1194, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1162\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [963/2000], Avg Train Loss: 0.1162, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1216\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [964/2000], Avg Train Loss: 0.1216, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1176\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [965/2000], Avg Train Loss: 0.1176, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [966/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1176\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [967/2000], Avg Train Loss: 0.1176, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1213\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [968/2000], Avg Train Loss: 0.1213, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1228\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [969/2000], Avg Train Loss: 0.1228, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1187\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [970/2000], Avg Train Loss: 0.1187, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1180\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [971/2000], Avg Train Loss: 0.1180, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1233\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [972/2000], Avg Train Loss: 0.1233, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1207\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [973/2000], Avg Train Loss: 0.1207, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1269\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [974/2000], Avg Train Loss: 0.1269, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1186\n",
      "LOG: Epoch [975/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [975/2000], Avg Train Loss: 0.1186, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1138\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [976/2000], Avg Train Loss: 0.1138, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1176\n",
      "LOG: Epoch [977/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [977/2000], Avg Train Loss: 0.1176, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1185\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [978/2000], Avg Train Loss: 0.1185, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [979/2000], Avg Train Loss: 0.1156, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1189\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [980/2000], Avg Train Loss: 0.1189, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1155\n",
      "LOG: Epoch [981/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [981/2000], Avg Train Loss: 0.1155, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1219\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [982/2000], Avg Train Loss: 0.1219, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.1201\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [983/2000], Avg Train Loss: 0.1201, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.1244\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/1], Val Loss: 0.1336\n",
      "Epoch [984/2000], Avg Train Loss: 0.1244, Avg Val Loss: 0.1336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 984!!\n",
      "No improvement for 100 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:01.377227Z",
     "iopub.status.busy": "2025-05-08T17:32:01.376227Z",
     "iopub.status.idle": "2025-05-08T17:32:11.266483Z",
     "shell.execute_reply": "2025-05-08T17:32:11.265478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/2312], Loss: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [20/2312], Loss: 0.0644\n",
      "Test Batch [30/2312], Loss: 0.5000\n",
      "Test Batch [40/2312], Loss: 0.0334\n",
      "Test Batch [50/2312], Loss: 0.5000\n",
      "Test Batch [60/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [70/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [80/2312], Loss: 0.0844\n",
      "Test Batch [90/2312], Loss: 0.5000\n",
      "Test Batch [100/2312], Loss: 0.0611\n",
      "Test Batch [110/2312], Loss: 0.5000\n",
      "Test Batch [120/2312], Loss: 0.0628\n",
      "Test Batch [130/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [140/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [150/2312], Loss: 0.5000\n",
      "Test Batch [160/2312], Loss: 0.0899\n",
      "Test Batch [170/2312], Loss: 0.5000\n",
      "Test Batch [180/2312], Loss: 0.5000\n",
      "Test Batch [190/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [200/2312], Loss: 0.1066\n",
      "Test Batch [210/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [220/2312], Loss: 0.5000\n",
      "Test Batch [230/2312], Loss: 0.0754\n",
      "Test Batch [240/2312], Loss: 0.5000\n",
      "Test Batch [250/2312], Loss: 0.0729\n",
      "Test Batch [260/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [270/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [280/2312], Loss: 0.5000\n",
      "Test Batch [290/2312], Loss: 0.0400\n",
      "Test Batch [300/2312], Loss: 0.0802\n",
      "Test Batch [310/2312], Loss: 0.5000\n",
      "Test Batch [320/2312], Loss: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [330/2312], Loss: 0.5000\n",
      "Test Batch [340/2312], Loss: 0.5000\n",
      "Test Batch [350/2312], Loss: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [360/2312], Loss: 0.0939\n",
      "Test Batch [370/2312], Loss: 0.0788\n",
      "Test Batch [380/2312], Loss: 0.0695\n",
      "Test Batch [390/2312], Loss: 0.0333\n",
      "Test Batch [400/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [410/2312], Loss: 0.0401\n",
      "Test Batch [420/2312], Loss: 0.0608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [430/2312], Loss: 0.0969\n",
      "Test Batch [440/2312], Loss: 0.5000\n",
      "Test Batch [450/2312], Loss: 0.0666\n",
      "Test Batch [460/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [470/2312], Loss: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [480/2312], Loss: 0.0280\n",
      "Test Batch [490/2312], Loss: 0.5000\n",
      "Test Batch [500/2312], Loss: 0.0750\n",
      "Test Batch [510/2312], Loss: 0.5000\n",
      "Test Batch [520/2312], Loss: 0.0858\n",
      "Test Batch [530/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [540/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [550/2312], Loss: 0.0632\n",
      "Test Batch [560/2312], Loss: 0.5000\n",
      "Test Batch [570/2312], Loss: 0.5000\n",
      "Test Batch [580/2312], Loss: 0.0310\n",
      "Test Batch [590/2312], Loss: 0.0570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [600/2312], Loss: 0.5000\n",
      "Test Batch [610/2312], Loss: 0.5000\n",
      "Test Batch [620/2312], Loss: 0.0402\n",
      "Test Batch [630/2312], Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [640/2312], Loss: 0.1016\n",
      "Test Batch [650/2312], Loss: 0.5000\n",
      "Test Batch [660/2312], Loss: 0.0770\n",
      "Test Batch [670/2312], Loss: 0.0301\n",
      "Test Batch [680/2312], Loss: 0.5000\n",
      "Test Batch [690/2312], Loss: 0.5000\n",
      "Test Batch [700/2312], Loss: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [710/2312], Loss: 0.0267\n",
      "Test Batch [720/2312], Loss: 0.5000\n",
      "Test Batch [730/2312], Loss: 0.0279\n",
      "Test Batch [740/2312], Loss: 0.5000\n",
      "Test Batch [750/2312], Loss: 0.0527\n",
      "Test Batch [760/2312], Loss: 0.1129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [770/2312], Loss: 0.5000\n",
      "Test Batch [780/2312], Loss: 0.5000\n",
      "Test Batch [790/2312], Loss: 0.0120\n",
      "Test Batch [800/2312], Loss: 0.0875\n",
      "Test Batch [810/2312], Loss: 0.5000\n",
      "Test Batch [820/2312], Loss: 0.1066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [830/2312], Loss: 0.5000\n",
      "Test Batch [840/2312], Loss: 0.0431\n",
      "Test Batch [850/2312], Loss: 0.1875\n",
      "Test Batch [860/2312], Loss: 0.0302\n",
      "Test Batch [870/2312], Loss: 0.1297\n",
      "Test Batch [880/2312], Loss: 0.5000\n",
      "Test Batch [890/2312], Loss: 0.5000\n",
      "Test Batch [900/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [910/2312], Loss: 0.5000\n",
      "Test Batch [920/2312], Loss: 0.0399\n",
      "Test Batch [930/2312], Loss: 0.0930\n",
      "Test Batch [940/2312], Loss: 0.0570\n",
      "Test Batch [950/2312], Loss: 0.5000\n",
      "Test Batch [960/2312], Loss: 0.5000\n",
      "Test Batch [970/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [980/2312], Loss: 0.0456\n",
      "Test Batch [990/2312], Loss: 0.0267\n",
      "Test Batch [1000/2312], Loss: 0.0409\n",
      "Test Batch [1010/2312], Loss: 0.0131\n",
      "Test Batch [1020/2312], Loss: 0.0912\n",
      "Test Batch [1030/2312], Loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1040/2312], Loss: 0.0321\n",
      "Test Batch [1050/2312], Loss: 0.0835\n",
      "Test Batch [1060/2312], Loss: 0.0494\n",
      "Test Batch [1070/2312], Loss: 0.0912\n",
      "Test Batch [1080/2312], Loss: 0.0505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1090/2312], Loss: 0.1350\n",
      "Test Batch [1100/2312], Loss: 0.0862\n",
      "Test Batch [1110/2312], Loss: 0.1002\n",
      "Test Batch [1120/2312], Loss: 0.0458\n",
      "Test Batch [1130/2312], Loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1140/2312], Loss: 0.5000\n",
      "Test Batch [1150/2312], Loss: 0.0318\n",
      "Test Batch [1160/2312], Loss: 0.0912\n",
      "Test Batch [1170/2312], Loss: 0.0561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1180/2312], Loss: 0.1154\n",
      "Test Batch [1190/2312], Loss: 0.0192\n",
      "Test Batch [1200/2312], Loss: 0.1192\n",
      "Test Batch [1210/2312], Loss: 0.0803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1220/2312], Loss: 0.1207\n",
      "Test Batch [1230/2312], Loss: 0.1277\n",
      "Test Batch [1240/2312], Loss: 0.0559\n",
      "Test Batch [1250/2312], Loss: 0.5000\n",
      "Test Batch [1260/2312], Loss: 0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1270/2312], Loss: 0.0723\n",
      "Test Batch [1280/2312], Loss: 0.2070\n",
      "Test Batch [1290/2312], Loss: 0.5000\n",
      "Test Batch [1300/2312], Loss: 0.0659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1310/2312], Loss: 0.0670\n",
      "Test Batch [1320/2312], Loss: 0.0817\n",
      "Test Batch [1330/2312], Loss: 0.0566\n",
      "Test Batch [1340/2312], Loss: 0.0407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1350/2312], Loss: 0.0914\n",
      "Test Batch [1360/2312], Loss: 0.1654\n",
      "Test Batch [1370/2312], Loss: 0.1075\n",
      "Test Batch [1380/2312], Loss: 0.0976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1390/2312], Loss: 0.0840\n",
      "Test Batch [1400/2312], Loss: 0.0796\n",
      "Test Batch [1410/2312], Loss: 0.0850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1420/2312], Loss: 0.1010\n",
      "Test Batch [1430/2312], Loss: 0.5000\n",
      "Test Batch [1440/2312], Loss: 0.0846\n",
      "Test Batch [1450/2312], Loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1460/2312], Loss: 0.1126\n",
      "Test Batch [1470/2312], Loss: 0.0905\n",
      "Test Batch [1480/2312], Loss: 0.0672\n",
      "Test Batch [1490/2312], Loss: 0.0928\n",
      "Test Batch [1500/2312], Loss: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1510/2312], Loss: 0.5000\n",
      "Test Batch [1520/2312], Loss: 0.5000\n",
      "Test Batch [1530/2312], Loss: 0.0787\n",
      "Test Batch [1540/2312], Loss: 0.0796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1550/2312], Loss: 0.0592\n",
      "Test Batch [1560/2312], Loss: 0.0640\n",
      "Test Batch [1570/2312], Loss: 0.1160\n",
      "Test Batch [1580/2312], Loss: 0.0793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1590/2312], Loss: 0.0930\n",
      "Test Batch [1600/2312], Loss: 0.0400\n",
      "Test Batch [1610/2312], Loss: 0.0873\n",
      "Test Batch [1620/2312], Loss: 0.1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1630/2312], Loss: 0.0939\n",
      "Test Batch [1640/2312], Loss: 0.5000\n",
      "Test Batch [1650/2312], Loss: 0.0358\n",
      "Test Batch [1660/2312], Loss: 0.1070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1670/2312], Loss: 0.0885\n",
      "Test Batch [1680/2312], Loss: 0.1045\n",
      "Test Batch [1690/2312], Loss: 0.1609\n",
      "Test Batch [1700/2312], Loss: 0.0776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1710/2312], Loss: 0.1051\n",
      "Test Batch [1720/2312], Loss: 0.0436\n",
      "Test Batch [1730/2312], Loss: 0.0700\n",
      "Test Batch [1740/2312], Loss: 0.5000\n",
      "Test Batch [1750/2312], Loss: 0.0486\n",
      "Test Batch [1760/2312], Loss: 0.0664\n",
      "Test Batch [1770/2312], Loss: 0.0472\n",
      "Test Batch [1780/2312], Loss: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1790/2312], Loss: 0.0787\n",
      "Test Batch [1800/2312], Loss: 0.0601\n",
      "Test Batch [1810/2312], Loss: 0.0659\n",
      "Test Batch [1820/2312], Loss: 0.1252\n",
      "Test Batch [1830/2312], Loss: 0.0493\n",
      "Test Batch [1840/2312], Loss: 0.1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1850/2312], Loss: 0.0809\n",
      "Test Batch [1860/2312], Loss: 0.0685\n",
      "Test Batch [1870/2312], Loss: 0.0628\n",
      "Test Batch [1880/2312], Loss: 0.0916\n",
      "Test Batch [1890/2312], Loss: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1900/2312], Loss: 0.0877\n",
      "Test Batch [1910/2312], Loss: 0.1873\n",
      "Test Batch [1920/2312], Loss: 0.1580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [1930/2312], Loss: 0.1281\n",
      "Test Batch [1940/2312], Loss: 0.1162\n",
      "Test Batch [1950/2312], Loss: 0.0834\n",
      "Test Batch [1960/2312], Loss: 0.1013\n",
      "Test Batch [1970/2312], Loss: 0.0887\n",
      "Test Batch [1980/2312], Loss: 0.0671\n",
      "Test Batch [1990/2312], Loss: 0.0528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2000/2312], Loss: 0.0614\n",
      "Test Batch [2010/2312], Loss: 0.0500\n",
      "Test Batch [2020/2312], Loss: 0.0689\n",
      "Test Batch [2030/2312], Loss: 0.0476\n",
      "Test Batch [2040/2312], Loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2050/2312], Loss: 0.1117\n",
      "Test Batch [2060/2312], Loss: 0.1304\n",
      "Test Batch [2070/2312], Loss: 0.0916\n",
      "Test Batch [2080/2312], Loss: 0.5000\n",
      "Test Batch [2090/2312], Loss: 0.0795\n",
      "Test Batch [2100/2312], Loss: 0.1473\n",
      "Test Batch [2110/2312], Loss: 0.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2120/2312], Loss: 0.1623\n",
      "Test Batch [2130/2312], Loss: 0.0436\n",
      "Test Batch [2140/2312], Loss: 0.0911\n",
      "Test Batch [2150/2312], Loss: 0.1731\n",
      "Test Batch [2160/2312], Loss: 0.0157\n",
      "Test Batch [2170/2312], Loss: 0.5000\n",
      "Test Batch [2180/2312], Loss: 0.1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2190/2312], Loss: 0.5000\n",
      "Test Batch [2200/2312], Loss: 0.5000\n",
      "Test Batch [2210/2312], Loss: 0.5000\n",
      "Test Batch [2220/2312], Loss: 0.0799\n",
      "Test Batch [2230/2312], Loss: 0.0095\n",
      "Test Batch [2240/2312], Loss: 0.0578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2250/2312], Loss: 0.0277\n",
      "Test Batch [2260/2312], Loss: 0.5000\n",
      "Test Batch [2270/2312], Loss: 0.0890\n",
      "Test Batch [2280/2312], Loss: 0.5000\n",
      "Test Batch [2290/2312], Loss: 0.0296\n",
      "Test Batch [2300/2312], Loss: 0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [2310/2312], Loss: 0.5000\n",
      "\n",
      "Test Loss: 0.2021\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:11.268484Z",
     "iopub.status.busy": "2025-05-08T17:32:11.268484Z",
     "iopub.status.idle": "2025-05-08T17:32:27.482302Z",
     "shell.execute_reply": "2025-05-08T17:32:27.482302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 20/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/2312 for test dataset.\n",
      "  Processed batch 40/2312 for test dataset.\n",
      "  Processed batch 50/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 60/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 70/2312 for test dataset.\n",
      "  Processed batch 80/2312 for test dataset.\n",
      "  Processed batch 90/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 100/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 110/2312 for test dataset.\n",
      "  Processed batch 120/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 130/2312 for test dataset.\n",
      "  Processed batch 140/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 150/2312 for test dataset.\n",
      "  Processed batch 160/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 170/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 180/2312 for test dataset.\n",
      "  Processed batch 190/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 200/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 210/2312 for test dataset.\n",
      "  Processed batch 220/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 230/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 240/2312 for test dataset.\n",
      "  Processed batch 250/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 260/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 270/2312 for test dataset.\n",
      "  Processed batch 280/2312 for test dataset.\n",
      "  Processed batch 290/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 300/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 310/2312 for test dataset.\n",
      "  Processed batch 320/2312 for test dataset.\n",
      "  Processed batch 330/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 340/2312 for test dataset.\n",
      "  Processed batch 350/2312 for test dataset.\n",
      "  Processed batch 360/2312 for test dataset.\n",
      "  Processed batch 370/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 380/2312 for test dataset.\n",
      "  Processed batch 390/2312 for test dataset.\n",
      "  Processed batch 400/2312 for test dataset.\n",
      "  Processed batch 410/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 420/2312 for test dataset.\n",
      "  Processed batch 430/2312 for test dataset.\n",
      "  Processed batch 440/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 450/2312 for test dataset.\n",
      "  Processed batch 460/2312 for test dataset.\n",
      "  Processed batch 470/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 480/2312 for test dataset.\n",
      "  Processed batch 490/2312 for test dataset.\n",
      "  Processed batch 500/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 510/2312 for test dataset.\n",
      "  Processed batch 520/2312 for test dataset.\n",
      "  Processed batch 530/2312 for test dataset.\n",
      "  Processed batch 540/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 550/2312 for test dataset.\n",
      "  Processed batch 560/2312 for test dataset.\n",
      "  Processed batch 570/2312 for test dataset.\n",
      "  Processed batch 580/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 590/2312 for test dataset.\n",
      "  Processed batch 600/2312 for test dataset.\n",
      "  Processed batch 610/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 620/2312 for test dataset.\n",
      "  Processed batch 630/2312 for test dataset.\n",
      "  Processed batch 640/2312 for test dataset.\n",
      "  Processed batch 650/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 660/2312 for test dataset.\n",
      "  Processed batch 670/2312 for test dataset.\n",
      "  Processed batch 680/2312 for test dataset.\n",
      "  Processed batch 690/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 700/2312 for test dataset.\n",
      "  Processed batch 710/2312 for test dataset.\n",
      "  Processed batch 720/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 730/2312 for test dataset.\n",
      "  Processed batch 740/2312 for test dataset.\n",
      "  Processed batch 750/2312 for test dataset.\n",
      "  Processed batch 760/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 770/2312 for test dataset.\n",
      "  Processed batch 780/2312 for test dataset.\n",
      "  Processed batch 790/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 800/2312 for test dataset.\n",
      "  Processed batch 810/2312 for test dataset.\n",
      "  Processed batch 820/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 830/2312 for test dataset.\n",
      "  Processed batch 840/2312 for test dataset.\n",
      "  Processed batch 850/2312 for test dataset.\n",
      "  Processed batch 860/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 870/2312 for test dataset.\n",
      "  Processed batch 880/2312 for test dataset.\n",
      "  Processed batch 890/2312 for test dataset.\n",
      "  Processed batch 900/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 910/2312 for test dataset.\n",
      "  Processed batch 920/2312 for test dataset.\n",
      "  Processed batch 930/2312 for test dataset.\n",
      "  Processed batch 940/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 950/2312 for test dataset.\n",
      "  Processed batch 960/2312 for test dataset.\n",
      "  Processed batch 970/2312 for test dataset.\n",
      "  Processed batch 980/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 990/2312 for test dataset.\n",
      "  Processed batch 1000/2312 for test dataset.\n",
      "  Processed batch 1010/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1020/2312 for test dataset.\n",
      "  Processed batch 1030/2312 for test dataset.\n",
      "  Processed batch 1040/2312 for test dataset.\n",
      "  Processed batch 1050/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1060/2312 for test dataset.\n",
      "  Processed batch 1070/2312 for test dataset.\n",
      "  Processed batch 1080/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1090/2312 for test dataset.\n",
      "  Processed batch 1100/2312 for test dataset.\n",
      "  Processed batch 1110/2312 for test dataset.\n",
      "  Processed batch 1120/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1130/2312 for test dataset.\n",
      "  Processed batch 1140/2312 for test dataset.\n",
      "  Processed batch 1150/2312 for test dataset.\n",
      "  Processed batch 1160/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1170/2312 for test dataset.\n",
      "  Processed batch 1180/2312 for test dataset.\n",
      "  Processed batch 1190/2312 for test dataset.\n",
      "  Processed batch 1200/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1210/2312 for test dataset.\n",
      "  Processed batch 1220/2312 for test dataset.\n",
      "  Processed batch 1230/2312 for test dataset.\n",
      "  Processed batch 1240/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1250/2312 for test dataset.\n",
      "  Processed batch 1260/2312 for test dataset.\n",
      "  Processed batch 1270/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1280/2312 for test dataset.\n",
      "  Processed batch 1290/2312 for test dataset.\n",
      "  Processed batch 1300/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1310/2312 for test dataset.\n",
      "  Processed batch 1320/2312 for test dataset.\n",
      "  Processed batch 1330/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1340/2312 for test dataset.\n",
      "  Processed batch 1350/2312 for test dataset.\n",
      "  Processed batch 1360/2312 for test dataset.\n",
      "  Processed batch 1370/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1380/2312 for test dataset.\n",
      "  Processed batch 1390/2312 for test dataset.\n",
      "  Processed batch 1400/2312 for test dataset.\n",
      "  Processed batch 1410/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1420/2312 for test dataset.\n",
      "  Processed batch 1430/2312 for test dataset.\n",
      "  Processed batch 1440/2312 for test dataset.\n",
      "  Processed batch 1450/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1460/2312 for test dataset.\n",
      "  Processed batch 1470/2312 for test dataset.\n",
      "  Processed batch 1480/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1490/2312 for test dataset.\n",
      "  Processed batch 1500/2312 for test dataset.\n",
      "  Processed batch 1510/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1520/2312 for test dataset.\n",
      "  Processed batch 1530/2312 for test dataset.\n",
      "  Processed batch 1540/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1550/2312 for test dataset.\n",
      "  Processed batch 1560/2312 for test dataset.\n",
      "  Processed batch 1570/2312 for test dataset.\n",
      "  Processed batch 1580/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1590/2312 for test dataset.\n",
      "  Processed batch 1600/2312 for test dataset.\n",
      "  Processed batch 1610/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1620/2312 for test dataset.\n",
      "  Processed batch 1630/2312 for test dataset.\n",
      "  Processed batch 1640/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1650/2312 for test dataset.\n",
      "  Processed batch 1660/2312 for test dataset.\n",
      "  Processed batch 1670/2312 for test dataset.\n",
      "  Processed batch 1680/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1690/2312 for test dataset.\n",
      "  Processed batch 1700/2312 for test dataset.\n",
      "  Processed batch 1710/2312 for test dataset.\n",
      "  Processed batch 1720/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1730/2312 for test dataset.\n",
      "  Processed batch 1740/2312 for test dataset.\n",
      "  Processed batch 1750/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1760/2312 for test dataset.\n",
      "  Processed batch 1770/2312 for test dataset.\n",
      "  Processed batch 1780/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1790/2312 for test dataset.\n",
      "  Processed batch 1800/2312 for test dataset.\n",
      "  Processed batch 1810/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1820/2312 for test dataset.\n",
      "  Processed batch 1830/2312 for test dataset.\n",
      "  Processed batch 1840/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1850/2312 for test dataset.\n",
      "  Processed batch 1860/2312 for test dataset.\n",
      "  Processed batch 1870/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1880/2312 for test dataset.\n",
      "  Processed batch 1890/2312 for test dataset.\n",
      "  Processed batch 1900/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1910/2312 for test dataset.\n",
      "  Processed batch 1920/2312 for test dataset.\n",
      "  Processed batch 1930/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1940/2312 for test dataset.\n",
      "  Processed batch 1950/2312 for test dataset.\n",
      "  Processed batch 1960/2312 for test dataset.\n",
      "  Processed batch 1970/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 1980/2312 for test dataset.\n",
      "  Processed batch 1990/2312 for test dataset.\n",
      "  Processed batch 2000/2312 for test dataset.\n",
      "  Processed batch 2010/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2020/2312 for test dataset.\n",
      "  Processed batch 2030/2312 for test dataset.\n",
      "  Processed batch 2040/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2050/2312 for test dataset.\n",
      "  Processed batch 2060/2312 for test dataset.\n",
      "  Processed batch 2070/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2080/2312 for test dataset.\n",
      "  Processed batch 2090/2312 for test dataset.\n",
      "  Processed batch 2100/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2110/2312 for test dataset.\n",
      "  Processed batch 2120/2312 for test dataset.\n",
      "  Processed batch 2130/2312 for test dataset.\n",
      "  Processed batch 2140/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2150/2312 for test dataset.\n",
      "  Processed batch 2160/2312 for test dataset.\n",
      "  Processed batch 2170/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2180/2312 for test dataset.\n",
      "  Processed batch 2190/2312 for test dataset.\n",
      "  Processed batch 2200/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2210/2312 for test dataset.\n",
      "  Processed batch 2220/2312 for test dataset.\n",
      "  Processed batch 2230/2312 for test dataset.\n",
      "  Processed batch 2240/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2250/2312 for test dataset.\n",
      "  Processed batch 2260/2312 for test dataset.\n",
      "  Processed batch 2270/2312 for test dataset.\n",
      "  Processed batch 2280/2312 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 2290/2312 for test dataset.\n",
      "  Processed batch 2300/2312 for test dataset.\n",
      "  Processed batch 2310/2312 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:27.484505Z",
     "iopub.status.busy": "2025-05-08T17:32:27.484505Z",
     "iopub.status.idle": "2025-05-08T17:32:27.487890Z",
     "shell.execute_reply": "2025-05-08T17:32:27.487890Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:27.489900Z",
     "iopub.status.busy": "2025-05-08T17:32:27.489900Z",
     "iopub.status.idle": "2025-05-08T17:32:45.696881Z",
     "shell.execute_reply": "2025-05-08T17:32:45.696881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:45.699891Z",
     "iopub.status.busy": "2025-05-08T17:32:45.699891Z",
     "iopub.status.idle": "2025-05-08T17:32:45.940848Z",
     "shell.execute_reply": "2025-05-08T17:32:45.940848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 100.00%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 96.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     65946\n",
      "           1       0.97      0.88      0.92      7573\n",
      "           2       0.75      0.93      0.83      3065\n",
      "           3       0.63      0.92      0.75      2660\n",
      "           4       0.92      0.91      0.91      6559\n",
      "           5       0.87      0.96      0.91      9223\n",
      "           6       0.98      0.81      0.89      7262\n",
      "           7       0.98      0.99      0.98     42801\n",
      "           8       0.93      0.99      0.96      2838\n",
      "\n",
      "    accuracy                           0.96    147927\n",
      "   macro avg       0.89      0.93      0.91    147927\n",
      "weighted avg       0.97      0.96      0.96    147927\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:45.943852Z",
     "iopub.status.busy": "2025-05-08T17:32:45.943852Z",
     "iopub.status.idle": "2025-05-08T17:32:46.584119Z",
     "shell.execute_reply": "2025-05-08T17:32:46.584119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (180, 128)\n",
      "Train labels shape: (180,)\n",
      "Val reps shape: (45, 128)\n",
      "Val labels shape: (45,)\n",
      "Test reps shape: (147927, 128)\n",
      "Test labels shape: (147927,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:46.587127Z",
     "iopub.status.busy": "2025-05-08T17:32:46.586128Z",
     "iopub.status.idle": "2025-05-08T17:32:46.602126Z",
     "shell.execute_reply": "2025-05-08T17:32:46.602126Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:46.605537Z",
     "iopub.status.busy": "2025-05-08T17:32:46.605537Z",
     "iopub.status.idle": "2025-05-08T17:32:48.939054Z",
     "shell.execute_reply": "2025-05-08T17:32:48.939054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.4261  |  Val Loss: 2.4052\n",
      "Validation loss improved from inf to 2.4052.\n",
      "[Epoch 2/1000] Train Loss: 2.3361  |  Val Loss: 2.3192\n",
      "Validation loss improved from 2.4052 to 2.3192.\n",
      "[Epoch 3/1000] Train Loss: 2.2519  |  Val Loss: 2.2370\n",
      "Validation loss improved from 2.3192 to 2.2370.\n",
      "[Epoch 4/1000] Train Loss: 2.1632  |  Val Loss: 2.1613\n",
      "Validation loss improved from 2.2370 to 2.1613.\n",
      "[Epoch 5/1000] Train Loss: 2.0945  |  Val Loss: 2.0892\n",
      "Validation loss improved from 2.1613 to 2.0892.\n",
      "[Epoch 6/1000] Train Loss: 2.0183  |  Val Loss: 2.0222\n",
      "Validation loss improved from 2.0892 to 2.0222.\n",
      "[Epoch 7/1000] Train Loss: 1.9487  |  Val Loss: 1.9585\n",
      "Validation loss improved from 2.0222 to 1.9585.\n",
      "[Epoch 8/1000] Train Loss: 1.8838  |  Val Loss: 1.8989\n",
      "Validation loss improved from 1.9585 to 1.8989.\n",
      "[Epoch 9/1000] Train Loss: 1.8280  |  Val Loss: 1.8460\n",
      "Validation loss improved from 1.8989 to 1.8460.\n",
      "[Epoch 10/1000] Train Loss: 1.7762  |  Val Loss: 1.7981\n",
      "Validation loss improved from 1.8460 to 1.7981.\n",
      "[Epoch 11/1000] Train Loss: 1.7301  |  Val Loss: 1.7541\n",
      "Validation loss improved from 1.7981 to 1.7541.\n",
      "[Epoch 12/1000] Train Loss: 1.6868  |  Val Loss: 1.7128\n",
      "Validation loss improved from 1.7541 to 1.7128.\n",
      "[Epoch 13/1000] Train Loss: 1.6444  |  Val Loss: 1.6724\n",
      "Validation loss improved from 1.7128 to 1.6724.\n",
      "[Epoch 14/1000] Train Loss: 1.6040  |  Val Loss: 1.6334\n",
      "Validation loss improved from 1.6724 to 1.6334.\n",
      "[Epoch 15/1000] Train Loss: 1.5647  |  Val Loss: 1.5957\n",
      "Validation loss improved from 1.6334 to 1.5957.\n",
      "[Epoch 16/1000] Train Loss: 1.5273  |  Val Loss: 1.5598\n",
      "Validation loss improved from 1.5957 to 1.5598.\n",
      "[Epoch 17/1000] Train Loss: 1.4911  |  Val Loss: 1.5257\n",
      "Validation loss improved from 1.5598 to 1.5257.\n",
      "[Epoch 18/1000] Train Loss: 1.4569  |  Val Loss: 1.4930\n",
      "Validation loss improved from 1.5257 to 1.4930.\n",
      "[Epoch 19/1000] Train Loss: 1.4242  |  Val Loss: 1.4621\n",
      "Validation loss improved from 1.4930 to 1.4621.\n",
      "[Epoch 20/1000] Train Loss: 1.3930  |  Val Loss: 1.4330\n",
      "Validation loss improved from 1.4621 to 1.4330.\n",
      "[Epoch 21/1000] Train Loss: 1.3617  |  Val Loss: 1.4048\n",
      "Validation loss improved from 1.4330 to 1.4048.\n",
      "[Epoch 22/1000] Train Loss: 1.3325  |  Val Loss: 1.3770\n",
      "Validation loss improved from 1.4048 to 1.3770.\n",
      "[Epoch 23/1000] Train Loss: 1.3041  |  Val Loss: 1.3501\n",
      "Validation loss improved from 1.3770 to 1.3501.\n",
      "[Epoch 24/1000] Train Loss: 1.2749  |  Val Loss: 1.3239\n",
      "Validation loss improved from 1.3501 to 1.3239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/1000] Train Loss: 1.2471  |  Val Loss: 1.2981\n",
      "Validation loss improved from 1.3239 to 1.2981.\n",
      "[Epoch 26/1000] Train Loss: 1.2197  |  Val Loss: 1.2726\n",
      "Validation loss improved from 1.2981 to 1.2726.\n",
      "[Epoch 27/1000] Train Loss: 1.1930  |  Val Loss: 1.2475\n",
      "Validation loss improved from 1.2726 to 1.2475.\n",
      "[Epoch 28/1000] Train Loss: 1.1678  |  Val Loss: 1.2228\n",
      "Validation loss improved from 1.2475 to 1.2228.\n",
      "[Epoch 29/1000] Train Loss: 1.1425  |  Val Loss: 1.1988\n",
      "Validation loss improved from 1.2228 to 1.1988.\n",
      "[Epoch 30/1000] Train Loss: 1.1179  |  Val Loss: 1.1755\n",
      "Validation loss improved from 1.1988 to 1.1755.\n",
      "[Epoch 31/1000] Train Loss: 1.0945  |  Val Loss: 1.1526\n",
      "Validation loss improved from 1.1755 to 1.1526.\n",
      "[Epoch 32/1000] Train Loss: 1.0712  |  Val Loss: 1.1304\n",
      "Validation loss improved from 1.1526 to 1.1304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/1000] Train Loss: 1.0488  |  Val Loss: 1.1086\n",
      "Validation loss improved from 1.1304 to 1.1086.\n",
      "[Epoch 34/1000] Train Loss: 1.0267  |  Val Loss: 1.0874\n",
      "Validation loss improved from 1.1086 to 1.0874.\n",
      "[Epoch 35/1000] Train Loss: 1.0053  |  Val Loss: 1.0668\n",
      "Validation loss improved from 1.0874 to 1.0668.\n",
      "[Epoch 36/1000] Train Loss: 0.9843  |  Val Loss: 1.0465\n",
      "Validation loss improved from 1.0668 to 1.0465.\n",
      "[Epoch 37/1000] Train Loss: 0.9635  |  Val Loss: 1.0261\n",
      "Validation loss improved from 1.0465 to 1.0261.\n",
      "[Epoch 38/1000] Train Loss: 0.9423  |  Val Loss: 1.0051\n",
      "Validation loss improved from 1.0261 to 1.0051.\n",
      "[Epoch 39/1000] Train Loss: 0.9205  |  Val Loss: 0.9837\n",
      "Validation loss improved from 1.0051 to 0.9837.\n",
      "[Epoch 40/1000] Train Loss: 0.8987  |  Val Loss: 0.9625\n",
      "Validation loss improved from 0.9837 to 0.9625.\n",
      "[Epoch 41/1000] Train Loss: 0.8770  |  Val Loss: 0.9412\n",
      "Validation loss improved from 0.9625 to 0.9412.\n",
      "[Epoch 42/1000] Train Loss: 0.8558  |  Val Loss: 0.9204\n",
      "Validation loss improved from 0.9412 to 0.9204.\n",
      "[Epoch 43/1000] Train Loss: 0.8350  |  Val Loss: 0.9001\n",
      "Validation loss improved from 0.9204 to 0.9001.\n",
      "[Epoch 44/1000] Train Loss: 0.8139  |  Val Loss: 0.8808\n",
      "Validation loss improved from 0.9001 to 0.8808.\n",
      "[Epoch 45/1000] Train Loss: 0.7944  |  Val Loss: 0.8622\n",
      "Validation loss improved from 0.8808 to 0.8622.\n",
      "[Epoch 46/1000] Train Loss: 0.7758  |  Val Loss: 0.8444\n",
      "Validation loss improved from 0.8622 to 0.8444.\n",
      "[Epoch 47/1000] Train Loss: 0.7579  |  Val Loss: 0.8272\n",
      "Validation loss improved from 0.8444 to 0.8272.\n",
      "[Epoch 48/1000] Train Loss: 0.7406  |  Val Loss: 0.8105\n",
      "Validation loss improved from 0.8272 to 0.8105.\n",
      "[Epoch 49/1000] Train Loss: 0.7239  |  Val Loss: 0.7946\n",
      "Validation loss improved from 0.8105 to 0.7946.\n",
      "[Epoch 50/1000] Train Loss: 0.7081  |  Val Loss: 0.7794\n",
      "Validation loss improved from 0.7946 to 0.7794.\n",
      "[Epoch 51/1000] Train Loss: 0.6925  |  Val Loss: 0.7648\n",
      "Validation loss improved from 0.7794 to 0.7648.\n",
      "[Epoch 52/1000] Train Loss: 0.6776  |  Val Loss: 0.7506\n",
      "Validation loss improved from 0.7648 to 0.7506.\n",
      "[Epoch 53/1000] Train Loss: 0.6633  |  Val Loss: 0.7369\n",
      "Validation loss improved from 0.7506 to 0.7369.\n",
      "[Epoch 54/1000] Train Loss: 0.6492  |  Val Loss: 0.7234\n",
      "Validation loss improved from 0.7369 to 0.7234.\n",
      "[Epoch 55/1000] Train Loss: 0.6355  |  Val Loss: 0.7101\n",
      "Validation loss improved from 0.7234 to 0.7101.\n",
      "[Epoch 56/1000] Train Loss: 0.6223  |  Val Loss: 0.6970\n",
      "Validation loss improved from 0.7101 to 0.6970.\n",
      "[Epoch 57/1000] Train Loss: 0.6092  |  Val Loss: 0.6843\n",
      "Validation loss improved from 0.6970 to 0.6843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] Train Loss: 0.5964  |  Val Loss: 0.6718\n",
      "Validation loss improved from 0.6843 to 0.6718.\n",
      "[Epoch 59/1000] Train Loss: 0.5839  |  Val Loss: 0.6597\n",
      "Validation loss improved from 0.6718 to 0.6597.\n",
      "[Epoch 60/1000] Train Loss: 0.5720  |  Val Loss: 0.6478\n",
      "Validation loss improved from 0.6597 to 0.6478.\n",
      "[Epoch 61/1000] Train Loss: 0.5598  |  Val Loss: 0.6362\n",
      "Validation loss improved from 0.6478 to 0.6362.\n",
      "[Epoch 62/1000] Train Loss: 0.5482  |  Val Loss: 0.6250\n",
      "Validation loss improved from 0.6362 to 0.6250.\n",
      "[Epoch 63/1000] Train Loss: 0.5368  |  Val Loss: 0.6139\n",
      "Validation loss improved from 0.6250 to 0.6139.\n",
      "[Epoch 64/1000] Train Loss: 0.5257  |  Val Loss: 0.6029\n",
      "Validation loss improved from 0.6139 to 0.6029.\n",
      "[Epoch 65/1000] Train Loss: 0.5149  |  Val Loss: 0.5922\n",
      "Validation loss improved from 0.6029 to 0.5922.\n",
      "[Epoch 66/1000] Train Loss: 0.5041  |  Val Loss: 0.5817\n",
      "Validation loss improved from 0.5922 to 0.5817.\n",
      "[Epoch 67/1000] Train Loss: 0.4935  |  Val Loss: 0.5715\n",
      "Validation loss improved from 0.5817 to 0.5715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] Train Loss: 0.4831  |  Val Loss: 0.5615\n",
      "Validation loss improved from 0.5715 to 0.5615.\n",
      "[Epoch 69/1000] Train Loss: 0.4733  |  Val Loss: 0.5516\n",
      "Validation loss improved from 0.5615 to 0.5516.\n",
      "[Epoch 70/1000] Train Loss: 0.4635  |  Val Loss: 0.5418\n",
      "Validation loss improved from 0.5516 to 0.5418.\n",
      "[Epoch 71/1000] Train Loss: 0.4538  |  Val Loss: 0.5321\n",
      "Validation loss improved from 0.5418 to 0.5321.\n",
      "[Epoch 72/1000] Train Loss: 0.4441  |  Val Loss: 0.5228\n",
      "Validation loss improved from 0.5321 to 0.5228.\n",
      "[Epoch 73/1000] Train Loss: 0.4350  |  Val Loss: 0.5136\n",
      "Validation loss improved from 0.5228 to 0.5136.\n",
      "[Epoch 74/1000] Train Loss: 0.4259  |  Val Loss: 0.5046\n",
      "Validation loss improved from 0.5136 to 0.5046.\n",
      "[Epoch 75/1000] Train Loss: 0.4164  |  Val Loss: 0.4959\n",
      "Validation loss improved from 0.5046 to 0.4959.\n",
      "[Epoch 76/1000] Train Loss: 0.4078  |  Val Loss: 0.4872\n",
      "Validation loss improved from 0.4959 to 0.4872.\n",
      "[Epoch 77/1000] Train Loss: 0.3991  |  Val Loss: 0.4789\n",
      "Validation loss improved from 0.4872 to 0.4789.\n",
      "[Epoch 78/1000] Train Loss: 0.3909  |  Val Loss: 0.4706\n",
      "Validation loss improved from 0.4789 to 0.4706.\n",
      "[Epoch 79/1000] Train Loss: 0.3828  |  Val Loss: 0.4626\n",
      "Validation loss improved from 0.4706 to 0.4626.\n",
      "[Epoch 80/1000] Train Loss: 0.3744  |  Val Loss: 0.4548\n",
      "Validation loss improved from 0.4626 to 0.4548.\n",
      "[Epoch 81/1000] Train Loss: 0.3667  |  Val Loss: 0.4473\n",
      "Validation loss improved from 0.4548 to 0.4473.\n",
      "[Epoch 82/1000] Train Loss: 0.3591  |  Val Loss: 0.4398\n",
      "Validation loss improved from 0.4473 to 0.4398.\n",
      "[Epoch 83/1000] Train Loss: 0.3515  |  Val Loss: 0.4326\n",
      "Validation loss improved from 0.4398 to 0.4326.\n",
      "[Epoch 84/1000] Train Loss: 0.3440  |  Val Loss: 0.4256\n",
      "Validation loss improved from 0.4326 to 0.4256.\n",
      "[Epoch 85/1000] Train Loss: 0.3369  |  Val Loss: 0.4188\n",
      "Validation loss improved from 0.4256 to 0.4188.\n",
      "[Epoch 86/1000] Train Loss: 0.3296  |  Val Loss: 0.4121\n",
      "Validation loss improved from 0.4188 to 0.4121.\n",
      "[Epoch 87/1000] Train Loss: 0.3229  |  Val Loss: 0.4056\n",
      "Validation loss improved from 0.4121 to 0.4056.\n",
      "[Epoch 88/1000] Train Loss: 0.3160  |  Val Loss: 0.3991\n",
      "Validation loss improved from 0.4056 to 0.3991.\n",
      "[Epoch 89/1000] Train Loss: 0.3091  |  Val Loss: 0.3926\n",
      "Validation loss improved from 0.3991 to 0.3926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 90/1000] Train Loss: 0.3026  |  Val Loss: 0.3863\n",
      "Validation loss improved from 0.3926 to 0.3863.\n",
      "[Epoch 91/1000] Train Loss: 0.2961  |  Val Loss: 0.3802\n",
      "Validation loss improved from 0.3863 to 0.3802.\n",
      "[Epoch 92/1000] Train Loss: 0.2897  |  Val Loss: 0.3743\n",
      "Validation loss improved from 0.3802 to 0.3743.\n",
      "[Epoch 93/1000] Train Loss: 0.2837  |  Val Loss: 0.3685\n",
      "Validation loss improved from 0.3743 to 0.3685.\n",
      "[Epoch 94/1000] Train Loss: 0.2778  |  Val Loss: 0.3629\n",
      "Validation loss improved from 0.3685 to 0.3629.\n",
      "[Epoch 95/1000] Train Loss: 0.2720  |  Val Loss: 0.3574\n",
      "Validation loss improved from 0.3629 to 0.3574.\n",
      "[Epoch 96/1000] Train Loss: 0.2663  |  Val Loss: 0.3522\n",
      "Validation loss improved from 0.3574 to 0.3522.\n",
      "[Epoch 97/1000] Train Loss: 0.2607  |  Val Loss: 0.3472\n",
      "Validation loss improved from 0.3522 to 0.3472.\n",
      "[Epoch 98/1000] Train Loss: 0.2558  |  Val Loss: 0.3424\n",
      "Validation loss improved from 0.3472 to 0.3424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 99/1000] Train Loss: 0.2504  |  Val Loss: 0.3374\n",
      "Validation loss improved from 0.3424 to 0.3374.\n",
      "[Epoch 100/1000] Train Loss: 0.2456  |  Val Loss: 0.3327\n",
      "Validation loss improved from 0.3374 to 0.3327.\n",
      "[Epoch 101/1000] Train Loss: 0.2407  |  Val Loss: 0.3282\n",
      "Validation loss improved from 0.3327 to 0.3282.\n",
      "[Epoch 102/1000] Train Loss: 0.2358  |  Val Loss: 0.3237\n",
      "Validation loss improved from 0.3282 to 0.3237.\n",
      "[Epoch 103/1000] Train Loss: 0.2314  |  Val Loss: 0.3195\n",
      "Validation loss improved from 0.3237 to 0.3195.\n",
      "[Epoch 104/1000] Train Loss: 0.2270  |  Val Loss: 0.3155\n",
      "Validation loss improved from 0.3195 to 0.3155.\n",
      "[Epoch 105/1000] Train Loss: 0.2226  |  Val Loss: 0.3116\n",
      "Validation loss improved from 0.3155 to 0.3116.\n",
      "[Epoch 106/1000] Train Loss: 0.2184  |  Val Loss: 0.3080\n",
      "Validation loss improved from 0.3116 to 0.3080.\n",
      "[Epoch 107/1000] Train Loss: 0.2143  |  Val Loss: 0.3043\n",
      "Validation loss improved from 0.3080 to 0.3043.\n",
      "[Epoch 108/1000] Train Loss: 0.2103  |  Val Loss: 0.3006\n",
      "Validation loss improved from 0.3043 to 0.3006.\n",
      "[Epoch 109/1000] Train Loss: 0.2063  |  Val Loss: 0.2972\n",
      "Validation loss improved from 0.3006 to 0.2972.\n",
      "[Epoch 110/1000] Train Loss: 0.2027  |  Val Loss: 0.2940\n",
      "Validation loss improved from 0.2972 to 0.2940.\n",
      "[Epoch 111/1000] Train Loss: 0.1989  |  Val Loss: 0.2907\n",
      "Validation loss improved from 0.2940 to 0.2907.\n",
      "[Epoch 112/1000] Train Loss: 0.1954  |  Val Loss: 0.2874\n",
      "Validation loss improved from 0.2907 to 0.2874.\n",
      "[Epoch 113/1000] Train Loss: 0.1917  |  Val Loss: 0.2843\n",
      "Validation loss improved from 0.2874 to 0.2843.\n",
      "[Epoch 114/1000] Train Loss: 0.1883  |  Val Loss: 0.2814\n",
      "Validation loss improved from 0.2843 to 0.2814.\n",
      "[Epoch 115/1000] Train Loss: 0.1850  |  Val Loss: 0.2787\n",
      "Validation loss improved from 0.2814 to 0.2787.\n",
      "[Epoch 116/1000] Train Loss: 0.1817  |  Val Loss: 0.2759\n",
      "Validation loss improved from 0.2787 to 0.2759.\n",
      "[Epoch 117/1000] Train Loss: 0.1785  |  Val Loss: 0.2732\n",
      "Validation loss improved from 0.2759 to 0.2732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 118/1000] Train Loss: 0.1754  |  Val Loss: 0.2706\n",
      "Validation loss improved from 0.2732 to 0.2706.\n",
      "[Epoch 119/1000] Train Loss: 0.1726  |  Val Loss: 0.2682\n",
      "Validation loss improved from 0.2706 to 0.2682.\n",
      "[Epoch 120/1000] Train Loss: 0.1695  |  Val Loss: 0.2657\n",
      "Validation loss improved from 0.2682 to 0.2657.\n",
      "[Epoch 121/1000] Train Loss: 0.1666  |  Val Loss: 0.2634\n",
      "Validation loss improved from 0.2657 to 0.2634.\n",
      "[Epoch 122/1000] Train Loss: 0.1639  |  Val Loss: 0.2612\n",
      "Validation loss improved from 0.2634 to 0.2612.\n",
      "[Epoch 123/1000] Train Loss: 0.1612  |  Val Loss: 0.2592\n",
      "Validation loss improved from 0.2612 to 0.2592.\n",
      "[Epoch 124/1000] Train Loss: 0.1585  |  Val Loss: 0.2570\n",
      "Validation loss improved from 0.2592 to 0.2570.\n",
      "[Epoch 125/1000] Train Loss: 0.1560  |  Val Loss: 0.2551\n",
      "Validation loss improved from 0.2570 to 0.2551.\n",
      "[Epoch 126/1000] Train Loss: 0.1533  |  Val Loss: 0.2531\n",
      "Validation loss improved from 0.2551 to 0.2531.\n",
      "[Epoch 127/1000] Train Loss: 0.1509  |  Val Loss: 0.2510\n",
      "Validation loss improved from 0.2531 to 0.2510.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 128/1000] Train Loss: 0.1486  |  Val Loss: 0.2491\n",
      "Validation loss improved from 0.2510 to 0.2491.\n",
      "[Epoch 129/1000] Train Loss: 0.1463  |  Val Loss: 0.2475\n",
      "Validation loss improved from 0.2491 to 0.2475.\n",
      "[Epoch 130/1000] Train Loss: 0.1440  |  Val Loss: 0.2461\n",
      "Validation loss improved from 0.2475 to 0.2461.\n",
      "[Epoch 131/1000] Train Loss: 0.1418  |  Val Loss: 0.2446\n",
      "Validation loss improved from 0.2461 to 0.2446.\n",
      "[Epoch 132/1000] Train Loss: 0.1396  |  Val Loss: 0.2431\n",
      "Validation loss improved from 0.2446 to 0.2431.\n",
      "[Epoch 133/1000] Train Loss: 0.1375  |  Val Loss: 0.2417\n",
      "Validation loss improved from 0.2431 to 0.2417.\n",
      "[Epoch 134/1000] Train Loss: 0.1354  |  Val Loss: 0.2403\n",
      "Validation loss improved from 0.2417 to 0.2403.\n",
      "[Epoch 135/1000] Train Loss: 0.1335  |  Val Loss: 0.2391\n",
      "Validation loss improved from 0.2403 to 0.2391.\n",
      "[Epoch 136/1000] Train Loss: 0.1315  |  Val Loss: 0.2379\n",
      "Validation loss improved from 0.2391 to 0.2379.\n",
      "[Epoch 137/1000] Train Loss: 0.1297  |  Val Loss: 0.2368\n",
      "Validation loss improved from 0.2379 to 0.2368.\n",
      "[Epoch 138/1000] Train Loss: 0.1278  |  Val Loss: 0.2357\n",
      "Validation loss improved from 0.2368 to 0.2357.\n",
      "[Epoch 139/1000] Train Loss: 0.1260  |  Val Loss: 0.2347\n",
      "Validation loss improved from 0.2357 to 0.2347.\n",
      "[Epoch 140/1000] Train Loss: 0.1242  |  Val Loss: 0.2338\n",
      "Validation loss improved from 0.2347 to 0.2338.\n",
      "[Epoch 141/1000] Train Loss: 0.1225  |  Val Loss: 0.2328\n",
      "Validation loss improved from 0.2338 to 0.2328.\n",
      "[Epoch 142/1000] Train Loss: 0.1208  |  Val Loss: 0.2319\n",
      "Validation loss improved from 0.2328 to 0.2319.\n",
      "[Epoch 143/1000] Train Loss: 0.1192  |  Val Loss: 0.2311\n",
      "Validation loss improved from 0.2319 to 0.2311.\n",
      "[Epoch 144/1000] Train Loss: 0.1176  |  Val Loss: 0.2302\n",
      "Validation loss improved from 0.2311 to 0.2302.\n",
      "[Epoch 145/1000] Train Loss: 0.1161  |  Val Loss: 0.2292\n",
      "Validation loss improved from 0.2302 to 0.2292.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 146/1000] Train Loss: 0.1144  |  Val Loss: 0.2285\n",
      "Validation loss improved from 0.2292 to 0.2285.\n",
      "[Epoch 147/1000] Train Loss: 0.1130  |  Val Loss: 0.2278\n",
      "Validation loss improved from 0.2285 to 0.2278.\n",
      "[Epoch 148/1000] Train Loss: 0.1116  |  Val Loss: 0.2270\n",
      "Validation loss improved from 0.2278 to 0.2270.\n",
      "[Epoch 149/1000] Train Loss: 0.1101  |  Val Loss: 0.2263\n",
      "Validation loss improved from 0.2270 to 0.2263.\n",
      "[Epoch 150/1000] Train Loss: 0.1087  |  Val Loss: 0.2256\n",
      "Validation loss improved from 0.2263 to 0.2256.\n",
      "[Epoch 151/1000] Train Loss: 0.1074  |  Val Loss: 0.2251\n",
      "Validation loss improved from 0.2256 to 0.2251.\n",
      "[Epoch 152/1000] Train Loss: 0.1061  |  Val Loss: 0.2246\n",
      "Validation loss improved from 0.2251 to 0.2246.\n",
      "[Epoch 153/1000] Train Loss: 0.1047  |  Val Loss: 0.2241\n",
      "Validation loss improved from 0.2246 to 0.2241.\n",
      "[Epoch 154/1000] Train Loss: 0.1035  |  Val Loss: 0.2234\n",
      "Validation loss improved from 0.2241 to 0.2234.\n",
      "[Epoch 155/1000] Train Loss: 0.1023  |  Val Loss: 0.2229\n",
      "Validation loss improved from 0.2234 to 0.2229.\n",
      "[Epoch 156/1000] Train Loss: 0.1011  |  Val Loss: 0.2223\n",
      "Validation loss improved from 0.2229 to 0.2223.\n",
      "[Epoch 157/1000] Train Loss: 0.0999  |  Val Loss: 0.2218\n",
      "Validation loss improved from 0.2223 to 0.2218.\n",
      "[Epoch 158/1000] Train Loss: 0.0987  |  Val Loss: 0.2214\n",
      "Validation loss improved from 0.2218 to 0.2214.\n",
      "[Epoch 159/1000] Train Loss: 0.0976  |  Val Loss: 0.2207\n",
      "Validation loss improved from 0.2214 to 0.2207.\n",
      "[Epoch 160/1000] Train Loss: 0.0965  |  Val Loss: 0.2201\n",
      "Validation loss improved from 0.2207 to 0.2201.\n",
      "[Epoch 161/1000] Train Loss: 0.0954  |  Val Loss: 0.2198\n",
      "Validation loss improved from 0.2201 to 0.2198.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 162/1000] Train Loss: 0.0944  |  Val Loss: 0.2194\n",
      "Validation loss improved from 0.2198 to 0.2194.\n",
      "[Epoch 163/1000] Train Loss: 0.0934  |  Val Loss: 0.2188\n",
      "Validation loss improved from 0.2194 to 0.2188.\n",
      "[Epoch 164/1000] Train Loss: 0.0923  |  Val Loss: 0.2186\n",
      "Validation loss improved from 0.2188 to 0.2186.\n",
      "[Epoch 165/1000] Train Loss: 0.0913  |  Val Loss: 0.2181\n",
      "Validation loss improved from 0.2186 to 0.2181.\n",
      "[Epoch 166/1000] Train Loss: 0.0904  |  Val Loss: 0.2178\n",
      "Validation loss improved from 0.2181 to 0.2178.\n",
      "[Epoch 167/1000] Train Loss: 0.0894  |  Val Loss: 0.2171\n",
      "Validation loss improved from 0.2178 to 0.2171.\n",
      "[Epoch 168/1000] Train Loss: 0.0885  |  Val Loss: 0.2165\n",
      "Validation loss improved from 0.2171 to 0.2165.\n",
      "[Epoch 169/1000] Train Loss: 0.0876  |  Val Loss: 0.2163\n",
      "Validation loss improved from 0.2165 to 0.2163.\n",
      "[Epoch 170/1000] Train Loss: 0.0867  |  Val Loss: 0.2159\n",
      "Validation loss improved from 0.2163 to 0.2159.\n",
      "[Epoch 171/1000] Train Loss: 0.0859  |  Val Loss: 0.2156\n",
      "Validation loss improved from 0.2159 to 0.2156.\n",
      "[Epoch 172/1000] Train Loss: 0.0849  |  Val Loss: 0.2153\n",
      "Validation loss improved from 0.2156 to 0.2153.\n",
      "[Epoch 173/1000] Train Loss: 0.0841  |  Val Loss: 0.2149\n",
      "Validation loss improved from 0.2153 to 0.2149.\n",
      "[Epoch 174/1000] Train Loss: 0.0833  |  Val Loss: 0.2149\n",
      "Validation loss improved from 0.2149 to 0.2149.\n",
      "[Epoch 175/1000] Train Loss: 0.0825  |  Val Loss: 0.2146\n",
      "Validation loss improved from 0.2149 to 0.2146.\n",
      "[Epoch 176/1000] Train Loss: 0.0817  |  Val Loss: 0.2143\n",
      "Validation loss improved from 0.2146 to 0.2143.\n",
      "[Epoch 177/1000] Train Loss: 0.0810  |  Val Loss: 0.2140\n",
      "Validation loss improved from 0.2143 to 0.2140.\n",
      "[Epoch 178/1000] Train Loss: 0.0802  |  Val Loss: 0.2140\n",
      "Validation loss improved from 0.2140 to 0.2140.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 179/1000] Train Loss: 0.0795  |  Val Loss: 0.2136\n",
      "Validation loss improved from 0.2140 to 0.2136.\n",
      "[Epoch 180/1000] Train Loss: 0.0787  |  Val Loss: 0.2134\n",
      "Validation loss improved from 0.2136 to 0.2134.\n",
      "[Epoch 181/1000] Train Loss: 0.0780  |  Val Loss: 0.2133\n",
      "Validation loss improved from 0.2134 to 0.2133.\n",
      "[Epoch 182/1000] Train Loss: 0.0773  |  Val Loss: 0.2131\n",
      "Validation loss improved from 0.2133 to 0.2131.\n",
      "[Epoch 183/1000] Train Loss: 0.0766  |  Val Loss: 0.2129\n",
      "Validation loss improved from 0.2131 to 0.2129.\n",
      "[Epoch 184/1000] Train Loss: 0.0759  |  Val Loss: 0.2130\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 185/1000] Train Loss: 0.0753  |  Val Loss: 0.2129\n",
      "Validation loss improved from 0.2129 to 0.2129.\n",
      "[Epoch 186/1000] Train Loss: 0.0746  |  Val Loss: 0.2127\n",
      "Validation loss improved from 0.2129 to 0.2127.\n",
      "[Epoch 187/1000] Train Loss: 0.0740  |  Val Loss: 0.2127\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 188/1000] Train Loss: 0.0734  |  Val Loss: 0.2127\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 189/1000] Train Loss: 0.0728  |  Val Loss: 0.2129\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 190/1000] Train Loss: 0.0721  |  Val Loss: 0.2127\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 191/1000] Train Loss: 0.0716  |  Val Loss: 0.2125\n",
      "Validation loss improved from 0.2127 to 0.2125.\n",
      "[Epoch 192/1000] Train Loss: 0.0710  |  Val Loss: 0.2123\n",
      "Validation loss improved from 0.2125 to 0.2123.\n",
      "[Epoch 193/1000] Train Loss: 0.0704  |  Val Loss: 0.2122\n",
      "Validation loss improved from 0.2123 to 0.2122.\n",
      "[Epoch 194/1000] Train Loss: 0.0699  |  Val Loss: 0.2122\n",
      "Validation loss improved from 0.2122 to 0.2122.\n",
      "[Epoch 195/1000] Train Loss: 0.0693  |  Val Loss: 0.2121\n",
      "Validation loss improved from 0.2122 to 0.2121.\n",
      "[Epoch 196/1000] Train Loss: 0.0688  |  Val Loss: 0.2122\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/1000] Train Loss: 0.0683  |  Val Loss: 0.2121\n",
      "Validation loss improved from 0.2121 to 0.2121.\n",
      "[Epoch 198/1000] Train Loss: 0.0677  |  Val Loss: 0.2121\n",
      "Validation loss improved from 0.2121 to 0.2121.\n",
      "[Epoch 199/1000] Train Loss: 0.0672  |  Val Loss: 0.2120\n",
      "Validation loss improved from 0.2121 to 0.2120.\n",
      "[Epoch 200/1000] Train Loss: 0.0667  |  Val Loss: 0.2119\n",
      "Validation loss improved from 0.2120 to 0.2119.\n",
      "[Epoch 201/1000] Train Loss: 0.0662  |  Val Loss: 0.2118\n",
      "Validation loss improved from 0.2119 to 0.2118.\n",
      "[Epoch 202/1000] Train Loss: 0.0658  |  Val Loss: 0.2119\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 203/1000] Train Loss: 0.0653  |  Val Loss: 0.2118\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 204/1000] Train Loss: 0.0648  |  Val Loss: 0.2118\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 205/1000] Train Loss: 0.0643  |  Val Loss: 0.2118\n",
      "Validation loss improved from 0.2118 to 0.2118.\n",
      "[Epoch 206/1000] Train Loss: 0.0640  |  Val Loss: 0.2121\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 207/1000] Train Loss: 0.0635  |  Val Loss: 0.2118\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 208/1000] Train Loss: 0.0631  |  Val Loss: 0.2116\n",
      "Validation loss improved from 0.2118 to 0.2116.\n",
      "[Epoch 209/1000] Train Loss: 0.0626  |  Val Loss: 0.2115\n",
      "Validation loss improved from 0.2116 to 0.2115.\n",
      "[Epoch 210/1000] Train Loss: 0.0623  |  Val Loss: 0.2117\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 211/1000] Train Loss: 0.0618  |  Val Loss: 0.2116\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 212/1000] Train Loss: 0.0614  |  Val Loss: 0.2116\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 213/1000] Train Loss: 0.0610  |  Val Loss: 0.2115\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 214/1000] Train Loss: 0.0606  |  Val Loss: 0.2117\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 215/1000] Train Loss: 0.0603  |  Val Loss: 0.2115\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 216/1000] Train Loss: 0.0598  |  Val Loss: 0.2114\n",
      "Validation loss improved from 0.2115 to 0.2114.\n",
      "[Epoch 217/1000] Train Loss: 0.0595  |  Val Loss: 0.2113\n",
      "Validation loss improved from 0.2114 to 0.2113.\n",
      "[Epoch 218/1000] Train Loss: 0.0591  |  Val Loss: 0.2115\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 219/1000] Train Loss: 0.0588  |  Val Loss: 0.2114\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 220/1000] Train Loss: 0.0584  |  Val Loss: 0.2115\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 221/1000] Train Loss: 0.0580  |  Val Loss: 0.2115\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 222/1000] Train Loss: 0.0577  |  Val Loss: 0.2115\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 223/1000] Train Loss: 0.0574  |  Val Loss: 0.2111\n",
      "Validation loss improved from 0.2113 to 0.2111.\n",
      "[Epoch 224/1000] Train Loss: 0.0570  |  Val Loss: 0.2112\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 225/1000] Train Loss: 0.0567  |  Val Loss: 0.2110\n",
      "Validation loss improved from 0.2111 to 0.2110.\n",
      "[Epoch 226/1000] Train Loss: 0.0564  |  Val Loss: 0.2111\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 227/1000] Train Loss: 0.0560  |  Val Loss: 0.2112\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 228/1000] Train Loss: 0.0557  |  Val Loss: 0.2111\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 229/1000] Train Loss: 0.0554  |  Val Loss: 0.2110\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 230/1000] Train Loss: 0.0551  |  Val Loss: 0.2110\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 231/1000] Train Loss: 0.0548  |  Val Loss: 0.2111\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 232/1000] Train Loss: 0.0545  |  Val Loss: 0.2112\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 233/1000] Train Loss: 0.0542  |  Val Loss: 0.2114\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 234/1000] Train Loss: 0.0539  |  Val Loss: 0.2116\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 235/1000] Train Loss: 0.0537  |  Val Loss: 0.2120\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 236/1000] Train Loss: 0.0533  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 237/1000] Train Loss: 0.0531  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 238/1000] Train Loss: 0.0527  |  Val Loss: 0.2125\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 239/1000] Train Loss: 0.0525  |  Val Loss: 0.2126\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 240/1000] Train Loss: 0.0522  |  Val Loss: 0.2128\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 241/1000] Train Loss: 0.0519  |  Val Loss: 0.2129\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 242/1000] Train Loss: 0.0518  |  Val Loss: 0.2132\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 243/1000] Train Loss: 0.0514  |  Val Loss: 0.2134\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 244/1000] Train Loss: 0.0512  |  Val Loss: 0.2135\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 245/1000] Train Loss: 0.0509  |  Val Loss: 0.2135\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 246/1000] Train Loss: 0.0507  |  Val Loss: 0.2136\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 247/1000] Train Loss: 0.0505  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 248/1000] Train Loss: 0.0502  |  Val Loss: 0.2140\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 249/1000] Train Loss: 0.0499  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 250/1000] Train Loss: 0.0497  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 251/1000] Train Loss: 0.0494  |  Val Loss: 0.2144\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 252/1000] Train Loss: 0.0492  |  Val Loss: 0.2145\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 253/1000] Train Loss: 0.0490  |  Val Loss: 0.2144\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 254/1000] Train Loss: 0.0488  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 255/1000] Train Loss: 0.0485  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 256/1000] Train Loss: 0.0483  |  Val Loss: 0.2146\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 257/1000] Train Loss: 0.0481  |  Val Loss: 0.2147\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 258/1000] Train Loss: 0.0479  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 259/1000] Train Loss: 0.0477  |  Val Loss: 0.2151\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 260/1000] Train Loss: 0.0474  |  Val Loss: 0.2153\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 261/1000] Train Loss: 0.0473  |  Val Loss: 0.2153\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 262/1000] Train Loss: 0.0470  |  Val Loss: 0.2155\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 263/1000] Train Loss: 0.0468  |  Val Loss: 0.2158\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 264/1000] Train Loss: 0.0466  |  Val Loss: 0.2161\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 265/1000] Train Loss: 0.0464  |  Val Loss: 0.2163\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 266/1000] Train Loss: 0.0462  |  Val Loss: 0.2166\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 267/1000] Train Loss: 0.0460  |  Val Loss: 0.2167\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 268/1000] Train Loss: 0.0459  |  Val Loss: 0.2171\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 269/1000] Train Loss: 0.0457  |  Val Loss: 0.2171\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 270/1000] Train Loss: 0.0455  |  Val Loss: 0.2174\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 271/1000] Train Loss: 0.0453  |  Val Loss: 0.2174\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 272/1000] Train Loss: 0.0451  |  Val Loss: 0.2173\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 273/1000] Train Loss: 0.0449  |  Val Loss: 0.2174\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 274/1000] Train Loss: 0.0448  |  Val Loss: 0.2176\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 275/1000] Train Loss: 0.0446  |  Val Loss: 0.2175\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 276/1000] Train Loss: 0.0444  |  Val Loss: 0.2176\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 277/1000] Train Loss: 0.0442  |  Val Loss: 0.2176\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 278/1000] Train Loss: 0.0441  |  Val Loss: 0.2177\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 279/1000] Train Loss: 0.0439  |  Val Loss: 0.2176\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 280/1000] Train Loss: 0.0438  |  Val Loss: 0.2178\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 281/1000] Train Loss: 0.0436  |  Val Loss: 0.2178\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 282/1000] Train Loss: 0.0434  |  Val Loss: 0.2179\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 283/1000] Train Loss: 0.0434  |  Val Loss: 0.2178\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 284/1000] Train Loss: 0.0431  |  Val Loss: 0.2180\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 285/1000] Train Loss: 0.0430  |  Val Loss: 0.2183\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 286/1000] Train Loss: 0.0428  |  Val Loss: 0.2183\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 287/1000] Train Loss: 0.0428  |  Val Loss: 0.2188\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 288/1000] Train Loss: 0.0426  |  Val Loss: 0.2188\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 289/1000] Train Loss: 0.0424  |  Val Loss: 0.2190\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 290/1000] Train Loss: 0.0423  |  Val Loss: 0.2194\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 291/1000] Train Loss: 0.0421  |  Val Loss: 0.2197\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 292/1000] Train Loss: 0.0420  |  Val Loss: 0.2196\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 293/1000] Train Loss: 0.0418  |  Val Loss: 0.2197\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 294/1000] Train Loss: 0.0417  |  Val Loss: 0.2197\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 295/1000] Train Loss: 0.0416  |  Val Loss: 0.2200\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 296/1000] Train Loss: 0.0414  |  Val Loss: 0.2201\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 297/1000] Train Loss: 0.0413  |  Val Loss: 0.2204\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 298/1000] Train Loss: 0.0411  |  Val Loss: 0.2206\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 299/1000] Train Loss: 0.0410  |  Val Loss: 0.2205\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 300/1000] Train Loss: 0.0409  |  Val Loss: 0.2206\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 301/1000] Train Loss: 0.0407  |  Val Loss: 0.2208\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 302/1000] Train Loss: 0.0407  |  Val Loss: 0.2207\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 303/1000] Train Loss: 0.0405  |  Val Loss: 0.2207\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 304/1000] Train Loss: 0.0404  |  Val Loss: 0.2208\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 305/1000] Train Loss: 0.0403  |  Val Loss: 0.2211\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 306/1000] Train Loss: 0.0401  |  Val Loss: 0.2213\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 307/1000] Train Loss: 0.0400  |  Val Loss: 0.2215\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 308/1000] Train Loss: 0.0399  |  Val Loss: 0.2215\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 309/1000] Train Loss: 0.0398  |  Val Loss: 0.2215\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 310/1000] Train Loss: 0.0397  |  Val Loss: 0.2218\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 311/1000] Train Loss: 0.0396  |  Val Loss: 0.2221\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 312/1000] Train Loss: 0.0395  |  Val Loss: 0.2225\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 313/1000] Train Loss: 0.0393  |  Val Loss: 0.2225\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 314/1000] Train Loss: 0.0393  |  Val Loss: 0.2228\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 315/1000] Train Loss: 0.0392  |  Val Loss: 0.2227\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 316/1000] Train Loss: 0.0390  |  Val Loss: 0.2228\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 317/1000] Train Loss: 0.0389  |  Val Loss: 0.2230\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 318/1000] Train Loss: 0.0388  |  Val Loss: 0.2231\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 319/1000] Train Loss: 0.0387  |  Val Loss: 0.2232\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 320/1000] Train Loss: 0.0387  |  Val Loss: 0.2237\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 321/1000] Train Loss: 0.0385  |  Val Loss: 0.2239\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 322/1000] Train Loss: 0.0384  |  Val Loss: 0.2239\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 323/1000] Train Loss: 0.0382  |  Val Loss: 0.2239\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 324/1000] Train Loss: 0.0383  |  Val Loss: 0.2236\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 325/1000] Train Loss: 0.0381  |  Val Loss: 0.2236\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 325 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:48.942060Z",
     "iopub.status.busy": "2025-05-08T17:32:48.942060Z",
     "iopub.status.idle": "2025-05-08T17:32:51.366433Z",
     "shell.execute_reply": "2025-05-08T17:32:51.366433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.1575 | Test Accuracy: 95.77%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:51.370438Z",
     "iopub.status.busy": "2025-05-08T17:32:51.369439Z",
     "iopub.status.idle": "2025-05-08T17:32:51.375931Z",
     "shell.execute_reply": "2025-05-08T17:32:51.375931Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:51.378944Z",
     "iopub.status.busy": "2025-05-08T17:32:51.378944Z",
     "iopub.status.idle": "2025-05-08T17:32:54.865870Z",
     "shell.execute_reply": "2025-05-08T17:32:54.865870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACtW0lEQVR4nOzdd3jT5dfH8U862S20QNmr7FH23lOQJcgQmSJ7IyCIrAqWIUOUIVv2dIsoyFCmbGWKMsoolFJogZZC2zx/8JCfoS000Caheb+uK9cl35Vz323i6cn53jEYjUajAAAAANgdJ1sHAAAAACB+JOsAAACAnSJZBwAAAOwUyToAAABgp0jWAQAAADtFsg4AAADYKZJ1AAAAwE6RrAMAAAB2imQdAAAAsFMk6wBgAzt37lSdOnWUIUMGGQwGGQwGXbx40WrPP378eBkMBo0fP95qz+nIateuLYPBoJ07d9o6FACvGJJ1IB558+Y1JVDPeixbtsx0jtFo1O7duzV8+HBVrlxZnp6ecnNzU/bs2dW6dWvt2LEjwed78j/y5z2SKrH666+/NGjQIJUqVUoZM2aUm5ubsmbNqgYNGmjmzJm6deuW2fE7d+40xZAtWzZFRkbGe90rV66YjnvWGGfNmpVgbO++++5LjTU2NlZr165VmzZtlCdPHqVJk0Zp06ZVwYIF1bFjR/3www8yGo0vdO2kcvLkSTVq1Eg7d+6Ut7e3qlWrpmrVqilVqlQ2jcvePPmDwmAwKGvWrIqOjk7w2Fu3bsnNzS3e1+bLWLZsmcaPH2/VP6QA4L9cbB0AYM8KFiyoLFmyJLg/a9aspv/evn276tevL0lycnKSr6+v0qZNq3Pnzumrr77SV199pQ8//FAfffRRgtfLlSuXcufOneD+Z+1LjJiYGA0ZMkRz5sxRbGysXFxc5Ovrq/Tp0+vGjRvatm2btm3bpgkTJmjjxo2m8fzX9evXNW/ePA0dOvSF45g8ebJ69uypNGnSvMxw4vj333/VqlUr/fnnn5KkjBkzqnDhwjIajbp06ZJWrVqlVatWqVy5ctq9e7fNkuPFixfr4cOHGjBggGbPnm2TGLy9vVW4cGF5e3vb5PktFRwcrF9++UVNmjSJd//atWv16NGjJH/eZcuWadeuXapdu7by5s37wtfJnTu3ChcunOS/8wAcgBFAHHny5DFKMi5dujTR52zdutXo6+trnDt3rjE0NNS0PSoqyjhq1CijJKMk4/fffx/n3Fq1ahklGceNG5cE0Sesbdu2RknG9OnTGz/99FNjWFiY2f4LFy4YR44caUyTJo1x5syZpu07duwwSjI6OzsbJRmzZMlivH//fpzrX7582TTOpz0Z45NrTJs2Ld4Yu3fv/kJzcfHiRWPmzJmNkozly5c37tixwxgTE2PaHx0dbdyxY4exQYMGRknG27dvW3T9pNS4cWOjJOPmzZttFsOrYNy4cUZJxsKFCxslGdu3b5/gsZUqVTIaDAZjwYIFLX7tPsuT39sdO3YkyfUAwFK0wQBJpGLFijp9+rT69OmjjBkzmra7ubnp448/VuPGjSVJCxcutEl8ixYt0vr165U6dWrt2LFDAwcOVIYMGcyOyZs3rwICAnTw4EH5+vrGuUbevHlVpUoVBQcHa86cOS8Ux1tvvSVJmjp1qu7fv/9C14jP22+/rZs3b6pWrVr67bffVLt2bTk5/e8tztnZWbVr19Yvv/yiOXPmyNnZOcme21JP2ohSp05tsxheJdWqVVPevHn17bff6u7du3H2//PPPzpw4IBq1ar10p8+AYC9IVkHkkiGDBnk4pJwZ1mDBg0kSX///be1QjKJiYnRpEmTJEljx45VuXLlnnl8sWLF1LRp03j3TZgwQdLjZPvevXsWx9KoUSNVrVpVN2/e1Oeff27x+fHZvn279uzZI1dXVy1fvvy5SXDfvn2VPn16s22PHj3SZ599pooVKypDhgxKmzat/Pz8NGnSJEVERMS5xsWLF2UwGEytEStXrlT58uWVJk0aZcqUSW3atNH58+fNzunatavZTYZ16tQx9Vh37dpV0uO2i//++2lP7h+oXbt2nH27d+/WG2+8IR8fH7m6uipTpkwqWrSo3n33Xe3fv9/s2OfdYLp37161atVKWbNmlZubm3LmzKnOnTvr9OnT8R7/3xsoz5w5ozZt2sjb21upU6dWuXLltH79+njPSwyDwaC3335bkZGR2rRpU5z9K1askCR17NgxwWtERkZqzZo1at++vQoXLqx06dIpXbp0Kl26tCZOnBjnD8cn87xr1y5J5j+r//bEP/17sHDhQlWoUEHp06c3u3cjvhtMf//9dzk7Oytt2rQ6e/ZsnJhPnTql1KlTy9nZWb///nui5gpAykOyDljJgwcPJNmmmnrgwAFdvHhRLi4u6tmz50tdq0GDBqpevbpCQkL02WefvdA1niT806ZNe6GE/2lr166VJDVt2vSFKquRkZF67bXXNHDgQB08eFA5c+aUr6+vTpw4oQ8//FDVqlWLc9Ptf40aNUqdOnVSSEiIChUqpIiICG3cuNE0T08UKlRI1apVM32iUaJECdPNpYUKFbI47v/69ttvVatWLX3zzTeKjo5WqVKllDVrVl2+fFmLFy82zVFizJs3T9WrV9fXX38tSfLz89P9+/e1YsUKlS1bVj/++GOC5x4+fFgVKlTQzz//rLx58yp9+vQ6cuSI2rVrp5UrV77w+Dp16iRJ8V5j1apVSpUqld58881nxtWhQwdt2rRJERERKlq0qLJnz66TJ09qzJgxqlmzptmN0x4eHgn+rKpVq2Z2v8oTffr0Uc+ePXXjxg0VKVJEnp6ezxxTjRo19N577ykiIkIdO3Y0u4H20aNH6tSpkx48eKDhw4erRo0az7wWgBTM1n04gD16kZ71Z4mNjTWWKVPGKMnYv3//OPuTu2d92rRpRknG0qVLv9D5T3rWCxQoYDQajcZff/3VKMmYKVMmY3h4uOm4xPSsr1ixwmg0Go01a9Y0SjJOmjTJ7LgX6VkvXry4UZJx1qxZLzA6o/G9994zSjJmz57dePjwYdP2c+fOGYsUKWKUZGzbtq3ZORcuXDBKMrq4uBgzZMhg1n8eFBRkLFWqlFGS8f3334/zfM/qg166dKlRkrFLly7xxvrkZ1GrVi2z7SVKlDBKMs6dO9cYHR1t2h4bG2vcsWOH8bvvvjM7/kk/+NPzfPToUaOLi4tRknHq1Kmmvv8HDx4Y+/bta5Rk9PDwMF67di3eMbm6uhr79+9vjIyMND3/+++/b5rf/8b2PE9i7N69u9FoNBorVKhgdHJyMl65csV0zJ49e8x+PvXq1Yv3tXvx4kXj+vXrjXfv3jXbHhQUZHzzzTeNkozjx4+PE8Pzetaf/B44Ozsb06ZNa/z2229N+yIiIp57naioKNPvyocffmja/uQ+Fz8/P2NUVFTCkwQgxaOyDjxDt27dnrmU4p07dxJ1nYULF+ro0aNyc3PT4MGDEzxuwoQJz3y+Y8eOvdA4rl69KknKly/fC53/tLp166pWrVoKDQ3Vp59++kLXeFJdnz59usLDw18qnpcZX3h4uObNmydJmjNnjsqWLWva5+vrq+XLl0uSNmzYoH///TfO+dHR0Ro3bpzpngRJ8vHx0cSJEyVJP/30k8UxvYhz584pY8aM6tOnj1k//pOWmWbNmiXqOp988omio6PVokULDR8+3NT37+7urs8//1zFixdXWFiYac6eVqxYMX366aemlXYMBoM++ugj+fj46Nq1a6aVel5Ex44dFRsbq1WrVpm2JaYFRpLy5MmjNm3aKF26dGbbfXx8tHz5crm5uZld11IxMTHy9/dX8+bNTdsS8ymam5ubVq5cKXd3dwUEBGjfvn3au3evpk6dqlSpUmnVqlVyc3N74bgAvPpI1oFnKFiwoNlH308/ntWj/sSRI0c0aNAgSdLEiRNVoECBBI/NlSvXM5/v6UQjsZ7clJc2bdoXOj8+T5LtGTNmKCwszOLza9eurdq1ays0NPSZ664nxsuMb/fu3YqIiFDu3LnVokWLOPsrVKigKlWqyGg0auvWrfFeo3v37vGeJylO33pyyZUrl+7cuZNgjIn1yy+/SJIGDBgQZ5/BYNDAgQPNjnvaO++8Y3ZjryS5urrKz89P0svNx1tvvSUXFxdTK8zDhw+1fv16eXt767XXXnvu+bGxsfr222/Vr18/NW7cWDVq1FD16tXVoEEDGQwGnTt3Lt77ExKrc+fOL3ReyZIlNXHiRMXExKhTp07q1KmTYmJi9PHHH6t48eIvHA+AlIF11oFn+OCDDxK80S8xLly4oKZNm+rBgwfq0KGDhg0b9szj33nnnWT5RsknN1Mm5eortWrVUt26dbV9+3bNmjVL48aNs/ga/v7+qlmzpmbOnKmBAwc+t8c3IenTp9edO3deaHxPbvgtUqRIvF/mJEnFixfXvn374r052NvbWx4eHnG2P1mfPyl68hNjyJAh6tevnxo2bKhy5cqpfv36ql69umrVqhXnZtqE3LlzRzdv3pT0uEIenyfJY0I3Sif0x2hSzEfmzJnVsGFDbd68WcePH9eFCxcUGhqqfv36ydXV9Znn3rlzR02aNNG+ffueedzt27dfaC10b2/vl1qzfujQofrxxx9NN6DWrVv3mZ/CAXAcVNaBZHL9+nU1aNBAQUFBev31102rfNhCjhw5JD3+4yEp+fv7S5JmzpyZ6Jag/6pRo4bq16+vO3fuaObMmS8cx8uM70nymJgvv4pv2cCEqvlPV5eTW9++fbV8+XL5+fnp8OHDmjJlipo1a6YsWbKoZ8+eifr047+JdELz8ay5kJ4/H8aX/PbY/95o+qTC/mTbswwdOlT79u1T4cKFtWnTJl29elVRUVEyGo0yGo2m36EX/WKll/3UysnJSbVq1TL9+8nKQQBAsg4kg9DQUDVo0ED//vuvatWqpQ0bNjy38pecqlatKkk6ceKEQkNDk+y61apVU4MGDRQWFqbp06e/0DWetNPMmjVLt2/ffqFrPBnfk2X2LPGktSg4ODjBY27cuCFJia5Qv4wnCVpCSe2zPj3o1KmTjh07pqCgIK1du1bdu3eXi4uLFi5c+NyebklmbVYJzYc15yI+LVq0UIYMGbRixQr98MMPKliwoCpVqvTMc6Kjo01LR3777bdq1aqVsmfPbuoFj46O1vXr15M99mc5duyYAgICTH/UjBgxwmwlIQCOi2QdSGL37t1TkyZNdOLECVWoUEHff/+9zb/8plKlSsqbN6+io6O1YMGCJL32k+r6p59++kJ/CFStWlWNGjVSeHj4Cyf87dq1kyT98MMPCgwMtOjcJ0smnj59OsEE+eTJk2bHJqcnFdon7ShP++eff557DR8fH7Vr106LFi3SgQMH5OTkpB9++EFBQUHPPM/T01OZM2eW9HiN7/hYcy7ikzp1arVq1Uo3btxQVFRUov4IuXnzpu7fv69MmTKpcOHCcfafOHFCMTEx8Z5rjer2gwcP1LFjRz18+FD+/v568803df36dfXu3TvZnxuA/SNZB5JQVFSUWrRooQMHDqh48eLasmWLzSqQ/+Xs7KxRo0ZJkj766CMdOXLkmcefPn1aP/zwQ6KuXblyZTVu3Fh3797VJ5988kLxPUn4Z8+e/cz1zBNSr149ValSRY8ePVKXLl1Ma9onZP78+aY2jurVqytNmjS6fPmyvv322zjHHjp0SPv27ZPBYDB9sVVyyp8/v6THldb/rrstPb5BcunSpRZdr1ixYqae+mvXrj33+EaNGklSvGvoG41G0/Ynx9lCz549Va9ePdWrVy9RLTBP/lgODw83W0v9ialTpz733PjOSyoffPCBTp48qcqVK2vkyJGaP3++fHx8tGnTJtNqRAAcF8k6kERiYmLUvn17bd++XQUKFNDWrVuVKVMmW4dl0rNnT7Vu3VoRERGqU6eOPvvsszh9x5cvX9aHH36o8uXLJ6qC+8STVpbVq1e/UGwVK1ZUkyZNdPfuXX3//fcvdI1Vq1bJy8tLO3fuVI0aNbRz507Fxsaa9sfGxmr37t167bXX1KdPH1MlNUOGDOrTp48kqX///jp69KjpnH///VddunSRJLVt2/aZK/kkFT8/P2XPnl1BQUEaN26cqdr/4MEDDR48ON6Kd3h4uNq3bx9nzDExMZo9e7Zu376ttGnTxltVftp7770nFxcXffvtt5o+fbrpeg8fPtSgQYN04sQJeXh4mObMFqpUqaJt27Zp27ZtiVqu09PTU8WLF1d0dLSGDBmihw8fSno8P1OmTNG6desSXB7xyR9PL9JilRg7duzQrFmzlCZNGi1fvlzOzs7y8vLSkiVLJD1elcfST4sApCysBgM8w8cff6xFixYluL9t27ampezWr1+vb775RtLjm8XatGkT7znZsmXThg0b4t23ZMkSbdu2LcHnq1mzpj7++ONERh/X2rVrNWjQIM2bN08DBw7Ue++9J19fX6VPn17BwcG6ePGiJClTpkwqVapUoq9boUIFNW3aNNHV+Pj4+/tr8+bNCbYjPE++fPm0b98+tWrVSocOHVKdOnWUKVMm5cmTR0ajUZcuXTL1xFeqVMmsNenJpw07duxQ2bJlVaxYMbm6upraI/z8/DRnzpwXHpslnJ2dNWXKFHXq1Ekff/yxFi5cqDx58ujvv/9WbGysAgIC4qwqFBsbq3Xr1mndunVKmzatfH195erqqosXLyokJEQGg0GzZs1K1NKfpUuX1uzZs9WvXz8NGzZM06ZNU+7cuXXu3DnduXNH7u7uWrVqlXx8fJJrCpJFQECAWrRooS+++EIbNmxQ/vz5TfMzZswYLV++XJcuXYpzXrt27TRnzhxNmTJFX3/9tXx8fGQwGDRy5MhELRf5LGFhYeratauMRqOmT5+uggULmvY1btxYvXv31vz589WlSxdt376dG04BB0WyDjzDuXPndO7cuQT3ly9f3vTfUVFRiTovT548CV7v8uXLunz5coL7X2ZpOElycXHRnDlz1KtXLy1cuFA7duzQlStXFBERoYwZM6pevXpq3ry5OnfubPEyihMmTHipZL1cuXJq3ry5vvvuuxe+RsGCBXXs2DGtW7dOmzZt0sGDB3X69GkZDAZlz55dTZo0UceOHdWoUSOzxCd16tT6+eefNW/ePK1YsUKnT59WbGysihUrpnbt2mnIkCEvtJzfi+rYsaPc3d01ZcoUnTx5UufPn1e9evU0ceLEeG/8TJ8+vVasWKFffvlFBw8e1MWLF/Xw4UPlypVLr732moYNG2Za5zwx+vTpo1KlSumTTz7Rnj17dOzYMWXOnFlNmzbVqFGjElzW0Z41a9ZMP/30k/z9/XX06FGdPXtWxYsX16xZs/T2228n2G5So0YNrV69WrNmzdLJkydNS1a+zJKuT/Tv31+BgYF67bXX4u1Pnz59un799Vft3LlTM2bM0HvvvffSzwng1WMwvuw6WgAAAACSBT3rAAAAgJ0iWQcAAADsFD3rwCvm+vXrevPNNxN9/OjRo9W4ceNkjAgAACQXknXgFfPgwQPt2bMn0cc/+cZJAADw4n777TdNmzZNhw8fVlBQkL7++mu1bNnymefs2rVLQ4cO1cmTJ5U9e3aNGDHC4i88ow0GeMXkzZtXRqMx0Y+kWLUCAABHd//+ffn5+enzzz9P1PEXLlxQkyZNVKNGDR09elQffPCBBg4cqE2bNln0vKwGAwAAAFjAYDA8t7L+/vvv67vvvtPp06dN23r37q3jx49r3759iX4uKusAAABwSFFRUQoPDzd7/Pd7U17Gvn371LBhQ7NtjRo10qFDh/To0aNEXyfF9qynLjvQ1iHY3O0/Zts6BAAAYGOp7CzbS12mv61DMHm/hbcmTJhgtm3cuHEaP378S1/7+vXrypo1q9m2rFmzKjo6WiEhIcqWLVuirmNnPz4AAADAOkaNGqWhQ4eabXN3d0+y6//327Il6Un3+dPbn4VkHQAAAA7J3d09SZPz//Lx8dH169fNtgUHB8vFxUVeXl6Jvg7JOgAAAKzH4Bi3TFapUkXff/+92bZffvlF5cuXl6ura6Kv4xizBQAAALyEe/fu6dixYzp27Jikx0szHjt2TIGBgZIet9R07tzZdHzv3r116dIlDR06VKdPn9aSJUu0ePFiDRs2zKLnpbIOAAAAPMehQ4dUp04d07+f9Lp36dJFy5YtU1BQkClxl6R8+fJp8+bNGjJkiObMmaPs2bNr9uzZat26tUXPm2LXWWc1GFaDAQAAdrgaTLlBtg7BJPLwp7YO4blogwEAAADsFMk6AAAAYKfs7IMRAAAApGgOshpMUmG2AAAAADtFZR0AAADWY8G3d4LKOgAAAGC3SNYBAAAAO0UbDAAAAKyHG0wtwmwBAAAAdopkHQAAALBTtMEAAADAelgNxiJU1gEAAAA7RWUdAAAA1sMNphZhtgAAAAA7RbIOAAAA2CnaYAAAAGA93GBqESrrAAAAgJ0iWQcAAADsFG0wAAAAsB5Wg7EIswUAAADYKZJ1AAAAwE7RBgMAAADrYTUYi1BZBwAAAOwUlXUAAABYDzeYWoTZAgAAAOwUyToAAABgp0jW/1/2zB5aMrGTrmwP0K09n2j/mhEqUzSXaf+C8W8r8shss8euL4fGuU6lUnn10xf9FbJnmoJ2TdbPCwYolburJKlGOd8413jyKFcst+kanwxrpT2rhuvO/hnav2ZE8g8+ia1bs0qNG9ZVhTIl1b5NKx05fMjWIVmdo8+Bo49fcqw5uHHjhka9P0w1q1ZSpXJ+atuqhU6dPBHvsf7jx8qveGGtXL7MukEmkcULv1CHtq1VpUIZ1a5RRYMH9NXFC+fNjtm29Rf17tFdtapVkl/xwjpz+nSc62xcv07du3ZS1Ypl5Ve8sMLDw601BKtypNdBfBx9/AkyGOzn8QogWZfkmT61ti8drEfRMWo5YJ7KvPmxRs78RnfuRpod9/OeU8rbYLTp0XLAfLP9lUrl1bef9dGv+86oRqfpqt5xuuav+12xsUZJ0v7jF8zOz9tgtJZ8tVcXr97S4VOBpusYDAYt/3a/Nv5yJPkHn8S2/LRZUycHqEfPPlq38RuVLVtOfXv1UNC1a7YOzWocfQ4cffySY81BeFiYunZ8Sy4urpozf6G++u5HvTdipNKnzxDn2O2/btOJP48rc5YsNog0aRw6+IfavfW2VqxZry8WLlV0TIx69+iuiIgI0zGRkREqXaaMBg0ZluB1HjyIVNVqNdS9R29rhG0TjvQ6iI+jjx9Jx2A0Go22DiI5pC47MNHHfjSgmaqUzq/63T9N8JgF49+WZ/rUavveogSP2fXlUP26/4z8521O1PO6uDjpn5/8NX/d75q86Oc4+0f3aqxmtUuq8ltTE3W9p93+Y/YLnfcy3m7fRkWLFdOHYyeYtrVs1lh16tbXoCHvWT0eW3D0OXD08UuONQezZnyiY0ePaNmK1c887saNG+r4VhvNW7BYA/r00tudOqtj567WCTIZhYaGqk6NKlry5UqVK1/BbN/Vq1fUpGE9rdv4jYoULRrv+Qf/OKB3u3XW7/sOKkOGuH/gvMoc6XUQH3safyo7W04kdY2xtg7BJPJ3f1uH8FxU1iW9XqukjpwK1Kop3XRp2yTtWz1C3d6oEue4GuV9dWnbJP359Yea82F7Zc6YzrQvc8Z0qlgyr26G3tOOpUN0cetE/bJwoKqWzp/g8zatWVLenum08vsDyTIua3v08KFOnzqpKlWrm22vUrWajh87aqOorMvR58DRxy853hzs2rFdxYuX0LAhA1W7RhW1bd1SmzasNzsmNjZWo0cOV9du3eXrW9BGkSaPe3fvSpIyeHjYOBL74mivg6c5+vify+BkP49XwKsRZTLLl8NLPd6srn8u31TzfvO0aNNuTR/eWh1e/1+V5Je9p9Rt9HI17vW5Rs78RuWK59ZPX/SXm+vjP1fz5fSW9LgavuTrvWrRf76OnbmszfP7q0CuzPE+b5eWlbV132lduXEn2cdoDbfv3FZMTIy8vLzMtnt5eSsk5KaNorIuR58DRx+/5HhzcOXKZa1ft0a58+TVvAWL1aZde00JmKjvv/3GdMzSxQvl7OKiDh072y7QZGA0GvXJ1ACVKVtOBQsWsnU4dsXRXgdPc/TxI2nZ2QcjcV2+fFnjxo3TkiVLEjwmKipKUVFRZtuMsTEyODkn6jmcnAw6cuqyxn3+gyTp+NkrKpY/m3q2qa7VPx6UJG385X9/CZ/6N0hHTgXq7I/j1bhGMX27/U85/f9NCou/2qMV3x0wXad2xULq0qKyxn7+vdlz5sjiqQZViqrj+0sTFeOrxPDUDRtGozHOtpTO0efA0ccvOc4cxMYaVbxECQ0c/PiG+6JFi+nff/7R+nVr1KxFS506eUKrVizX2o1fpbjxB0z017m//35uC5Ajc5TXQUIcffxIGnZfWQ8NDdWXX375zGMCAgLk4eFh9oi+kfg7rq+HhOv0+etm285cuKFcPhmfeU5gUKh8cz2+USooJEyS4lznbALX6dS8km6F3dcPv/2V6DjtXUbPjHJ2dlZISIjZ9tDQW/Ly8rZRVNbl6HPg6OOXHG8OMmfOrPwFCphty58/v4KCHt9Ed+TwIYWG3tJr9euobKliKluqmK5du6rp06aocYO6tgg5SQRM+kg7d27XwqVfKquPj63DsTuO9jp4mqOP/7ls3fryirXB2Lyy/t133z1z//nz55+5X5JGjRqloUPNl1HMUnNUomPYd+y8CuU1X52gYJ7MCgy6neA5mTzSKGfWjKYk/dK1UF0LvqNCecyv45s7i37ZeyrO+Z2bV9LqH/5QdHRsouO0d65ubiparLj2792jevUbmLbv37tXtevWs2Fk1uPoc+Do45ccbw5KlymrixcumG27dPGismfPIUlq2ryFKlWpara/T8/uatqshVq+0cpqcSYVo9GogEkfafuvW7V42QrlzJnr+Sc5IEd7HTzN0cePpGXzZL1ly5YyGAx61qI0z/vIyN3dXe7u7ubnJLIFRpI+W7VTO5YO0fB3GmjT1qOqUDyP3mlVVf0nrpMkpU3tpg97NdY3248r6Ga48mTPJP/+zXTrzn19t+NP03VmLt+uD3s11l9/X9Pxv6+oY9OKKpw3izqMMG/hqV2xkPLl9Nayb/fHG0/+XN5Kl9pdWb3SK7W7q0oVevw/vdPnr+tRdEyix2ULnbp00+iRI1SsRAn5+ZXRpg3rFBQUpDbt2ts6NKtx9Dlw9PFLjjUHHTt3UZeOb2nRgvlq2KixTvz1pzZuXK+x4x+vsODpmVGenuafLrq6uMrb21t58yV8A769+vijCfpp8w+a9dlcpU2TViE3H/cfp0ufXqlSpZIkhd25o6CgIN28GSxJunjx8R8z3t7e8s78+B6mkJs3FRISosuBj5ft/efc30qTJq2yZcsmD09PK48qeTjS6yA+jj7+Z3KiFcgSNk/Ws2XLpjlz5qhly5bx7j927JjKlSuXrDEcPhWodsMWyb9/M33Q4zVdvHZLwz/5Smt/etxKExNrVPGC2dWhaUV5pk+t6yHh2nXwnDqNXKp7Ef/rlf989U6lcnPR1PfeUEaPNPrr72tq2neuLlwx/xisa4vK2nfsvM5euBFvPPPGvKWa5f+3YsKBte9Lkgq/Pl6BQaFJPfwk9VrjJgq7c1sL5s3VzZvB8i1YSHPmLzBV2RyBo8+Bo49fcqw5KFGylGZ8+rlmz5qhL+bNUY6cOTXi/Q/0etPmtg4tWaxft0aS1L1rJ7Pt/hMD1OL/PynYuWO7xn74v0933x82RJLUu29/9ek3QJK0Yf1azZ/7uemYbp3fjnOdV50jvQ7i4+jjR9Kx+TrrzZs3V+nSpeXvH/86l8ePH1eZMmUUG2tZu4gl66ynVLZYZx0AANgXu1tnvc5Htg7BJHLHGFuH8Fw2//ENHz5c9+/fT3C/r6+vduzYYcWIAAAAkGxekRs77YXNk/UaNWo8c3/atGlVq1YtK0UDAAAA2A/+tAEAAADslM0r6wAAAHAgfDGURaisAwAAAHaKZB0AAACwU7TBAAAAwHpYDcYizBYAAABgp6isAwAAwHq4wdQiVNYBAAAAO0WyDgAAANgp2mAAAABgPdxgahFmCwAAALBTJOsAAACAnaINBgAAANbDajAWobIOAAAA2Ckq6wAAALAebjC1CLMFAAAA2CmSdQAAAMBO0QYDAAAA6+EGU4tQWQcAAADsFMk6AAAAYKdogwEAAID1sBqMRZgtAAAAwE6RrAMAAAB2ijYYAAAAWA+rwViEyjoAAABgp6isAwAAwHq4wdQizBYAAABgp0jWAQAAADtFGwwAAACshzYYizBbAAAAgJ0iWQcAAADsFG0wAAAAsB7WWbdIik3Wb/8x29Yh2FzGev62DsGmrmz+wNYh2Fxa9xT7EgcAwCHQBgMAAADYKcpuAAAAsB5Wg7EIswUAAADYKSrrAAAAsB5uMLUIlXUAAADATpGsAwAAAHaKNhgAAABYDzeYWoTZAgAAAOwUyToAAABgp2iDAQAAgPWwGoxFqKwDAAAAdorKOgAAAKzGQGXdIlTWAQAAADtFsg4AAADYKdpgAAAAYDW0wViGyjoAAABgp0jWAQAAADtFGwwAAACshy4Yi1BZBwAAAOwUyToAAABgp2iDAQAAgNWwGoxlqKwDAAAAdorKOgAAAKyGyrplqKwDAAAAdopkHQAAALBTtMEAAADAamiDsQyVdQAAAMBOkawDAAAAdoo2GAAAAFgNbTCWobIOAAAA2CmSdQAAAMBO0QYDAAAA66ELxiJU1pPBujWr1LhhXVUoU1Lt27TSkcOHbB2Sxc6sHajIXWPjPGYObixJalGjiL6b9rYufztMkbvGqpRv1jjX+HlW5zjnLx/b6rnP81HPelYZ48tavmShqpYtrlnTAkzbdv66VYP79lDjutVUtWxx/X32dJzzboXc1IQPR6ppg5qqW7W8unZ4U9u3/WzN0JNdSngNvCzmgDlw9PFLzIGjjx9Jg2Q9iW35abOmTg5Qj559tG7jNypbtpz69uqhoGvXbB2aRar3WqS8b0w3PZoMXSFJ+mrnKUlSmtSu2nfissYs+PWZ11n8/WGz6/Sf/mOcYyYs3mF2zOQVvyX9gJLYqZN/6duvNsi3YCGz7ZGRkSpVuoz6DBiS4Ln+Y0Yp8NIFTZ35uVas/1q16tbX2JHDdPZM3MT+VZRSXgMvgzlgDhx9/BJz4OjjfxaDwWA3j1cByXoSW/HlUr3RurVavdlG+QsU0IhRo+WTzUfr162xdWgWCQmL0I3Q+6ZHkyoF9e+VUP1+7JIkac0vfyngy9+0/fD5Z14n8sEjs+uE34+Kc8y9iIdmx9yPfJQsY0oqERH3NWH0+xo5ZoLSZ/Aw29e4aXO907OvKlSqkuD5J/48pjfbva1iJUopR85c6vZub6VLn15/nzmV3KFbRUp5DbwM5oA5cPTxS8yBo48fSYdkPQk9evhQp0+dVJWq1c22V6laTcePHbVRVC/P1cVJ7RuU0pc/HbP43HYNSuryt8N0eFlvBfRpoHSp3eIcM7RDVV35bpj2L+qpER2ry9XFvn8tp0+eqKrVaz4zIX+WUqXL6tdftig87I5iY2O19efNevTwocqUq5DEkVpfSn0NWII5YA4cffwSc+Do40fSsosbTCMjI3X48GFlypRJxYoVM9v34MEDrV+/Xp07d7ZRdIl3+85txcTEyMvLy2y7l5e3QkJu2iiql9e8RhF5pkullRYm62u3/aWLQXd0I/SeiufLIv+edVXSN6uavrfSdMycTQd09O/runM3UuWL5pB/z7rKm81Tfaf9kMSjSBpbf96ss2dOa/GKdS98jY8mT9eYke/ptTrV5OziolSpUilg+mzlzJU7CSO1jZT6GrAEc8AcOPr4JebA0cf/PK9K+4m9sHmy/vfff6thw4YKDAyUwWBQjRo1tGbNGmXLlk2SFBYWpm7duj0zWY+KilJUlHl7hdHZXe7u7skae0Ke/iU0Go2v9C9mlyZl9PMf/yjo1j2Lzlv6w/+qB6cu3NQ/V0K1d2EPlS7oo2PnrkuSPttwwHTMifPBunM3Ums+aqsPv/hVoeGRSTOAJHLjepBmTZusWXMXvNTv1oK5s3X3brhmz1ssj4ye+m3Hdn04YqjmLV6uAk/1wL+qUtpr4EUwB8yBo49fYg4cffxIGjbvN3j//fdVsmRJBQcH6+zZs8qQIYOqVaumwMDARF8jICBAHh4eZo9pUwKef2ISy+iZUc7OzgoJCTHbHhp6S15e3laPJynkzuqhuuXyadkPR176Wkf/DtLDRzHyzZkpwWP+OHVVklQgR8LH2MqZ06d0O/SW3nm7rWpUKKUaFUrp6OGD2rB2lWpUKKWYmJjnXuPK5UBtXLdaH4ybqPKVKqtgoSLq3quvihQrrk3rX/0+xpT4GrAUc8AcOPr4JebA0cePpGXzZH3v3r36+OOP5e3tLV9fX3333Xdq3LixatSoofPnn33z4hOjRo1SWFiY2WP4+6OSOfK4XN3cVLRYce3fu8ds+/69e+VXuozV40kKnRqXVvCd+/pp/7mXvlaxfJnl5ur8zAq9X0EfSdL1W3df+vmSWvmKlbVi/TdatmaT6VGkWHE1bNxUy9ZskrOz83OvEfXggSTJ6anKipOTk2JjY5MlbmtKia8BSzEHzIGjj19iDhx9/M9j6xVgXrXVYGzeBhMZGSkXF/Mw5syZIycnJ9WqVUurV69+7jXc3eO2vDyITtIwE61Tl24aPXKEipUoIT+/Mtq0YZ2CgoLUpl172wT0EgwGqXNjP63a8qdiYoxm+zKmT6VcWT2UzSu9JKlQrsd9eTdC7+lG6H3ly55R7RuU1M/7zykkLEJF82TW5H4NdPTvIO07cVmSVKl4TlUslkO7jl5U2L0olS+aXVP7NdT3u8/qcnC4dQebCGnTplUB34Jm21KnTiMPDw/T9vCwO7p+PUghNx/3JAZevCjpcZ+il3dm5cmbTzlz5daUSRM0YMgwZfDw1G87t+vggX2a9ulcq44nuaSk18CLYg6YA0cfv8QcOPr4kXRsnqwXKVJEhw4dUtGiRc22f/bZZzIajWrevLmNInsxrzVuorA7t7Vg3lzdvBks34KFNGf+AmXPnsPWoVmsbrn8yu3jqS83x71z/fVqhbVwVAvTv1eMf1OSNHHpLk1atkuPHsWoTtl86te6otKldtOV4HBt2X9Ok5btUmzs48Q/6mG03qxTXB90qSV3N2cFXg/Tkh+OasaaPXGe71Xx+64dmjT+Q9O/x44aJkl6p2dfvdu7n1xcXTX9s/maN3uGhg/ur8iICOXMlUsfTvhYVavXtFXYSSolvQZeFHPAHDj6+CXmwNHHj6RjMBqNxucflnwCAgL0+++/a/PmzfHu79u3r+bPn29xi4CtKuv2JGM9f1uHYFNXNn9g6xBsLq27zf8eBwDYWCo7+1+BV2f7uUfr1vK3bB3Cc9k8WU8uJOsk6yTrJOsAAJL1Z3kVknU7+/EBAAAgRXs17uu0GzZfDQYAAABA/EjWAQAAADtFGwwAAACs5lVZ39xeUFkHAAAA7BTJOgAAAGCnaIMBAACA1dAGYxkq6wAAAICdorIOAAAAq6Gybhkq6wAAAICdIlkHAAAA7BRtMAAAALAeumAsQmUdAAAAsFMk6wAAAEAizZ07V/ny5VOqVKlUrlw5/f777888ftWqVfLz81OaNGmULVs2devWTbdu3Ur085GsAwAAwGoMBoPdPCy1bt06DR48WKNHj9bRo0dVo0YNNW7cWIGBgfEev3v3bnXu3Fndu3fXyZMntWHDBh08eFDvvvtuop+TZB0AAABIhBkzZqh79+569913VbRoUc2aNUu5cuXSvHnz4j1+//79yps3rwYOHKh8+fKpevXq6tWrlw4dOpTo5yRZBwAAgEOKiopSeHi42SMqKireYx8+fKjDhw+rYcOGZtsbNmyovXv3xntO1apVdeXKFW3evFlGo1E3btzQxo0b9frrryc6RpJ1AAAAWI2tW1/++wgICJCHh4fZIyAgIN64Q0JCFBMTo6xZs5ptz5o1q65fvx7vOVWrVtWqVavUrl07ubm5ycfHR56envrss88SPV8k6wAAAHBIo0aNUlhYmNlj1KhRzzzn6V53o9GYYP/7qVOnNHDgQI0dO1aHDx/Wli1bdOHCBfXu3TvRMbLOOgAAAKzmRW7sTC7u7u5yd3dP1LHe3t5ydnaOU0UPDg6OU21/IiAgQNWqVdPw4cMlSaVKlVLatGlVo0YNTZw4UdmyZXvu81JZBwAAAJ7Dzc1N5cqV09atW822b926VVWrVo33nIiICDk5mafbzs7Okh5X5BODZB0AAABIhKFDh2rRokVasmSJTp8+rSFDhigwMNDU1jJq1Ch17tzZdHyzZs301Vdfad68eTp//rz27NmjgQMHqmLFisqePXuinpM2GAAAAFiNPbXBWKpdu3a6deuW/P39FRQUpBIlSmjz5s3KkyePJCkoKMhszfWuXbvq7t27+vzzz/Xee+/J09NTdevW1ZQpUxL9nAZjYmvwr5gH0baOwPYy1vO3dQg2dWXzB7YOwebSuvP3OAA4ulR29r+C7L2+snUIJte+aGXrEJ6LNhgAAADATtnZ31oAAABI0V7dLhiboLIOAAAA2CmSdQAAAMBO0QYDAAAAq3mVV4OxBSrrAAAAgJ2isg4AAACrobJuGSrrAAAAgJ0iWQcAAADsFG0wKdiF70bZOgSbytlqlq1DsLnbPw6zdQgAAJihDcYyVNYBAAAAO0WyDgAAANgp2mAAAABgPXTBWITKOgAAAGCnSNYBAAAAO0UbDAAAAKyG1WAsQ2UdAAAAsFNU1gEAAGA1VNYtQ2UdAAAAsFMk6wAAAICdog0GAAAAVkMbjGWorAMAAAB2imQdAAAAsFO0wQAAAMBqaIOxDJV1AAAAwE5RWQcAAID1UFi3CJV1AAAAwE6RrAMAAAB2ijYYAAAAWA03mFqGyjoAAABgp0jWAQAAADtFGwwAAACshjYYy1BZBwAAAOwUyToAAABgp2iDAQAAgNXQBWMZKusAAACAnaKyDgAAAKvhBlPLUFkHAAAA7BTJOgAAAGCnaIMBAACA1dAFYxkq6wAAAICdIlkHAAAA7BRtMMlg3ZpVWrZ0sUJu3lQB34IaMfIDlS1X3tZhvbSVyxbqtx3bFHjpgtzdU6lEydLqNWCIcufJZ3bcxQv/6ovPZ+r4kUOKNcYqX35fjf94urL6ZFN4WJiWLJijQwf2KvjGdXl4eqp6rbrq3nuA0qVLb6ORxW9Yu4pqWa2QCuXKpMiH0Tpw6qpGL/5N567cNh2TNpWrJnavqWZVfJUpQypduhGuud8e0cIfjpuOcXN11uQetdSmdhGldnfVjqOXNPjzbboack+SlDtrBo3qUEW1S+dW1oxpFHTrvtZsP6Upa/brUXSs1cedFFLqayCxDh86qGVLFuv0qRO6efOmZs6eo7r16ts6LKtz9N8DRx+/xBw4+vgTwmowlqGynsS2/LRZUycHqEfPPlq38RuVLVtOfXv1UNC1a7YO7aUdP3JIb7R5S/MWr9b0zxYoJiZawwb0VGRkhOmYq1cCNaBHZ+XOk0+z5i/VklWb1PmdXnJzc5MkhYQE61ZIsPoMGqala77SqLGT9Me+PZo6caythpWgGqVyaf73R1Vr8Co1HbVBzs5O+uHjNkrj7mo6ZmrvOmpQPq+6Td2s0j2W6rOvDmtG33pqWqWA6ZhpveuoedWC6hzwg+oNXaN0qd20yb+VnJwev1kVzpVJTk4G9f/0F5XtuUwjvtihd1/3k3+3GlYfc1JIya+BxIqMjFDhwoU1crT9/V5bi6P/Hjj6+CXmwNHHj6RjMBqNRlsHkRweRNvmed9u30ZFixXTh2MnmLa1bNZYderW16Ah71k1ljv3HyXv9W+HqkWjmpo9f5n8yj6uFEwYPUzOLi76cMLkRF9nx7afNWncSG3ZdVAuLkn3YU++tp8m2bUkydsjtS6v76f6763VnhNXJEmHvuiqjbvOaPLq/abj9nzeUT//cUH+y/coQxo3XV7fT92nbdbGXWclSdkypdW5lb3UcsxX2nb4YrzPNeTNCurR1E/Fui56qZhv/zjspc5/Efb0GrAHfsULO2Rl3dF/Dxx9/BJzYE/jT2VnfRSF3//Z1iGYnJ3SyNYhPBeV9ST06OFDnT51UlWqVjfbXqVqNR0/dtRGUSWfe/cet3Gk9/CQJMXGxmrfnt+UK3deDRvQUy0a1VTvbm/p952/PvM69+/dVZq06ZI0UU8OGdK6S5Ju331g2rb35BU1reyr7F7pJEk1/XKpYI5MpiS8TMGscnN1NkvKg0Lv6+SlEFUulv0Zz+Wm0P88z6vC0V4DiJ+j/x44+vgl5sDRx/88BoP9PF4FdpGsnz59WkuXLtWZM2ckSWfOnFGfPn30zjvvaPv27TaOLvFu37mtmJgYeXl5mW338vJWSMhNG0WVPIxGo+bMmqqSfmWVv0BBSdLt0FBFRkRo9ZeLVbFKdX3y2QLVqF1PY94frGNHDsZ7nbA7d7R8yRdq/kYba4b/Qqb0rK09J67o1KUQ07b35m7X6cBb+nd1b4X/OETfTWytQZ9v096TVyVJPpnSKuphtO7cizK7VvDtCGXNmDbe58mXzUN9WpTVoh+Px7vfnjnSawAJc/TfA0cfv8QcOPr4kbRsXsrcsmWLWrRooXTp0ikiIkJff/21OnfuLD8/PxmNRjVq1Eg///yz6tatm+A1oqKiFBVlngwZnd3l7u6e3OHH6+kbJ4xGY4q7mWLWtEk6/8/f+mzBctM2o/HxzZDVatZR2w6dJUkFCxXRiT+P6duv1qt02Qpm17h/755GDu2rPPkKqGuPPtYL/gXM7FdPJfNlVr331pht79eyrCoWyabWY79SYHC4qpfMpU/719f10HvacTQwwesZDJJRcTvQsmVKq+8mvamvfjurZVv+SvJxWIsjvAbwfI7+e+Do45eYA0cff0Ke3LOFxLF5Zd3f31/Dhw/XrVu3tHTpUnXo0EE9evTQ1q1btW3bNo0YMUKTJz+7/zkgIEAeHh5mj2lTAqw0gv/J6JlRzs7OCgkJMdseGnpLXl7eVo8nucya9rH2/LZDs+YuUZasPqbtHp4Z5ezsorz5CpgdnydvfgVfDzLbFnH/voYP6qXUqdNo4tRP5eLiKns1o29dNa1SQI1GrDet4CJJqdxcNKFrDb2/YKc2HzivExdCNP+7o9q464wGv/n4D5Proffl7uYiz3Tmfzhm9kyj4NsRZtuyZUqrLVPb6cDpa+r36S/JP7Bk4CivATybo/8eOPr4JebA0cePpGXzZP3kyZPq2rWrJKlt27a6e/euWrdubdr/1ltv6c8//3zmNUaNGqWwsDCzx/D3RyVn2PFydXNT0WLFtX/vHrPt+/fulV/pMlaPJ6kZjUbNmjZJv+/cpllzlyhbjpxm+11dXVWkWHEFBl4w23458KKy+vyvP/v+vXt6b0BPubq66uPpn9nsE5DEmNmvnlpUK6jXRqzXpRthZvtcXZzk5uqs2FjzCnlMrFFO/185OXruhh4+ilG9snlN+30ypVXxPN7af+p/KwJk90qnn6e107F/bqjn9C16VW/7TumvASSOo/8eOPr4JebA0cePpGXzNpj/cnJyUqpUqeTp6Wnalj59eoWFhSV8kiR397gtL7ZaDaZTl24aPXKEipUoIT+/Mtq0YZ2CgoLUpl172wSUhGZOnahff96sSZ/MVuo0aXXr/ysG6dKlk3uqVJKk9h27acLoYfIrU15lylXUH/t2a9/uXZo1b6mkxxX1YQN76sGDSH3o/6nu37uv+/fuS5I8Mz6uRNiLWf3rq12dImoz/hvdi3yorBnTSJLC7j/Ug4fRuhvxUL8dv6yPe9RS5MNoBd4IV41SOfV2/WJ6f8FOSVJ4xEMt+/kvTe5ZS7fCI3X77gMF9KilExdDtP3oJUmPK+o/T2uny8HhGrVwlzJ7pDbFcOOp6vurICW/BhIr4v59BQb+rw3q6pUrOnP6tDw8PJQte8I3Fqckjv574Ojjl5gDRx//s9AJZBmbJ+t58+bVP//8I19fX0nSvn37lDt3btP+y5cvK1u2bLYKz2KvNW6isDu3tWDeXN28GSzfgoU0Z/4CZc+ew9ahvbRvN62TJA3q3c1s+8ixE9W4aUtJUs069TV05Fit+nKRZk8PUO7ceeU/eaZKlS4rSTp75qROnXj8SUmHVk3MrrP2m5+VzY7mqVez0pKkrZ+Yv7H2+OQnrdx6UpLUOeB7+b9TU8veb6KM6VMpMDhc45ftNvtSpBHzdygmJlYrRzdTajcX7TgWqJ7jvjZV5OuVyyvfHBnlmyOj/l3d2+y5Ujf6JBlHmDxS8msgsU6ePKF3u3U2/fuTqY/b8pq3eEMffZz4ZU1fZY7+e+Do45eYA0cfP5KOzddZnz9/vnLlyqXXX3893v2jR4/WjRs3tGiRZetN26qybk+Se511e5fU66y/imyxzjoAwL7Y2zrrxUfbz31ZJyc1tHUIz2XzH1/v3r2fuX/SpElWigQAAADJjRVxLGPzG0wBAAAAxI9kHQAAALBTNm+DAQAAgOOgC8YyVNYBAAAAO0VlHQAAAFbDDaaWobIOAAAA2CmSdQAAAMBO0QYDAAAAq6ENxjJU1gEAAAA7RbIOAAAA2CnaYAAAAGA1dMFYhso6AAAAYKeorAMAAMBquMHUMlTWAQAAADtFsg4AAADYKdpgAAAAYDV0wViGyjoAAABgp0jWAQAAADtFGwwAAACshtVgLENlHQAAALBTJOsAAACAnaINBgAAAFZDF4xlqKwDAAAAdorKOgAAAKyGG0wtQ2UdAAAAsFMk6wAAAICdog0GAAAAVkMXjGWorAMAAAB2imQdAAAAsFO0wQAAAMBqWA3GMlTWAQAAADtFsg4AAADYKdpgUjDPtK62DsGmbv84zNYh2FzWzitsHYJN/TGjta1DsLk83mlsHQIAmKELxjJU1gEAAAA7RWUdAAAAVsMNppahsg4AAADYKZJ1AAAAwE7RBgMAAACroQvGMlTWAQAAADtFsg4AAADYKdpgAAAAYDWsBmMZKusAAACAnaKyDgAAAKuhsG4ZKusAAACAnSJZBwAAAOwUbTAAAACwGm4wtQyVdQAAAMBOkawDAAAAdoo2GAAAAFgNbTCWobIOAAAA2CmSdQAAAMBO0QYDAAAAq6ELxjJU1gEAAAA7RWUdAAAAVsMNppahsg4AAADYKZJ1AAAAwE7RBgMAAACroQvGMlTWAQAAADtFsg4AAADYKdpgAAAAYDWsBmMZKusAAACAnSJZBwAAAOwUbTAAAACwGrpgLENlHQAAALBTVNYBAABgNU6U1i1CZT0ZrFuzSo0b1lWFMiXVvk0rHTl8yNYhWZWjj19KGXMwtHkJ7fiosa4sbq9/5rXRqqG15Zstg2m/i7NBE9qX0d7JTXVtyVs6M6e15vepKh/P1Alec+OIugpb3Umvl89ltt0zrZu+6FNNgYvaKXBRO33Rp5o80rgm29iSyoaVi9W8Vhkt/GyaJCk6+pGWzf9UA7q2UZtGVdS1VQPNnPShboUEm5336OFDfTFrst5uXkdtGlXRxFGDFBJ8wxZDSFYp4XXwMhx9/BJz4OjjR9IgWU9iW37arKmTA9SjZx+t2/iNypYtp769eijo2jVbh2YVjj5+KeXMQbWiWbRw61nVH/uTWgZsk4uTQV+PrKc07o8/kEvj5iK/fF6a9vVfqjn6R3WcuUu+Phm0dlideK/Xt3FRGRN4rkX9qqtknoxqPeVXtZ7yq0rmyagv+lZPppEljXOnT+rn779S3gIFTduiHjzQv3+fVrvOPTRz4RqN/Gi6rl4J1KQPBpudu/Czadq/e4eGjw3Q5M+WKjIyUh+NGqiYmBgrjyL5pJTXwYty9PFLzIGjjx9Jh2Q9ia34cqneaN1ard5so/wFCmjEqNHyyeaj9evW2Do0q3D08UspZw5aT9mu1b+d15mrYToReFt9v9ir3JnTqXS+TJKk8MhHahmwTV8fuKR/gsJ16J8QjfjyoMrk91JOrzRm1yqRO6P6NSmqfl/sjfM8hbJnUIPSOTRg4X4dPBeig+dCNHDRfjUum9Oskm9PIiMiNH3iB+o/fIzSpf9fjGnTpddHM+aret2Gypk7r4oUL6VeA9/XP2dP6+aNIEnS/Xt3tW3zN3qn71CVLl9ZBQoV0dAPJ+rS+X90/PABWw0pyaWU18GLcvTxS8yBo4//WQwG+3m8CuwyWTcaE6q/2bdHDx/q9KmTqlLVvCJYpWo1HT921EZRWY+jj19K2XPgkcZNknT73sMEj8mQxlWxsUaFRTwybUvt5qzF/atr+LI/FBz2IM45FQtm1p37D3X43xDTtkP/hOjO/YeqVChzEo4g6cyfFaDyVWqodPnKzz32/v27MhgMSpsuvSTpn79PKzo6WmUqVDEd4+WdRbnzFdCZE8eTLWZrSsmvg8Rw9PFLzIGjjx9Jyy6TdXd3d50+fdrWYVjs9p3biomJkZeXl9l2Ly9vhYTctFFU1uPo45dS9hxM6lhOe8/c0Okrd+Ld7+7qpPHty2rD3gu6G/m/ZD2gU3n9ce6mNh++Eu95WT1TKyQ8bhIfEv5AWT0S7n+3ld9+3aLzf59R5x4Dnnvsw6goLV8wWzXrN1aatOkkSXdu3ZKLq6tZRV6SPDN66XborWSJ2dpS8usgMRx9/BJz4OjjR9Ky6WowQ4cOjXd7TEyMJk+ebPolnzFjxjOvExUVpaioKLNtRmd3ubu7J02gFnr6a3SNRqNDfbWuo49fSnlz8EnXiiqeO6Nem/BzvPtdnA1aMqCmnAzSe0v/MG1vXDanahb3UY1RPz7z+vF9mmYw2N+nbDeDr2vhZ9Pk/8lcuT3n/SU6+pGm+Y9UbKxRfYaMeu61H/+OJFWk9iGlvQ4s5ejjl5gDRx9/QpgDy9g0WZ81a5b8/Pzk6elptt1oNOr06dNKmzZton6gAQEBmjBhgtm20WPG6cOx45Mw2ufL6JlRzs7OCgkJMdseGnpLXl7eVo3FFhx9/FLKnIOpXSqocbmcauL/i66FRsTZ7+Js0LKBNZUnc1o1m7TVrKpes7iP8mVJr8BF7czOWTG4pvaeCVbTiVt1406kMsdTQfdKn0rB8VTcbenfs6cVdjtUQ3q+bdoWGxOjk8eP6Mev12nT1gNydnZWdPQjTR33vm4EXdXEmQtMVXVJ8vTyUvSjR7p3N9ysuh52J1RFS/hZdTzJJSW+Dizh6OOXmANHHz+Slk3bYCZNmqSwsDCNGTNGO3bsMD2cnZ21bNky7dixQ9u3b3/udUaNGqWwsDCzx/D3n1/JSmqubm4qWqy49u/dY7Z9/9698itdxurxWJujj19KeXMwrWsFNauQW80mbdWlm/fi7H+SqBfwyaAWH2+L088+87sTqjryB1Uf9aPpIUmjVhxWvy/2SZL+OHdTnmndVLbA/z4uLlfAW55p3XTgb/v6uLhUuYr6bOkGfbporenhW7iYatVvok8XrTVL1K9dDdRHM+Yrg4en2TV8CxWVi4uLjh3cb9oWeuumAi/8qyIpJFlPaa8DSzn6+CXmwNHHj6Rl08r6qFGjVL9+fXXs2FHNmjVTQECAXF0tX1vZ3T1uy8uD6KSK0jKdunTT6JEjVKxECfn5ldGmDesUFBSkNu3a2yYgK3P08UspZw6md6uoN6vmU4fpO3Qv8pGyeKSSJIVHPNKDRzFydjJo+aBa8suXSe2m7ZCzk8F0zO17D/UoJlbBYQ/ivan0yq37puT/72vh2nrsqma/W1mDFz9eDeXTdyvrpyNX9E9QuJVGmzhp0qRVnvy+ZttSpU6t9B4eypPfVzHR0Zo8drjO/31GYyZ/qtiYWN2+9biyli6Dh1xdXZU2XXrVb9JSS+bOUHoPD6VL76Gl82YqT35f+ZWrZIthJYuU8jp4UY4+fok5cPTxP4sTXTAWsfk3mFaoUEGHDx9Wv379VL58ea1cufKV7mV6rXEThd25rQXz5urmzWD5FiykOfMXKHv2HLYOzSocffxSypmDdxsUliRtHtvIbHuf+Xu0+rfzypEpjenLjfZMbmp2zOsf/aLdpxP/JT895uzWlC4V9PXIepKkn45c0fBlfzznLPsTcjNYf+zZJUka1N38f8iTZi1UyTLlJUnv9h8mZ2dnTR3/vqKiouRXtqIGBXwqZ2dnq8ecXFLK6+BFOfr4JebA0cePpGMw2tEdXGvXrtXgwYN18+ZN/fXXXypWrNgLX8tWlXXAnmTtvMLWIdjUHzNa2zoEm8vjneb5BwFI0VLZvDRrrsl8+ynGbO5d0eJz5s6dq2nTpikoKEjFixfXrFmzVKNGjQSPj4qKkr+/v1auXKnr168rZ86cGj16tN55551EPZ9d/fjat2+v6tWr6/Dhw8qTJ4+twwEAAABM1q1bp8GDB2vu3LmqVq2avvjiCzVu3FinTp1S7ty54z2nbdu2unHjhhYvXixfX18FBwcrOjrxVWW7StYlKWfOnMqZM6etwwAAAADMzJgxQ927d9e7774r6fHKhj///LPmzZungICAOMdv2bJFu3bt0vnz55Up0+NvAM+bN69Fz2mXX4oEAACAlMlgsJ9HVFSUwsPDzR5Pf3fPEw8fPtThw4fVsGFDs+0NGzbU3r174z3nu+++U/ny5TV16lTlyJFDhQoV0rBhwxQZGZno+SJZBwAAgEMKCAiQh4eH2SO+CrkkhYSEKCYmRlmzZjXbnjVrVl2/fj3ec86fP6/du3frxIkT+vrrrzVr1ixt3LhR/fr1S3SMdtcGAwAAAFjDqFGjNHToULNtTy8H/jRLvpk2NjZWBoNBq1atkoeHh6THrTRvvvmm5syZo9Sp434p4NNI1gEAAGA1BtnPEt3xfVdPQry9veXs7Bynih4cHByn2v5EtmzZlCNHDlOiLklFixaV0WjUlStXVLBgwec+L20wAAAAwHO4ubmpXLly2rp1q9n2rVu3qmrVqvGeU61aNV27dk337v3vW8D//vtvOTk5JXpBFZJ1AAAAWI2TwX4elho6dKgWLVqkJUuW6PTp0xoyZIgCAwPVu3dvSY/bajp37mw6vkOHDvLy8lK3bt106tQp/fbbbxo+fLjeeeedRLXASLTBAAAAAInSrl073bp1S/7+/goKClKJEiW0efNm0/cDBQUFKTAw0HR8unTptHXrVg0YMEDly5eXl5eX2rZtq4kTJyb6Oe3qG0yTEt9gCvANpnyDKd9gCsD+vsG0+YKDtg7B5LueFWwdwnPZ2Y8PAAAAKVlCK6cgfvSsAwAAAHaKZB0AAACwU7TBAAAAwGrogrEMlXUAAADATpGsAwAAAHaKNhgAAABYjRN9MBahsg4AAADYKSrrAAAAsBoK65ahsg4AAADYKZJ1AAAAwE7RBgMAAACrMdAHYxEq6wAAAICdIlkHAAAA7BRtMAAAALAaumAsQ2UdAAAAsFMk6wAAAICdog0GAAAAVuNEH4xFqKwDAAAAdorKOgAAAKyGurplqKwDAAAAdopkHQAAALBTiWqDCQwMtOiiuXPnfqFgAAAAkLIZuMHUIolK1vPmzWvRxMbExLxwQAAAAAAeS1SyvmTJEv4KAl5BQcs62joEm/Kq9p6tQ7C52/tm2DoEAMBLSFSy3rVr12QOAwAAAI7AifqvRV7qBtPIyEhdvXpV0dHRSRUPAAAAgP/3Qsn6jh07VKVKFaVPn1558uTRn3/+KUnq16+fvvrqqyQNEAAAAHBUFifr27dvV8OGDfXgwQMNGzZMsbGxpn3e3t5atmxZUsYHAACAFMRgMNjN41VgcbI+duxYNWnSREePHtXEiRPN9vn5+enYsWNJFRsAAADg0BJ1g+l/HT16VBs2bJAUd53MzJkzKzg4OGkiAwAAQIrzihS07YbFlXUXFxc9evQo3n3BwcFKnz79SwcFAAAA4AWS9QoVKmjFihXx7tu4caOqVKny0kEBAAAAeIE2mJEjR6pRo0Z644031LlzZxkMBh04cEBLlizRxo0btWPHjuSIEwAAACnAq3Jjp72wOFmvX7++vvzySw0ePFjffvutpMdLNnp6emrZsmWqXr16kgcJAAAAOCKLk3VJ6tixo1q3bq09e/YoODhY3t7eqlatmtKmTZvU8QEAAAAO64WSdUlKnTq16tevn5SxAAAAIIVzogvGIi+UrIeHh2vOnDnasWOHbt26JS8vL9WpU0d9+vSRp6dnEocIAAAAOCaLk/ULFy6oTp06CgwMVJ48eeTj46Nz585p27Ztmj9/vnbs2KH8+fMnR6wAAAB4xXGDqWUsXrpx0KBBevDggfbs2aMLFy5o3759unDhgnbv3q2oqCgNHjw4GcIEAAAAHI/Fyfr27ds1adKkOOupV61aVRMnTtT27duTLDgAAADAkVncBuPu7q5cuXLFuy937txyd3d/6aAAAACQMtEEYxmLK+stWrTQhg0b4t23YcMGNW3a9KWDAgAAAJDIyvqRI0dM/92hQwd1795dbdq0UYcOHeTj46Pr169r1apVOnTokBYvXpxswQIAAACOJFHJevny5c3u3DUajbp8+bK++uors22S1LBhQ8XExCRxmAAAAEgJnFgNxiKJStaXLl2a3HEAAAAAeEqikvUuXbokdxwAAAAAnvJC32AKAAAAvAi6YCzzQsl6aGioVq9erdOnTysyMtJsn8Fg4CZTAAAAIAlYnKwHBgaqQoUKioiIUEREhLy9vRUaGqqYmBhlzJhRHh4eyREnAAAAUgADpXWLWLzO+siRI1W8eHHduHFDRqNRP/30k+7fv6/PPvtMqVKl0o8//pgccQIAAAAOx+Jkfd++ferTp49SpUol6fGSjW5uburXr5+6d++u4cOHJ3mQAAAAgCOyOFm/ceOGsmXLJicnJzk7Oys8PNy0r1atWtq9e3eSBggAAICUw2Cwn8erwOJkPWvWrAoNDZUk5c2bV4cOHTLtu3jxolxcWGAGAAAASAoWZ9aVK1fW0aNH1bx5c7Vq1Ur+/v6KioqSm5ubpk2bprp16yZHnAAAAIDDsThZHzZsmC5evChJGjt2rE6fPq1x48bJaDSqZs2amjVrVhKHCAAAgJTC6VXpP7ETFifr5cqVU7ly5SRJadOm1Xfffafw8HAZDAalT58+yQMEAAAAHJXFPevxyZAhg9KnT6/ffvuNNhhJ69asUuOGdVWhTEm1b9NKRw4fev5JKYgjj3/92tV6841mqlqxrKpWLKtOHdpp9++7bB1Wkjl86KAG9e+tBnVrqEzJItrx6zaz/UajUfPnfqYGdWuocnk/vdutk/7955zZMQ8fPtTkjz9SnRqVVaViGQ0a0Ec3rl+35jAskj2zh5b4v60rWz/Srd8na/+q91SmSM54j/1sVBtFHpyh/m/VNNv+8/y+ijw4w+yxfFIns2POfPthnGM+6v96so0rOR0+dFAD+vZW/drV5Ve8sLY/9XviKBz5vfAJR58DRx8/kkaSJOtP3Lx5U7t2pZzE5EVs+Wmzpk4OUI+efbRu4zcqW7ac+vbqoaBr12wdmlU4+vizZPXRoCHDtHr9Jq1ev0kVK1XWoP799M9TCeurKjIyUoUKFdHID8bEu3/ZkkVauXyZRn4wRivXbJCXd2b17vmO7t+/Zzpm2pSPtePXbQqYOkNLv1ylyIgIDezfWzExMdYaRqJ5pk+t7YsG6FF0jFoOWqgybado5KzvdOduZJxjm9UqoQolcutacFi811r89T7lfW2c6dH/4w1xjpkw/yezYyYv3prkY7KGyMgIFS5cWCNHj7V1KDbj6O+FEnPg6ON/FluvAJPiV4PBs634cqneaN1ard5so/wFCmjEqNHyyeaj9evW2Do0q3D08deuU1c1atZS3rz5lDdvPg0YNERp0qTRn8eP2Tq0JFG9Rk31GzhY9eo3jLPPaDRq9crl6t6jt+rVbyjfgoX00aTJevDggX768QdJ0t27d/XNV5s0dPj7qlylqooULaaJAVP1z7m/dWD/XmsP57ne61JXV27cUS//tTp0KlCBQbe18+A5Xbh6y+y47Jk9NHN4K3Ubs1KPouP/oyPywSPduHXX9Ai//yDOMfciosyOuR/5MFnGldyq16il/oOGqH6DuL8njsLR3wsl5sDRx4+kQ7KehB49fKjTp06qStXqZturVK2m48eO2igq63H08T8tJiZGP23+UZGREfLzK2PrcJLd1StXFBJyU1WqVjNtc3NzU7lyFXT8+OOf/+lTJxUd/UhVqvzvmCxZsqqAb0G7/B15vUZxHTl9WasCOuvSzxO0b+VQdWtZ2ewYg8GgxRM6aObKHTp9/kaC12r3Wlld3uqvw+tGKGBQM6VL4x7nmKGd6+rK1o+0f9V7GtGtvlxdnJN8TEh+vBcyB44+/ucxGAx283gV2N2i6Ldv39aXX36pc+fOKVu2bOrSpYty5cpl67AS5fad24qJiZGXl5fZdi8vb4WE3LRRVNbj6ON/4tzfZ9WpQ3s9fBilNGnSaObsOSrg62vrsJJdyK3HP+NMcX7+XgoKevyx762Qm3J1dVUGD484x9wKCbFOoBbIl8NLPVpX1ezVuzR16a8qXzy3pr/3hqIeRmv15se9p+91qavomFjNWft7gtdZu+WILl67pRu37qp4fh/593tdJQtmV9P+X5iOmbP2Nx09e1V3wiNUvnhu+fd7XXmzZ1LfSeuTfZxIWrwXMgeOPn4kLZsn69mzZ9dff/0lLy8vXbhwQVWrVpUklSxZUt99950++eQT7d+/X0WKFEnwGlFRUYqKijLbZnR2l7t73MqVNTz9l5rRaHxl/npLCo4+/rx582n9pm909264tm39RWM+eF+Ll610iIRdiufnH8+2pxkfH5R8Qb0gJyeDjpy+rHFzN0uSjv99VcXy+6hn66pavfmQyhTJqX7ta6hqxxnPvM7Sb/ab/vvUv9f1z+UQ7V0xVKUL59Cxs1clSZ+t+c10zIl/gnQnPFJrpnbVh5//oNCwiGQYHZKbo78XSsyBo48fSSNRyXqpUqUSdbHw8HCLA7h+/brpxrIPPvhARYoU0Y8//qg0adIoKipKb775psaMGaMNG+LejPVEQECAJkyYYLZt9Jhx+nDseIvjeRkZPTPK2dlZIU9VCENDb8nLy9uqsdiCo4//CVc3N+XOk0eSVLxESZ088ZdWrVyuseP9bRxZ8vL2yixJuhUSosyZs5i2h966Zaq2e3ln1qNHjxQeFmZWXQ8NvSW/0qWtGm9iXA8Jj9PacubiDbWs+/g9sVqZ/MqSMZ3+/v5/N9y6uDhr8qDm6t++poq0mBjvdY+euaKHj6LlmzuzKVl/2h8nLkmSCuT0VmhYYFIMB1bCeyFz4Ojjfx56sC2TqPnKlCmTvLy8nvvIly+fatas+fwLJuDAgQMaM2aM0qRJI0lyd3fXhx9+qP379z/zvFGjRiksLMzsMfz9US8cx4tydXNT0WLFtX/vHrPt+/fulV/plN+z7OjjT4jRaNSjh6/mjYKWyJEzp7y9M2v/vv/dKPro0UMdPnzQ1LNftFhxubi4mh1z82aw/v3nnF3+juw7flGF8mQx21Ywd2YFXg+VJK3efEgVOnyiSh2nmx7XgsM0c+UONRv4RXyXlCQVK+AjN1cXBYUkXODwK5xD0uM/GPBq4b2QOXD08SNpJaqyvnPnzmQN4slHQlFRUcqaNavZvqxZs+rmzWf3d7m7x215eRCdtDEmVqcu3TR65AgVK1FCfn5ltGnDOgUFBalNu/a2CcjKHH38s2fNUPUaNZXVx0cR9+9ry0+bdejgH5r7xSJbh5YkIiLu63Lg/6q8V69e0dkzp5XBw0PZsmVXh46dtXjRF8qdJ49y586jxQu/UKpUqdT49aaSpPTp06tlq9aa8ckUeXh6ysPDQzOnT5VvwUKqVLmqrYaVoM/W7NKOxQM1vGs9bdp2XBWK59Y7b1Q2LbsYGhYRp0XlUXSMbty6q3OXHr9v5cvhpfaNy+nnPacUcue+iubz0eTBzXX0zBXtO35BklSpZB5VLJFHuw7/o7B7D1S+WC5NHdJS3+86ocs37lh1zEkh4v59Bf739+TKFZ05fVoeHh7Klj27DSOzHkd/L5SYA0cfP5KOzXvWJalevXpycXFReHi4/v77bxUvXty0LzAwUN7er85HRq81bqKwO7e1YN5c3bwZLN+ChTRn/gJlz57D1qFZhaOP/9atEI0eOUI3bwYrXfr0KlSosOZ+schshZRX2amTJ9TjnS6mf0+fNlmS1Kx5S/lPmqyu77yrqKgHCpjor/DwMJUoWUrzvlistGnTmc4ZNmKUnJ2d9f6wwYqKilLFSpX16efz5OxsfyufHD51We2GL5V/v9f1wbsNdfFaqIbP+FZrtxxJ9DUeRceoToWC6teuhtKlcdeVG3e0Zc8pTVr4i2JjjZKkqIfRerNBGX3Qo5HcXV0UeD1US77ZrxnLtyfX0JLVyZMn9G63zqZ/fzI1QJLUvMUb+ujjybYKy6oc/b1QYg4cffzPQt++ZQxGo9FoywCe7jWvXLmyGjVqZPr38OHDdeXKFa1ZY9m6pLaqrAP25Eky6Ki8qr1n6xBs7va+Z9/8CiDlS2UXpdn/GfjNGVuHYDK7ZcILmNgLm//4xo0b98z906ZNs1IkAAAASG5OFNYtwg25AAAAgJ0iWQcAAADslM3bYAAAAOA4aIOxzAsn62fOnNGuXbsUEhKi7t27y8fHR9euXVPGjBmVOnXqpIwRAAAAcEgWJ+sxMTHq2bOnli1bZvra3MaNG8vHx0e9evVSmTJl5O+fsr+pEQAAALAGi3vWJ02apNWrV2vatGk6ceKE/rvyY+PGjbVly5YkDRAAAAAph8FgsJvHq8DiyvqyZcs0ZswYDR06VDExMWb78uXLpwsXLiRZcAAAAIAjs7iyfvXqVVWpUiXefalSpdLdu3dfOigAAAAAL5CsZ8mSRefPn49339mzZ5UzZ86XDgoAAAApk5PBfh6vAouT9SZNmmjSpEm6evWqaZvBYFBYWJhmz56tZs2aJWmAAAAAgKOyOFn39/dXdHS0ihUrptatW8tgMOiDDz5QiRIl9ODBA40ZMyY54gQAAEAKYDDYz+NVYHGynjVrVh08eFBvvfWWDh8+LGdnZx0/flyNGzfW3r17lSlTpuSIEwAAAHA4L/SlSFmzZtX8+fOTOhYAAAAA//HC32AKAAAAWMrpVek/sRMWJ+vvvPPOM/cbDAYtXrz4hQMCAAAA8JjFyfr27dvjfOPTrVu3dO/ePXl6esrT0zOpYgMAAAAcmsXJ+sWLF+Pdvn37dvXt21cbNmx42ZgAAACQQlm8uomDS7L5qlu3rvr3769BgwYl1SUBAAAAh5akf9wUK1ZMf/zxR1JeEgAAAHBYSboazK5du+Tt7Z2UlwQAAEAKwmIwlrE4Wff394+zLSoqSn/++ad++uknDR8+PEkCAwAAABydxcn6+PHj42xzd3dX3rx55e/vT7IOAACABLHOumUsTtZjY2OTIw4AAAAAT7HoBtPIyEh16NBBu3fvTq54AAAAAPw/i5L11KlT69tvv6W6DgAAgBdiMNjP41Vg8dKNpUuX1okTJ5IjFgAAAAD/YXGyPnnyZE2dOlW7du1KjngAAAAA/L9E3WD622+/qWzZskqXLp369u2re/fuqW7dusqYMaOyZcsmw38+RzAYDDp+/HiyBQwAAIBXl9Mr0n5iLxKVrNepU0f79u1TxYoV5eXlxRcfAQAAAFaQqGTdaDSa/nvnzp3JFQsAAACA/7B4nXUAAADgRfGlSJZJ9A2mBiYWAAAAsKpEV9br1KkjJ6fn5/YGg0FhYWEvFRQAAABSJuq/lkl0sl67dm1lzpw5OWMBkNQc/A3x9r4Ztg7B5jJWHmLrEGzq9v6Ztg4BAF5KopP1sWPHqmLFiskZCwAAAID/4AZTAAAAWA3rrFvG4m8wBQAAAGAdJOsAAACAnUpUG0xsbGxyxwEAAAAHYHD01Q8sRGUdAAAAsFPcYAoAAACr4QZTy1BZBwAAAOwUyToAAABgp2iDAQAAgNXQBmMZKusAAACAnSJZBwAAAOwUbTAAAACwGoOBPhhLUFkHAAAA7BTJOgAAAGCnaIMBAACA1bAajGWorAMAAAB2iso6AAAArIb7Sy1DZR0AAACwUyTrAAAAgJ2iDQYAAABW40QfjEWorAMAAAB2imQdAAAAsFO0wQAAAMBqWGfdMlTWAQAAADtFsg4AAAAk0ty5c5UvXz6lSpVK5cqV0++//56o8/bs2SMXFxeVLl3aoucjWQcAAIDVGAz287DUunXrNHjwYI0ePVpHjx5VjRo11LhxYwUGBj7zvLCwMHXu3Fn16tWz+DlJ1gEAAIBEmDFjhrp37653331XRYsW1axZs5QrVy7Nmzfvmef16tVLHTp0UJUqVSx+TpJ1AAAAWI2TDHbzsMTDhw91+PBhNWzY0Gx7w4YNtXfv3gTPW7p0qf7991+NGzfuheaL1WAAAADgkKKiohQVFWW2zd3dXe7u7nGODQkJUUxMjLJmzWq2PWvWrLp+/Xq81z937pxGjhyp33//XS4uL5Z2U1kHAACAQwoICJCHh4fZIyAg4JnnGJ5qdjcajXG2SVJMTIw6dOigCRMmqFChQi8cI5V1AAAAWM2L3NiZXEaNGqWhQ4eabYuvqi5J3t7ecnZ2jlNFDw4OjlNtl6S7d+/q0KFDOnr0qPr37y9Jio2NldFolIuLi3755RfVrVv3uTFSWU8G69asUuOGdVWhTEm1b9NKRw4fsnVIVuXI41+/drXefKOZqlYsq6oVy6pTh3ba/fsuW4eVbKKjozVn9iy93qieKpfzU9PX6uuLeXMUGxtrOiYi4r4mT/JXo3q1VLmcn1o1a6L1a9fYMOqkdfjQQQ3o21v1a1eXX/HC2v7rtjjHnP/3Xw3s11vVKpVTlQpl1PGttgq6ds0G0VouXRp3TRvaUme/H6PQ3VO0Y/FAlSuWy7S/RZ2S+u6zXrq87SNFHpqpUoWyx7mGm6uzZgxvpcvbPlLI75O1YUZ35cjiEe/zubk6a/+qYQle61Uwb85n8ite2OxRt2Y1W4dldTdu3NCo94epZtVKqlTOT21btdCpkydsHZbVJOa9Abbn7u6uDBkymD0SStbd3NxUrlw5bd261Wz71q1bVbVq1TjHZ8iQQX/99ZeOHTtmevTu3VuFCxfWsWPHVKlSpUTFSGU9iW35abOmTg7Q6DHjVLpMWW1cv1Z9e/XQ19/9qGzZX83/8VjC0cefJauPBg0Zply5c0uSvv/2Gw3q30/rNn0tX9+CNo4u6S1bvEgb16+V/6TJKuDrq5MnT2j8hx8ofbr06tCpsyTpkymTdeiPA5oUMFXZc+TQvr17FDDRX5mzZFGdupYvYWVvIiMjVLhwYbV4o5XeGzwgzv7LgYHq2qmD3mjVWn36D1T6dOl1/vy/ckvgfwb2Zt6H7VSsQDa9M3aVgm6G660m5fTj3D4q22aKrt0MU5rU7tp3/IK+2nZM88a0j/ca0957Q6/XKK7OH6xQaNh9TR7cQptm9lDVTtMVG2s0O/bjgc0VFBImv8I5rDG8ZFPAt6AWLFpq+reTs7MNo7G+8LAwde34lspXrKQ58xcqk1cmXbl8WenTZ7B1aFbzvPcGvJqGDh2qTp06qXz58qpSpYoWLFigwMBA9e7dW9LjSv3Vq1e1fPlyOTk5qUSJEmbnZ8mSRalSpYqz/VlI1pPYii+X6o3WrdXqzTaSpBGjRmvv3t1av26NBg15z8bRJT9HH3/tOuYfZw0YNETr167Rn8ePpchk/c/jR1WrTj3VqFVbkpQ9R05t2fyjWfXsz+PH1LRFS5Wv+LiC0LpNO23asE6nTp5IEcl69Rq1VL1GrQT3fzZ7pqrXrKkhw0aYtuXMlSvB4+1JKndXtaxbSm3eW6I9R89LkiYt+FnNapVUjzerasK8n7Rm8+NPznJnyxjvNTKkTaWuLSqp+9hV2vHH35Kkd8as1Lkfx6luxULatv+s6diGVYuoXuXCemvEUr1WrVgyjy55uTg7yztzZluHYTNLFi9UVh8ffTTpf72/OXLktGFE1ve89wZH5mRHbTCWateunW7duiV/f38FBQWpRIkS2rx5s/LkySNJCgoKeu6a65aiDSYJPXr4UKdPnVSVqtXNtlepWk3Hjx21UVTW4+jjf1pMTIx+2vyjIiMj5OdXxtbhJIvSZcvpjwP7dOniBUnS2TNndOzIEVWrWfN/x5Qpq107tiv4xg0ZjUYd/GO/Ll28qKrVqid02RQjNjZWv+/aqTx58qp3j+6qXaOK3m7f5pX5ONzF2UkuLs568PCR2fYHUY9UtXT+RF2jTNGccnN1MUvKg0LCdfLfIFUulc+0LUumdJo7up26j12liAcPk2YANnQp8JLq166uxg3rasSwIbpy+bKtQ7KqXTu2q3jxEho2ZKBq16iitq1batOG9bYOC0gSffv21cWLFxUVFaXDhw+r5n/+n7ds2TLt3LkzwXPHjx+vY8eOWfR8Nk/Wjx49qgsXLpj+vXLlSlWrVk25cuVS9erVtXbtWhtGZ5nbd24rJiZGXl5eZtu9vLwVEnLTRlFZj6OP/4lzf59V5fJlVKFMSU3yH6eZs+eogK+vrcNKFt2699BrjV/XG82aqELpEnqrzRvq0KmzGjdpajrm/Q9GK3+BAmpUr5Yqlimpfr16aNSH41SmbDkbRm4dobduKSIiQksWL1S16jU0f8ES1a3XQEMH9dehg3/YOrznuhcRpf3HL2jUuw2VzTuDnJwMat+4nCqUyC0f78S1M/h4ZVDUw2jduRtptj049J6yeqc3/XvBuA5a+NVeHTn96ie1JUuV0qSPp2jegsUaN2GiboWEqPPb7XXnzm1bh2Y1V65c1vp1a5Q7T17NW7BYbdq115SAifr+229sHRrwyrF5G0z37t01ffp05cuXT4sWLdLAgQPVo0cPderUSWfPnlWPHj0UERGhd955J8FrxLdGptE5/jUyrSGxS/qkVI4+/rx582n9pm909264tm39RWM+eF+Ll61MkQn7zz9t1uYfvtfHUz5RAV9fnT1zRp9M+ViZs2RR8xZvSJLWrFyhv/48rlmfz1W2bDl05PBBBUycIO/MmVW5StwbclKSWOPjG23r1KmnTl26SpKKFC2q48eOaMO6tSpfoaINo0ucd8au0hdj2+v8lgmKjo7RsbNXtG7LEZUu8nItDQaDZPz/dvW+7WooQ7pUmrb01fjE4Xn+2/pQUFIpv9Jq+loDfffNN+rctZvtArOi2FijipcooYGDH6+yUbRoMf37zz9av26NmrVoadvgYHNODpQTJAWbJ+tnz55VgQIFJElz587VrFmz1LNnT9P+ChUqaNKkSc9M1gMCAjRhwgSzbaPHjNOHY8cnS8wJyeiZUc7OzgoJCTHbHhp6S15e3laNxRYcffxPuLq5Kff/964VL1FSJ0/8pVUrl2vseH8bR5b0Zk2fpm7v9tBrTV6XJBUsVFhBQde0dNECNW/xhh48eKDPPp2lGZ9+ZuprL1S4sM6eOaMVy5ak+GQ9o2dGubi4KP//v8c9kS9/AR07cthGUVnmwtVbathrjtKkclOGtKl0/Va4VnzcWRevhSbq/Ou3wuXu5iLP9KnNquuZM6bT/uMXJUm1KxRUxRJ5FLZ3mtm5e5YP1dotR9Rj/OokG48tpEmTRgULFVJg4EVbh2I1mTNnjvN7nz9/fm3b+rONIgJeXTZvg0mdOrVu3nzcInH16tU4y9hUqlTJrE0mPqNGjVJYWJjZY/j7o5It5oS4urmpaLHi2r93j9n2/Xv3yq90yuxZ/i9HH39CjEajHj189Xtw4/PgQaQMBvO3EScnJ9PSjdHR0YqOfiSDk/kxzs5OZss7plSubm4qXqKkLl40fw+7dOmismV/tVY7iXjwUNdvhcszfWrVr1JEP+xK3BJ8R09f0cNH0apXqbBpm49XBhUvkE37/3w8L+9N+0oVO0xTpbc/UaW3P1HLQQslSZ0+WK7xc39M+sFY2cOHD3X+/L/y9nacG05Llymri0/9v/vSxYvK/or93iN5GAz283gV2Lyy3rhxY82bN0+LFi1SrVq1tHHjRvn5+Zn2r1+/Xr7PaR+I72thH0QnS7jP1alLN40eOULFSpSQn18ZbdqwTkFBQWrTLv4lzVIaRx//7FkzVL1GTWX18VHE/fva8tNmHTr4h+Z+scjWoSWLmrXraPHC+cqWLZsK+PrqzOnTWrl8mVq+0VqSlC5dOpUrX0Gzpk9TKnd3ZcueQ4cP/aEfvvtWQ4ePtHH0SSPi/n2zO/+vXrmiM6dPy8PDQ9myZ1eXbt014r0hKleugipUrKQ9u3/Xbzt3aNHS5TaMOvHqVy4sg8Ggvy8Fq0Aub308sLnOXQrW8u8OSJIyZkijXD6eypb58brphfJkkSTduHVXN27dVfj9B1r27QFNHtxct8Lu63Z4hAIGNdeJf4K0/f9Xh7l8445043/PeS/icVvj+SshuhocZr3BJpHp06aoVu068smWTaGhoVo4f57u37un5i3fsHVoVtOxcxd16fiWFi2Yr4aNGuvEX39q48b1KfITxoQ8770BSCyD0Wg0Pv+w5HPt2jVVq1ZNuXPnVvny5TVv3jyVK1dORYsW1dmzZ7V//359/fXXatKkiUXXtVWyLj3+UqBlSxbr5s1g+RYspOHvj1K58hVsF5CVOfL4x435QH/s36+bN4OVLn16FSpUWN2691CVqrb5QpTYZH55379/T3M/m63tv27T7dBbypw5i15r8rp69ukrV1c3SVJIyE19NmuG9u3do/CwMGXLnl2t3myrjp27Jvu9DNboizz4xwG9261znO3NW7yhjz6eLEn6+quNWrJwgW7cuK68efOpT/8BqlO3frLHJkkZKw95qfNb1y8t//6vK0cWT4WGR+jb7cc1bs5mhd9/IEnq2LSCFo7vEOe8iQu2aNKCxy0P7m4uChjUXG0blVXqVK7a8cc5DZ6yUVdu3In3OXNny6iz349VpQ7T9OffL/flUbf3z3yp81/EiGFDdOTQQd2+fUcZM2VUqVKl1W/AoBR538qz7Nq5Q7NnzVDgpYvKkTOnOnXuptZt2to6LKtJzHuDtaSyeWnW3MIDl2wdgkmPSnlsHcJz2TxZl6Q7d+5o8uTJ+v7773X+/HnFxsYqW7ZsqlatmoYMGaLy5ctbfE1bJuuAvUjuZN3ecRPTyyfrrzpbJOuAvbG3ZH3xH0m7DvnL6F4xt61DeC67+PF5enpq8uTJmjzZun9pAgAAAPbM5jeYAgAAAIifXVTWAQAA4BjoULQMlXUAAADATlFZBwAAgNVQKbYM8wUAAADYKZJ1AAAAwE7RBgMAAACrSe4vxEtpqKwDAAAAdopkHQAAALBTtMEAAADAamiCsQyVdQAAAMBOkawDAAAAdoo2GAAAAFiNE6vBWITKOgAAAGCnqKwDAADAaqirW4bKOgAAAGCnSNYBAAAAO0UbDAAAAKyG+0stQ2UdAAAAsFMk6wAAAICdog0GAAAAVmOgD8YiVNYBAAAAO0WyDgAAANgp2mAAAABgNVSKLcN8AQAAAHaKyjoAAACshhtMLUNlHQAAALBTJOsAAACAnaINBgAAAFZDE4xlqKwDAAAAdopkHQAAALBTtMEAAADAalgNxjJU1gEAAAA7RWUdSMHuR8XYOgSbSuvubOsQbO7c1im2DsGmcryzxtYh2NzVJW/ZOgQAL4FkHQAAAFZDW4dlmC8AAADATlFZBwAAgNVwg6llqKwDAAAAdopkHQAAALBTtMEAAADAamiCsQyVdQAAAMBOkawDAAAAdoo2GAAAAFgNi8FYhso6AAAAYKeorAMAAMBqnLjF1CJU1gEAAAA7RbIOAAAA2CnaYAAAAGA13GBqGSrrAAAAgJ0iWQcAAADsFG0wAAAAsBoDq8FYhMo6AAAAYKdI1gEAAAA7RRsMAAAArIbVYCxDZR0AAACwU1TWAQAAYDVO3GBqESrrAAAAgJ0iWQcAAADsFG0wAAAAsBpuMLUMlXUAAADATpGsAwAAAHaKNhgAAABYDW0wlqGyDgAAANgpknUAAADATtEGAwAAAKsx8KVIFiFZTwbr1qzSsqWLFXLzpgr4FtSIkR+obLnytg7Lahx9/JJjzMGKJQv1xZxZavNWRw0aNsq0/eKFfzVv9gwdO3xIscZY5cvvK//J0+WTLbskqX/Prjp2+KDZteo1bKwJAZ9YNf6kFHzjhj6d8Yn27P5NUVFRyp0nr8b5T1Sx4iUkSb9u/UWbNqzT6VMndefOHa3d+LUKFylq46hfTIeWjXTj+rU425u3bqdBwz/Ulwvnase2n3Tzxg25uLqoUOFieqf3QBUtUUqSFB4Wpi8XztGhP/bp5o3r8vD0VLWaddW1V3+lS5fe2sNJlGwZU2tc29Kq55dNqVyd9e/1uxq0+ICOX7xtOmbEGyXUpXYBeaR10+F/b2nE8kM6ezXctN/NxUn+b5VRq8p5lMrNWb+dvK4RXx7StduRcZ7PzcVJv4xrqJJ5MqrWhz/pROAdawwzWTjCe+GzOPr4kTRI1pPYlp82a+rkAI0eM06ly5TVxvVr1bdXD3393Y/Klj27rcNLdo4+fskx5uD0yb/03dcbVKBgIbPtVy8Hqm/3TmraopW69+qvtOnS6dKF83J3dzc7rtkbb+rd3v1N/3Z3T2WVuJNDeFiYunZ6SxUqVtLn8xcqU6ZMunz5stKnz2A6JjIyUn5lyqp+w9f00fgxNoz25c1dukaxsbGmf1/495xGDOypWnUbSZJy5s6jAe99oGw5cuphVJQ2rlmh9wf10vKNP8ozYybdCgnWrZCb6jXgPeXNV0A3rl/TzCkfKSTkpsYHzLDVsBLkkcZVmz+sr92ng9Xuk526GR6lfFnSKSzikemYga8XVd/Xiqj/wv36J+iu3mtRXF+NqKNK7/+oew+iJUkfv11WjcrkUI+5exR676E+equMVg+tpbpjf1as0Wj2nOPbldb1O5EqmSejVcea1BzhvfBZHH38z+JEYd0i9KwnsRVfLtUbrVur1ZttlL9AAY0YNVo+2Xy0ft0aW4dmFY4+finlz0FExH1N+PB9jfhwgtJn8DDbt2DubFWpVlN9Bw1ToSJFlSNnLlWtUUsZM3mZHZcqVSp5eWc2PdKlt8+KamIsXbJIPj7ZNGFigEqULKXsOXKqUuUqypU7t+mYps1bqFeffqpcpYoNI00anhkzKZOXt+mxf89vyp4zl/zKPq4W1mv0uspVrKLsOXIpb35f9Rk8XPfv39P5f/6WJOUrUFDjJ89U1Rq1lT1nLpUpX0ndew/Q/t07FRMdbcuhxWtQ02K6GhqhAYsO6Mj5UF0Oua/fTt3QxeB7pmN6NSqsGd+d1A+HrujM1TD1W7Bfqd1c1LpKHklS+tSuertWfo1Zc1S7Tt7QX5duq/f8fSqWy0O1SmQ1e756pbKpTkkfjVtz1KrjTA4p/b3weRx9/Eg6JOtJ6NHDhzp96qSqVK1utr1K1Wo6fuzVf+N9Hkcfv+QYczBj8kRVrV5TFSqZJ56xsbHau3uXcuXOo6H9eqhp/Rrq0bm9ftvxa5xrbP3pR71et5o6tmmuz2dOU8T9+9YKP8nt2rFdxYqX0PChg1S3ZlW1f/MNfbVxva3DsopHjx5p25Yf9FrTN2SIZy22R48e6cdvNiptuvQqULBwgte5d++e0qRNJ2cX+/uw97UyOXTsQqiW9K+mM5+/oR0fvaZOtQuY9ufJnFY+nqm148R107aH0bHaezZYFQtmliSVzptJbi7O2vFXkOmY63cidfpKmCr6epu2Zc6QSrPeqag+X+xXxMMYK4wu+TjCe+GzOPr4kbTs753xFXb7zm3FxMTIy8u8iujl5a2QkJs2isp6HH38Usqfg20/b9bfZ05r4Yp1cfbdDr2lyIgIrVy2WD36DlCfgUO1f+9ujR4+SLO/WKoy5SpIkhq+9rqy5cgpLy9vnf/3nL74fJb+OXdWs+YusvZwksTVK5e1Yd0adezcVd179NKJv/7U1IBJcnV1U7MWLW0dXrLas+tX3bt3V41eb2G2fd/uXZo4ZriiHjxQJu/Mmjp7gTw842/pCAu7o5VLv1DTlm9aI2SL5cmcTt3qFtS8LWc08/tTKps/kwI6ltXDRzFat+eisnikliTdDHtgdl5w2APl8k4rScrimUpRj2LMWmeenPPkfEn6vEclLdv+j45dCDWd+6pK6e+Fz+Po438ebjC1jM2T9QEDBqht27aqUaPGC18jKipKUVFRZtuMzu5x+mSt5ekKk9FojLfqlFI5+villDkHN64H6dNPJmvGnAXxvraM/993W71WHbV7u4skqWDhojrx5zF9s2mdKVlv3qqN6Zz8vgWVM3cevduxrc6ePqXCRYtZYSRJKzbWqGLFi2vA4KGSpCJFi+nff/7RhvVrUnyy/tP3X6ti5eryzpzFbHvpchW0YPlGhYXd1o/fbtJHo4fp88Wr4rRD3b9/T6OH9lOevPnV+d0+1gw90ZycpGMXQjVx45+SpL8u3VaRHB7qVq+g1u25aDrO+FTfucEgPbUpDoPBIKMeH9SzQSGlT+2qmd+fStL4bS0lvhdawtHHj6Rh8zaYOXPmqHbt2ipUqJCmTJmi69evP/+kpwQEBMjDw8PsMW1KQDJE+2wZPTPK2dlZISEhZttDQ2/Jy8s7gbNSDkcfv5Sy5+Ds6VO6HXpL73Zsq1oVS6lWxVI6dvigNq5dpVoVSymDh6ecnV2UN38Bs/Py5Muv4OtBCVxVKlykmFxcXHTl8qXkHkKy8M6cWfkL+Jpty5e/gK4HJTzmlOBG0DUdObhfTVq0irMvdeo0ypErt4qV8NPw0f5ydnbWT99/bXZMxP37Gjm4t1KnTi3/KZ/KxcXVWqFb5MadB2arukjS39fClTNTGklScNjj1VyyeKY2OyZzhlS6Gf642h5854HcXZ3lkcZ8jN4Z3E0V+RrFsqq8r5eClrTVjaXtdGhaU0nSrxMaaU7Pykk/sGSWkt8LE8PRx4+kZfNkXZJ++eUXNWnSRJ988oly586tFi1a6IcffjBbceBZRo0apbCwMLPH8PdHPf/EJObq5qaixYpr/949Ztv3790rv9JlrB6PtTn6+KWUPQflK1bW8nXfaOnqTaZHkWLF1bBxUy1dvUlubm4qWryELl+6aHbe5UuXlNUn4ZUPLvz7j6Kjo+XlnTmZR5A8Spcpo0sXL5htC7x0UdmypezVHrb88I08M2ZS5ao1n3usUUY9evjQ9O/79+9pxKCecnVx1UeffCY3G30KmhgHzt2UbzbzG6AL+KTX5VuP77O4dPO+rt+JVO3iPqb9rs5Oqlo4i/4497jd4djFUD2MjlHtEv87JqtHKhXN6aE//nmczI1ceVg1R29RrQ8fP9pN3yVJenfOHk3acDxZx5gcUvJ7YWI4+vifx2Cwn8erwOZtMJJUsmRJ1atXT9OmTdPXX3+tJUuWqGXLlsqaNau6du2qbt26ydfXN8Hz3d3jtrw8sNGiAp26dNPokSNUrEQJ+fmV0aYN6xQUFKQ27drbJiArc/TxSyl3DtKkTav8vgXNtqVKnUYZPDxM29/q1E3jRr0nvzLlVLZCRR3Yu1t7f9+p2V8slfR4acdffvpBVarXlIdnRl08/68+nzlNhQoXVUm/V/N/YB07dVXXTm9p8YL5avBaY538609t2rheY8b5m44JC7uj60FBCg4OliRdvPA4uffy9pb3K/hHSmxsrLb8+I0aNmludlNoZGSEVi1bqKo1asvLK7PCwu7ou03rdDP4hmrVayjpcUX9/YG99OBBpD4YP1kR9++bbjD2+P9qpD2Zv+WsfhrTQEOaFdM3BwJVtoCXOtfx1dAlf5iO+eLnsxrSrJjO37irf6/f1ZDmxRT5MFqb9j3+tOhu5COt2nVeH71VRrfvPdTt+w/l3760Tl0O064TNyRJV29FmD3v/ajH/xO7EHwv3rXYXwUp9b0wsRx9/Eg6dpGsP+Hq6qq2bduqbdu2CgwM1JIlS7Rs2TJNnjxZMTGvxp3xrzVuorA7t7Vg3lzdvBks34KFNGf+AmXPnsPWoVmFo49fcuw5qFW3voZ9ME4rly7UrE8ClDtPXk2cOkt+ZcpJklxcXXX44AFtWLtSkRERypLVR1Wq19I7PfvYXZKWWMVLltT0WZ/ps09naMH8ucqRI6eGvz9KTZo2Mx2za8d2jfvwA9O/Rw5/3N/eq08/9e43wOoxv6wjB/cr+HqQXmv2htl2ZydnXb54QeM3f6fwO7eVwcNThYsW16z5Xypv/scFl7/PnNLpk4/7vzu92cTs/FVfbZGPnb1Ojl4IVefZv2tMGz8Na1FCgSH3NHrVEW3c97+2rdk/nlYqN2dN7VJenmncdPj8LbWeutO0xrokjV59RNGxRi3uX02pXJ3126kb6jfztzhrrKckjvxeKDH+Z+EGU8sYjE/fFWNlTk5Oun79urJkyRLvfqPRqG3btqlBgwYWXddWlXXAntx18BdCWvdX8w+ApBR679HzD0rB/AZtsnUINnd1yVu2DgE2lsquSrPSzrOhtg7BpHbhTLYO4bls3rOeJ0+eZ1bUDAaDxYk6AAAAkBLY/G+tCxcuPP8gAAAApAhOdMFYxOaVdQAAAADxI1kHAAAA7JTN22AAAADgOFgNxjJU1gEAAAA7RbIOAAAA2CnaYAAAAGA1BrpgLEJlHQAAALBTVNYBAABgNRTWLUNlHQAAALBTJOsAAACAnaINBgAAAFbjxB2mFqGyDgAAANgpknUAAADATtEGAwAAAKuhCcYyVNYBAAAAO0WyDgAAANgp2mAAAABgPfTBWITKOgAAAGCnqKwDAADAagyU1i1CZR0AAACwUyTrAAAAgJ2iDQYAAABWY6ALxiJU1gEAAAA7RbIOAAAA2CnaYAAAAGA1dMFYhso6AAAAYKdI1gEAAAA7RRsMAAAArIc+GItQWQcAAADsFJV1AAAAWI2B0rpFqKwDAAAAdopkHQAAALBTBqPRaLR1EMnhQbStIwAA20uZ7/CJx9eaSxkrDbJ1CDZ1+8Cntg7B5lLZWdPz4Yvhtg7BpFzeDLYO4bmorAMAAAB2imQdAAAAsFN29sEIAAAAUjK60yxDZR0AAACwU1TWAQAAYD2U1i1CZR0AAACwUyTrAAAAgJ2iDQYAAABWY6APxiJU1gEAAAA7RbIOAAAA2CmSdQAAAFiNwWA/jxcxd+5c5cuXT6lSpVK5cuX0+++/J3jsV199pQYNGihz5szKkCGDqlSpop9//tmi5yNZBwAAABJh3bp1Gjx4sEaPHq2jR4+qRo0aaty4sQIDA+M9/rffflODBg20efNmHT58WHXq1FGzZs109OjRRD+nwWg0GpNqAPbkQbStIwAA20uZ7/CJ96KVs5QkY6VBtg7Bpm4f+NTWIdhcKjtbTuRY4F1bh2BSOnd6i46vVKmSypYtq3nz5pm2FS1aVC1btlRAQECirlG8eHG1a9dOY8eOTdTxVNYBAABgNQY7elji4cOHOnz4sBo2bGi2vWHDhtq7d2+irhEbG6u7d+8qU6ZMiX5eO/tbCwAAALCOqKgoRUVFmW1zd3eXu7t7nGNDQkIUExOjrFmzmm3PmjWrrl+/nqjnmz59uu7fv6+2bdsmOkYq6wAAALAeW5fT//MICAiQh4eH2eN57SyGp/rrjEZjnG3xWbNmjcaPH69169YpS5Yszz3+CSrrAAAAcEijRo3S0KFDzbbFV1WXJG9vbzk7O8epogcHB8eptj9t3bp16t69uzZs2KD69etbFCOVdQAAADgkd3d3ZciQweyRULLu5uamcuXKaevWrWbbt27dqqpVqyb4HGvWrFHXrl21evVqvf766xbHSGUdAAAAVmOw+NZO+zF06FB16tRJ5cuXV5UqVbRgwQIFBgaqd+/ekh5X6q9evarly5dLepyod+7cWZ9++qkqV65sqsqnTp1aHh4eiXpOknUAAAAgEdq1a6dbt27J399fQUFBKlGihDZv3qw8efJIkoKCgszWXP/iiy8UHR2tfv36qV+/fqbtXbp00bJlyxL1nKyzDgApWMp8h0881llnnXXWWbe/ddb/vHzP1iGYlMqVztYhPJed/fgAAACQkvFHtGW4wRQAAACwUyTrAAAAgJ2iDQYAAABWQxeMZaisAwAAAHaKyjoAAACsh9K6RaisAwAAAHaKZB0AAACwU7TBAAAAwGoM9MFYhMo6AAAAYKdI1gEAAAA7RbKeDNatWaXGDeuqQpmSat+mlY4cPmTrkKzK0ccvOc4crF+7Wm++0UxVK5ZV1Ypl1alDO+3+fZdp/5gPRsqveGGzR8e32tow4qT3vDl4evxPHsuWLLJh1C9u/drVavNGM1WrVFbVKpVV57fNx/vr1l/Up2d31a5eSaVLFNaZM6fjvc7xY0fV453OqlyhtKpXKa/uXTvpwYMH1hqGVaSE94Fh3eor8vCnmvbeG5IkFxcnTRzQTAfXva+Q3VN1fou/Fk14W9m8MyR4jW9m91Lk4U/VrHZJs+2e6VNrsX9HXd81Wdd3TdZi/47ySJfa7JjaFQppx5LBCv5tis7/7K+JA5rJ2fnVS10WL/xCfsULa2rAJFuHYhcMBvt5vApevd94O7flp82aOjlAPXr20bqN36hs2XLq26uHgq5ds3VoVuHo45ccaw6yZPXRoCHDtHr9Jq1ev0kVK1XWoP799M8/50zHVKteQ7/u3G16zJm3wIYRJ73nzcF/x/7rzt2aMPFjGQwG1W/QyMaRv5isPj4aOGSYVq/bpNXrNqlCxcoaPOB/442MjFDpMmU0cPCwBK9x/NhR9ev9rqpUra6VazZo1dqNat/hbTk5pZz/JaWE94FyxXKr+xtV9effV03b0qRyU+kiuTR50c+q8vYnaj9ssQrmyaINM3vEe40BHWrLaIz/+ssmdVapwjnUov98teg/X6UK59Dijzqa9pfwza5vZvfSL/tOq3KHaeo86ku9XquEJg5olqTjTG4n/vpTGzesU6FChW0dCl5RKeed0U6s+HKp3mjdWq3ebKP8BQpoxKjR8snmo/Xr1tg6NKtw9PFLjjUHtevUVY2atZQ3bz7lzZtPAwYNUZo0afTn8WOmY9zc3OSdObPp4eHpabN4k8Pz5uC/Y/fOnFk7t/+qChUrKWeuXLYN/AXVqv14vHny5lOe/4z3r/8fb9PmLdWrT39VqlIlwWt8MjVAb73dSe+821O+vgWVJ09eNWj4mtzc3Kw0iuT3qr8PpE3tpqUTO6nvxLW6Ex5h2h5+74Ga9purTVuP6dylYP1x4pKGTt2kcsVyK5dPRrNrlCyYXQPfrq3e/qvjXL9w3qxqVK2Y+n60Vgf+uqgDf11Uv4/W6vWaJVQwTxZJUptGZXXi3DUFLPxZ56+EaPeRfzX28x/Uq011pUvjnrwTkEQi7t/XqPeHa9yEicrwf+3dd1hU19YG8HdoQxdFiuiliAoINtQoKGKLnWvFGkUs0Rs1AlGx3djFFnuLsSu22GOiWKIYBSMoGhU+u6gJKEgVlTKc7w+vk0zAwr1wzsF5f3nmecKefc6stVFcs2afQ4UKUodD5RSL9VKUn5eHhPgb8PJurjHu5d0MV6/ESRSVeLQ9f0C710ClUuHoTz/i5csXqFevgXo8NuYiWvp4wa9Te8z4eiqePXsmYZRl621r8Maz1FT8cjYS3Xv0kiC60qdSqXDsP/nWrV803+KkPXuGa79dRaVKlhg0oC9at/DG0MGfIe5y+dsi8jYfw8+BpRP9cexcPE5fvPXeueamhigsLERG9p9FvZGhPrbMDUDwgr148iy7yDFN6joiI/sFYq4nqscuXk9ERvYLNK3rBABQGujhVV6+xnEvc/NhZGiABm7l483u3Nkz0aKFL5p6eUsdiqwoZPQoD3jrxlKUnpEOlUoFS0tLjXFLy8pITU2RKCrxaHv+gHauwe1bNzGwf1/k5eXC2NgYS5avgnONGgCAZj4t8Gn7DqhiZ4ffHz/G6hXLMHxIAHZ9v/+j6qK+aw3+6vChAzA2NkGbT9tJEGXpuX3rJgYNeJ2vkbExFi9bBWfnovkW5/HjRwCAtatXInjcBLi6uuGHwwfx+dDB2HvwCBwcHMswcnGU958D/u0aoL5rNTQf+M175yoN9DBrjB92H7uM7Jxc9fiCkO648Nt9HIm8XuxxNpbmSEl7XmQ8Je05bCqbAQBORCdgdD9f9G7vib0n4mBraY6JQ1//3XnXHnm5OPrTj0hIiMeO3XulDoXKOVl01lesWIGAgADs2bMHALBt2zbUrl0brq6umDx5MgoKCt55fG5uLrKysjQeubm57zymLCn+dsWCIAhFxj5m2p4/oF1r4OjohD37DmLbjt3w79MP/54cirt37gAAOnTshBa+LVGzZi20bNUaq779DokPHuBs5Blpgy5l71qDvzp4YB86dfGDUlk+PsJ/G0cnJ+zedxBbw3ejd+9++HpKKO7eLZpvcQoLCwEAPf37oFv3nnB1q43xoZPh6OiEQ/v3lWXYoiuPPweq2Vhg4bieGDJ1G3Lz3v1vr56eDraFBUBHR4Gx8/aoxzu38EDLxrUwftH+dx4vFLOZXaFQAP8ZPnXhJiYvO4Tlk3sjM/ob/HZgCo6diwcAqP7z50iukpOSsGDeHMydt7Dc/30vE1K308tZa13yzvqsWbOwcOFCtGvXDmPHjsX9+/excOFCBAcHQ0dHB0uWLIG+vj5mzJjx1nOEhYUVeX7Kv6dh6tfTyzh6TRUtKkJXVxepqaka42lpz2BpWVnUWKSg7fkD2rkG+gYGsHdwAAC4e9TBjevXEL59K76ePrPIXCsra9jZ2eFh4gORoyxbH7IGly/F4sH9+1iwaKlEUZYefX0D2Nv/Jd8b17Bj+1b8e1rR7/nfWVlZAQCcnZ01xp2qOyMpufxcfPku5fnnQAO3f8DG0gxR2/+8QFhPTxfNPZ0xsrcPKnh9hcJCAXp6OgifFwgHO0t0HLlSo6vesnFNVK9mieQz8zTOvXPBEJyPu4v2I1biybMsWFuaFXn9yhVNNLbNLA8/g+XhZ1ClsjnSs1/CoUolzBrjhwe/p5VB9qUnPv4G0p49Q7/ePdRjKpUKl2JjsGtnOGLirkFXV1fCCKk8kbxY37x5MzZv3owePXrg6tWraNiwIbZs2YIBAwYAAFxdXTFhwoR3FuuTJk1CSEiIxpigK/47WX0DA7jVdseFqPNo0/ZT9fiFqCi0bN1G9HjEpu35A1wD4HW3LD8vr9jnMjLSkZycBCsra5GjEldxa3Bg317UdneHi6urRFGVHUEQkPeW7/nf2VWtBitrazx4cF9jPDHxAZo1b1EW4YmuPP8cOH3xFhr21iyy103rj5sPnuCbLac0CnXnf1ihw4gVSMt8oTF/0eaT2HTwgsbYpT0TMWHxAfx49vW2mF9/ewALM2M0crdH7I2HAIDGHg6wMDPGhd80/2wAQFJqFgCgdwdPPEpOR9z/PSq1nMtCk6ZNsffgDxpj06ZMgmP16ggcOpyFOpWI5MV6UlISGjVqBACoV68edHR0UL9+ffXznp6e+OM9t7pSKpVFPmZ69e5P78rMwIBATJk4AbU9PFCvXgPs+343kpKS4N+nrzQBiUzb8we0aw2WL12M5j4tYGNrixc5OTh29CfExlzE6m/X40VODtasXom2n7ZDZSsr/PH771ixbAksKlZE67ZtpQ691LxrDd54/vw5jh8/hq/Gh0oYael4W76r1r7ONzMzA0lJSUh5+hQAkHj/deFVuXJlVK5sBYVCgYDAoVi7agVqubjCxdUNPxw6gAf372HR4uWS5VXayuvPgecvchF/N0ljLOdlLtIycxB/Nwm6ujrYMX8IGrhWQ4+gddDV1YHNfzrkaZkvkF+gwpNn2cVeVPooOR2Jf7zuiN988AQR5+OxampfjJmzGwCwcmpf/Hj2Om4nPlUfEzywNY5HJ6CwUEDX1nUxbnBbfDZxMwoL33I/SJkwMTFFzZq1NMaMjI1hUcGiyLg2UpSX/ScyIXmxbmtri/j4eNjb2+P27dtQqVSIj4+Hu7s7AODGjRuwti4/XbgOHTshMyMd69asRkrKU9SoWQur1q6DnV1VqUMThbbnD2jXGjx7loopEycgJeUpTM3MUKuWC1Z/ux5e3s3w6tUr3L51Cz8cPojsrGxYWVmh8SdNsGDREpiYmEodeql51xq8ceynHwFBQMdOXSSMtHSkPUvFlEkTkPqXfFet/TPfM6d/xrSpk9TzQ8cHAwBG/Gs0/jVqDADgs4GDkZebh0Xzw5CZlYlatVyx9ruN+Ie9vfgJlZGP9edAVWsL9S83urhL881nu89X4JdLH3btAgAETt2Gb8b3xA+rvgAA/Hj2OoLna16M2a6ZGyYM/RRKfT1cu/0H/EPW43hU8b9oi+hjpRCKu8JDRFOnTsW6devQtWtXnDp1Cn379kV4eDgmTZoEhUKBOXPmoFevXli8eHGJzitVZ52ISE6k/QkvPZlfzymKik3GSh2CpNJ/XSZ1CJIzlLw1q+n/kl68f5JIXKsYSx3Ce0n+7ZsxYwaMjIxw4cIFjBgxAqGhoahbty4mTJiAFy9ewM/PD7NmzZI6TCIiIiIqBXwTXTKSd9bLCjvrRETsrLMoYGednXX5ddZvJsuns+5iy846EREREZEa30OXjCx+KRIRERERERXFYp2IiIiISKa4DYaIiIiIxMN9MCXCzjoRERERkUyxWCciIiIikilugyEiIiIi0Si4D6ZE2FknIiIiIpIpFutERERERDLFbTBEREREJBr+ZuGSYWediIiIiEim2FknIiIiItGwsV4y7KwTEREREckUi3UiIiIiIpniNhgiIiIiEg/3wZQIO+tERERERDLFYp2IiIiISKa4DYaIiIiIRKPgPpgSYWediIiIiEimWKwTEREREckUt8EQERERkWgU3AVTIuysExERERHJFDvrRERERCQaNtZLhp11IiIiIiKZYrFORERERCRT3AZDREREROLhPpgSYWediIiIiEimWKwTEREREckUt8EQERERkWgU3AdTIuysExERERHJFDvrRERERCQa/gbTkmFnnYiIiIhIphSCIAhSB1EWXhVIHQERERFJrWLj0VKHILmXcSulDkHDw7RcqUNQs6+klDqE9+I2GCIiIiISDXfBlAy3wRARERERyRSLdSIiIiIimeI2GCIiIiISDe8GUzLsrBMRERERyRSLdSIiIiIimeI2GCIiIiISEffBlAQ760REREREMsXOOhERERGJhheYlgw760REREREMsVinYiIiIhIprgNhoiIiIhEw10wJcPOOhERERGRTLFYJyIiIiKSKW6DISIiIiLR8G4wJcPOOhERERGRTLFYJyIiIiKSKW6DISIiIiLRKHg/mBJhZ52IiIiISKbYWSciIiIi8bCxXiLsrBMRERERyRSLdSIiIiIimeI2GCIiIiISDXfBlAw760REREREMsVinYiIiIhIprgNhoiIiIhEo+A+mBJhZ52IiIiISKZYrBMRERERyRS3wRARERGRaBS8H0yJsLNORERERCRT7KwTERERkXjYWC8RdtaJiIiIiGSKxXoZ2L0zHB3btUbjBnXQ178HLl+KlTokUWl7/gDXQNvzB7gGANdA2/MHPo41GDekHc5tH4+n5xYh8VQY9iwejpoO1hpzTIwMsCTUH3eOzUJa9GLE7ZuK4f7NNeasmNIXNw5PQ1r0Yjz8OQx7lnyOWo42GnNq2Ftjz5LP8ejneXjyy0L8vCkYLRrVLPMcSd5YrJeyY0d/woJ5YRj++b+we+9BeHo2xBcjhiPpjz+kDk0U2p4/wDXQ9vwBrgHANdD2/IGPZw18PGtg7e6z8B20CF3+tRK6uro4smY0jA0N1HMWjOuJT71rI3DKVtTvMRsrwk9j8QR/dGlZRz0nLuERPp++HfV7zMY/v1gFhUKBI6tHQUfnzz0hB1aMhJ6uDjqOWA7vAQtw9ebv2L98JGwszUTNuawpZPQoDxSCIAhSB1EWXhVI87oD+vrDrXZtTP16hnqsm19HtGrdFmODv5ImKBFpe/4A10Db8we4BgDXQNvzB+SzBhUbjy7V81WuaIpHP89D26FLcP7yXQBA7PeTsff4Zcz77ph63vnwCYg4fwMzV/9Y7Hk8atohZs9k1PabjvuPU2FpYYLHp+ej7ZAlOB/3+rymxkqknP8GHUcsx5mLt/7rmF/Grfyvjy0Lqc8lKtKKUdlU/pdvSt5ZT0pKwtdff43WrVvDzc0NHh4e8PPzw4YNG6BSqaQOr0Ty8/KQEH8DXt6aH315eTfD1StxEkUlHm3PH+AaaHv+ANcA4Bpoe/7Ax70G5qaGAID0zBfqsagr99DFtw7srCoAAFo0qomaDtY4GZVQ7DmMDQ0w6J9Ncf9xKh4npwMAnmXkIOFeEvp3+QTGhgbQ1dXBsJ7NkZyahbj4R2WcFcmZpG8nYmNj0bZtWzg5OcHIyAi3bt3CgAEDkJeXh3HjxmHDhg2IiIiAmVn5+PgnPSMdKpUKlpaWGuOWlpWRmpoiUVTi0fb8Aa6BtucPcA0AroG25w983Gsw/6ueOH/5DuLvJqnHvpr/PVZ/3R93j89Bfr4KhUIh/jVzB6Ku3NM49nN/H8wJ6gZTYyX+714yOv9rJfIL/mxMdhm5EnuWjkDK+UUoLBTwNC0bXUetQubzl6LlJwZFedl/IhOSdtaDgoIQHByMuLg4REVFYcuWLbh16xZ27dqFe/fu4eXLl5g6dep7z5Obm4usrCyNR25urggZFE/xtz+FgiAUGfuYaXv+ANdA2/MHuAYA10Db8wc+vjVYMrE36tS0Q8CkzRrjo/q1xCd1HNFz7Fp4D5iPiYsPYNmkPmjVxEVj3q6jMWja7/UWmjuPUrB9/hAoDf7smy6d3AcpadloO2QpfAYuxA9nfsP+5SNhW9lcjPRIpiQt1i9fvoyBAweqv+7fvz8uX76MJ0+eoGLFiliwYAH27t373vOEhYWhQoUKGo+F88PKMvRiVbSoCF1dXaSmpmqMp6U9g6VlZdHjEZu25w9wDbQ9f4BrAHANtD1/4ONcg8Wh/ujiWwfthy/H708z1OOGSn3MGOOH0G/246ez13H99h9Yu/ss9h6/jKCBbTTOkfX8Fe4+TMH5y3fRf9x6uDjZoGvregCAlp/UQicfDwyauAnRV+/hyv89RlDYHrzMzcdnfk3ETLXMKWT0X3kgabFubW2NpKQ/P0Z68uQJCgoKYG7++h1kzZo1kZaW9t7zTJo0CZmZmRqP8aGTyizut9E3MIBbbXdciDqvMX4hKgr16jcQPR6xaXv+ANdA2/MHuAYA10Db8wc+vjVYEuqPrq3rocOI5Uj845nGc/p6ujDQ10Ph3+7XoVIVatzppTgKKGCg/7qz/ubuMoWFhRpzCgvL96cR9L+TdM96t27dMHLkSCxcuBBKpRKzZs2Cr68vjIyMAAA3b95E1apV33sepVIJpVKpMSbV3WAGBgRiysQJqO3hgXr1GmDf97uRlJQE/z59pQlIZNqeP8A10Pb8Aa4BwDXQ9vyBj2cNlk7qjT4dG8E/eB2e57xS30Yx8/krvMrNR3bOK5yNvY25Qd3w8lU+HialwadhDQzo8glCF+8HADhWtUSv9g1xKjoBqenPYWdtga8Gt8XL3HxEnLsBAPj1t/tIz3qB9bMGYe66o3j5Kh9DenjDsaoljv1nDmknSYv12bNnIykpCX5+flCpVPDy8sL27dvVzysUCoSFib+d5X/RoWMnZGakY92a1UhJeYoaNWth1dp1sLN7/5uOj4G25w9wDbQ9f4BrAHANtD1/4ONZgxG9WwAATqwP0hgf/vU2bP/hVwDAoIkbMXNMV2yeG4CK5sZ4mJSG6auO4LvvzwEAcvMK0KyBM0b3b4mK5sZ4+iwb5y7fQavB3yAl/TmA13eD6Tp6NaaP8sPRb7+Evp4OEu4lwz94Ha7d+l28hEXADwpKRhb3WX/16hUKCgpgampaeueUzy08iYiISCKlfZ/18khu91lPfyGfW3NXNNaVOoT3ksWd4A0NDaUOgYiIiIhIdiT/pUhERERERFQ8FutERERERDLFYp2IiIiISKZksWediIiIiLQD7wZTMuysExERERHJFDvrRERERCQaBdhaLwl21omIiIiIZIrFOhERERGRTHEbDBERERGJhheYlgw760REREREMsVinYiIiIhIprgNhoiIiIhEw10wJcPOOhERERGRTLFYJyIiIiKSKW6DISIiIiLxcB9MibCzTkREREQkU+ysExEREZFoFGytlwg760REREREMsVinYiIiIhIprgNhoiIiIhEo+AumBJhZ52IiIiISKZYrBMRERERyRS3wRARERGRaLgLpmTYWSciIiIikikW60REREREMsVtMEREREQkHu6DKRF21omIiIiIZIqddSIiIiISjYKt9RJhZ52IiIiI6AOtXr0aTk5OMDQ0RMOGDfHLL7+8c35kZCQaNmwIQ0NDVK9eHWvXri3R67FYJyIiIiL6ALt370ZQUBCmTJmCuLg4+Pj4oGPHjnj48GGx8+/fv49OnTrBx8cHcXFxmDx5Mr788kvs27fvg19TIQiCUFoJyMmrAqkjICIiIqlVbDxa6hAk9zJupdQhaJBTjWZYwg3hTZo0gaenJ9asWaMec3NzQ7du3RAWFlZkfmhoKA4fPoyEhAT12MiRI3H16lVER0d/0Guys05ERERE9B55eXm4dOkS2rVrpzHerl07REVFFXtMdHR0kfnt27dHbGws8vPzP+h1eYEpEREREWml3Nxc5ObmaowplUoolcoic1NTU6FSqWBjY6MxbmNjg+Tk5GLPn5ycXOz8goICpKamokqVKu+N8aMt1kv6sUZpy83NRVhYGCZNmlTsN/xjp+35A1wDbc8f4Bpoe/4A10AO+Uu9BUQOayA3UtdofzV9dhhmzJihMTZt2jRMnz79rccoFJp3sxEEocjY++YXN/7W4z/WPetSy8rKQoUKFZCZmQlzc3OpwxGdtucPcA20PX+Aa6Dt+QNcA23PH+AayF1JOut5eXkwNjbG999/j+7du6vHx44diytXriAyMrLIMS1atECDBg2wbNky9diBAwfQu3dvvHjxAvr6+u+NkXvWiYiIiEgrKZVKmJubazze9gmIgYEBGjZsiBMnTmiMnzhxAt7e3sUe4+XlVWT+8ePH0ahRow8q1AEW60REREREHyQkJATr16/Hxo0bkZCQgODgYDx8+BAjR44EAEyaNAmDBg1Szx85ciQSExMREhKChIQEbNy4ERs2bMC4ceM++DVltGuIiIiIiEi++vTpg2fPnmHmzJlISkqCh4cHfvrpJzg4OAAAkpKSNO657uTkhJ9++gnBwcFYtWoV7OzssHz5cvTs2fODX5PFehlRKpWYNm2a1l5Mou35A1wDbc8f4Bpoe/4A10Db8we4Bh+jL774Al988UWxz23evLnImK+vLy5fvvxfvx4vMCUiIiIikinuWSciIiIikikW60REREREMsVinYiIiIhIplisl7KzZ8/Cz88PdnZ2UCgUOHjwoNQhiSosLAyNGzeGmZkZrK2t0a1bN9y8eVPqsESzZs0a1K1bV32vVi8vLxw9elTqsCQTFhYGhUKBoKAgqUMRzfTp06FQKDQetra2Uoclut9//x2fffYZLC0tYWxsjPr16+PSpUtShyUKR0fHIn8GFAoFRo0aJXVooikoKMDUqVPh5OQEIyMjVK9eHTNnzkRhYaHUoYkmOzsbQUFBcHBwgJGREby9vRETEyN1WFQO8W4wpSwnJwf16tVDYGBgiW7L87GIjIzEqFGj0LhxYxQUFGDKlClo164d4uPjYWJiInV4Za5atWqYN28eatSoAQDYsmULunbtiri4OLi7u0scnbhiYmKwbt061K1bV+pQROfu7o6TJ0+qv9bV1ZUwGvGlp6ejWbNmaNWqFY4ePQpra2vcvXsXFhYWUocmipiYGKhUKvXX169fx6effgp/f38JoxLX/PnzsXbtWmzZsgXu7u6IjY1FYGAgKlSogLFjx0odniiGDRuG69evY9u2bbCzs8P27dvRtm1bxMfHo2rVqlKHR+UI7wZThhQKBQ4cOIBu3bpJHYpkUlJSYG1tjcjISLRo0ULqcCRRqVIlLFy4EEOHDpU6FNE8f/4cnp6eWL16NWbPno369etj6dKlUocliunTp+PgwYO4cuWK1KFIZuLEiTh//jx++eUXqUORhaCgIBw5cgS3b9+GQqGQOhxRdOnSBTY2NtiwYYN6rGfPnjA2Nsa2bdskjEwcL1++hJmZGQ4dOoTOnTurx+vXr48uXbpg9uzZEkZH5Q23wVCZyszMBPC6YNU2KpUKu3btQk5ODry8vKQOR1SjRo1C586d0bZtW6lDkcTt27dhZ2cHJycn9O3bF/fu3ZM6JFEdPnwYjRo1gr+/P6ytrdGgQQN89913Uocliby8PGzfvh1DhgzRmkIdAJo3b45Tp07h1q1bAICrV6/i3Llz6NSpk8SRiaOgoAAqlQqGhoYa40ZGRjh37pxEUVF5xW0wVGYEQUBISAiaN28ODw8PqcMRzbVr1+Dl5YVXr17B1NQUBw4cQO3ataUOSzS7du3C5cuXtXZvZpMmTbB161bUqlULT548wezZs+Ht7Y0bN27A0tJS6vBEce/ePaxZswYhISGYPHkyLl68iC+//BJKpVLj13Brg4MHDyIjIwODBw+WOhRRhYaGIjMzE66urtDV1YVKpcKcOXPQr18/qUMThZmZGby8vDBr1iy4ubnBxsYGO3fuxK+//oqaNWtKHR6VMyzWqcyMHj0av/32m9Z1EVxcXHDlyhVkZGRg3759CAgIQGRkpFYU7I8ePcLYsWNx/PjxIh0lbdGxY0f1/9epUwdeXl5wdnbGli1bEBISImFk4iksLESjRo0wd+5cAECDBg1w48YNrFmzRuuK9Q0bNqBjx46ws7OTOhRR7d69G9u3b8eOHTvg7u6OK1euICgoCHZ2dggICJA6PFFs27YNQ4YMQdWqVaGrqwtPT0/079//f/pNlqSdWKxTmRgzZgwOHz6Ms2fPolq1alKHIyoDAwP1BaaNGjVCTEwMli1bhm+//VbiyMrepUuX8PTpUzRs2FA9plKpcPbsWaxcuRK5ublad7GliYkJ6tSpg9u3b0sdimiqVKlS5M2pm5sb9u3bJ1FE0khMTMTJkyexf/9+qUMR3fjx4zFx4kT07dsXwOs3romJiQgLC9OaYt3Z2RmRkZHIyclBVlYWqlSpgj59+sDJyUnq0KicYbFOpUoQBIwZMwYHDhzAmTNn+EMJr9ckNzdX6jBE0aZNG1y7dk1jLDAwEK6urggNDdW6Qh0AcnNzkZCQAB8fH6lDEU2zZs2K3LL11q1bcHBwkCgiaWzatAnW1tYaFxhqixcvXkBHR/OyOF1dXa26deMbJiYmMDExQXp6OiIiIrBgwQKpQ6JyhsV6KXv+/Dnu3Lmj/vr+/fu4cuUKKlWqBHt7ewkjE8eoUaOwY8cOHDp0CGZmZkhOTgYAVKhQAUZGRhJHV/YmT56Mjh074h//+Aeys7Oxa9cunDlzBseOHZM6NFGYmZkVuT7BxMQElpaWWnPdwrhx4+Dn5wd7e3s8ffoUs2fPRlZWltZ0EwEgODgY3t7emDt3Lnr37o2LFy9i3bp1WLdundShiaawsBCbNm1CQEAA9PS0759aPz8/zJkzB/b29nB3d0dcXBwWL16MIUOGSB2aaCIiIiAIAlxcXHDnzh2MHz8eLi4uCAwMlDo0Km8EKlWnT58WABR5BAQESB2aKIrLHYCwadMmqUMTxZAhQwQHBwfBwMBAsLKyEtq0aSMcP35c6rAk5evrK4wdO1bqMETTp08foUqVKoK+vr5gZ2cn9OjRQ7hx44bUYYnuhx9+EDw8PASlUim4uroK69atkzokUUVERAgAhJs3b0odiiSysrKEsWPHCvb29oKhoaFQvXp1YcqUKUJubq7UoYlm9+7dQvXq1QUDAwPB1tZWGDVqlJCRkSF1WFQO8T7rREREREQyxfusExERERHJFIt1IiIiIiKZYrFORERERCRTLNaJiIiIiGSKxToRERERkUyxWCciIiIikikW60REREREMsVinYiIiIhIplisE1GZ2rx5MxQKhfqhp6eHatWqITAwEL///rsoMTg6OmLw4MHqr8+cOQOFQoEzZ86U6DxRUVGYPn06MjIySjU+ABg8eDAcHR3fO69ly5bw8PAoldd8872JjY0tlfP99ZwPHjwotXMSEWkzFutEJIpNmzYhOjoaJ06cwPDhw7Fz5074+PggJydH9Fg8PT0RHR0NT0/PEh0XFRWFGTNmlEmxTkREVBw9qQMgIu3g4eGBRo0aAQBatWoFlUqFWbNm4eDBgxgwYECxx7x48QLGxsalHou5uTmaNm1a6uclIiIqbeysE5Ek3hTLiYmJAF5vAzE1NcW1a9fQrl07mJmZoU2bNgCAvLw8zJ49G66urlAqlbCyskJgYCBSUlI0zpmfn48JEybA1tYWxsbGaN68OS5evFjktd+2DebXX3+Fn58fLC0tYWhoCGdnZwQFBQEApk+fjvHjxwMAnJyc1Nt6/nqO3bt3w8vLCyYmJjA1NUX79u0RFxdX5PU3b94MFxcXKJVKuLm5YevWrf/VGr5NbGws+vbtC0dHRxgZGcHR0RH9+vVTr/XfpaenIzAwEJUqVYKJiQn8/Pxw7969IvNOnjyJNm3awNzcHMbGxmjWrBlOnTpVqrETEZEmFutEJIk7d+4AAKysrNRjeXl5+Oc//4nWrVvj0KFDmDFjBgoLC9G1a1fMmzcP/fv3x48//oh58+bhxIkTaNmyJV6+fKk+fvjw4Vi0aBEGDRqEQ4cOoWfPnujRowfS09PfG09ERAR8fHzw8OFDLF68GEePHsXUqVPx5MkTAMCwYcMwZswYAMD+/fsRHR2tsZVm7ty56NevH2rXro09e/Zg27ZtyM7Oho+PD+Lj49Wvs3nzZgQGBsLNzQ379u3D1KlTMWvWLPz888//+6L+x4MHD+Di4oKlS5ciIiIC8+fPR1JSEho3bozU1NQi84cOHQodHR3s2LEDS5cuxcWLF9GyZUuN7T7bt29Hu3btYG5uji1btmDPnj2oVKkS2rdvz4KdiKgsCUREZWjTpk0CAOHChQtCfn6+kJ2dLRw5ckSwsrISzMzMhOTkZEEQBCEgIEAAIGzcuFHj+J07dwoAhH379mmMx8TECACE1atXC4IgCAkJCQIAITg4WGNeeHi4AEAICAhQj50+fVoAIJw+fVo95uzsLDg7OwsvX758ay4LFy4UAAj379/XGH/48KGgp6cnjBkzRmM8OztbsLW1FXr37i0IgiCoVCrBzs5O8PT0FAoLC9XzHjx4IOjr6wsODg5vfe03fH19BXd39/fO+6uCggLh+fPngomJibBs2TL1+JvvTffu3TXmnz9/XgAgzJ49WxAEQcjJyREqVaok+Pn5acxTqVRCvXr1hE8++aTIOf++RkRE9N9hZ52IRNG0aVPo6+vDzMwMXbp0ga2tLY4ePQobGxuNeT179tT4+siRI7CwsICfnx8KCgrUj/r168PW1la9DeX06dMAUGT/e+/evaGn9+7Lc27duoW7d+9i6NChMDQ0LHFuERERKCgowKBBgzRiNDQ0hK+vrzrGmzdv4o8//kD//v2hUCjUxzs4OMDb27vEr/s2z58/R2hoKGrUqAE9PT3o6enB1NQUOTk5SEhIKDL/72vm7e0NBwcH9ZpGRUUhLS0NAQEBGvkVFhaiQ4cOiImJkeRCYSIibcALTIlIFFu3boWbmxv09PRgY2ODKlWqFJljbGwMc3NzjbEnT54gIyMDBgYGxZ73zbaOZ8+eAQBsbW01ntfT04OlpeU7Y3uz971atWoflszfvNkq07hx42Kf19HReWeMb8ZK63aH/fv3x6lTp/Dvf/8bjRs3hrm5ORQKBTp16qSxbeivr13c2Jt43+TXq1evt75mWloaTExMSiV+IiL6E4t1IhKFm5ub+m4wb/PXbvMblStXhqWlJY4dO1bsMWZmZgCgLsiTk5NRtWpV9fMFBQXqovNt3uybf/z48TvnvU3lypUBAHv37oWDg8Nb5/01xr8rbuy/kZmZiSNHjmDatGmYOHGiejw3NxdpaWnFHvO2eGrUqAHgz/xWrFjx1rvo/P0TEiIiKh0s1olI1rp06YJdu3ZBpVKhSZMmb53XsmVLAEB4eDgaNmyoHt+zZw8KCgre+Rq1atWCs7MzNm7ciJCQECiVymLnvRn/e3e6ffv20NPTw927d4ts4/krFxcXVKlSBTt37kRISIj6zUliYiKioqJgZ2f3zjg/hEKhgCAIRXJYv349VCpVsceEh4drxB0VFYXExEQMGzYMANCsWTNYWFggPj4eo0eP/p9jJCKiD8dinYhkrW/fvggPD0enTp0wduxYfPLJJ9DX18fjx49x+vRpdO3aFd27d4ebmxs+++wzLF26FPr6+mjbti2uX7+ORYsWFdlaU5xVq1bBz88PTZs2RXBwMOzt7fHw4UNEREQgPDwcAFCnTh0AwLJlyxAQEAB9fX24uLjA0dERM2fOxJQpU3Dv3j106NABFStWxJMnT3Dx4kWYmJhgxowZ0NHRwaxZszBs2DB0794dw4cPR0ZGBqZPn17sVpS3ycrKwt69e4uMW1lZwdfXFy1atMDChQtRuXJlODo6IjIyEhs2bICFhUWx54uNjcWwYcPg7++PR48eYcqUKahatSq++OILAICpqSlWrFiBgIAApKWloVevXrC2tkZKSgquXr2KlJQUrFmz5oPjJyKiEpD6Clci+ri9uTtITEzMO+cFBAQIJiYmxT6Xn58vLFq0SKhXr55gaGgomJqaCq6ursKIESOE27dvq+fl5uYKX331lWBtbS0YGhoKTZs2FaKjowUHB4f33g1GEAQhOjpa6Nixo1ChQgVBqVQKzs7ORe4uM2nSJMHOzk7Q0dEpco6DBw8KrVq1EszNzQWlUik4ODgIvXr1Ek6ePKlxjvXr1ws1a9YUDAwMhFq1agkbN24UAgICPvhuMACKffj6+gqCIAiPHz8WevbsKVSsWFEwMzMTOnToIFy/fr3IOrz53hw/flwYOHCgYGFhIRgZGQmdOnXSWNc3IiMjhc6dOwuVKlUS9PX1hapVqwqdO3cWvv/++yLn5N1giIhKh0IQBEGi9wlERERERPQOvHUjEREREZFMsVgnIiIiIpIpFutERERERDLFYp2IiIiISKZYrBMRERERyRSLdSIiIiIimWKxTkREREQkUyzWiYiIiIhkisU6EREREZFMsVgnIiIiIpIpFutERERERDLFYp2IiIiISKb+H0CB0hnLLCMXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 97.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 95.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 95.77%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T17:32:54.868875Z",
     "iopub.status.busy": "2025-05-08T17:32:54.868875Z",
     "iopub.status.idle": "2025-05-08T17:32:54.886163Z",
     "shell.execute_reply": "2025-05-08T17:32:54.886163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.80\n",
      "1    LRM (CAE)          96.08\n",
      "2    MLP (CAE)          96.81\n",
      "3     TSCL LRM          96.00\n",
      "4     TSCL MLP          95.41\n",
      "5  SCL_SDL LRM          96.27\n",
      "6  SCL_SDL MLP          95.77\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.80\n",
      "2    MLP (CAE)          96.81\n",
      "5  SCL_SDL LRM          96.27\n",
      "1    LRM (CAE)          96.08\n",
      "3     TSCL LRM          96.00\n",
      "6  SCL_SDL MLP          95.77\n",
      "4     TSCL MLP          95.41\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
