{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:53:56.803247Z",
     "iopub.status.busy": "2025-05-08T18:53:56.803247Z",
     "iopub.status.idle": "2025-05-08T18:53:56.806589Z",
     "shell.execute_reply": "2025-05-08T18:53:56.806589Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:53:56.810099Z",
     "iopub.status.busy": "2025-05-08T18:53:56.809595Z",
     "iopub.status.idle": "2025-05-08T18:53:58.892573Z",
     "shell.execute_reply": "2025-05-08T18:53:58.892573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:53:58.894581Z",
     "iopub.status.busy": "2025-05-08T18:53:58.894581Z",
     "iopub.status.idle": "2025-05-08T18:54:02.210409Z",
     "shell.execute_reply": "2025-05-08T18:54:02.210409Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:02.213458Z",
     "iopub.status.busy": "2025-05-08T18:54:02.213458Z",
     "iopub.status.idle": "2025-05-08T18:54:02.229982Z",
     "shell.execute_reply": "2025-05-08T18:54:02.229982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:02.231990Z",
     "iopub.status.busy": "2025-05-08T18:54:02.231990Z",
     "iopub.status.idle": "2025-05-08T18:54:03.192175Z",
     "shell.execute_reply": "2025-05-08T18:54:03.192175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1476, 256)\n",
      "Hypercube shape: (1476, 256, 145)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAAGxCAYAAABfkTXHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmc0lEQVR4nO3deXQUVdoG8Ke6qruTNEknnb2z0WGHgEICGHVmAB2QEZHPYcBlED/9HBhBRJABj+MCozA4Low6qHA44LAIZ86AoiIKsgwMICEhILJjCGFJQrYme9JV9/sj0NJkvUlVb3l/5/Q5prtSdTs+3Npu3VdgjDEQwkHn6QYQ30OhIdwoNIQbhYZwo9AQbhQawo1CQ7hRaAg3Cg3h1mlDs2rVKgiCgEOHDnV4XYIgYPr06Sq0ynWdr732mqrrVEunDQ1pPwoN4UahaUZNTQ1mz56N22+/HWazGRaLBenp6fj888+b/Z2PP/4YPXv2hNFoRN++fbF+/fpGy+Tn52PKlCmIj4+HwWCAzWbD/Pnz4XA4WmxPVVUVXnjhBdhsNgQEBMBisSAtLQ2ffvpph78rL8ntW/QRtbW1KCkpwQsvvIC4uDjU1dVh+/bteOihh7By5Uo8/vjjLstv3rwZO3fuxIIFC2AymbB06VI88sgjkCQJ48ePB9AQmCFDhkCn0+GVV15Bt27dsH//frz++us4f/48Vq5c2Wx7Zs2ahdWrV+P111/HwIEDUVlZiWPHjqG4uFjTv0OTWCe1cuVKBoBlZGS0aXmHw8Hq6+vZU089xQYOHOjyGQAWGBjI8vPzXZbv3bs36969u/O9KVOmsC5durDc3FyX33/rrbcYAPbjjz+6rPPVV191/pySksLGjRvH8xU1Q7unFvzrX//CXXfdhS5dukCSJOj1eqxYsQInTpxotOw999yD6Oho58+iKGLixIk4e/YsLl68CAD48ssvMXz4cFitVjgcDudr9OjRAIDdu3c325YhQ4bg66+/xrx587Br1y5UV1er/G3bjkLTjI0bN2LChAmIi4vDmjVrsH//fmRkZODJJ59ETU1No+VjYmKafe/GLqSgoABffPEF9Hq9y6tfv34AgKKiombb895772Hu3Ln47LPPMHz4cFgsFowbNw5nzpxR4+tyoWOaZqxZswY2mw0bNmyAIAjO92tra5tcPj8/v9n3wsPDAQAREREYMGAA3njjjSbXYbVam22PyWTC/PnzMX/+fBQUFDh7nQceeAAnT55s8/dSA4WmGYIgwGAwuAQmPz+/2bOn7777DgUFBc5dlCzL2LBhA7p164b4+HgAwJgxY7BlyxZ069YNYWFh7W5bdHQ0nnjiCRw5cgRLlixBVVUVgoKC2r0+Xp0+NDt27MD58+cbvT9ixAhs3LgRzzzzDMaPH4+8vDz85S9/QWxsbJO7hIiICIwYMQIvv/yy8+zp5MmTLqfdCxYswLZt23DnnXdixowZ6NWrF2pqanD+/Hls2bIFH330kTNgtxo6dCjGjBmDAQMGICwsDCdOnMDq1auRnp7u1sAAoLOn5l45OTnsr3/9K+vatSszGo2sT58+bPny5ezVV19lt/7ZALBp06axpUuXsm7dujG9Xs969+7N1q5d22i7V69eZTNmzGA2m43p9XpmsVhYamoqe+mll1hFRYXLOm8+e5o3bx5LS0tjYWFhzGg0suTkZPb888+zoqIizf5GzRGuN5CQNqOzJ8KNQkO4UWgIN68PzdKlS5036VJTU7Fnzx5PN6nT8+rQbNiwATNnzsRLL72Ew4cP4xe/+AVGjx6NCxcueLppnZpXnz0NHToUgwYNwocffuh8r0+fPhg3bhwWLVrkwZZ1bl57ca+urg6ZmZmYN2+ey/sjR47Evn37Gi1fW1vrcolfURSUlJQgPDzc5apuZ8EYQ3l5OaxWK3Q6dXcoXhuaoqIiyLLscucYaLiE3tR9nkWLFmH+/Pnuap7PyMvLa/Yqc3t5bWhuuLWXYIw12XO8+OKLmDVrlvNnu92OxMRE3I3fQIJe83Z6GwfqsRdbEBwcrPq6vTY0EREREEWxUa9SWFjYqPcBAKPRCKPR2Oh9CXpIQucLDa4fqWqxa/basyeDwYDU1FRs27bN5f0bN/yI53htTwM0jIudNGkS0tLSkJ6ejmXLluHChQuYOnWqp5vWqXl1aCZOnIji4mIsWLAAV65cQUpKCrZs2YKkpCRPN61T8+rrNB1x7do1mM1mDMODnfKYxsHqsQufw263IyQkRNV1e+0xDfFeFBrCjUJDuFFoCDcKDeFGoSHcKDSEG4WGcKPQEG4UGsKNQkO4UWgINwoN4UahIdwoNIQbhYZwo9AQbhQawo1CQ7hRaAg3Cg3hRqFphTxsEMofvgOC3uDppngNCk0rDJftUERAF2r2dFO8hlc/LOcN5NPnYD59DrKnG+JFqKch3Cg0hFunCo0uOBhCE9ORED6dKzThYRAMdBbUUZ3qQNhxnmYFVUOn6mmIOig0hBuFhnCj0BBuFBrCjULTgrpRadCZTC7vCZIEdMIZ0G9GoWlB4PkysLp6l/eKJg9G8VN3NFpWkCRAJ7qraR7Vqa7T8JJPnW30XtTnpwHGIAsCcNMclzWjBqIqQoJlXSZYfZ07m+l21NNwkouKgahwiD2SATTcmqi/NxVBB86hOlrA5RlpEFWeTdPbUE/TDvKJn0ssK+Xl0O/IhqzIsP5tP6ToKFz+fQqsm36C40rjwh/+QPWeZtGiRRg8eDCCg4MRFRWFcePG4dSpUy7LMMbw2muvwWq1IjAwEMOGDcOPP/7oskxtbS2effZZREREwGQyYezYsbh48aLazW03MTrq5x+U66NtGIMjvwBRH30PR8FVzzTMDVQPze7duzFt2jQcOHAA27Ztg8PhwMiRI1FZWelc5s0338Q777yDDz74ABkZGYiJicGvf/1rlJeXO5eZOXMmNm3ahPXr12Pv3r2oqKjAmDFjIMveMRxKLihs8n0pIR6iJfTnIPkhzWcsv3r1KqKiorB792788pe/BGMMVqsVM2fOxNy5cwE09CrR0dFYvHgxpkyZArvdjsjISKxevRoTJ04EAFy+fBkJCQnYsmULRo0a1ep2PTVjuc5kAqur9/jBsE/PWG632wEAFosFAJCTk4P8/HyMHDnSuYzRaMSvfvUrZ8W4zMxM1NfXuyxjtVqRkpLSZFU5oCF4165dc3l5glJZ6fHAaE3T0DDGMGvWLNx9991ISUkBAGf9ppYqxuXn58NgMCAsLKzZZW61aNEimM1m5yshIUHtr0Ou0zQ006dPx9GjR/Hpp582+qytFePausyLL74Iu93ufOXl5bW/4aRFmoXm2WefxebNm7Fz506XGooxMTEA0GLFuJiYGNTV1aG0tLTZZW5lNBoREhLi8iLaUD00jDFMnz4dGzduxI4dO2Cz2Vw+t9lsiImJcakYV1dXh927dzsrxqWmpkKv17ssc+XKFRw7doyqynkB1S/uTZs2DevWrcPnn3+O4OBgZ49iNpsRGBgIQRAwc+ZMLFy4ED169ECPHj2wcOFCBAUF4dFHH3Uu+9RTT2H27NkIDw+HxWLBCy+8gP79++Pee+9Vu8mEk+qhuVF4fdiwYS7vr1y5Ek888QQA4E9/+hOqq6vxzDPPoLS0FEOHDsW3337rUtn13XffhSRJmDBhAqqrq3HPPfdg1apVEMXOcVPQm1FlOT/l09dpiP+h0BBuFBrCjUJDuFFoCDcKDeFGoSHcKDSEG4WGcKPQEG4UGsKNQkO4UWh8kYefJafQ+CDREobqB4dAio3xyPYpND5CFxAA3fXxRnJxCUznruHEYiukJPcPoKfQ+Ijq4f1x5qPuqPqfoYAgQDl2EuIVI0ruinN7Wyg0PsK49RCS/6EgfOZ5CLf3BQCYzwD1Qe4/vqHQ+ArGIBw4htPbuwFSw/+2oCIZQUXuf/yXZo3wJYqMhL/sw43xuYGbMz3SDOppfJkiN55oQBAgDx+EmtGpmm2WQuNvGIO9qxEXx2q326LQ+AkxMhJCaj8AgGXlfnT/Y7Zm26LQ+ImKO204/WQXt2yLDoT9RJcD59HnhyA43LAtCo2faG5mLi3Q7snfCALYnbdBunlOQJVRaPwNY7iWHIiLS8JaX7adaPfkh8zrMhCSEY+TGq2fehp/pMiQTzaebV0tFBrCjUJDuFFoCDcKDeFGoSHcKDQ+Tgy3QIwId3lPFxCg6TYpND6sYsId6PNtGW7fdhVn/jEUYmQkWPptqN4cA7FPD822S6HxYVWROkwO34eHww5i1eiPUd8rDrXhRrzc7Qtc+aVFs+1SaHxYZFYldlf2AgAcr4mDVFGHoB3H8Jdnn4T1i1zNtku3EXyYcOAotjySjmX33Y+47+zAsVMQY6Jh3JIBB6tvfQXtpHlPs2jRIucs5Tf4Q2U5r8AYlKMnYX1zH1jmj7D/Lg3xG0vguEe78cGAxqHJyMjAsmXLMGDAAJf3/aGynDcRQ82oemgooqfm4MCnA2HMK9N0e5qFpqKiAo899hiWL1/uUreJMYYlS5bgpZdewkMPPYSUlBR88sknqKqqwrp16wA0FBZbsWIF3n77bdx7770YOHAg1qxZgx9++AHbt2/Xqsk+SzCZUNZNRPmCeMR+cAjy6XOabk+z0EybNg33339/owIY/l5ZzhMcly7D+rd9kL5zT01wTQ6E169fj6ysLGRkZDT6rKXKcrm5uc5l2lNZbv78+Wo0n7RC9Z4mLy8Pzz33HNasWYOAFq5MUmU536V6aDIzM1FYWIjU1FRIkgRJkrB792689957kCTJ2cNQZTnfpXpo7rnnHvzwww/Izs52vtLS0vDYY48hOzsbycnJVFnOx6l+TBMcHOysjHuDyWRCeHi4832qLOfbPHJFmCrL+TaqLOenqLIc8SoUGsKNQkO4UWj8iNi3J6SEeM23Q6G5ToqPA0u/zTlXr8/RiTg5NQxn/5AAQdL2pJhCA6By/FAUfmRCzrggCBoPytaMIiPkrIg7f30MNaMGaropCg2AkCNXEbrYhOQXD0K+etXTzWm32N2lkJmAy7+vg84UpNl2KDQA5DM/QbfnMKDIkGKiUfG7oZp38VrQFV9DWV0Q7u1+CnK/ZO22o9mafZScEAXlySLoQs3tXocYbgHuGICyx9NRM2aIiq1rmSM+HNEB5SiqNUG6VqPZdig0tzp8AsKqSCjlFe37fUHA2dm9gDdKEP6/ucgbKQA699z6uHx3F4RI1Tj2TS/Ip7Qbved7fbDGmMOB4A0H0O57K4wh8dtanNMnIOQnoM8XF+C4dYJojdSZGa45AhG/vRKyhneHKDQaEHdlodt/RIApcLjx1p6hXMB3J3qj19GT0DKmnT40uqAgVA/vB+NXjYemdoibepebxX/4AwRJglxZqel2Ov0xDetjw8URIgSj0dNN4SYM7AdBb3D+rJSXQ75ltKMWOn1oqmNNiNulgNXWeropXHTBwTg1xQShj3an1s1u2+1b9CJidxuK+ksI2nbU003hVvWrPujV8xIK7tJu6tfmdOrQVPWMgFQDKDXaXdPQSmGaBEmnoHSQw2UX5Q6d+kA4aP9ZBB3UaXqmoRVFajgr03epg6CX3PKQ3A2dOjTuOGjUim3TNRw3J4LpGaAobt12pw6NuwmSBOZQp04Ky/wRPY9I0JlDILt599qpj2ncSR42CLkvDVF1vA5zOCAXl6i2vrai0LhJRZwBcu9K6EJ+Do3utj6aT6qoBQoNh44MlwjJqUb45kCXukxXfhkG5faeajTNreiYpi0EAdVjB6O0h4Swsw4Efp4BcN5TEvYdQcg+OG+EiuEWRH9fjksjghF/2OhTFxepp2kDKc6KgjQR1dEM+UPEhvEyHXRpUm84gg0QawF5SF8VWuk+FJo2kAuuovvSHMTuVxBYIECxl7f+S62I+yofxsyzcAQAOeOMbr9A1xG0e2oDVl8Hx5V8hBwU0eUnMxQVLqTJZ34CAHRdcwGOOAuYQ7vZONVGoeHguHgJuHhJ3XXmXQTyfGvWUto9EW4UGsKNQnMTwXj9gLSVuf/cTdAbICV3hRgZ6emmAKBjGhc1IwagcJAegUUMwRcdCPj2iFvvHt9KkCQoQ1Nw/jeBQPdKhG+KQfB6zz/MR6G5SV2IiNpwBQ6TgIBSEZ68wC/FWXHh0a6o6FmPkOMCwvYZEbTvlFcM46DQ3CT0aDEq4iNh3WUHy/yx/Y+xdJAYEoLL/9MVYacdSFx3CY5LlwHAKwIDUGhcyCfOwHomR7XhC+0mirB+dQmOnFx4uCVNotDcwuOBwfXBYWVlnm5Gs+jsyVt58fyZFBrCjUJDuGkSmkuXLuH3v/89wsPDERQUhNtvvx2ZmZnOz6mynG9TPTSlpaW46667oNfr8fXXX+P48eN4++23ERoa6lyGKsv5NtVnLJ83bx7++9//Ys+ePU1+zhiD1WrFzJkzMXfuXAANvUp0dDQWL16MKVOmwG63IzIyEqtXr8bEiRMBAJcvX0ZCQgK2bNmCUaNGtdoOmrHch2Ys37x5M9LS0vC73/0OUVFRGDhwIJYvX+78nCrL+T7VQ/PTTz/hww8/RI8ePfDNN99g6tSpmDFjBv75z38CaLmy3I3P2ltZzmw2O18JCQlqfzVyneqhURQFgwYNwsKFCzFw4EBMmTIFTz/9ND788EOX5by1spwYEuJTQy89QfXQxMbGom9f14HSffr0wYULFwA0VI0DvLiynEHfMEmjWsMjBMHrhlp0lOqhueuuu3Dq1CmX906fPo2kpCQAgM1m8+rKcqyqWtVZrHRGI6SkBJ98KK45qt97ev7553HnnXdi4cKFmDBhAg4ePIhly5Zh2bJlABp2S95cWU6pqgKqqtRbX00NlNyGXaUUZ0VtjxjUB0swnSuDfPy0attxJ9VDM3jwYGzatAkvvvgiFixYAJvNhiVLluCxxx5zLtPpKsvduKphNECsqocxtxhKgecHU7UXVZbzUz51nYb4PwqNBsSwMN8tAdQGFBqViSEhEMLMYDXaPNCvCw72+HUkCo3KBFMQlIKr7XqKQYqJhtQ1seX1Gw0dKvahBgqNyuSrRVDaOWN4be841HRr+dkmuaQMQrDJo9d9KDQqa+8YY8FoRHFKAIy5rUyHpsiQL12B4MFjJgqNl9AFBsB0RYaS2/oEA6y21qMV8OhpBC8hl9lh+vf3HnvWigf1NGrzs5uTTaHQqEwMDfXJ+pc8KDQqY7W10HUxeboZmvLvfxIeoFRVATU+eFOVA/U0WvBAVTl3otAQbhQaHoIAMToKYneb28omeyMKDQfJltRwZlR2DVJSvKeb4zF0IMzBkZP78yg8D1Q/8RbU0/C4eZCjfw54bBMKDeFGoSHcKDSEG4XGQzw9ZLMjKDQeoAsOhhge5rPXeig0bnJzzyIY9FDKK3z2dgNdp3ETXY+ugEOGfPqcRyrcqol6Go0JkgQpuSuU0z+hPioYYqgZOlPDwHBdQAAEo9HTTeRGodEYUxjq4sIAUYR44BiYrEDplwwhPrZNc/J4I9o9aU2RofvvUbDrxy+svBw4+IOzzoEvXlemnsYdfPSAtzkUGsKNQtNOuoCATvHkQVMoNO0kmIIAwXv+fGJ0FKofHAIpQftxPt7zrX2MXGrX/FhFsiVBDLe0uIzOZII8bBByn+wOfYUMOb9Q0zYBFJr20yowN+3yHLkXIRgMEHt2a/JZKsFoRNnY/igYHICkfxdA+i7TLTU36ZTby0iJ8VCuFjc8CqPIcFzJh1hngRgZAccV12l0WW0tQtZ/jxAAshsHhXW+nkYQvPoqrFJUAsFwyxyBOrH5SZIYc/sowk7X04ihoWB1dWC12sxU1VFNzW3DKivB6j1fJvGGztfT6AQo1TWebgUXpaqqbccqbupFO11PI5eU+tWgcLFfL9RGd4HAGMrjjYAAhK3LAOrrNdum6j2Nw+HAn//8Z9hsNgQGBiI5ORkLFiyAoijOZTxaWc6PAgMANbFdUNLHCOPZQoSeqoChXAFTtP2Oqodm8eLF+Oijj/DBBx/gxIkTePPNN/G3v/0N77//vnMZqiynHuO+E4jdcAqOvItAxjGYvjys+fUj1WcsHzNmDKKjo7FixQrne7/97W8RFBSE1atXU2U5N/GpGcvvvvtufPfddzh9uqFYxJEjR7B371785je/AUCV5fyB6gfCc+fOhd1uR+/evSGKImRZxhtvvIFHHnkEQMuV5XJzc53LtKey3Pz589X+OqQJqvc0GzZswJo1a7Bu3TpkZWXhk08+wVtvvYVPPvnEZTlvrSxHWqd6TzNnzhzMmzcPDz/8MACgf//+yM3NxaJFizB58mSXynKxsbHO32uustzNvU1hYWGzRcKMRiOMXnylt60ESWr3XMTuonpPU1VVBZ3OdbWiKDpPub29spzHCALE7raG+W9UPnBVm+o9zQMPPIA33ngDiYmJ6NevHw4fPox33nkHTz75JADvryznKbouXSDU1EEps0MXEgx48YG86qF5//338fLLL+OZZ55BYWEhrFYrpkyZgldeecW5TKerLNcGrLoaiLBAqa6BLsICMTLSo7OSt4Qqy6lFEDp8tVlKiIdSUgrIMoSkeAhVNQ0X7drBp67TdEo6EVJM06WfechX8qELNUOpqYF86my7A6M1Co0amAJmCuz4ahwOOC5dVqFB2qLQqIExCBVVDQW+OsETChQalTjyC4DaOoiWsNYX9nEUGpWIYWFAYOd4FopCoxK5rAyoqwfzsVGB7dHpRu6pQdAboDMHQ7GX/zwMkzE4LrZeFc4fUE/TXqII6Px/V9QU6mnagdXXQb5a7HezQbQV9TTt5aHACEYjxH69PPrsFoXGx4jWGNTEdoHOg3fCKTQ+RjEFwlBaA6W01GNtoGOa5uhEiMmJgChCqKjivrwv6A3QhZobiq9zzuYp6A1gstzkLpCdPNvwiIoHj6eop2kOaxg0dq1/OKpSrFwX7XRBQdD1tDWEJSbSOcm07qahH83+rskEnS0Bgr7pf8/M4fD4ATj1NM1hDPLZHITodFDMQeAZQSIY9GA5eQ3/cxmD2CsZKLGDRVqAYydb/F2lshI4fa6jrdcUhaYVcjv+B8pldud/K2fOQ9ejKxzJsRCPnFGzaR5DodEYq6+DfOIMBMag6EToAgKg1Nxyq0EnenyXw4NC4w7Xd22CToBgDgGuh0YXHIyrE1IAHRC+4qDPBIcOhN2IORyQC36eE08wGnCtO1DSX4FoCfVcwzhRT+NBclExeiy7jLp4S0NVlptIXRPBqmtcQuYtKDQe5sjJhS4nt9F09+W3x8B0vgLwwtDQ7qkFQmq/Vqdk1UrwkQLoir3z2ScKTSsuTu4N3e193b5dR04uPY3gi8Ticoi1QIUtuFMM42wrOqZphi4gAKyyGjH//KFhNtDWrgjrREix0do8guJl13EoNM0Q4mNx5v9iAAEIKBYQ/+EPUG6a3u1WYu9ukIMMgJqh0YkAU6D8YgB0/8n2mvkCaffUDPlsDrptuIbg84ChrGFeHEGSmrzpKPZIRkXPUAgnctRrgE6EMLA35GEDIdQpXhMYgHqaFrHDPyLycMN/y7h+lzopzvWmoyCgJikMggx1J7RWZLDMHyF54Xw1FBoOSnl547vUjMGw5xh0RiNkDf7neltgAAqNKlhtLWQvnTZfC3RMQ7hRaLyNToSU3NWrrwtRaLyNIjdMJBAa6umWNIuOabyQ4/IVr6qPeSsKjTdiDGDecwX4Vt4bZ+K1KDSEG4XGSwlGY0PBeC9ExzReSte9Kyq6m2HKrYCSfdzTzXHB3dP85z//wQMPPACr1QpBEPDZZ5+5fK5W1bjS0lJMmjQJZrMZZrMZkyZNQllZGfcX9FXy8dPoctaOqoQuEPQGTzfHBXdoKisrcdttt+GDDz5o8nO1qsY9+uijyM7OxtatW7F161ZkZ2dj0qRJ7fiKPooxsAuXYSzyvtsTHZqxXBAEbNq0CePGjQMA1arGnThxAn379sWBAwcwdOhQAMCBAweQnp6OkydPolevXq22jSrL+ciM5WpVjdu/fz/MZrMzMABwxx13wGw2U2U5L6BqaFqqGnfjs7ZUjcvPz0dUVFSj9UdFRbVYWe7G8Y/ZbEZCQkKHvw9pmian3GpUjWtqeU9UlhMkCVJyV0jxcV59E9GdVA3NzVXjbtZc1biWlikoKGi0/qtXrzbqxW4wGo0ICQlxeamBORyQ8y6D1dZBjIhQZZ2+TtXQqFU1Lj09HXa7HQcPHnQu8/3338Nut3ukshyrrwPq68DiIt2+bW/EfXGvoqICZ8+edf6ck5OD7OxsWCwWJCYmqlI1rk+fPrjvvvvw9NNP4+OPPwYA/OEPf8CYMWPadOakidgoCNV1ntm2l+EOzaFDhzB8+HDnz7NmzQIATJ48GatWrVKtatzatWsxY8YM51nW2LFjm7025A7yqZ+cU6p1dlRZzk/5zHUa0jlQaFqjE6ELCnLO0NnedUhx1o6tw4tQaFrDFCg1tR16llq0hMIRFw4pyj9O2WloRGtUGHopFxUDJWVQAr1zfAwv6mncRZEb5gj2AxQawo1CQ7hRaAg3Co2vEoSGOWz0Bohurv1EZ08+StelC1jPRDBRB1brAI64b9AZ9TSeJAjtHjSulJdDd+4iFIMIR7ARguS+f/8UGg8SoyJhHz+oTXWgmiKX2aEvLIfh7BW3Tn5EofEgpcwOQQFY98R2r0M+8xMc+Y0HrGmJjmk8iNXWIuTfh35+Y0h/iBW1kE+ea/ttCw8MUqCexsOYw+HctUgFZbg0MgLyr27zcKtaRqHxIo7cPMRtKUBpD6PHajK0Be2evIx8+hyiS8qg2L33uS0KjReSi4o93YQW0e6JcKPQEG4UGsKNQkO4UWgINwoN4UahIdwoNIQbhYZwo9AQbhQawo1CQ7hRaAg3Cg3hRqEh3Cg0hBuFhnCj0BBuFBrCjUJDuFFoCDdVK8vV19dj7ty56N+/P0wmE6xWKx5//HFcvnzZZR1UWc63qVpZrqqqCllZWXj55ZeRlZWFjRs34vTp0xg7dqzLclRZzrepWlmuKRkZGRgyZAhyc3ORmJhIleXcxKdnLLfb7RAEAaGhoQCospw/0DQ0NTU1mDdvHh599FFn2qmynO/TLDT19fV4+OGHoSgKli5d2ury3lpZjjSmSWjq6+sxYcIE5OTkYNu2bS77VF+rLEcaUz00NwJz5swZbN++HeHh4S6f+2JlOeJK1cpyVqsV48ePR1ZWFr788kvIsuw8BrFYLDAYDL5bWY44cZ9y79q1y6Wy3A2TJ0/Ga6+9BpvN1uTv7dy5E8OGDQPQcIA8Z84crFu3zllZbunSpS4HryUlJZgxYwY2b94M4OfKcjfOwlpDp9zanXJTZTk/5dPXaYj/odAQbhQawo1CQ7hRaAg3Cg3hRqEh3Cg0hBuFhnCj0BBuFBrCjUJDuFFoCDcKDeFGoSHcKDSEG4WGcKPQEG4UGsKNQkO4UWgINwoN4UahIdwoNIQbhYZwo9AQbhQawo1CQ7hRaAg3Cg3hRqEh3Cg0hBuFhnCj0BBuFBrCjUJDuFFoCDcKDeFGoSHcKDSEm6rlCG81ZcoUCIKAJUuWuLxP5Qh9m6rlCG/22Wef4fvvv4fVam30GZUj9G3cBTVGjx6N0aNHt7jMpUuXMH36dHzzzTe4//77XT6z2+1YsWIFVq9e7SygsWbNGiQkJGD79u3OcoRbt251KUe4fPlypKen49SpU00W1aitrUVtba3zZ6ospx3Vj2kURcGkSZMwZ84c9OvXr9HnWpUjpMpy7qN6aBYvXgxJkjBjxowmP9eqHCFVlnMf7t1TSzIzM/H3v/8dWVlZzZYNbE5HyxEajUYYjUa+BpN2UbWn2bNnDwoLC5GYmAhJkiBJEnJzczF79mx07doVgHblCIn7qBqaSZMm4ejRo8jOzna+rFYr5syZg2+++QYAlSP0B6qWI0xMTGxUs1Kv1yMmJsZ5xkPlCH0fd2gOHTrkUo5w1qxZABrKEa5atapN63j33XchSRImTJjgLEe4atUqiKLoXGbt2rWYMWOG8yzrRjlC4nlUjtBPUTlC4lUoNIQbhYZwo9AQbhQawo1CQ7hRaAg3Cg3hRqEh3Cg0hJuq42m8yY27Iw7UA355o6RlDtQD+PnvoCa/DU1xcTEAYC+2eLglnlVeXg6z2azqOv02NBaLBQBw4cIF1f9o3u7atWtISEjA8ePHm3wapKP8NjQ6XcPhmtlsVv0ur6+Ii4tz/h3URAfChBuFhnDz29AYjUa8+uqrnfIJBa2/u9+O3CPa8duehmiHQkO4UWgINwoN4UahIdz8NjRLly6FzWZDQEAAUlNTsWfPHk83qUMWLVqEwYMHIzg4GFFRURg3bhxOnTrlsswTTzwBQRBcXnfccYfLMm2ZhaxVzA+tX7+e6fV6tnz5cnb8+HH23HPPMZPJxHJzcz3dtHYbNWoUW7lyJTt27BjLzs5m999/P0tMTGQVFRXOZSZPnszuu+8+duXKFeeruLjYZT1Tp05lcXFxbNu2bSwrK4sNHz6c3XbbbczhcLS5LX4ZmiFDhrCpU6e6vNe7d282b948D7VIfYWFhQwA2717t/O9yZMnswcffLDZ3ykrK2N6vZ6tX7/e+d6lS5eYTqdjW7dubfO2/W73VFdXh8zMTJeZtgBg5MiRzc6i5YvsdjuAn+/m37Br1y5ERUWhZ8+eePrpp1FYWOj8rC2zkLWF34WmqKgIsiw3msfm5pm2fB1jDLNmzcLdd9+NlJQU5/ujR4/G2rVrsWPHDrz99tvIyMjAiBEjnHMRtmUWsrbw26ERt86YxVqYRcvXTJ8+HUePHsXevXtd3p84caLzv1NSUpCWloakpCR89dVXeOihh5pdH+/fxu96moiICIii2Ohfzs0zbfmyZ599Fps3b8bOnTsRHx/f4rKxsbFISkrCmTNnALRtFrK28LvQGAwGpKamusy0BQDbtm3z6Vm0GGOYPn06Nm7ciB07dsBms7X6O8XFxcjLy0NsbCyAts1C1tbG+J0bp9wrVqxgx48fZzNnzmQmk4mdP3/e001rtz/+8Y/MbDazXbt2uZxSV1VVMcYYKy8vZ7Nnz2b79u1jOTk5bOfOnSw9PZ3FxcWxa9euOdczdepUFh8fz7Zv386ysrLYiBEj6JT7hn/84x8sKSmJGQwGNmjQIJdTU1+EhmcqGr1WrlzJGGOsqqqKjRw5kkVGRjK9Xs8SExPZ5MmT2YULF1zWU11dzaZPn84sFgsLDAxkY8aMabRMa2g8DeHmd8c0RHsUGsKNQkO4UWgINwoN4UahIdwoNIQbhYZwo9AQbhQawo1CQ7j9P5WMR5EVb3T/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Botswana_gt.mat'\n",
    "data_files = 'Botswana.mat'\n",
    "label_files = 'Botswana_gt'\n",
    "hypercube_files = 'Botswana'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:03.194180Z",
     "iopub.status.busy": "2025-05-08T18:54:03.194180Z",
     "iopub.status.idle": "2025-05-08T18:54:03.200346Z",
     "shell.execute_reply": "2025-05-08T18:54:03.200346Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:03.202887Z",
     "iopub.status.busy": "2025-05-08T18:54:03.201881Z",
     "iopub.status.idle": "2025-05-08T18:54:04.016963Z",
     "shell.execute_reply": "2025-05-08T18:54:04.016963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 3248\n",
      "Extracted windows shape: (3248, 5, 5, 145)\n",
      "Corresponding labels shape: (3248,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.020007Z",
     "iopub.status.busy": "2025-05-08T18:54:04.019007Z",
     "iopub.status.idle": "2025-05-08T18:54:04.027373Z",
     "shell.execute_reply": "2025-05-08T18:54:04.027373Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.030378Z",
     "iopub.status.busy": "2025-05-08T18:54:04.030378Z",
     "iopub.status.idle": "2025-05-08T18:54:04.196329Z",
     "shell.execute_reply": "2025-05-08T18:54:04.196329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 270 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 101 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 251 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 215 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 269 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 269 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 259 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 203 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 314 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 248 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 20 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 305 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 20 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 181 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 20 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 268 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 20 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 95 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 20 training samples and 5 validation samples for class '14'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t280 samples\n",
      "\tshape (280, 5, 5, 145) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t70 samples\n",
      "\tshape (70, 5, 5, 145) --\n",
      "\n",
      " -- Test set created with: \n",
      "\t2898 samples\n",
      "\tshape (2898, 5, 5, 145) --\n",
      "\n",
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(280, 5, 5, 145)\n",
      "(70, 5, 5, 145)\n",
      "(2898, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.199334Z",
     "iopub.status.busy": "2025-05-08T18:54:04.198335Z",
     "iopub.status.idle": "2025-05-08T18:54:04.202353Z",
     "shell.execute_reply": "2025-05-08T18:54:04.202353Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.205362Z",
     "iopub.status.busy": "2025-05-08T18:54:04.204361Z",
     "iopub.status.idle": "2025-05-08T18:54:04.268768Z",
     "shell.execute_reply": "2025-05-08T18:54:04.268768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 280\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.271774Z",
     "iopub.status.busy": "2025-05-08T18:54:04.270772Z",
     "iopub.status.idle": "2025-05-08T18:54:04.277424Z",
     "shell.execute_reply": "2025-05-08T18:54:04.276921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.279427Z",
     "iopub.status.busy": "2025-05-08T18:54:04.279427Z",
     "iopub.status.idle": "2025-05-08T18:54:04.295957Z",
     "shell.execute_reply": "2025-05-08T18:54:04.295455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2598, 5, 5, 145)\n",
      "Validation data shape: (650, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.297961Z",
     "iopub.status.busy": "2025-05-08T18:54:04.297961Z",
     "iopub.status.idle": "2025-05-08T18:54:04.302464Z",
     "shell.execute_reply": "2025-05-08T18:54:04.301961Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.305474Z",
     "iopub.status.busy": "2025-05-08T18:54:04.304474Z",
     "iopub.status.idle": "2025-05-08T18:54:04.313041Z",
     "shell.execute_reply": "2025-05-08T18:54:04.313041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.315550Z",
     "iopub.status.busy": "2025-05-08T18:54:04.315550Z",
     "iopub.status.idle": "2025-05-08T18:54:04.318720Z",
     "shell.execute_reply": "2025-05-08T18:54:04.318720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.321725Z",
     "iopub.status.busy": "2025-05-08T18:54:04.320726Z",
     "iopub.status.idle": "2025-05-08T18:54:04.327146Z",
     "shell.execute_reply": "2025-05-08T18:54:04.327146Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:04.330150Z",
     "iopub.status.busy": "2025-05-08T18:54:04.330150Z",
     "iopub.status.idle": "2025-05-08T18:54:26.186623Z",
     "shell.execute_reply": "2025-05-08T18:54:26.186623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/41], Loss: 0.2180, PSNR: -10.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.2092, PSNR: -9.0340\n",
      "\t[Val]   Batch [1/11] Loss: 0.2008, PSNR: -6.0651\n",
      "\t[Val]   Batch [10/11] Loss: 0.2010, PSNR: -8.3038\n",
      "Epoch [1/50] Validation Loss: 0.2008, PSNR: -7.9959\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/41], Loss: 0.1936, PSNR: -7.4908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.1872, PSNR: -8.2245\n",
      "\t[Val]   Batch [1/11] Loss: 0.1750, PSNR: -5.4670\n",
      "\t[Val]   Batch [10/11] Loss: 0.1752, PSNR: -7.7084\n",
      "Epoch [2/50] Validation Loss: 0.1750, PSNR: -7.3992\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/41], Loss: 0.1730, PSNR: -5.4180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.1663, PSNR: -7.7073\n",
      "\t[Val]   Batch [1/11] Loss: 0.1504, PSNR: -4.8100\n",
      "\t[Val]   Batch [10/11] Loss: 0.1504, PSNR: -7.0467\n",
      "Epoch [3/50] Validation Loss: 0.1504, PSNR: -6.7404\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/41], Loss: 0.1535, PSNR: -8.3206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.1462, PSNR: -7.0238\n",
      "\t[Val]   Batch [1/11] Loss: 0.1314, PSNR: -4.2238\n",
      "\t[Val]   Batch [10/11] Loss: 0.1315, PSNR: -6.4614\n",
      "Epoch [4/50] Validation Loss: 0.1313, PSNR: -6.1523\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/41], Loss: 0.1338, PSNR: -6.2355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.1273, PSNR: -6.5344\n",
      "\t[Val]   Batch [1/11] Loss: 0.1123, PSNR: -3.5414\n",
      "\t[Val]   Batch [10/11] Loss: 0.1124, PSNR: -5.7798\n",
      "Epoch [5/50] Validation Loss: 0.1123, PSNR: -5.4712\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/41], Loss: 0.1160, PSNR: -6.2699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.1100, PSNR: -5.7589\n",
      "\t[Val]   Batch [1/11] Loss: 0.0974, PSNR: -2.9233\n",
      "\t[Val]   Batch [10/11] Loss: 0.0976, PSNR: -5.1659\n",
      "Epoch [6/50] Validation Loss: 0.0975, PSNR: -4.8561\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/41], Loss: 0.1000, PSNR: -3.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0947, PSNR: -5.3138\n",
      "\t[Val]   Batch [1/11] Loss: 0.0839, PSNR: -2.2764\n",
      "\t[Val]   Batch [10/11] Loss: 0.0841, PSNR: -4.5185\n",
      "Epoch [7/50] Validation Loss: 0.0840, PSNR: -4.2087\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/41], Loss: 0.0859, PSNR: -5.2270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0815, PSNR: -4.8328\n",
      "\t[Val]   Batch [1/11] Loss: 0.0724, PSNR: -1.6343\n",
      "\t[Val]   Batch [10/11] Loss: 0.0725, PSNR: -3.8767\n",
      "Epoch [8/50] Validation Loss: 0.0724, PSNR: -3.5660\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/41], Loss: 0.0743, PSNR: -5.9731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0702, PSNR: -3.9115\n",
      "\t[Val]   Batch [1/11] Loss: 0.0638, PSNR: -1.0877\n",
      "\t[Val]   Batch [10/11] Loss: 0.0639, PSNR: -3.3292\n",
      "Epoch [9/50] Validation Loss: 0.0638, PSNR: -3.0188\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/41], Loss: 0.0656, PSNR: -4.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0608, PSNR: -3.1434\n",
      "\t[Val]   Batch [1/11] Loss: 0.0545, PSNR: -0.4039\n",
      "\t[Val]   Batch [10/11] Loss: 0.0546, PSNR: -2.6441\n",
      "Epoch [10/50] Validation Loss: 0.0545, PSNR: -2.3342\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/41], Loss: 0.0552, PSNR: -4.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0529, PSNR: -2.6920\n",
      "\t[Val]   Batch [1/11] Loss: 0.0493, PSNR: 0.0310\n",
      "\t[Val]   Batch [10/11] Loss: 0.0494, PSNR: -2.2071\n",
      "Epoch [11/50] Validation Loss: 0.0493, PSNR: -1.8983\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/41], Loss: 0.0483, PSNR: -4.2038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0464, PSNR: -2.2213\n",
      "\t[Val]   Batch [1/11] Loss: 0.0430, PSNR: 0.6235\n",
      "\t[Val]   Batch [10/11] Loss: 0.0431, PSNR: -1.6138\n",
      "Epoch [12/50] Validation Loss: 0.0430, PSNR: -1.3053\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/41], Loss: 0.0423, PSNR: -0.8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0410, PSNR: -1.5187\n",
      "\t[Val]   Batch [1/11] Loss: 0.0391, PSNR: 1.0431\n",
      "\t[Val]   Batch [10/11] Loss: 0.0391, PSNR: -1.1938\n",
      "Epoch [13/50] Validation Loss: 0.0390, PSNR: -0.8836\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/41], Loss: 0.0377, PSNR: 1.2036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0365, PSNR: -1.1037\n",
      "\t[Val]   Batch [1/11] Loss: 0.0347, PSNR: 1.5592\n",
      "\t[Val]   Batch [10/11] Loss: 0.0347, PSNR: -0.6783\n",
      "Epoch [14/50] Validation Loss: 0.0347, PSNR: -0.3671\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/41], Loss: 0.0336, PSNR: -2.5620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0326, PSNR: -0.6378\n",
      "\t[Val]   Batch [1/11] Loss: 0.0310, PSNR: 2.0539\n",
      "\t[Val]   Batch [10/11] Loss: 0.0310, PSNR: -0.1837\n",
      "Epoch [15/50] Validation Loss: 0.0309, PSNR: 0.1274\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/41], Loss: 0.0299, PSNR: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0294, PSNR: -0.3541\n",
      "\t[Val]   Batch [1/11] Loss: 0.0284, PSNR: 2.4333\n",
      "\t[Val]   Batch [10/11] Loss: 0.0284, PSNR: 0.1960\n",
      "Epoch [16/50] Validation Loss: 0.0283, PSNR: 0.5064\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/41], Loss: 0.0283, PSNR: -0.4075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0266, PSNR: 0.2260\n",
      "\t[Val]   Batch [1/11] Loss: 0.0258, PSNR: 2.8467\n",
      "\t[Val]   Batch [10/11] Loss: 0.0258, PSNR: 0.6101\n",
      "Epoch [17/50] Validation Loss: 0.0258, PSNR: 0.9201\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/41], Loss: 0.0252, PSNR: 2.9482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0242, PSNR: 0.6502\n",
      "\t[Val]   Batch [1/11] Loss: 0.0234, PSNR: 3.2679\n",
      "\t[Val]   Batch [10/11] Loss: 0.0234, PSNR: 1.0328\n",
      "Epoch [18/50] Validation Loss: 0.0234, PSNR: 1.3422\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/41], Loss: 0.0229, PSNR: 1.4253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0221, PSNR: 1.1869\n",
      "\t[Val]   Batch [1/11] Loss: 0.0216, PSNR: 3.6126\n",
      "\t[Val]   Batch [10/11] Loss: 0.0216, PSNR: 1.3781\n",
      "Epoch [19/50] Validation Loss: 0.0216, PSNR: 1.6875\n",
      "\n",
      "LOG: Epoch [20/50]\n",
      "\t Training Batch [1/41], Loss: 0.0207, PSNR: 0.8702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Training Loss: 0.0203, PSNR: 1.5084\n",
      "\t[Val]   Batch [1/11] Loss: 0.0198, PSNR: 4.0067\n",
      "\t[Val]   Batch [10/11] Loss: 0.0198, PSNR: 1.7711\n",
      "Epoch [20/50] Validation Loss: 0.0197, PSNR: 2.0819\n",
      "\n",
      "LOG: Epoch [21/50]\n",
      "\t Training Batch [1/41], Loss: 0.0195, PSNR: -0.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Training Loss: 0.0187, PSNR: 1.8186\n",
      "\t[Val]   Batch [1/11] Loss: 0.0183, PSNR: 4.3469\n",
      "\t[Val]   Batch [10/11] Loss: 0.0183, PSNR: 2.1098\n",
      "Epoch [21/50] Validation Loss: 0.0182, PSNR: 2.4224\n",
      "\n",
      "LOG: Epoch [22/50]\n",
      "\t Training Batch [1/41], Loss: 0.0177, PSNR: 2.5443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Training Loss: 0.0172, PSNR: 2.1798\n",
      "\t[Val]   Batch [1/11] Loss: 0.0170, PSNR: 4.6530\n",
      "\t[Val]   Batch [10/11] Loss: 0.0170, PSNR: 2.4172\n",
      "Epoch [22/50] Validation Loss: 0.0170, PSNR: 2.7285\n",
      "\n",
      "LOG: Epoch [23/50]\n",
      "\t Training Batch [1/41], Loss: 0.0165, PSNR: 3.2072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Training Loss: 0.0160, PSNR: 2.4105\n",
      "\t[Val]   Batch [1/11] Loss: 0.0157, PSNR: 4.9937\n",
      "\t[Val]   Batch [10/11] Loss: 0.0157, PSNR: 2.7598\n",
      "Epoch [23/50] Validation Loss: 0.0157, PSNR: 3.0692\n",
      "\n",
      "LOG: Epoch [24/50]\n",
      "\t Training Batch [1/41], Loss: 0.0151, PSNR: 2.7417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Training Loss: 0.0148, PSNR: 2.7889\n",
      "\t[Val]   Batch [1/11] Loss: 0.0147, PSNR: 5.3025\n",
      "\t[Val]   Batch [10/11] Loss: 0.0146, PSNR: 3.0687\n",
      "Epoch [24/50] Validation Loss: 0.0146, PSNR: 3.3781\n",
      "\n",
      "LOG: Epoch [25/50]\n",
      "\t Training Batch [1/41], Loss: 0.0142, PSNR: 5.4481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Training Loss: 0.0138, PSNR: 3.1120\n",
      "\t[Val]   Batch [1/11] Loss: 0.0137, PSNR: 5.6035\n",
      "\t[Val]   Batch [10/11] Loss: 0.0137, PSNR: 3.3686\n",
      "Epoch [25/50] Validation Loss: 0.0137, PSNR: 3.6792\n",
      "\n",
      "LOG: Epoch [26/50]\n",
      "\t Training Batch [1/41], Loss: 0.0136, PSNR: 5.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Training Loss: 0.0129, PSNR: 3.4167\n",
      "\t[Val]   Batch [1/11] Loss: 0.0128, PSNR: 5.8753\n",
      "\t[Val]   Batch [10/11] Loss: 0.0128, PSNR: 3.6405\n",
      "Epoch [26/50] Validation Loss: 0.0128, PSNR: 3.9506\n",
      "\n",
      "LOG: Epoch [27/50]\n",
      "\t Training Batch [1/41], Loss: 0.0119, PSNR: 2.7771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Training Loss: 0.0120, PSNR: 3.6644\n",
      "\t[Val]   Batch [1/11] Loss: 0.0119, PSNR: 6.1924\n",
      "\t[Val]   Batch [10/11] Loss: 0.0119, PSNR: 3.9576\n",
      "Epoch [27/50] Validation Loss: 0.0119, PSNR: 4.2676\n",
      "\n",
      "LOG: Epoch [28/50]\n",
      "\t Training Batch [1/41], Loss: 0.0116, PSNR: 4.3892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Training Loss: 0.0113, PSNR: 3.9232\n",
      "\t[Val]   Batch [1/11] Loss: 0.0112, PSNR: 6.4563\n",
      "\t[Val]   Batch [10/11] Loss: 0.0112, PSNR: 4.2229\n",
      "Epoch [28/50] Validation Loss: 0.0112, PSNR: 4.5316\n",
      "\n",
      "LOG: Epoch [29/50]\n",
      "\t Training Batch [1/41], Loss: 0.0109, PSNR: 4.6538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Training Loss: 0.0106, PSNR: 4.2072\n",
      "\t[Val]   Batch [1/11] Loss: 0.0106, PSNR: 6.7296\n",
      "\t[Val]   Batch [10/11] Loss: 0.0105, PSNR: 4.4965\n",
      "Epoch [29/50] Validation Loss: 0.0105, PSNR: 4.8054\n",
      "\n",
      "LOG: Epoch [30/50]\n",
      "\t Training Batch [1/41], Loss: 0.0104, PSNR: 4.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Training Loss: 0.0100, PSNR: 4.6512\n",
      "\t[Val]   Batch [1/11] Loss: 0.0099, PSNR: 7.0075\n",
      "\t[Val]   Batch [10/11] Loss: 0.0099, PSNR: 4.7744\n",
      "Epoch [30/50] Validation Loss: 0.0099, PSNR: 5.0837\n",
      "\n",
      "LOG: Epoch [31/50]\n",
      "\t Training Batch [1/41], Loss: 0.0099, PSNR: 3.2772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Training Loss: 0.0094, PSNR: 4.7942\n",
      "\t[Val]   Batch [1/11] Loss: 0.0093, PSNR: 7.2598\n",
      "\t[Val]   Batch [10/11] Loss: 0.0093, PSNR: 5.0264\n",
      "Epoch [31/50] Validation Loss: 0.0093, PSNR: 5.3364\n",
      "\n",
      "LOG: Epoch [32/50]\n",
      "\t Training Batch [1/41], Loss: 0.0092, PSNR: 3.8905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Training Loss: 0.0089, PSNR: 5.0094\n",
      "\t[Val]   Batch [1/11] Loss: 0.0089, PSNR: 7.4525\n",
      "\t[Val]   Batch [10/11] Loss: 0.0089, PSNR: 5.2202\n",
      "Epoch [32/50] Validation Loss: 0.0089, PSNR: 5.5297\n",
      "\n",
      "LOG: Epoch [33/50]\n",
      "\t Training Batch [1/41], Loss: 0.0085, PSNR: 3.9353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Training Loss: 0.0084, PSNR: 5.3634\n",
      "\t[Val]   Batch [1/11] Loss: 0.0084, PSNR: 7.7163\n",
      "\t[Val]   Batch [10/11] Loss: 0.0084, PSNR: 5.4844\n",
      "Epoch [33/50] Validation Loss: 0.0084, PSNR: 5.7938\n",
      "\n",
      "LOG: Epoch [34/50]\n",
      "\t Training Batch [1/41], Loss: 0.0081, PSNR: 5.9388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Training Loss: 0.0079, PSNR: 5.4131\n",
      "\t[Val]   Batch [1/11] Loss: 0.0079, PSNR: 7.9725\n",
      "\t[Val]   Batch [10/11] Loss: 0.0079, PSNR: 5.7403\n",
      "Epoch [34/50] Validation Loss: 0.0079, PSNR: 6.0507\n",
      "\n",
      "LOG: Epoch [35/50]\n",
      "\t Training Batch [1/41], Loss: 0.0076, PSNR: 6.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Training Loss: 0.0075, PSNR: 5.4678\n",
      "\t[Val]   Batch [1/11] Loss: 0.0076, PSNR: 8.1757\n",
      "\t[Val]   Batch [10/11] Loss: 0.0076, PSNR: 5.9433\n",
      "Epoch [35/50] Validation Loss: 0.0075, PSNR: 6.2545\n",
      "\n",
      "LOG: Epoch [36/50]\n",
      "\t Training Batch [1/41], Loss: 0.0075, PSNR: 3.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Training Loss: 0.0072, PSNR: 5.8676\n",
      "\t[Val]   Batch [1/11] Loss: 0.0072, PSNR: 8.3934\n",
      "\t[Val]   Batch [10/11] Loss: 0.0072, PSNR: 6.1609\n",
      "Epoch [36/50] Validation Loss: 0.0072, PSNR: 6.4727\n",
      "\n",
      "LOG: Epoch [37/50]\n",
      "\t Training Batch [1/41], Loss: 0.0068, PSNR: 6.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Training Loss: 0.0068, PSNR: 6.0350\n",
      "\t[Val]   Batch [1/11] Loss: 0.0068, PSNR: 8.6143\n",
      "\t[Val]   Batch [10/11] Loss: 0.0068, PSNR: 6.3816\n",
      "Epoch [37/50] Validation Loss: 0.0068, PSNR: 6.6934\n",
      "\n",
      "LOG: Epoch [38/50]\n",
      "\t Training Batch [1/41], Loss: 0.0066, PSNR: 4.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Training Loss: 0.0065, PSNR: 6.4653\n",
      "\t[Val]   Batch [1/11] Loss: 0.0065, PSNR: 8.8133\n",
      "\t[Val]   Batch [10/11] Loss: 0.0065, PSNR: 6.5804\n",
      "Epoch [38/50] Validation Loss: 0.0065, PSNR: 6.8918\n",
      "\n",
      "LOG: Epoch [39/50]\n",
      "\t Training Batch [1/41], Loss: 0.0066, PSNR: 5.3448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Training Loss: 0.0062, PSNR: 6.5628\n",
      "\t[Val]   Batch [1/11] Loss: 0.0062, PSNR: 9.0156\n",
      "\t[Val]   Batch [10/11] Loss: 0.0062, PSNR: 6.7822\n",
      "Epoch [39/50] Validation Loss: 0.0062, PSNR: 7.0936\n",
      "\n",
      "LOG: Epoch [40/50]\n",
      "\t Training Batch [1/41], Loss: 0.0061, PSNR: 4.6487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Training Loss: 0.0059, PSNR: 6.8453\n",
      "\t[Val]   Batch [1/11] Loss: 0.0059, PSNR: 9.2424\n",
      "\t[Val]   Batch [10/11] Loss: 0.0059, PSNR: 7.0084\n",
      "Epoch [40/50] Validation Loss: 0.0059, PSNR: 7.3204\n",
      "\n",
      "LOG: Epoch [41/50]\n",
      "\t Training Batch [1/41], Loss: 0.0057, PSNR: 5.4350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Training Loss: 0.0056, PSNR: 7.0781\n",
      "\t[Val]   Batch [1/11] Loss: 0.0057, PSNR: 9.4382\n",
      "\t[Val]   Batch [10/11] Loss: 0.0057, PSNR: 7.2039\n",
      "Epoch [41/50] Validation Loss: 0.0056, PSNR: 7.5164\n",
      "\n",
      "LOG: Epoch [42/50]\n",
      "\t Training Batch [1/41], Loss: 0.0053, PSNR: 6.7019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Training Loss: 0.0054, PSNR: 7.2830\n",
      "\t[Val]   Batch [1/11] Loss: 0.0055, PSNR: 9.5772\n",
      "\t[Val]   Batch [10/11] Loss: 0.0055, PSNR: 7.3436\n",
      "Epoch [42/50] Validation Loss: 0.0055, PSNR: 7.6564\n",
      "\n",
      "LOG: Epoch [43/50]\n",
      "\t Training Batch [1/41], Loss: 0.0053, PSNR: 5.5340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Training Loss: 0.0052, PSNR: 7.3659\n",
      "\t[Val]   Batch [1/11] Loss: 0.0052, PSNR: 9.7982\n",
      "\t[Val]   Batch [10/11] Loss: 0.0052, PSNR: 7.5649\n",
      "Epoch [43/50] Validation Loss: 0.0052, PSNR: 7.8783\n",
      "\n",
      "LOG: Epoch [44/50]\n",
      "\t Training Batch [1/41], Loss: 0.0051, PSNR: 5.5234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Training Loss: 0.0050, PSNR: 7.5553\n",
      "\t[Val]   Batch [1/11] Loss: 0.0050, PSNR: 9.9663\n",
      "\t[Val]   Batch [10/11] Loss: 0.0050, PSNR: 7.7320\n",
      "Epoch [44/50] Validation Loss: 0.0050, PSNR: 8.0468\n",
      "\n",
      "LOG: Epoch [45/50]\n",
      "\t Training Batch [1/41], Loss: 0.0048, PSNR: 6.7568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Training Loss: 0.0048, PSNR: 7.6793\n",
      "\t[Val]   Batch [1/11] Loss: 0.0048, PSNR: 10.1279\n",
      "\t[Val]   Batch [10/11] Loss: 0.0048, PSNR: 7.8953\n",
      "Epoch [45/50] Validation Loss: 0.0048, PSNR: 8.2084\n",
      "\n",
      "LOG: Epoch [46/50]\n",
      "\t Training Batch [1/41], Loss: 0.0046, PSNR: 5.8113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Training Loss: 0.0046, PSNR: 7.6028\n",
      "\t[Val]   Batch [1/11] Loss: 0.0046, PSNR: 10.3574\n",
      "\t[Val]   Batch [10/11] Loss: 0.0046, PSNR: 8.1260\n",
      "Epoch [46/50] Validation Loss: 0.0046, PSNR: 8.4377\n",
      "\n",
      "LOG: Epoch [47/50]\n",
      "\t Training Batch [1/41], Loss: 0.0044, PSNR: 8.8957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Training Loss: 0.0044, PSNR: 8.0274\n",
      "\t[Val]   Batch [1/11] Loss: 0.0044, PSNR: 10.5165\n",
      "\t[Val]   Batch [10/11] Loss: 0.0044, PSNR: 8.2860\n",
      "Epoch [47/50] Validation Loss: 0.0044, PSNR: 8.5975\n",
      "\n",
      "LOG: Epoch [48/50]\n",
      "\t Training Batch [1/41], Loss: 0.0044, PSNR: 6.6148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Training Loss: 0.0042, PSNR: 8.0616\n",
      "\t[Val]   Batch [1/11] Loss: 0.0043, PSNR: 10.6579\n",
      "\t[Val]   Batch [10/11] Loss: 0.0043, PSNR: 8.4270\n",
      "Epoch [48/50] Validation Loss: 0.0043, PSNR: 8.7392\n",
      "\n",
      "LOG: Epoch [49/50]\n",
      "\t Training Batch [1/41], Loss: 0.0042, PSNR: 6.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Training Loss: 0.0041, PSNR: 8.4364\n",
      "\t[Val]   Batch [1/11] Loss: 0.0041, PSNR: 10.8245\n",
      "\t[Val]   Batch [10/11] Loss: 0.0041, PSNR: 8.5927\n",
      "Epoch [49/50] Validation Loss: 0.0041, PSNR: 8.9058\n",
      "\n",
      "LOG: Epoch [50/50]\n",
      "\t Training Batch [1/41], Loss: 0.0041, PSNR: 10.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Training Loss: 0.0039, PSNR: 8.6468\n",
      "\t[Val]   Batch [1/11] Loss: 0.0039, PSNR: 10.9973\n",
      "\t[Val]   Batch [10/11] Loss: 0.0039, PSNR: 8.7658\n",
      "Epoch [50/50] Validation Loss: 0.0039, PSNR: 9.0789\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbuklEQVR4nOzdd3gU5frG8e/spockEFpCD6GG0CE0aUoVEUSOWBBRrFgOoAcFjgexoSiKFX9WrIACFhRp0gXpASE0IfSEFkgCIW13fn8sWQgphPRyf64rV2Zn3p08G0fl5n3nGcM0TRMRERERERHJE0tRFyAiIiIiIlIaKFyJiIiIiIjkA4UrERERERGRfKBwJSIiIiIikg8UrkRERERERPKBwpWIiIiIiEg+ULgSERERERHJBwpXIiIiIiIi+UDhSkREREREJB8oXImIFFMzZszAMAw2bdpU1KVk6uDBgxiGkaOvgwcPFmmtw4cPp06dOjkam5KSwvTp0+nQoQN+fn54enrSuHFjnnvuOc6cOVOwhebCCy+8UKx/9ytWrMAwDObMmVOkdYiIFAaXoi5ARERKpsDAQNatW5du38iRI4mNjeXbb7/NMLYkSEhI4Oabb2bNmjU8/PDDPP/883h6erJu3TrefPNNvvvuO5YsWULDhg2LutQMFi5ciJ+fX4b9JeV3LyJSGihciYhIrri7u9O+fft0+3x9fUlOTs6w/2oXL17E09OzIMvLldGjR7Ny5UpmzZrFkCFDnPu7d+/O4MGDCQsL4/bbb2fbtm1YrdZCqyshIQEvL69sx7Ru3ZpKlSoVUkUiIpIZLQsUESnh1qxZw0033YSPjw9eXl507NiR3377Ld2YhIQEnnnmGYKCgvDw8MDf3582bdowc+ZM55gDBw5w5513Uq1aNdzd3alatSo33XQT4eHheaqvTp063HLLLcybN4+WLVvi4eHBpEmTAIiOjuaRRx6hRo0auLm5ERQUxKRJk0hNTXW+P2354Ztvvslbb71FUFAQ5cqVo0OHDvz1118Zft6MGTNo2LAh7u7uNG7cmK+++ipHdUZHR/P555/Tu3fvdMEqTYMGDXj22WfZuXMnP/30EwADBw6kdu3a2O32DOPbtWtHq1atnK9N0+TDDz+kRYsWeHp6UqFCBQYPHsyBAwfSva9bt26EhoayatUqOnbsiJeXFw888ECOPkN20n6PU6ZM4ZVXXqFWrVp4eHjQpk0b/vjjjwzjc3JdARw7doyHH36YmjVr4ubmRrVq1Rg8eDAnTpxINy4lJYUJEyZQrVo1fH196dGjB3v27Ek3ZuvWrdxyyy1UqVIFd3d3qlWrRr9+/Th69GieP7+ISGHQzJWISAm2cuVKevbsSbNmzfjss89wd3fnww8/pH///sycOdMZEsaMGcPXX3/Nyy+/TMuWLblw4QI7duxIdw/RzTffjM1mY8qUKdSqVYvTp0+zdu1azp07l+c6t2zZwq5du/jvf/9LUFAQ3t7eREdHExYWhsVi4X//+x/BwcGsW7eOl19+mYMHD/LFF1+kO8cHH3xAo0aNmDZtGgDPP/88N998M5GRkc7lcDNmzOD+++9nwIABTJ06ldjYWF544QWSkpKwWLL/+8Tly5eTmprKwIEDsxwzcOBAxo8fz5IlS7j99tt54IEHGDBgAMuWLaNHjx7Ocbt372bDhg28++67zn2PPPIIM2bM4KmnnuL1118nJiaGF198kY4dO7Jt2zaqVq3qHBsVFcXQoUMZO3Ysr7766jVrB7DZbOlCKYBhGBlm2N5//31q167NtGnTsNvtTJkyhb59+7Jy5Uo6dOgA5Py6OnbsGG3btiUlJYXx48fTrFkzzpw5w6JFizh79my6zzR+/Hg6derEp59+SlxcHM8++yz9+/dn165dWK1WLly4QM+ePQkKCuKDDz6gatWqREdHs3z5cuLj46/5+UVEigVTRESKpS+++MIEzI0bN2Y5pn379maVKlXM+Ph4577U1FQzNDTUrFGjhmm3203TNM3Q0FBz4MCBWZ7n9OnTJmBOmzYtTzV37drVbNKkSbp9tWvXNq1Wq7lnz550+x955BGzXLly5qFDh9Ltf/PNN03A3Llzp2maphkZGWkCZtOmTc3U1FTnuA0bNpiAOXPmTNM0TdNms5nVqlUzW7Vq5fzcpmmaBw8eNF1dXc3atWtnW/trr71mAubChQuzHHPx4kUTMPv27WuapmmmpKSYVatWNe++++5048aOHWu6ubmZp0+fNk3TNNetW2cC5tSpU9ONO3LkiOnp6WmOHTvWua9r164mYP7xxx/Z1ptm4sSJJpDpV3BwsHNc2u+xWrVq5sWLF5374+LiTH9/f7NHjx7OfTm9rh544AHT1dXVjIiIyLK+5cuXm4B58803p9v//fffm4C5bt060zRNc9OmTSZg/vTTTzn63CIixZGWBYqIlFAXLlxg/fr1DB48mHLlyjn3W61W7r33Xo4ePepcdhUWFsbvv//Oc889x4oVK7h48WK6c/n7+xMcHMwbb7zBW2+9xdatWzNd6pZbzZo1o0GDBun2/frrr3Tv3p1q1aqRmprq/Orbty/gmD25Ur9+/dLNwjRr1gyAQ4cOAbBnzx6OHz/O3XffjWEYznG1a9emY8eO+fZZAOf5XVxcGDp0KPPmzSM2NhZwzCB9/fXXDBgwgIoVKzo/q2EYDB06NN1nDQgIoHnz5qxYsSLd+StUqMCNN954XTUtXbqUjRs3pvtKW754pUGDBuHh4eF87ePjQ//+/Vm1ahU2m+26rqvff/+d7t2707hx42vWd+utt6Z7ffU/v3r16lGhQgWeffZZPvroIyIiIq7r84uIFAcKVyIiJdTZs2cxTTPTbnDVqlUDcC77e/fdd3n22Wf56aef6N69O/7+/gwcOJB9+/YBjrDwxx9/0Lt3b6ZMmUKrVq2oXLkyTz31VL4sycqsxhMnTjB//nxcXV3TfTVp0gSA06dPpxufFlTSuLu7AziDYtpnDQgIyPCzMtt3tVq1agEQGRmZ5Zi0YzVr1nTue+CBB0hMTGTWrFkALFq0iKioKO6///50n9U0TapWrZrh8/71118ZPmtuOvw1b96cNm3apPsKDQ3NMC6r309ycjLnz5+/ruvq1KlT1KhRI0f1Xeufn5+fHytXrqRFixaMHz+eJk2aUK1aNSZOnEhKSkqOfoaISFHTPVciIiVUhQoVsFgsREVFZTh2/PhxAGf3OG9vbyZNmsSkSZM4ceKEcxarf//+7N69G3DM8Hz22WcA7N27l++//54XXniB5ORkPvroozzVeuVMUppKlSrRrFkzXnnllUzfk/YH+ZxK+8N7dHR0hmOZ7bta9+7dcXFx4aeffuLRRx/NdEzaTFDPnj2d+0JCQggLC+OLL77gkUce4YsvvqBatWr06tXLOaZSpUoYhsHq1audoeJKV+/L7PeVX7L6/bi5uVGuXDlcXFxyfF1Vrlw5X5tNNG3alFmzZmGaJtu3b2fGjBm8+OKLeHp68txzz+XbzxERKSiauRIRKaG8vb1p164d8+bNS7fMz263880331CjRo0MS/EAqlatyvDhw7nrrrvYs2cPCQkJGcY0aNCA//73vzRt2pQtW7YUSP233HILO3bsIDg4OMOMS5s2ba47XDVs2JDAwEBmzpyJaZrO/YcOHWLt2rXXfH9AQAAPPPAAixYtYvbs2RmO7927l9dff50mTZpkaHpx//33s379etasWcP8+fO577770i1hvOWWWzBNk2PHjmX6WZs2bXpdnzUv5s2bR2JiovN1fHw88+fPp3Pnzlit1uu6rvr27cvy5cszdP3LK8MwaN68OW+//Tbly5cvsGtQRCS/aeZKRKSYW7ZsGQcPHsyw/+abb2by5Mn07NmT7t2788wzz+Dm5saHH37Ijh07mDlzpnMGpF27dtxyyy00a9aMChUqsGvXLr7++ms6dOiAl5cX27dv54knnuBf//oX9evXx83NjWXLlrF9+/YCmzF48cUXWbJkCR07duSpp56iYcOGJCYmcvDgQRYsWMBHH32U4yVnABaLhZdeeokHH3yQ2267jYceeohz587xwgsv5GhZIMBbb73Fnj17GDp0KKtWraJ///64u7vz119/8eabb+Lj48PcuXMzdOC76667GDNmDHfddRdJSUkMHz483fFOnTrx8MMPc//997Np0ya6dOmCt7c3UVFRrFmzhqZNm/LYY4/l+LNmZvPmzZk+RDgkJARfX1/na6vVSs+ePRkzZgx2u53XX3+duLg4Z3t8IMfX1Ysvvsjvv/9Oly5dGD9+PE2bNuXcuXMsXLiQMWPG0KhRoxzX/+uvv/Lhhx8ycOBA6tati2mazJs3j3PnzqWbKRQRKdaKsJmGiIhkI61bYFZfkZGRpmma5urVq80bb7zR9Pb2Nj09Pc327dub8+fPT3eu5557zmzTpo1ZoUIF093d3axbt645evRoZze7EydOmMOHDzcbNWpkent7m+XKlTObNWtmvv322+k69F1LVt0C+/Xrl+n4U6dOmU899ZQZFBRkurq6mv7+/mbr1q3NCRMmmOfPnzdN83KXuzfeeCPD+wFz4sSJ6fZ9+umnZv369U03NzezQYMG5ueff27ed9991+wWmCY5Odn84IMPzHbt2pnlypUz3d3dzYYNG5pjx451/r4yc/fdd5uA2alTpyzHfP7552a7du2c/6yCg4PNYcOGmZs2bXKOyex3mJ3sugUC5pIlS0zTvPx7fP31181JkyaZNWrUMN3c3MyWLVuaixYtynDenFxXpunoePjAAw+YAQEBpqurq1mtWjXzjjvuME+cOGGa5uVugT/88EO696XV88UXX5imaZq7d+8277rrLjM4ONj09PQ0/fz8zLCwMHPGjBk5/l2IiBQ1wzSvWDshIiIipdLBgwcJCgrijTfe4JlnninqckRESiXdcyUiIiIiIpIPFK5ERERERETygZYFioiIiIiI5APNXImIiIiIiOQDhSsREREREZF8oHAlIiIiIiKSD/QQ4UzY7XaOHz+Oj4+P80GJIiIiIiJS9pimSXx8PNWqVcNiyX5uSuEqE8ePH6dmzZpFXYaIiIiIiBQTR44coUaNGtmOUbjKhI+PD+D4Bfr6+ubLOVNSUli8eDG9evXC1dU1X84pZYeuH8kLXT+SW7p2JC90/UheFKfrJy4ujpo1azozQnYUrjKRthTQ19c3X8OVl5cXvr6+RX6BSMmj60fyQteP5JauHckLXT+SF8Xx+snJ7UJqaCEiIiIiIpIPFK5ERERERETygcKViIiIiIhIPtA9VyIiIiJSIpimSWpqKjabrahLkQKWkpKCi4sLiYmJhfLP29XVFavVmufzKFyJiIiISLGXnJxMVFQUCQkJRV2KFALTNAkICODIkSOF8txZwzCoUaMG5cqVy9N5FK5EREREpFiz2+1ERkZitVqpVq0abm5uhfIHbik6drud8+fPU65cuWs+uDevTNPk1KlTHD16lPr16+dpBkvhSkRERESKteTkZOx2OzVr1sTLy6uoy5FCYLfbSU5OxsPDo8DDFUDlypU5ePAgKSkpeQpXamghIiIiIiVCYfwhW8qm/JoJ1RUqIiIiIiKSDxSuRERERERE8oHClYiIiIiUCTa7ybr9Z/g5/Bjr9p/BZjeLuqTr1q1bN0aNGpXj8QcPHsQwDMLDwwusJrlMDS1EREREpNRbuCOKSfMjiIpNdO4L9PNgYv8Q+oQG5vvPu9Y9PPfddx8zZsy47vPOmzcPV1fXHI+vWbMmUVFRVKpU6bp/1vU4ePAgQUFBbN26lRYtWhTozyrOFK5EREREpFRbuCOKx77ZwtXzVNGxiTz2zRamD22V7wErKirKuT179mz+97//sWfPHuc+T0/PdONTUlJyFJr8/f2vqw6r1UpAQMB1vUdyT8sCi7nSMH0tIiIikp9M0yQhOTVHX/GJKUz8ZWeGYAU4973wSwTxiSk5Op9p5uzPYgEBAc4vPz8/DMNwvk5MTKR8+fJ8//33dOvWDQ8PD7755hvOnDnDXXfdRY0aNfDy8qJp06bMnDkz3XmvXhZYp04dXn31VR544AF8fHyoVasWH3/8sfP41csCV6xYgWEY/PHHH7Rp0wYvLy86duyYLvgBvPzyy1SpUgUfHx8efPBBnnvuuTzNSCUlJfHUU09RpUoVPDw8uOGGG9i4caPz+NmzZ7nnnnuoXLkynp6eNGzYkG+//RZwtOJ/4oknCAwMxMPDgzp16jB58uRc11KQNHNVjBX29LWIiIhISXAxxUbI/xbly7lMIDoukaYvLM7R+IgXe+Pllj9/hH722WeZOnUqX3zxBe7u7iQmJtK6dWueffZZfH19+e2337j33nupW7cu7dq1y/I8U6dO5aWXXmL8+PHMmTOHxx57jC5dutCoUaMs3zNhwgSmTp1K5cqVefTRR3nggQf4888/Afj222955ZVX+PDDD+nUqROzZs1i6tSpBAUF5fqzjh07lrlz5/Lll19Su3ZtpkyZQu/evfnnn3/w9/fn+eefJyIigt9//51KlSqxd+9ezpw5A8C7777LL7/8wvfff0+tWrU4cuQIR44cyXUtBUnhqpgqiulrERERESk8o0aNYtCgQen2PfPMM87tJ598koULF/LDDz9kG65uvvlmRo4cCTgC29tvv82KFSuyDVevvPIKXbt2BeC5556jX79+JCYm4uHhwXvvvceIESO4//77Afjf//7H4sWLOX/+fK4+54ULF5g+fTozZsygb9++AHzyyScsWbKEzz77jP/85z8cPnyYli1b0qZNGwBq1apFXFwcAIcPH6Z+/frccMMNGIZB7dq1c1VHYVC4KoZsdpNJ8yOynL42gEnzI+gZEoDVkj8PPBMREREpKTxdrUS82DtHYzdExjD8i43XHDfj/raEBV37fiZPV2uOfm5OpAWJNDabjddee43Zs2dz7NgxkpKSSEpKwtvbO9vzNGvWzLmdtvzw5MmTOX5PYKDjL+xPnjxJrVq12LNnjzOspQkLC2PZsmU5+lxX279/PykpKXTq1Mm5z9XVlbCwMHbt2gXAY489xu23386WLVvo1asXt956K6GhoQAMHz6cnj170rBhQ/r06cMtt9xCr169clVLQdM9V8XQhsiYdEsBr2YCUbGJbIiMKbyiRERERIoJwzDwcnPJ0Vfn+pUJ9PMgq7+ONnDcdtG5fuUcne9aXQCvx9WhaerUqbz99tuMHTuWZcuWER4eTu/evUlOTs72PFc3wjAMA7vdnuP3pH2mK99z9efM6b1mmUl7b2bnTNvXt29fDh06xKhRozh+/Dg9e/bk+eefB6BVq1ZERkby0ksvcfHiRe644w4GDx6c63oKksJVMXQyPutglZtxIiIiImWV1WIwsX8IQIaAlfZ6Yv+QYrEaaPXq1QwYMIChQ4fSvHlz6taty759+wq9joYNG7Jhw4Z0+zZt2pTr89WrVw83NzfWrFnj3JeSksKmTZto3Lixc1/lypUZPnw433zzDW+99RZffvml85ivry9Dhgzhk08+Yfbs2cydO5eYmOI30aBlgcVQFR+PfB0nIiIiUpb1CQ1k+tBWGRqFBRSzRmH16tVj7ty5rF27lgoVKvDWW28RHR2dLoAUhieffJKHHnqINm3a0LFjR2bPns327dupW7fuNd97dddBgJCQEB577DH+85//4O/vT61atZgyZQoJCQmMGDECcNzX1bp1a5o0aUJSUhK//fYbDRo0AODtt98mMDCQFi1aYLFY+OGHHwgICKB8+fL5+rnzg8JVMRQW5E+gnwfRsYmZ3ndl4PiPQU7WBYuIiIiII2D1DAlgQ2QMJ+MTqeLj+LNUcZixSvP8888TGRlJ79698fLy4uGHH2bgwIHExsYWah333HMPBw4c4JlnniExMZE77riD4cOHZ5jNysydd96ZYV9kZCSvvfYadrude++9l/j4eNq0acOiRYuoUKECAG5ubowbN46DBw/i6enJDTfcwGeffQZAuXLleP3119m3bx9Wq5W2bduyYMECLJbitwjPMPOygLKUiouLw8/Pj9jYWHx9ffPlnCkpKSxYsICbb745Rw+IS+sWCKQLWGn/+qtbYNlyvdePyJV0/Uhu6dqRvMjP6ycxMZHIyEiCgoLw8NDKnaLQs2dPAgIC+Prrrwvl59ntduLi4vD19S2UEJXdNXY92UAzV8VUVtPXlX3ceXFAEwUrERERESkQCQkJfPTRR/Tu3Rur1crMmTNZunQpS5YsKerSij2Fq2Lsyunr//70N/tPXeChLnUVrERERESkwBiGwYIFC3j55ZdJSkqiYcOGzJ07lx49ehR1acWewlUxZ7UYdAiuyD3tavPirxEs2XmChzpf+2ZCEREREZHc8PT0ZOnSpUVdRolU/O4Ck0z1Dg0AYOOhGE7FJxVxNSIiIiIicjWFqxKienlPmtXwwzRh6a4TRV2OiIiIiIhcReGqBOndxDF7tWhndBFXIiIiIiIiV1O4KkHSwtWf/5wmLjGliKsREREREZErKVyVIPWqlCO4sjcpNpPlu08WdTkiIiIiInIFhasSpk+olgaKiIiIiBRHClfF1fLJsHJKht19mgTypHUeIXs+JDHFVgSFiYiIiEhh6datG6NGjXK+rlOnDtOmTcv2PYZh8NNPP+X5Z+fXecoShaviymKF5a9kCFih/3zE065zSLLB6n2ni6g4ERERkRIki7+0Bhz7l0/O9x/Zv3//LB+6u27dOgzDYMuWLdd93o0bN/Lwww/ntbx0XnjhBVq0aJFhf1RUFH379s3Xn3W1GTNmUL58+QL9GYWpyMPVhx9+SFBQEB4eHrRu3ZrVq1dnOXbevHn07NmTypUr4+vrS4cOHVi0aFGGcXPnziUkJAR3d3dCQkL48ccfC/IjFIyuY6H7BEfAWvw/SIiBlVMwVrzK8moP8Z5tEAt3aGmgiIiIyDVl8ZfWjmD1iuN4PhsxYgTLli3j0KFDGY59/vnntGjRglatWl33eStXroyXl1d+lHhNAQEBuLu7F8rPKi2KNFzNnj2bUaNGMWHCBLZu3Urnzp3p27cvhw8fznT8qlWr6NmzJwsWLGDz5s10796d/v37s3XrVueYdevWMWTIEO699162bdvGvffeyx133MH69esL62Pln65joXprWPsOvFHP8S9/9wl49hgHOJ53lWKzF3GRIiIiIoXMNCH5Qs6/OjwOXf7j+LPUspcd+5a97Hjd5T+O4zk9l2nmqMRbbrmFKlWqMGPGjHT7ExISmD17NiNGjODMmTPcdddd1KhRAy8vL5o2bcrMmTOzPe/VywL37dtHly5d8PDwICQkhCVLlmR4z7PPPkuDBg3w8vKibt26PP/886SkODpPz5gxg0mTJrFt2zYMw8AwDGfNVy8L/Pvvv7nxxhvx9PSkYsWKPPzww5w/f955fPjw4QwcOJA333yTwMBAKlasyOOPP+78Wblx+PBhBgwYQLly5fD19eWOO+7gxInLz3zdtm0b3bt3x8fHB19fX1q3bs2mTZsAOHToEP3796dChQp4e3vTpEkTFixYkOtacsKlQM9+DW+99RYjRozgwQcfBGDatGksWrSI6dOnM3lyxunZq9eXvvrqq/z888/Mnz+fli1bOsf07NmTceMcAWTcuHGsXLmSadOmXfNiLZZCB8OxzWDawOoGXcfS1m5S0duNMxeS2RAZQ6d6lYq6ShEREZHCk5IAr1bL3XtXveH4yur1tYw/Dm7e1xzm4uLCsGHDmDFjBv/73/8wDAOAH374geTkZO655x4SEhJo3bo1zz77LL6+vvz222/ce++91K1bl3bt2l3zZ9jtdgYNGkSlSpX466+/iIuLS3d/VhofHx9mzJhBtWrV+Pvvv3nooYfw8fFh7NixDBkyhB07drBw4UKWLl0KgJ+fX4ZzJCQk0KdPH9q3b8/GjRs5efIkDz74IE888US6ALl8+XICAwNZvnw5//zzD0OGDKFFixY89NBD1/w8VzNNk0GDBuHt7c3KlStJTU1l5MiRDBkyhBUrVgBwzz330LJlS6ZPn47VaiU8PBxXV1cAHn/8cZKTk1m1ahXe3t5ERERQrly5667jehRZuEpOTmbz5s0899xz6fb36tWLtWvX5ugcdrud+Ph4/P39nfvWrVvH6NGj043r3bt3tjf+JSUlkZSU5HwdFxcHQEpKSp6S9pXSznO957Oc2Y8VMAHDloxt2WTsnZ/hpkaV+X7zMRZsP05Y7Yz/AkjpktvrRwR0/Uju6dqRvMjP6yclJQXTNLHb7djtdrDbi2z5VdrPz4nhw4fzxhtvsGzZMrp37w44lgTedttt+Pn54efnx5gxY5zjH3/8cX7//Xe+//572rZt69yf9tmvfr148WJ27drFgQMHqFGjBgAvv/wy/fr1u/y7AsaPH+98b61atRgzZgzff/89zzzzDO7u7nh7e+Pi4kKVKlXSf85L3+12O19//TUXL15kxowZeHt7ExISwrvvvsuAAQOYPHkyVatWxTRNKlSowLvvvovVaqVBgwbcfPPNLF26lBEjRmT9+7zi+5WfccWKFWzfvp39+/dTs2ZNAL788kuaNm3K+vXradu2LYcPH+bpp5+mQYMGAAQHBzvPd/jwYQYNGkSTJk0Ax6xfZj8rbZ9pmqSkpGC1pl8mej3XcJGFq9OnT2Oz2ahatWq6/VWrViU6Omf3Ek2dOpULFy5wxx13OPdFR0df9zknT57MpEmTMuxfvHhxvq9pzWyqNisNon+icdQ8UiweuNoTOVzhBmqteo29+/ZS3v02wMqvWw/TxhKJxcjXMqWYup7rR+Rqun4kt3TtSF7kx/Xj4uJCQEAA58+fJzk52bE07/Fd130e940f4rnhPUyLK4Y9hYthT5LUduT1neRiKiTG5WhotWrVCAsL4+OPP6Z169ZERkayevVq5s2bR1xcHDabjbfffpsff/yRqKgokpOTSUpKwt3d3fmX/ampqSQnJztf2+12EhMTiYuLIzw8nBo1auDr6+s8nhYkLl686Nz3888/M336dCIjI7lw4QKpqan4+Pg4jyclJWGz2Zyv033cS+fZvn07TZo0STeuadOm2O12tmzZQqdOnUhJSaFBgwZcuHDB+f6KFSsSERGR6bkBEhMTMU0z0+N79+6levXq+Pn5OY/XqFEDPz8/tm7dSsOGDRk5ciQPP/wwX375JV27dmXgwIEEBQUB8OCDD/L000/z+++/061bN/r3709oaGimdSQnJ3Px4kVWrVpFampqumMJCQmZviczRbosEHBOkaYxTTPDvszMnDmTF154gZ9//jldys7NOceNG5fubw3i4uKoWbMmvXr1wtfXNycf45pSUlJYsmQJPXv2dE5VZsey+k2sW+dh6/Ic1nOHYPtMqjdsgc3tBhqveo26N9Tn28hWxCbZqN6sIy1rls+XOqV4ut7rR+RKun4kt3TtSF7k5/WTmJjIkSNHKFeuHB4eHpf2XufKnVVvYNnwHvZu46HLfzBXvYHnildx9/Jx3HdVQB566CGeeuop/u///o85c+ZQu3Zt+vfvj2EYvPHGG3z00Ue89dZbNG3aFG9vb0aPHo3dbnf+GdTFxQU3Nzfna4vFgoeHB76+vri7u2OxWDL986qnpye+vr789ddfjBgxghdeeIFevXrh5+fH7Nmzeeutt5zvc3d3x2q1ZnseV1dXXF1d040xL91/lnY/lKurq3N8muxqBPDw8MAwjAzHTdPENM1r1vXqq68yfPhwFixYwO+//85rr73Gd999x2233cYTTzzBgAED+O2331iyZAk33ngjb775Jk888USG8yUmJuLp6em8f+1KWQXDzBRZuKpUqRJWqzXDjNLJkyczzDxdLe0mwB9++CFDi8uAgIDrPqe7u3umnVDSLqL8lONzGkD3CVi7joW/58D2mVgjV8Jja8Bqxd1u48ZGVZm/7Th/7D5NWN3K+VqnFE8FcU1K2aHrR3JL147kRX5cPzabDcMwsFgsWCy5WBC4cgqseBW6T8DSdaxjX7dnwTCwLH8FDMPRSKwA3HnnnYwePZpZs2bx1Vdf8dBDDzmXna1Zs4YBAwYwbNgwwDEr9c8//9C4ceN0nzPts1/9ukmTJhw+fJjo6GiqVXPcg5bWxC3td7Vu3Tpq167Nf//7X+f705rHpZ3T3d0dm82W6e827TxNmjThq6++4uLFi3h7O+45W7duHRaLhUaNGmGxWJwNMa6u9cqfldn5Mztut9tp2LAhhw8f5tixY85lgREREcTGxtKkSRPnexo1akSjRo0YM2YMd911F19++SW33347ALVr12bkyJGMHDmScePG8emnn/LUU09lWodhGJler9dz/RZZt0A3Nzdat26dYap4yZIldOzYMcv3zZw5k+HDh/Pdd9/Rr1+/DMc7dOiQ4ZyLFy/O9pzFUvdxl/8lr9vN8f3E33D+5KU27ePo0yQAgEU7o51/cyAiIiIiV7HbHI+4uTpApT36xm4rsB9drlw5hgwZwvjx4zl+/DjDhw93HqtXrx5Llixh7dq17Nq1i0ceeSTHt8cA9OjRg4YNGzJs2DC2bdvG6tWrmTBhQrox9erV4/Dhw8yaNYv9+/fz7rvvZnhMUZ06dYiMjCQ8PJzTp0+n60WQ5p577sHDw4P77ruPHTt2sHz5cp588knuvffea06MXIvNZiM8PDzdV0REBN26daNZs2bcc889bNmyhQ0bNjBs2DC6du1KmzZtuHjxIk888QQrVqzg0KFD/Pnnn2zcuJHGjRsDMGrUKBYtWkRkZCRbtmxh2bJlzmMFpUhbsY8ZM4ZPP/2Uzz//nF27djF69GgOHz7Mo48+CjiW66UleXAEq2HDhjF16lTat29PdHQ00dHRxMbGOsf8+9//ZvHixbz++uvs3r2b119/naVLl2baOaXE8K4Egc0d2wdWOHd3a1gZNxcLB88ksOdEfNHUJiIiIlLcXfmX1le79JfWBWnEiBGcPXuWHj16UKtWLef+559/nlatWtG7d2+6detGQEAAAwcOzPF5LRYLP/74I0lJSYSFhfHggw/yyiuvpBszYMAARo8ezRNPPEGLFi1Yu3Ytzz//fLoxt99+O3369KF79+5Urlw50w7bXl5eLFq0iJiYGNq2bcvgwYO56aabeP/996/vl5GJ8+fP07Jly3Rft9xyC4ZhMG/ePCpUqECXLl3o0aMHdevWZfbs2QBYrVbOnDnDsGHDaNCgAXfccQd9+/Z19lKw2Ww8/vjjNG7cmD59+tCwYUM+/PDDPNebLbOIffDBB2bt2rVNNzc3s1WrVubKlSudx+677z6za9euztddu3Y1cTTOS/d13333pTvnDz/8YDZs2NB0dXU1GzVqZM6dO/e6aoqNjTUBMzY2Ni8fLZ3k5GTzp59+MpOTk3N3giUTTXOir2nOeyTd7hEzNpi1n/3VnLZkb96LlGIrz9ePlGm6fiS3dO1IXuTn9XPx4kUzIiLCvHjxYj5UJiWBzWYzz549a9pstkL5edldY9eTDYq8oUXaGsjMXP3QtbR+9tcyePBgBg8enMfKipm63WHN27B/maNDzqX1q72bBLB010kW7ozm3z3qF3GRIiIiIiJlV5EuC5TrUKs9uHjC+RNwMsK5u0fjqlgtBrui4jh8JudtIkVEREREJH8pXJUULu5Q5wbH9v5lzt0VvN1oF+R4iPKinTm/AVJERERERPKXwlVJEnyj4/v+5el29wl1dA1cqHAlIiIiIlJkFK5KkrRwdehPSEl07u4V4ghXWw6f5WRcYmbvFBERESnxTD16RgpIfl1bClclSeWG4BMIqYlweJ1zd4CfBy1qlsc0YXHEiSIsUERERCT/pT3ENSFB95dLwUhOTgZwPuA5t4q8W6BcB8NwzF6Ff+u47yq4u/NQ7yYBhB85x6Kd0QxtX7sIixQRERHJX1arlfLly3Py5EnA8cwl41LnZCmd7HY7ycnJJCYmYrEU7HyQ3W7n1KlTeHl54eKSt3ikcFXSOMNV+vuuejepyusLd7Nu/xliE1Lw83ItogJFRERE8l9AgOM2iLSAJaWbaZpcvHgRT0/PQgnSFouFWrVq5flnKVyVNHW7Ob6f+BvOn4RyVRy7K5ejYVUf9pyI54/dJxjUqkbR1SgiIiKSzwzDIDAwkCpVqpCSklLU5UgBS0lJYdWqVXTp0sW5LLQgubm55csMmcJVSeNdCQKbQ9Q2OLACmt3hPNS7SVX2nIhn0c5ohSsREREplaxWa57vi5Hiz2q1kpqaioeHR6GEq/yihhYlUd1L91pd8bwrgN6XWrKv3HuKhOTUwq5KRERERKRMU7gqiZzPu1oGV7SNDAn0pUYFTxJT7Kzae6qIihMRERERKZsUrkqiWu3BxRPOn4CTEc7dhmHQp4lj9mrRTrVkFxEREREpTApXJZGLO9S5wbF91dLAPpeWBi7ddYLkVHthVyYiIiIiUmYpXJVUzqWB6Vuyt6pVgUrl3IlPTOWvA2eKoDARERERkbJJ4aqkSgtXh/6ElETnbovFoFeTqgB8ue4gP4cfY93+M9jsZmZnERERERGRfKJW7CVV5YbgEwjxUXB4HQR3dx6q6O0GwB+7TvLHLseD9gL9PJjYP4Q+oYFFUq6IiIiISGmnmauSyjDSdw28ZOGOKN5f9k+G4dGxiTz2zRYW7ogqrApFRERERMoUhauS7Kr7rmx2k0nzI8hsAWDavknzI7REUERERESkAChclWR1uzm+n/gbzp9kQ2QMUbGJWQ43gajYRDZExhRKeSIiIiIiZYnCVUnmXQkCmzu2D6zgZHzWwepKOR0nIiIiIiI5p3BV0tW91Mhi/zKq+Hjk6C05HSciIiIiIjmncFXSXdHUIqxOBQL9PDCyGGrg6BoYFuRfWNWJiIiIiJQZClclXa324OIJ509gPb2Lif1DALIMWBP7h2C1ZHVURERERERyS+GqpHNxhzo3OLb3L6NPaCDTh7YiwC/90j9vNyvTh7bSc65ERERERAqIwlVpcNXzrvqEBrLm2RuZ+VB7HrwhCAAfDxd6hQQUVYUiIiIiIqWewlVpEHypqcWhtZDi6ARotRh0CK7IM70bUs7dhei4JLYeOVuERYqIiIiIlG4KV6VB5UbgEwipiXB4XbpDHq5WeoZUBWD+tqiiqE5EREREpExQuCoNDCPD0sAr3dLMcZ/Vgr+jsNvNwqxMRERERKTMULgqLZzhanmGQzfUr4SPhwsn45PYdEhLA0VERERECoLCVWlRt5vj+4m/4fzJdIfcXazOZha/bT9eyIWJiIiIiJQNClelhXclCGjm2D6wIsPhW5pfWhq4IxqblgaKiIiIiOQ7havSJJv7rjoFV8LP05VT8UlsiIwp5MJEREREREo/havS5MpwZaafnXJzsdC7iaNr4G9/a2mgiIiIiEh+U7gqTWq1BxdPOH8CTkZkONyvWTUAFu6IJtVmL+zqRERERERKNYWr0sTFHerc4NjOZGlgx+CKVPBy5fT5ZNZraaCIiIiISL5SuCptsrnvytVqoU+oo2vgr9v1QGERERERkfykcFXaBHd3fD+0FlISMxzu1zRtaWCUlgaKiIiIiOQjhavSpnIj8AmE1EQ4vC7D4fZ1/ano7cbZhBTW7j9TBAWKiIiIiJROCleljWFkuzTQ5Yqlgb9paaCIiIiISL5RuCqNnOFqeaaH+zVzPFB44c5oUrQ0UEREREQkXyhclTbLJ0P0347tE39D/InLx1ZOgeWTaRdUkUrl3Im9mMKf/5wumjpFREREREoZhavSxmKFP6dBOccDgzmwwvF95RRY/gpYrFgtBjc3VddAEREREZH8pHBV2nQdC90nOB4kDHBg+eVg1X2C4zjQr6ljaeCindEkp2ppoIiIiIhIXilclUZdx0KLux3b22ZmCFYAber4U8XHnfjEVNb8c6qIChURERERKT0UrkqrW6Zd3ra4pgtWwKWlgY7Zq1+3aWmgiIiIiEheKVyVVn++c3nbnuJYGniVWy51DVwScYLEFFthVSYiIiIiUiopXJVGafdYNejjeO1X0/H6qoDVqlYFAnw9iE9KZfU+dQ0UEREREckLhavS5srmFX0vham443DDmAwBy2IxnM+8+m378aKoVkRERESk1FC4Km3stsvNKyrUhkoNwLRBYDPHfnv65X/9tDRQRERERCRfuBR1AZLPuo9L/7peTzi9F/YthYEfZBjesmZ5qpf35Ni5i6zYc4o+oQGFVKiIiIiISOmimavSrn4Px/d/loJpZjhsGJcfKPzb3+oaKCIiIiKSWwpXpV3tTuDqBeejIfrvTIfc0qwaAH/sOsHFZC0NFBERERHJDYWr0s7FHYK6OLb/WZLpkGY1/KhRwZOEZBvL95wsxOJEREREREoPhauyoH5Px/d9SzM9bBhXdg3U0kARERERkdxQuCoL6l0KV0fWw8VzmQ7pn7Y0cPcJEpJTC6kwEREREZHSQ+GqLLiyJfuB5ZkOaVLNl9oVvUhMsfPHLi0NFBERERG5XgpXZUW9HCwNbOpYGvjVuoP8HH6MdfvPYLNn7DAoIiIiIiIZ6TlXZUX9HvDXB5dbshtGhiEVvNwA2HjwLBsPngUg0M+Dif1D6BMaWKjlioiIiIiUNJq5Kiuu0ZJ94Y4oXl2wK8P+6NhEHvtmCwt3qNGFiIiIiEh2FK7KimxastvsJpPmR5DZAsC0fZPmR2iJoIiIiIhINhSuypJ6PRzfr7rvakNkDFGxiVm+zQSiYhPZEBlTgMWJiIiIiJRsCldlSf3MW7KfjM86WF0pp+NERERERMoihauypEIdqFj/Ukv2Fc7dVXw8cvT2nI4TERERESmLFK7KmrTZqyvuuwoL8ifQz4OM/QMdDBxdA8OC/Au8PBERERGRkkrhqqxJu+/qnz8cLdkBq8VgYv8QgCwD1sT+IVgtWR0VERERERGFq7ImrSV7fBSc2OHc3Sc0kOlDWxHgl37pn6vVYPrQVnrOlYiIiIjINeghwmWNqwfU6Qz7FsG+JRDQ1HmoT2ggPUMC2BAZw76T8fzv552k2ExCq/sVYcEiIiIiIiWDZq7KIud9V0szHLJaDDoEV2RYhzp0qFsRgPnb9ABhEREREZFrUbgqi9Luuzr8FyTGZjns1hbVAPhl2/HCqEpEREREpERTuCqL/IOgYr0MLdmv1jc0AFerwa6oOPadiC+8+kRERERESiCFq7Kq3qWlgfuWZDmkvJcbXRtUBjR7JSIiIiJyLQpXZVX9jC3ZM3Nri+oA/Bx+HDObcSIiIiIiZZ3CVVlV+wZw8YT443BiZ5bDejSugqerlcMxCWw7mvX9WSIiIiIiZZ3CVVnl6gFBnR3b+xZnOczLzYVeTaoC8HP4scKoTERERESkRFK4Ksvq93J8z6Ql+5Vube7oGvjr9ihsdi0NFBERERHJjMJVWZbDluyd61emvJcrp+KT+OvAmUIqTkRERESkZFG4Ksty2JLdzcVC39BAAH4JV9dAEREREZHMKFyVdTloyQ4w4NIDhRfsiCIp1VbQVYmIiIiIlDgKV2VdDluyh9XxJ8DXg/jEVFbuOVVIxYmIiIiIlBwKV2VdDluyWywG/Zs7lgb+rAcKi4iIiIhkoHBV1l3Zkv2f7JcG3trc8UDhpREnOJ+UWtCViYiIiIiUKApXcsV9V9m3ZA+t7kvdSt4kpdpZEhFdCIWJiIiIiJQcCldy+b6rI39BYlyWwwzDoP+lZ179rK6BIiIiIiLpKFwJ+NcF/2Cwp2bbkh3g1ktdA1fvO82Z80mFUJyIiIiISMmgcCUO9S8tDbzGfVfBlcsRWt0Xm91kwQ4tDRQRERERSaNwJQ5X3neVTUt2gAGXGlvM19JAEREREREnhStxqNMJXDwcLdlPRmQ79JbmgRgGbDgYw7FzFwupQBERERGR4k3hShxcPaHOpZbs+7JfGhjo50lYHX8AftUzr0REREREAIUruZLzvqvsW7LD5cYW6hooIiIiIuKgcCWX1bvUkv3wumxbsgPcHBqIi8UgIiqOf07GF0JxIiIiIiLFm8KVOCyfDDvmOtqyX92SfeUUx/ErVPB2o0uDygD8otkrEREREZGiD1cffvghQUFBeHh40Lp1a1avXp3l2KioKO6++24aNmyIxWJh1KhRGcbMmDEDwzAyfCUmJhbgpygFLFZY/gp4Ou6lcrZkXznFsd9izfCWAZeWBv6y7TjmNToMioiIiIiUdkUarmbPns2oUaOYMGECW7dupXPnzvTt25fDhw9nOj4pKYnKlSszYcIEmjdvnuV5fX19iYqKSvfl4eFRUB+jdOg6FrpPgGObHK/3LYUVrzuCVfcJjuNX6dG4Kh6uFg6eSWD70dhCLlhEREREpHgp0nD11ltvMWLECB588EEaN27MtGnTqFmzJtOnT890fJ06dXjnnXcYNmwYfn5+WZ7XMAwCAgLSfUkOdB0LXS6FqPjjsOLVLIMVgLe7Cz1DHL/bX9Q1UERERETKOJei+sHJycls3ryZ5557Lt3+Xr16sXbt2jyd+/z589SuXRubzUaLFi146aWXaNmyZZbjk5KSSEpKcr6Oi3M0c0hJSSElJSVPtaRJO09+na/AdB6Ly6o3MDAxDSupHUdDNjX3a1KF+duOM3/bcf7Tsx5Wi1GIxZYdJeb6kWJJ14/klq4dyQtdP5IXxen6uZ4aiixcnT59GpvNRtWqVdPtr1q1KtHR0bk+b6NGjZgxYwZNmzYlLi6Od955h06dOrFt2zbq16+f6XsmT57MpEmTMuxfvHgxXl5eua4lM0uWZP8MqaLWIPonGuO4f8owbfzz2UPsDbwty/GpdvCyWjkZn8T7sxdS30/3XhWk4n79SPGm60dyS9eO5IWuH8mL4nD9JCQk5HhskYWrNIaRfqbDNM0M+65H+/btad++vfN1p06daNWqFe+99x7vvvtupu8ZN24cY8aMcb6Oi4ujZs2a9OrVC19f31zXcqWUlBSWLFlCz549cXV1zZdz5jfL6jexbp2H7YZnsGz8GCMpjsbRP9KgQUPsnZ/J8n3rU3fy/eZjnPSsxb9vblKIFZcdJeH6keJL14/klq4dyQtdP5IXxen6SVvVlhNFFq4qVaqE1WrNMEt18uTJDLNZeWGxWGjbti379u3Lcoy7uzvu7u4Z9ru6uub7P8yCOGe+WDkFVr0G3Sdg7ToWLp6GzTMgoCnWVa9htVqzvPdqYKsafL/5GIsiTvLSbU1xd8nYWVDyR7G9fqRE0PUjuaVrR/JC14/kRXG4fq7n5xdZQws3Nzdat26dYapvyZIldOzYMd9+jmmahIeHExgYmG/nLJXstvTNK5rf5fh+5gB0fsZxPAvtgipSxced2IspfLLqAD+HH2Pd/jPY7FoiKCIiIiJlR5EuCxwzZgz33nsvbdq0oUOHDnz88cccPnyYRx99FHAs1zt27BhfffWV8z3h4eGAo2nFqVOnCA8Px83NjZCQEAAmTZpE+/btqV+/PnFxcbz77ruEh4fzwQcfFPrnK1G6j0v/umY7qBAEZyOhUn1ofmeWb7VaDJpW9+OP3Sd5c/Fe5/5APw8m9g+hT6iCrYiIiIiUfkUaroYMGcKZM2d48cUXiYqKIjQ0lAULFlC7dm3A8dDgq595dWXXv82bN/Pdd99Ru3ZtDh48CMC5c+d4+OGHiY6Oxs/Pj5YtW7Jq1SrCwsIK7XOVCobhmL1a8SqEf5dtuFq4I4o/dp/MsD86NpHHvtnC9KGtFLBEREREpNQr8oYWI0eOZOTIkZkemzFjRoZ9ppn9UrO3336bt99+Oz9Kk+ZDHOEqchXEHgW/GhmG2Owmk+ZHZPp2EzCASfMj6BkSoDbtIiIiIlKqFelDhKWYq1AHancCTNg+O9MhGyJjiIpNzPIUJhAVm8iGyJgCKVFEREREpLhQuJLspTW22DYLMpk1PBmfdbDKzTgRERERkZJK4UqyFzIAXDzh9F44tiXD4So+Hjk6TU7HiYiIiIiUVApXkj0PX2h8i2N728wMh8OC/An08yCru6kMHF0Dw4L8C6xEEREREZHiQOFKri2tU+COOZCalO6Q1WIwsb+jDX5WAWti/xA1sxARERGRUk/hSq6tbncoFwAXz8K+xRkO9wkNZPrQVgT4pV/65+VmVRt2ERERESkzFK7k2ixWaHaHYzs849JAcASsNc/eyMyH2vNIl7oAuLtYuLFR1cKqUkRERESkSClcSc6kdQ3ctwgunMl0iNVi0CG4Iv/p3ZDKPu6cTUhhxZ6MDxcWERERESmNFK4kZ6qGQGBzsKc67r3KhovVwsAW1QCYu+VoYVQnIiIiIlLkFK4k55rf7fieSdfAq93eugYAy3af5OyF5IKsSkRERESkWFC4kpxrOhgsLnB8K5zcne3QRgG+NKnmS4rN5JdtxwupQBERERGRoqNwJTnnXQnq93Js52T2qpVj9kpLA0VERESkLFC4kuuT9syr7d+D3Zbt0AEtquFiMdh+NJZ9J+ILoTgRERERkaKjcCXXp0Ef8CgP8cchcmW2QyuWc6dbwyoAzNHslYiIiIiUcgpXcn1c3CH0dsf2tlnXHD64dXUAftp6DJvdLMjKRERERESKlMKVXL8Wl7oG7poPSdkv9+veqArlvVw5EZfEmn9OF0JxIiIiIiJFQ+FKrl/11lCxHqQkQMQv2Q51d7Fya/NLz7zarKWBIiIiIlJ6KVzJ9TMMaH6XY/s6ugYu2hlNXGJKQVYmIiIiIlJkFK4kd5oNAQw4uBrOHc5+aA0/6lUpR1KqnQXbowqnPhERERGRQqZwJblTviYEdXZsb5ud7VDDMPTMKxEREREp9RSuJPeuXBpoZt8J8LaW1bEYsPHgWQ6duVAIxYmIiIiIFC6FK8m9xreCqxfE7IejG7MdGuDnQad6lQCYu+VYYVQnIiIiIlKoFK4k99zLOQIW5KixxeDWjqWB87Ycxa5nXomIiIhIKaNwJXnT4tLSwB1zISUx26G9QgIo5+7C0bMX2XAwphCKExEREREpPApXkjd1OoNvdUiMhb0Lsx3q6WalX9NAQM+8EhEREZHSR+FK8sZivdSWnZw98+rS0sAFf0eRkJxakJWJiIiIiBQqhSvJu7SugfuWwPlT2Q5tW6cCtfy9uJBsY9HO6EIoTkRERESkcChcSd7tmAs+1cC0wd8/pD+2cgosn+x8aRgGg1pVB2DuZnUNFBEREZHSQ+FK8s5ihfjjju0rlwaunALLX3Ecv0LaA4X/3H+a4+cuFlaVIiIiIiIFSuFK8q7rWLhhtGM7ejuc2Hk5WHWf4Dh+hZr+XoQF+WOa8ONWzV6JiIiISOmgcCX5o8cLUKmBY/ujG7IMVmkGX5q9mrvlKKapZ16JiIiISMmncCX5p8cLju+mHaxuWQYrgL5NA/BwtXDg1AXCj5wrlPJERERERAqSwpXkn6jtl7dtyY6lgVnw8XClT5MAwDF7JSIiIiJS0ilcSf5YOQVWvgbV2zheVwlxLA3MJmClPfNq/rYoklJthVGliIiIiEiBUbiSvLuyecXNbzj2xRyAzk9nG7A6BlciwNeD2IspTF+xn5/Dj7Fu/xlsdt2DJSIiIiIlj0tRFyClgN12uXmFaULlRnBqN1So49hvz3xWymoxaF7Tj+idiUxbus+5P9DPg4n9Q+gTGlhIH0BEREREJO80cyV5133c5eYVhgHN73Rsb5vl2N99XKZvW7gjikU7T2TYHx2byGPfbGHhjqiCqlhEREREJN8pXEn+a3oHYMChP+HswUyH2Owmk+ZHZHosbVHgpPkRWiIoIiIiIiWGwpXkP7/qULebY3vb7EyHbIiMISo2MctTmEBUbCIbImPyvz4RERERkQKgcCUFo/ldju/bZjruw7rKyfisg1VuxomIiIiIFDWFKykYjW8Bt3JwNhKOrM9wuIqPR45Ok9NxIiIiIiJFTeFKCoabN4QMcGxvm5nhcFiQP4F+HhhZvN3A0TUwLMi/wEoUEREREclPCldScNK6Bu74EVIupjtktRhM7B8CkGXAmtg/BKslq6MiIiIiIsWLwpUUnNo3gF9NSIqFPb9nONwnNJDpQ1sR4Jd+6Z+LxeDDe1rpOVciIiIiUqIoXEnBsVig2RDH9rZZmQ7pExrImmdvZOZD7Xnt9qa4WS2k2k0q+bgXYqEiIiIiInmncCUFK21p4D9L4fzJTIdYLQYdgityZ9ta3NayOgDf/nWosCoUEREREckXCldSsCrVhxptwbTB3z9cc/g97WsBsODvaGIuJBd0dSIiIiIi+UbhSgpe2uxVeMaugVdrVqM8Tav7kWyz88OmIwVcmIiIiIhI/lG4koLXZBBY3eDE3xD99zWHD700e/XdhsPY7RkfQCwiIiIiUhwpXEnB8/KHBn0c21k0trhS/+bV8HF34dCZBP7cf7qAixMRERERyR8KV1I4mt/l+L79e7ClZjvUy82FQa3SGlscLujKRERERETyhcKVFI76PcGrIlw4CQeWX3P43e1qA7Bk1wlOxCUWdHUiIiIiInmmcCWFw+oKTf/l2A7/7prDGwb40LZOBWx2k1kb1NhCRERERIo/hSspPGlLA3f/BhfPXXP40PaO2atZGw+TarMXYGEiIiIiInmncCWFJ7A5VG4MtiSI+Pmaw/uEBuDv7UZUbCLL95wqhAJFRERERHJP4UoKj2FcfubVtms/88rdxcq/WtcA4Nv1hwqyMhERERGRPFO4ksLVbAgYFji8DmIOXHP4XWGOZ16t3HuKIzEJBV2diIiIiEiuKVxJ4fINhLrdHNvbZl9zeJ1K3nSuXwnTdDxUWERERESkuFK4ksKX1thi20wwzWsOv6edY/bq+41HSE5VYwsRERERKZ4UrqTwNboF3MrBuUNw+K9rDr+pcVWq+rpz5kIyi3ZGF0KBIiIiIiLXT+FKCp+bF4QMdGxvu/Yzr1ytFoa0dcxeqbGFiIiIiBRXCldSNFpcWhq48ydIuXjN4Xe2rYnFgL8OxPDPyfMFW5uIiIiISC4oXEnRqNUR/GpBUpzjocLXUK28Jzc2qgpo9kpEREREiieFKykaFgs0H+LY3jYrR2+5p71jaeDczUe5mGwrqMpERERERHJF4UqKTlrXwP1/QPyJaw7vWr8yNSp4EpeYyq/bjxdwcSIiIiIi10fhSopOxWCoEQamHf7+/prDLRaDu9ulNbbQM69EREREpHhRuJKis3wyeFV0bF+9NHDlFMfxq/yrdU1crQbhR86x41hsIRQpIiIiIpIzCldSdCxW2Ps7GFY4sQOitjv2r5wCy19xHL9KZR93ejcJAOC7DZq9EhEREZHiQ+FKik7XsdB9ApiXmlNsm3U5WHWf4DieiXva1Qbgp63HiE9MKaxqRURERESypXAlRavrWGh6h2P7rw+uGawA2tf1J7iyNwnJNn4KV2MLERERESkechWujhw5wtGjR52vN2zYwKhRo/j444/zrTApQwZ+eHnb4pJtsAIwDMM5e/Xxyv38vPUY6/afwWY3C7JKEREREZFs5Spc3X333SxfvhyA6OhoevbsyYYNGxg/fjwvvvhivhYoZcCaty9v21NhxWvXfIufpysAR85e5N+zw7nrk7+44fVlLNwRVVBVioiIiIhkK1fhaseOHYSFhQHw/fffExoaytq1a/nuu++YMWNGftYnpV3aPVadnwGP8o59KyY79mdh4Y4onvlhW4b90bGJPPbNFgUsERERESkSuQpXKSkpuLu7A7B06VJuvfVWABo1akRUlP5gKzl0ZfOKm56Hdo849per6tifScCy2U0mzY8gswWAafsmzY/QEkERERERKXS5CldNmjTho48+YvXq1SxZsoQ+ffoAcPz4cSpWrJivBUopZrelb17R7lFw9YLzJ6DZnY7jV9kQGUNUbGKWpzSBqNhENkTGFFDRIiIiIiKZy1W4ev311/m///s/unXrxl133UXz5s0B+OWXX5zLBUWuqfu49M0rvPyh9f2O7dgjjuNXORmfdbDKzTgRERERkfzikps3devWjdOnTxMXF0eFChWc+x9++GG8vLzyrTgpgzo8Dhs+hkN/wuH1UKtdusNVfDxydJqcjhMRERERyS+5mrm6ePEiSUlJzmB16NAhpk2bxp49e6hSpUq+FihljF91aH6nY3vNWxkOhwX5E+jngZHF2w0g0M+DsCD/AitRRERERCQzuQpXAwYM4KuvvgLg3LlztGvXjqlTpzJw4ECmT5+erwVKGXTDaDAssHchRO9Id8hqMZjYPwQg04BlAhP7h2C1ZBW/REREREQKRq7C1ZYtW+jcuTMAc+bMoWrVqhw6dIivvvqKd999N18LlDKoYjCEDHBsX/kMrEv6hAYyfWgrAvwyLv1rULUcfUIDC7pCEREREZEMcnXPVUJCAj4+PgAsXryYQYMGYbFYaN++PYcOHcrXAqWMumEM7PwRds6D7uMdgesKfUID6RkSwIbIGE7GJ2I1DP49ayt7T5xn25FzNK9ZvmjqFhEREZEyK1czV/Xq1eOnn37iyJEjLFq0iF69egFw8uRJfH1987VAKaMCm0G9nmDaYW3ms6FWi0GH4IoMaFGdW5pXY0CL6gB8vOpAYVYqIiIiIgLkMlz973//45lnnqFOnTqEhYXRoUMHwDGL1bJly3wtUMqwzmMc38O/g7hrP5z6oS51Afh9RxSHzlwoyMpERERERDLIVbgaPHgwhw8fZtOmTSxatMi5/6abbuLttzPeIyOSK7U7Qq0OYEuGde9fc3jjQF+6NqiM3YRPV0cWQoEiIiIiIpflKlwBBAQE0LJlS44fP86xY8cACAsLo1GjRvlWnAg3XJq92vQFJMRcc/gjl2avfth8hJgLyQVZmYiIiIhIOrkKV3a7nRdffBE/Pz9q165NrVq1KF++PC+99BJ2uz2/a5SyrH5PqNoUUi44Hi58DR2CKxJa3ZfEFDtfrTtY8PWJiIiIiFySq3A1YcIE3n//fV577TW2bt3Kli1bePXVV3nvvfd4/vnn87tGKcsMAzqPdmyv/wiSzl9juMEjXRydBb9ad4iLybaCrlBEREREBMhluPryyy/59NNPeeyxx2jWrBnNmzdn5MiRfPLJJ8yYMSOfS5QyL2Qg+NeFi2dhy5fXHN43NIAaFTyJuZDMnM1HCr4+ERERERFyGa5iYmIyvbeqUaNGxMRc+74YketisUKnUY7tte9BalK2w12sFh68IQiAT9dEYrObBVygiIiIiEguw1Xz5s15//2M3dvef/99mjVrlueiRDJofif4BEJ8FGybdc3hd7StSXkvVw6dSWDRzuhCKFBEREREyjqX3LxpypQp9OvXj6VLl9KhQwcMw2Dt2rUcOXKEBQsW5HeNIuDiDh2fhEXj4c9p0HKoY0YrC15uLgxrX5t3l/3D/63cT9/QAAzDKLx6RURERKTMydXMVdeuXdm7dy+33XYb586dIyYmhkGDBrFz506++OKL6zrXhx9+SFBQEB4eHrRu3ZrVq1dnOTYqKoq7776bhg0bYrFYGDVqVKbj5s6dS0hICO7u7oSEhPDjjz9eV01STLW6DzwrQMwBiPjpmsOHdayDu4uFbUdjWR+p5aoiIiIiUrBy/ZyratWq8corrzB37lzmzZvHyy+/zNmzZ/nyy2s3HEgze/ZsRo0axYQJE9i6dSudO3emb9++HD58ONPxSUlJVK5cmQkTJtC8efNMx6xbt44hQ4Zw7733sm3bNu69917uuOMO1q9fn6vPKcWIezlo96hje/XbYGZ/L1Wlcu7c3roGAB+vOlDQ1YmIiIhIGZfrcJUf3nrrLUaMGMGDDz5I48aNmTZtGjVr1mT69OmZjq9Tpw7vvPMOw4YNw8/PL9Mx06ZNo2fPnowbN45GjRoxbtw4brrpJqZNm1aAn0QKTdjD4OoNJ/6GfUuuOfyhznUxDFi2+yR7T8QXQoEiIiIiUlbl6p6r/JCcnMzmzZt57rnn0u3v1asXa9euzfV5161bx+jRo9Pt6927d7bhKikpiaSkyx3o4uLiAEhJSSElJSXXtVwp7Tz5db4yy9UHS6v7sK7/EPvqqdiCumc7vIafGz0bV2FxxEk+WvEPrw8KLaRC85euH8kLXT+SW7p2JC90/UheFKfr53pqKLJwdfr0aWw2G1WrVk23v2rVqkRH5767W3R09HWfc/LkyUyaNCnD/sWLF+Pl5ZXrWjKzZMm1Z1skex4pDelhuGA98hd/fv82MeUaZju+iQUW48LP4cdobhymvHshFVoAdP1IXuj6kdzStSN5oetH8qI4XD8JCQk5Hntd4WrQoEHZHj937tz1nA4gQwc30zTz3NXtes85btw4xowZ43wdFxdHzZo16dWrF76+vnmqJU1KSgpLliyhZ8+euLq65ss5yyrLqtcxAkIhKpxO9vXYbr48U2lZ/SaYNuxdnk33ntXxG9h06BxHvepxd+8GhV1ynun6kbzQ9SO5pWtH8kLXj+RFcbp+0la15cR1haus7nO68viwYcNydK5KlSphtVozzCidPHkyw8zT9QgICLjuc7q7u+PunnE6w9XVNd//YRbEOcscFzeICgcMLPuXYjm9CwKbwcopsOo16D4B61W/40e71uPBrzYxa+NRnurRAB+PkvnPQNeP5IWuH8ktXTuSF7p+JC+Kw/VzPT//usLV9bZZz46bmxutW7dmyZIl3Hbbbc79S5YsYcCAAbk+b4cOHViyZEm6+64WL15Mx44d81SvFCNdxzq+L3/F8X3NW1AlxPG6+4TLx69wY6MqBFf2Zv+pC8zccJiHuwQXYsEiIiIiUhYUabfAMWPG8Omnn/L555+za9cuRo8ezeHDh3n0UUe77XHjxmWYCQsPDyc8PJzz589z6tQpwsPDiYiIcB7/97//zeLFi3n99dfZvXs3r7/+OkuXLs3ymVhSQnUdC20fdGzv/DHbYAVgsRg83KUuAJ+vOUhyqr2wKhURERGRMqLIGloADBkyhDNnzvDiiy8SFRVFaGgoCxYsoHbt2oDjocFXP/OqZcuWzu3Nmzfz3XffUbt2bQ4ePAhAx44dmTVrFv/97395/vnnCQ4OZvbs2bRr167QPpcUkn5TYdNnjuddGZYsg1WagS2r8+bivUTHJfLLtuMMvvQMLBERERGR/FCk4Qpg5MiRjBw5MtNjM2bMyLDPvMaDYwEGDx7M4MGD81qaFHcrp1x+kLBphwX/gZvfyHK4u4uV+zvVYcrCPXy8cj/Vy3twMj6JKj4ehAX5Y7XkrZGKiIiIiJRtRR6uRHJl5ZTLSwGjt8Ou+bDhY/CunO0M1j3tavPO0n3sPXmeuz5Z79wf6OfBxP4h9AkNLIzqRURERKQUKtJ7rkRy5cpg1XWs4zuXZp2Wv+I4noV1+0+TlMn9VtGxiTz2zRYW7ogqoKJFREREpLRTuJKSx25L37yiSmNoNsSxXaGu43gmbHaTSfMjMj2Wtth00vwIbPZrLz0VEREREbmawpWUPN3HZVz61+05sLjA2QNQt2umb9sQGUNUbGKWpzWBqNhENkTG5GOxIiIiIlJWKFxJ6eAfBC3vdWz/8eLlRhdXOBmfdbDKzTgRERERkSspXEnp0XUsWN3h8Dr4548Mh6v4eOToNDkdJyIiIiJyJYUrKT18q0HYQ47tZS9lmL0KC/In0M+DrBquGzi6BoYF+RdomSIiIiJSOilcSelyw2hwKwdR4Y727FewWgwm9g8ByDJgTewfouddiYiIiEiuKFxJ6eJdCdo/5the9nKGzoF9QgOZPrQVAX4Zl/493LWunnMlIiIiIrmmcCWlT4cnwKM8nN4Df/+Q4XCf0EDWPHsjMx9qzzt3tmBgi2oA/LHrpNqwi4iIiEiuKVxJ6eNZHjr927G9YjKkJmcYYrUYdAiuyIAW1Zk0IBQ/T1f+OXmeeVuOFm6tIiIiIlJqKFxJ6dTuEfCuAmcPwtavsx3q5+nKyG7BAExbuo/ElMwfQiwiIiIikh2FKymd3LyhyzOO7VVvQMrFbIff17EOAb4eHDt3kW/XHy6EAkVERESktFG4ktKr9XDwqwnxUbDxs2yHerhaGdWjPgAfLP+H+MSUQihQREREREoThSspvVzcHQ8WBljzFiTFZzt8cOsa1K3kTcyFZD5ZHVkIBYqIiIhIaaJwJaVb87vBPxgSzsBf07Md6mK18EzvhgB8uvoAp88nFUaFIiIiIlJKKFxJ6WZ1ge7jHdtr34OEmGyH9w0NoGl1PxKSbby/7J9CKFBERERESguFKyn9mgyCqqGQFAdr3812qGEYPNunEQDfrj/EkZiEwqhQREREREoBhSsp/SwWuPG/ju2/PoL4E9kOv6F+JTrVq0iKzeTtpXsLoUARERERKQ0UrqRsaNAHqreB1Iuweuo1h4/t7Zi9+nHrMfZEZ98IQ0REREQEFK6krDAMuOl5x/bmL+Bc9s+yal6zPDc3DcA04Y1FuwuhQBEREREp6RSupOyo2w2CuoAtGVa+fs3hT/dqiNVisHTXSTYdzL4RhoiIiIiIwpWULeVrO76Hz4TTV3UDXDkFlk92vgyuXI5/ta4BwOsLd2OaZmFVKSIiIiIlkMKVlC3lazm+mzZY8erl/SunwPJXwGJNN/zfPerj5mJh48GzrNhzqhALFREREZGSRuFKypauY6Htg47tHXMh+u/Lwar7BMfxKwT6eTK8Yx3AMXtlt2v2SkREREQyp3AlZU+/qVC5sWP7/zpnGazSPNY1GB93F3ZHx/PLtuOFWKiIiIiIlCQKV1I2DfnG8d00weKSZbACqODtxqPdggF4c/FuVu89xc/hx1i3/ww2zWSJiIiIyCUuRV2ASJHYOe/ytj0Vlr18+UHDmbi/Ux0+Wrmfo2cTuffzDc79gX4eTOwfQp/QwIKsVkRERERKAM1cSdmTdo9Vl/+AX03HvlVvOPZnYdXeU8QnpmbYHx2byGPfbGHhjqiCqlZERERESgiFKylbrmxeceN/oe+l510ZFsf+TAKWzW4yaX5EpqdLWxQ4aX6ElgiKiIiIlHEKV1K22G3pm1c0vBka9AHT7ngGlj3j7NSGyBiiYhOzPKUJRMUmsiFSDxoWERERKct0z5WULd3HpX9tGI7ZqwMr4NwhqNQgw1tOxmcdrHIzTkRERERKJ81ciVSoA52fcWwvGg+JsekOV/HxyNFpcjpOREREREonhSsRgE5PgX8wnD8By19NdygsyJ9APw+MLN5q4OgaGBbkX+BlioiIiEjxpXAlAuDiDv3edGxv+BiitjkPWS0GE/uHAGQasExgYv8QrJas4peIiIiIlAUKVyJpgm+EJoMczS1+HQN2u/NQn9BApg9tRYBfxqV/VgvUq+JTmJWKiIiISDGkcCVypd6vgpsPHNsEW79Od6hPaCBrnr2RmQ+15507WzDzoXZ0a1AJmx0m/Pg3pqlW7CIiIiJlmcKVyJV8A6H7eMf20olw4Uy6w1aLQYfgigxoUZ0OwZV4aWBTPFwtrI+MYc7mo0VQsIiIiIgUFwpXIlcLexiqhsLFs46AlY2a/l6M7uFo3/7qgl3EXEgujApFREREpBhSuBK5mtUF+r3l2N76NRxen+3wB24IolGAD2cTUnjlt12FUKCIiIiIFEcKVyKZqdUOWg51bP82BmypWQ51tVp45bamGAbM3XKUtftPF1KRIiIiIlKcKFyJZKXHi+BZAU7scLRnz0br2hW4p10tAP774w4SU2yFUaGIiIiIFCMKVyJZ8a4IPV5wbC9/FeKish3+n96NqOzjzoHTF5i+Yn/B1yciIiIixYrClUh2Wg6D6m0gOR4WT8h2qJ+nq/Nhw9NX7Gf/qfOFUaGIiIiIFBMKVyLZsVjglrfAsMCOubB/ebbD+zUNpFvDyiTb7Hr2lYiIiEgZo3Alci2BzaHtQ47tBc9AalKWQw3D4KUBoXi4WvjrQAxztxwrpCJFREREpKgpXInkhKsnuHrDmX9g7bvpj62cAssnO1/W9Pdi1KVnX73yW4SefSUiIiJSRihcieSEmzekXHBsr3oTzh50bK+cAstfAYs13fARVzz76tUFevaViIiISFmgcCWSE13HQrfxju3URPj9ucvBqvsEx/ErpD37CmDO5qOs23+msCsWERERkUKmcCWSU92ehbBHHNt7f88yWKW58tlXE376m4TkVNbtP8PP4cdYt/8MNruaXYiIiIiUJi5FXYBIiXLzFNj4KZiXHhJcq322w8f2acSinSc4cOoCYa/8wfmkVOexQD8PJvYPoU9oYEFWLCIiIiKFRDNXItdj5RRHsDIu/avz7R0QE5nlcD9PVwa0qAaQLlgBRMcm8tg3W1i4I/uHE4uIiIhIyaBwJZJTV95jNf44lAuA1IvwWU9Iis/0LTa7yW9/Zx6e0hYFTpofoSWCIiIiIqWAwpVITlzdvMLVEx5a5ugieOEUfHwj2O0Z3rYhMobo2MQsT2sCUbGJbIiMKcDiRURERKQwKFyJ5ITdlrF5hV91uPdnMKxwZi+smJzhbSfjsw5WuRknIiIiIsWXwpVITnQfl3lXwJptYcD7ju1VU2DHvHSHq/h45Oj0OR0nIiIiIsWXwpVIXrW4Gzo84dj+aSREbXMeCgvyJ9DPAyOLtxo4ugaGBfkXeJkiIiIiUrAUrkTyQ88XoV4PR4OLmXfD+ZMAWC0GE/uHAGQasExgYv8QrJas4peIiIiIlBQKVyL5wWKF2z+DivUg7ijMHgqpSQD0CQ1k+tBWBPhlXPrn4WKhUYBvYVcrIiIiIgVA4Uokv3iWh7tmgbsfHFkPv40B09FivU9oIGuevZGZD7XnnTtb8M2IMNrWrkBiqp0nZm4hKdVWtLWLiIiISJ4pXInkp0r14V+fOx4yvPUbWP9/zkNWi0GH4IoMaFGdG+pX5t27W1LBy5Udx+KYvGB3ERYtIiIiIvlB4Uokv9XrAT1fcmwvGgf7l2U6LNDPk7fuaAHAjLUHWbgj84cNi4iIiEjJoHAlUhA6PA7N7wbTDj/cD2f2Zzqse6MqPNKlLgD/mbOdIzEJhVmliIiIiOQjhSuRgmAYcMvbUKMtJJ6Dz3pCYmzGcSunMNbjR1rWKk98YipPzNxKcqq90MsVERERkbxTuBIpKK4eMOQbcPOBhDPw8Y1gv6JxxcopsPwVrFYX3rurJb4eLmw7co43Fun+KxEREZGSSOFKpCD5BMB9v4DFBWL+gRn9HPsvBSu6T4CuY6lRwYs3/tUcgE9WR/LHrhNFWLSIiIiI5IbClUhBq94KbrvUNfDwOnixYrpglaZ3kwDu71QHgKd/2MbxcxeLoFgRERERyS2FK5HC0HQw3DDasW1PBYtrumCV5rm+jWha3Y9zCSk8NXMrKTbdfyUiIiJSUihciRQWF4/L2/YUWPZyhiHuLlbev7slPu4ubDp0lreW7MVmN1kfGcPm0wbrI2Ow2c1CLFpEREREcsqlqAsQKRNWToEVk6Hjv2HbTLhwEla9AVa3DDNYtSt689rtzXj8uy1MX7GfWRuOcDYhGbDy1b5NBPp5MLF/CH1CA4vms4iIiIhIpjRzJVLQrmxe0etFGPwZGJf+1Vv+iuP4Vfo1C6RLg0oAl4LVZdGxiTz2zRY9dFhERESkmFG4Eilodlv65hVBXaDbOMe2xQXiozO8xWY32Rsdn+np0hYFTpofoSWCIiIiIsWIwpVIQes+LmPzis7PQPCNjuYWB1dD0vl0hzdExhAdl5TlKU0gKjaRDZExBVCwiIiIiOSGwpVIUbBYYNAn4BMIp/fCb2PAvDwLdTI+MUenyek4ERERESl4ClciRcW7Egz+HAwrbJ8NW75yHqri45HNGy/L6TgRERERKXgKVyJFqXZHuOl5x/aC/0D03wCEBfkT6OeBkc1bA/08CAvyL/gaRURERCRHFK5EilrHf0P9XmBLgu/vg8Q4rBaDif1DALIMWCO7BWO1ZBe/RERERKQwKVyJFDWLBW77P/CtATH7Yf6/wTTpExrI9KGtCPBLv/TP5VKg+nRNJKfPZ930QkREREQKl8KVSHHg5Q//+sLRmn3nPNj4KQB9QgNZ8+yNfPNAG4bVt/HNA21Y/Wx3avp7cuhMAvd/sZELSalFXLyIiIiIgMKVSPFRMwx6THJsLxoPx7cCYLUYtAvyp3Ulk3ZB/gT6efLl/WH4e7vx97FYHvt2Cyk2exEWLiIiIiKgcCVSvHR4HBr2A1sy/DAcLp7LdFjdyuX4fHhbPF2trNp7imfnbMc09UBhERERkaKkcCVSnBgGDPwAyteCswfh58fTPf/qSi1qlufDoa2wWgzmbT3G6wv3FG6tIiIiIpKOwpVIceNZAf41A7DA7l9h/UcZx6ycAssn071hFV4b1BSAj1bu54s/Iwu1VBERERG5TOFKpDiq3hrq93BsLxqPcWzz5WMrp8DyV8BiBeBfbWryn94NAXjx1wh+3X68sKsVERERERSuRIqvu7+Hyo3AtGOd+S9cU89jWf2mI1h1nwBdxzqHjuwWzLAOtTFNGDN7G2v3n8ZmN1m3/ww/hx9j3f4z2Oy6J0tERESkILkUdQEikgXDgBGLYVozjMRz9P37cQzMDMHKMdRgYv8mnIpP4vcd0TzwxUbKebhw+nyyc0ygnwcT+4fQJzSwsD+JiIiISJmgmSuR4szDD+77BRMwMDEBgm/MdKjVYvD2kBbUq1KOxFR7umAFEB2byGPfbGHhjqgCL1tERESkLFK4Einu9i7CgEsBC/isJ/z5LtgzPtvK1WohPjEl09OkLQqcND9CSwRFRERECoDClUhxdql5ha3Lcyxo9hH2So57sFjyPHx3B1w4nW74hsgYTsQlZXk6E4iKTWRDZEwBFy4iIiJS9ihciRRXaV0Bu0/A3vkZUq1e2B5eDQ36Oo7/swQ+ugEOrnG+5WR8Yo5OndNxIiIiIpJzClcixZXdlrF5hWHA3bOg7UPg6Q/xUfBlf1jxOthtVPHxyNGpczpORERERHJO4UqkuOo+LkNXQKd+b8LoHdDiHscywRWvwlcDCKuUTKCfh+PerCxU8XEnLMi/QEoWERERKcuKPFx9+OGHBAUF4eHhQevWrVm9enW241euXEnr1q3x8PCgbt26fPTRR+mOz5gxA8MwMnwlJmoZlJQybt4w8EO47f/A1RsOrsb6fzfwXtszAFkGrIspNvZExxdenSIiIiJlRJGGq9mzZzNq1CgmTJjA1q1b6dy5M3379uXw4cOZjo+MjOTmm2+mc+fObN26lfHjx/PUU08xd+7cdON8fX2JiopK9+XhoWVQUko1vxMeWQlVQyHhNG3WPMTm6lOp7pv+MXZVfd2ZUG4+I1JnMeTjdWw8qKYWIiIiIvmpSB8i/NZbbzFixAgefPBBAKZNm8aiRYuYPn06kydPzjD+o48+olatWkybNg2Axo0bs2nTJt58801uv/125zjDMAgICMhxHUlJSSQlXe6wFhcXB0BKSgopKZm3tb5eaefJr/NJ2XLN68evDgxfiGXp/7Bu/hz/M5tZ5TOazUO+5Yi9IlV83Gl35HNcV89klt9Q4s+kcu9n63nvzuZ0a1C58D6IFAn990dyS9eO5IWuH8mL4nT9XE8NRRaukpOT2bx5M88991y6/b169WLt2rWZvmfdunX06tUr3b7evXvz2WefkZKSgqurKwDnz5+ndu3a2Gw2WrRowUsvvUTLli2zrGXy5MlMmjQpw/7Fixfj5eV1vR8tW0uWLMnX80nZcu3rpxuBdbxofegjrPHHaPlLT+x1RuKbeATXqHnsChyEtXIvQmx2Is7BI99s4Z5gO20q67lXZYH++yO5pWtH8kLXj+RFcbh+EhIScjy2yMLV6dOnsdlsVK1aNd3+qlWrEh0dnel7oqOjMx2fmprK6dOnCQwMpFGjRsyYMYOmTZsSFxfHO++8Q6dOndi2bRv169fP9Lzjxo1jzJgxztdxcXHUrFmTXr164evrm8dP6pCSksKSJUvo2bOnMwSK5NT1XT83Yz93P8ZXt+ASH0W7yHcAsHV5jnqdn6Ee0M9m57l5O/llexRf/2MlqGEj7m1fq8A/hxQN/fdHckvXjuSFrh/Ji+J0/aStasuJIl0WCI4lfFcyTTPDvmuNv3J/+/btad++vfN4p06daNWqFe+99x7vvvtupud0d3fH3d09w35XV9d8/4dZEOeUsiPH10/levDv7fBKVUc3QcCacAqr1QIWK66uMO3OlviXc2fG2oO8+Ntu4pPsPHVTvWz//ZOSTf/9kdzStSN5oetH8qI4XD/X8/OLrKFFpUqVsFqtGWapTp48mWF2Kk1AQECm411cXKhYsWKm77FYLLRt25Z9+/blT+EiJcWf0xzByrA6Xm/6DL4fBikXAbBYDCb2D2FUD8eM7ttL9zJpfgR2u4nNbrJu/xl+Dj/Guv1nsNm1bFBERETkWops5srNzY3WrVuzZMkSbrvtNuf+JUuWMGDAgEzf06FDB+bPn59u3+LFi2nTpk2WidI0TcLDw2natGn+FS9S3K2cAstfufwQ4h/uh53zYPev8NVAuGsmePljGAajejSgvKcrL8yPYMbag0RExXH4TALRcZcfXxDo58HE/iH0CQ0sus8kIiIiUswVaSv2MWPG8Omnn/L555+za9cuRo8ezeHDh3n00UcBx71Qw4YNc45/9NFHOXToEGPGjGHXrl18/vnnfPbZZzzzzDPOMZMmTWLRokUcOHCA8PBwRowYQXh4uPOcIqXe1cEK4F9fQMuhju0jf8EXfSH2qPMtwzsFMW1ICywGbIiMSResAKJjE3nsmy0s3BFVWJ9CREREpMQp0nA1ZMgQpk2bxosvvkiLFi1YtWoVCxYsoHbt2gBERUWle+ZVUFAQCxYsYMWKFc4ugO+++266Nuznzp3j4YcfpnHjxvTq1Ytjx46xatUqwsLCCv3ziRQJuy19sEoz4ANo+xC4lYNTu+HTnnAiwnm4f/Nq+HlmMQN86fuk+RFaIigiIiKShSJvaDFy5EhGjhyZ6bEZM2Zk2Ne1a1e2bNmS5fnefvtt3n777fwqT6Tk6T4u62P93oQbRsE3tzsC1ud94K7voM4NbIiM4WxC1s9xMIGo2EQ2RMbQITjzexxFREREyrIinbkSkSLgVwPu/x1qdYCkWPj6Ntj5EyfjE6/9XsjxOBEREZGyRuFKpCzy8od7f4RGt4AtGX4YTrNj3+forVV8PAq4OBEREZGSSeFKpKxy9YQ7voI2IwCToI0v8KL3HAyyvqfK1WpQ09+z8GoUERERKUEUrkTKMosV+k2FG/8LwDDbPH51G48rqRmGPmmdx+PGDwx4/0/W/nO6sCsVERERKfYUrkTKOsOALv+BW98HDJpYDrHMYyxeXL63arz3LzztOgf/cp6cuZDM0M/W8+GKf7Crc6CIiIiIk8KViDi0uhfung0WV2oSzdYKz/HRwOqsareRh22zoPsE7nj6PQa3roHdhCkL9/Dw15uJvZh1h0ERERGRskThSkQua9AbHlgErp64XzxJn4VdqbXtbej6LHQdi4erlTcGN+O1QU1xc7GwdNcJbn1/DTuPxwJgs5us23+Gn8OPsW7/GT0TS0RERMqUIn/OlYgUMzVawyNr4P02OB8fvP17qBoKjftjGAZ3htWiSTU/Hvt2M4fOJDDow7Xc2bYmiyNOEBV7eTlhoJ8HE/uH0Cc0sGg+i4iIiEgh0syViGS0cx5gguXS37+cjYTv74UZt8DxcACa1vDj1ydvoFvDyiSl2vly3aF0wQogOjaRx77ZwsIdUYVbv4iIiEgRULgSkfRWToHlr0D3CfC/M9D5Gcd+iwscWgMfd4OfRkJcFOW93Pjk3jaUc898EjxtUeCk+RFaIigiIiKlnsKViFx2ZbDqOtax76bnHa/tqVClCWBC+LfwXmtYOYUt+49zPilj6/Y0JhAVm8iGyJhC+QgiIiIiRUX3XInIZXZb+mCVJu213Qa3vgsLx8HRDbD8FZp5fsZ01xrsstfmXdvtGU75pHUeVsPOyfgWBV+/iIiISBFSuBKRy7qPy/rYlYFrxGLYMReWvoBn7BH6WqPpa91EoBHDuNSHnMOetM7jadc5TE0ZTEVvtwIsXERERKToaVmgiFw/w4Cmg+GJjdi7P88FPAC4y2U5C93GUsM4lS5YvWcbxKsLdrHjWGwRFy4iIiJScBSuRCT3XD2xdH2G9bcsYXZqN+wmNLIcZbXbv3nadQ7TUgbxnm0QXm5WIqLiGfDBn0z+fReJKbairlxEREQk3ylciUie3dimGX53fsRwt6nYTQPDcOzv77aRWX1g5X+6c0uzQGx2k/9beYDe01axdv9p5/v18GEREREpDXTPlYjkiz6hgfQ6fQbLChO7YcVi2gg2jxC84m6Iu4/3B77AgBbVef6nHRw6k8Ddn6znzrY1aVvHnzcX79HDh0VERKTE08yViOSPlVOwrHgVuk/AMjEGbhh9+diWL+H9tvRMXcni0Z0Z2r4WALM2HuHpH7bp4cMiIiJSKihciUjeZfZ8rB4vOF4DeFWChNMw7yF8f/gXL3f2YtbD7bFajExPp4cPi4iISEmkZYEiknfXej5WajK4esCqN+DACviwA9VCR2K1t8CGa6anvPLhwx2CKxZo+SIiIiL5QeFKRPIup8/HCh0Evz0N+5dRa9vb/OVejiW21jyb+kiGt+nhwyIiIlLSaFmgiBQe/7owdB7c/hnJHpXwN84zxGUlv7qOpwJxzmFpz8iymRaOn7uIaWppoIiIiBR/ClciUrguPYDY+tQm5ll6AxBqPcif7k8x2LqSp6xz0z18+PWFe7jrk7/YduRc0dYtIiIicg0KVyJSJKxeFfAa9A6Dkl7glN0XLyOZN13/jzGuc5mT2pn3bbfRM6Qqbi4W/joQw4AP/uTxb7dw8PSFdOfRM7JERESkuNA9VyJSZPqEBsI9d3LbLyGsSLoTF8MOwGCX1XQPTKHija9ytH9X3lqylx+3HuO3v6NYtDOau8Jq8dRN9dl8KIZJ8yP0jCwREREpFjRzJSJFqk9oIKs6huNi2LEbjs6BpmGl4qm/4NMbqbHoId7q7smCpzrTrWFlUu0mX/91iBteX8aj32zRM7JERESk2FC4EpGile7hw6eh+wQM0wYBzcCwwO5f4cP2NF4/jhm3BfLdQ+1oVt2XpFR7pqfTM7JERESkqChciUjRyezhw13HOl5Hb4e2D0KjW8C0Q/g38F4rOu6byvM3VmGUyxyetM7L9LRPWOcx5MI3bIiMKcQPIyIiImWd7rkSkaJzrYcP221w8xtwdBMsfQEOroa/PqTlphmkGHXo6BIBwHu2Qc63prVxn5oymJPx6ZcMioiIiBQkhSsRKTo5ffhwjTZw33zYvwz+mIRL1DY6WiNIMN142nUOVuxMsw1OF6zesw2i1/YoWtWqQE1/r4L/LCIiIlLmKVyJSMlgGFDvJqjbHVvEzxybO45aOJpWjHKdxxMuP+Fi2J3BCmBxxAmW7jpBv2bVeKRLXUKr+zlPZ7ObbIiM4WR8IlV8PAgL8sdqMYrko4mIiEjpoHAlIiWLxYI19DZ22VszffY7/NtlLgHGWVwMO6YJoZaD9DI3EtrtX2w6eoFVe08xf9tx5m87Tuf6lXikSzDxiSm8+KtauIuIiEj+UrgSkRKpd7NamJZn+O3HWEbYfsBugsWA3tZN9LZugq0zIHQwB1r1551dPvz6dzSr951m9b7TmZ4vrYX79KGtFLBEREQkV9QtUERKrD5nvmaE7QcONx/N/NsiiGow1HHArRxcPAsbP6HuT7fyzumH2dx1G0+2ds+yy6CJoxnG0R//pxbuIiIikiuauRKRkumKNu61uo6lFkCLD2Blbcf+Znc6Wrjvmg9n9lF+3WuMweCwpRK1LadwI5Wptjucp3vSOo8xrnOYmjiYDZExdAiuWGQfTUREREomhSsRKZly0sa9+zhIjINdv8C2WRgHV1PbcgqAJ11/4ibrFl5NvYdWxl7GuM51NsM4svEwDQN88Pd2y/RHqxmGiIiIZEbhSkRKppy2cffwhZZDoeVQNm/bzrLv32OQdTXBlihCLIf5xm0yABtsDVloDwPgp/Dj/PZ3FL2aBHBX21p0DK6I5VJ4Wrgjiknz1QxDREREMlK4EpEyo0XTpjyx4E4+jB1Ac2M/c90mYjUc91eFWfewxDqWCIJY49WDj2Na8dt2k9+2R1HT35MhbWpSsZw74+f9zdV3ZKkZhoiIiIAaWohIGWK1GEzsHwIYdLFsx2qYJJuOv2PaZ69GsmklhEgeTviEjZ5PsKjK+wx238DJmFjeXLyXE79M5Ak1wxAREZEsKFyJSJnSJzSQxa3+cjSvSBlMg6SvmJoymPqW4xxp9ADc/CZUb4Nh2mgYt5Y3jWn8Xe5JpvvMIIAYnnbN2G0wrRlGbKKdDZExRfTJREREpKhpWaCIlC0rp1A/4l3s3cbTseaD1ItPpIpPe+xHGhC84lWoNgEe+gNO74Nts2D7bNxij9CXxeAC5+xePO06h/LGeV5KHcaT1nk8fSmovWcbRL34xCx/tBphiIiIlG4KVyJStlzqMmjpOpYOV+4PfhYMw3EcoFJ9uOl5R0fCw2s5uXoGnv/8SnlLAgAjXBZyv3UhFgM+TunHe7ZBALy5aA9Hz17klmaB1K7o7Ty9GmGIiIiUfgpXIlK25LTLYBqLBercQMVanbjptd9pdv5PBllX09WyjbRJp4ddf6OVdR+/2tqz4Gw73lh0kTcW7aF5DT/6N6+Gt7uV8fN2qBGGiIhIKad7rkREcsBqMXju1pbMt3dki70+hgGppuM/oXYT2lj28oLrV6z3eILf/V5jmHUJR48e5uXfdnHilxfUCENERKQMULgSEcmhq5th1Ev6hqkpg7EYcCqgC9QIw8CkcdJ2XnT9go0ej/Oj9+uEGIfy1AjDZjdZt/8MP4cfY93+MwpiIiIixZSWBYqI5FQ2zTAqr3jVcX/W4M9h54+wcx6W41tpadsGVrCZBk+7zqGJ5SDPpjzMMOvidI0wzH9O06ZOBVyt6f/OS/dqiYiIlBwKVyIiOZWTZhjla0KnpxxfMQc4tOpbLmz5gRDLIQD6WDfR27IJw4CNtgbsMIMoRwLvL/+HL9cdpGuDytzUuApdG1RhQ+QZHvtmi+7VEhERKSEUrkREcup6m2H416XGrf/lhl0d8Yo7QD/LX4xymeNshNHWupcvrG+QalrYZdRlTWpj1u0IYfz2hiTiwWjXuTxhNZydCNOYwFPWeRz98SdsIR+rnbuIiEgxoXAlIlKArBaDif1DeOwbx7I+iwHJpgtuRip/24LwMRKoYzlBU/6hqcs/PMZ8UrESbg8m1bTQ3nU3Lth42/Yv5znT7tWamjiYDZExdAiumOXPt9lN1kfGsPm0QcXIGDrUq6IwJiIiUkAUrkREClhaI4z6EZfvsUp7+PC+kKeg9yMQuRoOrobIVbjEHqGNZa/z/f92/ZFB1tXMsXUlwDjDXS4rnOdJ2XuSZjX88HbP+J/z9PdrWflq3ybdryUiIlKAFK5ERApaNo0w6q94Far6OJYVtrgLTBPOHmT/ht/Z/uevdLBEEGCcpablNKMtcwFIMl1oZjnAcBaydFUon64+QIuaFehYrxIdgyvSslZ5jsx9nojtJ4i6aklhdGwiETP/S71mVak35NWi+G2IiIiUWgpXIiIFLSeNMNIYBvgHUafXYwzd2pDo2IvUMaJZ4vYfXAw7pgnuRio9rVvoad0CQLRZgT+Ph7LmSChP/RFKrIs/jxknGeM6BxPS3bP1xKUlhR/vvZMgu6klgiIiIvlI4UpEpKBdbyMMrrxXawv9LetwMewkmS64G6l8k3oTR80qPFj9EJVithCQepbbrau53boagD32GvxpD+XH1E487ToHIN1SxKkpg3kv8VaaZnO/ls1usiEyhpPxiVTx8SAsyF9BTERE5BoUrkREiqlr3atV6Y6PICURjvwFB1bAgRWYx8NpaDlKQ8tR4PLztUa5zMNq2Pm/lH7OmaxPVx/gfFIqrWtXwN/bzfFDl09m36kEhu3vluHZWl8Fr6B+Za/sw6KIiEgZpnAlIlJcXeterZWX7tWq283xBRgJMez56zc2LfuRTpYd1LGcAMBq2AF4xPU3BrisZZs9mPB99fh8bzCj7UFUrVyZtnX86XX6NDdGfcrglOO8x+XlhP86/x31Ixyhrn42JWvGS0REyjKFKxGR4up67tVK4+VPvW5DGb6+Gv+NTWS8y9c85PI7NtPAapjYTQgwzhJg3URv6ybHjzEN9sdWY1t4MMvswRw3bsqwnHCM6xzeShnMD/u7sSaLe7XSdyd0UHdCEREpSxSuRESKq1zcqwWX79eKmPlfHnL5PcOSwtmp3WjeKoxGtn1wbDOWc4epbxyjPscYbF0FQKppubSccC5Ww2Rmanc+s/XlQmwik37Zya0tqhFSzRcvN8f/Rv6ZPV7dCUVEpMxTuBIRKYX6nPmaPq5z+Nh6J+8l3go4ZqF8PFx4mFlQsRN0neEYfP4UHNvMni0riI74k+aW/ZQ3LgBgNUwA7nJZzl0uyzlir8zuzbVYt6kmX5o1uVihIeVrNKbO7lN57k6oJYUiIlLSKVyJiJRGl5YUjuj8H0L+Ocni1evp1bkdHerdDKuD0y8pLFcZGvYhxqUt923rDJg87/I1I1wWYjMtWA07500PyhmJ1LScoian6Mlmx3vPQ9IuV/4xq7GTWjztOoc6RjSvp97FEOvyHHcn1JJCEREpDRSuRERKo0tLCq1AuyB/zuwyaZc2E5TFksKwIH8C/Tz41/nvGOGyMMNywg9TbmWHVxvev8kdy8mdpBzfgXF6N+6pCTQxDjnPc7vLGm53WQPAIXtl/IwL3G5Zxbc/n2Jto1Y0qF6JxoE+1KnojYvVkuclhZrxEhGR4kLhSkREAMe9Wl8Fr6B+hKN5RdryvvdsgzCAMa5z2Fe/Dpb2LwHgCmC3s2X7Nj76/mcaGkdoaDlCP8t6jEvZprblFA9afne8iIOU9Vb2m9XYYdbkR+oQ79eQWnFHGOP6S66WFGrGS0REihOFKxERcapf2Yt9IU/xw/5ucEVg+aHc3fQPruZ4ztWVLBaaN2vB37/HsCQ2kSeYxy3W9SSbLrgZqSyyteG4WZGmLkdp6nIE99Q4GhlHaMQRYC2cByxwwXTnadc5dLFs53t7N1oZ+7jLZblzSWHQrhP0bBKQ7kfnRxMNzXqJiEh+UrgSEZHLuo+jPrAm09BxU6ZvubI74RjXjA88fitlMKcHz8W9SQDEHYPoHdijd3DxSDgXj2yjQuIRvI0kANpa99LWutd57uEui+hi3c6BmdV4x60myeXr4lalIeVr1OfC7tN5aqKhWS8REclvClciIpKB1WJk2XwiM9l1JxzDLDjTEIyx4FcD/GpgadgHb2D7/jPc/8lKGhhHaWw5zKsun2I1TEzT8SivikY8FY142lr2gh2IcXyl7LJy2KzCP1Tjadc5hFoi+SS1Hz0sW3jU9ddrNtHQfV4iIlIQFK5ERCTvruhO2DRd6MikO+EVwoL8qeDnx9+x7nRlG1bDJMl0wd1I5d2UgSyyh9HK+zQT2rlwMXo3nNqH9/mDuNkvEmxEOc/T27qZ3lZHB8Nk08rN1g2EWA6x++tq7PCrDRXr4lm1PpWq1aFmRR/W7D2Tu1mv5ZPZdyqBYfu7ZZjx+ip4hWPZZHbPJxMRkVJN4UpERPLuiu6EGWaKcvjA48yWFKamuBAy8GU8QgPxSHuTabL5751MnfUbwcZx6hpR3GddjOXSjJebYaOxcZjGHHaMj730dQCSTBeOmFWoZ1ZlM/V42nUOQUY0H9gGMMDyJ0+5/pTtrNe+UwnUj3iXwSnHeY/Loexf57+jfsQc9oU8Rf1sfk2a8RIRKd0UrkREpEjlaEkhVwQ0w6BFaBMifU6wLjaRJ6zzsFwx4/V5ah9W25vSxDOGexvYMGMO4BZ3CN+Lx3A3UqlnHKcex52nG+SyhkGXWsdfNN3oY91IM0skR78LYF6FmljK18SzUm3KBwTx5N7ODEk5ztOuc5x1PnlptuutlMH8sL8bazTjJSJSZilciYhI0crFksJrzXidSylHyG0vU/XKxhR2G8QeZefObXz7+wpqG9HUNk7Sy7KRtCzkaSTTxDhEEw6BDTh96esfx/E1ppVoqz9H7JV42nUO/3aZh4th5/vULsyzd+Zk7AXW7T/NDfUrp6s3rzNeoFkvEZGSQOFKRESKVi6XFF73jJfFChVq06hjLZav9ib60qxXH+tG56zXl6k9WWlvQQOPc9xR38AeewTX+OOUSzxOedsZ3AwbtYxTzlO6GHYA7nBZxR0uq0gxrUR97c8mawDn3KtxsVwNbL41mXOgCjek3HL9M16Q51kvhTIRkcKjcCUiIiVTLptoXGvW60yKHyGDXqbuVe3Y1+07wdOfLaSacZr7rQvp57IBm2lgNUxi7OXwNhJxN1KpZZyilnkKEv+GROA0DARwhRTTwtOucxjtMheLYbLO1ogYfAiNX8MX38fQoF4DKlSpTkAFHyp6u2GxGLmf9cqHULY+MobNpw0qRsbQoV4VhTIRkWtQuBIRkZIplzNekItZLyAsuAqmXw06nl9FP5cNmTzP63ZWePfmiwFVOX9iP0mnDsC5Q9hjDlIuMYpAzuB6aabLYpgAdLDupoN1t+MH7HZ82U2DM/iwmwqcs1bkaKofp83GPO06h2DjOF/Y+tDPsp6HXX/LdtYrL0sR0z8DzMpX+zZd1zPANFsmImWVwpWIiJQ9ubzP66vgFdSPcCzlS2vh/p5tEAYwxnUO/etVp2KTIVRs0s35vnX7z9Dnk79wJZVnXWbyoMvvpJoWXAw74ba6nMCfqsZZarjEUt5+FhfDRmXiqEwc2A+B5XINA13WMtBlrfP1fS6LuPnieja95E+ie2WSPCtj966K4VuVmRGV6Jza57qXIub1GWB6OLOIlGUKVyIiUvbkctarfmUv9oU8xQ/7u8EV4eGHcnfTP7iaY6ndVcKC/An08+Bf57/jQZffM5nxasUL5caz5tkbsWJCwhlSYo8Td/IIm3fuZvuu3VQxzlHVOEtPyyYsBhkesox5xLEEMRE46/i5vcH5f/mnXecwxmUOhgF77DWoYMRz2/lZzPq/dfhXrYl7+UA8/avhVaEq6/bk8hlg5CGYLZ8MFiu2zv/JOOO1+o1LYVjdFEWk+FO4EhERyanu46gPrMl02dtNmb4lRzNewdUuvd+AcpVxLVeZitWb4+Pbgfd3/AXAk9Z59LZucjbf+DClPz/bO1HFOMdDLTypTCz2+CgsF05CfDSeSaepYpzDy0gCHGEMoKHlKA0tRx0vTlz6ukIN04dTpi9Pu86hr3UDa+xNaWQcoot1Bz+ldmRhUiNc5i+lSb26lPevhH85Dyp4uWIYBsty+3BmixWWv8Jnq/bz6oVbnbv/v707j46yvvc4/n7mmSUrkSUkRMBG2UHolbAEUJRNolJEqVQsxbpdDkvB4K3SygGVil2uRS+C1VqrdYEDiNBbRKIiyiqKkYgRUWnhVjCChuyTWZ77R5Ih4yRAJkMmgc/rnDkn82z8hnwPzsff9qv49dzlWwFX/fq0v5pwhyJqCKOIRJLClYiISAOZNiO0x+sUwunxguBer7oW36jwuFiVMJmhE0cEBYIdXxwn6+mdgMVccxWzHK/isUwcho+3fD8k3+pMMifo1aqcJF8h8d7jJPm+w8Rf1RNW/ahetkP0sh0KPDcwLPFD4EPwWja+I5EvrESKjFZc6E/gIy5mrmM1/2H7nL/7Mhlu+4jr7dv5m3cUf3MPouN7HzO0zyW0io/FqE58G9tO4RPPfrJZQbHpDXzGu3xVgbRX2ymMre8vtxELdzRmCKNCmYjUReFKRETkbAujxwsa2ut1Uu1QNsvxakgoy/V04Y8Js9l6T61Q5vezO/9z7n/hTZKNEyRTyO8df8Ju+PFZBlv8/WhjFNOaYpJtxcRRjt3wk8wJko0T1Q0+2YYRZi4jzNzA+yn2N5hifwM2AhurNmwuNeIoN+Lo4Isl3hbLZ/4LmetYzRz7GkzD4g3fZXxupbH/lRX0MYfRqk0KCa2TsTljA88Nd+GOxgxhbOyG0ApmIucuhSsREZEm0tAeLwiv1yusUGazcVnPrhS1Osxn1XuA2Q1/YBjih/4uLPXdQGpSDFvvHQH+Sij7Fl/JN5R89zWffHGQ13Z9HAhgPzXfwDQs/BZ8aaWRaJSRQDnx1cMUY41KYqkEq5BOtu+1v3o1xVHmHkaZe8APrDx5vhwXRUYixbYkCjxx+OjIXMdqhtj2kePPYIDxKVn23bzsvZI1+y/mv//5Ja1aJ9MqMQHTZuDzW2EPYWzUhtBR3LNMgU6kaShciYiINGdh9nqFG8pOtQeYAfQat6jqS7nNBa06YLbqQFIaDOxpkb3vrcDmzKZhBYLZOu+Qk8Hsv67AW36CosLjlJz4jl35B8n58ACJlHOduYNR5of4LBum4edzfxrfkkhrSmhtFHMBJdgNP7G4ibXcpPiO0aVWMMs088k08wPvb7a/zc2+t+GvVe/LLBdFJFBsxNPXH88B0pjrWM0Vtr1s8fejv+0zrjI/Yr13MFsrL6L9/66lW+cOxCVeQFzCBcTEJzHliyv5seersDaEjsqeZdqEWqRJKVyJiIi0AA3u9QozlIWzB1hN+84omNkdmIntSE5sR3InOBrblTc/aMUs8xVGmR+G3Ffz/uU7B3NZ5yQKC7+lpPBryk98w0efHWTnx5/TxijmAqOYGea66t4ygzwrnSRKucAooRVl2AyLOMNNHG5SOU7XWqFsgPkZA8zPAu9/ZN/Jj9gJe6h61bLFclBij6HQHx+0IfSn/o50MI5zW+mfeWv5epJat8WMScSMTcIZl4gZ04oH9ndmhDeLuY7VmPhZ4pt4RsGsMb1lLXETagU6ackUrkRERM5hDQ5ltfYA6/V5AZve3cWYyweR2aX+PcBqhLU5c3qb6lUBTwapmvugahn5xBg7A9OvwbQZuJLb0y65PQCFrY9z396TqynW7i17w3tZ4Bkv3zGQjFST0hPHKC08Rv7BQ7y6/WOSjFKSKGGufTVmrbll8UYFCZSTZLqJt8qIpZwYPAC4DA8uPIFFP2o2hO5h+z961KzC+E3163tegsA3rzmOV5htfwXDgBNWHNeYuxhe/hF7FyeCKwGfIx6fPQG/I45d/67kUv8PmetYTRfj36zyX8m1tp3cbN/MM96xrDnQl5e+O05iYhKm/eRXO5/f4mdfXMnEMHraIhfKTm5C3Vx72RTmJJIUrkREROSkWnuADUpvw/F8i0E1XzZPsQcYEPbmzCO6teXRvRNZ+r3FJZZWzxH7Uc+2dX7ZPd1qigZVwyAHXtwO02ZwQUIbLriwG6k9M5mfl1xrCGP9c8tq/lzLW8m2/H/xyxe3k2CU83NzIzfbNwetwrjH35UEo4JuF1gkGBU4vCU4vGW4fKU4/WXEWWXEUxGyPH6SUUaSUVb1xlP9qiXTILBYyHj7DsazI3DudvtGbvdshMeq3ldYDsqNGNzEUG64eNLnpNx08aU/NWixkPd83QG4rmQ1bz6/k9TktjhiEnDExmN3xfPgZx0Z4R3DXMdqYqjkMd+N/Kf593Orl62Rwy0bszeb5s+duxSuREREJDLC3Jy5y6SH6dX7CKnfWxY9NSmGXuMW0aWeZdHDXU2xQXPLqhl2J5m9u2AlHWJsyUvcbN8cugqjvwvPxf+crdkjQr7s7vjiODc/XdXLNttcw92ONVRadpyGl5e8I/iHfxAJVHBtjwSSHR4sdwlUllBS9B0nCr8L9KYNs32MzbCwLDhGErFUDXWs6UGLMTzVvWzFYAH1LBYy0NzPQHN/1cF/Vr9q+RsEviXOcKxnhmM9UBXeJtvfZHz5Ng7+JhafPR6PLRavPRavGcv+7yy+83dnrmM1/W2fsck/gGHGXq6x7+YV71A2ftqG2e+9iSs2HkdMPK7YeGJiE7C74phyYHhY89nCDWWNWpwk3L3ZWuD8OQXBhlG4EhERkagb26cDo3ulNviLWLh7iIUzhDHcMAfBvWx3O9aEBLOjnjasSpjMsp+G7ll219Mnhz5eYeYFetme94yuboPF337Wlz7JDirKinCXFVNZXsKBw1+zZtdnxOFmnLmDq8338Vo27Iaf931d2W91JtZwkxrrIxY3Tl85Dr8bh7+cGNzEUUEMlbgMb6A9MYaHVL6rGhbpq37VklGrl+1Kcy9XmnsD526wb+MG/zbYUPfvcrtlUG53UmY5metYTbZ9NYYBX/sv4EozlyHl+/j4kRhMRwyW6ax62RzsP+am2N+FuY7VDLV9zDZ/H/rbPuNKcy8bfRm8nW/n9ndX4YhJwHTF4YiJx+aKY86BS8ny/CisxUnC3ZvtfOrZi9acvWhTuBIREZFmIZyl6sNduCOcIYwQfpiLxJ5lpxr6OKRHp+ovnyd7+S75ocWiT97ixyUvcbX5fsi973j6sSp+ctDwRwjuZau5tqaX7S/esazxXU4cbm7+jzakxvixKkuhspSC48c59PWxqqGPuJlkbg4sMLLb6k4sbmKoJN7mIQY3LiqJsdzYDT9QNX8tHnegHTXDJlNshaRQWPWmsvpVS79agW6w+SmDzU8D58aa7zPWeh/eDP2d/APAUfVz7TBXbMUw0dzCj8q3c3CRC7/pwm9z4DOc+E0nfpsDzwkfFxoOcn0XVw+3rBpeutXXm3KcfLT6t6Qe6IzdGYPN7sLmcGGzu3js0ySu8A5nrmM17Y1CnvONYZK5mTvtr7HUM56Vnw/lbZ8f0wzucozG/LnmEQQbMGevmVC4EhERkRYvnNUUoeFDGMMOczThnmWNvPd0ga7QSmBVwmTGTwwNZXc/XfcCI1u9fU4uMHLn4KC/c5+nkm35h5n70k5iDDe3m69xq31TYD7bK95hvOYfiBMvo7pdQNtY8HsrsTxuviks5vA3hTgML0683Gn+A9Ow8FkGr/sHVC3bb1SSYKvaV82FG5dVFfJiORns4GSYSzQqSDSqfz/+6tf39LMRNOTSrH7OMHMfw8x9VQc/Cr3vCQh8+w5srF1tpmMdMyvX4XvQoMxw4saFGyeVhhM3Tp7w2amwOUPmz+31pdPGKOK20j+T8/gqEuLjMEwnht0JpoO3DpQxwNefuY7VdDcO83d/JmNt7zHBvp1V3it4fX877tvzFk6nC9PuxO50YpgO7jnQkyzPdcx1rMaFh6W+6/lP83+527HmlGEuKgupNCMKVyIiIiIN1JS9bOH2loV779nuZRuY3ib4z3M4GdrnYuxJ/2RCyUvcat8Ucu8/PamsSpjM4z8LDXS/rCfQ5fs7BwW6PrV+Xzu+OMbNT+/Cjpc55hpmOtZRaZk4DR9/845irW8YTsPL5P4ppCWY+DwVWJ4K/F43Xx0rJP//juHCw+W2PDLNfHyWgWlY5Pl+wAE64sRLa5dFjM2H6a/EbnnA58H0V+LAixMPnYxvMAywLLAwAvPmTMMirnouHVA1dw7qnT/X1zxIXw5WHSysftUyBAI9e9fZd3EduwLnfmx/hx/73oH1IWXAOgj07M10rGOmYx0Afgtm2NdxZ8U/KH7Qjtdw4DNMfDjwGXYqsbPcY1Bp2jnkTw7asiDf34nOtgJ+Ufo/bH/8eRLiYrHMqjDntzl498sT/NDXl7mO1fS1fcnr/gF05mt+4Xj1tEM1mwuFKxEREZEm1FR7ljXm3nOll62+QDcwvW3gvpmOdSH3fWNdwKqEyVw7oe7FSe55eiezzFfINPND7t3kyajam+3WwfQPCnShwy1rguCjnht5yncdLir5/fhudG/nwF9Zhtddjr+yjINHjrN29+fE4OFac2fQ/Lmtvt58YHXDiZceyTEk2P3gr8TweSivKKe4tLw60Hm53JaHzbDwW/CJ9QMceLHjw2XzYceH3fJiUvWzEy92vIEQV8NmgIvqLQmgKvwFXxISBGuCY0/bYXpyuOpgISFBsD8EguBocw+jzaqN5gLbNJyo4L2D3zb8f2w0IYUrERERkRYgrN6ycO89x3vZGrs4yZnuzfb9+84kCI4a9MOQQNfVb/Hgp/XPn3vP05PnE6awdVZoz970WoFuuLk3EOhe92bUO1SzpmcP4BfmGrJrrW75pOc6nvNdjcPwkn3VRaS3duHzuvF73Pi9bg4dK2JD7iEceBln28F19l2BILjZ148d/l448NGzvYsEh4Xh82D4PZSVl1NUUobD8OLAyzW297AZFpWWPdBOgILik7XRHClciYiIiEidGhPKdgRtQt2+WfWyNea+cPdma6k9e9l1rG5ZRkzV39Oo0J69/n6L//6iKgheZ98Vcu+H/q6sSphcZxCcVisIXmfuCgTBWeYrgc/cPjGmzt9Lc6FwJSIiIiIRZdqM0E2oG3BvkwybbMRwy3D3ZjsfevaaOgg2NwpXIiIiItLihTtsMtz7wtqbrYXMn2vMfeHe25hA15xEPVwtW7aM3//+9xw5coTevXuzZMkSLr/88nqv37JlC9nZ2ezbt4+0tDR++ctfMm3atKBr1qxZw/z58/niiy+45JJL+M1vfsOECRPO9kcRERERkfNIUwe6sO6NQs9eNObsNRdRDVcrV65kzpw5LFu2jKFDh/KnP/2JrKwsPvnkEzp37hxy/cGDB7nmmmu48847eeGFF9i2bRvTp08nOTmZG2+8EYAdO3YwadIkHnroISZMmMDatWu56aab2Lp1K4MGDWrqjygiIiIiEnUtLQg2eM5eM2E7/SVnz6OPPsrtt9/OHXfcQc+ePVmyZAmdOnVi+fLldV7/5JNP0rlzZ5YsWULPnj254447uO222/jDH/4QuGbJkiWMHj2aefPm0aNHD+bNm8fIkSNZsmRJE30qEREREREJV82cvf7tGj5nL9qi1nNVWVnJBx98wH333Rd0fMyYMWzfvr3Oe3bs2MGYMWOCjl199dU888wzeDweHA4HO3bs4O677w655lThyu1243a7A++LiooA8Hg8eDyehnysetU8J1LPk/OL6kcaQ/Uj4VLtSGOofqQxmlP9NKQNUQtXx44dw+fzkZKSEnQ8JSWFo0eP1nnP0aNH67ze6/Vy7NgxOnToUO819T0TYPHixTzwwAMhxzdt2kRcXGTHdubk5ET0eXJ+Uf1IY6h+JFyqHWkM1Y80RnOon7KysjO+NuoLWhhGcDefZVkhx053/fePN/SZ8+bNIzs7O/C+qKiITp06MWbMGFq1anX6D3EGPB4POTk5jB49GofDEZFnyvlD9SONofqRcKl2pDFUP9IYzal+aka1nYmohat27dphmmZIj1JBQUFIz1ON1NTUOq+32+20bdv2lNfU90wAl8uFy+UKOe5wOCL+yzwbz5Tzh+pHGkP1I+FS7UhjqH6kMZpD/TTkz4/aghZOp5P+/fuHdPXl5OQwZMiQOu/JzMwMuX7Tpk1kZGQEPnR919T3TBERERERkUiI6rDA7OxspkyZQkZGBpmZmTz11FMcOnQosG/VvHnz+Pe//83zzz8PwLRp01i6dCnZ2dnceeed7Nixg2eeeYaXX3458MzZs2dzxRVX8Nvf/pbx48ezbt063njjDbZu3RqVzygiIiIiIueHqIarSZMmcfz4cR588EGOHDlCnz592LBhAxdddBEAR44c4dChQ4Hr09PT2bBhA3fffTdPPPEEaWlpPP7444E9rgCGDBnCihUruP/++5k/fz6XXHIJK1eu1B5XIiIiIiJyVkV9QYvp06czffr0Os/99a9/DTk2fPhw9uzZc8pnTpw4kYkTJ0aieSIiIiIiImckqpsIi4iIiIiInCsUrkRERERERCJA4UpERERERCQCFK5EREREREQiQOFKREREREQkAqK+WmBzZFkWAEVFRRF7psfjoaysjKKioqjvMi0tj+pHGkP1I+FS7UhjqH6kMZpT/dRkgpqMcCoKV3UoLi4GoFOnTlFuiYiIiIiINAfFxcUkJSWd8hrDOpMIdp7x+/189dVXJCYmYhhGRJ5ZVFREp06dOHz4MK1atYrIM+X8ofqRxlD9SLhUO9IYqh9pjOZUP5ZlUVxcTFpaGjbbqWdVqeeqDjabjY4dO56VZ7dq1SrqBSItl+pHGkP1I+FS7UhjqH6kMZpL/Zyux6qGFrQQERERERGJAIUrERERERGRCFC4aiIul4sFCxbgcrmi3RRpgVQ/0hiqHwmXakcaQ/UjjdFS60cLWoiIiIiIiESAeq5EREREREQiQOFKREREREQkAhSuREREREREIkDhSkREREREJAIUrprIsmXLSE9PJyYmhv79+/Puu+9Gu0nSDL3zzjuMGzeOtLQ0DMPg1VdfDTpvWRYLFy4kLS2N2NhYrrzySvbt2xedxkqzsnjxYgYMGEBiYiLt27fn+uuvZ//+/UHXqH6kPsuXL6dv376BzTozMzN57bXXAudVO3KmFi9ejGEYzJkzJ3BM9SP1WbhwIYZhBL1SU1MD51ti7ShcNYGVK1cyZ84cfv3rX/Phhx9y+eWXk5WVxaFDh6LdNGlmSktL6devH0uXLq3z/O9+9zseffRRli5dyu7du0lNTWX06NEUFxc3cUuludmyZQszZsxg586d5OTk4PV6GTNmDKWlpYFrVD9Sn44dO/LII4/w/vvv8/777zNixAjGjx8f+BKj2pEzsXv3bp566in69u0bdFz1I6fSu3dvjhw5Enjl5eUFzrXI2rHkrBs4cKA1bdq0oGM9evSw7rvvvii1SFoCwFq7dm3gvd/vt1JTU61HHnkkcKyiosJKSkqynnzyySi0UJqzgoICC7C2bNliWZbqRxqudevW1p///GfVjpyR4uJiq2vXrlZOTo41fPhwa/bs2ZZl6d8eObUFCxZY/fr1q/NcS60d9VydZZWVlXzwwQeMGTMm6PiYMWPYvn17lFolLdHBgwc5evRoUC25XC6GDx+uWpIQJ06cAKBNmzaA6kfOnM/nY8WKFZSWlpKZmanakTMyY8YMrr32WkaNGhV0XPUjp3PgwAHS0tJIT0/nJz/5CV9++SXQcmvHHu0GnOuOHTuGz+cjJSUl6HhKSgpHjx6NUqukJaqpl7pq6V//+lc0miTNlGVZZGdnM2zYMPr06QOofuT08vLyyMzMpKKigoSEBNauXUuvXr0CX2JUO1KfFStWsGfPHnbv3h1yTv/2yKkMGjSI559/nm7duvH111+zaNEihgwZwr59+1ps7ShcNRHDMILeW5YVckzkTKiW5HRmzpzJ3r172bp1a8g51Y/Up3v37uTm5lJYWMiaNWuYOnUqW7ZsCZxX7UhdDh8+zOzZs9m0aRMxMTH1Xqf6kbpkZWUFfr700kvJzMzkkksu4bnnnmPw4MFAy6sdDQs8y9q1a4dpmiG9VAUFBSFJXORUalbPUS3JqcyaNYv169ezefNmOnbsGDiu+pHTcTqddOnShYyMDBYvXky/fv147LHHVDtySh988AEFBQX0798fu92O3W5ny5YtPP7449jt9kCNqH7kTMTHx3PppZdy4MCBFvtvj8LVWeZ0Ounfvz85OTlBx3NychgyZEiUWiUtUXp6OqmpqUG1VFlZyZYtW1RLgmVZzJw5k1deeYW33nqL9PT0oPOqH2koy7Jwu92qHTmlkSNHkpeXR25ubuCVkZHBLbfcQm5uLhdffLHqR86Y2+0mPz+fDh06tNh/ezQssAlkZ2czZcoUMjIyyMzM5KmnnuLQoUNMmzYt2k2TZqakpITPP/888P7gwYPk5ubSpk0bOnfuzJw5c3j44Yfp2rUrXbt25eGHHyYuLo7JkydHsdXSHMyYMYOXXnqJdevWkZiYGPg/fUlJScTGxgb2nVH9SF1+9atfkZWVRadOnSguLmbFihW8/fbbbNy4UbUjp5SYmBiY21kjPj6etm3bBo6rfqQ+99xzD+PGjaNz584UFBSwaNEiioqKmDp1asv9tydq6xSeZ5544gnroosuspxOp3XZZZcFlkcWqW3z5s0WEPKaOnWqZVlVy5IuWLDASk1NtVwul3XFFVdYeXl50W20NAt11Q1gPfvss4FrVD9Sn9tuuy3w36jk5GRr5MiR1qZNmwLnVTvSELWXYrcs1Y/Ub9KkSVaHDh0sh8NhpaWlWTfccIO1b9++wPmWWDuGZVlWlHKdiIiIiIjIOUNzrkRERERERCJA4UpERERERCQCFK5EREREREQiQOFKREREREQkAhSuREREREREIkDhSkREREREJAIUrkRERERERCJA4UpERERERCQCFK5EREQizDAMXn311Wg3Q0REmpjClYiInFNuvfVWDMMIeY0dOzbaTRMRkXOcPdoNEBERibSxY8fy7LPPBh1zuVxRao2IiJwv1HMlIiLnHJfLRWpqatCrdevWQNWQveXLl5OVlUVsbCzp6emsWrUq6P68vDxGjBhBbGwsbdu25a677qKkpCTomr/85S/07t0bl8tFhw4dmDlzZtD5Y8eOMWHCBOLi4ujatSvr168/ux9aRESiTuFKRETOO/Pnz+fGG2/ko48+4qc//Sk333wz+fn5AJSVlTF27Fhat27N7t27WbVqFW+88UZQeFq+fDkzZszgrrvuIi8vj/Xr19OlS5egP+OBBx7gpptuYu/evVxzzTXccsstfPvtt036OUVEpGkZlmVZ0W6EiIhIpNx666288MILxMTEBB2/9957mT9/PoZhMG3aNJYvXx44N3jwYC677DKWLVvG008/zb333svhw4eJj48HYMOGDYwbN46vvvqKlJQULrzwQn7+85+zaNGiOttgGAb3338/Dz30EAClpaUkJiayYcMGzf0SETmHac6ViIicc6666qqg8ATQpk2bwM+ZmZlB5zIzM8nNzQUgPz+ffv36BYIVwNChQ/H7/ezfvx/DMPjqq68YOXLkKdvQt2/fwM/x8fEkJiZSUFAQ7kcSEZEWQOFKRETOOfHx8SHD9E7HMAwALMsK/FzXNbGxsWf0PIfDEXKv3+9vUJtERKRl0ZwrERE57+zcuTPkfY8ePQDo1asXubm5lJaWBs5v27YNm81Gt27dSExM5Ac/+AFvvvlmk7ZZRESaP/VciYjIOcftdnP06NGgY3a7nXbt2gGwatUqMjIyGDZsGC+++CLvvfcezzzzDAC33HILCxYsYOrUqSxcuJBvvvmGWbNmMWXKFFJSUgBYuHAh06ZNo3379mRlZVFcXMy2bduYNWtW035QERFpVhSuRETknLNx40Y6dOgQdKx79+58+umnQNVKfitWrGD69Omkpqby4osv0qtXLwDi4uJ4/fXXmT17NgMGDCAuLo4bb7yRRx99NPCsqVOnUlFRwR//+Efuuece2rVrx8SJE5vuA4qISLOk1QJFROS8YhgGa9eu5frrr492U0RE5ByjOVciIiIiIiIRoHAlIiIiIiISAZpzJSIi5xWNhhcRkbNFPVciIiIiIiIRoHAlIiIiIiISAQpXIiIiIiIiEaBwJSIiIiIiEgEKVyIiIiIiIhGgcCUiIiIiIhIBClciIiIiIiIRoHAlIiIiIiISAf8Pq/QdFTyb/iMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:26.189629Z",
     "iopub.status.busy": "2025-05-08T18:54:26.189629Z",
     "iopub.status.idle": "2025-05-08T18:54:26.336488Z",
     "shell.execute_reply": "2025-05-08T18:54:26.336488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/12 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:26.339493Z",
     "iopub.status.busy": "2025-05-08T18:54:26.338493Z",
     "iopub.status.idle": "2025-05-08T18:54:26.344061Z",
     "shell.execute_reply": "2025-05-08T18:54:26.344061Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:26.346066Z",
     "iopub.status.busy": "2025-05-08T18:54:26.346066Z",
     "iopub.status.idle": "2025-05-08T18:54:35.614686Z",
     "shell.execute_reply": "2025-05-08T18:54:35.614686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] completed, Average Training Loss: 2.6441\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss improved from inf to 2.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.5932\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.5641\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.5527\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.5241\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.5080\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.4806\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.4743\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.4643\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.4515\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.4287\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.4262\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 2.4100\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.3880\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.3892\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000] completed, Average Training Loss: 2.3649\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 2.3514\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.3400\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.3220\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.3192\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.3193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 2.2970\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 2.2908\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 2.2704\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.2746\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 2.2540\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.2389\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.2379\n",
      "    Validation Batch [1/1], Loss: 2.6430\n",
      "Validation Loss: 2.6430, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.2257\n",
      "    Validation Batch [1/1], Loss: 2.6430\n",
      "Validation Loss: 2.6430, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.2089\n",
      "    Validation Batch [1/1], Loss: 2.6430\n",
      "Validation Loss: 2.6430, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.2076\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 2.1925\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 2.1588\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6427 to 2.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 2.1720\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6427 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 2.1543\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 2.1282\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/1000] completed, Average Training Loss: 2.1434\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 2.1306\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n",
      "Epoch [39/1000] completed, Average Training Loss: 2.1224\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 2.1164\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 2.1006\n",
      "    Validation Batch [1/1], Loss: 2.6425\n",
      "Validation Loss: 2.6425, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6425. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 2.1057\n",
      "    Validation Batch [1/1], Loss: 2.6422\n",
      "Validation Loss: 2.6422, Validation Accuracy: 11.43%\n",
      "Validation loss improved from 2.6425 to 2.6422. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 2.0898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.6418\n",
      "Validation Loss: 2.6418, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6422 to 2.6418. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 2.0808\n",
      "    Validation Batch [1/1], Loss: 2.6416\n",
      "Validation Loss: 2.6416, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6418 to 2.6416. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 2.0716\n",
      "    Validation Batch [1/1], Loss: 2.6411\n",
      "Validation Loss: 2.6411, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.6416 to 2.6411. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 2.0614\n",
      "    Validation Batch [1/1], Loss: 2.6404\n",
      "Validation Loss: 2.6404, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6411 to 2.6404. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 2.0622\n",
      "    Validation Batch [1/1], Loss: 2.6395\n",
      "Validation Loss: 2.6395, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6404 to 2.6395. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 2.0323\n",
      "    Validation Batch [1/1], Loss: 2.6383\n",
      "Validation Loss: 2.6383, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6395 to 2.6383. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 2.0189\n",
      "    Validation Batch [1/1], Loss: 2.6371\n",
      "Validation Loss: 2.6371, Validation Accuracy: 4.29%\n",
      "Validation loss improved from 2.6383 to 2.6371. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 2.0300\n",
      "    Validation Batch [1/1], Loss: 2.6360\n",
      "Validation Loss: 2.6360, Validation Accuracy: 2.86%\n",
      "Validation loss improved from 2.6371 to 2.6360. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 2.0094\n",
      "    Validation Batch [1/1], Loss: 2.6346\n",
      "Validation Loss: 2.6346, Validation Accuracy: 1.43%\n",
      "Validation loss improved from 2.6360 to 2.6346. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 1.9943\n",
      "    Validation Batch [1/1], Loss: 2.6327\n",
      "Validation Loss: 2.6327, Validation Accuracy: 1.43%\n",
      "Validation loss improved from 2.6346 to 2.6327. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 1.9840\n",
      "    Validation Batch [1/1], Loss: 2.6300\n",
      "Validation Loss: 2.6300, Validation Accuracy: 1.43%\n",
      "Validation loss improved from 2.6327 to 2.6300. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 1.9883\n",
      "    Validation Batch [1/1], Loss: 2.6273\n",
      "Validation Loss: 2.6273, Validation Accuracy: 1.43%\n",
      "Validation loss improved from 2.6300 to 2.6273. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 1.9795\n",
      "    Validation Batch [1/1], Loss: 2.6238\n",
      "Validation Loss: 2.6238, Validation Accuracy: 1.43%\n",
      "Validation loss improved from 2.6273 to 2.6238. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 1.9580\n",
      "    Validation Batch [1/1], Loss: 2.6185\n",
      "Validation Loss: 2.6185, Validation Accuracy: 1.43%\n",
      "Validation loss improved from 2.6238 to 2.6185. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 1.9484\n",
      "    Validation Batch [1/1], Loss: 2.6116\n",
      "Validation Loss: 2.6116, Validation Accuracy: 4.29%\n",
      "Validation loss improved from 2.6185 to 2.6116. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.9426\n",
      "    Validation Batch [1/1], Loss: 2.6052\n",
      "Validation Loss: 2.6052, Validation Accuracy: 5.71%\n",
      "Validation loss improved from 2.6116 to 2.6052. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.9320\n",
      "    Validation Batch [1/1], Loss: 2.5979\n",
      "Validation Loss: 2.5979, Validation Accuracy: 11.43%\n",
      "Validation loss improved from 2.6052 to 2.5979. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/1000] completed, Average Training Loss: 1.9291\n",
      "    Validation Batch [1/1], Loss: 2.5900\n",
      "Validation Loss: 2.5900, Validation Accuracy: 12.86%\n",
      "Validation loss improved from 2.5979 to 2.5900. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 1.9251\n",
      "    Validation Batch [1/1], Loss: 2.5805\n",
      "Validation Loss: 2.5805, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5900 to 2.5805. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.9087\n",
      "    Validation Batch [1/1], Loss: 2.5670\n",
      "Validation Loss: 2.5670, Validation Accuracy: 20.00%\n",
      "Validation loss improved from 2.5805 to 2.5670. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.9072\n",
      "    Validation Batch [1/1], Loss: 2.5507\n",
      "Validation Loss: 2.5507, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.5670 to 2.5507. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.9055\n",
      "    Validation Batch [1/1], Loss: 2.5379\n",
      "Validation Loss: 2.5379, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.5507 to 2.5379. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.9070\n",
      "    Validation Batch [1/1], Loss: 2.5290\n",
      "Validation Loss: 2.5290, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.5379 to 2.5290. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.8931\n",
      "    Validation Batch [1/1], Loss: 2.5171\n",
      "Validation Loss: 2.5171, Validation Accuracy: 22.86%\n",
      "Validation loss improved from 2.5290 to 2.5171. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/1000] completed, Average Training Loss: 1.8803\n",
      "    Validation Batch [1/1], Loss: 2.5015\n",
      "Validation Loss: 2.5015, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.5171 to 2.5015. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.8608\n",
      "    Validation Batch [1/1], Loss: 2.4854\n",
      "Validation Loss: 2.4854, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.5015 to 2.4854. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.8547\n",
      "    Validation Batch [1/1], Loss: 2.4694\n",
      "Validation Loss: 2.4694, Validation Accuracy: 22.86%\n",
      "Validation loss improved from 2.4854 to 2.4694. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.8474\n",
      "    Validation Batch [1/1], Loss: 2.4514\n",
      "Validation Loss: 2.4514, Validation Accuracy: 22.86%\n",
      "Validation loss improved from 2.4694 to 2.4514. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.8761\n",
      "    Validation Batch [1/1], Loss: 2.4278\n",
      "Validation Loss: 2.4278, Validation Accuracy: 27.14%\n",
      "Validation loss improved from 2.4514 to 2.4278. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.8244\n",
      "    Validation Batch [1/1], Loss: 2.3982\n",
      "Validation Loss: 2.3982, Validation Accuracy: 32.86%\n",
      "Validation loss improved from 2.4278 to 2.3982. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.8328\n",
      "    Validation Batch [1/1], Loss: 2.3727\n",
      "Validation Loss: 2.3727, Validation Accuracy: 35.71%\n",
      "Validation loss improved from 2.3982 to 2.3727. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.8351\n",
      "    Validation Batch [1/1], Loss: 2.3504\n",
      "Validation Loss: 2.3504, Validation Accuracy: 35.71%\n",
      "Validation loss improved from 2.3727 to 2.3504. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.8067\n",
      "    Validation Batch [1/1], Loss: 2.3287\n",
      "Validation Loss: 2.3287, Validation Accuracy: 35.71%\n",
      "Validation loss improved from 2.3504 to 2.3287. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.8056\n",
      "    Validation Batch [1/1], Loss: 2.3027\n",
      "Validation Loss: 2.3027, Validation Accuracy: 37.14%\n",
      "Validation loss improved from 2.3287 to 2.3027. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.7941\n",
      "    Validation Batch [1/1], Loss: 2.2724\n",
      "Validation Loss: 2.2724, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.3027 to 2.2724. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.7914\n",
      "    Validation Batch [1/1], Loss: 2.2459\n",
      "Validation Loss: 2.2459, Validation Accuracy: 47.14%\n",
      "Validation loss improved from 2.2724 to 2.2459. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.7730\n",
      "    Validation Batch [1/1], Loss: 2.2195\n",
      "Validation Loss: 2.2195, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.2459 to 2.2195. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.7818\n",
      "    Validation Batch [1/1], Loss: 2.1985\n",
      "Validation Loss: 2.1985, Validation Accuracy: 52.86%\n",
      "Validation loss improved from 2.2195 to 2.1985. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.7562\n",
      "    Validation Batch [1/1], Loss: 2.1717\n",
      "Validation Loss: 2.1717, Validation Accuracy: 52.86%\n",
      "Validation loss improved from 2.1985 to 2.1717. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.7452\n",
      "    Validation Batch [1/1], Loss: 2.1383\n",
      "Validation Loss: 2.1383, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.1717 to 2.1383. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.7256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.0957\n",
      "Validation Loss: 2.0957, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.1383 to 2.0957. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.7363\n",
      "    Validation Batch [1/1], Loss: 2.0589\n",
      "Validation Loss: 2.0589, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.0957 to 2.0589. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.7259\n",
      "    Validation Batch [1/1], Loss: 2.0389\n",
      "Validation Loss: 2.0389, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0589 to 2.0389. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.7166\n",
      "    Validation Batch [1/1], Loss: 2.0274\n",
      "Validation Loss: 2.0274, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 2.0389 to 2.0274. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.7099\n",
      "    Validation Batch [1/1], Loss: 1.9988\n",
      "Validation Loss: 1.9988, Validation Accuracy: 65.71%\n",
      "Validation loss improved from 2.0274 to 1.9988. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.7062\n",
      "    Validation Batch [1/1], Loss: 1.9652\n",
      "Validation Loss: 1.9652, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.9988 to 1.9652. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.6862\n",
      "    Validation Batch [1/1], Loss: 1.9366\n",
      "Validation Loss: 1.9366, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.9652 to 1.9366. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.6724\n",
      "    Validation Batch [1/1], Loss: 1.9147\n",
      "Validation Loss: 1.9147, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.9366 to 1.9147. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.6883\n",
      "    Validation Batch [1/1], Loss: 1.8884\n",
      "Validation Loss: 1.8884, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.9147 to 1.8884. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/1000] completed, Average Training Loss: 1.6776\n",
      "    Validation Batch [1/1], Loss: 1.8632\n",
      "Validation Loss: 1.8632, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.8884 to 1.8632. Saving model...\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.6648\n",
      "    Validation Batch [1/1], Loss: 1.8384\n",
      "Validation Loss: 1.8384, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 1.8632 to 1.8384. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.6714\n",
      "    Validation Batch [1/1], Loss: 1.8108\n",
      "Validation Loss: 1.8108, Validation Accuracy: 65.71%\n",
      "Validation loss improved from 1.8384 to 1.8108. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.6628\n",
      "    Validation Batch [1/1], Loss: 1.7957\n",
      "Validation Loss: 1.7957, Validation Accuracy: 65.71%\n",
      "Validation loss improved from 1.8108 to 1.7957. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.6334\n",
      "    Validation Batch [1/1], Loss: 1.7819\n",
      "Validation Loss: 1.7819, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.7957 to 1.7819. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.6389\n",
      "    Validation Batch [1/1], Loss: 1.7691\n",
      "Validation Loss: 1.7691, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7819 to 1.7691. Saving model...\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.5810\n",
      "    Validation Batch [1/1], Loss: 1.7536\n",
      "Validation Loss: 1.7536, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.7691 to 1.7536. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.6056\n",
      "    Validation Batch [1/1], Loss: 1.7426\n",
      "Validation Loss: 1.7426, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7536 to 1.7426. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.5906\n",
      "    Validation Batch [1/1], Loss: 1.7130\n",
      "Validation Loss: 1.7130, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7426 to 1.7130. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.6178\n",
      "    Validation Batch [1/1], Loss: 1.6843\n",
      "Validation Loss: 1.6843, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7130 to 1.6843. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.6181\n",
      "    Validation Batch [1/1], Loss: 1.6684\n",
      "Validation Loss: 1.6684, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.6843 to 1.6684. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.5575\n",
      "    Validation Batch [1/1], Loss: 1.6608\n",
      "Validation Loss: 1.6608, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.6684 to 1.6608. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/1000] completed, Average Training Loss: 1.5719\n",
      "    Validation Batch [1/1], Loss: 1.6633\n",
      "Validation Loss: 1.6633, Validation Accuracy: 70.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.5584\n",
      "    Validation Batch [1/1], Loss: 1.6502\n",
      "Validation Loss: 1.6502, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 1.6608 to 1.6502. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.5113\n",
      "    Validation Batch [1/1], Loss: 1.6235\n",
      "Validation Loss: 1.6235, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 1.6502 to 1.6235. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.5452\n",
      "    Validation Batch [1/1], Loss: 1.5932\n",
      "Validation Loss: 1.5932, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.6235 to 1.5932. Saving model...\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.5282\n",
      "    Validation Batch [1/1], Loss: 1.5835\n",
      "Validation Loss: 1.5835, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.5932 to 1.5835. Saving model...\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.5311\n",
      "    Validation Batch [1/1], Loss: 1.5847\n",
      "Validation Loss: 1.5847, Validation Accuracy: 72.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.4900\n",
      "    Validation Batch [1/1], Loss: 1.5797\n",
      "Validation Loss: 1.5797, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.5835 to 1.5797. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 1.4852\n",
      "    Validation Batch [1/1], Loss: 1.5616\n",
      "Validation Loss: 1.5616, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.5797 to 1.5616. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 1.5100\n",
      "    Validation Batch [1/1], Loss: 1.5297\n",
      "Validation Loss: 1.5297, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5616 to 1.5297. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.5009\n",
      "    Validation Batch [1/1], Loss: 1.5122\n",
      "Validation Loss: 1.5122, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5297 to 1.5122. Saving model...\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 1.4934\n",
      "    Validation Batch [1/1], Loss: 1.5071\n",
      "Validation Loss: 1.5071, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.5122 to 1.5071. Saving model...\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.4689\n",
      "    Validation Batch [1/1], Loss: 1.5156\n",
      "Validation Loss: 1.5156, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/1000] completed, Average Training Loss: 1.4841\n",
      "    Validation Batch [1/1], Loss: 1.5080\n",
      "Validation Loss: 1.5080, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 1.4430\n",
      "    Validation Batch [1/1], Loss: 1.4758\n",
      "Validation Loss: 1.4758, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.5071 to 1.4758. Saving model...\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 1.4437\n",
      "    Validation Batch [1/1], Loss: 1.4531\n",
      "Validation Loss: 1.4531, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4758 to 1.4531. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 1.4414\n",
      "    Validation Batch [1/1], Loss: 1.4518\n",
      "Validation Loss: 1.4518, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.4531 to 1.4518. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 1.4585\n",
      "    Validation Batch [1/1], Loss: 1.4510\n",
      "Validation Loss: 1.4510, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.4518 to 1.4510. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 1.4343\n",
      "    Validation Batch [1/1], Loss: 1.4556\n",
      "Validation Loss: 1.4556, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 1.4173\n",
      "    Validation Batch [1/1], Loss: 1.4392\n",
      "Validation Loss: 1.4392, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.4510 to 1.4392. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 1.4137\n",
      "    Validation Batch [1/1], Loss: 1.4241\n",
      "Validation Loss: 1.4241, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.4392 to 1.4241. Saving model...\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 1.3843\n",
      "    Validation Batch [1/1], Loss: 1.4101\n",
      "Validation Loss: 1.4101, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.4241 to 1.4101. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 1.3807\n",
      "    Validation Batch [1/1], Loss: 1.4093\n",
      "Validation Loss: 1.4093, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.4101 to 1.4093. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 1.4098\n",
      "    Validation Batch [1/1], Loss: 1.3953\n",
      "Validation Loss: 1.3953, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.4093 to 1.3953. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 1.3715\n",
      "    Validation Batch [1/1], Loss: 1.3890\n",
      "Validation Loss: 1.3890, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.3953 to 1.3890. Saving model...\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/1000] completed, Average Training Loss: 1.3562\n",
      "    Validation Batch [1/1], Loss: 1.3905\n",
      "Validation Loss: 1.3905, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 1.3716\n",
      "    Validation Batch [1/1], Loss: 1.3760\n",
      "Validation Loss: 1.3760, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.3890 to 1.3760. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 1.3510\n",
      "    Validation Batch [1/1], Loss: 1.3681\n",
      "Validation Loss: 1.3681, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.3760 to 1.3681. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 1.3230\n",
      "    Validation Batch [1/1], Loss: 1.3494\n",
      "Validation Loss: 1.3494, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.3681 to 1.3494. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 1.3420\n",
      "    Validation Batch [1/1], Loss: 1.3510\n",
      "Validation Loss: 1.3510, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 1.3417\n",
      "    Validation Batch [1/1], Loss: 1.3291\n",
      "Validation Loss: 1.3291, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.3494 to 1.3291. Saving model...\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 1.3323\n",
      "    Validation Batch [1/1], Loss: 1.3177\n",
      "Validation Loss: 1.3177, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.3291 to 1.3177. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 1.3045\n",
      "    Validation Batch [1/1], Loss: 1.3188\n",
      "Validation Loss: 1.3188, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 1.3153\n",
      "    Validation Batch [1/1], Loss: 1.3181\n",
      "Validation Loss: 1.3181, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 1.2943\n",
      "    Validation Batch [1/1], Loss: 1.2898\n",
      "Validation Loss: 1.2898, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.3177 to 1.2898. Saving model...\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 1.2786\n",
      "    Validation Batch [1/1], Loss: 1.2643\n",
      "Validation Loss: 1.2643, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.2898 to 1.2643. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 1.2774\n",
      "    Validation Batch [1/1], Loss: 1.2536\n",
      "Validation Loss: 1.2536, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.2643 to 1.2536. Saving model...\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/1000] completed, Average Training Loss: 1.2583\n",
      "    Validation Batch [1/1], Loss: 1.2657\n",
      "Validation Loss: 1.2657, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 1.2502\n",
      "    Validation Batch [1/1], Loss: 1.2606\n",
      "Validation Loss: 1.2606, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 1.2763\n",
      "    Validation Batch [1/1], Loss: 1.2395\n",
      "Validation Loss: 1.2395, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.2536 to 1.2395. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 1.2520\n",
      "    Validation Batch [1/1], Loss: 1.2239\n",
      "Validation Loss: 1.2239, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.2395 to 1.2239. Saving model...\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 1.2350\n",
      "    Validation Batch [1/1], Loss: 1.2146\n",
      "Validation Loss: 1.2146, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.2239 to 1.2146. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 1.2003\n",
      "    Validation Batch [1/1], Loss: 1.2040\n",
      "Validation Loss: 1.2040, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.2146 to 1.2040. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 1.2245\n",
      "    Validation Batch [1/1], Loss: 1.2035\n",
      "Validation Loss: 1.2035, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.2040 to 1.2035. Saving model...\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 1.2543\n",
      "    Validation Batch [1/1], Loss: 1.2111\n",
      "Validation Loss: 1.2111, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 1.1985\n",
      "    Validation Batch [1/1], Loss: 1.2038\n",
      "Validation Loss: 1.2038, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 1.2084\n",
      "    Validation Batch [1/1], Loss: 1.1949\n",
      "Validation Loss: 1.1949, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.2035 to 1.1949. Saving model...\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 1.1853\n",
      "    Validation Batch [1/1], Loss: 1.1827\n",
      "Validation Loss: 1.1827, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.1949 to 1.1827. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 1.1905\n",
      "    Validation Batch [1/1], Loss: 1.1693\n",
      "Validation Loss: 1.1693, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.1827 to 1.1693. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/1000] completed, Average Training Loss: 1.1573\n",
      "    Validation Batch [1/1], Loss: 1.1560\n",
      "Validation Loss: 1.1560, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.1693 to 1.1560. Saving model...\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 1.1594\n",
      "    Validation Batch [1/1], Loss: 1.1397\n",
      "Validation Loss: 1.1397, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.1560 to 1.1397. Saving model...\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 1.1543\n",
      "    Validation Batch [1/1], Loss: 1.1381\n",
      "Validation Loss: 1.1381, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.1397 to 1.1381. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 1.1745\n",
      "    Validation Batch [1/1], Loss: 1.1468\n",
      "Validation Loss: 1.1468, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 1.1453\n",
      "    Validation Batch [1/1], Loss: 1.1416\n",
      "Validation Loss: 1.1416, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 1.1263\n",
      "    Validation Batch [1/1], Loss: 1.1383\n",
      "Validation Loss: 1.1383, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 1.1332\n",
      "    Validation Batch [1/1], Loss: 1.1011\n",
      "Validation Loss: 1.1011, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.1381 to 1.1011. Saving model...\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 1.1024\n",
      "    Validation Batch [1/1], Loss: 1.0909\n",
      "Validation Loss: 1.0909, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.1011 to 1.0909. Saving model...\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 1.0857\n",
      "    Validation Batch [1/1], Loss: 1.1005\n",
      "Validation Loss: 1.1005, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 1.1478\n",
      "    Validation Batch [1/1], Loss: 1.0852\n",
      "Validation Loss: 1.0852, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.0909 to 1.0852. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 1.1125\n",
      "    Validation Batch [1/1], Loss: 1.0857\n",
      "Validation Loss: 1.0857, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 1.0871\n",
      "    Validation Batch [1/1], Loss: 1.0861\n",
      "Validation Loss: 1.0861, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/1000] completed, Average Training Loss: 1.0729\n",
      "    Validation Batch [1/1], Loss: 1.0783\n",
      "Validation Loss: 1.0783, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.0852 to 1.0783. Saving model...\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 1.0915\n",
      "    Validation Batch [1/1], Loss: 1.0544\n",
      "Validation Loss: 1.0544, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.0783 to 1.0544. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 1.1020\n",
      "    Validation Batch [1/1], Loss: 1.0486\n",
      "Validation Loss: 1.0486, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.0544 to 1.0486. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 1.0693\n",
      "    Validation Batch [1/1], Loss: 1.0584\n",
      "Validation Loss: 1.0584, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 1.0285\n",
      "    Validation Batch [1/1], Loss: 1.0327\n",
      "Validation Loss: 1.0327, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.0486 to 1.0327. Saving model...\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 1.0574\n",
      "    Validation Batch [1/1], Loss: 1.0247\n",
      "Validation Loss: 1.0247, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.0327 to 1.0247. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 1.0550\n",
      "    Validation Batch [1/1], Loss: 1.0265\n",
      "Validation Loss: 1.0265, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 1.0030\n",
      "    Validation Batch [1/1], Loss: 1.0304\n",
      "Validation Loss: 1.0304, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 1.0217\n",
      "    Validation Batch [1/1], Loss: 1.0066\n",
      "Validation Loss: 1.0066, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.0247 to 1.0066. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 1.0408\n",
      "    Validation Batch [1/1], Loss: 1.0174\n",
      "Validation Loss: 1.0174, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 1.0163\n",
      "    Validation Batch [1/1], Loss: 0.9997\n",
      "Validation Loss: 0.9997, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.0066 to 0.9997. Saving model...\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 1.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.9905\n",
      "Validation Loss: 0.9905, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.9997 to 0.9905. Saving model...\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 1.0042\n",
      "    Validation Batch [1/1], Loss: 0.9908\n",
      "Validation Loss: 0.9908, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 1.0052\n",
      "    Validation Batch [1/1], Loss: 0.9754\n",
      "Validation Loss: 0.9754, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.9905 to 0.9754. Saving model...\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.9674\n",
      "    Validation Batch [1/1], Loss: 0.9742\n",
      "Validation Loss: 0.9742, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9754 to 0.9742. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.9913\n",
      "    Validation Batch [1/1], Loss: 0.9471\n",
      "Validation Loss: 0.9471, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.9742 to 0.9471. Saving model...\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.9391\n",
      "    Validation Batch [1/1], Loss: 0.9560\n",
      "Validation Loss: 0.9560, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.9804\n",
      "    Validation Batch [1/1], Loss: 0.9427\n",
      "Validation Loss: 0.9427, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.9471 to 0.9427. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.9516\n",
      "    Validation Batch [1/1], Loss: 0.9454\n",
      "Validation Loss: 0.9454, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 0.9592\n",
      "    Validation Batch [1/1], Loss: 0.9255\n",
      "Validation Loss: 0.9255, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.9427 to 0.9255. Saving model...\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.9627\n",
      "    Validation Batch [1/1], Loss: 0.9421\n",
      "Validation Loss: 0.9421, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.9305\n",
      "    Validation Batch [1/1], Loss: 0.9234\n",
      "Validation Loss: 0.9234, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9255 to 0.9234. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.9104\n",
      "    Validation Batch [1/1], Loss: 0.9149\n",
      "Validation Loss: 0.9149, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9234 to 0.9149. Saving model...\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/1000] completed, Average Training Loss: 0.9076\n",
      "    Validation Batch [1/1], Loss: 0.9025\n",
      "Validation Loss: 0.9025, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9149 to 0.9025. Saving model...\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.8912\n",
      "    Validation Batch [1/1], Loss: 0.8807\n",
      "Validation Loss: 0.8807, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.9025 to 0.8807. Saving model...\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.9214\n",
      "    Validation Batch [1/1], Loss: 0.8979\n",
      "Validation Loss: 0.8979, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.9078\n",
      "    Validation Batch [1/1], Loss: 0.8952\n",
      "Validation Loss: 0.8952, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.8757\n",
      "    Validation Batch [1/1], Loss: 0.8783\n",
      "Validation Loss: 0.8783, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8807 to 0.8783. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.8674\n",
      "    Validation Batch [1/1], Loss: 0.8725\n",
      "Validation Loss: 0.8725, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.8783 to 0.8725. Saving model...\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.8592\n",
      "    Validation Batch [1/1], Loss: 0.8630\n",
      "Validation Loss: 0.8630, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8725 to 0.8630. Saving model...\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.8438\n",
      "    Validation Batch [1/1], Loss: 0.8737\n",
      "Validation Loss: 0.8737, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.8517\n",
      "    Validation Batch [1/1], Loss: 0.8571\n",
      "Validation Loss: 0.8571, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8630 to 0.8571. Saving model...\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.8569\n",
      "    Validation Batch [1/1], Loss: 0.8483\n",
      "Validation Loss: 0.8483, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8571 to 0.8483. Saving model...\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.8550\n",
      "    Validation Batch [1/1], Loss: 0.8466\n",
      "Validation Loss: 0.8466, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8483 to 0.8466. Saving model...\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.8643\n",
      "    Validation Batch [1/1], Loss: 0.8429\n",
      "Validation Loss: 0.8429, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8466 to 0.8429. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.8455\n",
      "    Validation Batch [1/1], Loss: 0.8260\n",
      "Validation Loss: 0.8260, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8429 to 0.8260. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.8292\n",
      "    Validation Batch [1/1], Loss: 0.8128\n",
      "Validation Loss: 0.8128, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8260 to 0.8128. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [201/1000] completed, Average Training Loss: 0.8355\n",
      "    Validation Batch [1/1], Loss: 0.8105\n",
      "Validation Loss: 0.8105, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8128 to 0.8105. Saving model...\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.8098\n",
      "    Validation Batch [1/1], Loss: 0.8104\n",
      "Validation Loss: 0.8104, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8105 to 0.8104. Saving model...\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.8226\n",
      "    Validation Batch [1/1], Loss: 0.8140\n",
      "Validation Loss: 0.8140, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.7955\n",
      "    Validation Batch [1/1], Loss: 0.7928\n",
      "Validation Loss: 0.7928, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8104 to 0.7928. Saving model...\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.8024\n",
      "    Validation Batch [1/1], Loss: 0.8020\n",
      "Validation Loss: 0.8020, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.7979\n",
      "    Validation Batch [1/1], Loss: 0.7885\n",
      "Validation Loss: 0.7885, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7928 to 0.7885. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.8113\n",
      "    Validation Batch [1/1], Loss: 0.7992\n",
      "Validation Loss: 0.7992, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.7888\n",
      "    Validation Batch [1/1], Loss: 0.7920\n",
      "Validation Loss: 0.7920, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [209/1000] completed, Average Training Loss: 0.7773\n",
      "    Validation Batch [1/1], Loss: 0.7690\n",
      "Validation Loss: 0.7690, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7885 to 0.7690. Saving model...\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.7970\n",
      "    Validation Batch [1/1], Loss: 0.7618\n",
      "Validation Loss: 0.7618, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7690 to 0.7618. Saving model...\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.7772\n",
      "    Validation Batch [1/1], Loss: 0.7616\n",
      "Validation Loss: 0.7616, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7618 to 0.7616. Saving model...\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.7658\n",
      "    Validation Batch [1/1], Loss: 0.7633\n",
      "Validation Loss: 0.7633, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.7320\n",
      "    Validation Batch [1/1], Loss: 0.7561\n",
      "Validation Loss: 0.7561, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7616 to 0.7561. Saving model...\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.7490\n",
      "    Validation Batch [1/1], Loss: 0.7509\n",
      "Validation Loss: 0.7509, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.7561 to 0.7509. Saving model...\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.7269\n",
      "    Validation Batch [1/1], Loss: 0.7328\n",
      "Validation Loss: 0.7328, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7509 to 0.7328. Saving model...\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.7048\n",
      "    Validation Batch [1/1], Loss: 0.7241\n",
      "Validation Loss: 0.7241, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7328 to 0.7241. Saving model...\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.7056\n",
      "    Validation Batch [1/1], Loss: 0.7280\n",
      "Validation Loss: 0.7280, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.7437\n",
      "    Validation Batch [1/1], Loss: 0.7477\n",
      "Validation Loss: 0.7477, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.6932\n",
      "    Validation Batch [1/1], Loss: 0.7262\n",
      "Validation Loss: 0.7262, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.7410\n",
      "    Validation Batch [1/1], Loss: 0.7053\n",
      "Validation Loss: 0.7053, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7241 to 0.7053. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.6903\n",
      "    Validation Batch [1/1], Loss: 0.6989\n",
      "Validation Loss: 0.6989, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7053 to 0.6989. Saving model...\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.6953\n",
      "    Validation Batch [1/1], Loss: 0.7138\n",
      "Validation Loss: 0.7138, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.7240\n",
      "    Validation Batch [1/1], Loss: 0.7046\n",
      "Validation Loss: 0.7046, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.6791\n",
      "    Validation Batch [1/1], Loss: 0.6870\n",
      "Validation Loss: 0.6870, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6989 to 0.6870. Saving model...\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [225/1000] completed, Average Training Loss: 0.6940\n",
      "    Validation Batch [1/1], Loss: 0.6687\n",
      "Validation Loss: 0.6687, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6870 to 0.6687. Saving model...\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.6930\n",
      "    Validation Batch [1/1], Loss: 0.6766\n",
      "Validation Loss: 0.6766, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.6819\n",
      "    Validation Batch [1/1], Loss: 0.6772\n",
      "Validation Loss: 0.6772, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.6761\n",
      "    Validation Batch [1/1], Loss: 0.6722\n",
      "Validation Loss: 0.6722, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.6502\n",
      "    Validation Batch [1/1], Loss: 0.6612\n",
      "Validation Loss: 0.6612, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.6687 to 0.6612. Saving model...\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.6884\n",
      "    Validation Batch [1/1], Loss: 0.6622\n",
      "Validation Loss: 0.6622, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.6815\n",
      "    Validation Batch [1/1], Loss: 0.6430\n",
      "Validation Loss: 0.6430, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6612 to 0.6430. Saving model...\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [232/1000] completed, Average Training Loss: 0.6380\n",
      "    Validation Batch [1/1], Loss: 0.6358\n",
      "Validation Loss: 0.6358, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.6430 to 0.6358. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.6446\n",
      "    Validation Batch [1/1], Loss: 0.6354\n",
      "Validation Loss: 0.6354, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6358 to 0.6354. Saving model...\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.6345\n",
      "    Validation Batch [1/1], Loss: 0.6408\n",
      "Validation Loss: 0.6408, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.6579\n",
      "    Validation Batch [1/1], Loss: 0.6386\n",
      "Validation Loss: 0.6386, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.6137\n",
      "    Validation Batch [1/1], Loss: 0.6379\n",
      "Validation Loss: 0.6379, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.6164\n",
      "    Validation Batch [1/1], Loss: 0.6282\n",
      "Validation Loss: 0.6282, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6354 to 0.6282. Saving model...\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.6142\n",
      "    Validation Batch [1/1], Loss: 0.6231\n",
      "Validation Loss: 0.6231, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6282 to 0.6231. Saving model...\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.5992\n",
      "    Validation Batch [1/1], Loss: 0.6241\n",
      "Validation Loss: 0.6241, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.6347\n",
      "    Validation Batch [1/1], Loss: 0.6183\n",
      "Validation Loss: 0.6183, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6231 to 0.6183. Saving model...\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.6072\n",
      "    Validation Batch [1/1], Loss: 0.6355\n",
      "Validation Loss: 0.6355, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.6170\n",
      "    Validation Batch [1/1], Loss: 0.6017\n",
      "Validation Loss: 0.6017, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6183 to 0.6017. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.5981\n",
      "    Validation Batch [1/1], Loss: 0.5931\n",
      "Validation Loss: 0.5931, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6017 to 0.5931. Saving model...\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.6196\n",
      "    Validation Batch [1/1], Loss: 0.5907\n",
      "Validation Loss: 0.5907, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.5931 to 0.5907. Saving model...\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.6002\n",
      "    Validation Batch [1/1], Loss: 0.5914\n",
      "Validation Loss: 0.5914, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.5821\n",
      "    Validation Batch [1/1], Loss: 0.5952\n",
      "Validation Loss: 0.5952, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.5959\n",
      "    Validation Batch [1/1], Loss: 0.5849\n",
      "Validation Loss: 0.5849, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5907 to 0.5849. Saving model...\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [248/1000] completed, Average Training Loss: 0.5826\n",
      "    Validation Batch [1/1], Loss: 0.5759\n",
      "Validation Loss: 0.5759, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5849 to 0.5759. Saving model...\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.6004\n",
      "    Validation Batch [1/1], Loss: 0.5662\n",
      "Validation Loss: 0.5662, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5759 to 0.5662. Saving model...\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.5631\n",
      "    Validation Batch [1/1], Loss: 0.5608\n",
      "Validation Loss: 0.5608, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5662 to 0.5608. Saving model...\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.5481\n",
      "    Validation Batch [1/1], Loss: 0.5586\n",
      "Validation Loss: 0.5586, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5608 to 0.5586. Saving model...\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.5878\n",
      "    Validation Batch [1/1], Loss: 0.5625\n",
      "Validation Loss: 0.5625, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.5493\n",
      "    Validation Batch [1/1], Loss: 0.5741\n",
      "Validation Loss: 0.5741, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.5663\n",
      "    Validation Batch [1/1], Loss: 0.5623\n",
      "Validation Loss: 0.5623, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [255/1000] completed, Average Training Loss: 0.5523\n",
      "    Validation Batch [1/1], Loss: 0.5491\n",
      "Validation Loss: 0.5491, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5586 to 0.5491. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.5476\n",
      "    Validation Batch [1/1], Loss: 0.5324\n",
      "Validation Loss: 0.5324, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5491 to 0.5324. Saving model...\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.5233\n",
      "    Validation Batch [1/1], Loss: 0.5324\n",
      "Validation Loss: 0.5324, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.5114\n",
      "    Validation Batch [1/1], Loss: 0.5200\n",
      "Validation Loss: 0.5200, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5324 to 0.5200. Saving model...\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.5229\n",
      "    Validation Batch [1/1], Loss: 0.5318\n",
      "Validation Loss: 0.5318, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.5005\n",
      "    Validation Batch [1/1], Loss: 0.5316\n",
      "Validation Loss: 0.5316, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.4921\n",
      "    Validation Batch [1/1], Loss: 0.5477\n",
      "Validation Loss: 0.5477, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.5143\n",
      "    Validation Batch [1/1], Loss: 0.5108\n",
      "Validation Loss: 0.5108, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5200 to 0.5108. Saving model...\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.5151\n",
      "    Validation Batch [1/1], Loss: 0.5112\n",
      "Validation Loss: 0.5112, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.5251\n",
      "    Validation Batch [1/1], Loss: 0.5027\n",
      "Validation Loss: 0.5027, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5108 to 0.5027. Saving model...\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.4950\n",
      "    Validation Batch [1/1], Loss: 0.5222\n",
      "Validation Loss: 0.5222, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.5169\n",
      "    Validation Batch [1/1], Loss: 0.5009\n",
      "Validation Loss: 0.5009, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5027 to 0.5009. Saving model...\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.4711\n",
      "    Validation Batch [1/1], Loss: 0.4961\n",
      "Validation Loss: 0.4961, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5009 to 0.4961. Saving model...\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.4735\n",
      "    Validation Batch [1/1], Loss: 0.5040\n",
      "Validation Loss: 0.5040, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.4890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.5099\n",
      "Validation Loss: 0.5099, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.4864\n",
      "    Validation Batch [1/1], Loss: 0.5021\n",
      "Validation Loss: 0.5021, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.4844\n",
      "    Validation Batch [1/1], Loss: 0.4744\n",
      "Validation Loss: 0.4744, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4961 to 0.4744. Saving model...\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.4607\n",
      "    Validation Batch [1/1], Loss: 0.4654\n",
      "Validation Loss: 0.4654, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4744 to 0.4654. Saving model...\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.4741\n",
      "    Validation Batch [1/1], Loss: 0.4822\n",
      "Validation Loss: 0.4822, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.4429\n",
      "    Validation Batch [1/1], Loss: 0.4902\n",
      "Validation Loss: 0.4902, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.4625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.4732\n",
      "Validation Loss: 0.4732, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.4605\n",
      "    Validation Batch [1/1], Loss: 0.4928\n",
      "Validation Loss: 0.4928, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.4486\n",
      "    Validation Batch [1/1], Loss: 0.4765\n",
      "Validation Loss: 0.4765, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.4487\n",
      "    Validation Batch [1/1], Loss: 0.4757\n",
      "Validation Loss: 0.4757, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.4536\n",
      "    Validation Batch [1/1], Loss: 0.4784\n",
      "Validation Loss: 0.4784, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.4339\n",
      "    Validation Batch [1/1], Loss: 0.4578\n",
      "Validation Loss: 0.4578, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4654 to 0.4578. Saving model...\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.4558\n",
      "    Validation Batch [1/1], Loss: 0.4582\n",
      "Validation Loss: 0.4582, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.4356\n",
      "    Validation Batch [1/1], Loss: 0.4503\n",
      "Validation Loss: 0.4503, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4578 to 0.4503. Saving model...\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.4489\n",
      "    Validation Batch [1/1], Loss: 0.4403\n",
      "Validation Loss: 0.4403, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4503 to 0.4403. Saving model...\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.4217\n",
      "    Validation Batch [1/1], Loss: 0.4267\n",
      "Validation Loss: 0.4267, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4403 to 0.4267. Saving model...\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.4193\n",
      "    Validation Batch [1/1], Loss: 0.4197\n",
      "Validation Loss: 0.4197, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4267 to 0.4197. Saving model...\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.4128\n",
      "    Validation Batch [1/1], Loss: 0.4213\n",
      "Validation Loss: 0.4213, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.4162\n",
      "    Validation Batch [1/1], Loss: 0.4272\n",
      "Validation Loss: 0.4272, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.4000\n",
      "    Validation Batch [1/1], Loss: 0.4222\n",
      "Validation Loss: 0.4222, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.4131\n",
      "    Validation Batch [1/1], Loss: 0.4219\n",
      "Validation Loss: 0.4219, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.4149\n",
      "    Validation Batch [1/1], Loss: 0.4107\n",
      "Validation Loss: 0.4107, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4197 to 0.4107. Saving model...\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.4037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.4135\n",
      "Validation Loss: 0.4135, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.4218\n",
      "    Validation Batch [1/1], Loss: 0.4067\n",
      "Validation Loss: 0.4067, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4107 to 0.4067. Saving model...\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.4041\n",
      "    Validation Batch [1/1], Loss: 0.4008\n",
      "Validation Loss: 0.4008, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4067 to 0.4008. Saving model...\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.3981\n",
      "    Validation Batch [1/1], Loss: 0.3894\n",
      "Validation Loss: 0.3894, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4008 to 0.3894. Saving model...\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.3972\n",
      "    Validation Batch [1/1], Loss: 0.3987\n",
      "Validation Loss: 0.3987, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.3851\n",
      "    Validation Batch [1/1], Loss: 0.3892\n",
      "Validation Loss: 0.3892, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3894 to 0.3892. Saving model...\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [297/1000] completed, Average Training Loss: 0.3794\n",
      "    Validation Batch [1/1], Loss: 0.3786\n",
      "Validation Loss: 0.3786, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3892 to 0.3786. Saving model...\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.3801\n",
      "    Validation Batch [1/1], Loss: 0.3834\n",
      "Validation Loss: 0.3834, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.3631\n",
      "    Validation Batch [1/1], Loss: 0.3770\n",
      "Validation Loss: 0.3770, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3786 to 0.3770. Saving model...\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.3869\n",
      "    Validation Batch [1/1], Loss: 0.3772\n",
      "Validation Loss: 0.3772, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.3760\n",
      "    Validation Batch [1/1], Loss: 0.3904\n",
      "Validation Loss: 0.3904, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.3810\n",
      "    Validation Batch [1/1], Loss: 0.3723\n",
      "Validation Loss: 0.3723, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3770 to 0.3723. Saving model...\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.3718\n",
      "    Validation Batch [1/1], Loss: 0.3670\n",
      "Validation Loss: 0.3670, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3723 to 0.3670. Saving model...\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.3491\n",
      "    Validation Batch [1/1], Loss: 0.3759\n",
      "Validation Loss: 0.3759, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.3659\n",
      "    Validation Batch [1/1], Loss: 0.3753\n",
      "Validation Loss: 0.3753, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.3705\n",
      "    Validation Batch [1/1], Loss: 0.3615\n",
      "Validation Loss: 0.3615, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3670 to 0.3615. Saving model...\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.3914\n",
      "    Validation Batch [1/1], Loss: 0.3509\n",
      "Validation Loss: 0.3509, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3615 to 0.3509. Saving model...\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.3362\n",
      "    Validation Batch [1/1], Loss: 0.3420\n",
      "Validation Loss: 0.3420, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3509 to 0.3420. Saving model...\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.3357\n",
      "    Validation Batch [1/1], Loss: 0.3537\n",
      "Validation Loss: 0.3537, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.3685\n",
      "    Validation Batch [1/1], Loss: 0.3475\n",
      "Validation Loss: 0.3475, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.3357\n",
      "    Validation Batch [1/1], Loss: 0.3418\n",
      "Validation Loss: 0.3418, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3420 to 0.3418. Saving model...\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.3407\n",
      "    Validation Batch [1/1], Loss: 0.3413\n",
      "Validation Loss: 0.3413, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3418 to 0.3413. Saving model...\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [313/1000] completed, Average Training Loss: 0.3510\n",
      "    Validation Batch [1/1], Loss: 0.3399\n",
      "Validation Loss: 0.3399, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3413 to 0.3399. Saving model...\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.3454\n",
      "    Validation Batch [1/1], Loss: 0.3367\n",
      "Validation Loss: 0.3367, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3399 to 0.3367. Saving model...\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.3293\n",
      "    Validation Batch [1/1], Loss: 0.3225\n",
      "Validation Loss: 0.3225, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3367 to 0.3225. Saving model...\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.3291\n",
      "    Validation Batch [1/1], Loss: 0.3252\n",
      "Validation Loss: 0.3252, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.3363\n",
      "    Validation Batch [1/1], Loss: 0.3231\n",
      "Validation Loss: 0.3231, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.3276\n",
      "    Validation Batch [1/1], Loss: 0.3219\n",
      "Validation Loss: 0.3219, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3225 to 0.3219. Saving model...\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [319/1000] completed, Average Training Loss: 0.3053\n",
      "    Validation Batch [1/1], Loss: 0.3252\n",
      "Validation Loss: 0.3252, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.3293\n",
      "    Validation Batch [1/1], Loss: 0.3116\n",
      "Validation Loss: 0.3116, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3219 to 0.3116. Saving model...\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.3195\n",
      "    Validation Batch [1/1], Loss: 0.3150\n",
      "Validation Loss: 0.3150, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.3164\n",
      "    Validation Batch [1/1], Loss: 0.3109\n",
      "Validation Loss: 0.3109, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3116 to 0.3109. Saving model...\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.2998\n",
      "    Validation Batch [1/1], Loss: 0.3093\n",
      "Validation Loss: 0.3093, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3109 to 0.3093. Saving model...\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.2969\n",
      "    Validation Batch [1/1], Loss: 0.3048\n",
      "Validation Loss: 0.3048, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3093 to 0.3048. Saving model...\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.3132\n",
      "    Validation Batch [1/1], Loss: 0.3024\n",
      "Validation Loss: 0.3024, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3048 to 0.3024. Saving model...\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.2854\n",
      "    Validation Batch [1/1], Loss: 0.2971\n",
      "Validation Loss: 0.2971, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3024 to 0.2971. Saving model...\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.2998\n",
      "    Validation Batch [1/1], Loss: 0.3021\n",
      "Validation Loss: 0.3021, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.2957\n",
      "    Validation Batch [1/1], Loss: 0.3066\n",
      "Validation Loss: 0.3066, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.2902\n",
      "    Validation Batch [1/1], Loss: 0.2944\n",
      "Validation Loss: 0.2944, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2971 to 0.2944. Saving model...\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.2865\n",
      "    Validation Batch [1/1], Loss: 0.2804\n",
      "Validation Loss: 0.2804, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2944 to 0.2804. Saving model...\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.2770\n",
      "    Validation Batch [1/1], Loss: 0.2771\n",
      "Validation Loss: 0.2771, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2804 to 0.2771. Saving model...\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.2661\n",
      "    Validation Batch [1/1], Loss: 0.2741\n",
      "Validation Loss: 0.2741, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2771 to 0.2741. Saving model...\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.2876\n",
      "    Validation Batch [1/1], Loss: 0.2862\n",
      "Validation Loss: 0.2862, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.2813\n",
      "    Validation Batch [1/1], Loss: 0.2903\n",
      "Validation Loss: 0.2903, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.2664\n",
      "    Validation Batch [1/1], Loss: 0.2848\n",
      "Validation Loss: 0.2848, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.2959\n",
      "    Validation Batch [1/1], Loss: 0.2764\n",
      "Validation Loss: 0.2764, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.2812\n",
      "    Validation Batch [1/1], Loss: 0.2634\n",
      "Validation Loss: 0.2634, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2741 to 0.2634. Saving model...\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [338/1000] completed, Average Training Loss: 0.2786\n",
      "    Validation Batch [1/1], Loss: 0.2616\n",
      "Validation Loss: 0.2616, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2634 to 0.2616. Saving model...\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.2365\n",
      "    Validation Batch [1/1], Loss: 0.2633\n",
      "Validation Loss: 0.2633, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.2723\n",
      "    Validation Batch [1/1], Loss: 0.2649\n",
      "Validation Loss: 0.2649, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.2568\n",
      "    Validation Batch [1/1], Loss: 0.2638\n",
      "Validation Loss: 0.2638, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.2421\n",
      "    Validation Batch [1/1], Loss: 0.2609\n",
      "Validation Loss: 0.2609, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2616 to 0.2609. Saving model...\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.2544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2560\n",
      "Validation Loss: 0.2560, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2609 to 0.2560. Saving model...\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.2484\n",
      "    Validation Batch [1/1], Loss: 0.2501\n",
      "Validation Loss: 0.2501, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2560 to 0.2501. Saving model...\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.2458\n",
      "    Validation Batch [1/1], Loss: 0.2613\n",
      "Validation Loss: 0.2613, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.2335\n",
      "    Validation Batch [1/1], Loss: 0.2453\n",
      "Validation Loss: 0.2453, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2501 to 0.2453. Saving model...\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.2331\n",
      "    Validation Batch [1/1], Loss: 0.2435\n",
      "Validation Loss: 0.2435, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2453 to 0.2435. Saving model...\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.2424\n",
      "    Validation Batch [1/1], Loss: 0.2372\n",
      "Validation Loss: 0.2372, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2435 to 0.2372. Saving model...\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.2345\n",
      "    Validation Batch [1/1], Loss: 0.2413\n",
      "Validation Loss: 0.2413, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.2376\n",
      "    Validation Batch [1/1], Loss: 0.2463\n",
      "Validation Loss: 0.2463, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.2068\n",
      "    Validation Batch [1/1], Loss: 0.2431\n",
      "Validation Loss: 0.2431, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.2401\n",
      "    Validation Batch [1/1], Loss: 0.2464\n",
      "Validation Loss: 0.2464, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.2452\n",
      "    Validation Batch [1/1], Loss: 0.2488\n",
      "Validation Loss: 0.2488, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.2296\n",
      "    Validation Batch [1/1], Loss: 0.2504\n",
      "Validation Loss: 0.2504, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.2351\n",
      "    Validation Batch [1/1], Loss: 0.2418\n",
      "Validation Loss: 0.2418, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.2052\n",
      "    Validation Batch [1/1], Loss: 0.2346\n",
      "Validation Loss: 0.2346, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2372 to 0.2346. Saving model...\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.2283\n",
      "    Validation Batch [1/1], Loss: 0.2346\n",
      "Validation Loss: 0.2346, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.2137\n",
      "    Validation Batch [1/1], Loss: 0.2265\n",
      "Validation Loss: 0.2265, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2346 to 0.2265. Saving model...\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.2170\n",
      "    Validation Batch [1/1], Loss: 0.2223\n",
      "Validation Loss: 0.2223, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2265 to 0.2223. Saving model...\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.2279\n",
      "    Validation Batch [1/1], Loss: 0.2243\n",
      "Validation Loss: 0.2243, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [361/1000] completed, Average Training Loss: 0.2094\n",
      "    Validation Batch [1/1], Loss: 0.2303\n",
      "Validation Loss: 0.2303, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.2253\n",
      "    Validation Batch [1/1], Loss: 0.2313\n",
      "Validation Loss: 0.2313, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.2256\n",
      "    Validation Batch [1/1], Loss: 0.2228\n",
      "Validation Loss: 0.2228, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.2016\n",
      "    Validation Batch [1/1], Loss: 0.2197\n",
      "Validation Loss: 0.2197, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2223 to 0.2197. Saving model...\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.2068\n",
      "    Validation Batch [1/1], Loss: 0.2239\n",
      "Validation Loss: 0.2239, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [366/1000] completed, Average Training Loss: 0.2220\n",
      "    Validation Batch [1/1], Loss: 0.2156\n",
      "Validation Loss: 0.2156, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2197 to 0.2156. Saving model...\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.2162\n",
      "    Validation Batch [1/1], Loss: 0.2105\n",
      "Validation Loss: 0.2105, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2156 to 0.2105. Saving model...\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.2022\n",
      "    Validation Batch [1/1], Loss: 0.2156\n",
      "Validation Loss: 0.2156, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.2109\n",
      "    Validation Batch [1/1], Loss: 0.2267\n",
      "Validation Loss: 0.2267, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.2008\n",
      "    Validation Batch [1/1], Loss: 0.2386\n",
      "Validation Loss: 0.2386, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.2037\n",
      "    Validation Batch [1/1], Loss: 0.2174\n",
      "Validation Loss: 0.2174, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.1916\n",
      "    Validation Batch [1/1], Loss: 0.2060\n",
      "Validation Loss: 0.2060, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2105 to 0.2060. Saving model...\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.1941\n",
      "    Validation Batch [1/1], Loss: 0.2036\n",
      "Validation Loss: 0.2036, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2060 to 0.2036. Saving model...\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.2051\n",
      "    Validation Batch [1/1], Loss: 0.2058\n",
      "Validation Loss: 0.2058, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.1954\n",
      "    Validation Batch [1/1], Loss: 0.2137\n",
      "Validation Loss: 0.2137, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.1965\n",
      "    Validation Batch [1/1], Loss: 0.2219\n",
      "Validation Loss: 0.2219, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.1924\n",
      "    Validation Batch [1/1], Loss: 0.2134\n",
      "Validation Loss: 0.2134, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.1820\n",
      "    Validation Batch [1/1], Loss: 0.2048\n",
      "Validation Loss: 0.2048, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.1985\n",
      "    Validation Batch [1/1], Loss: 0.2062\n",
      "Validation Loss: 0.2062, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.1934\n",
      "    Validation Batch [1/1], Loss: 0.2014\n",
      "Validation Loss: 0.2014, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2036 to 0.2014. Saving model...\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.1764\n",
      "    Validation Batch [1/1], Loss: 0.1902\n",
      "Validation Loss: 0.1902, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2014 to 0.1902. Saving model...\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.1773\n",
      "    Validation Batch [1/1], Loss: 0.1884\n",
      "Validation Loss: 0.1884, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1902 to 0.1884. Saving model...\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.1822\n",
      "    Validation Batch [1/1], Loss: 0.1935\n",
      "Validation Loss: 0.1935, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.1956\n",
      "    Validation Batch [1/1], Loss: 0.1975\n",
      "Validation Loss: 0.1975, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.1774\n",
      "    Validation Batch [1/1], Loss: 0.1997\n",
      "Validation Loss: 0.1997, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.1855\n",
      "    Validation Batch [1/1], Loss: 0.1987\n",
      "Validation Loss: 0.1987, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [387/1000] completed, Average Training Loss: 0.1719\n",
      "    Validation Batch [1/1], Loss: 0.1924\n",
      "Validation Loss: 0.1924, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.1836\n",
      "    Validation Batch [1/1], Loss: 0.1899\n",
      "Validation Loss: 0.1899, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.1855\n",
      "    Validation Batch [1/1], Loss: 0.1866\n",
      "Validation Loss: 0.1866, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1884 to 0.1866. Saving model...\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.1677\n",
      "    Validation Batch [1/1], Loss: 0.2012\n",
      "Validation Loss: 0.2012, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.1734\n",
      "    Validation Batch [1/1], Loss: 0.2300\n",
      "Validation Loss: 0.2300, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.1702\n",
      "    Validation Batch [1/1], Loss: 0.2149\n",
      "Validation Loss: 0.2149, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.1608\n",
      "    Validation Batch [1/1], Loss: 0.2093\n",
      "Validation Loss: 0.2093, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.1596\n",
      "    Validation Batch [1/1], Loss: 0.2024\n",
      "Validation Loss: 0.2024, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.1783\n",
      "    Validation Batch [1/1], Loss: 0.1844\n",
      "Validation Loss: 0.1844, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1866 to 0.1844. Saving model...\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.1626\n",
      "    Validation Batch [1/1], Loss: 0.1881\n",
      "Validation Loss: 0.1881, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.1600\n",
      "    Validation Batch [1/1], Loss: 0.2050\n",
      "Validation Loss: 0.2050, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.1636\n",
      "    Validation Batch [1/1], Loss: 0.2193\n",
      "Validation Loss: 0.2193, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.1745\n",
      "    Validation Batch [1/1], Loss: 0.2055\n",
      "Validation Loss: 0.2055, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.1651\n",
      "    Validation Batch [1/1], Loss: 0.1894\n",
      "Validation Loss: 0.1894, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.1670\n",
      "    Validation Batch [1/1], Loss: 0.1873\n",
      "Validation Loss: 0.1873, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.1677\n",
      "    Validation Batch [1/1], Loss: 0.1797\n",
      "Validation Loss: 0.1797, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1844 to 0.1797. Saving model...\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.1610\n",
      "    Validation Batch [1/1], Loss: 0.1700\n",
      "Validation Loss: 0.1700, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1797 to 0.1700. Saving model...\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.1462\n",
      "    Validation Batch [1/1], Loss: 0.1670\n",
      "Validation Loss: 0.1670, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1700 to 0.1670. Saving model...\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.1559\n",
      "    Validation Batch [1/1], Loss: 0.1646\n",
      "Validation Loss: 0.1646, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1670 to 0.1646. Saving model...\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.1580\n",
      "    Validation Batch [1/1], Loss: 0.1623\n",
      "Validation Loss: 0.1623, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1646 to 0.1623. Saving model...\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.1532\n",
      "    Validation Batch [1/1], Loss: 0.1587\n",
      "Validation Loss: 0.1587, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1623 to 0.1587. Saving model...\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.1478\n",
      "    Validation Batch [1/1], Loss: 0.1595\n",
      "Validation Loss: 0.1595, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.1496\n",
      "    Validation Batch [1/1], Loss: 0.1611\n",
      "Validation Loss: 0.1611, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [410/1000] completed, Average Training Loss: 0.1396\n",
      "    Validation Batch [1/1], Loss: 0.1592\n",
      "Validation Loss: 0.1592, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.1465\n",
      "    Validation Batch [1/1], Loss: 0.1582\n",
      "Validation Loss: 0.1582, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1587 to 0.1582. Saving model...\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.1438\n",
      "    Validation Batch [1/1], Loss: 0.1590\n",
      "Validation Loss: 0.1590, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.1547\n",
      "    Validation Batch [1/1], Loss: 0.1534\n",
      "Validation Loss: 0.1534, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1582 to 0.1534. Saving model...\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.1566\n",
      "    Validation Batch [1/1], Loss: 0.1622\n",
      "Validation Loss: 0.1622, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.1408\n",
      "    Validation Batch [1/1], Loss: 0.1611\n",
      "Validation Loss: 0.1611, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.1426\n",
      "    Validation Batch [1/1], Loss: 0.1607\n",
      "Validation Loss: 0.1607, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.1518\n",
      "    Validation Batch [1/1], Loss: 0.1686\n",
      "Validation Loss: 0.1686, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.1505\n",
      "    Validation Batch [1/1], Loss: 0.1669\n",
      "Validation Loss: 0.1669, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.1397\n",
      "    Validation Batch [1/1], Loss: 0.1654\n",
      "Validation Loss: 0.1654, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.1455\n",
      "    Validation Batch [1/1], Loss: 0.1597\n",
      "Validation Loss: 0.1597, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.1366\n",
      "    Validation Batch [1/1], Loss: 0.1592\n",
      "Validation Loss: 0.1592, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.1451\n",
      "    Validation Batch [1/1], Loss: 0.1657\n",
      "Validation Loss: 0.1657, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n",
      "Epoch [423/1000] completed, Average Training Loss: 0.1450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1579\n",
      "Validation Loss: 0.1579, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.1472\n",
      "    Validation Batch [1/1], Loss: 0.1449\n",
      "Validation Loss: 0.1449, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1534 to 0.1449. Saving model...\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.1584\n",
      "    Validation Batch [1/1], Loss: 0.1462\n",
      "Validation Loss: 0.1462, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.1368\n",
      "    Validation Batch [1/1], Loss: 0.1465\n",
      "Validation Loss: 0.1465, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.1342\n",
      "    Validation Batch [1/1], Loss: 0.1564\n",
      "Validation Loss: 0.1564, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.1455\n",
      "    Validation Batch [1/1], Loss: 0.1589\n",
      "Validation Loss: 0.1589, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.1293\n",
      "    Validation Batch [1/1], Loss: 0.1482\n",
      "Validation Loss: 0.1482, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.1351\n",
      "    Validation Batch [1/1], Loss: 0.1463\n",
      "Validation Loss: 0.1463, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.1409\n",
      "    Validation Batch [1/1], Loss: 0.1549\n",
      "Validation Loss: 0.1549, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.1342\n",
      "    Validation Batch [1/1], Loss: 0.1634\n",
      "Validation Loss: 0.1634, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.1281\n",
      "    Validation Batch [1/1], Loss: 0.1655\n",
      "Validation Loss: 0.1655, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.1121\n",
      "    Validation Batch [1/1], Loss: 0.1584\n",
      "Validation Loss: 0.1584, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.1324\n",
      "    Validation Batch [1/1], Loss: 0.1576\n",
      "Validation Loss: 0.1576, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.1358\n",
      "    Validation Batch [1/1], Loss: 0.1503\n",
      "Validation Loss: 0.1503, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.1342\n",
      "    Validation Batch [1/1], Loss: 0.1629\n",
      "Validation Loss: 0.1629, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.1244\n",
      "    Validation Batch [1/1], Loss: 0.1768\n",
      "Validation Loss: 0.1768, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.1298\n",
      "    Validation Batch [1/1], Loss: 0.1647\n",
      "Validation Loss: 0.1647, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.1290\n",
      "    Validation Batch [1/1], Loss: 0.1458\n",
      "Validation Loss: 0.1458, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.1130\n",
      "    Validation Batch [1/1], Loss: 0.1471\n",
      "Validation Loss: 0.1471, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.1149\n",
      "    Validation Batch [1/1], Loss: 0.1499\n",
      "Validation Loss: 0.1499, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.1201\n",
      "    Validation Batch [1/1], Loss: 0.1529\n",
      "Validation Loss: 0.1529, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.1117\n",
      "    Validation Batch [1/1], Loss: 0.1562\n",
      "Validation Loss: 0.1562, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.1119\n",
      "    Validation Batch [1/1], Loss: 0.1583\n",
      "Validation Loss: 0.1583, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [446/1000] completed, Average Training Loss: 0.1156\n",
      "    Validation Batch [1/1], Loss: 0.1592\n",
      "Validation Loss: 0.1592, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.1204\n",
      "    Validation Batch [1/1], Loss: 0.1569\n",
      "Validation Loss: 0.1569, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.1025\n",
      "    Validation Batch [1/1], Loss: 0.1559\n",
      "Validation Loss: 0.1559, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.1001\n",
      "    Validation Batch [1/1], Loss: 0.1496\n",
      "Validation Loss: 0.1496, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.1223\n",
      "    Validation Batch [1/1], Loss: 0.1351\n",
      "Validation Loss: 0.1351, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1449 to 0.1351. Saving model...\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.1156\n",
      "    Validation Batch [1/1], Loss: 0.1336\n",
      "Validation Loss: 0.1336, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1351 to 0.1336. Saving model...\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.1123\n",
      "    Validation Batch [1/1], Loss: 0.1397\n",
      "Validation Loss: 0.1397, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.1134\n",
      "    Validation Batch [1/1], Loss: 0.1385\n",
      "Validation Loss: 0.1385, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.1341\n",
      "    Validation Batch [1/1], Loss: 0.1331\n",
      "Validation Loss: 0.1331, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1336 to 0.1331. Saving model...\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.1222\n",
      "    Validation Batch [1/1], Loss: 0.1440\n",
      "Validation Loss: 0.1440, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.1242\n",
      "    Validation Batch [1/1], Loss: 0.1421\n",
      "Validation Loss: 0.1421, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.1144\n",
      "    Validation Batch [1/1], Loss: 0.1348\n",
      "Validation Loss: 0.1348, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.1033\n",
      "    Validation Batch [1/1], Loss: 0.1374\n",
      "Validation Loss: 0.1374, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.1309\n",
      "    Validation Batch [1/1], Loss: 0.1495\n",
      "Validation Loss: 0.1495, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.1059\n",
      "    Validation Batch [1/1], Loss: 0.1688\n",
      "Validation Loss: 0.1688, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.1101\n",
      "    Validation Batch [1/1], Loss: 0.1473\n",
      "Validation Loss: 0.1473, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.1143\n",
      "    Validation Batch [1/1], Loss: 0.1343\n",
      "Validation Loss: 0.1343, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.1129\n",
      "    Validation Batch [1/1], Loss: 0.1397\n",
      "Validation Loss: 0.1397, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.1087\n",
      "    Validation Batch [1/1], Loss: 0.1336\n",
      "Validation Loss: 0.1336, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.1102\n",
      "    Validation Batch [1/1], Loss: 0.1458\n",
      "Validation Loss: 0.1458, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.1028\n",
      "    Validation Batch [1/1], Loss: 0.1576\n",
      "Validation Loss: 0.1576, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.1117\n",
      "    Validation Batch [1/1], Loss: 0.1382\n",
      "Validation Loss: 0.1382, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.1205\n",
      "    Validation Batch [1/1], Loss: 0.1290\n",
      "Validation Loss: 0.1290, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1331 to 0.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.1096\n",
      "    Validation Batch [1/1], Loss: 0.1304\n",
      "Validation Loss: 0.1304, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [470/1000] completed, Average Training Loss: 0.1115\n",
      "    Validation Batch [1/1], Loss: 0.1221\n",
      "Validation Loss: 0.1221, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1290 to 0.1221. Saving model...\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.1089\n",
      "    Validation Batch [1/1], Loss: 0.1277\n",
      "Validation Loss: 0.1277, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0995\n",
      "    Validation Batch [1/1], Loss: 0.1400\n",
      "Validation Loss: 0.1400, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.1063\n",
      "    Validation Batch [1/1], Loss: 0.1360\n",
      "Validation Loss: 0.1360, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.1043\n",
      "    Validation Batch [1/1], Loss: 0.1300\n",
      "Validation Loss: 0.1300, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0987\n",
      "    Validation Batch [1/1], Loss: 0.1272\n",
      "Validation Loss: 0.1272, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.1017\n",
      "    Validation Batch [1/1], Loss: 0.1279\n",
      "Validation Loss: 0.1279, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0904\n",
      "    Validation Batch [1/1], Loss: 0.1307\n",
      "Validation Loss: 0.1307, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.1040\n",
      "    Validation Batch [1/1], Loss: 0.1298\n",
      "Validation Loss: 0.1298, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0924\n",
      "    Validation Batch [1/1], Loss: 0.1227\n",
      "Validation Loss: 0.1227, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.1017\n",
      "    Validation Batch [1/1], Loss: 0.1171\n",
      "Validation Loss: 0.1171, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1221 to 0.1171. Saving model...\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.0889\n",
      "    Validation Batch [1/1], Loss: 0.1200\n",
      "Validation Loss: 0.1200, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.0897\n",
      "    Validation Batch [1/1], Loss: 0.1238\n",
      "Validation Loss: 0.1238, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0989\n",
      "    Validation Batch [1/1], Loss: 0.1196\n",
      "Validation Loss: 0.1196, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.1025\n",
      "    Validation Batch [1/1], Loss: 0.1200\n",
      "Validation Loss: 0.1200, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0954\n",
      "    Validation Batch [1/1], Loss: 0.1207\n",
      "Validation Loss: 0.1207, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.1135\n",
      "Validation Loss: 0.1135, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1171 to 0.1135. Saving model...\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0930\n",
      "    Validation Batch [1/1], Loss: 0.1140\n",
      "Validation Loss: 0.1140, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0975\n",
      "    Validation Batch [1/1], Loss: 0.1155\n",
      "Validation Loss: 0.1155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0974\n",
      "    Validation Batch [1/1], Loss: 0.1165\n",
      "Validation Loss: 0.1165, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0850\n",
      "    Validation Batch [1/1], Loss: 0.1131\n",
      "Validation Loss: 0.1131, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1135 to 0.1131. Saving model...\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0867\n",
      "    Validation Batch [1/1], Loss: 0.1124\n",
      "Validation Loss: 0.1124, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1131 to 0.1124. Saving model...\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0889\n",
      "    Validation Batch [1/1], Loss: 0.1166\n",
      "Validation Loss: 0.1166, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0977\n",
      "    Validation Batch [1/1], Loss: 0.1225\n",
      "Validation Loss: 0.1225, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0946\n",
      "    Validation Batch [1/1], Loss: 0.1248\n",
      "Validation Loss: 0.1248, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [495/1000] completed, Average Training Loss: 0.0994\n",
      "    Validation Batch [1/1], Loss: 0.1231\n",
      "Validation Loss: 0.1231, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0828\n",
      "    Validation Batch [1/1], Loss: 0.1167\n",
      "Validation Loss: 0.1167, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0854\n",
      "    Validation Batch [1/1], Loss: 0.1104\n",
      "Validation Loss: 0.1104, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1124 to 0.1104. Saving model...\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0852\n",
      "    Validation Batch [1/1], Loss: 0.1070\n",
      "Validation Loss: 0.1070, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1104 to 0.1070. Saving model...\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0831\n",
      "    Validation Batch [1/1], Loss: 0.1101\n",
      "Validation Loss: 0.1101, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0941\n",
      "    Validation Batch [1/1], Loss: 0.1207\n",
      "Validation Loss: 0.1207, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0868\n",
      "    Validation Batch [1/1], Loss: 0.1238\n",
      "Validation Loss: 0.1238, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0973\n",
      "    Validation Batch [1/1], Loss: 0.1175\n",
      "Validation Loss: 0.1175, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0859\n",
      "    Validation Batch [1/1], Loss: 0.1135\n",
      "Validation Loss: 0.1135, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0862\n",
      "    Validation Batch [1/1], Loss: 0.1136\n",
      "Validation Loss: 0.1136, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0852\n",
      "    Validation Batch [1/1], Loss: 0.1141\n",
      "Validation Loss: 0.1141, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0756\n",
      "    Validation Batch [1/1], Loss: 0.1118\n",
      "Validation Loss: 0.1118, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0821\n",
      "    Validation Batch [1/1], Loss: 0.1106\n",
      "Validation Loss: 0.1106, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0946\n",
      "    Validation Batch [1/1], Loss: 0.1164\n",
      "Validation Loss: 0.1164, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0797\n",
      "    Validation Batch [1/1], Loss: 0.1217\n",
      "Validation Loss: 0.1217, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0891\n",
      "    Validation Batch [1/1], Loss: 0.1189\n",
      "Validation Loss: 0.1189, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0750\n",
      "    Validation Batch [1/1], Loss: 0.1142\n",
      "Validation Loss: 0.1142, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0819\n",
      "    Validation Batch [1/1], Loss: 0.1108\n",
      "Validation Loss: 0.1108, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0883\n",
      "    Validation Batch [1/1], Loss: 0.1085\n",
      "Validation Loss: 0.1085, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0899\n",
      "    Validation Batch [1/1], Loss: 0.1075\n",
      "Validation Loss: 0.1075, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0782\n",
      "    Validation Batch [1/1], Loss: 0.1087\n",
      "Validation Loss: 0.1087, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0786\n",
      "    Validation Batch [1/1], Loss: 0.1087\n",
      "Validation Loss: 0.1087, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0868\n",
      "    Validation Batch [1/1], Loss: 0.1059\n",
      "Validation Loss: 0.1059, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1070 to 0.1059. Saving model...\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0893\n",
      "    Validation Batch [1/1], Loss: 0.1043\n",
      "Validation Loss: 0.1043, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1059 to 0.1043. Saving model...\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [519/1000] completed, Average Training Loss: 0.0818\n",
      "    Validation Batch [1/1], Loss: 0.1042\n",
      "Validation Loss: 0.1042, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1043 to 0.1042. Saving model...\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0768\n",
      "    Validation Batch [1/1], Loss: 0.1056\n",
      "Validation Loss: 0.1056, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0856\n",
      "    Validation Batch [1/1], Loss: 0.1083\n",
      "Validation Loss: 0.1083, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0795\n",
      "    Validation Batch [1/1], Loss: 0.1136\n",
      "Validation Loss: 0.1136, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0819\n",
      "    Validation Batch [1/1], Loss: 0.1079\n",
      "Validation Loss: 0.1079, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0758\n",
      "    Validation Batch [1/1], Loss: 0.1036\n",
      "Validation Loss: 0.1036, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1042 to 0.1036. Saving model...\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0686\n",
      "    Validation Batch [1/1], Loss: 0.1018\n",
      "Validation Loss: 0.1018, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1036 to 0.1018. Saving model...\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0721\n",
      "    Validation Batch [1/1], Loss: 0.1052\n",
      "Validation Loss: 0.1052, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0832\n",
      "    Validation Batch [1/1], Loss: 0.1000\n",
      "Validation Loss: 0.1000, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1018 to 0.1000. Saving model...\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0827\n",
      "    Validation Batch [1/1], Loss: 0.0980\n",
      "Validation Loss: 0.0980, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1000 to 0.0980. Saving model...\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0711\n",
      "    Validation Batch [1/1], Loss: 0.0998\n",
      "Validation Loss: 0.0998, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0721\n",
      "    Validation Batch [1/1], Loss: 0.1064\n",
      "Validation Loss: 0.1064, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0786\n",
      "    Validation Batch [1/1], Loss: 0.1083\n",
      "Validation Loss: 0.1083, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0740\n",
      "    Validation Batch [1/1], Loss: 0.1041\n",
      "Validation Loss: 0.1041, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0686\n",
      "    Validation Batch [1/1], Loss: 0.1056\n",
      "Validation Loss: 0.1056, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0833\n",
      "    Validation Batch [1/1], Loss: 0.1117\n",
      "Validation Loss: 0.1117, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0755\n",
      "    Validation Batch [1/1], Loss: 0.1126\n",
      "Validation Loss: 0.1126, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0695\n",
      "    Validation Batch [1/1], Loss: 0.1097\n",
      "Validation Loss: 0.1097, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0794\n",
      "    Validation Batch [1/1], Loss: 0.1086\n",
      "Validation Loss: 0.1086, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0796\n",
      "    Validation Batch [1/1], Loss: 0.1025\n",
      "Validation Loss: 0.1025, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0756\n",
      "    Validation Batch [1/1], Loss: 0.1008\n",
      "Validation Loss: 0.1008, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0682\n",
      "    Validation Batch [1/1], Loss: 0.1040\n",
      "Validation Loss: 0.1040, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0735\n",
      "    Validation Batch [1/1], Loss: 0.1067\n",
      "Validation Loss: 0.1067, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.1075\n",
      "Validation Loss: 0.1075, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [543/1000] completed, Average Training Loss: 0.0695\n",
      "    Validation Batch [1/1], Loss: 0.1141\n",
      "Validation Loss: 0.1141, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0686\n",
      "    Validation Batch [1/1], Loss: 0.1252\n",
      "Validation Loss: 0.1252, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0657\n",
      "    Validation Batch [1/1], Loss: 0.1239\n",
      "Validation Loss: 0.1239, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0773\n",
      "    Validation Batch [1/1], Loss: 0.1116\n",
      "Validation Loss: 0.1116, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0655\n",
      "    Validation Batch [1/1], Loss: 0.1076\n",
      "Validation Loss: 0.1076, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0819\n",
      "    Validation Batch [1/1], Loss: 0.1166\n",
      "Validation Loss: 0.1166, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0734\n",
      "    Validation Batch [1/1], Loss: 0.1132\n",
      "Validation Loss: 0.1132, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0773\n",
      "    Validation Batch [1/1], Loss: 0.1052\n",
      "Validation Loss: 0.1052, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0749\n",
      "    Validation Batch [1/1], Loss: 0.1030\n",
      "Validation Loss: 0.1030, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0643\n",
      "    Validation Batch [1/1], Loss: 0.1029\n",
      "Validation Loss: 0.1029, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0680\n",
      "    Validation Batch [1/1], Loss: 0.0997\n",
      "Validation Loss: 0.0997, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0699\n",
      "    Validation Batch [1/1], Loss: 0.0932\n",
      "Validation Loss: 0.0932, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0980 to 0.0932. Saving model...\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0642\n",
      "    Validation Batch [1/1], Loss: 0.0903\n",
      "Validation Loss: 0.0903, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0932 to 0.0903. Saving model...\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0682\n",
      "    Validation Batch [1/1], Loss: 0.0947\n",
      "Validation Loss: 0.0947, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0589\n",
      "    Validation Batch [1/1], Loss: 0.0974\n",
      "Validation Loss: 0.0974, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0665\n",
      "    Validation Batch [1/1], Loss: 0.0955\n",
      "Validation Loss: 0.0955, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0699\n",
      "    Validation Batch [1/1], Loss: 0.0939\n",
      "Validation Loss: 0.0939, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0638\n",
      "    Validation Batch [1/1], Loss: 0.0940\n",
      "Validation Loss: 0.0940, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0657\n",
      "    Validation Batch [1/1], Loss: 0.0980\n",
      "Validation Loss: 0.0980, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0689\n",
      "    Validation Batch [1/1], Loss: 0.0975\n",
      "Validation Loss: 0.0975, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0659\n",
      "    Validation Batch [1/1], Loss: 0.0979\n",
      "Validation Loss: 0.0979, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0629\n",
      "    Validation Batch [1/1], Loss: 0.0982\n",
      "Validation Loss: 0.0982, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0698\n",
      "    Validation Batch [1/1], Loss: 0.0951\n",
      "Validation Loss: 0.0951, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0666\n",
      "    Validation Batch [1/1], Loss: 0.0957\n",
      "Validation Loss: 0.0957, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0588\n",
      "    Validation Batch [1/1], Loss: 0.1003\n",
      "Validation Loss: 0.1003, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [568/1000] completed, Average Training Loss: 0.0556\n",
      "    Validation Batch [1/1], Loss: 0.0988\n",
      "Validation Loss: 0.0988, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0632\n",
      "    Validation Batch [1/1], Loss: 0.0983\n",
      "Validation Loss: 0.0983, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.0967\n",
      "Validation Loss: 0.0967, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0592\n",
      "    Validation Batch [1/1], Loss: 0.0950\n",
      "Validation Loss: 0.0950, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0566\n",
      "    Validation Batch [1/1], Loss: 0.0919\n",
      "Validation Loss: 0.0919, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0663\n",
      "    Validation Batch [1/1], Loss: 0.0895\n",
      "Validation Loss: 0.0895, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0903 to 0.0895. Saving model...\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0660\n",
      "    Validation Batch [1/1], Loss: 0.0922\n",
      "Validation Loss: 0.0922, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.1046\n",
      "Validation Loss: 0.1046, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.1170\n",
      "Validation Loss: 0.1170, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0657\n",
      "    Validation Batch [1/1], Loss: 0.1020\n",
      "Validation Loss: 0.1020, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0531\n",
      "    Validation Batch [1/1], Loss: 0.0880\n",
      "Validation Loss: 0.0880, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0895 to 0.0880. Saving model...\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0661\n",
      "    Validation Batch [1/1], Loss: 0.0896\n",
      "Validation Loss: 0.0896, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0573\n",
      "    Validation Batch [1/1], Loss: 0.0924\n",
      "Validation Loss: 0.0924, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0703\n",
      "    Validation Batch [1/1], Loss: 0.0950\n",
      "Validation Loss: 0.0950, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0613\n",
      "    Validation Batch [1/1], Loss: 0.0959\n",
      "Validation Loss: 0.0959, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0625\n",
      "    Validation Batch [1/1], Loss: 0.0970\n",
      "Validation Loss: 0.0970, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0595\n",
      "    Validation Batch [1/1], Loss: 0.0974\n",
      "Validation Loss: 0.0974, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0568\n",
      "    Validation Batch [1/1], Loss: 0.0974\n",
      "Validation Loss: 0.0974, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0601\n",
      "    Validation Batch [1/1], Loss: 0.0957\n",
      "Validation Loss: 0.0957, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0692\n",
      "    Validation Batch [1/1], Loss: 0.0949\n",
      "Validation Loss: 0.0949, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0608\n",
      "    Validation Batch [1/1], Loss: 0.0933\n",
      "Validation Loss: 0.0933, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0578\n",
      "    Validation Batch [1/1], Loss: 0.0895\n",
      "Validation Loss: 0.0895, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0567\n",
      "    Validation Batch [1/1], Loss: 0.0852\n",
      "Validation Loss: 0.0852, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0880 to 0.0852. Saving model...\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [591/1000] completed, Average Training Loss: 0.0663\n",
      "    Validation Batch [1/1], Loss: 0.0846\n",
      "Validation Loss: 0.0846, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0852 to 0.0846. Saving model...\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.0881\n",
      "Validation Loss: 0.0881, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0517\n",
      "    Validation Batch [1/1], Loss: 0.0865\n",
      "Validation Loss: 0.0865, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0555\n",
      "    Validation Batch [1/1], Loss: 0.0832\n",
      "Validation Loss: 0.0832, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0846 to 0.0832. Saving model...\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0519\n",
      "    Validation Batch [1/1], Loss: 0.0793\n",
      "Validation Loss: 0.0793, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0832 to 0.0793. Saving model...\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0586\n",
      "    Validation Batch [1/1], Loss: 0.0789\n",
      "Validation Loss: 0.0789, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0793 to 0.0789. Saving model...\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0566\n",
      "    Validation Batch [1/1], Loss: 0.0813\n",
      "Validation Loss: 0.0813, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0530\n",
      "    Validation Batch [1/1], Loss: 0.0870\n",
      "Validation Loss: 0.0870, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0686\n",
      "    Validation Batch [1/1], Loss: 0.0973\n",
      "Validation Loss: 0.0973, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0526\n",
      "    Validation Batch [1/1], Loss: 0.1067\n",
      "Validation Loss: 0.1067, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0564\n",
      "    Validation Batch [1/1], Loss: 0.1055\n",
      "Validation Loss: 0.1055, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0613\n",
      "    Validation Batch [1/1], Loss: 0.0948\n",
      "Validation Loss: 0.0948, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0464\n",
      "    Validation Batch [1/1], Loss: 0.0861\n",
      "Validation Loss: 0.0861, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.0832\n",
      "Validation Loss: 0.0832, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0663\n",
      "    Validation Batch [1/1], Loss: 0.0827\n",
      "Validation Loss: 0.0827, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0597\n",
      "    Validation Batch [1/1], Loss: 0.0811\n",
      "Validation Loss: 0.0811, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0631\n",
      "    Validation Batch [1/1], Loss: 0.0827\n",
      "Validation Loss: 0.0827, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0554\n",
      "    Validation Batch [1/1], Loss: 0.0864\n",
      "Validation Loss: 0.0864, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.0832\n",
      "Validation Loss: 0.0832, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0541\n",
      "    Validation Batch [1/1], Loss: 0.0803\n",
      "Validation Loss: 0.0803, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0529\n",
      "    Validation Batch [1/1], Loss: 0.0770\n",
      "Validation Loss: 0.0770, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0789 to 0.0770. Saving model...\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0585\n",
      "    Validation Batch [1/1], Loss: 0.0753\n",
      "Validation Loss: 0.0753, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0770 to 0.0753. Saving model...\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0508\n",
      "    Validation Batch [1/1], Loss: 0.0758\n",
      "Validation Loss: 0.0758, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.0772\n",
      "Validation Loss: 0.0772, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [615/1000] completed, Average Training Loss: 0.0598\n",
      "    Validation Batch [1/1], Loss: 0.0774\n",
      "Validation Loss: 0.0774, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0527\n",
      "    Validation Batch [1/1], Loss: 0.0782\n",
      "Validation Loss: 0.0782, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0423\n",
      "    Validation Batch [1/1], Loss: 0.0797\n",
      "Validation Loss: 0.0797, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0489\n",
      "    Validation Batch [1/1], Loss: 0.0827\n",
      "Validation Loss: 0.0827, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0526\n",
      "    Validation Batch [1/1], Loss: 0.0902\n",
      "Validation Loss: 0.0902, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0482\n",
      "    Validation Batch [1/1], Loss: 0.0931\n",
      "Validation Loss: 0.0931, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.0924\n",
      "Validation Loss: 0.0924, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.0914\n",
      "Validation Loss: 0.0914, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.0888\n",
      "Validation Loss: 0.0888, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0455\n",
      "    Validation Batch [1/1], Loss: 0.0865\n",
      "Validation Loss: 0.0865, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0419\n",
      "    Validation Batch [1/1], Loss: 0.0841\n",
      "Validation Loss: 0.0841, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0555\n",
      "    Validation Batch [1/1], Loss: 0.0805\n",
      "Validation Loss: 0.0805, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0527\n",
      "    Validation Batch [1/1], Loss: 0.0779\n",
      "Validation Loss: 0.0779, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0512\n",
      "    Validation Batch [1/1], Loss: 0.0820\n",
      "Validation Loss: 0.0820, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0603\n",
      "    Validation Batch [1/1], Loss: 0.0833\n",
      "Validation Loss: 0.0833, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0501\n",
      "    Validation Batch [1/1], Loss: 0.0800\n",
      "Validation Loss: 0.0800, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0487\n",
      "    Validation Batch [1/1], Loss: 0.0750\n",
      "Validation Loss: 0.0750, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0753 to 0.0750. Saving model...\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.0731\n",
      "Validation Loss: 0.0731, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0750 to 0.0731. Saving model...\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.0730\n",
      "Validation Loss: 0.0730, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0731 to 0.0730. Saving model...\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.0725\n",
      "Validation Loss: 0.0725, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0730 to 0.0725. Saving model...\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0398\n",
      "    Validation Batch [1/1], Loss: 0.0691\n",
      "Validation Loss: 0.0691, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0725 to 0.0691. Saving model...\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.0707\n",
      "Validation Loss: 0.0707, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0511\n",
      "    Validation Batch [1/1], Loss: 0.0850\n",
      "Validation Loss: 0.0850, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [638/1000] completed, Average Training Loss: 0.0497\n",
      "    Validation Batch [1/1], Loss: 0.0914\n",
      "Validation Loss: 0.0914, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0541\n",
      "    Validation Batch [1/1], Loss: 0.0833\n",
      "Validation Loss: 0.0833, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0466\n",
      "    Validation Batch [1/1], Loss: 0.0751\n",
      "Validation Loss: 0.0751, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0489\n",
      "    Validation Batch [1/1], Loss: 0.0765\n",
      "Validation Loss: 0.0765, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0442\n",
      "    Validation Batch [1/1], Loss: 0.0790\n",
      "Validation Loss: 0.0790, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0469\n",
      "    Validation Batch [1/1], Loss: 0.0791\n",
      "Validation Loss: 0.0791, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.0820\n",
      "Validation Loss: 0.0820, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0486\n",
      "    Validation Batch [1/1], Loss: 0.0962\n",
      "Validation Loss: 0.0962, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.1123\n",
      "Validation Loss: 0.1123, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0468\n",
      "    Validation Batch [1/1], Loss: 0.1008\n",
      "Validation Loss: 0.1008, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0573\n",
      "    Validation Batch [1/1], Loss: 0.0867\n",
      "Validation Loss: 0.0867, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0486\n",
      "    Validation Batch [1/1], Loss: 0.0866\n",
      "Validation Loss: 0.0866, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.0967\n",
      "Validation Loss: 0.0967, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0554\n",
      "    Validation Batch [1/1], Loss: 0.0852\n",
      "Validation Loss: 0.0852, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0539\n",
      "    Validation Batch [1/1], Loss: 0.0706\n",
      "Validation Loss: 0.0706, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0809\n",
      "Validation Loss: 0.0809, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.1041\n",
      "Validation Loss: 0.1041, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.0858\n",
      "Validation Loss: 0.0858, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.0784\n",
      "Validation Loss: 0.0784, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.0825\n",
      "Validation Loss: 0.0825, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0511\n",
      "    Validation Batch [1/1], Loss: 0.0883\n",
      "Validation Loss: 0.0883, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [659/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.0898\n",
      "Validation Loss: 0.0898, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0462\n",
      "    Validation Batch [1/1], Loss: 0.0889\n",
      "Validation Loss: 0.0889, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.0901\n",
      "Validation Loss: 0.0901, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.0907\n",
      "Validation Loss: 0.0907, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0472\n",
      "    Validation Batch [1/1], Loss: 0.0848\n",
      "Validation Loss: 0.0848, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0430\n",
      "    Validation Batch [1/1], Loss: 0.0765\n",
      "Validation Loss: 0.0765, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0398\n",
      "    Validation Batch [1/1], Loss: 0.0720\n",
      "Validation Loss: 0.0720, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.0687\n",
      "Validation Loss: 0.0687, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0691 to 0.0687. Saving model...\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0416\n",
      "    Validation Batch [1/1], Loss: 0.0643\n",
      "Validation Loss: 0.0643, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0687 to 0.0643. Saving model...\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.0634\n",
      "Validation Loss: 0.0634, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0643 to 0.0634. Saving model...\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.0654\n",
      "Validation Loss: 0.0654, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0508\n",
      "    Validation Batch [1/1], Loss: 0.0677\n",
      "Validation Loss: 0.0677, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0441\n",
      "    Validation Batch [1/1], Loss: 0.0721\n",
      "Validation Loss: 0.0721, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0451\n",
      "    Validation Batch [1/1], Loss: 0.0747\n",
      "Validation Loss: 0.0747, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.0732\n",
      "Validation Loss: 0.0732, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0405\n",
      "    Validation Batch [1/1], Loss: 0.0723\n",
      "Validation Loss: 0.0723, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.0740\n",
      "Validation Loss: 0.0740, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0765\n",
      "Validation Loss: 0.0765, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.0787\n",
      "Validation Loss: 0.0787, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.0810\n",
      "Validation Loss: 0.0810, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0330\n",
      "    Validation Batch [1/1], Loss: 0.0815\n",
      "Validation Loss: 0.0815, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0409\n",
      "    Validation Batch [1/1], Loss: 0.0808\n",
      "Validation Loss: 0.0808, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [681/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.0778\n",
      "Validation Loss: 0.0778, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0371\n",
      "    Validation Batch [1/1], Loss: 0.0770\n",
      "Validation Loss: 0.0770, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.0779\n",
      "Validation Loss: 0.0779, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.0765\n",
      "Validation Loss: 0.0765, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.0751\n",
      "Validation Loss: 0.0751, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.0740\n",
      "Validation Loss: 0.0740, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0374\n",
      "    Validation Batch [1/1], Loss: 0.0728\n",
      "Validation Loss: 0.0728, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0471\n",
      "    Validation Batch [1/1], Loss: 0.0730\n",
      "Validation Loss: 0.0730, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0389\n",
      "    Validation Batch [1/1], Loss: 0.0728\n",
      "Validation Loss: 0.0728, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.0729\n",
      "Validation Loss: 0.0729, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.0705\n",
      "Validation Loss: 0.0705, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.0685\n",
      "Validation Loss: 0.0685, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0414\n",
      "    Validation Batch [1/1], Loss: 0.0677\n",
      "Validation Loss: 0.0677, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0376\n",
      "    Validation Batch [1/1], Loss: 0.0700\n",
      "Validation Loss: 0.0700, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0483\n",
      "    Validation Batch [1/1], Loss: 0.0707\n",
      "Validation Loss: 0.0707, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0407\n",
      "    Validation Batch [1/1], Loss: 0.0705\n",
      "Validation Loss: 0.0705, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0699\n",
      "Validation Loss: 0.0699, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0403\n",
      "    Validation Batch [1/1], Loss: 0.0686\n",
      "Validation Loss: 0.0686, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0434\n",
      "    Validation Batch [1/1], Loss: 0.0688\n",
      "Validation Loss: 0.0688, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.0659\n",
      "Validation Loss: 0.0659, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.0655\n",
      "Validation Loss: 0.0655, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0434\n",
      "    Validation Batch [1/1], Loss: 0.0673\n",
      "Validation Loss: 0.0673, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.0683\n",
      "Validation Loss: 0.0683, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [704/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.0727\n",
      "Validation Loss: 0.0727, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0402\n",
      "    Validation Batch [1/1], Loss: 0.0793\n",
      "Validation Loss: 0.0793, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0329\n",
      "    Validation Batch [1/1], Loss: 0.0800\n",
      "Validation Loss: 0.0800, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0464\n",
      "    Validation Batch [1/1], Loss: 0.0804\n",
      "Validation Loss: 0.0804, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0302\n",
      "    Validation Batch [1/1], Loss: 0.0779\n",
      "Validation Loss: 0.0779, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0413\n",
      "    Validation Batch [1/1], Loss: 0.0711\n",
      "Validation Loss: 0.0711, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0678\n",
      "Validation Loss: 0.0678, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.0686\n",
      "Validation Loss: 0.0686, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0347\n",
      "    Validation Batch [1/1], Loss: 0.0718\n",
      "Validation Loss: 0.0718, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.0736\n",
      "Validation Loss: 0.0736, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0348\n",
      "    Validation Batch [1/1], Loss: 0.0724\n",
      "Validation Loss: 0.0724, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0270\n",
      "    Validation Batch [1/1], Loss: 0.0742\n",
      "Validation Loss: 0.0742, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.0727\n",
      "Validation Loss: 0.0727, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0344\n",
      "    Validation Batch [1/1], Loss: 0.0760\n",
      "Validation Loss: 0.0760, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.0764\n",
      "Validation Loss: 0.0764, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0748\n",
      "Validation Loss: 0.0748, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0388\n",
      "    Validation Batch [1/1], Loss: 0.0725\n",
      "Validation Loss: 0.0725, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.0724\n",
      "Validation Loss: 0.0724, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.0722\n",
      "Validation Loss: 0.0722, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.0739\n",
      "Validation Loss: 0.0739, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0731\n",
      "Validation Loss: 0.0731, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.0722\n",
      "Validation Loss: 0.0722, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0710\n",
      "Validation Loss: 0.0710, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.0735\n",
      "Validation Loss: 0.0735, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [728/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.0842\n",
      "Validation Loss: 0.0842, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0870\n",
      "Validation Loss: 0.0870, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0392\n",
      "    Validation Batch [1/1], Loss: 0.0776\n",
      "Validation Loss: 0.0776, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.0753\n",
      "Validation Loss: 0.0753, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.0744\n",
      "Validation Loss: 0.0744, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0343\n",
      "    Validation Batch [1/1], Loss: 0.0817\n",
      "Validation Loss: 0.0817, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0433\n",
      "    Validation Batch [1/1], Loss: 0.0849\n",
      "Validation Loss: 0.0849, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.0834\n",
      "Validation Loss: 0.0834, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.0732\n",
      "Validation Loss: 0.0732, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0378\n",
      "    Validation Batch [1/1], Loss: 0.0768\n",
      "Validation Loss: 0.0768, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.0849\n",
      "Validation Loss: 0.0849, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.0798\n",
      "Validation Loss: 0.0798, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.0684\n",
      "Validation Loss: 0.0684, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0345\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0376\n",
      "    Validation Batch [1/1], Loss: 0.0638\n",
      "Validation Loss: 0.0638, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.0662\n",
      "Validation Loss: 0.0662, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0692\n",
      "Validation Loss: 0.0692, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0697\n",
      "Validation Loss: 0.0697, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n",
      "Epoch [746/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.0671\n",
      "Validation Loss: 0.0671, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.0688\n",
      "Validation Loss: 0.0688, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.0694\n",
      "Validation Loss: 0.0694, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.0704\n",
      "Validation Loss: 0.0704, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0317\n",
      "    Validation Batch [1/1], Loss: 0.0754\n",
      "Validation Loss: 0.0754, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [751/1000] completed, Average Training Loss: 0.0302\n",
      "    Validation Batch [1/1], Loss: 0.0773\n",
      "Validation Loss: 0.0773, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.0749\n",
      "Validation Loss: 0.0749, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.0705\n",
      "Validation Loss: 0.0705, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0292\n",
      "    Validation Batch [1/1], Loss: 0.0664\n",
      "Validation Loss: 0.0664, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0724\n",
      "Validation Loss: 0.0724, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0808\n",
      "Validation Loss: 0.0808, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0330\n",
      "    Validation Batch [1/1], Loss: 0.0798\n",
      "Validation Loss: 0.0798, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.0741\n",
      "Validation Loss: 0.0741, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.0627\n",
      "Validation Loss: 0.0627, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0634 to 0.0627. Saving model...\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0344\n",
      "    Validation Batch [1/1], Loss: 0.0602\n",
      "Validation Loss: 0.0602, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0627 to 0.0602. Saving model...\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0592\n",
      "Validation Loss: 0.0592, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0602 to 0.0592. Saving model...\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.0575\n",
      "Validation Loss: 0.0575, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0592 to 0.0575. Saving model...\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.0575\n",
      "Validation Loss: 0.0575, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0292\n",
      "    Validation Batch [1/1], Loss: 0.0612\n",
      "Validation Loss: 0.0612, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.0620\n",
      "Validation Loss: 0.0620, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.0653\n",
      "Validation Loss: 0.0653, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n",
      "Epoch [768/1000] completed, Average Training Loss: 0.0329\n",
      "    Validation Batch [1/1], Loss: 0.0674\n",
      "Validation Loss: 0.0674, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.0687\n",
      "Validation Loss: 0.0687, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.0627\n",
      "Validation Loss: 0.0627, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.0583\n",
      "Validation Loss: 0.0583, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.0587\n",
      "Validation Loss: 0.0587, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0608\n",
      "Validation Loss: 0.0608, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0279\n",
      "    Validation Batch [1/1], Loss: 0.0611\n",
      "Validation Loss: 0.0611, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0581\n",
      "Validation Loss: 0.0581, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [776/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.0573\n",
      "Validation Loss: 0.0573, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0575 to 0.0573. Saving model...\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.0640\n",
      "Validation Loss: 0.0640, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.0660\n",
      "Validation Loss: 0.0660, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.0606\n",
      "Validation Loss: 0.0606, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n",
      "Epoch [780/1000] completed, Average Training Loss: 0.0322\n",
      "    Validation Batch [1/1], Loss: 0.0558\n",
      "Validation Loss: 0.0558, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0573 to 0.0558. Saving model...\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n",
      "Epoch [781/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.0550\n",
      "Validation Loss: 0.0550, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0558 to 0.0550. Saving model...\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.0557\n",
      "Validation Loss: 0.0557, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.0579\n",
      "Validation Loss: 0.0579, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0354\n",
      "    Validation Batch [1/1], Loss: 0.0604\n",
      "Validation Loss: 0.0604, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n",
      "Epoch [785/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.0623\n",
      "Validation Loss: 0.0623, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.0624\n",
      "Validation Loss: 0.0624, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.0659\n",
      "Validation Loss: 0.0659, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0680\n",
      "Validation Loss: 0.0680, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0704\n",
      "Validation Loss: 0.0704, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0317\n",
      "    Validation Batch [1/1], Loss: 0.0694\n",
      "Validation Loss: 0.0694, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n",
      "Epoch [792/1000] completed, Average Training Loss: 0.0250\n",
      "    Validation Batch [1/1], Loss: 0.0708\n",
      "Validation Loss: 0.0708, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0711\n",
      "Validation Loss: 0.0711, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.0712\n",
      "Validation Loss: 0.0712, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.0704\n",
      "Validation Loss: 0.0704, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0677\n",
      "Validation Loss: 0.0677, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.0645\n",
      "Validation Loss: 0.0645, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0651\n",
      "Validation Loss: 0.0651, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0667\n",
      "Validation Loss: 0.0667, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [800/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0667\n",
      "Validation Loss: 0.0667, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.0633\n",
      "Validation Loss: 0.0633, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.0642\n",
      "Validation Loss: 0.0642, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n",
      "Epoch [803/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0720\n",
      "Validation Loss: 0.0720, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.0723\n",
      "Validation Loss: 0.0723, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n",
      "Epoch [805/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.0673\n",
      "Validation Loss: 0.0673, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.0591\n",
      "Validation Loss: 0.0591, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0539\n",
      "Validation Loss: 0.0539, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0550 to 0.0539. Saving model...\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.0569\n",
      "Validation Loss: 0.0569, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n",
      "Epoch [809/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0641\n",
      "Validation Loss: 0.0641, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0311\n",
      "    Validation Batch [1/1], Loss: 0.0688\n",
      "Validation Loss: 0.0688, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0238\n",
      "    Validation Batch [1/1], Loss: 0.0744\n",
      "Validation Loss: 0.0744, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0276\n",
      "    Validation Batch [1/1], Loss: 0.0759\n",
      "Validation Loss: 0.0759, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0674\n",
      "Validation Loss: 0.0674, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n",
      "Epoch [814/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.0647\n",
      "Validation Loss: 0.0647, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.0626\n",
      "Validation Loss: 0.0626, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.0605\n",
      "Validation Loss: 0.0605, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.0578\n",
      "Validation Loss: 0.0578, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0566\n",
      "Validation Loss: 0.0566, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0314\n",
      "    Validation Batch [1/1], Loss: 0.0548\n",
      "Validation Loss: 0.0548, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.0590\n",
      "Validation Loss: 0.0590, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.0661\n",
      "Validation Loss: 0.0661, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.0663\n",
      "Validation Loss: 0.0663, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [823/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.0612\n",
      "Validation Loss: 0.0612, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n",
      "Epoch [824/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0589\n",
      "Validation Loss: 0.0589, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n",
      "Epoch [825/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.0611\n",
      "Validation Loss: 0.0611, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.0593\n",
      "Validation Loss: 0.0593, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n",
      "Epoch [827/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.0577\n",
      "Validation Loss: 0.0577, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n",
      "Epoch [828/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0623\n",
      "Validation Loss: 0.0623, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.0648\n",
      "Validation Loss: 0.0648, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [830/1000] - Training\n",
      "Epoch [830/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.0626\n",
      "Validation Loss: 0.0626, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [831/1000] - Training\n",
      "Epoch [831/1000] completed, Average Training Loss: 0.0287\n",
      "    Validation Batch [1/1], Loss: 0.0587\n",
      "Validation Loss: 0.0587, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [832/1000] - Training\n",
      "Epoch [832/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.0557\n",
      "Validation Loss: 0.0557, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [833/1000] - Training\n",
      "Epoch [833/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0570\n",
      "Validation Loss: 0.0570, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [834/1000] - Training\n",
      "Epoch [834/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0601\n",
      "Validation Loss: 0.0601, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [835/1000] - Training\n",
      "Epoch [835/1000] completed, Average Training Loss: 0.0281\n",
      "    Validation Batch [1/1], Loss: 0.0666\n",
      "Validation Loss: 0.0666, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [836/1000] - Training\n",
      "Epoch [836/1000] completed, Average Training Loss: 0.0276\n",
      "    Validation Batch [1/1], Loss: 0.0713\n",
      "Validation Loss: 0.0713, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [837/1000] - Training\n",
      "Epoch [837/1000] completed, Average Training Loss: 0.0282\n",
      "    Validation Batch [1/1], Loss: 0.0736\n",
      "Validation Loss: 0.0736, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [838/1000] - Training\n",
      "Epoch [838/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0737\n",
      "Validation Loss: 0.0737, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [839/1000] - Training\n",
      "Epoch [839/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0728\n",
      "Validation Loss: 0.0728, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [840/1000] - Training\n",
      "Epoch [840/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0684\n",
      "Validation Loss: 0.0684, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [841/1000] - Training\n",
      "Epoch [841/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [842/1000] - Training\n",
      "Epoch [842/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0638\n",
      "Validation Loss: 0.0638, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [843/1000] - Training\n",
      "Epoch [843/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.0606\n",
      "Validation Loss: 0.0606, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [844/1000] - Training\n",
      "Epoch [844/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.0612\n",
      "Validation Loss: 0.0612, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [845/1000] - Training\n",
      "Epoch [845/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.0645\n",
      "Validation Loss: 0.0645, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [846/1000] - Training\n",
      "Epoch [846/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.0670\n",
      "Validation Loss: 0.0670, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [847/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [847/1000] completed, Average Training Loss: 0.0196\n",
      "    Validation Batch [1/1], Loss: 0.0671\n",
      "Validation Loss: 0.0671, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [848/1000] - Training\n",
      "Epoch [848/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.0620\n",
      "Validation Loss: 0.0620, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [849/1000] - Training\n",
      "Epoch [849/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0589\n",
      "Validation Loss: 0.0589, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [850/1000] - Training\n",
      "Epoch [850/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.0577\n",
      "Validation Loss: 0.0577, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [851/1000] - Training\n",
      "Epoch [851/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0542\n",
      "Validation Loss: 0.0542, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [852/1000] - Training\n",
      "Epoch [852/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0516\n",
      "Validation Loss: 0.0516, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0539 to 0.0516. Saving model...\n",
      "\n",
      "LOG: Epoch [853/1000] - Training\n",
      "Epoch [853/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0496\n",
      "Validation Loss: 0.0496, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0516 to 0.0496. Saving model...\n",
      "\n",
      "LOG: Epoch [854/1000] - Training\n",
      "Epoch [854/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0515\n",
      "Validation Loss: 0.0515, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [855/1000] - Training\n",
      "Epoch [855/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0562\n",
      "Validation Loss: 0.0562, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [856/1000] - Training\n",
      "Epoch [856/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0647\n",
      "Validation Loss: 0.0647, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [857/1000] - Training\n",
      "Epoch [857/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0646\n",
      "Validation Loss: 0.0646, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [858/1000] - Training\n",
      "Epoch [858/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0579\n",
      "Validation Loss: 0.0579, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [859/1000] - Training\n",
      "Epoch [859/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.0483\n",
      "Validation Loss: 0.0483, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0496 to 0.0483. Saving model...\n",
      "\n",
      "LOG: Epoch [860/1000] - Training\n",
      "Epoch [860/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.0492\n",
      "Validation Loss: 0.0492, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [861/1000] - Training\n",
      "Epoch [861/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0562\n",
      "Validation Loss: 0.0562, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [862/1000] - Training\n",
      "Epoch [862/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0624\n",
      "Validation Loss: 0.0624, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [863/1000] - Training\n",
      "Epoch [863/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0632\n",
      "Validation Loss: 0.0632, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [864/1000] - Training\n",
      "Epoch [864/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0631\n",
      "Validation Loss: 0.0631, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [865/1000] - Training\n",
      "Epoch [865/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0703\n",
      "Validation Loss: 0.0703, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [866/1000] - Training\n",
      "Epoch [866/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0761\n",
      "Validation Loss: 0.0761, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [867/1000] - Training\n",
      "Epoch [867/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.0793\n",
      "Validation Loss: 0.0793, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [868/1000] - Training\n",
      "Epoch [868/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0668\n",
      "Validation Loss: 0.0668, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [869/1000] - Training\n",
      "Epoch [869/1000] completed, Average Training Loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0524\n",
      "Validation Loss: 0.0524, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [870/1000] - Training\n",
      "Epoch [870/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0516\n",
      "Validation Loss: 0.0516, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [871/1000] - Training\n",
      "Epoch [871/1000] completed, Average Training Loss: 0.0250\n",
      "    Validation Batch [1/1], Loss: 0.0581\n",
      "Validation Loss: 0.0581, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [872/1000] - Training\n",
      "Epoch [872/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0656\n",
      "Validation Loss: 0.0656, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [873/1000] - Training\n",
      "Epoch [873/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.0654\n",
      "Validation Loss: 0.0654, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [874/1000] - Training\n",
      "Epoch [874/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0538\n",
      "Validation Loss: 0.0538, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [875/1000] - Training\n",
      "Epoch [875/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0510\n",
      "Validation Loss: 0.0510, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [876/1000] - Training\n",
      "Epoch [876/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.0628\n",
      "Validation Loss: 0.0628, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [877/1000] - Training\n",
      "Epoch [877/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.0746\n",
      "Validation Loss: 0.0746, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [878/1000] - Training\n",
      "Epoch [878/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0785\n",
      "Validation Loss: 0.0785, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [879/1000] - Training\n",
      "Epoch [879/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.0694\n",
      "Validation Loss: 0.0694, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [880/1000] - Training\n",
      "Epoch [880/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0610\n",
      "Validation Loss: 0.0610, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [881/1000] - Training\n",
      "Epoch [881/1000] completed, Average Training Loss: 0.0222\n",
      "    Validation Batch [1/1], Loss: 0.0557\n",
      "Validation Loss: 0.0557, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [882/1000] - Training\n",
      "Epoch [882/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0567\n",
      "Validation Loss: 0.0567, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [883/1000] - Training\n",
      "Epoch [883/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.0562\n",
      "Validation Loss: 0.0562, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [884/1000] - Training\n",
      "Epoch [884/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0547\n",
      "Validation Loss: 0.0547, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [885/1000] - Training\n",
      "Epoch [885/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0547\n",
      "Validation Loss: 0.0547, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [886/1000] - Training\n",
      "Epoch [886/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0553\n",
      "Validation Loss: 0.0553, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [887/1000] - Training\n",
      "Epoch [887/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0565\n",
      "Validation Loss: 0.0565, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [888/1000] - Training\n",
      "Epoch [888/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.0561\n",
      "Validation Loss: 0.0561, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [889/1000] - Training\n",
      "Epoch [889/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.0536\n",
      "Validation Loss: 0.0536, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [890/1000] - Training\n",
      "Epoch [890/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0517\n",
      "Validation Loss: 0.0517, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [891/1000] - Training\n",
      "Epoch [891/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0494\n",
      "Validation Loss: 0.0494, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [892/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [892/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0485\n",
      "Validation Loss: 0.0485, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [893/1000] - Training\n",
      "Epoch [893/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0523\n",
      "Validation Loss: 0.0523, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [894/1000] - Training\n",
      "Epoch [894/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.0565\n",
      "Validation Loss: 0.0565, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [895/1000] - Training\n",
      "Epoch [895/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0590\n",
      "Validation Loss: 0.0590, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [896/1000] - Training\n",
      "Epoch [896/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.0634\n",
      "Validation Loss: 0.0634, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [897/1000] - Training\n",
      "Epoch [897/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.0680\n",
      "Validation Loss: 0.0680, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [898/1000] - Training\n",
      "Epoch [898/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.0696\n",
      "Validation Loss: 0.0696, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [899/1000] - Training\n",
      "Epoch [899/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0633\n",
      "Validation Loss: 0.0633, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [900/1000] - Training\n",
      "Epoch [900/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0552\n",
      "Validation Loss: 0.0552, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [901/1000] - Training\n",
      "Epoch [901/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.0559\n",
      "Validation Loss: 0.0559, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [902/1000] - Training\n",
      "Epoch [902/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0615\n",
      "Validation Loss: 0.0615, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [903/1000] - Training\n",
      "Epoch [903/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0610\n",
      "Validation Loss: 0.0610, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [904/1000] - Training\n",
      "Epoch [904/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0580\n",
      "Validation Loss: 0.0580, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [905/1000] - Training\n",
      "Epoch [905/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [906/1000] - Training\n",
      "Epoch [906/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.0523\n",
      "Validation Loss: 0.0523, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [907/1000] - Training\n",
      "Epoch [907/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0519\n",
      "Validation Loss: 0.0519, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [908/1000] - Training\n",
      "Epoch [908/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0517\n",
      "Validation Loss: 0.0517, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [909/1000] - Training\n",
      "Epoch [909/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0506\n",
      "Validation Loss: 0.0506, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [910/1000] - Training\n",
      "Epoch [910/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0535\n",
      "Validation Loss: 0.0535, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [911/1000] - Training\n",
      "Epoch [911/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0553\n",
      "Validation Loss: 0.0553, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [912/1000] - Training\n",
      "Epoch [912/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0501\n",
      "Validation Loss: 0.0501, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [913/1000] - Training\n",
      "Epoch [913/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0494\n",
      "Validation Loss: 0.0494, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [914/1000] - Training\n",
      "Epoch [914/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.0520\n",
      "Validation Loss: 0.0520, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [915/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [915/1000] completed, Average Training Loss: 0.0151\n",
      "    Validation Batch [1/1], Loss: 0.0552\n",
      "Validation Loss: 0.0552, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [916/1000] - Training\n",
      "Epoch [916/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0598\n",
      "Validation Loss: 0.0598, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [917/1000] - Training\n",
      "Epoch [917/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.0605\n",
      "Validation Loss: 0.0605, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [918/1000] - Training\n",
      "Epoch [918/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0627\n",
      "Validation Loss: 0.0627, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [919/1000] - Training\n",
      "Epoch [919/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0660\n",
      "Validation Loss: 0.0660, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [920/1000] - Training\n",
      "Epoch [920/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0687\n",
      "Validation Loss: 0.0687, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [921/1000] - Training\n",
      "Epoch [921/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0713\n",
      "Validation Loss: 0.0713, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [922/1000] - Training\n",
      "Epoch [922/1000] completed, Average Training Loss: 0.0137\n",
      "    Validation Batch [1/1], Loss: 0.0719\n",
      "Validation Loss: 0.0719, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [923/1000] - Training\n",
      "Epoch [923/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0669\n",
      "Validation Loss: 0.0669, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [924/1000] - Training\n",
      "Epoch [924/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0602\n",
      "Validation Loss: 0.0602, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [925/1000] - Training\n",
      "Epoch [925/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0563\n",
      "Validation Loss: 0.0563, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [926/1000] - Training\n",
      "Epoch [926/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0544\n",
      "Validation Loss: 0.0544, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [927/1000] - Training\n",
      "Epoch [927/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.0542\n",
      "Validation Loss: 0.0542, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [928/1000] - Training\n",
      "Epoch [928/1000] completed, Average Training Loss: 0.0154\n",
      "    Validation Batch [1/1], Loss: 0.0555\n",
      "Validation Loss: 0.0555, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [929/1000] - Training\n",
      "Epoch [929/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.0572\n",
      "Validation Loss: 0.0572, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [930/1000] - Training\n",
      "Epoch [930/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.0579\n",
      "Validation Loss: 0.0579, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [931/1000] - Training\n",
      "Epoch [931/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.0572\n",
      "Validation Loss: 0.0572, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [932/1000] - Training\n",
      "Epoch [932/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.0573\n",
      "Validation Loss: 0.0573, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [933/1000] - Training\n",
      "Epoch [933/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0585\n",
      "Validation Loss: 0.0585, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [934/1000] - Training\n",
      "Epoch [934/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.0643\n",
      "Validation Loss: 0.0643, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [935/1000] - Training\n",
      "Epoch [935/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [936/1000] - Training\n",
      "Epoch [936/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0639\n",
      "Validation Loss: 0.0639, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [937/1000] - Training\n",
      "Epoch [937/1000] completed, Average Training Loss: 0.0180\n",
      "    Validation Batch [1/1], Loss: 0.0620\n",
      "Validation Loss: 0.0620, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [938/1000] - Training\n",
      "Epoch [938/1000] completed, Average Training Loss: 0.0217\n",
      "    Validation Batch [1/1], Loss: 0.0665\n",
      "Validation Loss: 0.0665, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [939/1000] - Training\n",
      "Epoch [939/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0776\n",
      "Validation Loss: 0.0776, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [940/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [940/1000] completed, Average Training Loss: 0.0220\n",
      "    Validation Batch [1/1], Loss: 0.0794\n",
      "Validation Loss: 0.0794, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [941/1000] - Training\n",
      "Epoch [941/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0690\n",
      "Validation Loss: 0.0690, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [942/1000] - Training\n",
      "Epoch [942/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.0610\n",
      "Validation Loss: 0.0610, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [943/1000] - Training\n",
      "Epoch [943/1000] completed, Average Training Loss: 0.0142\n",
      "    Validation Batch [1/1], Loss: 0.0572\n",
      "Validation Loss: 0.0572, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [944/1000] - Training\n",
      "Epoch [944/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0544\n",
      "Validation Loss: 0.0544, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [945/1000] - Training\n",
      "Epoch [945/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0531\n",
      "Validation Loss: 0.0531, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [946/1000] - Training\n",
      "Epoch [946/1000] completed, Average Training Loss: 0.0152\n",
      "    Validation Batch [1/1], Loss: 0.0538\n",
      "Validation Loss: 0.0538, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [947/1000] - Training\n",
      "Epoch [947/1000] completed, Average Training Loss: 0.0185\n",
      "    Validation Batch [1/1], Loss: 0.0562\n",
      "Validation Loss: 0.0562, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [948/1000] - Training\n",
      "Epoch [948/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0597\n",
      "Validation Loss: 0.0597, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [949/1000] - Training\n",
      "Epoch [949/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0631\n",
      "Validation Loss: 0.0631, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [950/1000] - Training\n",
      "Epoch [950/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0626\n",
      "Validation Loss: 0.0626, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [951/1000] - Training\n",
      "Epoch [951/1000] completed, Average Training Loss: 0.0229\n",
      "    Validation Batch [1/1], Loss: 0.0587\n",
      "Validation Loss: 0.0587, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [952/1000] - Training\n",
      "Epoch [952/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0578\n",
      "Validation Loss: 0.0578, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [953/1000] - Training\n",
      "Epoch [953/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0589\n",
      "Validation Loss: 0.0589, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [954/1000] - Training\n",
      "Epoch [954/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0609\n",
      "Validation Loss: 0.0609, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [955/1000] - Training\n",
      "Epoch [955/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0661\n",
      "Validation Loss: 0.0661, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [956/1000] - Training\n",
      "Epoch [956/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0670\n",
      "Validation Loss: 0.0670, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [957/1000] - Training\n",
      "Epoch [957/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0660\n",
      "Validation Loss: 0.0660, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [958/1000] - Training\n",
      "Epoch [958/1000] completed, Average Training Loss: 0.0182\n",
      "    Validation Batch [1/1], Loss: 0.0604\n",
      "Validation Loss: 0.0604, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [959/1000] - Training\n",
      "Epoch [959/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.0555\n",
      "Validation Loss: 0.0555, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 959. No improvement for 100 epochs.\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/12], Loss: 0.0071\n",
      "\n",
      "Final Test Loss: 0.0958, Test Accuracy: 97.65%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:35.617691Z",
     "iopub.status.busy": "2025-05-08T18:54:35.616692Z",
     "iopub.status.idle": "2025-05-08T18:54:35.697360Z",
     "shell.execute_reply": "2025-05-08T18:54:35.697360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:35.700366Z",
     "iopub.status.busy": "2025-05-08T18:54:35.700366Z",
     "iopub.status.idle": "2025-05-08T18:54:35.704927Z",
     "shell.execute_reply": "2025-05-08T18:54:35.704927Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:35.706931Z",
     "iopub.status.busy": "2025-05-08T18:54:35.706931Z",
     "iopub.status.idle": "2025-05-08T18:54:35.886547Z",
     "shell.execute_reply": "2025-05-08T18:54:35.886037Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:35.888549Z",
     "iopub.status.busy": "2025-05-08T18:54:35.888549Z",
     "iopub.status.idle": "2025-05-08T18:54:35.893053Z",
     "shell.execute_reply": "2025-05-08T18:54:35.893053Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:35.895057Z",
     "iopub.status.busy": "2025-05-08T18:54:35.895057Z",
     "iopub.status.idle": "2025-05-08T18:54:36.051802Z",
     "shell.execute_reply": "2025-05-08T18:54:36.051356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "LOG: Training features shape: (280, 64), Training labels shape: (280,)\n",
      "LOG: Validation features shape: (70, 64), Validation labels shape: (70,)\n",
      "LOG: Test features shape: (2898, 64), Test labels shape: (2898,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 80.00%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       0.67      0.80      0.73         5\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       1.00      0.40      0.57         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.67      0.80      0.73         5\n",
      "           8       0.67      0.80      0.73         5\n",
      "           9       0.80      0.80      0.80         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.60      0.60      0.60         5\n",
      "          13       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.80        70\n",
      "   macro avg       0.81      0.80      0.79        70\n",
      "weighted avg       0.81      0.80      0.79        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 78.40%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       245\n",
      "           1       0.41      1.00      0.58        76\n",
      "           2       0.80      0.81      0.81       226\n",
      "           3       0.76      0.87      0.81       190\n",
      "           4       0.78      0.54      0.64       244\n",
      "           5       0.72      0.24      0.36       244\n",
      "           6       0.92      0.90      0.91       234\n",
      "           7       0.74      0.88      0.80       178\n",
      "           8       0.67      0.75      0.71       289\n",
      "           9       0.84      0.83      0.83       223\n",
      "          10       0.92      0.82      0.86       280\n",
      "          11       0.78      0.99      0.87       156\n",
      "          12       0.72      0.81      0.76       243\n",
      "          13       0.95      0.90      0.93        70\n",
      "\n",
      "    accuracy                           0.78      2898\n",
      "   macro avg       0.79      0.81      0.78      2898\n",
      "weighted avg       0.80      0.78      0.77      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:36.054314Z",
     "iopub.status.busy": "2025-05-08T18:54:36.054314Z",
     "iopub.status.idle": "2025-05-08T18:54:36.057799Z",
     "shell.execute_reply": "2025-05-08T18:54:36.057799Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:36.059806Z",
     "iopub.status.busy": "2025-05-08T18:54:36.059806Z",
     "iopub.status.idle": "2025-05-08T18:54:36.068246Z",
     "shell.execute_reply": "2025-05-08T18:54:36.068246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "Train reps shape: (280, 64)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 64)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 64)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:36.070251Z",
     "iopub.status.busy": "2025-05-08T18:54:36.070251Z",
     "iopub.status.idle": "2025-05-08T18:54:36.075541Z",
     "shell.execute_reply": "2025-05-08T18:54:36.075541Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:36.078546Z",
     "iopub.status.busy": "2025-05-08T18:54:36.078546Z",
     "iopub.status.idle": "2025-05-08T18:54:47.488246Z",
     "shell.execute_reply": "2025-05-08T18:54:47.487227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7264  |  Val Loss: 2.6499\n",
      "Validation loss improved from inf to 2.6499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/1000] Train Loss: 2.6429  |  Val Loss: 2.6188\n",
      "Validation loss improved from 2.6499 to 2.6188.\n",
      "[Epoch 3/1000] Train Loss: 2.6083  |  Val Loss: 2.5957\n",
      "Validation loss improved from 2.6188 to 2.5957.\n",
      "[Epoch 4/1000] Train Loss: 2.5890  |  Val Loss: 2.5760\n",
      "Validation loss improved from 2.5957 to 2.5760.\n",
      "[Epoch 5/1000] Train Loss: 2.5677  |  Val Loss: 2.5589\n",
      "Validation loss improved from 2.5760 to 2.5589.\n",
      "[Epoch 6/1000] Train Loss: 2.5549  |  Val Loss: 2.5466\n",
      "Validation loss improved from 2.5589 to 2.5466.\n",
      "[Epoch 7/1000] Train Loss: 2.5381  |  Val Loss: 2.5286\n",
      "Validation loss improved from 2.5466 to 2.5286.\n",
      "[Epoch 8/1000] Train Loss: 2.5176  |  Val Loss: 2.5091\n",
      "Validation loss improved from 2.5286 to 2.5091.\n",
      "[Epoch 9/1000] Train Loss: 2.4928  |  Val Loss: 2.4855\n",
      "Validation loss improved from 2.5091 to 2.4855.\n",
      "[Epoch 10/1000] Train Loss: 2.4685  |  Val Loss: 2.4596\n",
      "Validation loss improved from 2.4855 to 2.4596.\n",
      "[Epoch 11/1000] Train Loss: 2.4439  |  Val Loss: 2.4336\n",
      "Validation loss improved from 2.4596 to 2.4336.\n",
      "[Epoch 12/1000] Train Loss: 2.4116  |  Val Loss: 2.4056\n",
      "Validation loss improved from 2.4336 to 2.4056.\n",
      "[Epoch 13/1000] Train Loss: 2.3799  |  Val Loss: 2.3736\n",
      "Validation loss improved from 2.4056 to 2.3736.\n",
      "[Epoch 14/1000] Train Loss: 2.3508  |  Val Loss: 2.3411\n",
      "Validation loss improved from 2.3736 to 2.3411.\n",
      "[Epoch 15/1000] Train Loss: 2.3164  |  Val Loss: 2.2995\n",
      "Validation loss improved from 2.3411 to 2.2995.\n",
      "[Epoch 16/1000] Train Loss: 2.2721  |  Val Loss: 2.2623\n",
      "Validation loss improved from 2.2995 to 2.2623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/1000] Train Loss: 2.2310  |  Val Loss: 2.2212\n",
      "Validation loss improved from 2.2623 to 2.2212.\n",
      "[Epoch 18/1000] Train Loss: 2.1867  |  Val Loss: 2.1814\n",
      "Validation loss improved from 2.2212 to 2.1814.\n",
      "[Epoch 19/1000] Train Loss: 2.1462  |  Val Loss: 2.1410\n",
      "Validation loss improved from 2.1814 to 2.1410.\n",
      "[Epoch 20/1000] Train Loss: 2.1088  |  Val Loss: 2.1102\n",
      "Validation loss improved from 2.1410 to 2.1102.\n",
      "[Epoch 21/1000] Train Loss: 2.0670  |  Val Loss: 2.0582\n",
      "Validation loss improved from 2.1102 to 2.0582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/1000] Train Loss: 2.0195  |  Val Loss: 2.0126\n",
      "Validation loss improved from 2.0582 to 2.0126.\n",
      "[Epoch 23/1000] Train Loss: 1.9786  |  Val Loss: 1.9692\n",
      "Validation loss improved from 2.0126 to 1.9692.\n",
      "[Epoch 24/1000] Train Loss: 1.9288  |  Val Loss: 1.9271\n",
      "Validation loss improved from 1.9692 to 1.9271.\n",
      "[Epoch 25/1000] Train Loss: 1.8871  |  Val Loss: 1.8848\n",
      "Validation loss improved from 1.9271 to 1.8848.\n",
      "[Epoch 26/1000] Train Loss: 1.8454  |  Val Loss: 1.8441\n",
      "Validation loss improved from 1.8848 to 1.8441.\n",
      "[Epoch 27/1000] Train Loss: 1.8060  |  Val Loss: 1.8113\n",
      "Validation loss improved from 1.8441 to 1.8113.\n",
      "[Epoch 28/1000] Train Loss: 1.7668  |  Val Loss: 1.7642\n",
      "Validation loss improved from 1.8113 to 1.7642.\n",
      "[Epoch 29/1000] Train Loss: 1.7211  |  Val Loss: 1.7264\n",
      "Validation loss improved from 1.7642 to 1.7264.\n",
      "[Epoch 30/1000] Train Loss: 1.6874  |  Val Loss: 1.7086\n",
      "Validation loss improved from 1.7264 to 1.7086.\n",
      "[Epoch 31/1000] Train Loss: 1.6663  |  Val Loss: 1.6568\n",
      "Validation loss improved from 1.7086 to 1.6568.\n",
      "[Epoch 32/1000] Train Loss: 1.6073  |  Val Loss: 1.6303\n",
      "Validation loss improved from 1.6568 to 1.6303.\n",
      "[Epoch 33/1000] Train Loss: 1.5919  |  Val Loss: 1.6251\n",
      "Validation loss improved from 1.6303 to 1.6251.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 1.5656  |  Val Loss: 1.5738\n",
      "Validation loss improved from 1.6251 to 1.5738.\n",
      "[Epoch 35/1000] Train Loss: 1.5313  |  Val Loss: 1.5613\n",
      "Validation loss improved from 1.5738 to 1.5613.\n",
      "[Epoch 36/1000] Train Loss: 1.5039  |  Val Loss: 1.5295\n",
      "Validation loss improved from 1.5613 to 1.5295.\n",
      "[Epoch 37/1000] Train Loss: 1.4905  |  Val Loss: 1.5064\n",
      "Validation loss improved from 1.5295 to 1.5064.\n",
      "[Epoch 38/1000] Train Loss: 1.4595  |  Val Loss: 1.4979\n",
      "Validation loss improved from 1.5064 to 1.4979.\n",
      "[Epoch 39/1000] Train Loss: 1.4368  |  Val Loss: 1.5001\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/1000] Train Loss: 1.4384  |  Val Loss: 1.4665\n",
      "Validation loss improved from 1.4979 to 1.4665.\n",
      "[Epoch 41/1000] Train Loss: 1.4091  |  Val Loss: 1.4471\n",
      "Validation loss improved from 1.4665 to 1.4471.\n",
      "[Epoch 42/1000] Train Loss: 1.3940  |  Val Loss: 1.4281\n",
      "Validation loss improved from 1.4471 to 1.4281.\n",
      "[Epoch 43/1000] Train Loss: 1.3794  |  Val Loss: 1.4313\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 44/1000] Train Loss: 1.4003  |  Val Loss: 1.4161\n",
      "Validation loss improved from 1.4281 to 1.4161.\n",
      "[Epoch 45/1000] Train Loss: 1.3631  |  Val Loss: 1.4025\n",
      "Validation loss improved from 1.4161 to 1.4025.\n",
      "[Epoch 46/1000] Train Loss: 1.3438  |  Val Loss: 1.3916\n",
      "Validation loss improved from 1.4025 to 1.3916.\n",
      "[Epoch 47/1000] Train Loss: 1.3333  |  Val Loss: 1.3816\n",
      "Validation loss improved from 1.3916 to 1.3816.\n",
      "[Epoch 48/1000] Train Loss: 1.3257  |  Val Loss: 1.3937\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 49/1000] Train Loss: 1.3163  |  Val Loss: 1.3676\n",
      "Validation loss improved from 1.3816 to 1.3676.\n",
      "[Epoch 50/1000] Train Loss: 1.2984  |  Val Loss: 1.3869\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 51/1000] Train Loss: 1.2998  |  Val Loss: 1.3712\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/1000] Train Loss: 1.2964  |  Val Loss: 1.3560\n",
      "Validation loss improved from 1.3676 to 1.3560.\n",
      "[Epoch 53/1000] Train Loss: 1.2931  |  Val Loss: 1.3581\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 54/1000] Train Loss: 1.2918  |  Val Loss: 1.3539\n",
      "Validation loss improved from 1.3560 to 1.3539.\n",
      "[Epoch 55/1000] Train Loss: 1.2920  |  Val Loss: 1.3412\n",
      "Validation loss improved from 1.3539 to 1.3412.\n",
      "[Epoch 56/1000] Train Loss: 1.2866  |  Val Loss: 1.3827\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 57/1000] Train Loss: 1.2670  |  Val Loss: 1.3267\n",
      "Validation loss improved from 1.3412 to 1.3267.\n",
      "[Epoch 58/1000] Train Loss: 1.2832  |  Val Loss: 1.3432\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/1000] Train Loss: 1.2573  |  Val Loss: 1.3332\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 60/1000] Train Loss: 1.2525  |  Val Loss: 1.3134\n",
      "Validation loss improved from 1.3267 to 1.3134.\n",
      "[Epoch 61/1000] Train Loss: 1.2728  |  Val Loss: 1.3320\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 62/1000] Train Loss: 1.2697  |  Val Loss: 1.4492\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 63/1000] Train Loss: 1.3096  |  Val Loss: 1.3276\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 64/1000] Train Loss: 1.2605  |  Val Loss: 1.3121\n",
      "Validation loss improved from 1.3134 to 1.3121.\n",
      "[Epoch 65/1000] Train Loss: 1.2343  |  Val Loss: 1.3118\n",
      "Validation loss improved from 1.3121 to 1.3118.\n",
      "[Epoch 66/1000] Train Loss: 1.2354  |  Val Loss: 1.3018\n",
      "Validation loss improved from 1.3118 to 1.3018.\n",
      "[Epoch 67/1000] Train Loss: 1.2386  |  Val Loss: 1.3033\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 68/1000] Train Loss: 1.2244  |  Val Loss: 1.3131\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 69/1000] Train Loss: 1.2562  |  Val Loss: 1.3010\n",
      "Validation loss improved from 1.3018 to 1.3010.\n",
      "[Epoch 70/1000] Train Loss: 1.2245  |  Val Loss: 1.2929\n",
      "Validation loss improved from 1.3010 to 1.2929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71/1000] Train Loss: 1.2321  |  Val Loss: 1.3459\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 72/1000] Train Loss: 1.2403  |  Val Loss: 1.3212\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 73/1000] Train Loss: 1.2575  |  Val Loss: 1.2951\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 74/1000] Train Loss: 1.2345  |  Val Loss: 1.3548\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 75/1000] Train Loss: 1.2769  |  Val Loss: 1.3832\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 76/1000] Train Loss: 1.2701  |  Val Loss: 1.3557\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 1.2409  |  Val Loss: 1.2774\n",
      "Validation loss improved from 1.2929 to 1.2774.\n",
      "[Epoch 78/1000] Train Loss: 1.2437  |  Val Loss: 1.2810\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 79/1000] Train Loss: 1.2230  |  Val Loss: 1.3218\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 80/1000] Train Loss: 1.2175  |  Val Loss: 1.2808\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 81/1000] Train Loss: 1.1953  |  Val Loss: 1.2765\n",
      "Validation loss improved from 1.2774 to 1.2765.\n",
      "[Epoch 82/1000] Train Loss: 1.2055  |  Val Loss: 1.3515\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 83/1000] Train Loss: 1.2379  |  Val Loss: 1.2751\n",
      "Validation loss improved from 1.2765 to 1.2751.\n",
      "[Epoch 84/1000] Train Loss: 1.1941  |  Val Loss: 1.3069\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 85/1000] Train Loss: 1.1869  |  Val Loss: 1.2931\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 86/1000] Train Loss: 1.2214  |  Val Loss: 1.3079\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 87/1000] Train Loss: 1.2133  |  Val Loss: 1.2758\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 88/1000] Train Loss: 1.2054  |  Val Loss: 1.2718\n",
      "Validation loss improved from 1.2751 to 1.2718.\n",
      "[Epoch 89/1000] Train Loss: 1.2518  |  Val Loss: 1.3965\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 90/1000] Train Loss: 1.2357  |  Val Loss: 1.3514\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 91/1000] Train Loss: 1.2443  |  Val Loss: 1.3960\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 92/1000] Train Loss: 1.2438  |  Val Loss: 1.2727\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 93/1000] Train Loss: 1.2223  |  Val Loss: 1.2604\n",
      "Validation loss improved from 1.2718 to 1.2604.\n",
      "[Epoch 94/1000] Train Loss: 1.2260  |  Val Loss: 1.2932\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 95/1000] Train Loss: 1.2083  |  Val Loss: 1.2861\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 96/1000] Train Loss: 1.2117  |  Val Loss: 1.3423\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 97/1000] Train Loss: 1.2068  |  Val Loss: 1.2628\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 98/1000] Train Loss: 1.1972  |  Val Loss: 1.2707\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 99/1000] Train Loss: 1.1955  |  Val Loss: 1.2711\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 100/1000] Train Loss: 1.1989  |  Val Loss: 1.2519\n",
      "Validation loss improved from 1.2604 to 1.2519.\n",
      "[Epoch 101/1000] Train Loss: 1.1813  |  Val Loss: 1.2684\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 102/1000] Train Loss: 1.1712  |  Val Loss: 1.2536\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 103/1000] Train Loss: 1.1974  |  Val Loss: 1.3335\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 104/1000] Train Loss: 1.1946  |  Val Loss: 1.2708\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 105/1000] Train Loss: 1.1979  |  Val Loss: 1.2961\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 106/1000] Train Loss: 1.1829  |  Val Loss: 1.2457\n",
      "Validation loss improved from 1.2519 to 1.2457.\n",
      "[Epoch 107/1000] Train Loss: 1.1672  |  Val Loss: 1.2805\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 108/1000] Train Loss: 1.1805  |  Val Loss: 1.2430\n",
      "Validation loss improved from 1.2457 to 1.2430.\n",
      "[Epoch 109/1000] Train Loss: 1.1646  |  Val Loss: 1.2354\n",
      "Validation loss improved from 1.2430 to 1.2354.\n",
      "[Epoch 110/1000] Train Loss: 1.1650  |  Val Loss: 1.2395\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 111/1000] Train Loss: 1.1657  |  Val Loss: 1.2511\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 112/1000] Train Loss: 1.1705  |  Val Loss: 1.2659\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 113/1000] Train Loss: 1.1851  |  Val Loss: 1.2621\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 114/1000] Train Loss: 1.2168  |  Val Loss: 1.2406\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 115/1000] Train Loss: 1.1923  |  Val Loss: 1.3036\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 116/1000] Train Loss: 1.2016  |  Val Loss: 1.2555\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 117/1000] Train Loss: 1.1944  |  Val Loss: 1.3294\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 118/1000] Train Loss: 1.2107  |  Val Loss: 1.2459\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 119/1000] Train Loss: 1.1986  |  Val Loss: 1.2515\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 120/1000] Train Loss: 1.1911  |  Val Loss: 1.2503\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 121/1000] Train Loss: 1.1852  |  Val Loss: 1.2284\n",
      "Validation loss improved from 1.2354 to 1.2284.\n",
      "[Epoch 122/1000] Train Loss: 1.1657  |  Val Loss: 1.2559\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 123/1000] Train Loss: 1.1615  |  Val Loss: 1.2356\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 124/1000] Train Loss: 1.1677  |  Val Loss: 1.2863\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 125/1000] Train Loss: 1.1692  |  Val Loss: 1.2471\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 126/1000] Train Loss: 1.1918  |  Val Loss: 1.3017\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 127/1000] Train Loss: 1.1896  |  Val Loss: 1.2368\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 128/1000] Train Loss: 1.1692  |  Val Loss: 1.2499\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 129/1000] Train Loss: 1.1637  |  Val Loss: 1.2333\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 130/1000] Train Loss: 1.1627  |  Val Loss: 1.2237\n",
      "Validation loss improved from 1.2284 to 1.2237.\n",
      "[Epoch 131/1000] Train Loss: 1.1638  |  Val Loss: 1.2714\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 132/1000] Train Loss: 1.1780  |  Val Loss: 1.2360\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 133/1000] Train Loss: 1.1543  |  Val Loss: 1.2718\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 134/1000] Train Loss: 1.1626  |  Val Loss: 1.2154\n",
      "Validation loss improved from 1.2237 to 1.2154.\n",
      "[Epoch 135/1000] Train Loss: 1.1528  |  Val Loss: 1.2760\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 136/1000] Train Loss: 1.1821  |  Val Loss: 1.2228\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 137/1000] Train Loss: 1.1566  |  Val Loss: 1.2437\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 138/1000] Train Loss: 1.1551  |  Val Loss: 1.2213\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 139/1000] Train Loss: 1.1541  |  Val Loss: 1.2584\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 140/1000] Train Loss: 1.1544  |  Val Loss: 1.2258\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 141/1000] Train Loss: 1.1590  |  Val Loss: 1.3152\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 142/1000] Train Loss: 1.1642  |  Val Loss: 1.2569\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 143/1000] Train Loss: 1.1905  |  Val Loss: 1.3312\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 144/1000] Train Loss: 1.1720  |  Val Loss: 1.2518\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 145/1000] Train Loss: 1.1880  |  Val Loss: 1.2752\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 146/1000] Train Loss: 1.1610  |  Val Loss: 1.2104\n",
      "Validation loss improved from 1.2154 to 1.2104.\n",
      "[Epoch 147/1000] Train Loss: 1.1565  |  Val Loss: 1.2350\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 148/1000] Train Loss: 1.1395  |  Val Loss: 1.2136\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 149/1000] Train Loss: 1.1453  |  Val Loss: 1.2608\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 150/1000] Train Loss: 1.1536  |  Val Loss: 1.2240\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 151/1000] Train Loss: 1.1403  |  Val Loss: 1.2556\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 152/1000] Train Loss: 1.1431  |  Val Loss: 1.2074\n",
      "Validation loss improved from 1.2104 to 1.2074.\n",
      "[Epoch 153/1000] Train Loss: 1.1497  |  Val Loss: 1.2803\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 154/1000] Train Loss: 1.1589  |  Val Loss: 1.2172\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 155/1000] Train Loss: 1.1411  |  Val Loss: 1.2058\n",
      "Validation loss improved from 1.2074 to 1.2058.\n",
      "[Epoch 156/1000] Train Loss: 1.1697  |  Val Loss: 1.2976\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 157/1000] Train Loss: 1.1679  |  Val Loss: 1.2817\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 158/1000] Train Loss: 1.2057  |  Val Loss: 1.3202\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 159/1000] Train Loss: 1.1553  |  Val Loss: 1.2340\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 160/1000] Train Loss: 1.1602  |  Val Loss: 1.2740\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 161/1000] Train Loss: 1.1674  |  Val Loss: 1.2219\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 162/1000] Train Loss: 1.1499  |  Val Loss: 1.2352\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 163/1000] Train Loss: 1.1465  |  Val Loss: 1.2198\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 164/1000] Train Loss: 1.1345  |  Val Loss: 1.2318\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 165/1000] Train Loss: 1.1482  |  Val Loss: 1.2314\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 166/1000] Train Loss: 1.1817  |  Val Loss: 1.3222\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 167/1000] Train Loss: 1.1552  |  Val Loss: 1.2558\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 168/1000] Train Loss: 1.2408  |  Val Loss: 1.3525\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 169/1000] Train Loss: 1.1811  |  Val Loss: 1.2190\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 170/1000] Train Loss: 1.1549  |  Val Loss: 1.2399\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 171/1000] Train Loss: 1.1382  |  Val Loss: 1.2009\n",
      "Validation loss improved from 1.2058 to 1.2009.\n",
      "[Epoch 172/1000] Train Loss: 1.1516  |  Val Loss: 1.2031\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 173/1000] Train Loss: 1.1696  |  Val Loss: 1.2898\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 174/1000] Train Loss: 1.1918  |  Val Loss: 1.2133\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 175/1000] Train Loss: 1.1532  |  Val Loss: 1.2365\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 176/1000] Train Loss: 1.1490  |  Val Loss: 1.2159\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 177/1000] Train Loss: 1.1325  |  Val Loss: 1.2261\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 178/1000] Train Loss: 1.1357  |  Val Loss: 1.2149\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 179/1000] Train Loss: 1.1344  |  Val Loss: 1.2001\n",
      "Validation loss improved from 1.2009 to 1.2001.\n",
      "[Epoch 180/1000] Train Loss: 1.1249  |  Val Loss: 1.2271\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 181/1000] Train Loss: 1.1402  |  Val Loss: 1.2128\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 182/1000] Train Loss: 1.1364  |  Val Loss: 1.2114\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 183/1000] Train Loss: 1.1224  |  Val Loss: 1.2076\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 184/1000] Train Loss: 1.1249  |  Val Loss: 1.2708\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 185/1000] Train Loss: 1.1490  |  Val Loss: 1.2300\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 186/1000] Train Loss: 1.1641  |  Val Loss: 1.2913\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 187/1000] Train Loss: 1.1510  |  Val Loss: 1.1974\n",
      "Validation loss improved from 1.2001 to 1.1974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 188/1000] Train Loss: 1.1387  |  Val Loss: 1.2784\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 189/1000] Train Loss: 1.1590  |  Val Loss: 1.1956\n",
      "Validation loss improved from 1.1974 to 1.1956.\n",
      "[Epoch 190/1000] Train Loss: 1.1680  |  Val Loss: 1.2094\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 191/1000] Train Loss: 1.1661  |  Val Loss: 1.2454\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 192/1000] Train Loss: 1.1542  |  Val Loss: 1.1887\n",
      "Validation loss improved from 1.1956 to 1.1887.\n",
      "[Epoch 193/1000] Train Loss: 1.1412  |  Val Loss: 1.2062\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 194/1000] Train Loss: 1.1321  |  Val Loss: 1.1988\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 195/1000] Train Loss: 1.1256  |  Val Loss: 1.1998\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 196/1000] Train Loss: 1.1221  |  Val Loss: 1.2104\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 197/1000] Train Loss: 1.1348  |  Val Loss: 1.2388\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 198/1000] Train Loss: 1.1325  |  Val Loss: 1.1997\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 199/1000] Train Loss: 1.1239  |  Val Loss: 1.2269\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 200/1000] Train Loss: 1.1288  |  Val Loss: 1.2182\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 201/1000] Train Loss: 1.1256  |  Val Loss: 1.1936\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 202/1000] Train Loss: 1.1315  |  Val Loss: 1.2042\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 203/1000] Train Loss: 1.1283  |  Val Loss: 1.1967\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 204/1000] Train Loss: 1.1149  |  Val Loss: 1.2378\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 205/1000] Train Loss: 1.1283  |  Val Loss: 1.1974\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 206/1000] Train Loss: 1.1231  |  Val Loss: 1.1821\n",
      "Validation loss improved from 1.1887 to 1.1821.\n",
      "[Epoch 207/1000] Train Loss: 1.1256  |  Val Loss: 1.1891\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 208/1000] Train Loss: 1.1206  |  Val Loss: 1.1872\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 209/1000] Train Loss: 1.1257  |  Val Loss: 1.1960\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 210/1000] Train Loss: 1.1222  |  Val Loss: 1.2324\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 211/1000] Train Loss: 1.1397  |  Val Loss: 1.1761\n",
      "Validation loss improved from 1.1821 to 1.1761.\n",
      "[Epoch 212/1000] Train Loss: 1.1287  |  Val Loss: 1.1897\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 213/1000] Train Loss: 1.1317  |  Val Loss: 1.2517\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 214/1000] Train Loss: 1.1545  |  Val Loss: 1.2027\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 215/1000] Train Loss: 1.1593  |  Val Loss: 1.2972\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 216/1000] Train Loss: 1.1386  |  Val Loss: 1.2008\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 217/1000] Train Loss: 1.1540  |  Val Loss: 1.2747\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 218/1000] Train Loss: 1.1118  |  Val Loss: 1.2147\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 219/1000] Train Loss: 1.1521  |  Val Loss: 1.2930\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 220/1000] Train Loss: 1.1313  |  Val Loss: 1.1948\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 221/1000] Train Loss: 1.1310  |  Val Loss: 1.2995\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 222/1000] Train Loss: 1.1823  |  Val Loss: 1.1866\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 223/1000] Train Loss: 1.1341  |  Val Loss: 1.2241\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 224/1000] Train Loss: 1.1277  |  Val Loss: 1.1982\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 225/1000] Train Loss: 1.1427  |  Val Loss: 1.2000\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 226/1000] Train Loss: 1.1190  |  Val Loss: 1.1952\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 227/1000] Train Loss: 1.1215  |  Val Loss: 1.2420\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 228/1000] Train Loss: 1.1390  |  Val Loss: 1.1910\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 229/1000] Train Loss: 1.1139  |  Val Loss: 1.2104\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 230/1000] Train Loss: 1.1102  |  Val Loss: 1.1760\n",
      "Validation loss improved from 1.1761 to 1.1760.\n",
      "[Epoch 231/1000] Train Loss: 1.1112  |  Val Loss: 1.1962\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 232/1000] Train Loss: 1.1076  |  Val Loss: 1.1833\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 233/1000] Train Loss: 1.1146  |  Val Loss: 1.1824\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 234/1000] Train Loss: 1.1164  |  Val Loss: 1.2407\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 235/1000] Train Loss: 1.1255  |  Val Loss: 1.1676\n",
      "Validation loss improved from 1.1760 to 1.1676.\n",
      "[Epoch 236/1000] Train Loss: 1.1189  |  Val Loss: 1.1713\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 237/1000] Train Loss: 1.1170  |  Val Loss: 1.2583\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 238/1000] Train Loss: 1.1215  |  Val Loss: 1.1996\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 239/1000] Train Loss: 1.1482  |  Val Loss: 1.2108\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 240/1000] Train Loss: 1.1104  |  Val Loss: 1.1811\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 241/1000] Train Loss: 1.1255  |  Val Loss: 1.1687\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 242/1000] Train Loss: 1.1253  |  Val Loss: 1.2934\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 243/1000] Train Loss: 1.1511  |  Val Loss: 1.1939\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 244/1000] Train Loss: 1.1201  |  Val Loss: 1.3159\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 245/1000] Train Loss: 1.1584  |  Val Loss: 1.2466\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 246/1000] Train Loss: 1.1899  |  Val Loss: 1.3033\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 247/1000] Train Loss: 1.1127  |  Val Loss: 1.2329\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 248/1000] Train Loss: 1.1616  |  Val Loss: 1.3442\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 249/1000] Train Loss: 1.1710  |  Val Loss: 1.1816\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 250/1000] Train Loss: 1.1330  |  Val Loss: 1.2376\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 251/1000] Train Loss: 1.1076  |  Val Loss: 1.1731\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 252/1000] Train Loss: 1.1134  |  Val Loss: 1.2552\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 253/1000] Train Loss: 1.1297  |  Val Loss: 1.1818\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 254/1000] Train Loss: 1.1127  |  Val Loss: 1.1978\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 255/1000] Train Loss: 1.1042  |  Val Loss: 1.1821\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 256/1000] Train Loss: 1.1151  |  Val Loss: 1.2232\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 257/1000] Train Loss: 1.1070  |  Val Loss: 1.1752\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 258/1000] Train Loss: 1.1213  |  Val Loss: 1.2586\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 259/1000] Train Loss: 1.1245  |  Val Loss: 1.1839\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 260/1000] Train Loss: 1.1083  |  Val Loss: 1.1781\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 261/1000] Train Loss: 1.1145  |  Val Loss: 1.2074\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 262/1000] Train Loss: 1.1178  |  Val Loss: 1.1630\n",
      "Validation loss improved from 1.1676 to 1.1630.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 263/1000] Train Loss: 1.1007  |  Val Loss: 1.2204\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 264/1000] Train Loss: 1.1049  |  Val Loss: 1.1862\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 265/1000] Train Loss: 1.0993  |  Val Loss: 1.2338\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 266/1000] Train Loss: 1.1102  |  Val Loss: 1.1855\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 267/1000] Train Loss: 1.1044  |  Val Loss: 1.2088\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 268/1000] Train Loss: 1.0979  |  Val Loss: 1.1819\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 269/1000] Train Loss: 1.1072  |  Val Loss: 1.1875\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 270/1000] Train Loss: 1.1064  |  Val Loss: 1.1685\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 271/1000] Train Loss: 1.0977  |  Val Loss: 1.2047\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 272/1000] Train Loss: 1.1003  |  Val Loss: 1.1727\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 273/1000] Train Loss: 1.1355  |  Val Loss: 1.2836\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 274/1000] Train Loss: 1.1308  |  Val Loss: 1.2030\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 275/1000] Train Loss: 1.1232  |  Val Loss: 1.3551\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 276/1000] Train Loss: 1.1504  |  Val Loss: 1.2088\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 277/1000] Train Loss: 1.1600  |  Val Loss: 1.3286\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 278/1000] Train Loss: 1.1562  |  Val Loss: 1.1773\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 279/1000] Train Loss: 1.1416  |  Val Loss: 1.2273\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 280/1000] Train Loss: 1.1376  |  Val Loss: 1.1675\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 281/1000] Train Loss: 1.1244  |  Val Loss: 1.1679\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 282/1000] Train Loss: 1.1238  |  Val Loss: 1.2097\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 283/1000] Train Loss: 1.1305  |  Val Loss: 1.1766\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 284/1000] Train Loss: 1.1312  |  Val Loss: 1.2952\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 285/1000] Train Loss: 1.1292  |  Val Loss: 1.1916\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 286/1000] Train Loss: 1.1650  |  Val Loss: 1.2685\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 287/1000] Train Loss: 1.1125  |  Val Loss: 1.1977\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 288/1000] Train Loss: 1.1653  |  Val Loss: 1.3346\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 289/1000] Train Loss: 1.1410  |  Val Loss: 1.1918\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 290/1000] Train Loss: 1.1330  |  Val Loss: 1.2541\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 291/1000] Train Loss: 1.1168  |  Val Loss: 1.1821\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 292/1000] Train Loss: 1.1145  |  Val Loss: 1.2009\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 293/1000] Train Loss: 1.1012  |  Val Loss: 1.1702\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 294/1000] Train Loss: 1.1146  |  Val Loss: 1.1781\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 295/1000] Train Loss: 1.1065  |  Val Loss: 1.2332\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 296/1000] Train Loss: 1.1095  |  Val Loss: 1.1806\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 297/1000] Train Loss: 1.1301  |  Val Loss: 1.3093\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 298/1000] Train Loss: 1.1380  |  Val Loss: 1.1880\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 299/1000] Train Loss: 1.1212  |  Val Loss: 1.3053\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 300/1000] Train Loss: 1.1292  |  Val Loss: 1.1816\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 301/1000] Train Loss: 1.1145  |  Val Loss: 1.2239\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 302/1000] Train Loss: 1.1131  |  Val Loss: 1.1743\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 303/1000] Train Loss: 1.0941  |  Val Loss: 1.1758\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 304/1000] Train Loss: 1.1075  |  Val Loss: 1.1656\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 305/1000] Train Loss: 1.1134  |  Val Loss: 1.1729\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 306/1000] Train Loss: 1.1286  |  Val Loss: 1.2531\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 307/1000] Train Loss: 1.1060  |  Val Loss: 1.1743\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 308/1000] Train Loss: 1.1332  |  Val Loss: 1.3250\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 309/1000] Train Loss: 1.1308  |  Val Loss: 1.1948\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 310/1000] Train Loss: 1.1218  |  Val Loss: 1.3232\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 311/1000] Train Loss: 1.1415  |  Val Loss: 1.1609\n",
      "Validation loss improved from 1.1630 to 1.1609.\n",
      "[Epoch 312/1000] Train Loss: 1.1096  |  Val Loss: 1.2111\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 313/1000] Train Loss: 1.1153  |  Val Loss: 1.1762\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 314/1000] Train Loss: 1.1056  |  Val Loss: 1.1605\n",
      "Validation loss improved from 1.1609 to 1.1605.\n",
      "[Epoch 315/1000] Train Loss: 1.0972  |  Val Loss: 1.2236\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 316/1000] Train Loss: 1.1148  |  Val Loss: 1.1856\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 317/1000] Train Loss: 1.1325  |  Val Loss: 1.3268\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 318/1000] Train Loss: 1.1631  |  Val Loss: 1.1677\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 319/1000] Train Loss: 1.1096  |  Val Loss: 1.2054\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 320/1000] Train Loss: 1.1015  |  Val Loss: 1.1510\n",
      "Validation loss improved from 1.1605 to 1.1510.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 321/1000] Train Loss: 1.0745  |  Val Loss: 1.2735\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 322/1000] Train Loss: 1.1213  |  Val Loss: 1.1682\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 323/1000] Train Loss: 1.0977  |  Val Loss: 1.2047\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 324/1000] Train Loss: 1.1050  |  Val Loss: 1.1987\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 325/1000] Train Loss: 1.1085  |  Val Loss: 1.1765\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 326/1000] Train Loss: 1.0857  |  Val Loss: 1.1839\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 327/1000] Train Loss: 1.0964  |  Val Loss: 1.1710\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 328/1000] Train Loss: 1.1085  |  Val Loss: 1.2022\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 329/1000] Train Loss: 1.0975  |  Val Loss: 1.1649\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 330/1000] Train Loss: 1.0891  |  Val Loss: 1.1980\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 331/1000] Train Loss: 1.0866  |  Val Loss: 1.1732\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 332/1000] Train Loss: 1.0898  |  Val Loss: 1.1737\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 333/1000] Train Loss: 1.0890  |  Val Loss: 1.1754\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 334/1000] Train Loss: 1.0899  |  Val Loss: 1.2389\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 335/1000] Train Loss: 1.1117  |  Val Loss: 1.1826\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 336/1000] Train Loss: 1.0914  |  Val Loss: 1.2278\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 337/1000] Train Loss: 1.0997  |  Val Loss: 1.1710\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 338/1000] Train Loss: 1.1143  |  Val Loss: 1.2555\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 339/1000] Train Loss: 1.1017  |  Val Loss: 1.1822\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 340/1000] Train Loss: 1.0892  |  Val Loss: 1.2095\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 341/1000] Train Loss: 1.0890  |  Val Loss: 1.1772\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 342/1000] Train Loss: 1.0994  |  Val Loss: 1.2138\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 343/1000] Train Loss: 1.0834  |  Val Loss: 1.1639\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 344/1000] Train Loss: 1.0985  |  Val Loss: 1.1889\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 345/1000] Train Loss: 1.0882  |  Val Loss: 1.1721\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 346/1000] Train Loss: 1.0887  |  Val Loss: 1.2167\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 347/1000] Train Loss: 1.1021  |  Val Loss: 1.2173\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 348/1000] Train Loss: 1.0957  |  Val Loss: 1.1596\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 349/1000] Train Loss: 1.0953  |  Val Loss: 1.2258\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 350/1000] Train Loss: 1.1054  |  Val Loss: 1.1791\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 351/1000] Train Loss: 1.1336  |  Val Loss: 1.2443\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 352/1000] Train Loss: 1.0850  |  Val Loss: 1.1644\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 353/1000] Train Loss: 1.0966  |  Val Loss: 1.3014\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 354/1000] Train Loss: 1.1027  |  Val Loss: 1.1601\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 355/1000] Train Loss: 1.1048  |  Val Loss: 1.2143\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 356/1000] Train Loss: 1.1114  |  Val Loss: 1.1832\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 357/1000] Train Loss: 1.1112  |  Val Loss: 1.1619\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 358/1000] Train Loss: 1.0928  |  Val Loss: 1.2120\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 359/1000] Train Loss: 1.0988  |  Val Loss: 1.1725\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 360/1000] Train Loss: 1.0986  |  Val Loss: 1.1876\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 361/1000] Train Loss: 1.0868  |  Val Loss: 1.1568\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 362/1000] Train Loss: 1.0889  |  Val Loss: 1.2046\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 363/1000] Train Loss: 1.1157  |  Val Loss: 1.1615\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 364/1000] Train Loss: 1.0956  |  Val Loss: 1.1851\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 365/1000] Train Loss: 1.1207  |  Val Loss: 1.2046\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 366/1000] Train Loss: 1.1161  |  Val Loss: 1.1711\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 367/1000] Train Loss: 1.0904  |  Val Loss: 1.2140\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 368/1000] Train Loss: 1.0840  |  Val Loss: 1.1550\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 369/1000] Train Loss: 1.1002  |  Val Loss: 1.1640\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 370/1000] Train Loss: 1.0914  |  Val Loss: 1.2044\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 371/1000] Train Loss: 1.0950  |  Val Loss: 1.1572\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 372/1000] Train Loss: 1.0874  |  Val Loss: 1.1614\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 373/1000] Train Loss: 1.0842  |  Val Loss: 1.1989\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 374/1000] Train Loss: 1.0902  |  Val Loss: 1.1484\n",
      "Validation loss improved from 1.1510 to 1.1484.\n",
      "[Epoch 375/1000] Train Loss: 1.0844  |  Val Loss: 1.2049\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 376/1000] Train Loss: 1.0834  |  Val Loss: 1.1809\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 377/1000] Train Loss: 1.0822  |  Val Loss: 1.1705\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 378/1000] Train Loss: 1.0892  |  Val Loss: 1.1894\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 379/1000] Train Loss: 1.0887  |  Val Loss: 1.1773\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 380/1000] Train Loss: 1.0869  |  Val Loss: 1.1480\n",
      "Validation loss improved from 1.1484 to 1.1480.\n",
      "[Epoch 381/1000] Train Loss: 1.0837  |  Val Loss: 1.1894\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 382/1000] Train Loss: 1.0881  |  Val Loss: 1.1541\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 383/1000] Train Loss: 1.0861  |  Val Loss: 1.1521\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 384/1000] Train Loss: 1.1163  |  Val Loss: 1.2329\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 385/1000] Train Loss: 1.1072  |  Val Loss: 1.1740\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 386/1000] Train Loss: 1.1099  |  Val Loss: 1.3192\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 387/1000] Train Loss: 1.1357  |  Val Loss: 1.1699\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 388/1000] Train Loss: 1.0984  |  Val Loss: 1.2961\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 389/1000] Train Loss: 1.1281  |  Val Loss: 1.1513\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 390/1000] Train Loss: 1.0962  |  Val Loss: 1.1710\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 391/1000] Train Loss: 1.0788  |  Val Loss: 1.1658\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 392/1000] Train Loss: 1.1167  |  Val Loss: 1.1444\n",
      "Validation loss improved from 1.1480 to 1.1444.\n",
      "[Epoch 393/1000] Train Loss: 1.1182  |  Val Loss: 1.2286\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 394/1000] Train Loss: 1.1057  |  Val Loss: 1.1603\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 395/1000] Train Loss: 1.1142  |  Val Loss: 1.2807\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 396/1000] Train Loss: 1.1173  |  Val Loss: 1.1433\n",
      "Validation loss improved from 1.1444 to 1.1433.\n",
      "[Epoch 397/1000] Train Loss: 1.0742  |  Val Loss: 1.2150\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 398/1000] Train Loss: 1.0978  |  Val Loss: 1.1704\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 399/1000] Train Loss: 1.0941  |  Val Loss: 1.1586\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 400/1000] Train Loss: 1.0748  |  Val Loss: 1.1588\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 401/1000] Train Loss: 1.0807  |  Val Loss: 1.1401\n",
      "Validation loss improved from 1.1433 to 1.1401.\n",
      "[Epoch 402/1000] Train Loss: 1.1009  |  Val Loss: 1.2533\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 403/1000] Train Loss: 1.1026  |  Val Loss: 1.1474\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 404/1000] Train Loss: 1.1052  |  Val Loss: 1.2760\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 405/1000] Train Loss: 1.0909  |  Val Loss: 1.1560\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 406/1000] Train Loss: 1.1073  |  Val Loss: 1.2037\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 407/1000] Train Loss: 1.0771  |  Val Loss: 1.1460\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 408/1000] Train Loss: 1.0878  |  Val Loss: 1.2216\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 409/1000] Train Loss: 1.0950  |  Val Loss: 1.1563\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 410/1000] Train Loss: 1.0729  |  Val Loss: 1.1754\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 411/1000] Train Loss: 1.0659  |  Val Loss: 1.1491\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 412/1000] Train Loss: 1.0867  |  Val Loss: 1.2051\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 413/1000] Train Loss: 1.0878  |  Val Loss: 1.1590\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 414/1000] Train Loss: 1.0887  |  Val Loss: 1.2239\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 415/1000] Train Loss: 1.0824  |  Val Loss: 1.1493\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 416/1000] Train Loss: 1.0804  |  Val Loss: 1.1792\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 417/1000] Train Loss: 1.0924  |  Val Loss: 1.2005\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 418/1000] Train Loss: 1.1219  |  Val Loss: 1.1538\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 419/1000] Train Loss: 1.0762  |  Val Loss: 1.2269\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 420/1000] Train Loss: 1.0826  |  Val Loss: 1.1479\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 421/1000] Train Loss: 1.0966  |  Val Loss: 1.2605\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 422/1000] Train Loss: 1.0790  |  Val Loss: 1.1609\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 423/1000] Train Loss: 1.1159  |  Val Loss: 1.2416\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 424/1000] Train Loss: 1.0873  |  Val Loss: 1.1770\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 425/1000] Train Loss: 1.0950  |  Val Loss: 1.2280\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 426/1000] Train Loss: 1.1135  |  Val Loss: 1.1779\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 427/1000] Train Loss: 1.1056  |  Val Loss: 1.1526\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 428/1000] Train Loss: 1.0923  |  Val Loss: 1.2678\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 429/1000] Train Loss: 1.1203  |  Val Loss: 1.1478\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 430/1000] Train Loss: 1.1325  |  Val Loss: 1.2298\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 431/1000] Train Loss: 1.0841  |  Val Loss: 1.1412\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 432/1000] Train Loss: 1.0865  |  Val Loss: 1.1763\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 433/1000] Train Loss: 1.0595  |  Val Loss: 1.1410\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 434/1000] Train Loss: 1.0760  |  Val Loss: 1.2121\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 435/1000] Train Loss: 1.0942  |  Val Loss: 1.1604\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 436/1000] Train Loss: 1.0655  |  Val Loss: 1.2065\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 437/1000] Train Loss: 1.0893  |  Val Loss: 1.1353\n",
      "Validation loss improved from 1.1401 to 1.1353.\n",
      "[Epoch 438/1000] Train Loss: 1.0621  |  Val Loss: 1.2003\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 439/1000] Train Loss: 1.0849  |  Val Loss: 1.1669\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 440/1000] Train Loss: 1.1015  |  Val Loss: 1.1535\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 441/1000] Train Loss: 1.1223  |  Val Loss: 1.2170\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 442/1000] Train Loss: 1.0825  |  Val Loss: 1.1353\n",
      "Validation loss improved from 1.1353 to 1.1353.\n",
      "[Epoch 443/1000] Train Loss: 1.0706  |  Val Loss: 1.1521\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 444/1000] Train Loss: 1.0804  |  Val Loss: 1.1645\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 445/1000] Train Loss: 1.1005  |  Val Loss: 1.1405\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 446/1000] Train Loss: 1.1107  |  Val Loss: 1.2837\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 447/1000] Train Loss: 1.1136  |  Val Loss: 1.1963\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 448/1000] Train Loss: 1.1013  |  Val Loss: 1.4678\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 449/1000] Train Loss: 1.1783  |  Val Loss: 1.1675\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 450/1000] Train Loss: 1.1033  |  Val Loss: 1.2391\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 451/1000] Train Loss: 1.1006  |  Val Loss: 1.1459\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 452/1000] Train Loss: 1.0865  |  Val Loss: 1.1807\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 453/1000] Train Loss: 1.0626  |  Val Loss: 1.1518\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 454/1000] Train Loss: 1.0810  |  Val Loss: 1.1495\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 455/1000] Train Loss: 1.0579  |  Val Loss: 1.1561\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 456/1000] Train Loss: 1.0821  |  Val Loss: 1.1861\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 457/1000] Train Loss: 1.0602  |  Val Loss: 1.1318\n",
      "Validation loss improved from 1.1353 to 1.1318.\n",
      "[Epoch 458/1000] Train Loss: 1.0650  |  Val Loss: 1.1875\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 459/1000] Train Loss: 1.0647  |  Val Loss: 1.1380\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 460/1000] Train Loss: 1.0651  |  Val Loss: 1.2182\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 461/1000] Train Loss: 1.0745  |  Val Loss: 1.1337\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 462/1000] Train Loss: 1.0641  |  Val Loss: 1.1741\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 463/1000] Train Loss: 1.0610  |  Val Loss: 1.1428\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 464/1000] Train Loss: 1.0577  |  Val Loss: 1.1567\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 465/1000] Train Loss: 1.0584  |  Val Loss: 1.1606\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 466/1000] Train Loss: 1.0667  |  Val Loss: 1.1233\n",
      "Validation loss improved from 1.1318 to 1.1233.\n",
      "[Epoch 467/1000] Train Loss: 1.0739  |  Val Loss: 1.1758\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 468/1000] Train Loss: 1.0611  |  Val Loss: 1.1328\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 469/1000] Train Loss: 1.0749  |  Val Loss: 1.2618\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 470/1000] Train Loss: 1.1001  |  Val Loss: 1.1281\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 471/1000] Train Loss: 1.0628  |  Val Loss: 1.1428\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 472/1000] Train Loss: 1.0479  |  Val Loss: 1.1483\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 473/1000] Train Loss: 1.0577  |  Val Loss: 1.1514\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 474/1000] Train Loss: 1.0486  |  Val Loss: 1.1404\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 475/1000] Train Loss: 1.0542  |  Val Loss: 1.1440\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 476/1000] Train Loss: 1.0552  |  Val Loss: 1.1805\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 477/1000] Train Loss: 1.0553  |  Val Loss: 1.1225\n",
      "Validation loss improved from 1.1233 to 1.1225.\n",
      "[Epoch 478/1000] Train Loss: 1.0656  |  Val Loss: 1.1887\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 479/1000] Train Loss: 1.0498  |  Val Loss: 1.1219\n",
      "Validation loss improved from 1.1225 to 1.1219.\n",
      "[Epoch 480/1000] Train Loss: 1.0494  |  Val Loss: 1.1765\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 481/1000] Train Loss: 1.0484  |  Val Loss: 1.1312\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 482/1000] Train Loss: 1.0638  |  Val Loss: 1.1872\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 483/1000] Train Loss: 1.0707  |  Val Loss: 1.1347\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 484/1000] Train Loss: 1.0535  |  Val Loss: 1.1489\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 485/1000] Train Loss: 1.0582  |  Val Loss: 1.1634\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 486/1000] Train Loss: 1.0648  |  Val Loss: 1.1331\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 487/1000] Train Loss: 1.0522  |  Val Loss: 1.1788\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 488/1000] Train Loss: 1.0650  |  Val Loss: 1.1545\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 489/1000] Train Loss: 1.0642  |  Val Loss: 1.1209\n",
      "Validation loss improved from 1.1219 to 1.1209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 490/1000] Train Loss: 1.0474  |  Val Loss: 1.2027\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 491/1000] Train Loss: 1.0786  |  Val Loss: 1.1159\n",
      "Validation loss improved from 1.1209 to 1.1159.\n",
      "[Epoch 492/1000] Train Loss: 1.0474  |  Val Loss: 1.1867\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 493/1000] Train Loss: 1.0582  |  Val Loss: 1.1180\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 494/1000] Train Loss: 1.0500  |  Val Loss: 1.1593\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 495/1000] Train Loss: 1.0484  |  Val Loss: 1.1351\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 496/1000] Train Loss: 1.0444  |  Val Loss: 1.1095\n",
      "Validation loss improved from 1.1159 to 1.1095.\n",
      "[Epoch 497/1000] Train Loss: 1.0660  |  Val Loss: 1.1704\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 498/1000] Train Loss: 1.0680  |  Val Loss: 1.1225\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 499/1000] Train Loss: 1.0842  |  Val Loss: 1.2278\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 500/1000] Train Loss: 1.0770  |  Val Loss: 1.1301\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 501/1000] Train Loss: 1.0627  |  Val Loss: 1.1083\n",
      "Validation loss improved from 1.1095 to 1.1083.\n",
      "[Epoch 502/1000] Train Loss: 1.0517  |  Val Loss: 1.1904\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 503/1000] Train Loss: 1.0596  |  Val Loss: 1.1373\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 504/1000] Train Loss: 1.1035  |  Val Loss: 1.1524\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 505/1000] Train Loss: 1.0762  |  Val Loss: 1.1589\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 506/1000] Train Loss: 1.0691  |  Val Loss: 1.1179\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 507/1000] Train Loss: 1.1167  |  Val Loss: 1.2036\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 508/1000] Train Loss: 1.0921  |  Val Loss: 1.1121\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 509/1000] Train Loss: 1.0567  |  Val Loss: 1.1749\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 510/1000] Train Loss: 1.0927  |  Val Loss: 1.1332\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 511/1000] Train Loss: 1.0897  |  Val Loss: 1.2567\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 512/1000] Train Loss: 1.0915  |  Val Loss: 1.1252\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 513/1000] Train Loss: 1.0472  |  Val Loss: 1.1594\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 514/1000] Train Loss: 1.0321  |  Val Loss: 1.1211\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 515/1000] Train Loss: 1.0478  |  Val Loss: 1.1646\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 516/1000] Train Loss: 1.0405  |  Val Loss: 1.1192\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 517/1000] Train Loss: 1.0293  |  Val Loss: 1.1616\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 518/1000] Train Loss: 1.0415  |  Val Loss: 1.1049\n",
      "Validation loss improved from 1.1083 to 1.1049.\n",
      "[Epoch 519/1000] Train Loss: 1.0368  |  Val Loss: 1.1469\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 520/1000] Train Loss: 1.0338  |  Val Loss: 1.1226\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 521/1000] Train Loss: 1.0336  |  Val Loss: 1.1459\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 522/1000] Train Loss: 1.0358  |  Val Loss: 1.1023\n",
      "Validation loss improved from 1.1049 to 1.1023.\n",
      "[Epoch 523/1000] Train Loss: 1.0361  |  Val Loss: 1.1955\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 524/1000] Train Loss: 1.0451  |  Val Loss: 1.1366\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 525/1000] Train Loss: 1.0765  |  Val Loss: 1.3520\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 526/1000] Train Loss: 1.1353  |  Val Loss: 1.1674\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 527/1000] Train Loss: 1.0960  |  Val Loss: 1.2852\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 528/1000] Train Loss: 1.0855  |  Val Loss: 1.1046\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 529/1000] Train Loss: 1.0304  |  Val Loss: 1.1913\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 530/1000] Train Loss: 1.0565  |  Val Loss: 1.1037\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 531/1000] Train Loss: 1.0611  |  Val Loss: 1.1208\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 532/1000] Train Loss: 1.0618  |  Val Loss: 1.1625\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 533/1000] Train Loss: 1.0748  |  Val Loss: 1.1032\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 534/1000] Train Loss: 1.0868  |  Val Loss: 1.1773\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 535/1000] Train Loss: 1.1144  |  Val Loss: 1.0940\n",
      "Validation loss improved from 1.1023 to 1.0940.\n",
      "[Epoch 536/1000] Train Loss: 1.1264  |  Val Loss: 1.1831\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 537/1000] Train Loss: 1.0993  |  Val Loss: 1.1023\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 538/1000] Train Loss: 1.0804  |  Val Loss: 1.1573\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 539/1000] Train Loss: 1.0409  |  Val Loss: 1.1014\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 540/1000] Train Loss: 1.0211  |  Val Loss: 1.1277\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 541/1000] Train Loss: 1.0324  |  Val Loss: 1.1115\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 542/1000] Train Loss: 1.0246  |  Val Loss: 1.1146\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 543/1000] Train Loss: 1.0331  |  Val Loss: 1.1085\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 544/1000] Train Loss: 1.0186  |  Val Loss: 1.1057\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 545/1000] Train Loss: 1.0297  |  Val Loss: 1.1460\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 546/1000] Train Loss: 1.0426  |  Val Loss: 1.1066\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 547/1000] Train Loss: 1.0274  |  Val Loss: 1.1285\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 548/1000] Train Loss: 1.0215  |  Val Loss: 1.0829\n",
      "Validation loss improved from 1.0940 to 1.0829.\n",
      "[Epoch 549/1000] Train Loss: 1.0244  |  Val Loss: 1.1490\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 550/1000] Train Loss: 1.0230  |  Val Loss: 1.0967\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 551/1000] Train Loss: 1.0175  |  Val Loss: 1.1147\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 552/1000] Train Loss: 1.0115  |  Val Loss: 1.1312\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 553/1000] Train Loss: 1.0212  |  Val Loss: 1.0870\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 554/1000] Train Loss: 1.0334  |  Val Loss: 1.1340\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 555/1000] Train Loss: 1.0379  |  Val Loss: 1.0972\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 556/1000] Train Loss: 1.0616  |  Val Loss: 1.1120\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 557/1000] Train Loss: 1.0088  |  Val Loss: 1.1071\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 558/1000] Train Loss: 1.0401  |  Val Loss: 1.1475\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 559/1000] Train Loss: 1.0143  |  Val Loss: 1.1226\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 560/1000] Train Loss: 1.0285  |  Val Loss: 1.1168\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 561/1000] Train Loss: 1.0315  |  Val Loss: 1.1208\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 562/1000] Train Loss: 1.0219  |  Val Loss: 1.1250\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 563/1000] Train Loss: 1.0074  |  Val Loss: 1.0841\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 564/1000] Train Loss: 1.0130  |  Val Loss: 1.0903\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 565/1000] Train Loss: 1.0077  |  Val Loss: 1.1227\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 566/1000] Train Loss: 0.9982  |  Val Loss: 1.1040\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 567/1000] Train Loss: 1.0068  |  Val Loss: 1.1023\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 568/1000] Train Loss: 1.0034  |  Val Loss: 1.0702\n",
      "Validation loss improved from 1.0829 to 1.0702.\n",
      "[Epoch 569/1000] Train Loss: 1.0081  |  Val Loss: 1.1175\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 570/1000] Train Loss: 0.9995  |  Val Loss: 1.0905\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 571/1000] Train Loss: 0.9990  |  Val Loss: 1.1088\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 572/1000] Train Loss: 1.0037  |  Val Loss: 1.1033\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 573/1000] Train Loss: 1.0129  |  Val Loss: 1.0783\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 574/1000] Train Loss: 1.0376  |  Val Loss: 1.1701\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 575/1000] Train Loss: 1.0862  |  Val Loss: 1.0921\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 576/1000] Train Loss: 1.1075  |  Val Loss: 1.2341\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 577/1000] Train Loss: 1.1374  |  Val Loss: 1.0896\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 578/1000] Train Loss: 1.0350  |  Val Loss: 1.1236\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 579/1000] Train Loss: 1.0175  |  Val Loss: 1.0999\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 580/1000] Train Loss: 1.0056  |  Val Loss: 1.1082\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 581/1000] Train Loss: 1.0055  |  Val Loss: 1.0952\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 582/1000] Train Loss: 0.9860  |  Val Loss: 1.0989\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 583/1000] Train Loss: 0.9991  |  Val Loss: 1.0701\n",
      "Validation loss improved from 1.0702 to 1.0701.\n",
      "[Epoch 584/1000] Train Loss: 0.9859  |  Val Loss: 1.1194\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 585/1000] Train Loss: 0.9913  |  Val Loss: 1.1091\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 586/1000] Train Loss: 1.0634  |  Val Loss: 1.0794\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 587/1000] Train Loss: 0.9912  |  Val Loss: 1.0588\n",
      "Validation loss improved from 1.0701 to 1.0588.\n",
      "[Epoch 588/1000] Train Loss: 1.0058  |  Val Loss: 1.0510\n",
      "Validation loss improved from 1.0588 to 1.0510.\n",
      "[Epoch 589/1000] Train Loss: 1.0376  |  Val Loss: 1.1426\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 590/1000] Train Loss: 1.0523  |  Val Loss: 1.0696\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 591/1000] Train Loss: 0.9919  |  Val Loss: 1.1091\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 592/1000] Train Loss: 0.9811  |  Val Loss: 1.0690\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 593/1000] Train Loss: 0.9908  |  Val Loss: 1.0708\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 594/1000] Train Loss: 0.9896  |  Val Loss: 1.0565\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 595/1000] Train Loss: 0.9904  |  Val Loss: 1.1095\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 596/1000] Train Loss: 0.9838  |  Val Loss: 1.0604\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 597/1000] Train Loss: 0.9719  |  Val Loss: 1.0671\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 598/1000] Train Loss: 0.9872  |  Val Loss: 1.0792\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 599/1000] Train Loss: 0.9970  |  Val Loss: 1.0440\n",
      "Validation loss improved from 1.0510 to 1.0440.\n",
      "[Epoch 600/1000] Train Loss: 0.9992  |  Val Loss: 1.1140\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 601/1000] Train Loss: 0.9730  |  Val Loss: 1.0438\n",
      "Validation loss improved from 1.0440 to 1.0438.\n",
      "[Epoch 602/1000] Train Loss: 0.9969  |  Val Loss: 1.1131\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 603/1000] Train Loss: 0.9760  |  Val Loss: 1.0453\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 604/1000] Train Loss: 0.9913  |  Val Loss: 1.0808\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 605/1000] Train Loss: 1.0213  |  Val Loss: 1.1078\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 606/1000] Train Loss: 1.0172  |  Val Loss: 1.0542\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 607/1000] Train Loss: 1.0338  |  Val Loss: 1.1203\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 608/1000] Train Loss: 1.0044  |  Val Loss: 1.0495\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 609/1000] Train Loss: 1.0181  |  Val Loss: 1.2228\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 610/1000] Train Loss: 1.0072  |  Val Loss: 1.0640\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 611/1000] Train Loss: 0.9906  |  Val Loss: 1.1201\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 612/1000] Train Loss: 0.9889  |  Val Loss: 1.0560\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 613/1000] Train Loss: 0.9726  |  Val Loss: 1.0584\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 614/1000] Train Loss: 0.9623  |  Val Loss: 1.0529\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 615/1000] Train Loss: 0.9666  |  Val Loss: 1.0411\n",
      "Validation loss improved from 1.0438 to 1.0411.\n",
      "[Epoch 616/1000] Train Loss: 0.9901  |  Val Loss: 1.1229\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 617/1000] Train Loss: 0.9869  |  Val Loss: 1.0496\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 618/1000] Train Loss: 0.9873  |  Val Loss: 1.1137\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 619/1000] Train Loss: 0.9821  |  Val Loss: 1.0305\n",
      "Validation loss improved from 1.0411 to 1.0305.\n",
      "[Epoch 620/1000] Train Loss: 0.9556  |  Val Loss: 1.0413\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 621/1000] Train Loss: 0.9734  |  Val Loss: 1.0556\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 622/1000] Train Loss: 0.9499  |  Val Loss: 1.0585\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 623/1000] Train Loss: 0.9866  |  Val Loss: 1.0979\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 624/1000] Train Loss: 0.9731  |  Val Loss: 1.0422\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 625/1000] Train Loss: 0.9489  |  Val Loss: 1.0741\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 626/1000] Train Loss: 0.9526  |  Val Loss: 1.0487\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 627/1000] Train Loss: 0.9604  |  Val Loss: 1.0259\n",
      "Validation loss improved from 1.0305 to 1.0259.\n",
      "[Epoch 628/1000] Train Loss: 0.9541  |  Val Loss: 1.0427\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 629/1000] Train Loss: 0.9492  |  Val Loss: 1.0635\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 630/1000] Train Loss: 0.9461  |  Val Loss: 1.0192\n",
      "Validation loss improved from 1.0259 to 1.0192.\n",
      "[Epoch 631/1000] Train Loss: 0.9607  |  Val Loss: 1.0913\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 632/1000] Train Loss: 0.9406  |  Val Loss: 1.0230\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 633/1000] Train Loss: 0.9594  |  Val Loss: 1.0400\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 634/1000] Train Loss: 0.9703  |  Val Loss: 1.0818\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 635/1000] Train Loss: 0.9844  |  Val Loss: 1.0122\n",
      "Validation loss improved from 1.0192 to 1.0122.\n",
      "[Epoch 636/1000] Train Loss: 0.9878  |  Val Loss: 1.1234\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 637/1000] Train Loss: 0.9732  |  Val Loss: 1.0383\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 638/1000] Train Loss: 1.0462  |  Val Loss: 1.1492\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 639/1000] Train Loss: 1.1231  |  Val Loss: 1.0272\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 640/1000] Train Loss: 1.0992  |  Val Loss: 1.1470\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 641/1000] Train Loss: 1.0467  |  Val Loss: 1.0151\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 642/1000] Train Loss: 0.9778  |  Val Loss: 1.0688\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 643/1000] Train Loss: 0.9526  |  Val Loss: 1.0098\n",
      "Validation loss improved from 1.0122 to 1.0098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 644/1000] Train Loss: 0.9814  |  Val Loss: 1.0095\n",
      "Validation loss improved from 1.0098 to 1.0095.\n",
      "[Epoch 645/1000] Train Loss: 0.9724  |  Val Loss: 1.0748\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 646/1000] Train Loss: 0.9378  |  Val Loss: 1.0485\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 647/1000] Train Loss: 0.9667  |  Val Loss: 1.1613\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 648/1000] Train Loss: 0.9626  |  Val Loss: 1.0407\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 649/1000] Train Loss: 0.9731  |  Val Loss: 1.0386\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 650/1000] Train Loss: 0.9637  |  Val Loss: 1.0179\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 651/1000] Train Loss: 0.9511  |  Val Loss: 0.9868\n",
      "Validation loss improved from 1.0095 to 0.9868.\n",
      "[Epoch 652/1000] Train Loss: 0.9581  |  Val Loss: 1.0652\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 653/1000] Train Loss: 0.9558  |  Val Loss: 0.9880\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 654/1000] Train Loss: 0.9586  |  Val Loss: 1.0210\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 655/1000] Train Loss: 0.9393  |  Val Loss: 0.9868\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 656/1000] Train Loss: 0.9185  |  Val Loss: 0.9855\n",
      "Validation loss improved from 0.9868 to 0.9855.\n",
      "[Epoch 657/1000] Train Loss: 0.9126  |  Val Loss: 1.0125\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 658/1000] Train Loss: 0.9225  |  Val Loss: 0.9749\n",
      "Validation loss improved from 0.9855 to 0.9749.\n",
      "[Epoch 659/1000] Train Loss: 0.9407  |  Val Loss: 1.1085\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 660/1000] Train Loss: 0.9714  |  Val Loss: 0.9682\n",
      "Validation loss improved from 0.9749 to 0.9682.\n",
      "[Epoch 661/1000] Train Loss: 0.9139  |  Val Loss: 0.9942\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 662/1000] Train Loss: 0.9189  |  Val Loss: 0.9919\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 663/1000] Train Loss: 0.9272  |  Val Loss: 0.9791\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 664/1000] Train Loss: 0.8934  |  Val Loss: 0.9653\n",
      "Validation loss improved from 0.9682 to 0.9653.\n",
      "[Epoch 665/1000] Train Loss: 0.9030  |  Val Loss: 1.0264\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 666/1000] Train Loss: 0.9072  |  Val Loss: 0.9979\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 667/1000] Train Loss: 0.9114  |  Val Loss: 0.9737\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 668/1000] Train Loss: 0.9206  |  Val Loss: 0.9698\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 669/1000] Train Loss: 0.9389  |  Val Loss: 1.1183\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 670/1000] Train Loss: 0.9536  |  Val Loss: 1.0071\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 671/1000] Train Loss: 0.9482  |  Val Loss: 1.0006\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 672/1000] Train Loss: 0.8914  |  Val Loss: 0.9693\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 673/1000] Train Loss: 0.8826  |  Val Loss: 1.0416\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 674/1000] Train Loss: 0.8891  |  Val Loss: 0.9410\n",
      "Validation loss improved from 0.9653 to 0.9410.\n",
      "[Epoch 675/1000] Train Loss: 0.9501  |  Val Loss: 1.0305\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 676/1000] Train Loss: 0.9152  |  Val Loss: 0.9730\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 677/1000] Train Loss: 0.9372  |  Val Loss: 1.0984\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 678/1000] Train Loss: 0.9626  |  Val Loss: 0.9823\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 679/1000] Train Loss: 0.9748  |  Val Loss: 1.0362\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 680/1000] Train Loss: 1.0193  |  Val Loss: 1.1310\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 681/1000] Train Loss: 0.9665  |  Val Loss: 0.9568\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 682/1000] Train Loss: 0.9251  |  Val Loss: 0.9701\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 683/1000] Train Loss: 0.9128  |  Val Loss: 1.1231\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 684/1000] Train Loss: 0.9572  |  Val Loss: 1.0596\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 685/1000] Train Loss: 0.9273  |  Val Loss: 1.1919\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 686/1000] Train Loss: 0.9868  |  Val Loss: 1.0074\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 687/1000] Train Loss: 0.8885  |  Val Loss: 1.0276\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 688/1000] Train Loss: 0.8757  |  Val Loss: 0.9686\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 689/1000] Train Loss: 0.8691  |  Val Loss: 0.9812\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 690/1000] Train Loss: 0.8574  |  Val Loss: 0.9587\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 691/1000] Train Loss: 0.8723  |  Val Loss: 0.9599\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 692/1000] Train Loss: 0.8514  |  Val Loss: 0.9460\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 693/1000] Train Loss: 0.8515  |  Val Loss: 0.9725\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 694/1000] Train Loss: 0.8609  |  Val Loss: 0.9423\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 695/1000] Train Loss: 0.8582  |  Val Loss: 0.9841\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 696/1000] Train Loss: 0.9099  |  Val Loss: 0.9593\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 697/1000] Train Loss: 0.8748  |  Val Loss: 0.9876\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 698/1000] Train Loss: 0.9445  |  Val Loss: 0.9260\n",
      "Validation loss improved from 0.9410 to 0.9260.\n",
      "[Epoch 699/1000] Train Loss: 0.9793  |  Val Loss: 1.1412\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 700/1000] Train Loss: 0.9578  |  Val Loss: 1.0781\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 701/1000] Train Loss: 0.9108  |  Val Loss: 0.9479\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 702/1000] Train Loss: 0.8776  |  Val Loss: 1.0411\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 703/1000] Train Loss: 0.8712  |  Val Loss: 0.9250\n",
      "Validation loss improved from 0.9260 to 0.9250.\n",
      "[Epoch 704/1000] Train Loss: 0.8847  |  Val Loss: 0.9351\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 705/1000] Train Loss: 0.8269  |  Val Loss: 1.0206\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 706/1000] Train Loss: 0.8937  |  Val Loss: 0.9195\n",
      "Validation loss improved from 0.9250 to 0.9195.\n",
      "[Epoch 707/1000] Train Loss: 0.8810  |  Val Loss: 1.0084\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 708/1000] Train Loss: 0.9433  |  Val Loss: 1.1551\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 709/1000] Train Loss: 0.9606  |  Val Loss: 0.9696\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 710/1000] Train Loss: 0.8557  |  Val Loss: 0.9248\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 711/1000] Train Loss: 0.8525  |  Val Loss: 0.9777\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 712/1000] Train Loss: 0.8491  |  Val Loss: 1.0665\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 713/1000] Train Loss: 0.9042  |  Val Loss: 0.9584\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 714/1000] Train Loss: 0.9295  |  Val Loss: 0.9920\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 715/1000] Train Loss: 0.8938  |  Val Loss: 0.9537\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 716/1000] Train Loss: 0.8329  |  Val Loss: 0.9983\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 717/1000] Train Loss: 0.8597  |  Val Loss: 0.9093\n",
      "Validation loss improved from 0.9195 to 0.9093.\n",
      "[Epoch 718/1000] Train Loss: 0.8185  |  Val Loss: 0.9393\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 719/1000] Train Loss: 0.8195  |  Val Loss: 0.8942\n",
      "Validation loss improved from 0.9093 to 0.8942.\n",
      "[Epoch 720/1000] Train Loss: 0.8306  |  Val Loss: 0.9609\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 721/1000] Train Loss: 0.8369  |  Val Loss: 0.9241\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 722/1000] Train Loss: 0.8142  |  Val Loss: 0.8952\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 723/1000] Train Loss: 0.8191  |  Val Loss: 0.8907\n",
      "Validation loss improved from 0.8942 to 0.8907.\n",
      "[Epoch 724/1000] Train Loss: 0.8086  |  Val Loss: 0.9103\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 725/1000] Train Loss: 0.8049  |  Val Loss: 0.8939\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 726/1000] Train Loss: 0.8322  |  Val Loss: 0.9143\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 727/1000] Train Loss: 0.8131  |  Val Loss: 0.9051\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 728/1000] Train Loss: 0.8161  |  Val Loss: 0.9048\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 729/1000] Train Loss: 0.7972  |  Val Loss: 0.9281\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 730/1000] Train Loss: 0.8125  |  Val Loss: 0.8850\n",
      "Validation loss improved from 0.8907 to 0.8850.\n",
      "[Epoch 731/1000] Train Loss: 0.7958  |  Val Loss: 0.9053\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 732/1000] Train Loss: 0.7991  |  Val Loss: 0.8869\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 733/1000] Train Loss: 0.8005  |  Val Loss: 0.9088\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 734/1000] Train Loss: 0.7950  |  Val Loss: 0.8968\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 735/1000] Train Loss: 0.8040  |  Val Loss: 0.9055\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 736/1000] Train Loss: 0.7962  |  Val Loss: 0.9044\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 737/1000] Train Loss: 0.7982  |  Val Loss: 0.8964\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 738/1000] Train Loss: 0.7830  |  Val Loss: 0.8944\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 739/1000] Train Loss: 0.7970  |  Val Loss: 0.8842\n",
      "Validation loss improved from 0.8850 to 0.8842.\n",
      "[Epoch 740/1000] Train Loss: 0.8063  |  Val Loss: 0.9235\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 741/1000] Train Loss: 0.8186  |  Val Loss: 0.9137\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 742/1000] Train Loss: 0.7941  |  Val Loss: 0.9037\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 743/1000] Train Loss: 0.7887  |  Val Loss: 0.9601\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 744/1000] Train Loss: 0.8187  |  Val Loss: 0.9668\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 745/1000] Train Loss: 0.8144  |  Val Loss: 0.8811\n",
      "Validation loss improved from 0.8842 to 0.8811.\n",
      "[Epoch 746/1000] Train Loss: 0.7736  |  Val Loss: 0.8719\n",
      "Validation loss improved from 0.8811 to 0.8719.\n",
      "[Epoch 747/1000] Train Loss: 0.7855  |  Val Loss: 0.9028\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 748/1000] Train Loss: 0.7798  |  Val Loss: 0.8873\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 749/1000] Train Loss: 0.8057  |  Val Loss: 0.9400\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 750/1000] Train Loss: 0.8415  |  Val Loss: 0.8691\n",
      "Validation loss improved from 0.8719 to 0.8691.\n",
      "[Epoch 751/1000] Train Loss: 0.7917  |  Val Loss: 0.9212\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 752/1000] Train Loss: 0.8322  |  Val Loss: 0.8709\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 753/1000] Train Loss: 0.7882  |  Val Loss: 0.8917\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 754/1000] Train Loss: 0.7807  |  Val Loss: 0.9061\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 755/1000] Train Loss: 0.7834  |  Val Loss: 0.8766\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 756/1000] Train Loss: 0.7693  |  Val Loss: 0.8813\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 757/1000] Train Loss: 0.7610  |  Val Loss: 0.9840\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 758/1000] Train Loss: 0.8345  |  Val Loss: 0.9113\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 759/1000] Train Loss: 0.7915  |  Val Loss: 0.8710\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 760/1000] Train Loss: 0.7784  |  Val Loss: 0.8830\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 761/1000] Train Loss: 0.7783  |  Val Loss: 0.8719\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 762/1000] Train Loss: 0.7626  |  Val Loss: 0.8682\n",
      "Validation loss improved from 0.8691 to 0.8682.\n",
      "[Epoch 763/1000] Train Loss: 0.7587  |  Val Loss: 0.8816\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 764/1000] Train Loss: 0.7645  |  Val Loss: 0.8562\n",
      "Validation loss improved from 0.8682 to 0.8562.\n",
      "[Epoch 765/1000] Train Loss: 0.7809  |  Val Loss: 0.8880\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 766/1000] Train Loss: 0.7590  |  Val Loss: 0.8733\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 767/1000] Train Loss: 0.7549  |  Val Loss: 0.8610\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 768/1000] Train Loss: 0.7474  |  Val Loss: 0.8911\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 769/1000] Train Loss: 0.7480  |  Val Loss: 0.8608\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 770/1000] Train Loss: 0.7598  |  Val Loss: 0.8932\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 771/1000] Train Loss: 0.7716  |  Val Loss: 0.8650\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 772/1000] Train Loss: 0.7462  |  Val Loss: 0.8650\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 773/1000] Train Loss: 0.7557  |  Val Loss: 0.8519\n",
      "Validation loss improved from 0.8562 to 0.8519.\n",
      "[Epoch 774/1000] Train Loss: 0.7474  |  Val Loss: 0.8997\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 775/1000] Train Loss: 0.7676  |  Val Loss: 0.8725\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 776/1000] Train Loss: 0.7479  |  Val Loss: 0.8703\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 777/1000] Train Loss: 0.7757  |  Val Loss: 0.9419\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 778/1000] Train Loss: 0.7665  |  Val Loss: 0.8947\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 779/1000] Train Loss: 0.7992  |  Val Loss: 0.8665\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 780/1000] Train Loss: 0.7759  |  Val Loss: 0.8712\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 781/1000] Train Loss: 0.7375  |  Val Loss: 0.8620\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 782/1000] Train Loss: 0.7351  |  Val Loss: 0.8585\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 783/1000] Train Loss: 0.7413  |  Val Loss: 0.8573\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 784/1000] Train Loss: 0.7508  |  Val Loss: 0.8481\n",
      "Validation loss improved from 0.8519 to 0.8481.\n",
      "[Epoch 785/1000] Train Loss: 0.7690  |  Val Loss: 0.8517\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 786/1000] Train Loss: 0.7362  |  Val Loss: 0.8703\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 787/1000] Train Loss: 0.7288  |  Val Loss: 0.8520\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 788/1000] Train Loss: 0.7424  |  Val Loss: 0.9117\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 789/1000] Train Loss: 0.7606  |  Val Loss: 0.8405\n",
      "Validation loss improved from 0.8481 to 0.8405.\n",
      "[Epoch 790/1000] Train Loss: 0.7372  |  Val Loss: 0.8555\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 791/1000] Train Loss: 0.7403  |  Val Loss: 0.8354\n",
      "Validation loss improved from 0.8405 to 0.8354.\n",
      "[Epoch 792/1000] Train Loss: 0.7453  |  Val Loss: 0.9583\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 793/1000] Train Loss: 0.7634  |  Val Loss: 0.8760\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 794/1000] Train Loss: 0.7453  |  Val Loss: 0.8502\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 795/1000] Train Loss: 0.7428  |  Val Loss: 0.8831\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 796/1000] Train Loss: 0.7432  |  Val Loss: 0.8235\n",
      "Validation loss improved from 0.8354 to 0.8235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 797/1000] Train Loss: 0.7208  |  Val Loss: 0.9620\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 798/1000] Train Loss: 0.7788  |  Val Loss: 0.8307\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 799/1000] Train Loss: 0.7367  |  Val Loss: 0.8374\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 800/1000] Train Loss: 0.7438  |  Val Loss: 0.8558\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 801/1000] Train Loss: 0.7871  |  Val Loss: 0.8527\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 802/1000] Train Loss: 0.7816  |  Val Loss: 0.8805\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 803/1000] Train Loss: 0.7571  |  Val Loss: 0.8216\n",
      "Validation loss improved from 0.8235 to 0.8216.\n",
      "[Epoch 804/1000] Train Loss: 0.7456  |  Val Loss: 0.8664\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 805/1000] Train Loss: 0.7308  |  Val Loss: 0.8196\n",
      "Validation loss improved from 0.8216 to 0.8196.\n",
      "[Epoch 806/1000] Train Loss: 0.7120  |  Val Loss: 0.8832\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 807/1000] Train Loss: 0.7273  |  Val Loss: 0.8468\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 808/1000] Train Loss: 0.7488  |  Val Loss: 0.8696\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 809/1000] Train Loss: 0.7468  |  Val Loss: 0.8222\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 810/1000] Train Loss: 0.7474  |  Val Loss: 0.9662\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 811/1000] Train Loss: 0.7480  |  Val Loss: 0.8266\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 812/1000] Train Loss: 0.7215  |  Val Loss: 0.8286\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 813/1000] Train Loss: 0.7034  |  Val Loss: 0.8706\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 814/1000] Train Loss: 0.7265  |  Val Loss: 0.8661\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 815/1000] Train Loss: 0.7192  |  Val Loss: 0.8580\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 816/1000] Train Loss: 0.7081  |  Val Loss: 0.8319\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 817/1000] Train Loss: 0.7177  |  Val Loss: 0.8641\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 818/1000] Train Loss: 0.7109  |  Val Loss: 0.8941\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 819/1000] Train Loss: 0.7389  |  Val Loss: 0.8744\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 820/1000] Train Loss: 0.7268  |  Val Loss: 0.8947\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 821/1000] Train Loss: 0.7359  |  Val Loss: 0.8288\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 822/1000] Train Loss: 0.7461  |  Val Loss: 0.8466\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 823/1000] Train Loss: 0.7271  |  Val Loss: 0.8994\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 824/1000] Train Loss: 0.7513  |  Val Loss: 0.8449\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 825/1000] Train Loss: 0.9090  |  Val Loss: 0.9240\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 826/1000] Train Loss: 0.7810  |  Val Loss: 0.8981\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 827/1000] Train Loss: 0.7652  |  Val Loss: 0.8333\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 828/1000] Train Loss: 0.7807  |  Val Loss: 0.9483\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 829/1000] Train Loss: 0.7537  |  Val Loss: 0.8421\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 830/1000] Train Loss: 0.7226  |  Val Loss: 0.8333\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 831/1000] Train Loss: 0.7152  |  Val Loss: 0.8811\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 832/1000] Train Loss: 0.7017  |  Val Loss: 0.8236\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 833/1000] Train Loss: 0.7469  |  Val Loss: 0.8911\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 834/1000] Train Loss: 0.7361  |  Val Loss: 0.8080\n",
      "Validation loss improved from 0.8196 to 0.8080.\n",
      "[Epoch 835/1000] Train Loss: 0.7122  |  Val Loss: 0.8422\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 836/1000] Train Loss: 0.7024  |  Val Loss: 0.8264\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 837/1000] Train Loss: 0.7027  |  Val Loss: 0.8447\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 838/1000] Train Loss: 0.7741  |  Val Loss: 0.8298\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 839/1000] Train Loss: 0.7925  |  Val Loss: 0.9916\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 840/1000] Train Loss: 0.7786  |  Val Loss: 0.8575\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 841/1000] Train Loss: 0.7352  |  Val Loss: 0.8329\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 842/1000] Train Loss: 0.7392  |  Val Loss: 0.8389\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 843/1000] Train Loss: 0.6885  |  Val Loss: 0.8585\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 844/1000] Train Loss: 0.7660  |  Val Loss: 0.9436\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 845/1000] Train Loss: 0.7402  |  Val Loss: 0.8043\n",
      "Validation loss improved from 0.8080 to 0.8043.\n",
      "[Epoch 846/1000] Train Loss: 0.6888  |  Val Loss: 0.8045\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 847/1000] Train Loss: 0.6845  |  Val Loss: 0.8119\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 848/1000] Train Loss: 0.6732  |  Val Loss: 0.7986\n",
      "Validation loss improved from 0.8043 to 0.7986.\n",
      "[Epoch 849/1000] Train Loss: 0.6836  |  Val Loss: 0.8004\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 850/1000] Train Loss: 0.6801  |  Val Loss: 0.8000\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 851/1000] Train Loss: 0.6698  |  Val Loss: 0.8148\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 852/1000] Train Loss: 0.6615  |  Val Loss: 0.8488\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 853/1000] Train Loss: 0.6873  |  Val Loss: 0.8084\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 854/1000] Train Loss: 0.6687  |  Val Loss: 0.8172\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 855/1000] Train Loss: 0.6608  |  Val Loss: 0.8273\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 856/1000] Train Loss: 0.6631  |  Val Loss: 0.8505\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 857/1000] Train Loss: 0.7003  |  Val Loss: 0.8171\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 858/1000] Train Loss: 0.7039  |  Val Loss: 0.8132\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 859/1000] Train Loss: 0.6749  |  Val Loss: 0.7903\n",
      "Validation loss improved from 0.7986 to 0.7903.\n",
      "[Epoch 860/1000] Train Loss: 0.6627  |  Val Loss: 0.8182\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 861/1000] Train Loss: 0.6884  |  Val Loss: 0.8287\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 862/1000] Train Loss: 0.6947  |  Val Loss: 0.8316\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 863/1000] Train Loss: 0.6595  |  Val Loss: 0.7950\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 864/1000] Train Loss: 0.6575  |  Val Loss: 0.8143\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 865/1000] Train Loss: 0.6688  |  Val Loss: 0.7999\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 866/1000] Train Loss: 0.6955  |  Val Loss: 0.7834\n",
      "Validation loss improved from 0.7903 to 0.7834.\n",
      "[Epoch 867/1000] Train Loss: 0.7068  |  Val Loss: 0.8309\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 868/1000] Train Loss: 0.6859  |  Val Loss: 0.7946\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 869/1000] Train Loss: 0.6757  |  Val Loss: 0.8229\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 870/1000] Train Loss: 0.6505  |  Val Loss: 0.8091\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 871/1000] Train Loss: 0.7045  |  Val Loss: 0.8815\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 872/1000] Train Loss: 0.7412  |  Val Loss: 0.8409\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 873/1000] Train Loss: 0.7032  |  Val Loss: 0.8161\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 874/1000] Train Loss: 0.6726  |  Val Loss: 0.8383\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 875/1000] Train Loss: 0.6810  |  Val Loss: 0.7627\n",
      "Validation loss improved from 0.7834 to 0.7627.\n",
      "[Epoch 876/1000] Train Loss: 0.6406  |  Val Loss: 0.8414\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 877/1000] Train Loss: 0.6658  |  Val Loss: 0.7717\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 878/1000] Train Loss: 0.6507  |  Val Loss: 0.8047\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 879/1000] Train Loss: 0.6985  |  Val Loss: 0.8181\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 880/1000] Train Loss: 0.7029  |  Val Loss: 0.8098\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 881/1000] Train Loss: 0.6718  |  Val Loss: 0.7879\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 882/1000] Train Loss: 0.6504  |  Val Loss: 0.8196\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 883/1000] Train Loss: 0.6662  |  Val Loss: 0.7766\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 884/1000] Train Loss: 0.6402  |  Val Loss: 0.7926\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 885/1000] Train Loss: 0.6458  |  Val Loss: 0.8594\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 886/1000] Train Loss: 0.6774  |  Val Loss: 0.7905\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 887/1000] Train Loss: 0.6488  |  Val Loss: 0.7683\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 888/1000] Train Loss: 0.6364  |  Val Loss: 0.7794\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 889/1000] Train Loss: 0.6480  |  Val Loss: 0.7740\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 890/1000] Train Loss: 0.6656  |  Val Loss: 0.7925\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 891/1000] Train Loss: 0.6859  |  Val Loss: 0.8007\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 892/1000] Train Loss: 0.6588  |  Val Loss: 0.7597\n",
      "Validation loss improved from 0.7627 to 0.7597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 893/1000] Train Loss: 0.6270  |  Val Loss: 0.7580\n",
      "Validation loss improved from 0.7597 to 0.7580.\n",
      "[Epoch 894/1000] Train Loss: 0.6440  |  Val Loss: 0.9195\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 895/1000] Train Loss: 0.7051  |  Val Loss: 0.7528\n",
      "Validation loss improved from 0.7580 to 0.7528.\n",
      "[Epoch 896/1000] Train Loss: 0.6433  |  Val Loss: 0.7575\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 897/1000] Train Loss: 0.6468  |  Val Loss: 0.9208\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 898/1000] Train Loss: 0.7043  |  Val Loss: 0.7862\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 899/1000] Train Loss: 0.6496  |  Val Loss: 0.8026\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 900/1000] Train Loss: 0.6506  |  Val Loss: 0.8172\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 901/1000] Train Loss: 0.6539  |  Val Loss: 0.7904\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 902/1000] Train Loss: 0.6436  |  Val Loss: 0.8135\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 903/1000] Train Loss: 0.6702  |  Val Loss: 0.7502\n",
      "Validation loss improved from 0.7528 to 0.7502.\n",
      "[Epoch 904/1000] Train Loss: 0.6238  |  Val Loss: 0.7678\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 905/1000] Train Loss: 0.6343  |  Val Loss: 0.8051\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 906/1000] Train Loss: 0.6469  |  Val Loss: 0.8133\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 907/1000] Train Loss: 0.6817  |  Val Loss: 0.8724\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 908/1000] Train Loss: 0.6760  |  Val Loss: 0.7963\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 909/1000] Train Loss: 0.6341  |  Val Loss: 0.7454\n",
      "Validation loss improved from 0.7502 to 0.7454.\n",
      "[Epoch 910/1000] Train Loss: 0.6352  |  Val Loss: 0.7593\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 911/1000] Train Loss: 0.6312  |  Val Loss: 0.7597\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 912/1000] Train Loss: 0.6420  |  Val Loss: 0.7638\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 913/1000] Train Loss: 0.6789  |  Val Loss: 0.7518\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 914/1000] Train Loss: 0.6347  |  Val Loss: 0.7846\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 915/1000] Train Loss: 0.6507  |  Val Loss: 0.8087\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 916/1000] Train Loss: 0.6418  |  Val Loss: 0.7762\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 917/1000] Train Loss: 0.6175  |  Val Loss: 0.7676\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 918/1000] Train Loss: 0.6172  |  Val Loss: 0.7450\n",
      "Validation loss improved from 0.7454 to 0.7450.\n",
      "[Epoch 919/1000] Train Loss: 0.6437  |  Val Loss: 0.7594\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 920/1000] Train Loss: 0.6113  |  Val Loss: 0.7857\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 921/1000] Train Loss: 0.6589  |  Val Loss: 0.9032\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 922/1000] Train Loss: 0.7275  |  Val Loss: 0.7369\n",
      "Validation loss improved from 0.7450 to 0.7369.\n",
      "[Epoch 923/1000] Train Loss: 0.7128  |  Val Loss: 0.8450\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 924/1000] Train Loss: 0.6932  |  Val Loss: 0.8940\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 925/1000] Train Loss: 0.7192  |  Val Loss: 0.7557\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 926/1000] Train Loss: 0.7034  |  Val Loss: 0.8662\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 927/1000] Train Loss: 0.7385  |  Val Loss: 1.0005\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 928/1000] Train Loss: 0.7688  |  Val Loss: 0.7553\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 929/1000] Train Loss: 0.7068  |  Val Loss: 0.8623\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 930/1000] Train Loss: 0.7111  |  Val Loss: 0.9004\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 931/1000] Train Loss: 0.6744  |  Val Loss: 0.8607\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 932/1000] Train Loss: 0.6695  |  Val Loss: 0.9028\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 933/1000] Train Loss: 0.6698  |  Val Loss: 0.7458\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 934/1000] Train Loss: 0.5988  |  Val Loss: 0.7605\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 935/1000] Train Loss: 0.6013  |  Val Loss: 0.7399\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 936/1000] Train Loss: 0.6000  |  Val Loss: 0.7581\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 937/1000] Train Loss: 0.6090  |  Val Loss: 0.7441\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 938/1000] Train Loss: 0.6014  |  Val Loss: 0.7510\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 939/1000] Train Loss: 0.6007  |  Val Loss: 0.7234\n",
      "Validation loss improved from 0.7369 to 0.7234.\n",
      "[Epoch 940/1000] Train Loss: 0.6020  |  Val Loss: 0.7996\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 941/1000] Train Loss: 0.6115  |  Val Loss: 0.7513\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 942/1000] Train Loss: 0.6158  |  Val Loss: 0.7379\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 943/1000] Train Loss: 0.6021  |  Val Loss: 0.7416\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 944/1000] Train Loss: 0.5924  |  Val Loss: 0.7618\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 945/1000] Train Loss: 0.5974  |  Val Loss: 0.7474\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 946/1000] Train Loss: 0.5868  |  Val Loss: 0.7437\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 947/1000] Train Loss: 0.5810  |  Val Loss: 0.7338\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 948/1000] Train Loss: 0.5910  |  Val Loss: 0.7384\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 949/1000] Train Loss: 0.5986  |  Val Loss: 0.7675\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 950/1000] Train Loss: 0.6109  |  Val Loss: 0.8281\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 951/1000] Train Loss: 0.6571  |  Val Loss: 0.7464\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 952/1000] Train Loss: 0.6077  |  Val Loss: 0.7309\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 953/1000] Train Loss: 0.6289  |  Val Loss: 0.7208\n",
      "Validation loss improved from 0.7234 to 0.7208.\n",
      "[Epoch 954/1000] Train Loss: 0.6249  |  Val Loss: 0.7462\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 955/1000] Train Loss: 0.6167  |  Val Loss: 0.7628\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 956/1000] Train Loss: 0.6068  |  Val Loss: 0.7199\n",
      "Validation loss improved from 0.7208 to 0.7199.\n",
      "[Epoch 957/1000] Train Loss: 0.5781  |  Val Loss: 0.7190\n",
      "Validation loss improved from 0.7199 to 0.7190.\n",
      "[Epoch 958/1000] Train Loss: 0.5788  |  Val Loss: 0.7431\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 959/1000] Train Loss: 0.6142  |  Val Loss: 0.7453\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 960/1000] Train Loss: 0.6713  |  Val Loss: 1.0412\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 961/1000] Train Loss: 0.8185  |  Val Loss: 1.0006\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 962/1000] Train Loss: 0.8391  |  Val Loss: 0.7750\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 963/1000] Train Loss: 0.6760  |  Val Loss: 0.8408\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 964/1000] Train Loss: 0.6423  |  Val Loss: 0.7450\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 965/1000] Train Loss: 0.5963  |  Val Loss: 0.7475\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 966/1000] Train Loss: 0.5890  |  Val Loss: 0.7348\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 967/1000] Train Loss: 0.5877  |  Val Loss: 0.7186\n",
      "Validation loss improved from 0.7190 to 0.7186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 968/1000] Train Loss: 0.5901  |  Val Loss: 0.7282\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 969/1000] Train Loss: 0.6036  |  Val Loss: 0.7363\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 970/1000] Train Loss: 0.6032  |  Val Loss: 0.9551\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 971/1000] Train Loss: 0.7007  |  Val Loss: 0.8529\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 972/1000] Train Loss: 0.6962  |  Val Loss: 0.7400\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 973/1000] Train Loss: 0.6687  |  Val Loss: 0.7401\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 974/1000] Train Loss: 0.6019  |  Val Loss: 0.7157\n",
      "Validation loss improved from 0.7186 to 0.7157.\n",
      "[Epoch 975/1000] Train Loss: 0.5720  |  Val Loss: 0.7364\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 976/1000] Train Loss: 0.5726  |  Val Loss: 0.7061\n",
      "Validation loss improved from 0.7157 to 0.7061.\n",
      "[Epoch 977/1000] Train Loss: 0.5716  |  Val Loss: 0.7340\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 978/1000] Train Loss: 0.5800  |  Val Loss: 0.7153\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 979/1000] Train Loss: 0.6007  |  Val Loss: 0.7778\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 980/1000] Train Loss: 0.6173  |  Val Loss: 0.7735\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 981/1000] Train Loss: 0.6072  |  Val Loss: 0.8469\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 982/1000] Train Loss: 0.6225  |  Val Loss: 0.7198\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 983/1000] Train Loss: 0.5632  |  Val Loss: 0.7234\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 984/1000] Train Loss: 0.5706  |  Val Loss: 0.7536\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 985/1000] Train Loss: 0.5703  |  Val Loss: 0.7222\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 986/1000] Train Loss: 0.5749  |  Val Loss: 0.7139\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 987/1000] Train Loss: 0.5878  |  Val Loss: 0.7839\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 988/1000] Train Loss: 0.6235  |  Val Loss: 0.7789\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 989/1000] Train Loss: 0.6647  |  Val Loss: 0.7454\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 990/1000] Train Loss: 0.6037  |  Val Loss: 0.7740\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 991/1000] Train Loss: 0.6211  |  Val Loss: 0.7655\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 992/1000] Train Loss: 0.5866  |  Val Loss: 0.8817\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 993/1000] Train Loss: 0.6587  |  Val Loss: 0.7546\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 994/1000] Train Loss: 0.6079  |  Val Loss: 0.8091\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 995/1000] Train Loss: 0.6074  |  Val Loss: 0.7214\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 996/1000] Train Loss: 0.6174  |  Val Loss: 0.7337\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 997/1000] Train Loss: 0.5849  |  Val Loss: 0.7388\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 998/1000] Train Loss: 0.5939  |  Val Loss: 0.7589\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 999/1000] Train Loss: 0.6106  |  Val Loss: 0.7872\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 1000/1000] Train Loss: 0.6557  |  Val Loss: 0.9962\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:47.491238Z",
     "iopub.status.busy": "2025-05-08T18:54:47.490238Z",
     "iopub.status.idle": "2025-05-08T18:54:47.636355Z",
     "shell.execute_reply": "2025-05-08T18:54:47.636355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 1.0847 | Test Accuracy: 51.55%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:47.638587Z",
     "iopub.status.busy": "2025-05-08T18:54:47.638587Z",
     "iopub.status.idle": "2025-05-08T18:54:47.648353Z",
     "shell.execute_reply": "2025-05-08T18:54:47.648353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:47.650358Z",
     "iopub.status.busy": "2025-05-08T18:54:47.650358Z",
     "iopub.status.idle": "2025-05-08T18:54:47.661000Z",
     "shell.execute_reply": "2025-05-08T18:54:47.661000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:47.664518Z",
     "iopub.status.busy": "2025-05-08T18:54:47.663510Z",
     "iopub.status.idle": "2025-05-08T18:54:47.668618Z",
     "shell.execute_reply": "2025-05-08T18:54:47.668618Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:47.671625Z",
     "iopub.status.busy": "2025-05-08T18:54:47.670627Z",
     "iopub.status.idle": "2025-05-08T18:54:47.674630Z",
     "shell.execute_reply": "2025-05-08T18:54:47.674630Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:47.677634Z",
     "iopub.status.busy": "2025-05-08T18:54:47.677634Z",
     "iopub.status.idle": "2025-05-08T18:54:56.774595Z",
     "shell.execute_reply": "2025-05-08T18:54:56.774595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 7.8957\n",
      "Epoch [1/2000], Avg Train Loss: 7.8957\n",
      "Epoch [1/2000], Avg Val Loss: 3.5429\n",
      "Validation loss improved from inf to 3.5429. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8991\n",
      "Epoch [2/2000], Avg Train Loss: 7.8991\n",
      "Epoch [2/2000], Avg Val Loss: 3.5241\n",
      "Validation loss improved from 3.5429 to 3.5241. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7766\n",
      "Epoch [3/2000], Avg Train Loss: 7.7766\n",
      "Epoch [3/2000], Avg Val Loss: 3.5064\n",
      "Validation loss improved from 3.5241 to 3.5064. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7232\n",
      "Epoch [4/2000], Avg Train Loss: 7.7232\n",
      "Epoch [4/2000], Avg Val Loss: 3.4897\n",
      "Validation loss improved from 3.5064 to 3.4897. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6407\n",
      "Epoch [5/2000], Avg Train Loss: 7.6407\n",
      "Epoch [5/2000], Avg Val Loss: 3.4737\n",
      "Validation loss improved from 3.4897 to 3.4737. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3645\n",
      "Epoch [6/2000], Avg Train Loss: 7.3645\n",
      "Epoch [6/2000], Avg Val Loss: 3.4586\n",
      "Validation loss improved from 3.4737 to 3.4586. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3010\n",
      "Epoch [7/2000], Avg Train Loss: 7.3010\n",
      "Epoch [7/2000], Avg Val Loss: 3.4442\n",
      "Validation loss improved from 3.4586 to 3.4442. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3835\n",
      "Epoch [8/2000], Avg Train Loss: 7.3835\n",
      "Epoch [8/2000], Avg Val Loss: 3.4306\n",
      "Validation loss improved from 3.4442 to 3.4306. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2243\n",
      "Epoch [9/2000], Avg Train Loss: 7.2243\n",
      "Epoch [9/2000], Avg Val Loss: 3.4179\n",
      "Validation loss improved from 3.4306 to 3.4179. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2213\n",
      "Epoch [10/2000], Avg Train Loss: 7.2213\n",
      "Epoch [10/2000], Avg Val Loss: 3.4058\n",
      "Validation loss improved from 3.4179 to 3.4058. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1276\n",
      "Epoch [11/2000], Avg Train Loss: 7.1276\n",
      "Epoch [11/2000], Avg Val Loss: 3.3944\n",
      "Validation loss improved from 3.4058 to 3.3944. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1367\n",
      "Epoch [12/2000], Avg Train Loss: 7.1367\n",
      "Epoch [12/2000], Avg Val Loss: 3.3836\n",
      "Validation loss improved from 3.3944 to 3.3836. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1319\n",
      "Epoch [13/2000], Avg Train Loss: 7.1319\n",
      "Epoch [13/2000], Avg Val Loss: 3.3734\n",
      "Validation loss improved from 3.3836 to 3.3734. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9450\n",
      "Epoch [14/2000], Avg Train Loss: 6.9450\n",
      "Epoch [14/2000], Avg Val Loss: 3.3637\n",
      "Validation loss improved from 3.3734 to 3.3637. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.7492\n",
      "Epoch [15/2000], Avg Train Loss: 6.7492\n",
      "Epoch [15/2000], Avg Val Loss: 3.3547\n",
      "Validation loss improved from 3.3637 to 3.3547. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8512\n",
      "Epoch [16/2000], Avg Train Loss: 6.8512\n",
      "Epoch [16/2000], Avg Val Loss: 3.3462\n",
      "Validation loss improved from 3.3547 to 3.3462. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8116\n",
      "Epoch [17/2000], Avg Train Loss: 6.8116\n",
      "Epoch [17/2000], Avg Val Loss: 3.3382\n",
      "Validation loss improved from 3.3462 to 3.3382. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8136\n",
      "Epoch [18/2000], Avg Train Loss: 6.8136\n",
      "Epoch [18/2000], Avg Val Loss: 3.3307\n",
      "Validation loss improved from 3.3382 to 3.3307. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6651\n",
      "Epoch [19/2000], Avg Train Loss: 6.6651\n",
      "Epoch [19/2000], Avg Val Loss: 3.3237\n",
      "Validation loss improved from 3.3307 to 3.3237. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7000\n",
      "Epoch [20/2000], Avg Train Loss: 6.7000\n",
      "Epoch [20/2000], Avg Val Loss: 3.3172\n",
      "Validation loss improved from 3.3237 to 3.3172. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5727\n",
      "Epoch [21/2000], Avg Train Loss: 6.5727\n",
      "Epoch [21/2000], Avg Val Loss: 3.3111\n",
      "Validation loss improved from 3.3172 to 3.3111. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3937\n",
      "Epoch [22/2000], Avg Train Loss: 6.3937\n",
      "Epoch [22/2000], Avg Val Loss: 3.3054\n",
      "Validation loss improved from 3.3111 to 3.3054. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.5512\n",
      "Epoch [23/2000], Avg Train Loss: 6.5512\n",
      "Epoch [23/2000], Avg Val Loss: 3.3001\n",
      "Validation loss improved from 3.3054 to 3.3001. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4327\n",
      "Epoch [24/2000], Avg Train Loss: 6.4327\n",
      "Epoch [24/2000], Avg Val Loss: 3.2951\n",
      "Validation loss improved from 3.3001 to 3.2951. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3152\n",
      "Epoch [25/2000], Avg Train Loss: 6.3152\n",
      "Epoch [25/2000], Avg Val Loss: 3.2904\n",
      "Validation loss improved from 3.2951 to 3.2904. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1603\n",
      "Epoch [26/2000], Avg Train Loss: 6.1603\n",
      "Epoch [26/2000], Avg Val Loss: 3.2859\n",
      "Validation loss improved from 3.2904 to 3.2859. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1787\n",
      "Epoch [27/2000], Avg Train Loss: 6.1787\n",
      "Epoch [27/2000], Avg Val Loss: 3.2818\n",
      "Validation loss improved from 3.2859 to 3.2818. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1771\n",
      "Epoch [28/2000], Avg Train Loss: 6.1771\n",
      "Epoch [28/2000], Avg Val Loss: 3.2779\n",
      "Validation loss improved from 3.2818 to 3.2779. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2168\n",
      "Epoch [29/2000], Avg Train Loss: 6.2168\n",
      "Epoch [29/2000], Avg Val Loss: 3.2743\n",
      "Validation loss improved from 3.2779 to 3.2743. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0107\n",
      "Epoch [30/2000], Avg Train Loss: 6.0107\n",
      "Epoch [30/2000], Avg Val Loss: 3.2708\n",
      "Validation loss improved from 3.2743 to 3.2708. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0547\n",
      "Epoch [31/2000], Avg Train Loss: 6.0547\n",
      "Epoch [31/2000], Avg Val Loss: 3.2677\n",
      "Validation loss improved from 3.2708 to 3.2677. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0301\n",
      "Epoch [32/2000], Avg Train Loss: 6.0301\n",
      "Epoch [32/2000], Avg Val Loss: 3.2648\n",
      "Validation loss improved from 3.2677 to 3.2648. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0309\n",
      "Epoch [33/2000], Avg Train Loss: 6.0309\n",
      "Epoch [33/2000], Avg Val Loss: 3.2620\n",
      "Validation loss improved from 3.2648 to 3.2620. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9465\n",
      "Epoch [34/2000], Avg Train Loss: 5.9465\n",
      "Epoch [34/2000], Avg Val Loss: 3.2596\n",
      "Validation loss improved from 3.2620 to 3.2596. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.0226\n",
      "Epoch [35/2000], Avg Train Loss: 6.0226\n",
      "Epoch [35/2000], Avg Val Loss: 3.2572\n",
      "Validation loss improved from 3.2596 to 3.2572. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8717\n",
      "Epoch [36/2000], Avg Train Loss: 5.8717\n",
      "Epoch [36/2000], Avg Val Loss: 3.2551\n",
      "Validation loss improved from 3.2572 to 3.2551. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8391\n",
      "Epoch [37/2000], Avg Train Loss: 5.8391\n",
      "Epoch [37/2000], Avg Val Loss: 3.2530\n",
      "Validation loss improved from 3.2551 to 3.2530. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7873\n",
      "Epoch [38/2000], Avg Train Loss: 5.7873\n",
      "Epoch [38/2000], Avg Val Loss: 3.2512\n",
      "Validation loss improved from 3.2530 to 3.2512. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8741\n",
      "Epoch [39/2000], Avg Train Loss: 5.8741\n",
      "Epoch [39/2000], Avg Val Loss: 3.2495\n",
      "Validation loss improved from 3.2512 to 3.2495. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8523\n",
      "Epoch [40/2000], Avg Train Loss: 5.8523\n",
      "Epoch [40/2000], Avg Val Loss: 3.2478\n",
      "Validation loss improved from 3.2495 to 3.2478. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8089\n",
      "Epoch [41/2000], Avg Train Loss: 5.8089\n",
      "Epoch [41/2000], Avg Val Loss: 3.2463\n",
      "Validation loss improved from 3.2478 to 3.2463. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7499\n",
      "Epoch [42/2000], Avg Train Loss: 5.7499\n",
      "Epoch [42/2000], Avg Val Loss: 3.2448\n",
      "Validation loss improved from 3.2463 to 3.2448. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7415\n",
      "Epoch [43/2000], Avg Train Loss: 5.7415\n",
      "Epoch [43/2000], Avg Val Loss: 3.2435\n",
      "Validation loss improved from 3.2448 to 3.2435. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6982\n",
      "Epoch [44/2000], Avg Train Loss: 5.6982\n",
      "Epoch [44/2000], Avg Val Loss: 3.2422\n",
      "Validation loss improved from 3.2435 to 3.2422. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6853\n",
      "Epoch [45/2000], Avg Train Loss: 5.6853\n",
      "Epoch [45/2000], Avg Val Loss: 3.2410\n",
      "Validation loss improved from 3.2422 to 3.2410. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6090\n",
      "Epoch [46/2000], Avg Train Loss: 5.6090\n",
      "Epoch [46/2000], Avg Val Loss: 3.2399\n",
      "Validation loss improved from 3.2410 to 3.2399. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6227\n",
      "Epoch [47/2000], Avg Train Loss: 5.6227\n",
      "Epoch [47/2000], Avg Val Loss: 3.2388\n",
      "Validation loss improved from 3.2399 to 3.2388. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5791\n",
      "Epoch [48/2000], Avg Train Loss: 5.5791\n",
      "Epoch [48/2000], Avg Val Loss: 3.2377\n",
      "Validation loss improved from 3.2388 to 3.2377. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5652\n",
      "Epoch [49/2000], Avg Train Loss: 5.5652\n",
      "Epoch [49/2000], Avg Val Loss: 3.2367\n",
      "Validation loss improved from 3.2377 to 3.2367. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.5172\n",
      "Epoch [50/2000], Avg Train Loss: 5.5172\n",
      "Epoch [50/2000], Avg Val Loss: 3.2357\n",
      "Validation loss improved from 3.2367 to 3.2357. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5500\n",
      "Epoch [51/2000], Avg Train Loss: 5.5500\n",
      "Epoch [51/2000], Avg Val Loss: 3.2348\n",
      "Validation loss improved from 3.2357 to 3.2348. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5944\n",
      "Epoch [52/2000], Avg Train Loss: 5.5944\n",
      "Epoch [52/2000], Avg Val Loss: 3.2339\n",
      "Validation loss improved from 3.2348 to 3.2339. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5261\n",
      "Epoch [53/2000], Avg Train Loss: 5.5261\n",
      "Epoch [53/2000], Avg Val Loss: 3.2329\n",
      "Validation loss improved from 3.2339 to 3.2329. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5109\n",
      "Epoch [54/2000], Avg Train Loss: 5.5109\n",
      "Epoch [54/2000], Avg Val Loss: 3.2321\n",
      "Validation loss improved from 3.2329 to 3.2321. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.4713\n",
      "Epoch [55/2000], Avg Train Loss: 5.4713\n",
      "Epoch [55/2000], Avg Val Loss: 3.2312\n",
      "Validation loss improved from 3.2321 to 3.2312. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4563\n",
      "Epoch [56/2000], Avg Train Loss: 5.4563\n",
      "Epoch [56/2000], Avg Val Loss: 3.2303\n",
      "Validation loss improved from 3.2312 to 3.2303. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3732\n",
      "Epoch [57/2000], Avg Train Loss: 5.3732\n",
      "Epoch [57/2000], Avg Val Loss: 3.2293\n",
      "Validation loss improved from 3.2303 to 3.2293. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4272\n",
      "Epoch [58/2000], Avg Train Loss: 5.4272\n",
      "Epoch [58/2000], Avg Val Loss: 3.2284\n",
      "Validation loss improved from 3.2293 to 3.2284. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3383\n",
      "Epoch [59/2000], Avg Train Loss: 5.3383\n",
      "Epoch [59/2000], Avg Val Loss: 3.2275\n",
      "Validation loss improved from 3.2284 to 3.2275. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3363\n",
      "Epoch [60/2000], Avg Train Loss: 5.3363\n",
      "Epoch [60/2000], Avg Val Loss: 3.2266\n",
      "Validation loss improved from 3.2275 to 3.2266. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3963\n",
      "Epoch [61/2000], Avg Train Loss: 5.3963\n",
      "Epoch [61/2000], Avg Val Loss: 3.2256\n",
      "Validation loss improved from 3.2266 to 3.2256. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3917\n",
      "Epoch [62/2000], Avg Train Loss: 5.3917\n",
      "Epoch [62/2000], Avg Val Loss: 3.2247\n",
      "Validation loss improved from 3.2256 to 3.2247. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3776\n",
      "Epoch [63/2000], Avg Train Loss: 5.3776\n",
      "Epoch [63/2000], Avg Val Loss: 3.2237\n",
      "Validation loss improved from 3.2247 to 3.2237. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3429\n",
      "Epoch [64/2000], Avg Train Loss: 5.3429\n",
      "Epoch [64/2000], Avg Val Loss: 3.2227\n",
      "Validation loss improved from 3.2237 to 3.2227. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3180\n",
      "Epoch [65/2000], Avg Train Loss: 5.3180\n",
      "Epoch [65/2000], Avg Val Loss: 3.2217\n",
      "Validation loss improved from 3.2227 to 3.2217. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3314\n",
      "Epoch [66/2000], Avg Train Loss: 5.3314\n",
      "Epoch [66/2000], Avg Val Loss: 3.2207\n",
      "Validation loss improved from 3.2217 to 3.2207. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3199\n",
      "Epoch [67/2000], Avg Train Loss: 5.3199\n",
      "Epoch [67/2000], Avg Val Loss: 3.2197\n",
      "Validation loss improved from 3.2207 to 3.2197. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2810\n",
      "Epoch [68/2000], Avg Train Loss: 5.2810\n",
      "Epoch [68/2000], Avg Val Loss: 3.2187\n",
      "Validation loss improved from 3.2197 to 3.2187. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3063\n",
      "Epoch [69/2000], Avg Train Loss: 5.3063\n",
      "Epoch [69/2000], Avg Val Loss: 3.2177\n",
      "Validation loss improved from 3.2187 to 3.2177. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2829\n",
      "Epoch [70/2000], Avg Train Loss: 5.2829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/2000], Avg Val Loss: 3.2168\n",
      "Validation loss improved from 3.2177 to 3.2168. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2029\n",
      "Epoch [71/2000], Avg Train Loss: 5.2029\n",
      "Epoch [71/2000], Avg Val Loss: 3.2157\n",
      "Validation loss improved from 3.2168 to 3.2157. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2639\n",
      "Epoch [72/2000], Avg Train Loss: 5.2639\n",
      "Epoch [72/2000], Avg Val Loss: 3.2147\n",
      "Validation loss improved from 3.2157 to 3.2147. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2040\n",
      "Epoch [73/2000], Avg Train Loss: 5.2040\n",
      "Epoch [73/2000], Avg Val Loss: 3.2137\n",
      "Validation loss improved from 3.2147 to 3.2137. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2035\n",
      "Epoch [74/2000], Avg Train Loss: 5.2035\n",
      "Epoch [74/2000], Avg Val Loss: 3.2126\n",
      "Validation loss improved from 3.2137 to 3.2126. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2179\n",
      "Epoch [75/2000], Avg Train Loss: 5.2179\n",
      "Epoch [75/2000], Avg Val Loss: 3.2115\n",
      "Validation loss improved from 3.2126 to 3.2115. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2513\n",
      "Epoch [76/2000], Avg Train Loss: 5.2513\n",
      "Epoch [76/2000], Avg Val Loss: 3.2105\n",
      "Validation loss improved from 3.2115 to 3.2105. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1708\n",
      "Epoch [77/2000], Avg Train Loss: 5.1708\n",
      "Epoch [77/2000], Avg Val Loss: 3.2094\n",
      "Validation loss improved from 3.2105 to 3.2094. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2118\n",
      "Epoch [78/2000], Avg Train Loss: 5.2118\n",
      "Epoch [78/2000], Avg Val Loss: 3.2084\n",
      "Validation loss improved from 3.2094 to 3.2084. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1840\n",
      "Epoch [79/2000], Avg Train Loss: 5.1840\n",
      "Epoch [79/2000], Avg Val Loss: 3.2072\n",
      "Validation loss improved from 3.2084 to 3.2072. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2061\n",
      "Epoch [80/2000], Avg Train Loss: 5.2061\n",
      "Epoch [80/2000], Avg Val Loss: 3.2061\n",
      "Validation loss improved from 3.2072 to 3.2061. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1858\n",
      "Epoch [81/2000], Avg Train Loss: 5.1858\n",
      "Epoch [81/2000], Avg Val Loss: 3.2050\n",
      "Validation loss improved from 3.2061 to 3.2050. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0900\n",
      "Epoch [82/2000], Avg Train Loss: 5.0900\n",
      "Epoch [82/2000], Avg Val Loss: 3.2039\n",
      "Validation loss improved from 3.2050 to 3.2039. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1644\n",
      "Epoch [83/2000], Avg Train Loss: 5.1644\n",
      "Epoch [83/2000], Avg Val Loss: 3.2027\n",
      "Validation loss improved from 3.2039 to 3.2027. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1425\n",
      "Epoch [84/2000], Avg Train Loss: 5.1425\n",
      "Epoch [84/2000], Avg Val Loss: 3.2015\n",
      "Validation loss improved from 3.2027 to 3.2015. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1447\n",
      "Epoch [85/2000], Avg Train Loss: 5.1447\n",
      "Epoch [85/2000], Avg Val Loss: 3.2004\n",
      "Validation loss improved from 3.2015 to 3.2004. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0895\n",
      "Epoch [86/2000], Avg Train Loss: 5.0895\n",
      "Epoch [86/2000], Avg Val Loss: 3.1992\n",
      "Validation loss improved from 3.2004 to 3.1992. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1328\n",
      "Epoch [87/2000], Avg Train Loss: 5.1328\n",
      "Epoch [87/2000], Avg Val Loss: 3.1980\n",
      "Validation loss improved from 3.1992 to 3.1980. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1493\n",
      "Epoch [88/2000], Avg Train Loss: 5.1493\n",
      "Epoch [88/2000], Avg Val Loss: 3.1968\n",
      "Validation loss improved from 3.1980 to 3.1968. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1241\n",
      "Epoch [89/2000], Avg Train Loss: 5.1241\n",
      "Epoch [89/2000], Avg Val Loss: 3.1956\n",
      "Validation loss improved from 3.1968 to 3.1956. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0958\n",
      "Epoch [90/2000], Avg Train Loss: 5.0958\n",
      "Epoch [90/2000], Avg Val Loss: 3.1944\n",
      "Validation loss improved from 3.1956 to 3.1944. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1714\n",
      "Epoch [91/2000], Avg Train Loss: 5.1714\n",
      "Epoch [91/2000], Avg Val Loss: 3.1932\n",
      "Validation loss improved from 3.1944 to 3.1932. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1471\n",
      "Epoch [92/2000], Avg Train Loss: 5.1471\n",
      "Epoch [92/2000], Avg Val Loss: 3.1920\n",
      "Validation loss improved from 3.1932 to 3.1920. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1245\n",
      "Epoch [93/2000], Avg Train Loss: 5.1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/2000], Avg Val Loss: 3.1908\n",
      "Validation loss improved from 3.1920 to 3.1908. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0900\n",
      "Epoch [94/2000], Avg Train Loss: 5.0900\n",
      "Epoch [94/2000], Avg Val Loss: 3.1897\n",
      "Validation loss improved from 3.1908 to 3.1897. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0676\n",
      "Epoch [95/2000], Avg Train Loss: 5.0676\n",
      "Epoch [95/2000], Avg Val Loss: 3.1885\n",
      "Validation loss improved from 3.1897 to 3.1885. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1352\n",
      "Epoch [96/2000], Avg Train Loss: 5.1352\n",
      "Epoch [96/2000], Avg Val Loss: 3.1873\n",
      "Validation loss improved from 3.1885 to 3.1873. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0670\n",
      "Epoch [97/2000], Avg Train Loss: 5.0670\n",
      "Epoch [97/2000], Avg Val Loss: 3.1861\n",
      "Validation loss improved from 3.1873 to 3.1861. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0479\n",
      "Epoch [98/2000], Avg Train Loss: 5.0479\n",
      "Epoch [98/2000], Avg Val Loss: 3.1848\n",
      "Validation loss improved from 3.1861 to 3.1848. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0022\n",
      "Epoch [99/2000], Avg Train Loss: 5.0022\n",
      "Epoch [99/2000], Avg Val Loss: 3.1836\n",
      "Validation loss improved from 3.1848 to 3.1836. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0628\n",
      "Epoch [100/2000], Avg Train Loss: 5.0628\n",
      "Epoch [100/2000], Avg Val Loss: 3.1823\n",
      "Validation loss improved from 3.1836 to 3.1823. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0932\n",
      "Epoch [101/2000], Avg Train Loss: 5.0932\n",
      "Epoch [101/2000], Avg Val Loss: 3.1810\n",
      "Validation loss improved from 3.1823 to 3.1810. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0357\n",
      "Epoch [102/2000], Avg Train Loss: 5.0357\n",
      "Epoch [102/2000], Avg Val Loss: 3.1797\n",
      "Validation loss improved from 3.1810 to 3.1797. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0567\n",
      "Epoch [103/2000], Avg Train Loss: 5.0567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/2000], Avg Val Loss: 3.1785\n",
      "Validation loss improved from 3.1797 to 3.1785. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0304\n",
      "Epoch [104/2000], Avg Train Loss: 5.0304\n",
      "Epoch [104/2000], Avg Val Loss: 3.1772\n",
      "Validation loss improved from 3.1785 to 3.1772. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0542\n",
      "Epoch [105/2000], Avg Train Loss: 5.0542\n",
      "Epoch [105/2000], Avg Val Loss: 3.1760\n",
      "Validation loss improved from 3.1772 to 3.1760. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0352\n",
      "Epoch [106/2000], Avg Train Loss: 5.0352\n",
      "Epoch [106/2000], Avg Val Loss: 3.1747\n",
      "Validation loss improved from 3.1760 to 3.1747. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0499\n",
      "Epoch [107/2000], Avg Train Loss: 5.0499\n",
      "Epoch [107/2000], Avg Val Loss: 3.1734\n",
      "Validation loss improved from 3.1747 to 3.1734. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0141\n",
      "Epoch [108/2000], Avg Train Loss: 5.0141\n",
      "Epoch [108/2000], Avg Val Loss: 3.1720\n",
      "Validation loss improved from 3.1734 to 3.1720. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9787\n",
      "Epoch [109/2000], Avg Train Loss: 4.9787\n",
      "Epoch [109/2000], Avg Val Loss: 3.1707\n",
      "Validation loss improved from 3.1720 to 3.1707. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9740\n",
      "Epoch [110/2000], Avg Train Loss: 4.9740\n",
      "Epoch [110/2000], Avg Val Loss: 3.1693\n",
      "Validation loss improved from 3.1707 to 3.1693. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0217\n",
      "Epoch [111/2000], Avg Train Loss: 5.0217\n",
      "Epoch [111/2000], Avg Val Loss: 3.1679\n",
      "Validation loss improved from 3.1693 to 3.1679. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0199\n",
      "Epoch [112/2000], Avg Train Loss: 5.0199\n",
      "Epoch [112/2000], Avg Val Loss: 3.1666\n",
      "Validation loss improved from 3.1679 to 3.1666. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9975\n",
      "Epoch [113/2000], Avg Train Loss: 4.9975\n",
      "Epoch [113/2000], Avg Val Loss: 3.1652\n",
      "Validation loss improved from 3.1666 to 3.1652. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9485\n",
      "Epoch [114/2000], Avg Train Loss: 4.9485\n",
      "Epoch [114/2000], Avg Val Loss: 3.1638\n",
      "Validation loss improved from 3.1652 to 3.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0404\n",
      "Epoch [115/2000], Avg Train Loss: 5.0404\n",
      "Epoch [115/2000], Avg Val Loss: 3.1624\n",
      "Validation loss improved from 3.1638 to 3.1624. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9796\n",
      "Epoch [116/2000], Avg Train Loss: 4.9796\n",
      "Epoch [116/2000], Avg Val Loss: 3.1611\n",
      "Validation loss improved from 3.1624 to 3.1611. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9572\n",
      "Epoch [117/2000], Avg Train Loss: 4.9572\n",
      "Epoch [117/2000], Avg Val Loss: 3.1596\n",
      "Validation loss improved from 3.1611 to 3.1596. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9690\n",
      "Epoch [118/2000], Avg Train Loss: 4.9690\n",
      "Epoch [118/2000], Avg Val Loss: 3.1582\n",
      "Validation loss improved from 3.1596 to 3.1582. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9488\n",
      "Epoch [119/2000], Avg Train Loss: 4.9488\n",
      "Epoch [119/2000], Avg Val Loss: 3.1567\n",
      "Validation loss improved from 3.1582 to 3.1567. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.9766\n",
      "Epoch [120/2000], Avg Train Loss: 4.9766\n",
      "Epoch [120/2000], Avg Val Loss: 3.1553\n",
      "Validation loss improved from 3.1567 to 3.1553. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9599\n",
      "Epoch [121/2000], Avg Train Loss: 4.9599\n",
      "Epoch [121/2000], Avg Val Loss: 3.1538\n",
      "Validation loss improved from 3.1553 to 3.1538. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9620\n",
      "Epoch [122/2000], Avg Train Loss: 4.9620\n",
      "Epoch [122/2000], Avg Val Loss: 3.1524\n",
      "Validation loss improved from 3.1538 to 3.1524. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9370\n",
      "Epoch [123/2000], Avg Train Loss: 4.9370\n",
      "Epoch [123/2000], Avg Val Loss: 3.1509\n",
      "Validation loss improved from 3.1524 to 3.1509. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9604\n",
      "Epoch [124/2000], Avg Train Loss: 4.9604\n",
      "Epoch [124/2000], Avg Val Loss: 3.1494\n",
      "Validation loss improved from 3.1509 to 3.1494. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9582\n",
      "Epoch [125/2000], Avg Train Loss: 4.9582\n",
      "Epoch [125/2000], Avg Val Loss: 3.1480\n",
      "Validation loss improved from 3.1494 to 3.1480. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9258\n",
      "Epoch [126/2000], Avg Train Loss: 4.9258\n",
      "Epoch [126/2000], Avg Val Loss: 3.1465\n",
      "Validation loss improved from 3.1480 to 3.1465. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9153\n",
      "Epoch [127/2000], Avg Train Loss: 4.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/2000], Avg Val Loss: 3.1450\n",
      "Validation loss improved from 3.1465 to 3.1450. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8964\n",
      "Epoch [128/2000], Avg Train Loss: 4.8964\n",
      "Epoch [128/2000], Avg Val Loss: 3.1435\n",
      "Validation loss improved from 3.1450 to 3.1435. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9123\n",
      "Epoch [129/2000], Avg Train Loss: 4.9123\n",
      "Epoch [129/2000], Avg Val Loss: 3.1420\n",
      "Validation loss improved from 3.1435 to 3.1420. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9317\n",
      "Epoch [130/2000], Avg Train Loss: 4.9317\n",
      "Epoch [130/2000], Avg Val Loss: 3.1405\n",
      "Validation loss improved from 3.1420 to 3.1405. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9343\n",
      "Epoch [131/2000], Avg Train Loss: 4.9343\n",
      "Epoch [131/2000], Avg Val Loss: 3.1391\n",
      "Validation loss improved from 3.1405 to 3.1391. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9024\n",
      "Epoch [132/2000], Avg Train Loss: 4.9024\n",
      "Epoch [132/2000], Avg Val Loss: 3.1377\n",
      "Validation loss improved from 3.1391 to 3.1377. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9244\n",
      "Epoch [133/2000], Avg Train Loss: 4.9244\n",
      "Epoch [133/2000], Avg Val Loss: 3.1362\n",
      "Validation loss improved from 3.1377 to 3.1362. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8888\n",
      "Epoch [134/2000], Avg Train Loss: 4.8888\n",
      "Epoch [134/2000], Avg Val Loss: 3.1348\n",
      "Validation loss improved from 3.1362 to 3.1348. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9332\n",
      "Epoch [135/2000], Avg Train Loss: 4.9332\n",
      "Epoch [135/2000], Avg Val Loss: 3.1334\n",
      "Validation loss improved from 3.1348 to 3.1334. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8506\n",
      "Epoch [136/2000], Avg Train Loss: 4.8506\n",
      "Epoch [136/2000], Avg Val Loss: 3.1319\n",
      "Validation loss improved from 3.1334 to 3.1319. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9231\n",
      "Epoch [137/2000], Avg Train Loss: 4.9231\n",
      "Epoch [137/2000], Avg Val Loss: 3.1305\n",
      "Validation loss improved from 3.1319 to 3.1305. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8497\n",
      "Epoch [138/2000], Avg Train Loss: 4.8497\n",
      "Epoch [138/2000], Avg Val Loss: 3.1290\n",
      "Validation loss improved from 3.1305 to 3.1290. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9307\n",
      "Epoch [139/2000], Avg Train Loss: 4.9307\n",
      "Epoch [139/2000], Avg Val Loss: 3.1276\n",
      "Validation loss improved from 3.1290 to 3.1276. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8709\n",
      "Epoch [140/2000], Avg Train Loss: 4.8709\n",
      "Epoch [140/2000], Avg Val Loss: 3.1261\n",
      "Validation loss improved from 3.1276 to 3.1261. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8583\n",
      "Epoch [141/2000], Avg Train Loss: 4.8583\n",
      "Epoch [141/2000], Avg Val Loss: 3.1246\n",
      "Validation loss improved from 3.1261 to 3.1246. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8859\n",
      "Epoch [142/2000], Avg Train Loss: 4.8859\n",
      "Epoch [142/2000], Avg Val Loss: 3.1231\n",
      "Validation loss improved from 3.1246 to 3.1231. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8931\n",
      "Epoch [143/2000], Avg Train Loss: 4.8931\n",
      "Epoch [143/2000], Avg Val Loss: 3.1216\n",
      "Validation loss improved from 3.1231 to 3.1216. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9013\n",
      "Epoch [144/2000], Avg Train Loss: 4.9013\n",
      "Epoch [144/2000], Avg Val Loss: 3.1200\n",
      "Validation loss improved from 3.1216 to 3.1200. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8806\n",
      "Epoch [145/2000], Avg Train Loss: 4.8806\n",
      "Epoch [145/2000], Avg Val Loss: 3.1185\n",
      "Validation loss improved from 3.1200 to 3.1185. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8537\n",
      "Epoch [146/2000], Avg Train Loss: 4.8537\n",
      "Epoch [146/2000], Avg Val Loss: 3.1170\n",
      "Validation loss improved from 3.1185 to 3.1170. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8456\n",
      "Epoch [147/2000], Avg Train Loss: 4.8456\n",
      "Epoch [147/2000], Avg Val Loss: 3.1155\n",
      "Validation loss improved from 3.1170 to 3.1155. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8668\n",
      "Epoch [148/2000], Avg Train Loss: 4.8668\n",
      "Epoch [148/2000], Avg Val Loss: 3.1140\n",
      "Validation loss improved from 3.1155 to 3.1140. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8630\n",
      "Epoch [149/2000], Avg Train Loss: 4.8630\n",
      "Epoch [149/2000], Avg Val Loss: 3.1125\n",
      "Validation loss improved from 3.1140 to 3.1125. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8172\n",
      "Epoch [150/2000], Avg Train Loss: 4.8172\n",
      "Epoch [150/2000], Avg Val Loss: 3.1109\n",
      "Validation loss improved from 3.1125 to 3.1109. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8869\n",
      "Epoch [151/2000], Avg Train Loss: 4.8869\n",
      "Epoch [151/2000], Avg Val Loss: 3.1094\n",
      "Validation loss improved from 3.1109 to 3.1094. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7839\n",
      "Epoch [152/2000], Avg Train Loss: 4.7839\n",
      "Epoch [152/2000], Avg Val Loss: 3.1078\n",
      "Validation loss improved from 3.1094 to 3.1078. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8667\n",
      "Epoch [153/2000], Avg Train Loss: 4.8667\n",
      "Epoch [153/2000], Avg Val Loss: 3.1063\n",
      "Validation loss improved from 3.1078 to 3.1063. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8101\n",
      "Epoch [154/2000], Avg Train Loss: 4.8101\n",
      "Epoch [154/2000], Avg Val Loss: 3.1047\n",
      "Validation loss improved from 3.1063 to 3.1047. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8440\n",
      "Epoch [155/2000], Avg Train Loss: 4.8440\n",
      "Epoch [155/2000], Avg Val Loss: 3.1032\n",
      "Validation loss improved from 3.1047 to 3.1032. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8033\n",
      "Epoch [156/2000], Avg Train Loss: 4.8033\n",
      "Epoch [156/2000], Avg Val Loss: 3.1016\n",
      "Validation loss improved from 3.1032 to 3.1016. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7836\n",
      "Epoch [157/2000], Avg Train Loss: 4.7836\n",
      "Epoch [157/2000], Avg Val Loss: 3.1000\n",
      "Validation loss improved from 3.1016 to 3.1000. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8433\n",
      "Epoch [158/2000], Avg Train Loss: 4.8433\n",
      "Epoch [158/2000], Avg Val Loss: 3.0985\n",
      "Validation loss improved from 3.1000 to 3.0985. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8390\n",
      "Epoch [159/2000], Avg Train Loss: 4.8390\n",
      "Epoch [159/2000], Avg Val Loss: 3.0970\n",
      "Validation loss improved from 3.0985 to 3.0970. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8491\n",
      "Epoch [160/2000], Avg Train Loss: 4.8491\n",
      "Epoch [160/2000], Avg Val Loss: 3.0954\n",
      "Validation loss improved from 3.0970 to 3.0954. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8189\n",
      "Epoch [161/2000], Avg Train Loss: 4.8189\n",
      "Epoch [161/2000], Avg Val Loss: 3.0939\n",
      "Validation loss improved from 3.0954 to 3.0939. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8161\n",
      "Epoch [162/2000], Avg Train Loss: 4.8161\n",
      "Epoch [162/2000], Avg Val Loss: 3.0924\n",
      "Validation loss improved from 3.0939 to 3.0924. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8118\n",
      "Epoch [163/2000], Avg Train Loss: 4.8118\n",
      "Epoch [163/2000], Avg Val Loss: 3.0909\n",
      "Validation loss improved from 3.0924 to 3.0909. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7751\n",
      "Epoch [164/2000], Avg Train Loss: 4.7751\n",
      "Epoch [164/2000], Avg Val Loss: 3.0894\n",
      "Validation loss improved from 3.0909 to 3.0894. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7918\n",
      "Epoch [165/2000], Avg Train Loss: 4.7918\n",
      "Epoch [165/2000], Avg Val Loss: 3.0878\n",
      "Validation loss improved from 3.0894 to 3.0878. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7964\n",
      "Epoch [166/2000], Avg Train Loss: 4.7964\n",
      "Epoch [166/2000], Avg Val Loss: 3.0863\n",
      "Validation loss improved from 3.0878 to 3.0863. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7735\n",
      "Epoch [167/2000], Avg Train Loss: 4.7735\n",
      "Epoch [167/2000], Avg Val Loss: 3.0848\n",
      "Validation loss improved from 3.0863 to 3.0848. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7938\n",
      "Epoch [168/2000], Avg Train Loss: 4.7938\n",
      "Epoch [168/2000], Avg Val Loss: 3.0833\n",
      "Validation loss improved from 3.0848 to 3.0833. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8268\n",
      "Epoch [169/2000], Avg Train Loss: 4.8268\n",
      "Epoch [169/2000], Avg Val Loss: 3.0818\n",
      "Validation loss improved from 3.0833 to 3.0818. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7859\n",
      "Epoch [170/2000], Avg Train Loss: 4.7859\n",
      "Epoch [170/2000], Avg Val Loss: 3.0803\n",
      "Validation loss improved from 3.0818 to 3.0803. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7822\n",
      "Epoch [171/2000], Avg Train Loss: 4.7822\n",
      "Epoch [171/2000], Avg Val Loss: 3.0788\n",
      "Validation loss improved from 3.0803 to 3.0788. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7578\n",
      "Epoch [172/2000], Avg Train Loss: 4.7578\n",
      "Epoch [172/2000], Avg Val Loss: 3.0773\n",
      "Validation loss improved from 3.0788 to 3.0773. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7438\n",
      "Epoch [173/2000], Avg Train Loss: 4.7438\n",
      "Epoch [173/2000], Avg Val Loss: 3.0759\n",
      "Validation loss improved from 3.0773 to 3.0759. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7509\n",
      "Epoch [174/2000], Avg Train Loss: 4.7509\n",
      "Epoch [174/2000], Avg Val Loss: 3.0744\n",
      "Validation loss improved from 3.0759 to 3.0744. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7976\n",
      "Epoch [175/2000], Avg Train Loss: 4.7976\n",
      "Epoch [175/2000], Avg Val Loss: 3.0729\n",
      "Validation loss improved from 3.0744 to 3.0729. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7521\n",
      "Epoch [176/2000], Avg Train Loss: 4.7521\n",
      "Epoch [176/2000], Avg Val Loss: 3.0714\n",
      "Validation loss improved from 3.0729 to 3.0714. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7623\n",
      "Epoch [177/2000], Avg Train Loss: 4.7623\n",
      "Epoch [177/2000], Avg Val Loss: 3.0699\n",
      "Validation loss improved from 3.0714 to 3.0699. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7905\n",
      "Epoch [178/2000], Avg Train Loss: 4.7905\n",
      "Epoch [178/2000], Avg Val Loss: 3.0685\n",
      "Validation loss improved from 3.0699 to 3.0685. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7861\n",
      "Epoch [179/2000], Avg Train Loss: 4.7861\n",
      "Epoch [179/2000], Avg Val Loss: 3.0670\n",
      "Validation loss improved from 3.0685 to 3.0670. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7333\n",
      "Epoch [180/2000], Avg Train Loss: 4.7333\n",
      "Epoch [180/2000], Avg Val Loss: 3.0655\n",
      "Validation loss improved from 3.0670 to 3.0655. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7766\n",
      "Epoch [181/2000], Avg Train Loss: 4.7766\n",
      "Epoch [181/2000], Avg Val Loss: 3.0640\n",
      "Validation loss improved from 3.0655 to 3.0640. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7267\n",
      "Epoch [182/2000], Avg Train Loss: 4.7267\n",
      "Epoch [182/2000], Avg Val Loss: 3.0626\n",
      "Validation loss improved from 3.0640 to 3.0626. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7697\n",
      "Epoch [183/2000], Avg Train Loss: 4.7697\n",
      "Epoch [183/2000], Avg Val Loss: 3.0611\n",
      "Validation loss improved from 3.0626 to 3.0611. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7438\n",
      "Epoch [184/2000], Avg Train Loss: 4.7438\n",
      "Epoch [184/2000], Avg Val Loss: 3.0597\n",
      "Validation loss improved from 3.0611 to 3.0597. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7554\n",
      "Epoch [185/2000], Avg Train Loss: 4.7554\n",
      "Epoch [185/2000], Avg Val Loss: 3.0582\n",
      "Validation loss improved from 3.0597 to 3.0582. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7606\n",
      "Epoch [186/2000], Avg Train Loss: 4.7606\n",
      "Epoch [186/2000], Avg Val Loss: 3.0567\n",
      "Validation loss improved from 3.0582 to 3.0567. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7433\n",
      "Epoch [187/2000], Avg Train Loss: 4.7433\n",
      "Epoch [187/2000], Avg Val Loss: 3.0553\n",
      "Validation loss improved from 3.0567 to 3.0553. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7374\n",
      "Epoch [188/2000], Avg Train Loss: 4.7374\n",
      "Epoch [188/2000], Avg Val Loss: 3.0539\n",
      "Validation loss improved from 3.0553 to 3.0539. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7386\n",
      "Epoch [189/2000], Avg Train Loss: 4.7386\n",
      "Epoch [189/2000], Avg Val Loss: 3.0524\n",
      "Validation loss improved from 3.0539 to 3.0524. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7528\n",
      "Epoch [190/2000], Avg Train Loss: 4.7528\n",
      "Epoch [190/2000], Avg Val Loss: 3.0509\n",
      "Validation loss improved from 3.0524 to 3.0509. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7481\n",
      "Epoch [191/2000], Avg Train Loss: 4.7481\n",
      "Epoch [191/2000], Avg Val Loss: 3.0495\n",
      "Validation loss improved from 3.0509 to 3.0495. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7070\n",
      "Epoch [192/2000], Avg Train Loss: 4.7070\n",
      "Epoch [192/2000], Avg Val Loss: 3.0480\n",
      "Validation loss improved from 3.0495 to 3.0480. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7274\n",
      "Epoch [193/2000], Avg Train Loss: 4.7274\n",
      "Epoch [193/2000], Avg Val Loss: 3.0465\n",
      "Validation loss improved from 3.0480 to 3.0465. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7176\n",
      "Epoch [194/2000], Avg Train Loss: 4.7176\n",
      "Epoch [194/2000], Avg Val Loss: 3.0450\n",
      "Validation loss improved from 3.0465 to 3.0450. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7373\n",
      "Epoch [195/2000], Avg Train Loss: 4.7373\n",
      "Epoch [195/2000], Avg Val Loss: 3.0435\n",
      "Validation loss improved from 3.0450 to 3.0435. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7135\n",
      "Epoch [196/2000], Avg Train Loss: 4.7135\n",
      "Epoch [196/2000], Avg Val Loss: 3.0420\n",
      "Validation loss improved from 3.0435 to 3.0420. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7211\n",
      "Epoch [197/2000], Avg Train Loss: 4.7211\n",
      "Epoch [197/2000], Avg Val Loss: 3.0405\n",
      "Validation loss improved from 3.0420 to 3.0405. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7387\n",
      "Epoch [198/2000], Avg Train Loss: 4.7387\n",
      "Epoch [198/2000], Avg Val Loss: 3.0390\n",
      "Validation loss improved from 3.0405 to 3.0390. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7091\n",
      "Epoch [199/2000], Avg Train Loss: 4.7091\n",
      "Epoch [199/2000], Avg Val Loss: 3.0375\n",
      "Validation loss improved from 3.0390 to 3.0375. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7153\n",
      "Epoch [200/2000], Avg Train Loss: 4.7153\n",
      "Epoch [200/2000], Avg Val Loss: 3.0360\n",
      "Validation loss improved from 3.0375 to 3.0360. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7058\n",
      "Epoch [201/2000], Avg Train Loss: 4.7058\n",
      "Epoch [201/2000], Avg Val Loss: 3.0345\n",
      "Validation loss improved from 3.0360 to 3.0345. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7009\n",
      "Epoch [202/2000], Avg Train Loss: 4.7009\n",
      "Epoch [202/2000], Avg Val Loss: 3.0331\n",
      "Validation loss improved from 3.0345 to 3.0331. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7054\n",
      "Epoch [203/2000], Avg Train Loss: 4.7054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [203/2000], Avg Val Loss: 3.0316\n",
      "Validation loss improved from 3.0331 to 3.0316. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6812\n",
      "Epoch [204/2000], Avg Train Loss: 4.6812\n",
      "Epoch [204/2000], Avg Val Loss: 3.0302\n",
      "Validation loss improved from 3.0316 to 3.0302. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6858\n",
      "Epoch [205/2000], Avg Train Loss: 4.6858\n",
      "Epoch [205/2000], Avg Val Loss: 3.0287\n",
      "Validation loss improved from 3.0302 to 3.0287. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7318\n",
      "Epoch [206/2000], Avg Train Loss: 4.7318\n",
      "Epoch [206/2000], Avg Val Loss: 3.0273\n",
      "Validation loss improved from 3.0287 to 3.0273. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6965\n",
      "Epoch [207/2000], Avg Train Loss: 4.6965\n",
      "Epoch [207/2000], Avg Val Loss: 3.0259\n",
      "Validation loss improved from 3.0273 to 3.0259. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7200\n",
      "Epoch [208/2000], Avg Train Loss: 4.7200\n",
      "Epoch [208/2000], Avg Val Loss: 3.0245\n",
      "Validation loss improved from 3.0259 to 3.0245. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7330\n",
      "Epoch [209/2000], Avg Train Loss: 4.7330\n",
      "Epoch [209/2000], Avg Val Loss: 3.0230\n",
      "Validation loss improved from 3.0245 to 3.0230. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6913\n",
      "Epoch [210/2000], Avg Train Loss: 4.6913\n",
      "Epoch [210/2000], Avg Val Loss: 3.0216\n",
      "Validation loss improved from 3.0230 to 3.0216. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6639\n",
      "Epoch [211/2000], Avg Train Loss: 4.6639\n",
      "Epoch [211/2000], Avg Val Loss: 3.0202\n",
      "Validation loss improved from 3.0216 to 3.0202. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7036\n",
      "Epoch [212/2000], Avg Train Loss: 4.7036\n",
      "Epoch [212/2000], Avg Val Loss: 3.0187\n",
      "Validation loss improved from 3.0202 to 3.0187. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6942\n",
      "Epoch [213/2000], Avg Train Loss: 4.6942\n",
      "Epoch [213/2000], Avg Val Loss: 3.0173\n",
      "Validation loss improved from 3.0187 to 3.0173. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6992\n",
      "Epoch [214/2000], Avg Train Loss: 4.6992\n",
      "Epoch [214/2000], Avg Val Loss: 3.0159\n",
      "Validation loss improved from 3.0173 to 3.0159. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7119\n",
      "Epoch [215/2000], Avg Train Loss: 4.7119\n",
      "Epoch [215/2000], Avg Val Loss: 3.0145\n",
      "Validation loss improved from 3.0159 to 3.0145. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7072\n",
      "Epoch [216/2000], Avg Train Loss: 4.7072\n",
      "Epoch [216/2000], Avg Val Loss: 3.0131\n",
      "Validation loss improved from 3.0145 to 3.0131. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6938\n",
      "Epoch [217/2000], Avg Train Loss: 4.6938\n",
      "Epoch [217/2000], Avg Val Loss: 3.0117\n",
      "Validation loss improved from 3.0131 to 3.0117. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7241\n",
      "Epoch [218/2000], Avg Train Loss: 4.7241\n",
      "Epoch [218/2000], Avg Val Loss: 3.0103\n",
      "Validation loss improved from 3.0117 to 3.0103. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7183\n",
      "Epoch [219/2000], Avg Train Loss: 4.7183\n",
      "Epoch [219/2000], Avg Val Loss: 3.0089\n",
      "Validation loss improved from 3.0103 to 3.0089. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6645\n",
      "Epoch [220/2000], Avg Train Loss: 4.6645\n",
      "Epoch [220/2000], Avg Val Loss: 3.0074\n",
      "Validation loss improved from 3.0089 to 3.0074. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7042\n",
      "Epoch [221/2000], Avg Train Loss: 4.7042\n",
      "Epoch [221/2000], Avg Val Loss: 3.0061\n",
      "Validation loss improved from 3.0074 to 3.0061. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6598\n",
      "Epoch [222/2000], Avg Train Loss: 4.6598\n",
      "Epoch [222/2000], Avg Val Loss: 3.0047\n",
      "Validation loss improved from 3.0061 to 3.0047. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6979\n",
      "Epoch [223/2000], Avg Train Loss: 4.6979\n",
      "Epoch [223/2000], Avg Val Loss: 3.0033\n",
      "Validation loss improved from 3.0047 to 3.0033. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6378\n",
      "Epoch [224/2000], Avg Train Loss: 4.6378\n",
      "Epoch [224/2000], Avg Val Loss: 3.0019\n",
      "Validation loss improved from 3.0033 to 3.0019. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6866\n",
      "Epoch [225/2000], Avg Train Loss: 4.6866\n",
      "Epoch [225/2000], Avg Val Loss: 3.0005\n",
      "Validation loss improved from 3.0019 to 3.0005. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6468\n",
      "Epoch [226/2000], Avg Train Loss: 4.6468\n",
      "Epoch [226/2000], Avg Val Loss: 2.9991\n",
      "Validation loss improved from 3.0005 to 2.9991. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6508\n",
      "Epoch [227/2000], Avg Train Loss: 4.6508\n",
      "Epoch [227/2000], Avg Val Loss: 2.9978\n",
      "Validation loss improved from 2.9991 to 2.9978. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6606\n",
      "Epoch [228/2000], Avg Train Loss: 4.6606\n",
      "Epoch [228/2000], Avg Val Loss: 2.9965\n",
      "Validation loss improved from 2.9978 to 2.9965. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6511\n",
      "Epoch [229/2000], Avg Train Loss: 4.6511\n",
      "Epoch [229/2000], Avg Val Loss: 2.9951\n",
      "Validation loss improved from 2.9965 to 2.9951. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7107\n",
      "Epoch [230/2000], Avg Train Loss: 4.7107\n",
      "Epoch [230/2000], Avg Val Loss: 2.9938\n",
      "Validation loss improved from 2.9951 to 2.9938. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6675\n",
      "Epoch [231/2000], Avg Train Loss: 4.6675\n",
      "Epoch [231/2000], Avg Val Loss: 2.9925\n",
      "Validation loss improved from 2.9938 to 2.9925. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6673\n",
      "Epoch [232/2000], Avg Train Loss: 4.6673\n",
      "Epoch [232/2000], Avg Val Loss: 2.9911\n",
      "Validation loss improved from 2.9925 to 2.9911. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6124\n",
      "Epoch [233/2000], Avg Train Loss: 4.6124\n",
      "Epoch [233/2000], Avg Val Loss: 2.9897\n",
      "Validation loss improved from 2.9911 to 2.9897. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6508\n",
      "Epoch [234/2000], Avg Train Loss: 4.6508\n",
      "Epoch [234/2000], Avg Val Loss: 2.9883\n",
      "Validation loss improved from 2.9897 to 2.9883. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6435\n",
      "Epoch [235/2000], Avg Train Loss: 4.6435\n",
      "Epoch [235/2000], Avg Val Loss: 2.9869\n",
      "Validation loss improved from 2.9883 to 2.9869. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6484\n",
      "Epoch [236/2000], Avg Train Loss: 4.6484\n",
      "Epoch [236/2000], Avg Val Loss: 2.9855\n",
      "Validation loss improved from 2.9869 to 2.9855. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6758\n",
      "Epoch [237/2000], Avg Train Loss: 4.6758\n",
      "Epoch [237/2000], Avg Val Loss: 2.9842\n",
      "Validation loss improved from 2.9855 to 2.9842. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6262\n",
      "Epoch [238/2000], Avg Train Loss: 4.6262\n",
      "Epoch [238/2000], Avg Val Loss: 2.9828\n",
      "Validation loss improved from 2.9842 to 2.9828. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6157\n",
      "Epoch [239/2000], Avg Train Loss: 4.6157\n",
      "Epoch [239/2000], Avg Val Loss: 2.9814\n",
      "Validation loss improved from 2.9828 to 2.9814. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6502\n",
      "Epoch [240/2000], Avg Train Loss: 4.6502\n",
      "Epoch [240/2000], Avg Val Loss: 2.9799\n",
      "Validation loss improved from 2.9814 to 2.9799. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6276\n",
      "Epoch [241/2000], Avg Train Loss: 4.6276\n",
      "Epoch [241/2000], Avg Val Loss: 2.9786\n",
      "Validation loss improved from 2.9799 to 2.9786. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6169\n",
      "Epoch [242/2000], Avg Train Loss: 4.6169\n",
      "Epoch [242/2000], Avg Val Loss: 2.9772\n",
      "Validation loss improved from 2.9786 to 2.9772. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6674\n",
      "Epoch [243/2000], Avg Train Loss: 4.6674\n",
      "Epoch [243/2000], Avg Val Loss: 2.9758\n",
      "Validation loss improved from 2.9772 to 2.9758. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6397\n",
      "Epoch [244/2000], Avg Train Loss: 4.6397\n",
      "Epoch [244/2000], Avg Val Loss: 2.9745\n",
      "Validation loss improved from 2.9758 to 2.9745. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6159\n",
      "Epoch [245/2000], Avg Train Loss: 4.6159\n",
      "Epoch [245/2000], Avg Val Loss: 2.9731\n",
      "Validation loss improved from 2.9745 to 2.9731. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6172\n",
      "Epoch [246/2000], Avg Train Loss: 4.6172\n",
      "Epoch [246/2000], Avg Val Loss: 2.9717\n",
      "Validation loss improved from 2.9731 to 2.9717. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6401\n",
      "Epoch [247/2000], Avg Train Loss: 4.6401\n",
      "Epoch [247/2000], Avg Val Loss: 2.9704\n",
      "Validation loss improved from 2.9717 to 2.9704. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6279\n",
      "Epoch [248/2000], Avg Train Loss: 4.6279\n",
      "Epoch [248/2000], Avg Val Loss: 2.9690\n",
      "Validation loss improved from 2.9704 to 2.9690. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5839\n",
      "Epoch [249/2000], Avg Train Loss: 4.5839\n",
      "Epoch [249/2000], Avg Val Loss: 2.9677\n",
      "Validation loss improved from 2.9690 to 2.9677. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6125\n",
      "Epoch [250/2000], Avg Train Loss: 4.6125\n",
      "Epoch [250/2000], Avg Val Loss: 2.9664\n",
      "Validation loss improved from 2.9677 to 2.9664. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5633\n",
      "Epoch [251/2000], Avg Train Loss: 4.5633\n",
      "Epoch [251/2000], Avg Val Loss: 2.9651\n",
      "Validation loss improved from 2.9664 to 2.9651. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6432\n",
      "Epoch [252/2000], Avg Train Loss: 4.6432\n",
      "Epoch [252/2000], Avg Val Loss: 2.9639\n",
      "Validation loss improved from 2.9651 to 2.9639. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6205\n",
      "Epoch [253/2000], Avg Train Loss: 4.6205\n",
      "Epoch [253/2000], Avg Val Loss: 2.9626\n",
      "Validation loss improved from 2.9639 to 2.9626. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6271\n",
      "Epoch [254/2000], Avg Train Loss: 4.6271\n",
      "Epoch [254/2000], Avg Val Loss: 2.9614\n",
      "Validation loss improved from 2.9626 to 2.9614. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5832\n",
      "Epoch [255/2000], Avg Train Loss: 4.5832\n",
      "Epoch [255/2000], Avg Val Loss: 2.9601\n",
      "Validation loss improved from 2.9614 to 2.9601. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5825\n",
      "Epoch [256/2000], Avg Train Loss: 4.5825\n",
      "Epoch [256/2000], Avg Val Loss: 2.9588\n",
      "Validation loss improved from 2.9601 to 2.9588. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6056\n",
      "Epoch [257/2000], Avg Train Loss: 4.6056\n",
      "Epoch [257/2000], Avg Val Loss: 2.9575\n",
      "Validation loss improved from 2.9588 to 2.9575. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6161\n",
      "Epoch [258/2000], Avg Train Loss: 4.6161\n",
      "Epoch [258/2000], Avg Val Loss: 2.9563\n",
      "Validation loss improved from 2.9575 to 2.9563. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6394\n",
      "Epoch [259/2000], Avg Train Loss: 4.6394\n",
      "Epoch [259/2000], Avg Val Loss: 2.9550\n",
      "Validation loss improved from 2.9563 to 2.9550. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5978\n",
      "Epoch [260/2000], Avg Train Loss: 4.5978\n",
      "Epoch [260/2000], Avg Val Loss: 2.9537\n",
      "Validation loss improved from 2.9550 to 2.9537. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6057\n",
      "Epoch [261/2000], Avg Train Loss: 4.6057\n",
      "Epoch [261/2000], Avg Val Loss: 2.9524\n",
      "Validation loss improved from 2.9537 to 2.9524. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6048\n",
      "Epoch [262/2000], Avg Train Loss: 4.6048\n",
      "Epoch [262/2000], Avg Val Loss: 2.9511\n",
      "Validation loss improved from 2.9524 to 2.9511. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5665\n",
      "Epoch [263/2000], Avg Train Loss: 4.5665\n",
      "Epoch [263/2000], Avg Val Loss: 2.9498\n",
      "Validation loss improved from 2.9511 to 2.9498. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5937\n",
      "Epoch [264/2000], Avg Train Loss: 4.5937\n",
      "Epoch [264/2000], Avg Val Loss: 2.9484\n",
      "Validation loss improved from 2.9498 to 2.9484. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5539\n",
      "Epoch [265/2000], Avg Train Loss: 4.5539\n",
      "Epoch [265/2000], Avg Val Loss: 2.9471\n",
      "Validation loss improved from 2.9484 to 2.9471. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5858\n",
      "Epoch [266/2000], Avg Train Loss: 4.5858\n",
      "Epoch [266/2000], Avg Val Loss: 2.9458\n",
      "Validation loss improved from 2.9471 to 2.9458. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6034\n",
      "Epoch [267/2000], Avg Train Loss: 4.6034\n",
      "Epoch [267/2000], Avg Val Loss: 2.9445\n",
      "Validation loss improved from 2.9458 to 2.9445. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5955\n",
      "Epoch [268/2000], Avg Train Loss: 4.5955\n",
      "Epoch [268/2000], Avg Val Loss: 2.9433\n",
      "Validation loss improved from 2.9445 to 2.9433. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6022\n",
      "Epoch [269/2000], Avg Train Loss: 4.6022\n",
      "Epoch [269/2000], Avg Val Loss: 2.9420\n",
      "Validation loss improved from 2.9433 to 2.9420. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5658\n",
      "Epoch [270/2000], Avg Train Loss: 4.5658\n",
      "Epoch [270/2000], Avg Val Loss: 2.9408\n",
      "Validation loss improved from 2.9420 to 2.9408. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5575\n",
      "Epoch [271/2000], Avg Train Loss: 4.5575\n",
      "Epoch [271/2000], Avg Val Loss: 2.9396\n",
      "Validation loss improved from 2.9408 to 2.9396. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6305\n",
      "Epoch [272/2000], Avg Train Loss: 4.6305\n",
      "Epoch [272/2000], Avg Val Loss: 2.9384\n",
      "Validation loss improved from 2.9396 to 2.9384. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5510\n",
      "Epoch [273/2000], Avg Train Loss: 4.5510\n",
      "Epoch [273/2000], Avg Val Loss: 2.9371\n",
      "Validation loss improved from 2.9384 to 2.9371. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5713\n",
      "Epoch [274/2000], Avg Train Loss: 4.5713\n",
      "Epoch [274/2000], Avg Val Loss: 2.9359\n",
      "Validation loss improved from 2.9371 to 2.9359. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5824\n",
      "Epoch [275/2000], Avg Train Loss: 4.5824\n",
      "Epoch [275/2000], Avg Val Loss: 2.9347\n",
      "Validation loss improved from 2.9359 to 2.9347. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5294\n",
      "Epoch [276/2000], Avg Train Loss: 4.5294\n",
      "Epoch [276/2000], Avg Val Loss: 2.9334\n",
      "Validation loss improved from 2.9347 to 2.9334. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5875\n",
      "Epoch [277/2000], Avg Train Loss: 4.5875\n",
      "Epoch [277/2000], Avg Val Loss: 2.9322\n",
      "Validation loss improved from 2.9334 to 2.9322. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5799\n",
      "Epoch [278/2000], Avg Train Loss: 4.5799\n",
      "Epoch [278/2000], Avg Val Loss: 2.9309\n",
      "Validation loss improved from 2.9322 to 2.9309. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5397\n",
      "Epoch [279/2000], Avg Train Loss: 4.5397\n",
      "Epoch [279/2000], Avg Val Loss: 2.9296\n",
      "Validation loss improved from 2.9309 to 2.9296. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5447\n",
      "Epoch [280/2000], Avg Train Loss: 4.5447\n",
      "Epoch [280/2000], Avg Val Loss: 2.9283\n",
      "Validation loss improved from 2.9296 to 2.9283. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5571\n",
      "Epoch [281/2000], Avg Train Loss: 4.5571\n",
      "Epoch [281/2000], Avg Val Loss: 2.9270\n",
      "Validation loss improved from 2.9283 to 2.9270. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6033\n",
      "Epoch [282/2000], Avg Train Loss: 4.6033\n",
      "Epoch [282/2000], Avg Val Loss: 2.9258\n",
      "Validation loss improved from 2.9270 to 2.9258. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5573\n",
      "Epoch [283/2000], Avg Train Loss: 4.5573\n",
      "Epoch [283/2000], Avg Val Loss: 2.9245\n",
      "Validation loss improved from 2.9258 to 2.9245. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5604\n",
      "Epoch [284/2000], Avg Train Loss: 4.5604\n",
      "Epoch [284/2000], Avg Val Loss: 2.9232\n",
      "Validation loss improved from 2.9245 to 2.9232. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5191\n",
      "Epoch [285/2000], Avg Train Loss: 4.5191\n",
      "Epoch [285/2000], Avg Val Loss: 2.9219\n",
      "Validation loss improved from 2.9232 to 2.9219. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5474\n",
      "Epoch [286/2000], Avg Train Loss: 4.5474\n",
      "Epoch [286/2000], Avg Val Loss: 2.9206\n",
      "Validation loss improved from 2.9219 to 2.9206. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5347\n",
      "Epoch [287/2000], Avg Train Loss: 4.5347\n",
      "Epoch [287/2000], Avg Val Loss: 2.9193\n",
      "Validation loss improved from 2.9206 to 2.9193. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5598\n",
      "Epoch [288/2000], Avg Train Loss: 4.5598\n",
      "Epoch [288/2000], Avg Val Loss: 2.9180\n",
      "Validation loss improved from 2.9193 to 2.9180. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5330\n",
      "Epoch [289/2000], Avg Train Loss: 4.5330\n",
      "Epoch [289/2000], Avg Val Loss: 2.9166\n",
      "Validation loss improved from 2.9180 to 2.9166. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4979\n",
      "Epoch [290/2000], Avg Train Loss: 4.4979\n",
      "Epoch [290/2000], Avg Val Loss: 2.9153\n",
      "Validation loss improved from 2.9166 to 2.9153. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5550\n",
      "Epoch [291/2000], Avg Train Loss: 4.5550\n",
      "Epoch [291/2000], Avg Val Loss: 2.9140\n",
      "Validation loss improved from 2.9153 to 2.9140. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5668\n",
      "Epoch [292/2000], Avg Train Loss: 4.5668\n",
      "Epoch [292/2000], Avg Val Loss: 2.9127\n",
      "Validation loss improved from 2.9140 to 2.9127. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5241\n",
      "Epoch [293/2000], Avg Train Loss: 4.5241\n",
      "Epoch [293/2000], Avg Val Loss: 2.9114\n",
      "Validation loss improved from 2.9127 to 2.9114. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5220\n",
      "Epoch [294/2000], Avg Train Loss: 4.5220\n",
      "Epoch [294/2000], Avg Val Loss: 2.9101\n",
      "Validation loss improved from 2.9114 to 2.9101. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5680\n",
      "Epoch [295/2000], Avg Train Loss: 4.5680\n",
      "Epoch [295/2000], Avg Val Loss: 2.9089\n",
      "Validation loss improved from 2.9101 to 2.9089. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5858\n",
      "Epoch [296/2000], Avg Train Loss: 4.5858\n",
      "Epoch [296/2000], Avg Val Loss: 2.9076\n",
      "Validation loss improved from 2.9089 to 2.9076. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5416\n",
      "Epoch [297/2000], Avg Train Loss: 4.5416\n",
      "Epoch [297/2000], Avg Val Loss: 2.9063\n",
      "Validation loss improved from 2.9076 to 2.9063. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5112\n",
      "Epoch [298/2000], Avg Train Loss: 4.5112\n",
      "Epoch [298/2000], Avg Val Loss: 2.9050\n",
      "Validation loss improved from 2.9063 to 2.9050. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5404\n",
      "Epoch [299/2000], Avg Train Loss: 4.5404\n",
      "Epoch [299/2000], Avg Val Loss: 2.9037\n",
      "Validation loss improved from 2.9050 to 2.9037. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5477\n",
      "Epoch [300/2000], Avg Train Loss: 4.5477\n",
      "Epoch [300/2000], Avg Val Loss: 2.9024\n",
      "Validation loss improved from 2.9037 to 2.9024. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5083\n",
      "Epoch [301/2000], Avg Train Loss: 4.5083\n",
      "Epoch [301/2000], Avg Val Loss: 2.9011\n",
      "Validation loss improved from 2.9024 to 2.9011. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5035\n",
      "Epoch [302/2000], Avg Train Loss: 4.5035\n",
      "Epoch [302/2000], Avg Val Loss: 2.8999\n",
      "Validation loss improved from 2.9011 to 2.8999. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5106\n",
      "Epoch [303/2000], Avg Train Loss: 4.5106\n",
      "Epoch [303/2000], Avg Val Loss: 2.8986\n",
      "Validation loss improved from 2.8999 to 2.8986. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5108\n",
      "Epoch [304/2000], Avg Train Loss: 4.5108\n",
      "Epoch [304/2000], Avg Val Loss: 2.8973\n",
      "Validation loss improved from 2.8986 to 2.8973. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4884\n",
      "Epoch [305/2000], Avg Train Loss: 4.4884\n",
      "Epoch [305/2000], Avg Val Loss: 2.8960\n",
      "Validation loss improved from 2.8973 to 2.8960. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4835\n",
      "Epoch [306/2000], Avg Train Loss: 4.4835\n",
      "Epoch [306/2000], Avg Val Loss: 2.8947\n",
      "Validation loss improved from 2.8960 to 2.8947. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5333\n",
      "Epoch [307/2000], Avg Train Loss: 4.5333\n",
      "Epoch [307/2000], Avg Val Loss: 2.8934\n",
      "Validation loss improved from 2.8947 to 2.8934. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4913\n",
      "Epoch [308/2000], Avg Train Loss: 4.4913\n",
      "Epoch [308/2000], Avg Val Loss: 2.8921\n",
      "Validation loss improved from 2.8934 to 2.8921. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4884\n",
      "Epoch [309/2000], Avg Train Loss: 4.4884\n",
      "Epoch [309/2000], Avg Val Loss: 2.8908\n",
      "Validation loss improved from 2.8921 to 2.8908. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4746\n",
      "Epoch [310/2000], Avg Train Loss: 4.4746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [310/2000], Avg Val Loss: 2.8895\n",
      "Validation loss improved from 2.8908 to 2.8895. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4907\n",
      "Epoch [311/2000], Avg Train Loss: 4.4907\n",
      "Epoch [311/2000], Avg Val Loss: 2.8883\n",
      "Validation loss improved from 2.8895 to 2.8883. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5254\n",
      "Epoch [312/2000], Avg Train Loss: 4.5254\n",
      "Epoch [312/2000], Avg Val Loss: 2.8870\n",
      "Validation loss improved from 2.8883 to 2.8870. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5047\n",
      "Epoch [313/2000], Avg Train Loss: 4.5047\n",
      "Epoch [313/2000], Avg Val Loss: 2.8857\n",
      "Validation loss improved from 2.8870 to 2.8857. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5239\n",
      "Epoch [314/2000], Avg Train Loss: 4.5239\n",
      "Epoch [314/2000], Avg Val Loss: 2.8845\n",
      "Validation loss improved from 2.8857 to 2.8845. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4943\n",
      "Epoch [315/2000], Avg Train Loss: 4.4943\n",
      "Epoch [315/2000], Avg Val Loss: 2.8833\n",
      "Validation loss improved from 2.8845 to 2.8833. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4905\n",
      "Epoch [316/2000], Avg Train Loss: 4.4905\n",
      "Epoch [316/2000], Avg Val Loss: 2.8820\n",
      "Validation loss improved from 2.8833 to 2.8820. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4886\n",
      "Epoch [317/2000], Avg Train Loss: 4.4886\n",
      "Epoch [317/2000], Avg Val Loss: 2.8808\n",
      "Validation loss improved from 2.8820 to 2.8808. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4932\n",
      "Epoch [318/2000], Avg Train Loss: 4.4932\n",
      "Epoch [318/2000], Avg Val Loss: 2.8796\n",
      "Validation loss improved from 2.8808 to 2.8796. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4691\n",
      "Epoch [319/2000], Avg Train Loss: 4.4691\n",
      "Epoch [319/2000], Avg Val Loss: 2.8784\n",
      "Validation loss improved from 2.8796 to 2.8784. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4896\n",
      "Epoch [320/2000], Avg Train Loss: 4.4896\n",
      "Epoch [320/2000], Avg Val Loss: 2.8772\n",
      "Validation loss improved from 2.8784 to 2.8772. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4766\n",
      "Epoch [321/2000], Avg Train Loss: 4.4766\n",
      "Epoch [321/2000], Avg Val Loss: 2.8759\n",
      "Validation loss improved from 2.8772 to 2.8759. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4683\n",
      "Epoch [322/2000], Avg Train Loss: 4.4683\n",
      "Epoch [322/2000], Avg Val Loss: 2.8747\n",
      "Validation loss improved from 2.8759 to 2.8747. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4826\n",
      "Epoch [323/2000], Avg Train Loss: 4.4826\n",
      "Epoch [323/2000], Avg Val Loss: 2.8735\n",
      "Validation loss improved from 2.8747 to 2.8735. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4752\n",
      "Epoch [324/2000], Avg Train Loss: 4.4752\n",
      "Epoch [324/2000], Avg Val Loss: 2.8722\n",
      "Validation loss improved from 2.8735 to 2.8722. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5163\n",
      "Epoch [325/2000], Avg Train Loss: 4.5163\n",
      "Epoch [325/2000], Avg Val Loss: 2.8710\n",
      "Validation loss improved from 2.8722 to 2.8710. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4595\n",
      "Epoch [326/2000], Avg Train Loss: 4.4595\n",
      "Epoch [326/2000], Avg Val Loss: 2.8698\n",
      "Validation loss improved from 2.8710 to 2.8698. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4702\n",
      "Epoch [327/2000], Avg Train Loss: 4.4702\n",
      "Epoch [327/2000], Avg Val Loss: 2.8685\n",
      "Validation loss improved from 2.8698 to 2.8685. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4567\n",
      "Epoch [328/2000], Avg Train Loss: 4.4567\n",
      "Epoch [328/2000], Avg Val Loss: 2.8672\n",
      "Validation loss improved from 2.8685 to 2.8672. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4413\n",
      "Epoch [329/2000], Avg Train Loss: 4.4413\n",
      "Epoch [329/2000], Avg Val Loss: 2.8659\n",
      "Validation loss improved from 2.8672 to 2.8659. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5098\n",
      "Epoch [330/2000], Avg Train Loss: 4.5098\n",
      "Epoch [330/2000], Avg Val Loss: 2.8647\n",
      "Validation loss improved from 2.8659 to 2.8647. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4857\n",
      "Epoch [331/2000], Avg Train Loss: 4.4857\n",
      "Epoch [331/2000], Avg Val Loss: 2.8634\n",
      "Validation loss improved from 2.8647 to 2.8634. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4857\n",
      "Epoch [332/2000], Avg Train Loss: 4.4857\n",
      "Epoch [332/2000], Avg Val Loss: 2.8622\n",
      "Validation loss improved from 2.8634 to 2.8622. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4632\n",
      "Epoch [333/2000], Avg Train Loss: 4.4632\n",
      "Epoch [333/2000], Avg Val Loss: 2.8610\n",
      "Validation loss improved from 2.8622 to 2.8610. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4598\n",
      "Epoch [334/2000], Avg Train Loss: 4.4598\n",
      "Epoch [334/2000], Avg Val Loss: 2.8598\n",
      "Validation loss improved from 2.8610 to 2.8598. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4710\n",
      "Epoch [335/2000], Avg Train Loss: 4.4710\n",
      "Epoch [335/2000], Avg Val Loss: 2.8587\n",
      "Validation loss improved from 2.8598 to 2.8587. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4878\n",
      "Epoch [336/2000], Avg Train Loss: 4.4878\n",
      "Epoch [336/2000], Avg Val Loss: 2.8575\n",
      "Validation loss improved from 2.8587 to 2.8575. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4662\n",
      "Epoch [337/2000], Avg Train Loss: 4.4662\n",
      "Epoch [337/2000], Avg Val Loss: 2.8563\n",
      "Validation loss improved from 2.8575 to 2.8563. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4576\n",
      "Epoch [338/2000], Avg Train Loss: 4.4576\n",
      "Epoch [338/2000], Avg Val Loss: 2.8551\n",
      "Validation loss improved from 2.8563 to 2.8551. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4983\n",
      "Epoch [339/2000], Avg Train Loss: 4.4983\n",
      "Epoch [339/2000], Avg Val Loss: 2.8540\n",
      "Validation loss improved from 2.8551 to 2.8540. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4473\n",
      "Epoch [340/2000], Avg Train Loss: 4.4473\n",
      "Epoch [340/2000], Avg Val Loss: 2.8528\n",
      "Validation loss improved from 2.8540 to 2.8528. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4143\n",
      "Epoch [341/2000], Avg Train Loss: 4.4143\n",
      "Epoch [341/2000], Avg Val Loss: 2.8516\n",
      "Validation loss improved from 2.8528 to 2.8516. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4404\n",
      "Epoch [342/2000], Avg Train Loss: 4.4404\n",
      "Epoch [342/2000], Avg Val Loss: 2.8504\n",
      "Validation loss improved from 2.8516 to 2.8504. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4872\n",
      "Epoch [343/2000], Avg Train Loss: 4.4872\n",
      "Epoch [343/2000], Avg Val Loss: 2.8492\n",
      "Validation loss improved from 2.8504 to 2.8492. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4371\n",
      "Epoch [344/2000], Avg Train Loss: 4.4371\n",
      "Epoch [344/2000], Avg Val Loss: 2.8480\n",
      "Validation loss improved from 2.8492 to 2.8480. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4650\n",
      "Epoch [345/2000], Avg Train Loss: 4.4650\n",
      "Epoch [345/2000], Avg Val Loss: 2.8467\n",
      "Validation loss improved from 2.8480 to 2.8467. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4769\n",
      "Epoch [346/2000], Avg Train Loss: 4.4769\n",
      "Epoch [346/2000], Avg Val Loss: 2.8455\n",
      "Validation loss improved from 2.8467 to 2.8455. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4537\n",
      "Epoch [347/2000], Avg Train Loss: 4.4537\n",
      "Epoch [347/2000], Avg Val Loss: 2.8443\n",
      "Validation loss improved from 2.8455 to 2.8443. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4609\n",
      "Epoch [348/2000], Avg Train Loss: 4.4609\n",
      "Epoch [348/2000], Avg Val Loss: 2.8431\n",
      "Validation loss improved from 2.8443 to 2.8431. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4490\n",
      "Epoch [349/2000], Avg Train Loss: 4.4490\n",
      "Epoch [349/2000], Avg Val Loss: 2.8420\n",
      "Validation loss improved from 2.8431 to 2.8420. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4273\n",
      "Epoch [350/2000], Avg Train Loss: 4.4273\n",
      "Epoch [350/2000], Avg Val Loss: 2.8408\n",
      "Validation loss improved from 2.8420 to 2.8408. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4063\n",
      "Epoch [351/2000], Avg Train Loss: 4.4063\n",
      "Epoch [351/2000], Avg Val Loss: 2.8395\n",
      "Validation loss improved from 2.8408 to 2.8395. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4643\n",
      "Epoch [352/2000], Avg Train Loss: 4.4643\n",
      "Epoch [352/2000], Avg Val Loss: 2.8383\n",
      "Validation loss improved from 2.8395 to 2.8383. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5007\n",
      "Epoch [353/2000], Avg Train Loss: 4.5007\n",
      "Epoch [353/2000], Avg Val Loss: 2.8370\n",
      "Validation loss improved from 2.8383 to 2.8370. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4771\n",
      "Epoch [354/2000], Avg Train Loss: 4.4771\n",
      "Epoch [354/2000], Avg Val Loss: 2.8358\n",
      "Validation loss improved from 2.8370 to 2.8358. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4935\n",
      "Epoch [355/2000], Avg Train Loss: 4.4935\n",
      "Epoch [355/2000], Avg Val Loss: 2.8346\n",
      "Validation loss improved from 2.8358 to 2.8346. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4150\n",
      "Epoch [356/2000], Avg Train Loss: 4.4150\n",
      "Epoch [356/2000], Avg Val Loss: 2.8334\n",
      "Validation loss improved from 2.8346 to 2.8334. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4443\n",
      "Epoch [357/2000], Avg Train Loss: 4.4443\n",
      "Epoch [357/2000], Avg Val Loss: 2.8322\n",
      "Validation loss improved from 2.8334 to 2.8322. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4198\n",
      "Epoch [358/2000], Avg Train Loss: 4.4198\n",
      "Epoch [358/2000], Avg Val Loss: 2.8310\n",
      "Validation loss improved from 2.8322 to 2.8310. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4323\n",
      "Epoch [359/2000], Avg Train Loss: 4.4323\n",
      "Epoch [359/2000], Avg Val Loss: 2.8298\n",
      "Validation loss improved from 2.8310 to 2.8298. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4392\n",
      "Epoch [360/2000], Avg Train Loss: 4.4392\n",
      "Epoch [360/2000], Avg Val Loss: 2.8286\n",
      "Validation loss improved from 2.8298 to 2.8286. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4595\n",
      "Epoch [361/2000], Avg Train Loss: 4.4595\n",
      "Epoch [361/2000], Avg Val Loss: 2.8274\n",
      "Validation loss improved from 2.8286 to 2.8274. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4537\n",
      "Epoch [362/2000], Avg Train Loss: 4.4537\n",
      "Epoch [362/2000], Avg Val Loss: 2.8262\n",
      "Validation loss improved from 2.8274 to 2.8262. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4105\n",
      "Epoch [363/2000], Avg Train Loss: 4.4105\n",
      "Epoch [363/2000], Avg Val Loss: 2.8251\n",
      "Validation loss improved from 2.8262 to 2.8251. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4132\n",
      "Epoch [364/2000], Avg Train Loss: 4.4132\n",
      "Epoch [364/2000], Avg Val Loss: 2.8239\n",
      "Validation loss improved from 2.8251 to 2.8239. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4255\n",
      "Epoch [365/2000], Avg Train Loss: 4.4255\n",
      "Epoch [365/2000], Avg Val Loss: 2.8227\n",
      "Validation loss improved from 2.8239 to 2.8227. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4445\n",
      "Epoch [366/2000], Avg Train Loss: 4.4445\n",
      "Epoch [366/2000], Avg Val Loss: 2.8216\n",
      "Validation loss improved from 2.8227 to 2.8216. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4215\n",
      "Epoch [367/2000], Avg Train Loss: 4.4215\n",
      "Epoch [367/2000], Avg Val Loss: 2.8204\n",
      "Validation loss improved from 2.8216 to 2.8204. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4528\n",
      "Epoch [368/2000], Avg Train Loss: 4.4528\n",
      "Epoch [368/2000], Avg Val Loss: 2.8192\n",
      "Validation loss improved from 2.8204 to 2.8192. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3934\n",
      "Epoch [369/2000], Avg Train Loss: 4.3934\n",
      "Epoch [369/2000], Avg Val Loss: 2.8181\n",
      "Validation loss improved from 2.8192 to 2.8181. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4390\n",
      "Epoch [370/2000], Avg Train Loss: 4.4390\n",
      "Epoch [370/2000], Avg Val Loss: 2.8170\n",
      "Validation loss improved from 2.8181 to 2.8170. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4456\n",
      "Epoch [371/2000], Avg Train Loss: 4.4456\n",
      "Epoch [371/2000], Avg Val Loss: 2.8159\n",
      "Validation loss improved from 2.8170 to 2.8159. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4396\n",
      "Epoch [372/2000], Avg Train Loss: 4.4396\n",
      "Epoch [372/2000], Avg Val Loss: 2.8148\n",
      "Validation loss improved from 2.8159 to 2.8148. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3856\n",
      "Epoch [373/2000], Avg Train Loss: 4.3856\n",
      "Epoch [373/2000], Avg Val Loss: 2.8137\n",
      "Validation loss improved from 2.8148 to 2.8137. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4207\n",
      "Epoch [374/2000], Avg Train Loss: 4.4207\n",
      "Epoch [374/2000], Avg Val Loss: 2.8125\n",
      "Validation loss improved from 2.8137 to 2.8125. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3734\n",
      "Epoch [375/2000], Avg Train Loss: 4.3734\n",
      "Epoch [375/2000], Avg Val Loss: 2.8114\n",
      "Validation loss improved from 2.8125 to 2.8114. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3904\n",
      "Epoch [376/2000], Avg Train Loss: 4.3904\n",
      "Epoch [376/2000], Avg Val Loss: 2.8102\n",
      "Validation loss improved from 2.8114 to 2.8102. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4130\n",
      "Epoch [377/2000], Avg Train Loss: 4.4130\n",
      "Epoch [377/2000], Avg Val Loss: 2.8091\n",
      "Validation loss improved from 2.8102 to 2.8091. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3942\n",
      "Epoch [378/2000], Avg Train Loss: 4.3942\n",
      "Epoch [378/2000], Avg Val Loss: 2.8080\n",
      "Validation loss improved from 2.8091 to 2.8080. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4199\n",
      "Epoch [379/2000], Avg Train Loss: 4.4199\n",
      "Epoch [379/2000], Avg Val Loss: 2.8069\n",
      "Validation loss improved from 2.8080 to 2.8069. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3982\n",
      "Epoch [380/2000], Avg Train Loss: 4.3982\n",
      "Epoch [380/2000], Avg Val Loss: 2.8058\n",
      "Validation loss improved from 2.8069 to 2.8058. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4064\n",
      "Epoch [381/2000], Avg Train Loss: 4.4064\n",
      "Epoch [381/2000], Avg Val Loss: 2.8047\n",
      "Validation loss improved from 2.8058 to 2.8047. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3951\n",
      "Epoch [382/2000], Avg Train Loss: 4.3951\n",
      "Epoch [382/2000], Avg Val Loss: 2.8036\n",
      "Validation loss improved from 2.8047 to 2.8036. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3806\n",
      "Epoch [383/2000], Avg Train Loss: 4.3806\n",
      "Epoch [383/2000], Avg Val Loss: 2.8025\n",
      "Validation loss improved from 2.8036 to 2.8025. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4080\n",
      "Epoch [384/2000], Avg Train Loss: 4.4080\n",
      "Epoch [384/2000], Avg Val Loss: 2.8014\n",
      "Validation loss improved from 2.8025 to 2.8014. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3834\n",
      "Epoch [385/2000], Avg Train Loss: 4.3834\n",
      "Epoch [385/2000], Avg Val Loss: 2.8003\n",
      "Validation loss improved from 2.8014 to 2.8003. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3683\n",
      "Epoch [386/2000], Avg Train Loss: 4.3683\n",
      "Epoch [386/2000], Avg Val Loss: 2.7991\n",
      "Validation loss improved from 2.8003 to 2.7991. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4214\n",
      "Epoch [387/2000], Avg Train Loss: 4.4214\n",
      "Epoch [387/2000], Avg Val Loss: 2.7980\n",
      "Validation loss improved from 2.7991 to 2.7980. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4157\n",
      "Epoch [388/2000], Avg Train Loss: 4.4157\n",
      "Epoch [388/2000], Avg Val Loss: 2.7969\n",
      "Validation loss improved from 2.7980 to 2.7969. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3932\n",
      "Epoch [389/2000], Avg Train Loss: 4.3932\n",
      "Epoch [389/2000], Avg Val Loss: 2.7957\n",
      "Validation loss improved from 2.7969 to 2.7957. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3648\n",
      "Epoch [390/2000], Avg Train Loss: 4.3648\n",
      "Epoch [390/2000], Avg Val Loss: 2.7945\n",
      "Validation loss improved from 2.7957 to 2.7945. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3782\n",
      "Epoch [391/2000], Avg Train Loss: 4.3782\n",
      "Epoch [391/2000], Avg Val Loss: 2.7934\n",
      "Validation loss improved from 2.7945 to 2.7934. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4020\n",
      "Epoch [392/2000], Avg Train Loss: 4.4020\n",
      "Epoch [392/2000], Avg Val Loss: 2.7922\n",
      "Validation loss improved from 2.7934 to 2.7922. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3557\n",
      "Epoch [393/2000], Avg Train Loss: 4.3557\n",
      "Epoch [393/2000], Avg Val Loss: 2.7910\n",
      "Validation loss improved from 2.7922 to 2.7910. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4257\n",
      "Epoch [394/2000], Avg Train Loss: 4.4257\n",
      "Epoch [394/2000], Avg Val Loss: 2.7899\n",
      "Validation loss improved from 2.7910 to 2.7899. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4135\n",
      "Epoch [395/2000], Avg Train Loss: 4.4135\n",
      "Epoch [395/2000], Avg Val Loss: 2.7887\n",
      "Validation loss improved from 2.7899 to 2.7887. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3858\n",
      "Epoch [396/2000], Avg Train Loss: 4.3858\n",
      "Epoch [396/2000], Avg Val Loss: 2.7875\n",
      "Validation loss improved from 2.7887 to 2.7875. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3824\n",
      "Epoch [397/2000], Avg Train Loss: 4.3824\n",
      "Epoch [397/2000], Avg Val Loss: 2.7864\n",
      "Validation loss improved from 2.7875 to 2.7864. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3616\n",
      "Epoch [398/2000], Avg Train Loss: 4.3616\n",
      "Epoch [398/2000], Avg Val Loss: 2.7852\n",
      "Validation loss improved from 2.7864 to 2.7852. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4197\n",
      "Epoch [399/2000], Avg Train Loss: 4.4197\n",
      "Epoch [399/2000], Avg Val Loss: 2.7840\n",
      "Validation loss improved from 2.7852 to 2.7840. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3508\n",
      "Epoch [400/2000], Avg Train Loss: 4.3508\n",
      "Epoch [400/2000], Avg Val Loss: 2.7828\n",
      "Validation loss improved from 2.7840 to 2.7828. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3613\n",
      "Epoch [401/2000], Avg Train Loss: 4.3613\n",
      "Epoch [401/2000], Avg Val Loss: 2.7817\n",
      "Validation loss improved from 2.7828 to 2.7817. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3519\n",
      "Epoch [402/2000], Avg Train Loss: 4.3519\n",
      "Epoch [402/2000], Avg Val Loss: 2.7806\n",
      "Validation loss improved from 2.7817 to 2.7806. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4025\n",
      "Epoch [403/2000], Avg Train Loss: 4.4025\n",
      "Epoch [403/2000], Avg Val Loss: 2.7794\n",
      "Validation loss improved from 2.7806 to 2.7794. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3546\n",
      "Epoch [404/2000], Avg Train Loss: 4.3546\n",
      "Epoch [404/2000], Avg Val Loss: 2.7783\n",
      "Validation loss improved from 2.7794 to 2.7783. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3580\n",
      "Epoch [405/2000], Avg Train Loss: 4.3580\n",
      "Epoch [405/2000], Avg Val Loss: 2.7771\n",
      "Validation loss improved from 2.7783 to 2.7771. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3669\n",
      "Epoch [406/2000], Avg Train Loss: 4.3669\n",
      "Epoch [406/2000], Avg Val Loss: 2.7760\n",
      "Validation loss improved from 2.7771 to 2.7760. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4070\n",
      "Epoch [407/2000], Avg Train Loss: 4.4070\n",
      "Epoch [407/2000], Avg Val Loss: 2.7748\n",
      "Validation loss improved from 2.7760 to 2.7748. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3522\n",
      "Epoch [408/2000], Avg Train Loss: 4.3522\n",
      "Epoch [408/2000], Avg Val Loss: 2.7737\n",
      "Validation loss improved from 2.7748 to 2.7737. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3735\n",
      "Epoch [409/2000], Avg Train Loss: 4.3735\n",
      "Epoch [409/2000], Avg Val Loss: 2.7726\n",
      "Validation loss improved from 2.7737 to 2.7726. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3450\n",
      "Epoch [410/2000], Avg Train Loss: 4.3450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [410/2000], Avg Val Loss: 2.7715\n",
      "Validation loss improved from 2.7726 to 2.7715. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3648\n",
      "Epoch [411/2000], Avg Train Loss: 4.3648\n",
      "Epoch [411/2000], Avg Val Loss: 2.7704\n",
      "Validation loss improved from 2.7715 to 2.7704. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3670\n",
      "Epoch [412/2000], Avg Train Loss: 4.3670\n",
      "Epoch [412/2000], Avg Val Loss: 2.7693\n",
      "Validation loss improved from 2.7704 to 2.7693. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3255\n",
      "Epoch [413/2000], Avg Train Loss: 4.3255\n",
      "Epoch [413/2000], Avg Val Loss: 2.7682\n",
      "Validation loss improved from 2.7693 to 2.7682. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3473\n",
      "Epoch [414/2000], Avg Train Loss: 4.3473\n",
      "Epoch [414/2000], Avg Val Loss: 2.7670\n",
      "Validation loss improved from 2.7682 to 2.7670. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3354\n",
      "Epoch [415/2000], Avg Train Loss: 4.3354\n",
      "Epoch [415/2000], Avg Val Loss: 2.7659\n",
      "Validation loss improved from 2.7670 to 2.7659. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3270\n",
      "Epoch [416/2000], Avg Train Loss: 4.3270\n",
      "Epoch [416/2000], Avg Val Loss: 2.7648\n",
      "Validation loss improved from 2.7659 to 2.7648. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3632\n",
      "Epoch [417/2000], Avg Train Loss: 4.3632\n",
      "Epoch [417/2000], Avg Val Loss: 2.7636\n",
      "Validation loss improved from 2.7648 to 2.7636. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3793\n",
      "Epoch [418/2000], Avg Train Loss: 4.3793\n",
      "Epoch [418/2000], Avg Val Loss: 2.7625\n",
      "Validation loss improved from 2.7636 to 2.7625. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3757\n",
      "Epoch [419/2000], Avg Train Loss: 4.3757\n",
      "Epoch [419/2000], Avg Val Loss: 2.7614\n",
      "Validation loss improved from 2.7625 to 2.7614. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3639\n",
      "Epoch [420/2000], Avg Train Loss: 4.3639\n",
      "Epoch [420/2000], Avg Val Loss: 2.7603\n",
      "Validation loss improved from 2.7614 to 2.7603. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4298\n",
      "Epoch [421/2000], Avg Train Loss: 4.4298\n",
      "Epoch [421/2000], Avg Val Loss: 2.7592\n",
      "Validation loss improved from 2.7603 to 2.7592. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3747\n",
      "Epoch [422/2000], Avg Train Loss: 4.3747\n",
      "Epoch [422/2000], Avg Val Loss: 2.7582\n",
      "Validation loss improved from 2.7592 to 2.7582. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3721\n",
      "Epoch [423/2000], Avg Train Loss: 4.3721\n",
      "Epoch [423/2000], Avg Val Loss: 2.7571\n",
      "Validation loss improved from 2.7582 to 2.7571. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3461\n",
      "Epoch [424/2000], Avg Train Loss: 4.3461\n",
      "Epoch [424/2000], Avg Val Loss: 2.7561\n",
      "Validation loss improved from 2.7571 to 2.7561. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3368\n",
      "Epoch [425/2000], Avg Train Loss: 4.3368\n",
      "Epoch [425/2000], Avg Val Loss: 2.7551\n",
      "Validation loss improved from 2.7561 to 2.7551. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3613\n",
      "Epoch [426/2000], Avg Train Loss: 4.3613\n",
      "Epoch [426/2000], Avg Val Loss: 2.7540\n",
      "Validation loss improved from 2.7551 to 2.7540. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3041\n",
      "Epoch [427/2000], Avg Train Loss: 4.3041\n",
      "Epoch [427/2000], Avg Val Loss: 2.7530\n",
      "Validation loss improved from 2.7540 to 2.7530. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3450\n",
      "Epoch [428/2000], Avg Train Loss: 4.3450\n",
      "Epoch [428/2000], Avg Val Loss: 2.7520\n",
      "Validation loss improved from 2.7530 to 2.7520. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3075\n",
      "Epoch [429/2000], Avg Train Loss: 4.3075\n",
      "Epoch [429/2000], Avg Val Loss: 2.7509\n",
      "Validation loss improved from 2.7520 to 2.7509. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3564\n",
      "Epoch [430/2000], Avg Train Loss: 4.3564\n",
      "Epoch [430/2000], Avg Val Loss: 2.7499\n",
      "Validation loss improved from 2.7509 to 2.7499. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3642\n",
      "Epoch [431/2000], Avg Train Loss: 4.3642\n",
      "Epoch [431/2000], Avg Val Loss: 2.7489\n",
      "Validation loss improved from 2.7499 to 2.7489. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3567\n",
      "Epoch [432/2000], Avg Train Loss: 4.3567\n",
      "Epoch [432/2000], Avg Val Loss: 2.7479\n",
      "Validation loss improved from 2.7489 to 2.7479. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3230\n",
      "Epoch [433/2000], Avg Train Loss: 4.3230\n",
      "Epoch [433/2000], Avg Val Loss: 2.7469\n",
      "Validation loss improved from 2.7479 to 2.7469. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3968\n",
      "Epoch [434/2000], Avg Train Loss: 4.3968\n",
      "Epoch [434/2000], Avg Val Loss: 2.7460\n",
      "Validation loss improved from 2.7469 to 2.7460. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3726\n",
      "Epoch [435/2000], Avg Train Loss: 4.3726\n",
      "Epoch [435/2000], Avg Val Loss: 2.7450\n",
      "Validation loss improved from 2.7460 to 2.7450. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3602\n",
      "Epoch [436/2000], Avg Train Loss: 4.3602\n",
      "Epoch [436/2000], Avg Val Loss: 2.7440\n",
      "Validation loss improved from 2.7450 to 2.7440. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3193\n",
      "Epoch [437/2000], Avg Train Loss: 4.3193\n",
      "Epoch [437/2000], Avg Val Loss: 2.7430\n",
      "Validation loss improved from 2.7440 to 2.7430. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3136\n",
      "Epoch [438/2000], Avg Train Loss: 4.3136\n",
      "Epoch [438/2000], Avg Val Loss: 2.7420\n",
      "Validation loss improved from 2.7430 to 2.7420. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2944\n",
      "Epoch [439/2000], Avg Train Loss: 4.2944\n",
      "Epoch [439/2000], Avg Val Loss: 2.7410\n",
      "Validation loss improved from 2.7420 to 2.7410. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3192\n",
      "Epoch [440/2000], Avg Train Loss: 4.3192\n",
      "Epoch [440/2000], Avg Val Loss: 2.7399\n",
      "Validation loss improved from 2.7410 to 2.7399. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2891\n",
      "Epoch [441/2000], Avg Train Loss: 4.2891\n",
      "Epoch [441/2000], Avg Val Loss: 2.7389\n",
      "Validation loss improved from 2.7399 to 2.7389. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3010\n",
      "Epoch [442/2000], Avg Train Loss: 4.3010\n",
      "Epoch [442/2000], Avg Val Loss: 2.7379\n",
      "Validation loss improved from 2.7389 to 2.7379. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3398\n",
      "Epoch [443/2000], Avg Train Loss: 4.3398\n",
      "Epoch [443/2000], Avg Val Loss: 2.7368\n",
      "Validation loss improved from 2.7379 to 2.7368. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3015\n",
      "Epoch [444/2000], Avg Train Loss: 4.3015\n",
      "Epoch [444/2000], Avg Val Loss: 2.7358\n",
      "Validation loss improved from 2.7368 to 2.7358. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2924\n",
      "Epoch [445/2000], Avg Train Loss: 4.2924\n",
      "Epoch [445/2000], Avg Val Loss: 2.7349\n",
      "Validation loss improved from 2.7358 to 2.7349. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2996\n",
      "Epoch [446/2000], Avg Train Loss: 4.2996\n",
      "Epoch [446/2000], Avg Val Loss: 2.7338\n",
      "Validation loss improved from 2.7349 to 2.7338. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3358\n",
      "Epoch [447/2000], Avg Train Loss: 4.3358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [447/2000], Avg Val Loss: 2.7328\n",
      "Validation loss improved from 2.7338 to 2.7328. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3195\n",
      "Epoch [448/2000], Avg Train Loss: 4.3195\n",
      "Epoch [448/2000], Avg Val Loss: 2.7318\n",
      "Validation loss improved from 2.7328 to 2.7318. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3029\n",
      "Epoch [449/2000], Avg Train Loss: 4.3029\n",
      "Epoch [449/2000], Avg Val Loss: 2.7308\n",
      "Validation loss improved from 2.7318 to 2.7308. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2746\n",
      "Epoch [450/2000], Avg Train Loss: 4.2746\n",
      "Epoch [450/2000], Avg Val Loss: 2.7299\n",
      "Validation loss improved from 2.7308 to 2.7299. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3417\n",
      "Epoch [451/2000], Avg Train Loss: 4.3417\n",
      "Epoch [451/2000], Avg Val Loss: 2.7289\n",
      "Validation loss improved from 2.7299 to 2.7289. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3071\n",
      "Epoch [452/2000], Avg Train Loss: 4.3071\n",
      "Epoch [452/2000], Avg Val Loss: 2.7280\n",
      "Validation loss improved from 2.7289 to 2.7280. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3005\n",
      "Epoch [453/2000], Avg Train Loss: 4.3005\n",
      "Epoch [453/2000], Avg Val Loss: 2.7270\n",
      "Validation loss improved from 2.7280 to 2.7270. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3000\n",
      "Epoch [454/2000], Avg Train Loss: 4.3000\n",
      "Epoch [454/2000], Avg Val Loss: 2.7261\n",
      "Validation loss improved from 2.7270 to 2.7261. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2996\n",
      "Epoch [455/2000], Avg Train Loss: 4.2996\n",
      "Epoch [455/2000], Avg Val Loss: 2.7252\n",
      "Validation loss improved from 2.7261 to 2.7252. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3025\n",
      "Epoch [456/2000], Avg Train Loss: 4.3025\n",
      "Epoch [456/2000], Avg Val Loss: 2.7242\n",
      "Validation loss improved from 2.7252 to 2.7242. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2807\n",
      "Epoch [457/2000], Avg Train Loss: 4.2807\n",
      "Epoch [457/2000], Avg Val Loss: 2.7233\n",
      "Validation loss improved from 2.7242 to 2.7233. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3084\n",
      "Epoch [458/2000], Avg Train Loss: 4.3084\n",
      "Epoch [458/2000], Avg Val Loss: 2.7223\n",
      "Validation loss improved from 2.7233 to 2.7223. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2705\n",
      "Epoch [459/2000], Avg Train Loss: 4.2705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [459/2000], Avg Val Loss: 2.7214\n",
      "Validation loss improved from 2.7223 to 2.7214. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3103\n",
      "Epoch [460/2000], Avg Train Loss: 4.3103\n",
      "Epoch [460/2000], Avg Val Loss: 2.7204\n",
      "Validation loss improved from 2.7214 to 2.7204. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2830\n",
      "Epoch [461/2000], Avg Train Loss: 4.2830\n",
      "Epoch [461/2000], Avg Val Loss: 2.7194\n",
      "Validation loss improved from 2.7204 to 2.7194. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3100\n",
      "Epoch [462/2000], Avg Train Loss: 4.3100\n",
      "Epoch [462/2000], Avg Val Loss: 2.7184\n",
      "Validation loss improved from 2.7194 to 2.7184. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2932\n",
      "Epoch [463/2000], Avg Train Loss: 4.2932\n",
      "Epoch [463/2000], Avg Val Loss: 2.7174\n",
      "Validation loss improved from 2.7184 to 2.7174. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3162\n",
      "Epoch [464/2000], Avg Train Loss: 4.3162\n",
      "Epoch [464/2000], Avg Val Loss: 2.7163\n",
      "Validation loss improved from 2.7174 to 2.7163. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2720\n",
      "Epoch [465/2000], Avg Train Loss: 4.2720\n",
      "Epoch [465/2000], Avg Val Loss: 2.7152\n",
      "Validation loss improved from 2.7163 to 2.7152. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2600\n",
      "Epoch [466/2000], Avg Train Loss: 4.2600\n",
      "Epoch [466/2000], Avg Val Loss: 2.7142\n",
      "Validation loss improved from 2.7152 to 2.7142. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2818\n",
      "Epoch [467/2000], Avg Train Loss: 4.2818\n",
      "Epoch [467/2000], Avg Val Loss: 2.7131\n",
      "Validation loss improved from 2.7142 to 2.7131. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2916\n",
      "Epoch [468/2000], Avg Train Loss: 4.2916\n",
      "Epoch [468/2000], Avg Val Loss: 2.7120\n",
      "Validation loss improved from 2.7131 to 2.7120. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3051\n",
      "Epoch [469/2000], Avg Train Loss: 4.3051\n",
      "Epoch [469/2000], Avg Val Loss: 2.7110\n",
      "Validation loss improved from 2.7120 to 2.7110. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2879\n",
      "Epoch [470/2000], Avg Train Loss: 4.2879\n",
      "Epoch [470/2000], Avg Val Loss: 2.7099\n",
      "Validation loss improved from 2.7110 to 2.7099. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2723\n",
      "Epoch [471/2000], Avg Train Loss: 4.2723\n",
      "Epoch [471/2000], Avg Val Loss: 2.7089\n",
      "Validation loss improved from 2.7099 to 2.7089. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2978\n",
      "Epoch [472/2000], Avg Train Loss: 4.2978\n",
      "Epoch [472/2000], Avg Val Loss: 2.7079\n",
      "Validation loss improved from 2.7089 to 2.7079. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2712\n",
      "Epoch [473/2000], Avg Train Loss: 4.2712\n",
      "Epoch [473/2000], Avg Val Loss: 2.7069\n",
      "Validation loss improved from 2.7079 to 2.7069. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2890\n",
      "Epoch [474/2000], Avg Train Loss: 4.2890\n",
      "Epoch [474/2000], Avg Val Loss: 2.7058\n",
      "Validation loss improved from 2.7069 to 2.7058. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2986\n",
      "Epoch [475/2000], Avg Train Loss: 4.2986\n",
      "Epoch [475/2000], Avg Val Loss: 2.7048\n",
      "Validation loss improved from 2.7058 to 2.7048. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2697\n",
      "Epoch [476/2000], Avg Train Loss: 4.2697\n",
      "Epoch [476/2000], Avg Val Loss: 2.7037\n",
      "Validation loss improved from 2.7048 to 2.7037. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2741\n",
      "Epoch [477/2000], Avg Train Loss: 4.2741\n",
      "Epoch [477/2000], Avg Val Loss: 2.7027\n",
      "Validation loss improved from 2.7037 to 2.7027. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2254\n",
      "Epoch [478/2000], Avg Train Loss: 4.2254\n",
      "Epoch [478/2000], Avg Val Loss: 2.7016\n",
      "Validation loss improved from 2.7027 to 2.7016. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2788\n",
      "Epoch [479/2000], Avg Train Loss: 4.2788\n",
      "Epoch [479/2000], Avg Val Loss: 2.7005\n",
      "Validation loss improved from 2.7016 to 2.7005. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2718\n",
      "Epoch [480/2000], Avg Train Loss: 4.2718\n",
      "Epoch [480/2000], Avg Val Loss: 2.6995\n",
      "Validation loss improved from 2.7005 to 2.6995. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3064\n",
      "Epoch [481/2000], Avg Train Loss: 4.3064\n",
      "Epoch [481/2000], Avg Val Loss: 2.6985\n",
      "Validation loss improved from 2.6995 to 2.6985. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2892\n",
      "Epoch [482/2000], Avg Train Loss: 4.2892\n",
      "Epoch [482/2000], Avg Val Loss: 2.6976\n",
      "Validation loss improved from 2.6985 to 2.6976. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3300\n",
      "Epoch [483/2000], Avg Train Loss: 4.3300\n",
      "Epoch [483/2000], Avg Val Loss: 2.6967\n",
      "Validation loss improved from 2.6976 to 2.6967. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2759\n",
      "Epoch [484/2000], Avg Train Loss: 4.2759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [484/2000], Avg Val Loss: 2.6958\n",
      "Validation loss improved from 2.6967 to 2.6958. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2841\n",
      "Epoch [485/2000], Avg Train Loss: 4.2841\n",
      "Epoch [485/2000], Avg Val Loss: 2.6949\n",
      "Validation loss improved from 2.6958 to 2.6949. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2350\n",
      "Epoch [486/2000], Avg Train Loss: 4.2350\n",
      "Epoch [486/2000], Avg Val Loss: 2.6939\n",
      "Validation loss improved from 2.6949 to 2.6939. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2983\n",
      "Epoch [487/2000], Avg Train Loss: 4.2983\n",
      "Epoch [487/2000], Avg Val Loss: 2.6930\n",
      "Validation loss improved from 2.6939 to 2.6930. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2875\n",
      "Epoch [488/2000], Avg Train Loss: 4.2875\n",
      "Epoch [488/2000], Avg Val Loss: 2.6921\n",
      "Validation loss improved from 2.6930 to 2.6921. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2546\n",
      "Epoch [489/2000], Avg Train Loss: 4.2546\n",
      "Epoch [489/2000], Avg Val Loss: 2.6912\n",
      "Validation loss improved from 2.6921 to 2.6912. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2529\n",
      "Epoch [490/2000], Avg Train Loss: 4.2529\n",
      "Epoch [490/2000], Avg Val Loss: 2.6903\n",
      "Validation loss improved from 2.6912 to 2.6903. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2638\n",
      "Epoch [491/2000], Avg Train Loss: 4.2638\n",
      "Epoch [491/2000], Avg Val Loss: 2.6894\n",
      "Validation loss improved from 2.6903 to 2.6894. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2380\n",
      "Epoch [492/2000], Avg Train Loss: 4.2380\n",
      "Epoch [492/2000], Avg Val Loss: 2.6885\n",
      "Validation loss improved from 2.6894 to 2.6885. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2540\n",
      "Epoch [493/2000], Avg Train Loss: 4.2540\n",
      "Epoch [493/2000], Avg Val Loss: 2.6876\n",
      "Validation loss improved from 2.6885 to 2.6876. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2164\n",
      "Epoch [494/2000], Avg Train Loss: 4.2164\n",
      "Epoch [494/2000], Avg Val Loss: 2.6867\n",
      "Validation loss improved from 2.6876 to 2.6867. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2216\n",
      "Epoch [495/2000], Avg Train Loss: 4.2216\n",
      "Epoch [495/2000], Avg Val Loss: 2.6858\n",
      "Validation loss improved from 2.6867 to 2.6858. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2171\n",
      "Epoch [496/2000], Avg Train Loss: 4.2171\n",
      "Epoch [496/2000], Avg Val Loss: 2.6849\n",
      "Validation loss improved from 2.6858 to 2.6849. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2036\n",
      "Epoch [497/2000], Avg Train Loss: 4.2036\n",
      "Epoch [497/2000], Avg Val Loss: 2.6840\n",
      "Validation loss improved from 2.6849 to 2.6840. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2498\n",
      "Epoch [498/2000], Avg Train Loss: 4.2498\n",
      "Epoch [498/2000], Avg Val Loss: 2.6831\n",
      "Validation loss improved from 2.6840 to 2.6831. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2618\n",
      "Epoch [499/2000], Avg Train Loss: 4.2618\n",
      "Epoch [499/2000], Avg Val Loss: 2.6822\n",
      "Validation loss improved from 2.6831 to 2.6822. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2388\n",
      "Epoch [500/2000], Avg Train Loss: 4.2388\n",
      "Epoch [500/2000], Avg Val Loss: 2.6813\n",
      "Validation loss improved from 2.6822 to 2.6813. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2665\n",
      "Epoch [501/2000], Avg Train Loss: 4.2665\n",
      "Epoch [501/2000], Avg Val Loss: 2.6804\n",
      "Validation loss improved from 2.6813 to 2.6804. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2743\n",
      "Epoch [502/2000], Avg Train Loss: 4.2743\n",
      "Epoch [502/2000], Avg Val Loss: 2.6795\n",
      "Validation loss improved from 2.6804 to 2.6795. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1962\n",
      "Epoch [503/2000], Avg Train Loss: 4.1962\n",
      "Epoch [503/2000], Avg Val Loss: 2.6787\n",
      "Validation loss improved from 2.6795 to 2.6787. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2430\n",
      "Epoch [504/2000], Avg Train Loss: 4.2430\n",
      "Epoch [504/2000], Avg Val Loss: 2.6779\n",
      "Validation loss improved from 2.6787 to 2.6779. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2305\n",
      "Epoch [505/2000], Avg Train Loss: 4.2305\n",
      "Epoch [505/2000], Avg Val Loss: 2.6770\n",
      "Validation loss improved from 2.6779 to 2.6770. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2336\n",
      "Epoch [506/2000], Avg Train Loss: 4.2336\n",
      "Epoch [506/2000], Avg Val Loss: 2.6762\n",
      "Validation loss improved from 2.6770 to 2.6762. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2581\n",
      "Epoch [507/2000], Avg Train Loss: 4.2581\n",
      "Epoch [507/2000], Avg Val Loss: 2.6754\n",
      "Validation loss improved from 2.6762 to 2.6754. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2453\n",
      "Epoch [508/2000], Avg Train Loss: 4.2453\n",
      "Epoch [508/2000], Avg Val Loss: 2.6746\n",
      "Validation loss improved from 2.6754 to 2.6746. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2832\n",
      "Epoch [509/2000], Avg Train Loss: 4.2832\n",
      "Epoch [509/2000], Avg Val Loss: 2.6738\n",
      "Validation loss improved from 2.6746 to 2.6738. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2318\n",
      "Epoch [510/2000], Avg Train Loss: 4.2318\n",
      "Epoch [510/2000], Avg Val Loss: 2.6730\n",
      "Validation loss improved from 2.6738 to 2.6730. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2295\n",
      "Epoch [511/2000], Avg Train Loss: 4.2295\n",
      "Epoch [511/2000], Avg Val Loss: 2.6722\n",
      "Validation loss improved from 2.6730 to 2.6722. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2263\n",
      "Epoch [512/2000], Avg Train Loss: 4.2263\n",
      "Epoch [512/2000], Avg Val Loss: 2.6714\n",
      "Validation loss improved from 2.6722 to 2.6714. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2139\n",
      "Epoch [513/2000], Avg Train Loss: 4.2139\n",
      "Epoch [513/2000], Avg Val Loss: 2.6705\n",
      "Validation loss improved from 2.6714 to 2.6705. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2203\n",
      "Epoch [514/2000], Avg Train Loss: 4.2203\n",
      "Epoch [514/2000], Avg Val Loss: 2.6696\n",
      "Validation loss improved from 2.6705 to 2.6696. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2473\n",
      "Epoch [515/2000], Avg Train Loss: 4.2473\n",
      "Epoch [515/2000], Avg Val Loss: 2.6688\n",
      "Validation loss improved from 2.6696 to 2.6688. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2426\n",
      "Epoch [516/2000], Avg Train Loss: 4.2426\n",
      "Epoch [516/2000], Avg Val Loss: 2.6680\n",
      "Validation loss improved from 2.6688 to 2.6680. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2355\n",
      "Epoch [517/2000], Avg Train Loss: 4.2355\n",
      "Epoch [517/2000], Avg Val Loss: 2.6672\n",
      "Validation loss improved from 2.6680 to 2.6672. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2190\n",
      "Epoch [518/2000], Avg Train Loss: 4.2190\n",
      "Epoch [518/2000], Avg Val Loss: 2.6663\n",
      "Validation loss improved from 2.6672 to 2.6663. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2108\n",
      "Epoch [519/2000], Avg Train Loss: 4.2108\n",
      "Epoch [519/2000], Avg Val Loss: 2.6655\n",
      "Validation loss improved from 2.6663 to 2.6655. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2132\n",
      "Epoch [520/2000], Avg Train Loss: 4.2132\n",
      "Epoch [520/2000], Avg Val Loss: 2.6646\n",
      "Validation loss improved from 2.6655 to 2.6646. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2008\n",
      "Epoch [521/2000], Avg Train Loss: 4.2008\n",
      "Epoch [521/2000], Avg Val Loss: 2.6638\n",
      "Validation loss improved from 2.6646 to 2.6638. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2359\n",
      "Epoch [522/2000], Avg Train Loss: 4.2359\n",
      "Epoch [522/2000], Avg Val Loss: 2.6629\n",
      "Validation loss improved from 2.6638 to 2.6629. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2568\n",
      "Epoch [523/2000], Avg Train Loss: 4.2568\n",
      "Epoch [523/2000], Avg Val Loss: 2.6620\n",
      "Validation loss improved from 2.6629 to 2.6620. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1982\n",
      "Epoch [524/2000], Avg Train Loss: 4.1982\n",
      "Epoch [524/2000], Avg Val Loss: 2.6612\n",
      "Validation loss improved from 2.6620 to 2.6612. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1862\n",
      "Epoch [525/2000], Avg Train Loss: 4.1862\n",
      "Epoch [525/2000], Avg Val Loss: 2.6603\n",
      "Validation loss improved from 2.6612 to 2.6603. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1966\n",
      "Epoch [526/2000], Avg Train Loss: 4.1966\n",
      "Epoch [526/2000], Avg Val Loss: 2.6594\n",
      "Validation loss improved from 2.6603 to 2.6594. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1371\n",
      "Epoch [527/2000], Avg Train Loss: 4.1371\n",
      "Epoch [527/2000], Avg Val Loss: 2.6585\n",
      "Validation loss improved from 2.6594 to 2.6585. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1401\n",
      "Epoch [528/2000], Avg Train Loss: 4.1401\n",
      "Epoch [528/2000], Avg Val Loss: 2.6577\n",
      "Validation loss improved from 2.6585 to 2.6577. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2311\n",
      "Epoch [529/2000], Avg Train Loss: 4.2311\n",
      "Epoch [529/2000], Avg Val Loss: 2.6568\n",
      "Validation loss improved from 2.6577 to 2.6568. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2034\n",
      "Epoch [530/2000], Avg Train Loss: 4.2034\n",
      "Epoch [530/2000], Avg Val Loss: 2.6560\n",
      "Validation loss improved from 2.6568 to 2.6560. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2135\n",
      "Epoch [531/2000], Avg Train Loss: 4.2135\n",
      "Epoch [531/2000], Avg Val Loss: 2.6551\n",
      "Validation loss improved from 2.6560 to 2.6551. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1773\n",
      "Epoch [532/2000], Avg Train Loss: 4.1773\n",
      "Epoch [532/2000], Avg Val Loss: 2.6543\n",
      "Validation loss improved from 2.6551 to 2.6543. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2330\n",
      "Epoch [533/2000], Avg Train Loss: 4.2330\n",
      "Epoch [533/2000], Avg Val Loss: 2.6534\n",
      "Validation loss improved from 2.6543 to 2.6534. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2493\n",
      "Epoch [534/2000], Avg Train Loss: 4.2493\n",
      "Epoch [534/2000], Avg Val Loss: 2.6526\n",
      "Validation loss improved from 2.6534 to 2.6526. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2163\n",
      "Epoch [535/2000], Avg Train Loss: 4.2163\n",
      "Epoch [535/2000], Avg Val Loss: 2.6517\n",
      "Validation loss improved from 2.6526 to 2.6517. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1604\n",
      "Epoch [536/2000], Avg Train Loss: 4.1604\n",
      "Epoch [536/2000], Avg Val Loss: 2.6509\n",
      "Validation loss improved from 2.6517 to 2.6509. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1864\n",
      "Epoch [537/2000], Avg Train Loss: 4.1864\n",
      "Epoch [537/2000], Avg Val Loss: 2.6500\n",
      "Validation loss improved from 2.6509 to 2.6500. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2094\n",
      "Epoch [538/2000], Avg Train Loss: 4.2094\n",
      "Epoch [538/2000], Avg Val Loss: 2.6491\n",
      "Validation loss improved from 2.6500 to 2.6491. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1323\n",
      "Epoch [539/2000], Avg Train Loss: 4.1323\n",
      "Epoch [539/2000], Avg Val Loss: 2.6483\n",
      "Validation loss improved from 2.6491 to 2.6483. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1781\n",
      "Epoch [540/2000], Avg Train Loss: 4.1781\n",
      "Epoch [540/2000], Avg Val Loss: 2.6474\n",
      "Validation loss improved from 2.6483 to 2.6474. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1885\n",
      "Epoch [541/2000], Avg Train Loss: 4.1885\n",
      "Epoch [541/2000], Avg Val Loss: 2.6466\n",
      "Validation loss improved from 2.6474 to 2.6466. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2228\n",
      "Epoch [542/2000], Avg Train Loss: 4.2228\n",
      "Epoch [542/2000], Avg Val Loss: 2.6458\n",
      "Validation loss improved from 2.6466 to 2.6458. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1962\n",
      "Epoch [543/2000], Avg Train Loss: 4.1962\n",
      "Epoch [543/2000], Avg Val Loss: 2.6450\n",
      "Validation loss improved from 2.6458 to 2.6450. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1833\n",
      "Epoch [544/2000], Avg Train Loss: 4.1833\n",
      "Epoch [544/2000], Avg Val Loss: 2.6442\n",
      "Validation loss improved from 2.6450 to 2.6442. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1687\n",
      "Epoch [545/2000], Avg Train Loss: 4.1687\n",
      "Epoch [545/2000], Avg Val Loss: 2.6433\n",
      "Validation loss improved from 2.6442 to 2.6433. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2097\n",
      "Epoch [546/2000], Avg Train Loss: 4.2097\n",
      "Epoch [546/2000], Avg Val Loss: 2.6426\n",
      "Validation loss improved from 2.6433 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1594\n",
      "Epoch [547/2000], Avg Train Loss: 4.1594\n",
      "Epoch [547/2000], Avg Val Loss: 2.6417\n",
      "Validation loss improved from 2.6426 to 2.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2005\n",
      "Epoch [548/2000], Avg Train Loss: 4.2005\n",
      "Epoch [548/2000], Avg Val Loss: 2.6410\n",
      "Validation loss improved from 2.6417 to 2.6410. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1956\n",
      "Epoch [549/2000], Avg Train Loss: 4.1956\n",
      "Epoch [549/2000], Avg Val Loss: 2.6402\n",
      "Validation loss improved from 2.6410 to 2.6402. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2028\n",
      "Epoch [550/2000], Avg Train Loss: 4.2028\n",
      "Epoch [550/2000], Avg Val Loss: 2.6394\n",
      "Validation loss improved from 2.6402 to 2.6394. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1414\n",
      "Epoch [551/2000], Avg Train Loss: 4.1414\n",
      "Epoch [551/2000], Avg Val Loss: 2.6386\n",
      "Validation loss improved from 2.6394 to 2.6386. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1910\n",
      "Epoch [552/2000], Avg Train Loss: 4.1910\n",
      "Epoch [552/2000], Avg Val Loss: 2.6378\n",
      "Validation loss improved from 2.6386 to 2.6378. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2075\n",
      "Epoch [553/2000], Avg Train Loss: 4.2075\n",
      "Epoch [553/2000], Avg Val Loss: 2.6369\n",
      "Validation loss improved from 2.6378 to 2.6369. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1723\n",
      "Epoch [554/2000], Avg Train Loss: 4.1723\n",
      "Epoch [554/2000], Avg Val Loss: 2.6361\n",
      "Validation loss improved from 2.6369 to 2.6361. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1550\n",
      "Epoch [555/2000], Avg Train Loss: 4.1550\n",
      "Epoch [555/2000], Avg Val Loss: 2.6352\n",
      "Validation loss improved from 2.6361 to 2.6352. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1660\n",
      "Epoch [556/2000], Avg Train Loss: 4.1660\n",
      "Epoch [556/2000], Avg Val Loss: 2.6344\n",
      "Validation loss improved from 2.6352 to 2.6344. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2120\n",
      "Epoch [557/2000], Avg Train Loss: 4.2120\n",
      "Epoch [557/2000], Avg Val Loss: 2.6336\n",
      "Validation loss improved from 2.6344 to 2.6336. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1737\n",
      "Epoch [558/2000], Avg Train Loss: 4.1737\n",
      "Epoch [558/2000], Avg Val Loss: 2.6328\n",
      "Validation loss improved from 2.6336 to 2.6328. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1612\n",
      "Epoch [559/2000], Avg Train Loss: 4.1612\n",
      "Epoch [559/2000], Avg Val Loss: 2.6319\n",
      "Validation loss improved from 2.6328 to 2.6319. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1695\n",
      "Epoch [560/2000], Avg Train Loss: 4.1695\n",
      "Epoch [560/2000], Avg Val Loss: 2.6312\n",
      "Validation loss improved from 2.6319 to 2.6312. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1816\n",
      "Epoch [561/2000], Avg Train Loss: 4.1816\n",
      "Epoch [561/2000], Avg Val Loss: 2.6304\n",
      "Validation loss improved from 2.6312 to 2.6304. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1557\n",
      "Epoch [562/2000], Avg Train Loss: 4.1557\n",
      "Epoch [562/2000], Avg Val Loss: 2.6296\n",
      "Validation loss improved from 2.6304 to 2.6296. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1740\n",
      "Epoch [563/2000], Avg Train Loss: 4.1740\n",
      "Epoch [563/2000], Avg Val Loss: 2.6288\n",
      "Validation loss improved from 2.6296 to 2.6288. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1275\n",
      "Epoch [564/2000], Avg Train Loss: 4.1275\n",
      "Epoch [564/2000], Avg Val Loss: 2.6280\n",
      "Validation loss improved from 2.6288 to 2.6280. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1795\n",
      "Epoch [565/2000], Avg Train Loss: 4.1795\n",
      "Epoch [565/2000], Avg Val Loss: 2.6272\n",
      "Validation loss improved from 2.6280 to 2.6272. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1951\n",
      "Epoch [566/2000], Avg Train Loss: 4.1951\n",
      "Epoch [566/2000], Avg Val Loss: 2.6264\n",
      "Validation loss improved from 2.6272 to 2.6264. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1181\n",
      "Epoch [567/2000], Avg Train Loss: 4.1181\n",
      "Epoch [567/2000], Avg Val Loss: 2.6256\n",
      "Validation loss improved from 2.6264 to 2.6256. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1598\n",
      "Epoch [568/2000], Avg Train Loss: 4.1598\n",
      "Epoch [568/2000], Avg Val Loss: 2.6248\n",
      "Validation loss improved from 2.6256 to 2.6248. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1470\n",
      "Epoch [569/2000], Avg Train Loss: 4.1470\n",
      "Epoch [569/2000], Avg Val Loss: 2.6240\n",
      "Validation loss improved from 2.6248 to 2.6240. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1281\n",
      "Epoch [570/2000], Avg Train Loss: 4.1281\n",
      "Epoch [570/2000], Avg Val Loss: 2.6233\n",
      "Validation loss improved from 2.6240 to 2.6233. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1103\n",
      "Epoch [571/2000], Avg Train Loss: 4.1103\n",
      "Epoch [571/2000], Avg Val Loss: 2.6225\n",
      "Validation loss improved from 2.6233 to 2.6225. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1896\n",
      "Epoch [572/2000], Avg Train Loss: 4.1896\n",
      "Epoch [572/2000], Avg Val Loss: 2.6217\n",
      "Validation loss improved from 2.6225 to 2.6217. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1543\n",
      "Epoch [573/2000], Avg Train Loss: 4.1543\n",
      "Epoch [573/2000], Avg Val Loss: 2.6209\n",
      "Validation loss improved from 2.6217 to 2.6209. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1244\n",
      "Epoch [574/2000], Avg Train Loss: 4.1244\n",
      "Epoch [574/2000], Avg Val Loss: 2.6202\n",
      "Validation loss improved from 2.6209 to 2.6202. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1363\n",
      "Epoch [575/2000], Avg Train Loss: 4.1363\n",
      "Epoch [575/2000], Avg Val Loss: 2.6195\n",
      "Validation loss improved from 2.6202 to 2.6195. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1627\n",
      "Epoch [576/2000], Avg Train Loss: 4.1627\n",
      "Epoch [576/2000], Avg Val Loss: 2.6188\n",
      "Validation loss improved from 2.6195 to 2.6188. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1450\n",
      "Epoch [577/2000], Avg Train Loss: 4.1450\n",
      "Epoch [577/2000], Avg Val Loss: 2.6181\n",
      "Validation loss improved from 2.6188 to 2.6181. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1272\n",
      "Epoch [578/2000], Avg Train Loss: 4.1272\n",
      "Epoch [578/2000], Avg Val Loss: 2.6174\n",
      "Validation loss improved from 2.6181 to 2.6174. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1838\n",
      "Epoch [579/2000], Avg Train Loss: 4.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [579/2000], Avg Val Loss: 2.6167\n",
      "Validation loss improved from 2.6174 to 2.6167. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0832\n",
      "Epoch [580/2000], Avg Train Loss: 4.0832\n",
      "Epoch [580/2000], Avg Val Loss: 2.6160\n",
      "Validation loss improved from 2.6167 to 2.6160. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1210\n",
      "Epoch [581/2000], Avg Train Loss: 4.1210\n",
      "Epoch [581/2000], Avg Val Loss: 2.6153\n",
      "Validation loss improved from 2.6160 to 2.6153. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1231\n",
      "Epoch [582/2000], Avg Train Loss: 4.1231\n",
      "Epoch [582/2000], Avg Val Loss: 2.6146\n",
      "Validation loss improved from 2.6153 to 2.6146. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0908\n",
      "Epoch [583/2000], Avg Train Loss: 4.0908\n",
      "Epoch [583/2000], Avg Val Loss: 2.6139\n",
      "Validation loss improved from 2.6146 to 2.6139. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1648\n",
      "Epoch [584/2000], Avg Train Loss: 4.1648\n",
      "Epoch [584/2000], Avg Val Loss: 2.6132\n",
      "Validation loss improved from 2.6139 to 2.6132. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1074\n",
      "Epoch [585/2000], Avg Train Loss: 4.1074\n",
      "Epoch [585/2000], Avg Val Loss: 2.6125\n",
      "Validation loss improved from 2.6132 to 2.6125. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0757\n",
      "Epoch [586/2000], Avg Train Loss: 4.0757\n",
      "Epoch [586/2000], Avg Val Loss: 2.6118\n",
      "Validation loss improved from 2.6125 to 2.6118. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0966\n",
      "Epoch [587/2000], Avg Train Loss: 4.0966\n",
      "Epoch [587/2000], Avg Val Loss: 2.6111\n",
      "Validation loss improved from 2.6118 to 2.6111. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1593\n",
      "Epoch [588/2000], Avg Train Loss: 4.1593\n",
      "Epoch [588/2000], Avg Val Loss: 2.6104\n",
      "Validation loss improved from 2.6111 to 2.6104. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1362\n",
      "Epoch [589/2000], Avg Train Loss: 4.1362\n",
      "Epoch [589/2000], Avg Val Loss: 2.6097\n",
      "Validation loss improved from 2.6104 to 2.6097. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1231\n",
      "Epoch [590/2000], Avg Train Loss: 4.1231\n",
      "Epoch [590/2000], Avg Val Loss: 2.6090\n",
      "Validation loss improved from 2.6097 to 2.6090. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1476\n",
      "Epoch [591/2000], Avg Train Loss: 4.1476\n",
      "Epoch [591/2000], Avg Val Loss: 2.6083\n",
      "Validation loss improved from 2.6090 to 2.6083. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1686\n",
      "Epoch [592/2000], Avg Train Loss: 4.1686\n",
      "Epoch [592/2000], Avg Val Loss: 2.6077\n",
      "Validation loss improved from 2.6083 to 2.6077. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1368\n",
      "Epoch [593/2000], Avg Train Loss: 4.1368\n",
      "Epoch [593/2000], Avg Val Loss: 2.6071\n",
      "Validation loss improved from 2.6077 to 2.6071. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1446\n",
      "Epoch [594/2000], Avg Train Loss: 4.1446\n",
      "Epoch [594/2000], Avg Val Loss: 2.6064\n",
      "Validation loss improved from 2.6071 to 2.6064. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0903\n",
      "Epoch [595/2000], Avg Train Loss: 4.0903\n",
      "Epoch [595/2000], Avg Val Loss: 2.6058\n",
      "Validation loss improved from 2.6064 to 2.6058. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1311\n",
      "Epoch [596/2000], Avg Train Loss: 4.1311\n",
      "Epoch [596/2000], Avg Val Loss: 2.6051\n",
      "Validation loss improved from 2.6058 to 2.6051. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0920\n",
      "Epoch [597/2000], Avg Train Loss: 4.0920\n",
      "Epoch [597/2000], Avg Val Loss: 2.6044\n",
      "Validation loss improved from 2.6051 to 2.6044. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1159\n",
      "Epoch [598/2000], Avg Train Loss: 4.1159\n",
      "Epoch [598/2000], Avg Val Loss: 2.6038\n",
      "Validation loss improved from 2.6044 to 2.6038. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1305\n",
      "Epoch [599/2000], Avg Train Loss: 4.1305\n",
      "Epoch [599/2000], Avg Val Loss: 2.6031\n",
      "Validation loss improved from 2.6038 to 2.6031. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1397\n",
      "Epoch [600/2000], Avg Train Loss: 4.1397\n",
      "Epoch [600/2000], Avg Val Loss: 2.6024\n",
      "Validation loss improved from 2.6031 to 2.6024. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1650\n",
      "Epoch [601/2000], Avg Train Loss: 4.1650\n",
      "Epoch [601/2000], Avg Val Loss: 2.6017\n",
      "Validation loss improved from 2.6024 to 2.6017. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1036\n",
      "Epoch [602/2000], Avg Train Loss: 4.1036\n",
      "Epoch [602/2000], Avg Val Loss: 2.6010\n",
      "Validation loss improved from 2.6017 to 2.6010. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1249\n",
      "Epoch [603/2000], Avg Train Loss: 4.1249\n",
      "Epoch [603/2000], Avg Val Loss: 2.6004\n",
      "Validation loss improved from 2.6010 to 2.6004. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1175\n",
      "Epoch [604/2000], Avg Train Loss: 4.1175\n",
      "Epoch [604/2000], Avg Val Loss: 2.5997\n",
      "Validation loss improved from 2.6004 to 2.5997. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0681\n",
      "Epoch [605/2000], Avg Train Loss: 4.0681\n",
      "Epoch [605/2000], Avg Val Loss: 2.5989\n",
      "Validation loss improved from 2.5997 to 2.5989. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1210\n",
      "Epoch [606/2000], Avg Train Loss: 4.1210\n",
      "Epoch [606/2000], Avg Val Loss: 2.5981\n",
      "Validation loss improved from 2.5989 to 2.5981. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1341\n",
      "Epoch [607/2000], Avg Train Loss: 4.1341\n",
      "Epoch [607/2000], Avg Val Loss: 2.5974\n",
      "Validation loss improved from 2.5981 to 2.5974. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1334\n",
      "Epoch [608/2000], Avg Train Loss: 4.1334\n",
      "Epoch [608/2000], Avg Val Loss: 2.5967\n",
      "Validation loss improved from 2.5974 to 2.5967. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1131\n",
      "Epoch [609/2000], Avg Train Loss: 4.1131\n",
      "Epoch [609/2000], Avg Val Loss: 2.5960\n",
      "Validation loss improved from 2.5967 to 2.5960. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1011\n",
      "Epoch [610/2000], Avg Train Loss: 4.1011\n",
      "Epoch [610/2000], Avg Val Loss: 2.5953\n",
      "Validation loss improved from 2.5960 to 2.5953. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0883\n",
      "Epoch [611/2000], Avg Train Loss: 4.0883\n",
      "Epoch [611/2000], Avg Val Loss: 2.5946\n",
      "Validation loss improved from 2.5953 to 2.5946. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0891\n",
      "Epoch [612/2000], Avg Train Loss: 4.0891\n",
      "Epoch [612/2000], Avg Val Loss: 2.5939\n",
      "Validation loss improved from 2.5946 to 2.5939. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0902\n",
      "Epoch [613/2000], Avg Train Loss: 4.0902\n",
      "Epoch [613/2000], Avg Val Loss: 2.5933\n",
      "Validation loss improved from 2.5939 to 2.5933. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0749\n",
      "Epoch [614/2000], Avg Train Loss: 4.0749\n",
      "Epoch [614/2000], Avg Val Loss: 2.5926\n",
      "Validation loss improved from 2.5933 to 2.5926. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1087\n",
      "Epoch [615/2000], Avg Train Loss: 4.1087\n",
      "Epoch [615/2000], Avg Val Loss: 2.5918\n",
      "Validation loss improved from 2.5926 to 2.5918. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1037\n",
      "Epoch [616/2000], Avg Train Loss: 4.1037\n",
      "Epoch [616/2000], Avg Val Loss: 2.5912\n",
      "Validation loss improved from 2.5918 to 2.5912. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1188\n",
      "Epoch [617/2000], Avg Train Loss: 4.1188\n",
      "Epoch [617/2000], Avg Val Loss: 2.5905\n",
      "Validation loss improved from 2.5912 to 2.5905. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1011\n",
      "Epoch [618/2000], Avg Train Loss: 4.1011\n",
      "Epoch [618/2000], Avg Val Loss: 2.5898\n",
      "Validation loss improved from 2.5905 to 2.5898. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1050\n",
      "Epoch [619/2000], Avg Train Loss: 4.1050\n",
      "Epoch [619/2000], Avg Val Loss: 2.5892\n",
      "Validation loss improved from 2.5898 to 2.5892. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0684\n",
      "Epoch [620/2000], Avg Train Loss: 4.0684\n",
      "Epoch [620/2000], Avg Val Loss: 2.5885\n",
      "Validation loss improved from 2.5892 to 2.5885. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0596\n",
      "Epoch [621/2000], Avg Train Loss: 4.0596\n",
      "Epoch [621/2000], Avg Val Loss: 2.5878\n",
      "Validation loss improved from 2.5885 to 2.5878. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0339\n",
      "Epoch [622/2000], Avg Train Loss: 4.0339\n",
      "Epoch [622/2000], Avg Val Loss: 2.5871\n",
      "Validation loss improved from 2.5878 to 2.5871. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1052\n",
      "Epoch [623/2000], Avg Train Loss: 4.1052\n",
      "Epoch [623/2000], Avg Val Loss: 2.5864\n",
      "Validation loss improved from 2.5871 to 2.5864. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0332\n",
      "Epoch [624/2000], Avg Train Loss: 4.0332\n",
      "Epoch [624/2000], Avg Val Loss: 2.5856\n",
      "Validation loss improved from 2.5864 to 2.5856. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1026\n",
      "Epoch [625/2000], Avg Train Loss: 4.1026\n",
      "Epoch [625/2000], Avg Val Loss: 2.5848\n",
      "Validation loss improved from 2.5856 to 2.5848. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0731\n",
      "Epoch [626/2000], Avg Train Loss: 4.0731\n",
      "Epoch [626/2000], Avg Val Loss: 2.5841\n",
      "Validation loss improved from 2.5848 to 2.5841. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0853\n",
      "Epoch [627/2000], Avg Train Loss: 4.0853\n",
      "Epoch [627/2000], Avg Val Loss: 2.5834\n",
      "Validation loss improved from 2.5841 to 2.5834. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0616\n",
      "Epoch [628/2000], Avg Train Loss: 4.0616\n",
      "Epoch [628/2000], Avg Val Loss: 2.5826\n",
      "Validation loss improved from 2.5834 to 2.5826. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0681\n",
      "Epoch [629/2000], Avg Train Loss: 4.0681\n",
      "Epoch [629/2000], Avg Val Loss: 2.5820\n",
      "Validation loss improved from 2.5826 to 2.5820. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0568\n",
      "Epoch [630/2000], Avg Train Loss: 4.0568\n",
      "Epoch [630/2000], Avg Val Loss: 2.5813\n",
      "Validation loss improved from 2.5820 to 2.5813. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1067\n",
      "Epoch [631/2000], Avg Train Loss: 4.1067\n",
      "Epoch [631/2000], Avg Val Loss: 2.5806\n",
      "Validation loss improved from 2.5813 to 2.5806. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0938\n",
      "Epoch [632/2000], Avg Train Loss: 4.0938\n",
      "Epoch [632/2000], Avg Val Loss: 2.5799\n",
      "Validation loss improved from 2.5806 to 2.5799. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0754\n",
      "Epoch [633/2000], Avg Train Loss: 4.0754\n",
      "Epoch [633/2000], Avg Val Loss: 2.5792\n",
      "Validation loss improved from 2.5799 to 2.5792. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1243\n",
      "Epoch [634/2000], Avg Train Loss: 4.1243\n",
      "Epoch [634/2000], Avg Val Loss: 2.5785\n",
      "Validation loss improved from 2.5792 to 2.5785. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0663\n",
      "Epoch [635/2000], Avg Train Loss: 4.0663\n",
      "Epoch [635/2000], Avg Val Loss: 2.5779\n",
      "Validation loss improved from 2.5785 to 2.5779. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0618\n",
      "Epoch [636/2000], Avg Train Loss: 4.0618\n",
      "Epoch [636/2000], Avg Val Loss: 2.5772\n",
      "Validation loss improved from 2.5779 to 2.5772. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0751\n",
      "Epoch [637/2000], Avg Train Loss: 4.0751\n",
      "Epoch [637/2000], Avg Val Loss: 2.5765\n",
      "Validation loss improved from 2.5772 to 2.5765. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1399\n",
      "Epoch [638/2000], Avg Train Loss: 4.1399\n",
      "Epoch [638/2000], Avg Val Loss: 2.5759\n",
      "Validation loss improved from 2.5765 to 2.5759. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0695\n",
      "Epoch [639/2000], Avg Train Loss: 4.0695\n",
      "Epoch [639/2000], Avg Val Loss: 2.5752\n",
      "Validation loss improved from 2.5759 to 2.5752. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1079\n",
      "Epoch [640/2000], Avg Train Loss: 4.1079\n",
      "Epoch [640/2000], Avg Val Loss: 2.5746\n",
      "Validation loss improved from 2.5752 to 2.5746. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0799\n",
      "Epoch [641/2000], Avg Train Loss: 4.0799\n",
      "Epoch [641/2000], Avg Val Loss: 2.5740\n",
      "Validation loss improved from 2.5746 to 2.5740. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0905\n",
      "Epoch [642/2000], Avg Train Loss: 4.0905\n",
      "Epoch [642/2000], Avg Val Loss: 2.5733\n",
      "Validation loss improved from 2.5740 to 2.5733. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0578\n",
      "Epoch [643/2000], Avg Train Loss: 4.0578\n",
      "Epoch [643/2000], Avg Val Loss: 2.5727\n",
      "Validation loss improved from 2.5733 to 2.5727. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0470\n",
      "Epoch [644/2000], Avg Train Loss: 4.0470\n",
      "Epoch [644/2000], Avg Val Loss: 2.5721\n",
      "Validation loss improved from 2.5727 to 2.5721. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0230\n",
      "Epoch [645/2000], Avg Train Loss: 4.0230\n",
      "Epoch [645/2000], Avg Val Loss: 2.5715\n",
      "Validation loss improved from 2.5721 to 2.5715. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0554\n",
      "Epoch [646/2000], Avg Train Loss: 4.0554\n",
      "Epoch [646/2000], Avg Val Loss: 2.5709\n",
      "Validation loss improved from 2.5715 to 2.5709. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0250\n",
      "Epoch [647/2000], Avg Train Loss: 4.0250\n",
      "Epoch [647/2000], Avg Val Loss: 2.5702\n",
      "Validation loss improved from 2.5709 to 2.5702. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0451\n",
      "Epoch [648/2000], Avg Train Loss: 4.0451\n",
      "Epoch [648/2000], Avg Val Loss: 2.5696\n",
      "Validation loss improved from 2.5702 to 2.5696. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0478\n",
      "Epoch [649/2000], Avg Train Loss: 4.0478\n",
      "Epoch [649/2000], Avg Val Loss: 2.5690\n",
      "Validation loss improved from 2.5696 to 2.5690. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0379\n",
      "Epoch [650/2000], Avg Train Loss: 4.0379\n",
      "Epoch [650/2000], Avg Val Loss: 2.5684\n",
      "Validation loss improved from 2.5690 to 2.5684. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0451\n",
      "Epoch [651/2000], Avg Train Loss: 4.0451\n",
      "Epoch [651/2000], Avg Val Loss: 2.5678\n",
      "Validation loss improved from 2.5684 to 2.5678. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0481\n",
      "Epoch [652/2000], Avg Train Loss: 4.0481\n",
      "Epoch [652/2000], Avg Val Loss: 2.5672\n",
      "Validation loss improved from 2.5678 to 2.5672. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0293\n",
      "Epoch [653/2000], Avg Train Loss: 4.0293\n",
      "Epoch [653/2000], Avg Val Loss: 2.5667\n",
      "Validation loss improved from 2.5672 to 2.5667. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0502\n",
      "Epoch [654/2000], Avg Train Loss: 4.0502\n",
      "Epoch [654/2000], Avg Val Loss: 2.5661\n",
      "Validation loss improved from 2.5667 to 2.5661. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0321\n",
      "Epoch [655/2000], Avg Train Loss: 4.0321\n",
      "Epoch [655/2000], Avg Val Loss: 2.5656\n",
      "Validation loss improved from 2.5661 to 2.5656. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0502\n",
      "Epoch [656/2000], Avg Train Loss: 4.0502\n",
      "Epoch [656/2000], Avg Val Loss: 2.5650\n",
      "Validation loss improved from 2.5656 to 2.5650. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0176\n",
      "Epoch [657/2000], Avg Train Loss: 4.0176\n",
      "Epoch [657/2000], Avg Val Loss: 2.5644\n",
      "Validation loss improved from 2.5650 to 2.5644. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0915\n",
      "Epoch [658/2000], Avg Train Loss: 4.0915\n",
      "Epoch [658/2000], Avg Val Loss: 2.5638\n",
      "Validation loss improved from 2.5644 to 2.5638. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0404\n",
      "Epoch [659/2000], Avg Train Loss: 4.0404\n",
      "Epoch [659/2000], Avg Val Loss: 2.5632\n",
      "Validation loss improved from 2.5638 to 2.5632. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0554\n",
      "Epoch [660/2000], Avg Train Loss: 4.0554\n",
      "Epoch [660/2000], Avg Val Loss: 2.5627\n",
      "Validation loss improved from 2.5632 to 2.5627. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0523\n",
      "Epoch [661/2000], Avg Train Loss: 4.0523\n",
      "Epoch [661/2000], Avg Val Loss: 2.5622\n",
      "Validation loss improved from 2.5627 to 2.5622. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0431\n",
      "Epoch [662/2000], Avg Train Loss: 4.0431\n",
      "Epoch [662/2000], Avg Val Loss: 2.5616\n",
      "Validation loss improved from 2.5622 to 2.5616. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0257\n",
      "Epoch [663/2000], Avg Train Loss: 4.0257\n",
      "Epoch [663/2000], Avg Val Loss: 2.5611\n",
      "Validation loss improved from 2.5616 to 2.5611. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0382\n",
      "Epoch [664/2000], Avg Train Loss: 4.0382\n",
      "Epoch [664/2000], Avg Val Loss: 2.5606\n",
      "Validation loss improved from 2.5611 to 2.5606. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0482\n",
      "Epoch [665/2000], Avg Train Loss: 4.0482\n",
      "Epoch [665/2000], Avg Val Loss: 2.5602\n",
      "Validation loss improved from 2.5606 to 2.5602. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0314\n",
      "Epoch [666/2000], Avg Train Loss: 4.0314\n",
      "Epoch [666/2000], Avg Val Loss: 2.5597\n",
      "Validation loss improved from 2.5602 to 2.5597. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0629\n",
      "Epoch [667/2000], Avg Train Loss: 4.0629\n",
      "Epoch [667/2000], Avg Val Loss: 2.5593\n",
      "Validation loss improved from 2.5597 to 2.5593. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0181\n",
      "Epoch [668/2000], Avg Train Loss: 4.0181\n",
      "Epoch [668/2000], Avg Val Loss: 2.5587\n",
      "Validation loss improved from 2.5593 to 2.5587. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0201\n",
      "Epoch [669/2000], Avg Train Loss: 4.0201\n",
      "Epoch [669/2000], Avg Val Loss: 2.5582\n",
      "Validation loss improved from 2.5587 to 2.5582. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0333\n",
      "Epoch [670/2000], Avg Train Loss: 4.0333\n",
      "Epoch [670/2000], Avg Val Loss: 2.5577\n",
      "Validation loss improved from 2.5582 to 2.5577. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0122\n",
      "Epoch [671/2000], Avg Train Loss: 4.0122\n",
      "Epoch [671/2000], Avg Val Loss: 2.5570\n",
      "Validation loss improved from 2.5577 to 2.5570. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0043\n",
      "Epoch [672/2000], Avg Train Loss: 4.0043\n",
      "Epoch [672/2000], Avg Val Loss: 2.5564\n",
      "Validation loss improved from 2.5570 to 2.5564. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0400\n",
      "Epoch [673/2000], Avg Train Loss: 4.0400\n",
      "Epoch [673/2000], Avg Val Loss: 2.5557\n",
      "Validation loss improved from 2.5564 to 2.5557. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0058\n",
      "Epoch [674/2000], Avg Train Loss: 4.0058\n",
      "Epoch [674/2000], Avg Val Loss: 2.5551\n",
      "Validation loss improved from 2.5557 to 2.5551. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0225\n",
      "Epoch [675/2000], Avg Train Loss: 4.0225\n",
      "Epoch [675/2000], Avg Val Loss: 2.5545\n",
      "Validation loss improved from 2.5551 to 2.5545. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0483\n",
      "Epoch [676/2000], Avg Train Loss: 4.0483\n",
      "Epoch [676/2000], Avg Val Loss: 2.5538\n",
      "Validation loss improved from 2.5545 to 2.5538. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0423\n",
      "Epoch [677/2000], Avg Train Loss: 4.0423\n",
      "Epoch [677/2000], Avg Val Loss: 2.5532\n",
      "Validation loss improved from 2.5538 to 2.5532. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9842\n",
      "Epoch [678/2000], Avg Train Loss: 3.9842\n",
      "Epoch [678/2000], Avg Val Loss: 2.5526\n",
      "Validation loss improved from 2.5532 to 2.5526. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0033\n",
      "Epoch [679/2000], Avg Train Loss: 4.0033\n",
      "Epoch [679/2000], Avg Val Loss: 2.5520\n",
      "Validation loss improved from 2.5526 to 2.5520. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0017\n",
      "Epoch [680/2000], Avg Train Loss: 4.0017\n",
      "Epoch [680/2000], Avg Val Loss: 2.5514\n",
      "Validation loss improved from 2.5520 to 2.5514. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0160\n",
      "Epoch [681/2000], Avg Train Loss: 4.0160\n",
      "Epoch [681/2000], Avg Val Loss: 2.5507\n",
      "Validation loss improved from 2.5514 to 2.5507. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0440\n",
      "Epoch [682/2000], Avg Train Loss: 4.0440\n",
      "Epoch [682/2000], Avg Val Loss: 2.5501\n",
      "Validation loss improved from 2.5507 to 2.5501. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0186\n",
      "Epoch [683/2000], Avg Train Loss: 4.0186\n",
      "Epoch [683/2000], Avg Val Loss: 2.5496\n",
      "Validation loss improved from 2.5501 to 2.5496. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0127\n",
      "Epoch [684/2000], Avg Train Loss: 4.0127\n",
      "Epoch [684/2000], Avg Val Loss: 2.5491\n",
      "Validation loss improved from 2.5496 to 2.5491. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0186\n",
      "Epoch [685/2000], Avg Train Loss: 4.0186\n",
      "Epoch [685/2000], Avg Val Loss: 2.5485\n",
      "Validation loss improved from 2.5491 to 2.5485. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0110\n",
      "Epoch [686/2000], Avg Train Loss: 4.0110\n",
      "Epoch [686/2000], Avg Val Loss: 2.5480\n",
      "Validation loss improved from 2.5485 to 2.5480. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0018\n",
      "Epoch [687/2000], Avg Train Loss: 4.0018\n",
      "Epoch [687/2000], Avg Val Loss: 2.5475\n",
      "Validation loss improved from 2.5480 to 2.5475. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0323\n",
      "Epoch [688/2000], Avg Train Loss: 4.0323\n",
      "Epoch [688/2000], Avg Val Loss: 2.5470\n",
      "Validation loss improved from 2.5475 to 2.5470. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0348\n",
      "Epoch [689/2000], Avg Train Loss: 4.0348\n",
      "Epoch [689/2000], Avg Val Loss: 2.5464\n",
      "Validation loss improved from 2.5470 to 2.5464. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0260\n",
      "Epoch [690/2000], Avg Train Loss: 4.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [690/2000], Avg Val Loss: 2.5459\n",
      "Validation loss improved from 2.5464 to 2.5459. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0371\n",
      "Epoch [691/2000], Avg Train Loss: 4.0371\n",
      "Epoch [691/2000], Avg Val Loss: 2.5453\n",
      "Validation loss improved from 2.5459 to 2.5453. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0317\n",
      "Epoch [692/2000], Avg Train Loss: 4.0317\n",
      "Epoch [692/2000], Avg Val Loss: 2.5448\n",
      "Validation loss improved from 2.5453 to 2.5448. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9916\n",
      "Epoch [693/2000], Avg Train Loss: 3.9916\n",
      "Epoch [693/2000], Avg Val Loss: 2.5442\n",
      "Validation loss improved from 2.5448 to 2.5442. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0500\n",
      "Epoch [694/2000], Avg Train Loss: 4.0500\n",
      "Epoch [694/2000], Avg Val Loss: 2.5437\n",
      "Validation loss improved from 2.5442 to 2.5437. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9851\n",
      "Epoch [695/2000], Avg Train Loss: 3.9851\n",
      "Epoch [695/2000], Avg Val Loss: 2.5432\n",
      "Validation loss improved from 2.5437 to 2.5432. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0145\n",
      "Epoch [696/2000], Avg Train Loss: 4.0145\n",
      "Epoch [696/2000], Avg Val Loss: 2.5426\n",
      "Validation loss improved from 2.5432 to 2.5426. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0066\n",
      "Epoch [697/2000], Avg Train Loss: 4.0066\n",
      "Epoch [697/2000], Avg Val Loss: 2.5421\n",
      "Validation loss improved from 2.5426 to 2.5421. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0330\n",
      "Epoch [698/2000], Avg Train Loss: 4.0330\n",
      "Epoch [698/2000], Avg Val Loss: 2.5416\n",
      "Validation loss improved from 2.5421 to 2.5416. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9723\n",
      "Epoch [699/2000], Avg Train Loss: 3.9723\n",
      "Epoch [699/2000], Avg Val Loss: 2.5410\n",
      "Validation loss improved from 2.5416 to 2.5410. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9921\n",
      "Epoch [700/2000], Avg Train Loss: 3.9921\n",
      "Epoch [700/2000], Avg Val Loss: 2.5405\n",
      "Validation loss improved from 2.5410 to 2.5405. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9745\n",
      "Epoch [701/2000], Avg Train Loss: 3.9745\n",
      "Epoch [701/2000], Avg Val Loss: 2.5398\n",
      "Validation loss improved from 2.5405 to 2.5398. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9863\n",
      "Epoch [702/2000], Avg Train Loss: 3.9863\n",
      "Epoch [702/2000], Avg Val Loss: 2.5392\n",
      "Validation loss improved from 2.5398 to 2.5392. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9985\n",
      "Epoch [703/2000], Avg Train Loss: 3.9985\n",
      "Epoch [703/2000], Avg Val Loss: 2.5386\n",
      "Validation loss improved from 2.5392 to 2.5386. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9919\n",
      "Epoch [704/2000], Avg Train Loss: 3.9919\n",
      "Epoch [704/2000], Avg Val Loss: 2.5380\n",
      "Validation loss improved from 2.5386 to 2.5380. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9899\n",
      "Epoch [705/2000], Avg Train Loss: 3.9899\n",
      "Epoch [705/2000], Avg Val Loss: 2.5374\n",
      "Validation loss improved from 2.5380 to 2.5374. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9393\n",
      "Epoch [706/2000], Avg Train Loss: 3.9393\n",
      "Epoch [706/2000], Avg Val Loss: 2.5367\n",
      "Validation loss improved from 2.5374 to 2.5367. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9812\n",
      "Epoch [707/2000], Avg Train Loss: 3.9812\n",
      "Epoch [707/2000], Avg Val Loss: 2.5361\n",
      "Validation loss improved from 2.5367 to 2.5361. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0307\n",
      "Epoch [708/2000], Avg Train Loss: 4.0307\n",
      "Epoch [708/2000], Avg Val Loss: 2.5355\n",
      "Validation loss improved from 2.5361 to 2.5355. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9784\n",
      "Epoch [709/2000], Avg Train Loss: 3.9784\n",
      "Epoch [709/2000], Avg Val Loss: 2.5348\n",
      "Validation loss improved from 2.5355 to 2.5348. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0058\n",
      "Epoch [710/2000], Avg Train Loss: 4.0058\n",
      "Epoch [710/2000], Avg Val Loss: 2.5342\n",
      "Validation loss improved from 2.5348 to 2.5342. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0400\n",
      "Epoch [711/2000], Avg Train Loss: 4.0400\n",
      "Epoch [711/2000], Avg Val Loss: 2.5335\n",
      "Validation loss improved from 2.5342 to 2.5335. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0151\n",
      "Epoch [712/2000], Avg Train Loss: 4.0151\n",
      "Epoch [712/2000], Avg Val Loss: 2.5330\n",
      "Validation loss improved from 2.5335 to 2.5330. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9687\n",
      "Epoch [713/2000], Avg Train Loss: 3.9687\n",
      "Epoch [713/2000], Avg Val Loss: 2.5324\n",
      "Validation loss improved from 2.5330 to 2.5324. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0011\n",
      "Epoch [714/2000], Avg Train Loss: 4.0011\n",
      "Epoch [714/2000], Avg Val Loss: 2.5319\n",
      "Validation loss improved from 2.5324 to 2.5319. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0058\n",
      "Epoch [715/2000], Avg Train Loss: 4.0058\n",
      "Epoch [715/2000], Avg Val Loss: 2.5313\n",
      "Validation loss improved from 2.5319 to 2.5313. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9827\n",
      "Epoch [716/2000], Avg Train Loss: 3.9827\n",
      "Epoch [716/2000], Avg Val Loss: 2.5308\n",
      "Validation loss improved from 2.5313 to 2.5308. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9980\n",
      "Epoch [717/2000], Avg Train Loss: 3.9980\n",
      "Epoch [717/2000], Avg Val Loss: 2.5303\n",
      "Validation loss improved from 2.5308 to 2.5303. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9424\n",
      "Epoch [718/2000], Avg Train Loss: 3.9424\n",
      "Epoch [718/2000], Avg Val Loss: 2.5297\n",
      "Validation loss improved from 2.5303 to 2.5297. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9491\n",
      "Epoch [719/2000], Avg Train Loss: 3.9491\n",
      "Epoch [719/2000], Avg Val Loss: 2.5292\n",
      "Validation loss improved from 2.5297 to 2.5292. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9894\n",
      "Epoch [720/2000], Avg Train Loss: 3.9894\n",
      "Epoch [720/2000], Avg Val Loss: 2.5286\n",
      "Validation loss improved from 2.5292 to 2.5286. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9381\n",
      "Epoch [721/2000], Avg Train Loss: 3.9381\n",
      "Epoch [721/2000], Avg Val Loss: 2.5281\n",
      "Validation loss improved from 2.5286 to 2.5281. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9528\n",
      "Epoch [722/2000], Avg Train Loss: 3.9528\n",
      "Epoch [722/2000], Avg Val Loss: 2.5276\n",
      "Validation loss improved from 2.5281 to 2.5276. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9672\n",
      "Epoch [723/2000], Avg Train Loss: 3.9672\n",
      "Epoch [723/2000], Avg Val Loss: 2.5270\n",
      "Validation loss improved from 2.5276 to 2.5270. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9544\n",
      "Epoch [724/2000], Avg Train Loss: 3.9544\n",
      "Epoch [724/2000], Avg Val Loss: 2.5264\n",
      "Validation loss improved from 2.5270 to 2.5264. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9411\n",
      "Epoch [725/2000], Avg Train Loss: 3.9411\n",
      "Epoch [725/2000], Avg Val Loss: 2.5257\n",
      "Validation loss improved from 2.5264 to 2.5257. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9987\n",
      "Epoch [726/2000], Avg Train Loss: 3.9987\n",
      "Epoch [726/2000], Avg Val Loss: 2.5251\n",
      "Validation loss improved from 2.5257 to 2.5251. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9672\n",
      "Epoch [727/2000], Avg Train Loss: 3.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [727/2000], Avg Val Loss: 2.5244\n",
      "Validation loss improved from 2.5251 to 2.5244. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9759\n",
      "Epoch [728/2000], Avg Train Loss: 3.9759\n",
      "Epoch [728/2000], Avg Val Loss: 2.5238\n",
      "Validation loss improved from 2.5244 to 2.5238. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9760\n",
      "Epoch [729/2000], Avg Train Loss: 3.9760\n",
      "Epoch [729/2000], Avg Val Loss: 2.5231\n",
      "Validation loss improved from 2.5238 to 2.5231. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0046\n",
      "Epoch [730/2000], Avg Train Loss: 4.0046\n",
      "Epoch [730/2000], Avg Val Loss: 2.5225\n",
      "Validation loss improved from 2.5231 to 2.5225. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0019\n",
      "Epoch [731/2000], Avg Train Loss: 4.0019\n",
      "Epoch [731/2000], Avg Val Loss: 2.5218\n",
      "Validation loss improved from 2.5225 to 2.5218. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0061\n",
      "Epoch [732/2000], Avg Train Loss: 4.0061\n",
      "Epoch [732/2000], Avg Val Loss: 2.5212\n",
      "Validation loss improved from 2.5218 to 2.5212. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9780\n",
      "Epoch [733/2000], Avg Train Loss: 3.9780\n",
      "Epoch [733/2000], Avg Val Loss: 2.5206\n",
      "Validation loss improved from 2.5212 to 2.5206. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9824\n",
      "Epoch [734/2000], Avg Train Loss: 3.9824\n",
      "Epoch [734/2000], Avg Val Loss: 2.5200\n",
      "Validation loss improved from 2.5206 to 2.5200. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9261\n",
      "Epoch [735/2000], Avg Train Loss: 3.9261\n",
      "Epoch [735/2000], Avg Val Loss: 2.5194\n",
      "Validation loss improved from 2.5200 to 2.5194. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9798\n",
      "Epoch [736/2000], Avg Train Loss: 3.9798\n",
      "Epoch [736/2000], Avg Val Loss: 2.5188\n",
      "Validation loss improved from 2.5194 to 2.5188. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9468\n",
      "Epoch [737/2000], Avg Train Loss: 3.9468\n",
      "Epoch [737/2000], Avg Val Loss: 2.5181\n",
      "Validation loss improved from 2.5188 to 2.5181. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9323\n",
      "Epoch [738/2000], Avg Train Loss: 3.9323\n",
      "Epoch [738/2000], Avg Val Loss: 2.5175\n",
      "Validation loss improved from 2.5181 to 2.5175. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9697\n",
      "Epoch [739/2000], Avg Train Loss: 3.9697\n",
      "Epoch [739/2000], Avg Val Loss: 2.5168\n",
      "Validation loss improved from 2.5175 to 2.5168. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9576\n",
      "Epoch [740/2000], Avg Train Loss: 3.9576\n",
      "Epoch [740/2000], Avg Val Loss: 2.5162\n",
      "Validation loss improved from 2.5168 to 2.5162. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9603\n",
      "Epoch [741/2000], Avg Train Loss: 3.9603\n",
      "Epoch [741/2000], Avg Val Loss: 2.5156\n",
      "Validation loss improved from 2.5162 to 2.5156. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9589\n",
      "Epoch [742/2000], Avg Train Loss: 3.9589\n",
      "Epoch [742/2000], Avg Val Loss: 2.5151\n",
      "Validation loss improved from 2.5156 to 2.5151. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9491\n",
      "Epoch [743/2000], Avg Train Loss: 3.9491\n",
      "Epoch [743/2000], Avg Val Loss: 2.5145\n",
      "Validation loss improved from 2.5151 to 2.5145. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9722\n",
      "Epoch [744/2000], Avg Train Loss: 3.9722\n",
      "Epoch [744/2000], Avg Val Loss: 2.5140\n",
      "Validation loss improved from 2.5145 to 2.5140. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9600\n",
      "Epoch [745/2000], Avg Train Loss: 3.9600\n",
      "Epoch [745/2000], Avg Val Loss: 2.5134\n",
      "Validation loss improved from 2.5140 to 2.5134. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9675\n",
      "Epoch [746/2000], Avg Train Loss: 3.9675\n",
      "Epoch [746/2000], Avg Val Loss: 2.5128\n",
      "Validation loss improved from 2.5134 to 2.5128. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9284\n",
      "Epoch [747/2000], Avg Train Loss: 3.9284\n",
      "Epoch [747/2000], Avg Val Loss: 2.5122\n",
      "Validation loss improved from 2.5128 to 2.5122. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9839\n",
      "Epoch [748/2000], Avg Train Loss: 3.9839\n",
      "Epoch [748/2000], Avg Val Loss: 2.5117\n",
      "Validation loss improved from 2.5122 to 2.5117. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9786\n",
      "Epoch [749/2000], Avg Train Loss: 3.9786\n",
      "Epoch [749/2000], Avg Val Loss: 2.5112\n",
      "Validation loss improved from 2.5117 to 2.5112. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9967\n",
      "Epoch [750/2000], Avg Train Loss: 3.9967\n",
      "Epoch [750/2000], Avg Val Loss: 2.5108\n",
      "Validation loss improved from 2.5112 to 2.5108. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9102\n",
      "Epoch [751/2000], Avg Train Loss: 3.9102\n",
      "Epoch [751/2000], Avg Val Loss: 2.5103\n",
      "Validation loss improved from 2.5108 to 2.5103. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9288\n",
      "Epoch [752/2000], Avg Train Loss: 3.9288\n",
      "Epoch [752/2000], Avg Val Loss: 2.5099\n",
      "Validation loss improved from 2.5103 to 2.5099. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9540\n",
      "Epoch [753/2000], Avg Train Loss: 3.9540\n",
      "Epoch [753/2000], Avg Val Loss: 2.5094\n",
      "Validation loss improved from 2.5099 to 2.5094. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9491\n",
      "Epoch [754/2000], Avg Train Loss: 3.9491\n",
      "Epoch [754/2000], Avg Val Loss: 2.5090\n",
      "Validation loss improved from 2.5094 to 2.5090. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9346\n",
      "Epoch [755/2000], Avg Train Loss: 3.9346\n",
      "Epoch [755/2000], Avg Val Loss: 2.5085\n",
      "Validation loss improved from 2.5090 to 2.5085. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9433\n",
      "Epoch [756/2000], Avg Train Loss: 3.9433\n",
      "Epoch [756/2000], Avg Val Loss: 2.5079\n",
      "Validation loss improved from 2.5085 to 2.5079. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9019\n",
      "Epoch [757/2000], Avg Train Loss: 3.9019\n",
      "Epoch [757/2000], Avg Val Loss: 2.5074\n",
      "Validation loss improved from 2.5079 to 2.5074. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9410\n",
      "Epoch [758/2000], Avg Train Loss: 3.9410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [758/2000], Avg Val Loss: 2.5068\n",
      "Validation loss improved from 2.5074 to 2.5068. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9524\n",
      "Epoch [759/2000], Avg Train Loss: 3.9524\n",
      "Epoch [759/2000], Avg Val Loss: 2.5063\n",
      "Validation loss improved from 2.5068 to 2.5063. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9718\n",
      "Epoch [760/2000], Avg Train Loss: 3.9718\n",
      "Epoch [760/2000], Avg Val Loss: 2.5059\n",
      "Validation loss improved from 2.5063 to 2.5059. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9699\n",
      "Epoch [761/2000], Avg Train Loss: 3.9699\n",
      "Epoch [761/2000], Avg Val Loss: 2.5054\n",
      "Validation loss improved from 2.5059 to 2.5054. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9547\n",
      "Epoch [762/2000], Avg Train Loss: 3.9547\n",
      "Epoch [762/2000], Avg Val Loss: 2.5050\n",
      "Validation loss improved from 2.5054 to 2.5050. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9791\n",
      "Epoch [763/2000], Avg Train Loss: 3.9791\n",
      "Epoch [763/2000], Avg Val Loss: 2.5045\n",
      "Validation loss improved from 2.5050 to 2.5045. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9549\n",
      "Epoch [764/2000], Avg Train Loss: 3.9549\n",
      "Epoch [764/2000], Avg Val Loss: 2.5042\n",
      "Validation loss improved from 2.5045 to 2.5042. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9541\n",
      "Epoch [765/2000], Avg Train Loss: 3.9541\n",
      "Epoch [765/2000], Avg Val Loss: 2.5038\n",
      "Validation loss improved from 2.5042 to 2.5038. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9102\n",
      "Epoch [766/2000], Avg Train Loss: 3.9102\n",
      "Epoch [766/2000], Avg Val Loss: 2.5033\n",
      "Validation loss improved from 2.5038 to 2.5033. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9157\n",
      "Epoch [767/2000], Avg Train Loss: 3.9157\n",
      "Epoch [767/2000], Avg Val Loss: 2.5029\n",
      "Validation loss improved from 2.5033 to 2.5029. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9387\n",
      "Epoch [768/2000], Avg Train Loss: 3.9387\n",
      "Epoch [768/2000], Avg Val Loss: 2.5024\n",
      "Validation loss improved from 2.5029 to 2.5024. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9437\n",
      "Epoch [769/2000], Avg Train Loss: 3.9437\n",
      "Epoch [769/2000], Avg Val Loss: 2.5019\n",
      "Validation loss improved from 2.5024 to 2.5019. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9103\n",
      "Epoch [770/2000], Avg Train Loss: 3.9103\n",
      "Epoch [770/2000], Avg Val Loss: 2.5014\n",
      "Validation loss improved from 2.5019 to 2.5014. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9487\n",
      "Epoch [771/2000], Avg Train Loss: 3.9487\n",
      "Epoch [771/2000], Avg Val Loss: 2.5009\n",
      "Validation loss improved from 2.5014 to 2.5009. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9516\n",
      "Epoch [772/2000], Avg Train Loss: 3.9516\n",
      "Epoch [772/2000], Avg Val Loss: 2.5004\n",
      "Validation loss improved from 2.5009 to 2.5004. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9187\n",
      "Epoch [773/2000], Avg Train Loss: 3.9187\n",
      "Epoch [773/2000], Avg Val Loss: 2.4999\n",
      "Validation loss improved from 2.5004 to 2.4999. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9389\n",
      "Epoch [774/2000], Avg Train Loss: 3.9389\n",
      "Epoch [774/2000], Avg Val Loss: 2.4994\n",
      "Validation loss improved from 2.4999 to 2.4994. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9435\n",
      "Epoch [775/2000], Avg Train Loss: 3.9435\n",
      "Epoch [775/2000], Avg Val Loss: 2.4989\n",
      "Validation loss improved from 2.4994 to 2.4989. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9138\n",
      "Epoch [776/2000], Avg Train Loss: 3.9138\n",
      "Epoch [776/2000], Avg Val Loss: 2.4983\n",
      "Validation loss improved from 2.4989 to 2.4983. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9219\n",
      "Epoch [777/2000], Avg Train Loss: 3.9219\n",
      "Epoch [777/2000], Avg Val Loss: 2.4977\n",
      "Validation loss improved from 2.4983 to 2.4977. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9140\n",
      "Epoch [778/2000], Avg Train Loss: 3.9140\n",
      "Epoch [778/2000], Avg Val Loss: 2.4971\n",
      "Validation loss improved from 2.4977 to 2.4971. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9149\n",
      "Epoch [779/2000], Avg Train Loss: 3.9149\n",
      "Epoch [779/2000], Avg Val Loss: 2.4966\n",
      "Validation loss improved from 2.4971 to 2.4966. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8804\n",
      "Epoch [780/2000], Avg Train Loss: 3.8804\n",
      "Epoch [780/2000], Avg Val Loss: 2.4961\n",
      "Validation loss improved from 2.4966 to 2.4961. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9311\n",
      "Epoch [781/2000], Avg Train Loss: 3.9311\n",
      "Epoch [781/2000], Avg Val Loss: 2.4956\n",
      "Validation loss improved from 2.4961 to 2.4956. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9176\n",
      "Epoch [782/2000], Avg Train Loss: 3.9176\n",
      "Epoch [782/2000], Avg Val Loss: 2.4951\n",
      "Validation loss improved from 2.4956 to 2.4951. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9238\n",
      "Epoch [783/2000], Avg Train Loss: 3.9238\n",
      "Epoch [783/2000], Avg Val Loss: 2.4945\n",
      "Validation loss improved from 2.4951 to 2.4945. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8917\n",
      "Epoch [784/2000], Avg Train Loss: 3.8917\n",
      "Epoch [784/2000], Avg Val Loss: 2.4941\n",
      "Validation loss improved from 2.4945 to 2.4941. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9047\n",
      "Epoch [785/2000], Avg Train Loss: 3.9047\n",
      "Epoch [785/2000], Avg Val Loss: 2.4936\n",
      "Validation loss improved from 2.4941 to 2.4936. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9588\n",
      "Epoch [786/2000], Avg Train Loss: 3.9588\n",
      "Epoch [786/2000], Avg Val Loss: 2.4931\n",
      "Validation loss improved from 2.4936 to 2.4931. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9035\n",
      "Epoch [787/2000], Avg Train Loss: 3.9035\n",
      "Epoch [787/2000], Avg Val Loss: 2.4926\n",
      "Validation loss improved from 2.4931 to 2.4926. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9334\n",
      "Epoch [788/2000], Avg Train Loss: 3.9334\n",
      "Epoch [788/2000], Avg Val Loss: 2.4921\n",
      "Validation loss improved from 2.4926 to 2.4921. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9743\n",
      "Epoch [789/2000], Avg Train Loss: 3.9743\n",
      "Epoch [789/2000], Avg Val Loss: 2.4917\n",
      "Validation loss improved from 2.4921 to 2.4917. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9446\n",
      "Epoch [790/2000], Avg Train Loss: 3.9446\n",
      "Epoch [790/2000], Avg Val Loss: 2.4914\n",
      "Validation loss improved from 2.4917 to 2.4914. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8698\n",
      "Epoch [791/2000], Avg Train Loss: 3.8698\n",
      "Epoch [791/2000], Avg Val Loss: 2.4910\n",
      "Validation loss improved from 2.4914 to 2.4910. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9026\n",
      "Epoch [792/2000], Avg Train Loss: 3.9026\n",
      "Epoch [792/2000], Avg Val Loss: 2.4906\n",
      "Validation loss improved from 2.4910 to 2.4906. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9294\n",
      "Epoch [793/2000], Avg Train Loss: 3.9294\n",
      "Epoch [793/2000], Avg Val Loss: 2.4902\n",
      "Validation loss improved from 2.4906 to 2.4902. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9681\n",
      "Epoch [794/2000], Avg Train Loss: 3.9681\n",
      "Epoch [794/2000], Avg Val Loss: 2.4898\n",
      "Validation loss improved from 2.4902 to 2.4898. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9120\n",
      "Epoch [795/2000], Avg Train Loss: 3.9120\n",
      "Epoch [795/2000], Avg Val Loss: 2.4893\n",
      "Validation loss improved from 2.4898 to 2.4893. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9209\n",
      "Epoch [796/2000], Avg Train Loss: 3.9209\n",
      "Epoch [796/2000], Avg Val Loss: 2.4890\n",
      "Validation loss improved from 2.4893 to 2.4890. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9293\n",
      "Epoch [797/2000], Avg Train Loss: 3.9293\n",
      "Epoch [797/2000], Avg Val Loss: 2.4887\n",
      "Validation loss improved from 2.4890 to 2.4887. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8748\n",
      "Epoch [798/2000], Avg Train Loss: 3.8748\n",
      "Epoch [798/2000], Avg Val Loss: 2.4883\n",
      "Validation loss improved from 2.4887 to 2.4883. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9309\n",
      "Epoch [799/2000], Avg Train Loss: 3.9309\n",
      "Epoch [799/2000], Avg Val Loss: 2.4879\n",
      "Validation loss improved from 2.4883 to 2.4879. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8989\n",
      "Epoch [800/2000], Avg Train Loss: 3.8989\n",
      "Epoch [800/2000], Avg Val Loss: 2.4875\n",
      "Validation loss improved from 2.4879 to 2.4875. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8923\n",
      "Epoch [801/2000], Avg Train Loss: 3.8923\n",
      "Epoch [801/2000], Avg Val Loss: 2.4871\n",
      "Validation loss improved from 2.4875 to 2.4871. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9121\n",
      "Epoch [802/2000], Avg Train Loss: 3.9121\n",
      "Epoch [802/2000], Avg Val Loss: 2.4867\n",
      "Validation loss improved from 2.4871 to 2.4867. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9006\n",
      "Epoch [803/2000], Avg Train Loss: 3.9006\n",
      "Epoch [803/2000], Avg Val Loss: 2.4863\n",
      "Validation loss improved from 2.4867 to 2.4863. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9219\n",
      "Epoch [804/2000], Avg Train Loss: 3.9219\n",
      "Epoch [804/2000], Avg Val Loss: 2.4859\n",
      "Validation loss improved from 2.4863 to 2.4859. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8847\n",
      "Epoch [805/2000], Avg Train Loss: 3.8847\n",
      "Epoch [805/2000], Avg Val Loss: 2.4854\n",
      "Validation loss improved from 2.4859 to 2.4854. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9120\n",
      "Epoch [806/2000], Avg Train Loss: 3.9120\n",
      "Epoch [806/2000], Avg Val Loss: 2.4849\n",
      "Validation loss improved from 2.4854 to 2.4849. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9472\n",
      "Epoch [807/2000], Avg Train Loss: 3.9472\n",
      "Epoch [807/2000], Avg Val Loss: 2.4844\n",
      "Validation loss improved from 2.4849 to 2.4844. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8902\n",
      "Epoch [808/2000], Avg Train Loss: 3.8902\n",
      "Epoch [808/2000], Avg Val Loss: 2.4839\n",
      "Validation loss improved from 2.4844 to 2.4839. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8567\n",
      "Epoch [809/2000], Avg Train Loss: 3.8567\n",
      "Epoch [809/2000], Avg Val Loss: 2.4834\n",
      "Validation loss improved from 2.4839 to 2.4834. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8757\n",
      "Epoch [810/2000], Avg Train Loss: 3.8757\n",
      "Epoch [810/2000], Avg Val Loss: 2.4830\n",
      "Validation loss improved from 2.4834 to 2.4830. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8832\n",
      "Epoch [811/2000], Avg Train Loss: 3.8832\n",
      "Epoch [811/2000], Avg Val Loss: 2.4825\n",
      "Validation loss improved from 2.4830 to 2.4825. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8845\n",
      "Epoch [812/2000], Avg Train Loss: 3.8845\n",
      "Epoch [812/2000], Avg Val Loss: 2.4820\n",
      "Validation loss improved from 2.4825 to 2.4820. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8750\n",
      "Epoch [813/2000], Avg Train Loss: 3.8750\n",
      "Epoch [813/2000], Avg Val Loss: 2.4815\n",
      "Validation loss improved from 2.4820 to 2.4815. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8540\n",
      "Epoch [814/2000], Avg Train Loss: 3.8540\n",
      "Epoch [814/2000], Avg Val Loss: 2.4809\n",
      "Validation loss improved from 2.4815 to 2.4809. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8757\n",
      "Epoch [815/2000], Avg Train Loss: 3.8757\n",
      "Epoch [815/2000], Avg Val Loss: 2.4803\n",
      "Validation loss improved from 2.4809 to 2.4803. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8837\n",
      "Epoch [816/2000], Avg Train Loss: 3.8837\n",
      "Epoch [816/2000], Avg Val Loss: 2.4797\n",
      "Validation loss improved from 2.4803 to 2.4797. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8787\n",
      "Epoch [817/2000], Avg Train Loss: 3.8787\n",
      "Epoch [817/2000], Avg Val Loss: 2.4791\n",
      "Validation loss improved from 2.4797 to 2.4791. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8478\n",
      "Epoch [818/2000], Avg Train Loss: 3.8478\n",
      "Epoch [818/2000], Avg Val Loss: 2.4786\n",
      "Validation loss improved from 2.4791 to 2.4786. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8755\n",
      "Epoch [819/2000], Avg Train Loss: 3.8755\n",
      "Epoch [819/2000], Avg Val Loss: 2.4781\n",
      "Validation loss improved from 2.4786 to 2.4781. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8425\n",
      "Epoch [820/2000], Avg Train Loss: 3.8425\n",
      "Epoch [820/2000], Avg Val Loss: 2.4775\n",
      "Validation loss improved from 2.4781 to 2.4775. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8659\n",
      "Epoch [821/2000], Avg Train Loss: 3.8659\n",
      "Epoch [821/2000], Avg Val Loss: 2.4769\n",
      "Validation loss improved from 2.4775 to 2.4769. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8679\n",
      "Epoch [822/2000], Avg Train Loss: 3.8679\n",
      "Epoch [822/2000], Avg Val Loss: 2.4764\n",
      "Validation loss improved from 2.4769 to 2.4764. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8898\n",
      "Epoch [823/2000], Avg Train Loss: 3.8898\n",
      "Epoch [823/2000], Avg Val Loss: 2.4759\n",
      "Validation loss improved from 2.4764 to 2.4759. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8776\n",
      "Epoch [824/2000], Avg Train Loss: 3.8776\n",
      "Epoch [824/2000], Avg Val Loss: 2.4753\n",
      "Validation loss improved from 2.4759 to 2.4753. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8902\n",
      "Epoch [825/2000], Avg Train Loss: 3.8902\n",
      "Epoch [825/2000], Avg Val Loss: 2.4748\n",
      "Validation loss improved from 2.4753 to 2.4748. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8879\n",
      "Epoch [826/2000], Avg Train Loss: 3.8879\n",
      "Epoch [826/2000], Avg Val Loss: 2.4743\n",
      "Validation loss improved from 2.4748 to 2.4743. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8643\n",
      "Epoch [827/2000], Avg Train Loss: 3.8643\n",
      "Epoch [827/2000], Avg Val Loss: 2.4738\n",
      "Validation loss improved from 2.4743 to 2.4738. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9203\n",
      "Epoch [828/2000], Avg Train Loss: 3.9203\n",
      "Epoch [828/2000], Avg Val Loss: 2.4732\n",
      "Validation loss improved from 2.4738 to 2.4732. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8977\n",
      "Epoch [829/2000], Avg Train Loss: 3.8977\n",
      "Epoch [829/2000], Avg Val Loss: 2.4728\n",
      "Validation loss improved from 2.4732 to 2.4728. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8984\n",
      "Epoch [830/2000], Avg Train Loss: 3.8984\n",
      "Epoch [830/2000], Avg Val Loss: 2.4723\n",
      "Validation loss improved from 2.4728 to 2.4723. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9188\n",
      "Epoch [831/2000], Avg Train Loss: 3.9188\n",
      "Epoch [831/2000], Avg Val Loss: 2.4719\n",
      "Validation loss improved from 2.4723 to 2.4719. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8813\n",
      "Epoch [832/2000], Avg Train Loss: 3.8813\n",
      "Epoch [832/2000], Avg Val Loss: 2.4714\n",
      "Validation loss improved from 2.4719 to 2.4714. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8563\n",
      "Epoch [833/2000], Avg Train Loss: 3.8563\n",
      "Epoch [833/2000], Avg Val Loss: 2.4711\n",
      "Validation loss improved from 2.4714 to 2.4711. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8589\n",
      "Epoch [834/2000], Avg Train Loss: 3.8589\n",
      "Epoch [834/2000], Avg Val Loss: 2.4706\n",
      "Validation loss improved from 2.4711 to 2.4706. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8693\n",
      "Epoch [835/2000], Avg Train Loss: 3.8693\n",
      "Epoch [835/2000], Avg Val Loss: 2.4702\n",
      "Validation loss improved from 2.4706 to 2.4702. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8983\n",
      "Epoch [836/2000], Avg Train Loss: 3.8983\n",
      "Epoch [836/2000], Avg Val Loss: 2.4698\n",
      "Validation loss improved from 2.4702 to 2.4698. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8467\n",
      "Epoch [837/2000], Avg Train Loss: 3.8467\n",
      "Epoch [837/2000], Avg Val Loss: 2.4694\n",
      "Validation loss improved from 2.4698 to 2.4694. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9257\n",
      "Epoch [838/2000], Avg Train Loss: 3.9257\n",
      "Epoch [838/2000], Avg Val Loss: 2.4690\n",
      "Validation loss improved from 2.4694 to 2.4690. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9015\n",
      "Epoch [839/2000], Avg Train Loss: 3.9015\n",
      "Epoch [839/2000], Avg Val Loss: 2.4686\n",
      "Validation loss improved from 2.4690 to 2.4686. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8540\n",
      "Epoch [840/2000], Avg Train Loss: 3.8540\n",
      "Epoch [840/2000], Avg Val Loss: 2.4682\n",
      "Validation loss improved from 2.4686 to 2.4682. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8658\n",
      "Epoch [841/2000], Avg Train Loss: 3.8658\n",
      "Epoch [841/2000], Avg Val Loss: 2.4678\n",
      "Validation loss improved from 2.4682 to 2.4678. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8901\n",
      "Epoch [842/2000], Avg Train Loss: 3.8901\n",
      "Epoch [842/2000], Avg Val Loss: 2.4675\n",
      "Validation loss improved from 2.4678 to 2.4675. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8473\n",
      "Epoch [843/2000], Avg Train Loss: 3.8473\n",
      "Epoch [843/2000], Avg Val Loss: 2.4671\n",
      "Validation loss improved from 2.4675 to 2.4671. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8426\n",
      "Epoch [844/2000], Avg Train Loss: 3.8426\n",
      "Epoch [844/2000], Avg Val Loss: 2.4668\n",
      "Validation loss improved from 2.4671 to 2.4668. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8523\n",
      "Epoch [845/2000], Avg Train Loss: 3.8523\n",
      "Epoch [845/2000], Avg Val Loss: 2.4665\n",
      "Validation loss improved from 2.4668 to 2.4665. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8502\n",
      "Epoch [846/2000], Avg Train Loss: 3.8502\n",
      "Epoch [846/2000], Avg Val Loss: 2.4662\n",
      "Validation loss improved from 2.4665 to 2.4662. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8764\n",
      "Epoch [847/2000], Avg Train Loss: 3.8764\n",
      "Epoch [847/2000], Avg Val Loss: 2.4659\n",
      "Validation loss improved from 2.4662 to 2.4659. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8441\n",
      "Epoch [848/2000], Avg Train Loss: 3.8441\n",
      "Epoch [848/2000], Avg Val Loss: 2.4656\n",
      "Validation loss improved from 2.4659 to 2.4656. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8391\n",
      "Epoch [849/2000], Avg Train Loss: 3.8391\n",
      "Epoch [849/2000], Avg Val Loss: 2.4653\n",
      "Validation loss improved from 2.4656 to 2.4653. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8741\n",
      "Epoch [850/2000], Avg Train Loss: 3.8741\n",
      "Epoch [850/2000], Avg Val Loss: 2.4650\n",
      "Validation loss improved from 2.4653 to 2.4650. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8346\n",
      "Epoch [851/2000], Avg Train Loss: 3.8346\n",
      "Epoch [851/2000], Avg Val Loss: 2.4647\n",
      "Validation loss improved from 2.4650 to 2.4647. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8601\n",
      "Epoch [852/2000], Avg Train Loss: 3.8601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [852/2000], Avg Val Loss: 2.4643\n",
      "Validation loss improved from 2.4647 to 2.4643. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8818\n",
      "Epoch [853/2000], Avg Train Loss: 3.8818\n",
      "Epoch [853/2000], Avg Val Loss: 2.4640\n",
      "Validation loss improved from 2.4643 to 2.4640. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8865\n",
      "Epoch [854/2000], Avg Train Loss: 3.8865\n",
      "Epoch [854/2000], Avg Val Loss: 2.4636\n",
      "Validation loss improved from 2.4640 to 2.4636. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8387\n",
      "Epoch [855/2000], Avg Train Loss: 3.8387\n",
      "Epoch [855/2000], Avg Val Loss: 2.4632\n",
      "Validation loss improved from 2.4636 to 2.4632. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8558\n",
      "Epoch [856/2000], Avg Train Loss: 3.8558\n",
      "Epoch [856/2000], Avg Val Loss: 2.4629\n",
      "Validation loss improved from 2.4632 to 2.4629. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8862\n",
      "Epoch [857/2000], Avg Train Loss: 3.8862\n",
      "Epoch [857/2000], Avg Val Loss: 2.4625\n",
      "Validation loss improved from 2.4629 to 2.4625. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8373\n",
      "Epoch [858/2000], Avg Train Loss: 3.8373\n",
      "Epoch [858/2000], Avg Val Loss: 2.4621\n",
      "Validation loss improved from 2.4625 to 2.4621. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8357\n",
      "Epoch [859/2000], Avg Train Loss: 3.8357\n",
      "Epoch [859/2000], Avg Val Loss: 2.4617\n",
      "Validation loss improved from 2.4621 to 2.4617. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8364\n",
      "Epoch [860/2000], Avg Train Loss: 3.8364\n",
      "Epoch [860/2000], Avg Val Loss: 2.4614\n",
      "Validation loss improved from 2.4617 to 2.4614. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8363\n",
      "Epoch [861/2000], Avg Train Loss: 3.8363\n",
      "Epoch [861/2000], Avg Val Loss: 2.4611\n",
      "Validation loss improved from 2.4614 to 2.4611. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8289\n",
      "Epoch [862/2000], Avg Train Loss: 3.8289\n",
      "Epoch [862/2000], Avg Val Loss: 2.4607\n",
      "Validation loss improved from 2.4611 to 2.4607. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8463\n",
      "Epoch [863/2000], Avg Train Loss: 3.8463\n",
      "Epoch [863/2000], Avg Val Loss: 2.4604\n",
      "Validation loss improved from 2.4607 to 2.4604. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8697\n",
      "Epoch [864/2000], Avg Train Loss: 3.8697\n",
      "Epoch [864/2000], Avg Val Loss: 2.4601\n",
      "Validation loss improved from 2.4604 to 2.4601. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8536\n",
      "Epoch [865/2000], Avg Train Loss: 3.8536\n",
      "Epoch [865/2000], Avg Val Loss: 2.4598\n",
      "Validation loss improved from 2.4601 to 2.4598. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8412\n",
      "Epoch [866/2000], Avg Train Loss: 3.8412\n",
      "Epoch [866/2000], Avg Val Loss: 2.4595\n",
      "Validation loss improved from 2.4598 to 2.4595. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8299\n",
      "Epoch [867/2000], Avg Train Loss: 3.8299\n",
      "Epoch [867/2000], Avg Val Loss: 2.4592\n",
      "Validation loss improved from 2.4595 to 2.4592. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8442\n",
      "Epoch [868/2000], Avg Train Loss: 3.8442\n",
      "Epoch [868/2000], Avg Val Loss: 2.4590\n",
      "Validation loss improved from 2.4592 to 2.4590. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8440\n",
      "Epoch [869/2000], Avg Train Loss: 3.8440\n",
      "Epoch [869/2000], Avg Val Loss: 2.4587\n",
      "Validation loss improved from 2.4590 to 2.4587. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8313\n",
      "Epoch [870/2000], Avg Train Loss: 3.8313\n",
      "Epoch [870/2000], Avg Val Loss: 2.4585\n",
      "Validation loss improved from 2.4587 to 2.4585. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7754\n",
      "Epoch [871/2000], Avg Train Loss: 3.7754\n",
      "Epoch [871/2000], Avg Val Loss: 2.4583\n",
      "Validation loss improved from 2.4585 to 2.4583. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8429\n",
      "Epoch [872/2000], Avg Train Loss: 3.8429\n",
      "Epoch [872/2000], Avg Val Loss: 2.4580\n",
      "Validation loss improved from 2.4583 to 2.4580. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8257\n",
      "Epoch [873/2000], Avg Train Loss: 3.8257\n",
      "Epoch [873/2000], Avg Val Loss: 2.4577\n",
      "Validation loss improved from 2.4580 to 2.4577. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8481\n",
      "Epoch [874/2000], Avg Train Loss: 3.8481\n",
      "Epoch [874/2000], Avg Val Loss: 2.4573\n",
      "Validation loss improved from 2.4577 to 2.4573. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8609\n",
      "Epoch [875/2000], Avg Train Loss: 3.8609\n",
      "Epoch [875/2000], Avg Val Loss: 2.4570\n",
      "Validation loss improved from 2.4573 to 2.4570. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7993\n",
      "Epoch [876/2000], Avg Train Loss: 3.7993\n",
      "Epoch [876/2000], Avg Val Loss: 2.4567\n",
      "Validation loss improved from 2.4570 to 2.4567. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8518\n",
      "Epoch [877/2000], Avg Train Loss: 3.8518\n",
      "Epoch [877/2000], Avg Val Loss: 2.4563\n",
      "Validation loss improved from 2.4567 to 2.4563. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8063\n",
      "Epoch [878/2000], Avg Train Loss: 3.8063\n",
      "Epoch [878/2000], Avg Val Loss: 2.4561\n",
      "Validation loss improved from 2.4563 to 2.4561. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8209\n",
      "Epoch [879/2000], Avg Train Loss: 3.8209\n",
      "Epoch [879/2000], Avg Val Loss: 2.4557\n",
      "Validation loss improved from 2.4561 to 2.4557. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8113\n",
      "Epoch [880/2000], Avg Train Loss: 3.8113\n",
      "Epoch [880/2000], Avg Val Loss: 2.4554\n",
      "Validation loss improved from 2.4557 to 2.4554. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8274\n",
      "Epoch [881/2000], Avg Train Loss: 3.8274\n",
      "Epoch [881/2000], Avg Val Loss: 2.4550\n",
      "Validation loss improved from 2.4554 to 2.4550. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8422\n",
      "Epoch [882/2000], Avg Train Loss: 3.8422\n",
      "Epoch [882/2000], Avg Val Loss: 2.4545\n",
      "Validation loss improved from 2.4550 to 2.4545. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8234\n",
      "Epoch [883/2000], Avg Train Loss: 3.8234\n",
      "Epoch [883/2000], Avg Val Loss: 2.4541\n",
      "Validation loss improved from 2.4545 to 2.4541. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8333\n",
      "Epoch [884/2000], Avg Train Loss: 3.8333\n",
      "Epoch [884/2000], Avg Val Loss: 2.4537\n",
      "Validation loss improved from 2.4541 to 2.4537. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8493\n",
      "Epoch [885/2000], Avg Train Loss: 3.8493\n",
      "Epoch [885/2000], Avg Val Loss: 2.4534\n",
      "Validation loss improved from 2.4537 to 2.4534. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8246\n",
      "Epoch [886/2000], Avg Train Loss: 3.8246\n",
      "Epoch [886/2000], Avg Val Loss: 2.4529\n",
      "Validation loss improved from 2.4534 to 2.4529. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8086\n",
      "Epoch [887/2000], Avg Train Loss: 3.8086\n",
      "Epoch [887/2000], Avg Val Loss: 2.4523\n",
      "Validation loss improved from 2.4529 to 2.4523. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8338\n",
      "Epoch [888/2000], Avg Train Loss: 3.8338\n",
      "Epoch [888/2000], Avg Val Loss: 2.4518\n",
      "Validation loss improved from 2.4523 to 2.4518. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8334\n",
      "Epoch [889/2000], Avg Train Loss: 3.8334\n",
      "Epoch [889/2000], Avg Val Loss: 2.4512\n",
      "Validation loss improved from 2.4518 to 2.4512. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8389\n",
      "Epoch [890/2000], Avg Train Loss: 3.8389\n",
      "Epoch [890/2000], Avg Val Loss: 2.4507\n",
      "Validation loss improved from 2.4512 to 2.4507. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8080\n",
      "Epoch [891/2000], Avg Train Loss: 3.8080\n",
      "Epoch [891/2000], Avg Val Loss: 2.4501\n",
      "Validation loss improved from 2.4507 to 2.4501. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8255\n",
      "Epoch [892/2000], Avg Train Loss: 3.8255\n",
      "Epoch [892/2000], Avg Val Loss: 2.4497\n",
      "Validation loss improved from 2.4501 to 2.4497. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8276\n",
      "Epoch [893/2000], Avg Train Loss: 3.8276\n",
      "Epoch [893/2000], Avg Val Loss: 2.4493\n",
      "Validation loss improved from 2.4497 to 2.4493. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8243\n",
      "Epoch [894/2000], Avg Train Loss: 3.8243\n",
      "Epoch [894/2000], Avg Val Loss: 2.4489\n",
      "Validation loss improved from 2.4493 to 2.4489. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7678\n",
      "Epoch [895/2000], Avg Train Loss: 3.7678\n",
      "Epoch [895/2000], Avg Val Loss: 2.4485\n",
      "Validation loss improved from 2.4489 to 2.4485. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7483\n",
      "Epoch [896/2000], Avg Train Loss: 3.7483\n",
      "Epoch [896/2000], Avg Val Loss: 2.4482\n",
      "Validation loss improved from 2.4485 to 2.4482. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8175\n",
      "Epoch [897/2000], Avg Train Loss: 3.8175\n",
      "Epoch [897/2000], Avg Val Loss: 2.4479\n",
      "Validation loss improved from 2.4482 to 2.4479. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8149\n",
      "Epoch [898/2000], Avg Train Loss: 3.8149\n",
      "Epoch [898/2000], Avg Val Loss: 2.4476\n",
      "Validation loss improved from 2.4479 to 2.4476. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8214\n",
      "Epoch [899/2000], Avg Train Loss: 3.8214\n",
      "Epoch [899/2000], Avg Val Loss: 2.4474\n",
      "Validation loss improved from 2.4476 to 2.4474. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8188\n",
      "Epoch [900/2000], Avg Train Loss: 3.8188\n",
      "Epoch [900/2000], Avg Val Loss: 2.4470\n",
      "Validation loss improved from 2.4474 to 2.4470. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8234\n",
      "Epoch [901/2000], Avg Train Loss: 3.8234\n",
      "Epoch [901/2000], Avg Val Loss: 2.4467\n",
      "Validation loss improved from 2.4470 to 2.4467. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8201\n",
      "Epoch [902/2000], Avg Train Loss: 3.8201\n",
      "Epoch [902/2000], Avg Val Loss: 2.4464\n",
      "Validation loss improved from 2.4467 to 2.4464. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8228\n",
      "Epoch [903/2000], Avg Train Loss: 3.8228\n",
      "Epoch [903/2000], Avg Val Loss: 2.4461\n",
      "Validation loss improved from 2.4464 to 2.4461. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7829\n",
      "Epoch [904/2000], Avg Train Loss: 3.7829\n",
      "Epoch [904/2000], Avg Val Loss: 2.4457\n",
      "Validation loss improved from 2.4461 to 2.4457. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8481\n",
      "Epoch [905/2000], Avg Train Loss: 3.8481\n",
      "Epoch [905/2000], Avg Val Loss: 2.4453\n",
      "Validation loss improved from 2.4457 to 2.4453. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8262\n",
      "Epoch [906/2000], Avg Train Loss: 3.8262\n",
      "Epoch [906/2000], Avg Val Loss: 2.4450\n",
      "Validation loss improved from 2.4453 to 2.4450. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7839\n",
      "Epoch [907/2000], Avg Train Loss: 3.7839\n",
      "Epoch [907/2000], Avg Val Loss: 2.4446\n",
      "Validation loss improved from 2.4450 to 2.4446. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7675\n",
      "Epoch [908/2000], Avg Train Loss: 3.7675\n",
      "Epoch [908/2000], Avg Val Loss: 2.4443\n",
      "Validation loss improved from 2.4446 to 2.4443. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8184\n",
      "Epoch [909/2000], Avg Train Loss: 3.8184\n",
      "Epoch [909/2000], Avg Val Loss: 2.4440\n",
      "Validation loss improved from 2.4443 to 2.4440. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8017\n",
      "Epoch [910/2000], Avg Train Loss: 3.8017\n",
      "Epoch [910/2000], Avg Val Loss: 2.4438\n",
      "Validation loss improved from 2.4440 to 2.4438. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8120\n",
      "Epoch [911/2000], Avg Train Loss: 3.8120\n",
      "Epoch [911/2000], Avg Val Loss: 2.4435\n",
      "Validation loss improved from 2.4438 to 2.4435. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7957\n",
      "Epoch [912/2000], Avg Train Loss: 3.7957\n",
      "Epoch [912/2000], Avg Val Loss: 2.4433\n",
      "Validation loss improved from 2.4435 to 2.4433. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7876\n",
      "Epoch [913/2000], Avg Train Loss: 3.7876\n",
      "Epoch [913/2000], Avg Val Loss: 2.4431\n",
      "Validation loss improved from 2.4433 to 2.4431. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8152\n",
      "Epoch [914/2000], Avg Train Loss: 3.8152\n",
      "Epoch [914/2000], Avg Val Loss: 2.4428\n",
      "Validation loss improved from 2.4431 to 2.4428. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7989\n",
      "Epoch [915/2000], Avg Train Loss: 3.7989\n",
      "Epoch [915/2000], Avg Val Loss: 2.4425\n",
      "Validation loss improved from 2.4428 to 2.4425. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8125\n",
      "Epoch [916/2000], Avg Train Loss: 3.8125\n",
      "Epoch [916/2000], Avg Val Loss: 2.4423\n",
      "Validation loss improved from 2.4425 to 2.4423. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8425\n",
      "Epoch [917/2000], Avg Train Loss: 3.8425\n",
      "Epoch [917/2000], Avg Val Loss: 2.4421\n",
      "Validation loss improved from 2.4423 to 2.4421. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8046\n",
      "Epoch [918/2000], Avg Train Loss: 3.8046\n",
      "Epoch [918/2000], Avg Val Loss: 2.4418\n",
      "Validation loss improved from 2.4421 to 2.4418. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7742\n",
      "Epoch [919/2000], Avg Train Loss: 3.7742\n",
      "Epoch [919/2000], Avg Val Loss: 2.4416\n",
      "Validation loss improved from 2.4418 to 2.4416. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7954\n",
      "Epoch [920/2000], Avg Train Loss: 3.7954\n",
      "Epoch [920/2000], Avg Val Loss: 2.4414\n",
      "Validation loss improved from 2.4416 to 2.4414. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7522\n",
      "Epoch [921/2000], Avg Train Loss: 3.7522\n",
      "Epoch [921/2000], Avg Val Loss: 2.4413\n",
      "Validation loss improved from 2.4414 to 2.4413. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7979\n",
      "Epoch [922/2000], Avg Train Loss: 3.7979\n",
      "Epoch [922/2000], Avg Val Loss: 2.4412\n",
      "Validation loss improved from 2.4413 to 2.4412. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8049\n",
      "Epoch [923/2000], Avg Train Loss: 3.8049\n",
      "Epoch [923/2000], Avg Val Loss: 2.4410\n",
      "Validation loss improved from 2.4412 to 2.4410. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7695\n",
      "Epoch [924/2000], Avg Train Loss: 3.7695\n",
      "Epoch [924/2000], Avg Val Loss: 2.4409\n",
      "Validation loss improved from 2.4410 to 2.4409. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8425\n",
      "Epoch [925/2000], Avg Train Loss: 3.8425\n",
      "Epoch [925/2000], Avg Val Loss: 2.4406\n",
      "Validation loss improved from 2.4409 to 2.4406. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8024\n",
      "Epoch [926/2000], Avg Train Loss: 3.8024\n",
      "Epoch [926/2000], Avg Val Loss: 2.4405\n",
      "Validation loss improved from 2.4406 to 2.4405. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7658\n",
      "Epoch [927/2000], Avg Train Loss: 3.7658\n",
      "Epoch [927/2000], Avg Val Loss: 2.4403\n",
      "Validation loss improved from 2.4405 to 2.4403. Saving model...\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7608\n",
      "Epoch [928/2000], Avg Train Loss: 3.7608\n",
      "Epoch [928/2000], Avg Val Loss: 2.4401\n",
      "Validation loss improved from 2.4403 to 2.4401. Saving model...\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7620\n",
      "Epoch [929/2000], Avg Train Loss: 3.7620\n",
      "Epoch [929/2000], Avg Val Loss: 2.4400\n",
      "Validation loss improved from 2.4401 to 2.4400. Saving model...\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8351\n",
      "Epoch [930/2000], Avg Train Loss: 3.8351\n",
      "Epoch [930/2000], Avg Val Loss: 2.4398\n",
      "Validation loss improved from 2.4400 to 2.4398. Saving model...\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8131\n",
      "Epoch [931/2000], Avg Train Loss: 3.8131\n",
      "Epoch [931/2000], Avg Val Loss: 2.4397\n",
      "Validation loss improved from 2.4398 to 2.4397. Saving model...\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8059\n",
      "Epoch [932/2000], Avg Train Loss: 3.8059\n",
      "Epoch [932/2000], Avg Val Loss: 2.4396\n",
      "Validation loss improved from 2.4397 to 2.4396. Saving model...\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8078\n",
      "Epoch [933/2000], Avg Train Loss: 3.8078\n",
      "Epoch [933/2000], Avg Val Loss: 2.4394\n",
      "Validation loss improved from 2.4396 to 2.4394. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8068\n",
      "Epoch [934/2000], Avg Train Loss: 3.8068\n",
      "Epoch [934/2000], Avg Val Loss: 2.4393\n",
      "Validation loss improved from 2.4394 to 2.4393. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7831\n",
      "Epoch [935/2000], Avg Train Loss: 3.7831\n",
      "Epoch [935/2000], Avg Val Loss: 2.4394\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8035\n",
      "Epoch [936/2000], Avg Train Loss: 3.8035\n",
      "Epoch [936/2000], Avg Val Loss: 2.4393\n",
      "Validation loss improved from 2.4393 to 2.4393. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8142\n",
      "Epoch [937/2000], Avg Train Loss: 3.8142\n",
      "Epoch [937/2000], Avg Val Loss: 2.4391\n",
      "Validation loss improved from 2.4393 to 2.4391. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8050\n",
      "Epoch [938/2000], Avg Train Loss: 3.8050\n",
      "Epoch [938/2000], Avg Val Loss: 2.4390\n",
      "Validation loss improved from 2.4391 to 2.4390. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7956\n",
      "Epoch [939/2000], Avg Train Loss: 3.7956\n",
      "Epoch [939/2000], Avg Val Loss: 2.4389\n",
      "Validation loss improved from 2.4390 to 2.4389. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8064\n",
      "Epoch [940/2000], Avg Train Loss: 3.8064\n",
      "Epoch [940/2000], Avg Val Loss: 2.4387\n",
      "Validation loss improved from 2.4389 to 2.4387. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8078\n",
      "Epoch [941/2000], Avg Train Loss: 3.8078\n",
      "Epoch [941/2000], Avg Val Loss: 2.4386\n",
      "Validation loss improved from 2.4387 to 2.4386. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7687\n",
      "Epoch [942/2000], Avg Train Loss: 3.7687\n",
      "Epoch [942/2000], Avg Val Loss: 2.4384\n",
      "Validation loss improved from 2.4386 to 2.4384. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7993\n",
      "Epoch [943/2000], Avg Train Loss: 3.7993\n",
      "Epoch [943/2000], Avg Val Loss: 2.4381\n",
      "Validation loss improved from 2.4384 to 2.4381. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7848\n",
      "Epoch [944/2000], Avg Train Loss: 3.7848\n",
      "Epoch [944/2000], Avg Val Loss: 2.4378\n",
      "Validation loss improved from 2.4381 to 2.4378. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7786\n",
      "Epoch [945/2000], Avg Train Loss: 3.7786\n",
      "Epoch [945/2000], Avg Val Loss: 2.4375\n",
      "Validation loss improved from 2.4378 to 2.4375. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7852\n",
      "Epoch [946/2000], Avg Train Loss: 3.7852\n",
      "Epoch [946/2000], Avg Val Loss: 2.4372\n",
      "Validation loss improved from 2.4375 to 2.4372. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7641\n",
      "Epoch [947/2000], Avg Train Loss: 3.7641\n",
      "Epoch [947/2000], Avg Val Loss: 2.4368\n",
      "Validation loss improved from 2.4372 to 2.4368. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7923\n",
      "Epoch [948/2000], Avg Train Loss: 3.7923\n",
      "Epoch [948/2000], Avg Val Loss: 2.4364\n",
      "Validation loss improved from 2.4368 to 2.4364. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7969\n",
      "Epoch [949/2000], Avg Train Loss: 3.7969\n",
      "Epoch [949/2000], Avg Val Loss: 2.4361\n",
      "Validation loss improved from 2.4364 to 2.4361. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7107\n",
      "Epoch [950/2000], Avg Train Loss: 3.7107\n",
      "Epoch [950/2000], Avg Val Loss: 2.4357\n",
      "Validation loss improved from 2.4361 to 2.4357. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7678\n",
      "Epoch [951/2000], Avg Train Loss: 3.7678\n",
      "Epoch [951/2000], Avg Val Loss: 2.4354\n",
      "Validation loss improved from 2.4357 to 2.4354. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7805\n",
      "Epoch [952/2000], Avg Train Loss: 3.7805\n",
      "Epoch [952/2000], Avg Val Loss: 2.4350\n",
      "Validation loss improved from 2.4354 to 2.4350. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7556\n",
      "Epoch [953/2000], Avg Train Loss: 3.7556\n",
      "Epoch [953/2000], Avg Val Loss: 2.4347\n",
      "Validation loss improved from 2.4350 to 2.4347. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7609\n",
      "Epoch [954/2000], Avg Train Loss: 3.7609\n",
      "Epoch [954/2000], Avg Val Loss: 2.4345\n",
      "Validation loss improved from 2.4347 to 2.4345. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8258\n",
      "Epoch [955/2000], Avg Train Loss: 3.8258\n",
      "Epoch [955/2000], Avg Val Loss: 2.4342\n",
      "Validation loss improved from 2.4345 to 2.4342. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7444\n",
      "Epoch [956/2000], Avg Train Loss: 3.7444\n",
      "Epoch [956/2000], Avg Val Loss: 2.4340\n",
      "Validation loss improved from 2.4342 to 2.4340. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7888\n",
      "Epoch [957/2000], Avg Train Loss: 3.7888\n",
      "Epoch [957/2000], Avg Val Loss: 2.4337\n",
      "Validation loss improved from 2.4340 to 2.4337. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7637\n",
      "Epoch [958/2000], Avg Train Loss: 3.7637\n",
      "Epoch [958/2000], Avg Val Loss: 2.4335\n",
      "Validation loss improved from 2.4337 to 2.4335. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8139\n",
      "Epoch [959/2000], Avg Train Loss: 3.8139\n",
      "Epoch [959/2000], Avg Val Loss: 2.4334\n",
      "Validation loss improved from 2.4335 to 2.4334. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7767\n",
      "Epoch [960/2000], Avg Train Loss: 3.7767\n",
      "Epoch [960/2000], Avg Val Loss: 2.4334\n",
      "Validation loss improved from 2.4334 to 2.4334. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7257\n",
      "Epoch [961/2000], Avg Train Loss: 3.7257\n",
      "Epoch [961/2000], Avg Val Loss: 2.4333\n",
      "Validation loss improved from 2.4334 to 2.4333. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7691\n",
      "Epoch [962/2000], Avg Train Loss: 3.7691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [962/2000], Avg Val Loss: 2.4332\n",
      "Validation loss improved from 2.4333 to 2.4332. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7530\n",
      "Epoch [963/2000], Avg Train Loss: 3.7530\n",
      "Epoch [963/2000], Avg Val Loss: 2.4330\n",
      "Validation loss improved from 2.4332 to 2.4330. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7651\n",
      "Epoch [964/2000], Avg Train Loss: 3.7651\n",
      "Epoch [964/2000], Avg Val Loss: 2.4329\n",
      "Validation loss improved from 2.4330 to 2.4329. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7392\n",
      "Epoch [965/2000], Avg Train Loss: 3.7392\n",
      "Epoch [965/2000], Avg Val Loss: 2.4328\n",
      "Validation loss improved from 2.4329 to 2.4328. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7713\n",
      "Epoch [966/2000], Avg Train Loss: 3.7713\n",
      "Epoch [966/2000], Avg Val Loss: 2.4326\n",
      "Validation loss improved from 2.4328 to 2.4326. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7957\n",
      "Epoch [967/2000], Avg Train Loss: 3.7957\n",
      "Epoch [967/2000], Avg Val Loss: 2.4324\n",
      "Validation loss improved from 2.4326 to 2.4324. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7811\n",
      "Epoch [968/2000], Avg Train Loss: 3.7811\n",
      "Epoch [968/2000], Avg Val Loss: 2.4322\n",
      "Validation loss improved from 2.4324 to 2.4322. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7312\n",
      "Epoch [969/2000], Avg Train Loss: 3.7312\n",
      "Epoch [969/2000], Avg Val Loss: 2.4319\n",
      "Validation loss improved from 2.4322 to 2.4319. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7846\n",
      "Epoch [970/2000], Avg Train Loss: 3.7846\n",
      "Epoch [970/2000], Avg Val Loss: 2.4318\n",
      "Validation loss improved from 2.4319 to 2.4318. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7681\n",
      "Epoch [971/2000], Avg Train Loss: 3.7681\n",
      "Epoch [971/2000], Avg Val Loss: 2.4316\n",
      "Validation loss improved from 2.4318 to 2.4316. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7731\n",
      "Epoch [972/2000], Avg Train Loss: 3.7731\n",
      "Epoch [972/2000], Avg Val Loss: 2.4314\n",
      "Validation loss improved from 2.4316 to 2.4314. Saving model...\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7391\n",
      "Epoch [973/2000], Avg Train Loss: 3.7391\n",
      "Epoch [973/2000], Avg Val Loss: 2.4311\n",
      "Validation loss improved from 2.4314 to 2.4311. Saving model...\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7583\n",
      "Epoch [974/2000], Avg Train Loss: 3.7583\n",
      "Epoch [974/2000], Avg Val Loss: 2.4308\n",
      "Validation loss improved from 2.4311 to 2.4308. Saving model...\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7645\n",
      "Epoch [975/2000], Avg Train Loss: 3.7645\n",
      "Epoch [975/2000], Avg Val Loss: 2.4305\n",
      "Validation loss improved from 2.4308 to 2.4305. Saving model...\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7531\n",
      "Epoch [976/2000], Avg Train Loss: 3.7531\n",
      "Epoch [976/2000], Avg Val Loss: 2.4302\n",
      "Validation loss improved from 2.4305 to 2.4302. Saving model...\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7696\n",
      "Epoch [977/2000], Avg Train Loss: 3.7696\n",
      "Epoch [977/2000], Avg Val Loss: 2.4300\n",
      "Validation loss improved from 2.4302 to 2.4300. Saving model...\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7518\n",
      "Epoch [978/2000], Avg Train Loss: 3.7518\n",
      "Epoch [978/2000], Avg Val Loss: 2.4298\n",
      "Validation loss improved from 2.4300 to 2.4298. Saving model...\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7265\n",
      "Epoch [979/2000], Avg Train Loss: 3.7265\n",
      "Epoch [979/2000], Avg Val Loss: 2.4295\n",
      "Validation loss improved from 2.4298 to 2.4295. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7239\n",
      "Epoch [980/2000], Avg Train Loss: 3.7239\n",
      "Epoch [980/2000], Avg Val Loss: 2.4293\n",
      "Validation loss improved from 2.4295 to 2.4293. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7337\n",
      "Epoch [981/2000], Avg Train Loss: 3.7337\n",
      "Epoch [981/2000], Avg Val Loss: 2.4290\n",
      "Validation loss improved from 2.4293 to 2.4290. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7274\n",
      "Epoch [982/2000], Avg Train Loss: 3.7274\n",
      "Epoch [982/2000], Avg Val Loss: 2.4287\n",
      "Validation loss improved from 2.4290 to 2.4287. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7391\n",
      "Epoch [983/2000], Avg Train Loss: 3.7391\n",
      "Epoch [983/2000], Avg Val Loss: 2.4284\n",
      "Validation loss improved from 2.4287 to 2.4284. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7295\n",
      "Epoch [984/2000], Avg Train Loss: 3.7295\n",
      "Epoch [984/2000], Avg Val Loss: 2.4280\n",
      "Validation loss improved from 2.4284 to 2.4280. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7704\n",
      "Epoch [985/2000], Avg Train Loss: 3.7704\n",
      "Epoch [985/2000], Avg Val Loss: 2.4277\n",
      "Validation loss improved from 2.4280 to 2.4277. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7960\n",
      "Epoch [986/2000], Avg Train Loss: 3.7960\n",
      "Epoch [986/2000], Avg Val Loss: 2.4273\n",
      "Validation loss improved from 2.4277 to 2.4273. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7410\n",
      "Epoch [987/2000], Avg Train Loss: 3.7410\n",
      "Epoch [987/2000], Avg Val Loss: 2.4269\n",
      "Validation loss improved from 2.4273 to 2.4269. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7477\n",
      "Epoch [988/2000], Avg Train Loss: 3.7477\n",
      "Epoch [988/2000], Avg Val Loss: 2.4266\n",
      "Validation loss improved from 2.4269 to 2.4266. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7731\n",
      "Epoch [989/2000], Avg Train Loss: 3.7731\n",
      "Epoch [989/2000], Avg Val Loss: 2.4263\n",
      "Validation loss improved from 2.4266 to 2.4263. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7109\n",
      "Epoch [990/2000], Avg Train Loss: 3.7109\n",
      "Epoch [990/2000], Avg Val Loss: 2.4261\n",
      "Validation loss improved from 2.4263 to 2.4261. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7396\n",
      "Epoch [991/2000], Avg Train Loss: 3.7396\n",
      "Epoch [991/2000], Avg Val Loss: 2.4259\n",
      "Validation loss improved from 2.4261 to 2.4259. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7953\n",
      "Epoch [992/2000], Avg Train Loss: 3.7953\n",
      "Epoch [992/2000], Avg Val Loss: 2.4256\n",
      "Validation loss improved from 2.4259 to 2.4256. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7471\n",
      "Epoch [993/2000], Avg Train Loss: 3.7471\n",
      "Epoch [993/2000], Avg Val Loss: 2.4256\n",
      "Validation loss improved from 2.4256 to 2.4256. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7506\n",
      "Epoch [994/2000], Avg Train Loss: 3.7506\n",
      "Epoch [994/2000], Avg Val Loss: 2.4255\n",
      "Validation loss improved from 2.4256 to 2.4255. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7206\n",
      "Epoch [995/2000], Avg Train Loss: 3.7206\n",
      "Epoch [995/2000], Avg Val Loss: 2.4255\n",
      "Validation loss improved from 2.4255 to 2.4255. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7802\n",
      "Epoch [996/2000], Avg Train Loss: 3.7802\n",
      "Epoch [996/2000], Avg Val Loss: 2.4255\n",
      "Validation loss improved from 2.4255 to 2.4255. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7442\n",
      "Epoch [997/2000], Avg Train Loss: 3.7442\n",
      "Epoch [997/2000], Avg Val Loss: 2.4255\n",
      "Validation loss improved from 2.4255 to 2.4255. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7626\n",
      "Epoch [998/2000], Avg Train Loss: 3.7626\n",
      "Epoch [998/2000], Avg Val Loss: 2.4254\n",
      "Validation loss improved from 2.4255 to 2.4254. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7641\n",
      "Epoch [999/2000], Avg Train Loss: 3.7641\n",
      "Epoch [999/2000], Avg Val Loss: 2.4254\n",
      "Validation loss improved from 2.4254 to 2.4254. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7362\n",
      "Epoch [1000/2000], Avg Train Loss: 3.7362\n",
      "Epoch [1000/2000], Avg Val Loss: 2.4253\n",
      "Validation loss improved from 2.4254 to 2.4253. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7290\n",
      "Epoch [1001/2000], Avg Train Loss: 3.7290\n",
      "Epoch [1001/2000], Avg Val Loss: 2.4252\n",
      "Validation loss improved from 2.4253 to 2.4252. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7169\n",
      "Epoch [1002/2000], Avg Train Loss: 3.7169\n",
      "Epoch [1002/2000], Avg Val Loss: 2.4250\n",
      "Validation loss improved from 2.4252 to 2.4250. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7383\n",
      "Epoch [1003/2000], Avg Train Loss: 3.7383\n",
      "Epoch [1003/2000], Avg Val Loss: 2.4250\n",
      "Validation loss improved from 2.4250 to 2.4250. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7373\n",
      "Epoch [1004/2000], Avg Train Loss: 3.7373\n",
      "Epoch [1004/2000], Avg Val Loss: 2.4248\n",
      "Validation loss improved from 2.4250 to 2.4248. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7800\n",
      "Epoch [1005/2000], Avg Train Loss: 3.7800\n",
      "Epoch [1005/2000], Avg Val Loss: 2.4247\n",
      "Validation loss improved from 2.4248 to 2.4247. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7256\n",
      "Epoch [1006/2000], Avg Train Loss: 3.7256\n",
      "Epoch [1006/2000], Avg Val Loss: 2.4246\n",
      "Validation loss improved from 2.4247 to 2.4246. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7205\n",
      "Epoch [1007/2000], Avg Train Loss: 3.7205\n",
      "Epoch [1007/2000], Avg Val Loss: 2.4246\n",
      "Validation loss improved from 2.4246 to 2.4246. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7341\n",
      "Epoch [1008/2000], Avg Train Loss: 3.7341\n",
      "Epoch [1008/2000], Avg Val Loss: 2.4245\n",
      "Validation loss improved from 2.4246 to 2.4245. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7734\n",
      "Epoch [1009/2000], Avg Train Loss: 3.7734\n",
      "Epoch [1009/2000], Avg Val Loss: 2.4243\n",
      "Validation loss improved from 2.4245 to 2.4243. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7066\n",
      "Epoch [1010/2000], Avg Train Loss: 3.7066\n",
      "Epoch [1010/2000], Avg Val Loss: 2.4241\n",
      "Validation loss improved from 2.4243 to 2.4241. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7310\n",
      "Epoch [1011/2000], Avg Train Loss: 3.7310\n",
      "Epoch [1011/2000], Avg Val Loss: 2.4239\n",
      "Validation loss improved from 2.4241 to 2.4239. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7476\n",
      "Epoch [1012/2000], Avg Train Loss: 3.7476\n",
      "Epoch [1012/2000], Avg Val Loss: 2.4237\n",
      "Validation loss improved from 2.4239 to 2.4237. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7254\n",
      "Epoch [1013/2000], Avg Train Loss: 3.7254\n",
      "Epoch [1013/2000], Avg Val Loss: 2.4234\n",
      "Validation loss improved from 2.4237 to 2.4234. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7471\n",
      "Epoch [1014/2000], Avg Train Loss: 3.7471\n",
      "Epoch [1014/2000], Avg Val Loss: 2.4230\n",
      "Validation loss improved from 2.4234 to 2.4230. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7447\n",
      "Epoch [1015/2000], Avg Train Loss: 3.7447\n",
      "Epoch [1015/2000], Avg Val Loss: 2.4227\n",
      "Validation loss improved from 2.4230 to 2.4227. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7157\n",
      "Epoch [1016/2000], Avg Train Loss: 3.7157\n",
      "Epoch [1016/2000], Avg Val Loss: 2.4224\n",
      "Validation loss improved from 2.4227 to 2.4224. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7450\n",
      "Epoch [1017/2000], Avg Train Loss: 3.7450\n",
      "Epoch [1017/2000], Avg Val Loss: 2.4220\n",
      "Validation loss improved from 2.4224 to 2.4220. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7103\n",
      "Epoch [1018/2000], Avg Train Loss: 3.7103\n",
      "Epoch [1018/2000], Avg Val Loss: 2.4217\n",
      "Validation loss improved from 2.4220 to 2.4217. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7453\n",
      "Epoch [1019/2000], Avg Train Loss: 3.7453\n",
      "Epoch [1019/2000], Avg Val Loss: 2.4213\n",
      "Validation loss improved from 2.4217 to 2.4213. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7292\n",
      "Epoch [1020/2000], Avg Train Loss: 3.7292\n",
      "Epoch [1020/2000], Avg Val Loss: 2.4209\n",
      "Validation loss improved from 2.4213 to 2.4209. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7694\n",
      "Epoch [1021/2000], Avg Train Loss: 3.7694\n",
      "Epoch [1021/2000], Avg Val Loss: 2.4206\n",
      "Validation loss improved from 2.4209 to 2.4206. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7647\n",
      "Epoch [1022/2000], Avg Train Loss: 3.7647\n",
      "Epoch [1022/2000], Avg Val Loss: 2.4202\n",
      "Validation loss improved from 2.4206 to 2.4202. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7566\n",
      "Epoch [1023/2000], Avg Train Loss: 3.7566\n",
      "Epoch [1023/2000], Avg Val Loss: 2.4199\n",
      "Validation loss improved from 2.4202 to 2.4199. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6895\n",
      "Epoch [1024/2000], Avg Train Loss: 3.6895\n",
      "Epoch [1024/2000], Avg Val Loss: 2.4195\n",
      "Validation loss improved from 2.4199 to 2.4195. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6984\n",
      "Epoch [1025/2000], Avg Train Loss: 3.6984\n",
      "Epoch [1025/2000], Avg Val Loss: 2.4193\n",
      "Validation loss improved from 2.4195 to 2.4193. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7008\n",
      "Epoch [1026/2000], Avg Train Loss: 3.7008\n",
      "Epoch [1026/2000], Avg Val Loss: 2.4191\n",
      "Validation loss improved from 2.4193 to 2.4191. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7255\n",
      "Epoch [1027/2000], Avg Train Loss: 3.7255\n",
      "Epoch [1027/2000], Avg Val Loss: 2.4188\n",
      "Validation loss improved from 2.4191 to 2.4188. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7450\n",
      "Epoch [1028/2000], Avg Train Loss: 3.7450\n",
      "Epoch [1028/2000], Avg Val Loss: 2.4186\n",
      "Validation loss improved from 2.4188 to 2.4186. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7161\n",
      "Epoch [1029/2000], Avg Train Loss: 3.7161\n",
      "Epoch [1029/2000], Avg Val Loss: 2.4185\n",
      "Validation loss improved from 2.4186 to 2.4185. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7002\n",
      "Epoch [1030/2000], Avg Train Loss: 3.7002\n",
      "Epoch [1030/2000], Avg Val Loss: 2.4184\n",
      "Validation loss improved from 2.4185 to 2.4184. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7202\n",
      "Epoch [1031/2000], Avg Train Loss: 3.7202\n",
      "Epoch [1031/2000], Avg Val Loss: 2.4182\n",
      "Validation loss improved from 2.4184 to 2.4182. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7550\n",
      "Epoch [1032/2000], Avg Train Loss: 3.7550\n",
      "Epoch [1032/2000], Avg Val Loss: 2.4181\n",
      "Validation loss improved from 2.4182 to 2.4181. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7196\n",
      "Epoch [1033/2000], Avg Train Loss: 3.7196\n",
      "Epoch [1033/2000], Avg Val Loss: 2.4180\n",
      "Validation loss improved from 2.4181 to 2.4180. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6995\n",
      "Epoch [1034/2000], Avg Train Loss: 3.6995\n",
      "Epoch [1034/2000], Avg Val Loss: 2.4178\n",
      "Validation loss improved from 2.4180 to 2.4178. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7415\n",
      "Epoch [1035/2000], Avg Train Loss: 3.7415\n",
      "Epoch [1035/2000], Avg Val Loss: 2.4177\n",
      "Validation loss improved from 2.4178 to 2.4177. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6997\n",
      "Epoch [1036/2000], Avg Train Loss: 3.6997\n",
      "Epoch [1036/2000], Avg Val Loss: 2.4175\n",
      "Validation loss improved from 2.4177 to 2.4175. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7464\n",
      "Epoch [1037/2000], Avg Train Loss: 3.7464\n",
      "Epoch [1037/2000], Avg Val Loss: 2.4173\n",
      "Validation loss improved from 2.4175 to 2.4173. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6896\n",
      "Epoch [1038/2000], Avg Train Loss: 3.6896\n",
      "Epoch [1038/2000], Avg Val Loss: 2.4170\n",
      "Validation loss improved from 2.4173 to 2.4170. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7406\n",
      "Epoch [1039/2000], Avg Train Loss: 3.7406\n",
      "Epoch [1039/2000], Avg Val Loss: 2.4167\n",
      "Validation loss improved from 2.4170 to 2.4167. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6989\n",
      "Epoch [1040/2000], Avg Train Loss: 3.6989\n",
      "Epoch [1040/2000], Avg Val Loss: 2.4164\n",
      "Validation loss improved from 2.4167 to 2.4164. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7037\n",
      "Epoch [1041/2000], Avg Train Loss: 3.7037\n",
      "Epoch [1041/2000], Avg Val Loss: 2.4162\n",
      "Validation loss improved from 2.4164 to 2.4162. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7334\n",
      "Epoch [1042/2000], Avg Train Loss: 3.7334\n",
      "Epoch [1042/2000], Avg Val Loss: 2.4159\n",
      "Validation loss improved from 2.4162 to 2.4159. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6947\n",
      "Epoch [1043/2000], Avg Train Loss: 3.6947\n",
      "Epoch [1043/2000], Avg Val Loss: 2.4157\n",
      "Validation loss improved from 2.4159 to 2.4157. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6977\n",
      "Epoch [1044/2000], Avg Train Loss: 3.6977\n",
      "Epoch [1044/2000], Avg Val Loss: 2.4155\n",
      "Validation loss improved from 2.4157 to 2.4155. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7144\n",
      "Epoch [1045/2000], Avg Train Loss: 3.7144\n",
      "Epoch [1045/2000], Avg Val Loss: 2.4153\n",
      "Validation loss improved from 2.4155 to 2.4153. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7216\n",
      "Epoch [1046/2000], Avg Train Loss: 3.7216\n",
      "Epoch [1046/2000], Avg Val Loss: 2.4151\n",
      "Validation loss improved from 2.4153 to 2.4151. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7273\n",
      "Epoch [1047/2000], Avg Train Loss: 3.7273\n",
      "Epoch [1047/2000], Avg Val Loss: 2.4151\n",
      "Validation loss improved from 2.4151 to 2.4151. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6767\n",
      "Epoch [1048/2000], Avg Train Loss: 3.6767\n",
      "Epoch [1048/2000], Avg Val Loss: 2.4149\n",
      "Validation loss improved from 2.4151 to 2.4149. Saving model...\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7566\n",
      "Epoch [1049/2000], Avg Train Loss: 3.7566\n",
      "Epoch [1049/2000], Avg Val Loss: 2.4148\n",
      "Validation loss improved from 2.4149 to 2.4148. Saving model...\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7033\n",
      "Epoch [1050/2000], Avg Train Loss: 3.7033\n",
      "Epoch [1050/2000], Avg Val Loss: 2.4148\n",
      "Validation loss improved from 2.4148 to 2.4148. Saving model...\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6802\n",
      "Epoch [1051/2000], Avg Train Loss: 3.6802\n",
      "Epoch [1051/2000], Avg Val Loss: 2.4146\n",
      "Validation loss improved from 2.4148 to 2.4146. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7012\n",
      "Epoch [1052/2000], Avg Train Loss: 3.7012\n",
      "Epoch [1052/2000], Avg Val Loss: 2.4145\n",
      "Validation loss improved from 2.4146 to 2.4145. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6975\n",
      "Epoch [1053/2000], Avg Train Loss: 3.6975\n",
      "Epoch [1053/2000], Avg Val Loss: 2.4143\n",
      "Validation loss improved from 2.4145 to 2.4143. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6924\n",
      "Epoch [1054/2000], Avg Train Loss: 3.6924\n",
      "Epoch [1054/2000], Avg Val Loss: 2.4141\n",
      "Validation loss improved from 2.4143 to 2.4141. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7285\n",
      "Epoch [1055/2000], Avg Train Loss: 3.7285\n",
      "Epoch [1055/2000], Avg Val Loss: 2.4139\n",
      "Validation loss improved from 2.4141 to 2.4139. Saving model...\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6844\n",
      "Epoch [1056/2000], Avg Train Loss: 3.6844\n",
      "Epoch [1056/2000], Avg Val Loss: 2.4137\n",
      "Validation loss improved from 2.4139 to 2.4137. Saving model...\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7200\n",
      "Epoch [1057/2000], Avg Train Loss: 3.7200\n",
      "Epoch [1057/2000], Avg Val Loss: 2.4135\n",
      "Validation loss improved from 2.4137 to 2.4135. Saving model...\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6568\n",
      "Epoch [1058/2000], Avg Train Loss: 3.6568\n",
      "Epoch [1058/2000], Avg Val Loss: 2.4133\n",
      "Validation loss improved from 2.4135 to 2.4133. Saving model...\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7047\n",
      "Epoch [1059/2000], Avg Train Loss: 3.7047\n",
      "Epoch [1059/2000], Avg Val Loss: 2.4131\n",
      "Validation loss improved from 2.4133 to 2.4131. Saving model...\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7165\n",
      "Epoch [1060/2000], Avg Train Loss: 3.7165\n",
      "Epoch [1060/2000], Avg Val Loss: 2.4128\n",
      "Validation loss improved from 2.4131 to 2.4128. Saving model...\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7156\n",
      "Epoch [1061/2000], Avg Train Loss: 3.7156\n",
      "Epoch [1061/2000], Avg Val Loss: 2.4125\n",
      "Validation loss improved from 2.4128 to 2.4125. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7310\n",
      "Epoch [1062/2000], Avg Train Loss: 3.7310\n",
      "Epoch [1062/2000], Avg Val Loss: 2.4123\n",
      "Validation loss improved from 2.4125 to 2.4123. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6860\n",
      "Epoch [1063/2000], Avg Train Loss: 3.6860\n",
      "Epoch [1063/2000], Avg Val Loss: 2.4121\n",
      "Validation loss improved from 2.4123 to 2.4121. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7188\n",
      "Epoch [1064/2000], Avg Train Loss: 3.7188\n",
      "Epoch [1064/2000], Avg Val Loss: 2.4120\n",
      "Validation loss improved from 2.4121 to 2.4120. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6940\n",
      "Epoch [1065/2000], Avg Train Loss: 3.6940\n",
      "Epoch [1065/2000], Avg Val Loss: 2.4118\n",
      "Validation loss improved from 2.4120 to 2.4118. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6544\n",
      "Epoch [1066/2000], Avg Train Loss: 3.6544\n",
      "Epoch [1066/2000], Avg Val Loss: 2.4117\n",
      "Validation loss improved from 2.4118 to 2.4117. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6597\n",
      "Epoch [1067/2000], Avg Train Loss: 3.6597\n",
      "Epoch [1067/2000], Avg Val Loss: 2.4115\n",
      "Validation loss improved from 2.4117 to 2.4115. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6984\n",
      "Epoch [1068/2000], Avg Train Loss: 3.6984\n",
      "Epoch [1068/2000], Avg Val Loss: 2.4112\n",
      "Validation loss improved from 2.4115 to 2.4112. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6622\n",
      "Epoch [1069/2000], Avg Train Loss: 3.6622\n",
      "Epoch [1069/2000], Avg Val Loss: 2.4110\n",
      "Validation loss improved from 2.4112 to 2.4110. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6995\n",
      "Epoch [1070/2000], Avg Train Loss: 3.6995\n",
      "Epoch [1070/2000], Avg Val Loss: 2.4109\n",
      "Validation loss improved from 2.4110 to 2.4109. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7360\n",
      "Epoch [1071/2000], Avg Train Loss: 3.7360\n",
      "Epoch [1071/2000], Avg Val Loss: 2.4108\n",
      "Validation loss improved from 2.4109 to 2.4108. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7316\n",
      "Epoch [1072/2000], Avg Train Loss: 3.7316\n",
      "Epoch [1072/2000], Avg Val Loss: 2.4106\n",
      "Validation loss improved from 2.4108 to 2.4106. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6702\n",
      "Epoch [1073/2000], Avg Train Loss: 3.6702\n",
      "Epoch [1073/2000], Avg Val Loss: 2.4105\n",
      "Validation loss improved from 2.4106 to 2.4105. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6696\n",
      "Epoch [1074/2000], Avg Train Loss: 3.6696\n",
      "Epoch [1074/2000], Avg Val Loss: 2.4104\n",
      "Validation loss improved from 2.4105 to 2.4104. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6832\n",
      "Epoch [1075/2000], Avg Train Loss: 3.6832\n",
      "Epoch [1075/2000], Avg Val Loss: 2.4103\n",
      "Validation loss improved from 2.4104 to 2.4103. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6755\n",
      "Epoch [1076/2000], Avg Train Loss: 3.6755\n",
      "Epoch [1076/2000], Avg Val Loss: 2.4102\n",
      "Validation loss improved from 2.4103 to 2.4102. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6679\n",
      "Epoch [1077/2000], Avg Train Loss: 3.6679\n",
      "Epoch [1077/2000], Avg Val Loss: 2.4102\n",
      "Validation loss improved from 2.4102 to 2.4102. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6762\n",
      "Epoch [1078/2000], Avg Train Loss: 3.6762\n",
      "Epoch [1078/2000], Avg Val Loss: 2.4100\n",
      "Validation loss improved from 2.4102 to 2.4100. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6626\n",
      "Epoch [1079/2000], Avg Train Loss: 3.6626\n",
      "Epoch [1079/2000], Avg Val Loss: 2.4098\n",
      "Validation loss improved from 2.4100 to 2.4098. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6955\n",
      "Epoch [1080/2000], Avg Train Loss: 3.6955\n",
      "Epoch [1080/2000], Avg Val Loss: 2.4096\n",
      "Validation loss improved from 2.4098 to 2.4096. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6776\n",
      "Epoch [1081/2000], Avg Train Loss: 3.6776\n",
      "Epoch [1081/2000], Avg Val Loss: 2.4093\n",
      "Validation loss improved from 2.4096 to 2.4093. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7025\n",
      "Epoch [1082/2000], Avg Train Loss: 3.7025\n",
      "Epoch [1082/2000], Avg Val Loss: 2.4091\n",
      "Validation loss improved from 2.4093 to 2.4091. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6921\n",
      "Epoch [1083/2000], Avg Train Loss: 3.6921\n",
      "Epoch [1083/2000], Avg Val Loss: 2.4089\n",
      "Validation loss improved from 2.4091 to 2.4089. Saving model...\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6814\n",
      "Epoch [1084/2000], Avg Train Loss: 3.6814\n",
      "Epoch [1084/2000], Avg Val Loss: 2.4087\n",
      "Validation loss improved from 2.4089 to 2.4087. Saving model...\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7077\n",
      "Epoch [1085/2000], Avg Train Loss: 3.7077\n",
      "Epoch [1085/2000], Avg Val Loss: 2.4087\n",
      "Validation loss improved from 2.4087 to 2.4087. Saving model...\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7212\n",
      "Epoch [1086/2000], Avg Train Loss: 3.7212\n",
      "Epoch [1086/2000], Avg Val Loss: 2.4085\n",
      "Validation loss improved from 2.4087 to 2.4085. Saving model...\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7088\n",
      "Epoch [1087/2000], Avg Train Loss: 3.7088\n",
      "Epoch [1087/2000], Avg Val Loss: 2.4085\n",
      "Validation loss improved from 2.4085 to 2.4085. Saving model...\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6925\n",
      "Epoch [1088/2000], Avg Train Loss: 3.6925\n",
      "Epoch [1088/2000], Avg Val Loss: 2.4084\n",
      "Validation loss improved from 2.4085 to 2.4084. Saving model...\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7010\n",
      "Epoch [1089/2000], Avg Train Loss: 3.7010\n",
      "Epoch [1089/2000], Avg Val Loss: 2.4083\n",
      "Validation loss improved from 2.4084 to 2.4083. Saving model...\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6672\n",
      "Epoch [1090/2000], Avg Train Loss: 3.6672\n",
      "Epoch [1090/2000], Avg Val Loss: 2.4082\n",
      "Validation loss improved from 2.4083 to 2.4082. Saving model...\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6743\n",
      "Epoch [1091/2000], Avg Train Loss: 3.6743\n",
      "Epoch [1091/2000], Avg Val Loss: 2.4081\n",
      "Validation loss improved from 2.4082 to 2.4081. Saving model...\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6621\n",
      "Epoch [1092/2000], Avg Train Loss: 3.6621\n",
      "Epoch [1092/2000], Avg Val Loss: 2.4080\n",
      "Validation loss improved from 2.4081 to 2.4080. Saving model...\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6523\n",
      "Epoch [1093/2000], Avg Train Loss: 3.6523\n",
      "Epoch [1093/2000], Avg Val Loss: 2.4080\n",
      "Validation loss improved from 2.4080 to 2.4080. Saving model...\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6796\n",
      "Epoch [1094/2000], Avg Train Loss: 3.6796\n",
      "Epoch [1094/2000], Avg Val Loss: 2.4080\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6586\n",
      "Epoch [1095/2000], Avg Train Loss: 3.6586\n",
      "Epoch [1095/2000], Avg Val Loss: 2.4080\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7072\n",
      "Epoch [1096/2000], Avg Train Loss: 3.7072\n",
      "Epoch [1096/2000], Avg Val Loss: 2.4081\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6727\n",
      "Epoch [1097/2000], Avg Train Loss: 3.6727\n",
      "Epoch [1097/2000], Avg Val Loss: 2.4082\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6747\n",
      "Epoch [1098/2000], Avg Train Loss: 3.6747\n",
      "Epoch [1098/2000], Avg Val Loss: 2.4084\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6783\n",
      "Epoch [1099/2000], Avg Train Loss: 3.6783\n",
      "Epoch [1099/2000], Avg Val Loss: 2.4086\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6674\n",
      "Epoch [1100/2000], Avg Train Loss: 3.6674\n",
      "Epoch [1100/2000], Avg Val Loss: 2.4087\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6827\n",
      "Epoch [1101/2000], Avg Train Loss: 3.6827\n",
      "Epoch [1101/2000], Avg Val Loss: 2.4089\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6628\n",
      "Epoch [1102/2000], Avg Train Loss: 3.6628\n",
      "Epoch [1102/2000], Avg Val Loss: 2.4089\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6967\n",
      "Epoch [1103/2000], Avg Train Loss: 3.6967\n",
      "Epoch [1103/2000], Avg Val Loss: 2.4091\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6968\n",
      "Epoch [1104/2000], Avg Train Loss: 3.6968\n",
      "Epoch [1104/2000], Avg Val Loss: 2.4090\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7041\n",
      "Epoch [1105/2000], Avg Train Loss: 3.7041\n",
      "Epoch [1105/2000], Avg Val Loss: 2.4090\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6429\n",
      "Epoch [1106/2000], Avg Train Loss: 3.6429\n",
      "Epoch [1106/2000], Avg Val Loss: 2.4091\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6692\n",
      "Epoch [1107/2000], Avg Train Loss: 3.6692\n",
      "Epoch [1107/2000], Avg Val Loss: 2.4092\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6949\n",
      "Epoch [1108/2000], Avg Train Loss: 3.6949\n",
      "Epoch [1108/2000], Avg Val Loss: 2.4092\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6992\n",
      "Epoch [1109/2000], Avg Train Loss: 3.6992\n",
      "Epoch [1109/2000], Avg Val Loss: 2.4093\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6812\n",
      "Epoch [1110/2000], Avg Train Loss: 3.6812\n",
      "Epoch [1110/2000], Avg Val Loss: 2.4093\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6925\n",
      "Epoch [1111/2000], Avg Train Loss: 3.6925\n",
      "Epoch [1111/2000], Avg Val Loss: 2.4093\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6433\n",
      "Epoch [1112/2000], Avg Train Loss: 3.6433\n",
      "Epoch [1112/2000], Avg Val Loss: 2.4092\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7094\n",
      "Epoch [1113/2000], Avg Train Loss: 3.7094\n",
      "Epoch [1113/2000], Avg Val Loss: 2.4091\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6279\n",
      "Epoch [1114/2000], Avg Train Loss: 3.6279\n",
      "Epoch [1114/2000], Avg Val Loss: 2.4089\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6554\n",
      "Epoch [1115/2000], Avg Train Loss: 3.6554\n",
      "Epoch [1115/2000], Avg Val Loss: 2.4088\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7161\n",
      "Epoch [1116/2000], Avg Train Loss: 3.7161\n",
      "Epoch [1116/2000], Avg Val Loss: 2.4086\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6577\n",
      "Epoch [1117/2000], Avg Train Loss: 3.6577\n",
      "Epoch [1117/2000], Avg Val Loss: 2.4084\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6500\n",
      "Epoch [1118/2000], Avg Train Loss: 3.6500\n",
      "Epoch [1118/2000], Avg Val Loss: 2.4082\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6597\n",
      "Epoch [1119/2000], Avg Train Loss: 3.6597\n",
      "Epoch [1119/2000], Avg Val Loss: 2.4081\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6519\n",
      "Epoch [1120/2000], Avg Train Loss: 3.6519\n",
      "Epoch [1120/2000], Avg Val Loss: 2.4080\n",
      "Validation loss improved from 2.4080 to 2.4080. Saving model...\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6973\n",
      "Epoch [1121/2000], Avg Train Loss: 3.6973\n",
      "Epoch [1121/2000], Avg Val Loss: 2.4078\n",
      "Validation loss improved from 2.4080 to 2.4078. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6523\n",
      "Epoch [1122/2000], Avg Train Loss: 3.6523\n",
      "Epoch [1122/2000], Avg Val Loss: 2.4076\n",
      "Validation loss improved from 2.4078 to 2.4076. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6593\n",
      "Epoch [1123/2000], Avg Train Loss: 3.6593\n",
      "Epoch [1123/2000], Avg Val Loss: 2.4074\n",
      "Validation loss improved from 2.4076 to 2.4074. Saving model...\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6581\n",
      "Epoch [1124/2000], Avg Train Loss: 3.6581\n",
      "Epoch [1124/2000], Avg Val Loss: 2.4073\n",
      "Validation loss improved from 2.4074 to 2.4073. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7196\n",
      "Epoch [1125/2000], Avg Train Loss: 3.7196\n",
      "Epoch [1125/2000], Avg Val Loss: 2.4072\n",
      "Validation loss improved from 2.4073 to 2.4072. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6574\n",
      "Epoch [1126/2000], Avg Train Loss: 3.6574\n",
      "Epoch [1126/2000], Avg Val Loss: 2.4071\n",
      "Validation loss improved from 2.4072 to 2.4071. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7030\n",
      "Epoch [1127/2000], Avg Train Loss: 3.7030\n",
      "Epoch [1127/2000], Avg Val Loss: 2.4071\n",
      "Validation loss improved from 2.4071 to 2.4071. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6690\n",
      "Epoch [1128/2000], Avg Train Loss: 3.6690\n",
      "Epoch [1128/2000], Avg Val Loss: 2.4070\n",
      "Validation loss improved from 2.4071 to 2.4070. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6853\n",
      "Epoch [1129/2000], Avg Train Loss: 3.6853\n",
      "Epoch [1129/2000], Avg Val Loss: 2.4069\n",
      "Validation loss improved from 2.4070 to 2.4069. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6501\n",
      "Epoch [1130/2000], Avg Train Loss: 3.6501\n",
      "Epoch [1130/2000], Avg Val Loss: 2.4069\n",
      "Validation loss improved from 2.4069 to 2.4069. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6340\n",
      "Epoch [1131/2000], Avg Train Loss: 3.6340\n",
      "Epoch [1131/2000], Avg Val Loss: 2.4069\n",
      "Validation loss improved from 2.4069 to 2.4069. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6514\n",
      "Epoch [1132/2000], Avg Train Loss: 3.6514\n",
      "Epoch [1132/2000], Avg Val Loss: 2.4069\n",
      "Validation loss improved from 2.4069 to 2.4069. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6235\n",
      "Epoch [1133/2000], Avg Train Loss: 3.6235\n",
      "Epoch [1133/2000], Avg Val Loss: 2.4068\n",
      "Validation loss improved from 2.4069 to 2.4068. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6467\n",
      "Epoch [1134/2000], Avg Train Loss: 3.6467\n",
      "Epoch [1134/2000], Avg Val Loss: 2.4068\n",
      "Validation loss improved from 2.4068 to 2.4068. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6715\n",
      "Epoch [1135/2000], Avg Train Loss: 3.6715\n",
      "Epoch [1135/2000], Avg Val Loss: 2.4068\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6782\n",
      "Epoch [1136/2000], Avg Train Loss: 3.6782\n",
      "Epoch [1136/2000], Avg Val Loss: 2.4067\n",
      "Validation loss improved from 2.4068 to 2.4067. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6855\n",
      "Epoch [1137/2000], Avg Train Loss: 3.6855\n",
      "Epoch [1137/2000], Avg Val Loss: 2.4067\n",
      "Validation loss improved from 2.4067 to 2.4067. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6512\n",
      "Epoch [1138/2000], Avg Train Loss: 3.6512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1138/2000], Avg Val Loss: 2.4066\n",
      "Validation loss improved from 2.4067 to 2.4066. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6754\n",
      "Epoch [1139/2000], Avg Train Loss: 3.6754\n",
      "Epoch [1139/2000], Avg Val Loss: 2.4066\n",
      "Validation loss improved from 2.4066 to 2.4066. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6807\n",
      "Epoch [1140/2000], Avg Train Loss: 3.6807\n",
      "Epoch [1140/2000], Avg Val Loss: 2.4065\n",
      "Validation loss improved from 2.4066 to 2.4065. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6329\n",
      "Epoch [1141/2000], Avg Train Loss: 3.6329\n",
      "Epoch [1141/2000], Avg Val Loss: 2.4064\n",
      "Validation loss improved from 2.4065 to 2.4064. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6761\n",
      "Epoch [1142/2000], Avg Train Loss: 3.6761\n",
      "Epoch [1142/2000], Avg Val Loss: 2.4063\n",
      "Validation loss improved from 2.4064 to 2.4063. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6614\n",
      "Epoch [1143/2000], Avg Train Loss: 3.6614\n",
      "Epoch [1143/2000], Avg Val Loss: 2.4061\n",
      "Validation loss improved from 2.4063 to 2.4061. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6428\n",
      "Epoch [1144/2000], Avg Train Loss: 3.6428\n",
      "Epoch [1144/2000], Avg Val Loss: 2.4061\n",
      "Validation loss improved from 2.4061 to 2.4061. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6865\n",
      "Epoch [1145/2000], Avg Train Loss: 3.6865\n",
      "Epoch [1145/2000], Avg Val Loss: 2.4060\n",
      "Validation loss improved from 2.4061 to 2.4060. Saving model...\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6544\n",
      "Epoch [1146/2000], Avg Train Loss: 3.6544\n",
      "Epoch [1146/2000], Avg Val Loss: 2.4060\n",
      "Validation loss improved from 2.4060 to 2.4060. Saving model...\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6311\n",
      "Epoch [1147/2000], Avg Train Loss: 3.6311\n",
      "Epoch [1147/2000], Avg Val Loss: 2.4060\n",
      "Validation loss improved from 2.4060 to 2.4060. Saving model...\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6491\n",
      "Epoch [1148/2000], Avg Train Loss: 3.6491\n",
      "Epoch [1148/2000], Avg Val Loss: 2.4059\n",
      "Validation loss improved from 2.4060 to 2.4059. Saving model...\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6221\n",
      "Epoch [1149/2000], Avg Train Loss: 3.6221\n",
      "Epoch [1149/2000], Avg Val Loss: 2.4058\n",
      "Validation loss improved from 2.4059 to 2.4058. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6703\n",
      "Epoch [1150/2000], Avg Train Loss: 3.6703\n",
      "Epoch [1150/2000], Avg Val Loss: 2.4058\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6573\n",
      "Epoch [1151/2000], Avg Train Loss: 3.6573\n",
      "Epoch [1151/2000], Avg Val Loss: 2.4057\n",
      "Validation loss improved from 2.4058 to 2.4057. Saving model...\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6595\n",
      "Epoch [1152/2000], Avg Train Loss: 3.6595\n",
      "Epoch [1152/2000], Avg Val Loss: 2.4056\n",
      "Validation loss improved from 2.4057 to 2.4056. Saving model...\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6327\n",
      "Epoch [1153/2000], Avg Train Loss: 3.6327\n",
      "Epoch [1153/2000], Avg Val Loss: 2.4055\n",
      "Validation loss improved from 2.4056 to 2.4055. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6640\n",
      "Epoch [1154/2000], Avg Train Loss: 3.6640\n",
      "Epoch [1154/2000], Avg Val Loss: 2.4053\n",
      "Validation loss improved from 2.4055 to 2.4053. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6265\n",
      "Epoch [1155/2000], Avg Train Loss: 3.6265\n",
      "Epoch [1155/2000], Avg Val Loss: 2.4052\n",
      "Validation loss improved from 2.4053 to 2.4052. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6513\n",
      "Epoch [1156/2000], Avg Train Loss: 3.6513\n",
      "Epoch [1156/2000], Avg Val Loss: 2.4051\n",
      "Validation loss improved from 2.4052 to 2.4051. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6446\n",
      "Epoch [1157/2000], Avg Train Loss: 3.6446\n",
      "Epoch [1157/2000], Avg Val Loss: 2.4051\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6558\n",
      "Epoch [1158/2000], Avg Train Loss: 3.6558\n",
      "Epoch [1158/2000], Avg Val Loss: 2.4051\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6871\n",
      "Epoch [1159/2000], Avg Train Loss: 3.6871\n",
      "Epoch [1159/2000], Avg Val Loss: 2.4051\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6471\n",
      "Epoch [1160/2000], Avg Train Loss: 3.6471\n",
      "Epoch [1160/2000], Avg Val Loss: 2.4051\n",
      "Validation loss improved from 2.4051 to 2.4051. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6586\n",
      "Epoch [1161/2000], Avg Train Loss: 3.6586\n",
      "Epoch [1161/2000], Avg Val Loss: 2.4050\n",
      "Validation loss improved from 2.4051 to 2.4050. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6237\n",
      "Epoch [1162/2000], Avg Train Loss: 3.6237\n",
      "Epoch [1162/2000], Avg Val Loss: 2.4048\n",
      "Validation loss improved from 2.4050 to 2.4048. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6500\n",
      "Epoch [1163/2000], Avg Train Loss: 3.6500\n",
      "Epoch [1163/2000], Avg Val Loss: 2.4047\n",
      "Validation loss improved from 2.4048 to 2.4047. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6416\n",
      "Epoch [1164/2000], Avg Train Loss: 3.6416\n",
      "Epoch [1164/2000], Avg Val Loss: 2.4045\n",
      "Validation loss improved from 2.4047 to 2.4045. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6532\n",
      "Epoch [1165/2000], Avg Train Loss: 3.6532\n",
      "Epoch [1165/2000], Avg Val Loss: 2.4044\n",
      "Validation loss improved from 2.4045 to 2.4044. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6281\n",
      "Epoch [1166/2000], Avg Train Loss: 3.6281\n",
      "Epoch [1166/2000], Avg Val Loss: 2.4042\n",
      "Validation loss improved from 2.4044 to 2.4042. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6175\n",
      "Epoch [1167/2000], Avg Train Loss: 3.6175\n",
      "Epoch [1167/2000], Avg Val Loss: 2.4040\n",
      "Validation loss improved from 2.4042 to 2.4040. Saving model...\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6589\n",
      "Epoch [1168/2000], Avg Train Loss: 3.6589\n",
      "Epoch [1168/2000], Avg Val Loss: 2.4038\n",
      "Validation loss improved from 2.4040 to 2.4038. Saving model...\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6096\n",
      "Epoch [1169/2000], Avg Train Loss: 3.6096\n",
      "Epoch [1169/2000], Avg Val Loss: 2.4036\n",
      "Validation loss improved from 2.4038 to 2.4036. Saving model...\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6332\n",
      "Epoch [1170/2000], Avg Train Loss: 3.6332\n",
      "Epoch [1170/2000], Avg Val Loss: 2.4034\n",
      "Validation loss improved from 2.4036 to 2.4034. Saving model...\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6193\n",
      "Epoch [1171/2000], Avg Train Loss: 3.6193\n",
      "Epoch [1171/2000], Avg Val Loss: 2.4033\n",
      "Validation loss improved from 2.4034 to 2.4033. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6473\n",
      "Epoch [1172/2000], Avg Train Loss: 3.6473\n",
      "Epoch [1172/2000], Avg Val Loss: 2.4031\n",
      "Validation loss improved from 2.4033 to 2.4031. Saving model...\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6049\n",
      "Epoch [1173/2000], Avg Train Loss: 3.6049\n",
      "Epoch [1173/2000], Avg Val Loss: 2.4030\n",
      "Validation loss improved from 2.4031 to 2.4030. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6496\n",
      "Epoch [1174/2000], Avg Train Loss: 3.6496\n",
      "Epoch [1174/2000], Avg Val Loss: 2.4029\n",
      "Validation loss improved from 2.4030 to 2.4029. Saving model...\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6615\n",
      "Epoch [1175/2000], Avg Train Loss: 3.6615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1175/2000], Avg Val Loss: 2.4028\n",
      "Validation loss improved from 2.4029 to 2.4028. Saving model...\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6343\n",
      "Epoch [1176/2000], Avg Train Loss: 3.6343\n",
      "Epoch [1176/2000], Avg Val Loss: 2.4027\n",
      "Validation loss improved from 2.4028 to 2.4027. Saving model...\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6523\n",
      "Epoch [1177/2000], Avg Train Loss: 3.6523\n",
      "Epoch [1177/2000], Avg Val Loss: 2.4028\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6900\n",
      "Epoch [1178/2000], Avg Train Loss: 3.6900\n",
      "Epoch [1178/2000], Avg Val Loss: 2.4028\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6360\n",
      "Epoch [1179/2000], Avg Train Loss: 3.6360\n",
      "Epoch [1179/2000], Avg Val Loss: 2.4027\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6202\n",
      "Epoch [1180/2000], Avg Train Loss: 3.6202\n",
      "Epoch [1180/2000], Avg Val Loss: 2.4026\n",
      "Validation loss improved from 2.4027 to 2.4026. Saving model...\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6805\n",
      "Epoch [1181/2000], Avg Train Loss: 3.6805\n",
      "Epoch [1181/2000], Avg Val Loss: 2.4024\n",
      "Validation loss improved from 2.4026 to 2.4024. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6493\n",
      "Epoch [1182/2000], Avg Train Loss: 3.6493\n",
      "Epoch [1182/2000], Avg Val Loss: 2.4021\n",
      "Validation loss improved from 2.4024 to 2.4021. Saving model...\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6289\n",
      "Epoch [1183/2000], Avg Train Loss: 3.6289\n",
      "Epoch [1183/2000], Avg Val Loss: 2.4018\n",
      "Validation loss improved from 2.4021 to 2.4018. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6145\n",
      "Epoch [1184/2000], Avg Train Loss: 3.6145\n",
      "Epoch [1184/2000], Avg Val Loss: 2.4014\n",
      "Validation loss improved from 2.4018 to 2.4014. Saving model...\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6135\n",
      "Epoch [1185/2000], Avg Train Loss: 3.6135\n",
      "Epoch [1185/2000], Avg Val Loss: 2.4012\n",
      "Validation loss improved from 2.4014 to 2.4012. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6752\n",
      "Epoch [1186/2000], Avg Train Loss: 3.6752\n",
      "Epoch [1186/2000], Avg Val Loss: 2.4010\n",
      "Validation loss improved from 2.4012 to 2.4010. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6054\n",
      "Epoch [1187/2000], Avg Train Loss: 3.6054\n",
      "Epoch [1187/2000], Avg Val Loss: 2.4008\n",
      "Validation loss improved from 2.4010 to 2.4008. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6307\n",
      "Epoch [1188/2000], Avg Train Loss: 3.6307\n",
      "Epoch [1188/2000], Avg Val Loss: 2.4007\n",
      "Validation loss improved from 2.4008 to 2.4007. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6248\n",
      "Epoch [1189/2000], Avg Train Loss: 3.6248\n",
      "Epoch [1189/2000], Avg Val Loss: 2.4004\n",
      "Validation loss improved from 2.4007 to 2.4004. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6575\n",
      "Epoch [1190/2000], Avg Train Loss: 3.6575\n",
      "Epoch [1190/2000], Avg Val Loss: 2.4003\n",
      "Validation loss improved from 2.4004 to 2.4003. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6007\n",
      "Epoch [1191/2000], Avg Train Loss: 3.6007\n",
      "Epoch [1191/2000], Avg Val Loss: 2.4002\n",
      "Validation loss improved from 2.4003 to 2.4002. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6344\n",
      "Epoch [1192/2000], Avg Train Loss: 3.6344\n",
      "Epoch [1192/2000], Avg Val Loss: 2.4001\n",
      "Validation loss improved from 2.4002 to 2.4001. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6310\n",
      "Epoch [1193/2000], Avg Train Loss: 3.6310\n",
      "Epoch [1193/2000], Avg Val Loss: 2.4001\n",
      "Validation loss improved from 2.4001 to 2.4001. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5910\n",
      "Epoch [1194/2000], Avg Train Loss: 3.5910\n",
      "Epoch [1194/2000], Avg Val Loss: 2.4002\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6290\n",
      "Epoch [1195/2000], Avg Train Loss: 3.6290\n",
      "Epoch [1195/2000], Avg Val Loss: 2.4003\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6056\n",
      "Epoch [1196/2000], Avg Train Loss: 3.6056\n",
      "Epoch [1196/2000], Avg Val Loss: 2.4004\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6209\n",
      "Epoch [1197/2000], Avg Train Loss: 3.6209\n",
      "Epoch [1197/2000], Avg Val Loss: 2.4005\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6172\n",
      "Epoch [1198/2000], Avg Train Loss: 3.6172\n",
      "Epoch [1198/2000], Avg Val Loss: 2.4007\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6523\n",
      "Epoch [1199/2000], Avg Train Loss: 3.6523\n",
      "Epoch [1199/2000], Avg Val Loss: 2.4009\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6034\n",
      "Epoch [1200/2000], Avg Train Loss: 3.6034\n",
      "Epoch [1200/2000], Avg Val Loss: 2.4010\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6247\n",
      "Epoch [1201/2000], Avg Train Loss: 3.6247\n",
      "Epoch [1201/2000], Avg Val Loss: 2.4010\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6048\n",
      "Epoch [1202/2000], Avg Train Loss: 3.6048\n",
      "Epoch [1202/2000], Avg Val Loss: 2.4009\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5340\n",
      "Epoch [1203/2000], Avg Train Loss: 3.5340\n",
      "Epoch [1203/2000], Avg Val Loss: 2.4008\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6139\n",
      "Epoch [1204/2000], Avg Train Loss: 3.6139\n",
      "Epoch [1204/2000], Avg Val Loss: 2.4008\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5818\n",
      "Epoch [1205/2000], Avg Train Loss: 3.5818\n",
      "Epoch [1205/2000], Avg Val Loss: 2.4007\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6235\n",
      "Epoch [1206/2000], Avg Train Loss: 3.6235\n",
      "Epoch [1206/2000], Avg Val Loss: 2.4006\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6138\n",
      "Epoch [1207/2000], Avg Train Loss: 3.6138\n",
      "Epoch [1207/2000], Avg Val Loss: 2.4003\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5917\n",
      "Epoch [1208/2000], Avg Train Loss: 3.5917\n",
      "Epoch [1208/2000], Avg Val Loss: 2.4001\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5841\n",
      "Epoch [1209/2000], Avg Train Loss: 3.5841\n",
      "Epoch [1209/2000], Avg Val Loss: 2.3998\n",
      "Validation loss improved from 2.4001 to 2.3998. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6084\n",
      "Epoch [1210/2000], Avg Train Loss: 3.6084\n",
      "Epoch [1210/2000], Avg Val Loss: 2.3996\n",
      "Validation loss improved from 2.3998 to 2.3996. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6387\n",
      "Epoch [1211/2000], Avg Train Loss: 3.6387\n",
      "Epoch [1211/2000], Avg Val Loss: 2.3994\n",
      "Validation loss improved from 2.3996 to 2.3994. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6309\n",
      "Epoch [1212/2000], Avg Train Loss: 3.6309\n",
      "Epoch [1212/2000], Avg Val Loss: 2.3993\n",
      "Validation loss improved from 2.3994 to 2.3993. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6084\n",
      "Epoch [1213/2000], Avg Train Loss: 3.6084\n",
      "Epoch [1213/2000], Avg Val Loss: 2.3992\n",
      "Validation loss improved from 2.3993 to 2.3992. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6297\n",
      "Epoch [1214/2000], Avg Train Loss: 3.6297\n",
      "Epoch [1214/2000], Avg Val Loss: 2.3991\n",
      "Validation loss improved from 2.3992 to 2.3991. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6427\n",
      "Epoch [1215/2000], Avg Train Loss: 3.6427\n",
      "Epoch [1215/2000], Avg Val Loss: 2.3990\n",
      "Validation loss improved from 2.3991 to 2.3990. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6094\n",
      "Epoch [1216/2000], Avg Train Loss: 3.6094\n",
      "Epoch [1216/2000], Avg Val Loss: 2.3990\n",
      "Validation loss improved from 2.3990 to 2.3990. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6060\n",
      "Epoch [1217/2000], Avg Train Loss: 3.6060\n",
      "Epoch [1217/2000], Avg Val Loss: 2.3989\n",
      "Validation loss improved from 2.3990 to 2.3989. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5947\n",
      "Epoch [1218/2000], Avg Train Loss: 3.5947\n",
      "Epoch [1218/2000], Avg Val Loss: 2.3988\n",
      "Validation loss improved from 2.3989 to 2.3988. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5870\n",
      "Epoch [1219/2000], Avg Train Loss: 3.5870\n",
      "Epoch [1219/2000], Avg Val Loss: 2.3986\n",
      "Validation loss improved from 2.3988 to 2.3986. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6402\n",
      "Epoch [1220/2000], Avg Train Loss: 3.6402\n",
      "Epoch [1220/2000], Avg Val Loss: 2.3984\n",
      "Validation loss improved from 2.3986 to 2.3984. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5717\n",
      "Epoch [1221/2000], Avg Train Loss: 3.5717\n",
      "Epoch [1221/2000], Avg Val Loss: 2.3983\n",
      "Validation loss improved from 2.3984 to 2.3983. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6340\n",
      "Epoch [1222/2000], Avg Train Loss: 3.6340\n",
      "Epoch [1222/2000], Avg Val Loss: 2.3981\n",
      "Validation loss improved from 2.3983 to 2.3981. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5871\n",
      "Epoch [1223/2000], Avg Train Loss: 3.5871\n",
      "Epoch [1223/2000], Avg Val Loss: 2.3980\n",
      "Validation loss improved from 2.3981 to 2.3980. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5904\n",
      "Epoch [1224/2000], Avg Train Loss: 3.5904\n",
      "Epoch [1224/2000], Avg Val Loss: 2.3980\n",
      "Validation loss improved from 2.3980 to 2.3980. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6495\n",
      "Epoch [1225/2000], Avg Train Loss: 3.6495\n",
      "Epoch [1225/2000], Avg Val Loss: 2.3981\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6256\n",
      "Epoch [1226/2000], Avg Train Loss: 3.6256\n",
      "Epoch [1226/2000], Avg Val Loss: 2.3981\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5965\n",
      "Epoch [1227/2000], Avg Train Loss: 3.5965\n",
      "Epoch [1227/2000], Avg Val Loss: 2.3981\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6254\n",
      "Epoch [1228/2000], Avg Train Loss: 3.6254\n",
      "Epoch [1228/2000], Avg Val Loss: 2.3982\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5970\n",
      "Epoch [1229/2000], Avg Train Loss: 3.5970\n",
      "Epoch [1229/2000], Avg Val Loss: 2.3982\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5911\n",
      "Epoch [1230/2000], Avg Train Loss: 3.5911\n",
      "Epoch [1230/2000], Avg Val Loss: 2.3982\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6424\n",
      "Epoch [1231/2000], Avg Train Loss: 3.6424\n",
      "Epoch [1231/2000], Avg Val Loss: 2.3983\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5976\n",
      "Epoch [1232/2000], Avg Train Loss: 3.5976\n",
      "Epoch [1232/2000], Avg Val Loss: 2.3984\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5815\n",
      "Epoch [1233/2000], Avg Train Loss: 3.5815\n",
      "Epoch [1233/2000], Avg Val Loss: 2.3986\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5952\n",
      "Epoch [1234/2000], Avg Train Loss: 3.5952\n",
      "Epoch [1234/2000], Avg Val Loss: 2.3987\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5769\n",
      "Epoch [1235/2000], Avg Train Loss: 3.5769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1235/2000], Avg Val Loss: 2.3988\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6526\n",
      "Epoch [1236/2000], Avg Train Loss: 3.6526\n",
      "Epoch [1236/2000], Avg Val Loss: 2.3988\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6073\n",
      "Epoch [1237/2000], Avg Train Loss: 3.6073\n",
      "Epoch [1237/2000], Avg Val Loss: 2.3988\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6351\n",
      "Epoch [1238/2000], Avg Train Loss: 3.6351\n",
      "Epoch [1238/2000], Avg Val Loss: 2.3987\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5882\n",
      "Epoch [1239/2000], Avg Train Loss: 3.5882\n",
      "Epoch [1239/2000], Avg Val Loss: 2.3988\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6165\n",
      "Epoch [1240/2000], Avg Train Loss: 3.6165\n",
      "Epoch [1240/2000], Avg Val Loss: 2.3988\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5988\n",
      "Epoch [1241/2000], Avg Train Loss: 3.5988\n",
      "Epoch [1241/2000], Avg Val Loss: 2.3990\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6234\n",
      "Epoch [1242/2000], Avg Train Loss: 3.6234\n",
      "Epoch [1242/2000], Avg Val Loss: 2.3992\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6129\n",
      "Epoch [1243/2000], Avg Train Loss: 3.6129\n",
      "Epoch [1243/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5700\n",
      "Epoch [1244/2000], Avg Train Loss: 3.5700\n",
      "Epoch [1244/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6410\n",
      "Epoch [1245/2000], Avg Train Loss: 3.6410\n",
      "Epoch [1245/2000], Avg Val Loss: 2.3994\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6213\n",
      "Epoch [1246/2000], Avg Train Loss: 3.6213\n",
      "Epoch [1246/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6168\n",
      "Epoch [1247/2000], Avg Train Loss: 3.6168\n",
      "Epoch [1247/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5884\n",
      "Epoch [1248/2000], Avg Train Loss: 3.5884\n",
      "Epoch [1248/2000], Avg Val Loss: 2.3992\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6095\n",
      "Epoch [1249/2000], Avg Train Loss: 3.6095\n",
      "Epoch [1249/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6019\n",
      "Epoch [1250/2000], Avg Train Loss: 3.6019\n",
      "Epoch [1250/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6107\n",
      "Epoch [1251/2000], Avg Train Loss: 3.6107\n",
      "Epoch [1251/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6449\n",
      "Epoch [1252/2000], Avg Train Loss: 3.6449\n",
      "Epoch [1252/2000], Avg Val Loss: 2.3994\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6209\n",
      "Epoch [1253/2000], Avg Train Loss: 3.6209\n",
      "Epoch [1253/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6190\n",
      "Epoch [1254/2000], Avg Train Loss: 3.6190\n",
      "Epoch [1254/2000], Avg Val Loss: 2.3996\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6122\n",
      "Epoch [1255/2000], Avg Train Loss: 3.6122\n",
      "Epoch [1255/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5999\n",
      "Epoch [1256/2000], Avg Train Loss: 3.5999\n",
      "Epoch [1256/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5950\n",
      "Epoch [1257/2000], Avg Train Loss: 3.5950\n",
      "Epoch [1257/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5733\n",
      "Epoch [1258/2000], Avg Train Loss: 3.5733\n",
      "Epoch [1258/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6479\n",
      "Epoch [1259/2000], Avg Train Loss: 3.6479\n",
      "Epoch [1259/2000], Avg Val Loss: 2.3994\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6048\n",
      "Epoch [1260/2000], Avg Train Loss: 3.6048\n",
      "Epoch [1260/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6076\n",
      "Epoch [1261/2000], Avg Train Loss: 3.6076\n",
      "Epoch [1261/2000], Avg Val Loss: 2.3998\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5836\n",
      "Epoch [1262/2000], Avg Train Loss: 3.5836\n",
      "Epoch [1262/2000], Avg Val Loss: 2.4000\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6257\n",
      "Epoch [1263/2000], Avg Train Loss: 3.6257\n",
      "Epoch [1263/2000], Avg Val Loss: 2.4001\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5730\n",
      "Epoch [1264/2000], Avg Train Loss: 3.5730\n",
      "Epoch [1264/2000], Avg Val Loss: 2.4002\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5896\n",
      "Epoch [1265/2000], Avg Train Loss: 3.5896\n",
      "Epoch [1265/2000], Avg Val Loss: 2.4003\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6128\n",
      "Epoch [1266/2000], Avg Train Loss: 3.6128\n",
      "Epoch [1266/2000], Avg Val Loss: 2.4003\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5425\n",
      "Epoch [1267/2000], Avg Train Loss: 3.5425\n",
      "Epoch [1267/2000], Avg Val Loss: 2.4002\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5925\n",
      "Epoch [1268/2000], Avg Train Loss: 3.5925\n",
      "Epoch [1268/2000], Avg Val Loss: 2.4001\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5933\n",
      "Epoch [1269/2000], Avg Train Loss: 3.5933\n",
      "Epoch [1269/2000], Avg Val Loss: 2.4000\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6251\n",
      "Epoch [1270/2000], Avg Train Loss: 3.6251\n",
      "Epoch [1270/2000], Avg Val Loss: 2.3999\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5679\n",
      "Epoch [1271/2000], Avg Train Loss: 3.5679\n",
      "Epoch [1271/2000], Avg Val Loss: 2.3997\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5551\n",
      "Epoch [1272/2000], Avg Train Loss: 3.5551\n",
      "Epoch [1272/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6151\n",
      "Epoch [1273/2000], Avg Train Loss: 3.6151\n",
      "Epoch [1273/2000], Avg Val Loss: 2.3995\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5975\n",
      "Epoch [1274/2000], Avg Train Loss: 3.5975\n",
      "Epoch [1274/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6005\n",
      "Epoch [1275/2000], Avg Train Loss: 3.6005\n",
      "Epoch [1275/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5932\n",
      "Epoch [1276/2000], Avg Train Loss: 3.5932\n",
      "Epoch [1276/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5862\n",
      "Epoch [1277/2000], Avg Train Loss: 3.5862\n",
      "Epoch [1277/2000], Avg Val Loss: 2.3993\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5746\n",
      "Epoch [1278/2000], Avg Train Loss: 3.5746\n",
      "Epoch [1278/2000], Avg Val Loss: 2.3994\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5438\n",
      "Epoch [1279/2000], Avg Train Loss: 3.5438\n",
      "Epoch [1279/2000], Avg Val Loss: 2.3997\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5657\n",
      "Epoch [1280/2000], Avg Train Loss: 3.5657\n",
      "Epoch [1280/2000], Avg Val Loss: 2.3999\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6115\n",
      "Epoch [1281/2000], Avg Train Loss: 3.6115\n",
      "Epoch [1281/2000], Avg Val Loss: 2.4001\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5778\n",
      "Epoch [1282/2000], Avg Train Loss: 3.5778\n",
      "Epoch [1282/2000], Avg Val Loss: 2.4002\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6127\n",
      "Epoch [1283/2000], Avg Train Loss: 3.6127\n",
      "Epoch [1283/2000], Avg Val Loss: 2.4004\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5722\n",
      "Epoch [1284/2000], Avg Train Loss: 3.5722\n",
      "Epoch [1284/2000], Avg Val Loss: 2.4005\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6186\n",
      "Epoch [1285/2000], Avg Train Loss: 3.6186\n",
      "Epoch [1285/2000], Avg Val Loss: 2.4006\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5686\n",
      "Epoch [1286/2000], Avg Train Loss: 3.5686\n",
      "Epoch [1286/2000], Avg Val Loss: 2.4005\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5926\n",
      "Epoch [1287/2000], Avg Train Loss: 3.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1287/2000], Avg Val Loss: 2.4005\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5919\n",
      "Epoch [1288/2000], Avg Train Loss: 3.5919\n",
      "Epoch [1288/2000], Avg Val Loss: 2.4004\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5573\n",
      "Epoch [1289/2000], Avg Train Loss: 3.5573\n",
      "Epoch [1289/2000], Avg Val Loss: 2.4004\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6101\n",
      "Epoch [1290/2000], Avg Train Loss: 3.6101\n",
      "Epoch [1290/2000], Avg Val Loss: 2.4001\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5682\n",
      "Epoch [1291/2000], Avg Train Loss: 3.5682\n",
      "Epoch [1291/2000], Avg Val Loss: 2.3998\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5957\n",
      "Epoch [1292/2000], Avg Train Loss: 3.5957\n",
      "Epoch [1292/2000], Avg Val Loss: 2.3996\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5767\n",
      "Epoch [1293/2000], Avg Train Loss: 3.5767\n",
      "Epoch [1293/2000], Avg Val Loss: 2.3991\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5766\n",
      "Epoch [1294/2000], Avg Train Loss: 3.5766\n",
      "Epoch [1294/2000], Avg Val Loss: 2.3987\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5503\n",
      "Epoch [1295/2000], Avg Train Loss: 3.5503\n",
      "Epoch [1295/2000], Avg Val Loss: 2.3982\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5603\n",
      "Epoch [1296/2000], Avg Train Loss: 3.5603\n",
      "Epoch [1296/2000], Avg Val Loss: 2.3978\n",
      "Validation loss improved from 2.3980 to 2.3978. Saving model...\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5711\n",
      "Epoch [1297/2000], Avg Train Loss: 3.5711\n",
      "Epoch [1297/2000], Avg Val Loss: 2.3973\n",
      "Validation loss improved from 2.3978 to 2.3973. Saving model...\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5707\n",
      "Epoch [1298/2000], Avg Train Loss: 3.5707\n",
      "Epoch [1298/2000], Avg Val Loss: 2.3970\n",
      "Validation loss improved from 2.3973 to 2.3970. Saving model...\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6113\n",
      "Epoch [1299/2000], Avg Train Loss: 3.6113\n",
      "Epoch [1299/2000], Avg Val Loss: 2.3967\n",
      "Validation loss improved from 2.3970 to 2.3967. Saving model...\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6076\n",
      "Epoch [1300/2000], Avg Train Loss: 3.6076\n",
      "Epoch [1300/2000], Avg Val Loss: 2.3963\n",
      "Validation loss improved from 2.3967 to 2.3963. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5754\n",
      "Epoch [1301/2000], Avg Train Loss: 3.5754\n",
      "Epoch [1301/2000], Avg Val Loss: 2.3961\n",
      "Validation loss improved from 2.3963 to 2.3961. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5881\n",
      "Epoch [1302/2000], Avg Train Loss: 3.5881\n",
      "Epoch [1302/2000], Avg Val Loss: 2.3960\n",
      "Validation loss improved from 2.3961 to 2.3960. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5393\n",
      "Epoch [1303/2000], Avg Train Loss: 3.5393\n",
      "Epoch [1303/2000], Avg Val Loss: 2.3960\n",
      "Validation loss improved from 2.3960 to 2.3960. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5664\n",
      "Epoch [1304/2000], Avg Train Loss: 3.5664\n",
      "Epoch [1304/2000], Avg Val Loss: 2.3959\n",
      "Validation loss improved from 2.3960 to 2.3959. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5536\n",
      "Epoch [1305/2000], Avg Train Loss: 3.5536\n",
      "Epoch [1305/2000], Avg Val Loss: 2.3959\n",
      "Validation loss improved from 2.3959 to 2.3959. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5529\n",
      "Epoch [1306/2000], Avg Train Loss: 3.5529\n",
      "Epoch [1306/2000], Avg Val Loss: 2.3961\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6010\n",
      "Epoch [1307/2000], Avg Train Loss: 3.6010\n",
      "Epoch [1307/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5624\n",
      "Epoch [1308/2000], Avg Train Loss: 3.5624\n",
      "Epoch [1308/2000], Avg Val Loss: 2.3964\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5810\n",
      "Epoch [1309/2000], Avg Train Loss: 3.5810\n",
      "Epoch [1309/2000], Avg Val Loss: 2.3964\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5824\n",
      "Epoch [1310/2000], Avg Train Loss: 3.5824\n",
      "Epoch [1310/2000], Avg Val Loss: 2.3965\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5693\n",
      "Epoch [1311/2000], Avg Train Loss: 3.5693\n",
      "Epoch [1311/2000], Avg Val Loss: 2.3966\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5953\n",
      "Epoch [1312/2000], Avg Train Loss: 3.5953\n",
      "Epoch [1312/2000], Avg Val Loss: 2.3966\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5877\n",
      "Epoch [1313/2000], Avg Train Loss: 3.5877\n",
      "Epoch [1313/2000], Avg Val Loss: 2.3966\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5539\n",
      "Epoch [1314/2000], Avg Train Loss: 3.5539\n",
      "Epoch [1314/2000], Avg Val Loss: 2.3966\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5855\n",
      "Epoch [1315/2000], Avg Train Loss: 3.5855\n",
      "Epoch [1315/2000], Avg Val Loss: 2.3967\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5567\n",
      "Epoch [1316/2000], Avg Train Loss: 3.5567\n",
      "Epoch [1316/2000], Avg Val Loss: 2.3968\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5541\n",
      "Epoch [1317/2000], Avg Train Loss: 3.5541\n",
      "Epoch [1317/2000], Avg Val Loss: 2.3969\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5787\n",
      "Epoch [1318/2000], Avg Train Loss: 3.5787\n",
      "Epoch [1318/2000], Avg Val Loss: 2.3971\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5815\n",
      "Epoch [1319/2000], Avg Train Loss: 3.5815\n",
      "Epoch [1319/2000], Avg Val Loss: 2.3972\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5976\n",
      "Epoch [1320/2000], Avg Train Loss: 3.5976\n",
      "Epoch [1320/2000], Avg Val Loss: 2.3972\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6032\n",
      "Epoch [1321/2000], Avg Train Loss: 3.6032\n",
      "Epoch [1321/2000], Avg Val Loss: 2.3972\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5873\n",
      "Epoch [1322/2000], Avg Train Loss: 3.5873\n",
      "Epoch [1322/2000], Avg Val Loss: 2.3971\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5685\n",
      "Epoch [1323/2000], Avg Train Loss: 3.5685\n",
      "Epoch [1323/2000], Avg Val Loss: 2.3970\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5502\n",
      "Epoch [1324/2000], Avg Train Loss: 3.5502\n",
      "Epoch [1324/2000], Avg Val Loss: 2.3968\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5526\n",
      "Epoch [1325/2000], Avg Train Loss: 3.5526\n",
      "Epoch [1325/2000], Avg Val Loss: 2.3966\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5979\n",
      "Epoch [1326/2000], Avg Train Loss: 3.5979\n",
      "Epoch [1326/2000], Avg Val Loss: 2.3964\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5779\n",
      "Epoch [1327/2000], Avg Train Loss: 3.5779\n",
      "Epoch [1327/2000], Avg Val Loss: 2.3964\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5808\n",
      "Epoch [1328/2000], Avg Train Loss: 3.5808\n",
      "Epoch [1328/2000], Avg Val Loss: 2.3962\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5722\n",
      "Epoch [1329/2000], Avg Train Loss: 3.5722\n",
      "Epoch [1329/2000], Avg Val Loss: 2.3962\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5793\n",
      "Epoch [1330/2000], Avg Train Loss: 3.5793\n",
      "Epoch [1330/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5705\n",
      "Epoch [1331/2000], Avg Train Loss: 3.5705\n",
      "Epoch [1331/2000], Avg Val Loss: 2.3964\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5862\n",
      "Epoch [1332/2000], Avg Train Loss: 3.5862\n",
      "Epoch [1332/2000], Avg Val Loss: 2.3964\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5829\n",
      "Epoch [1333/2000], Avg Train Loss: 3.5829\n",
      "Epoch [1333/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5208\n",
      "Epoch [1334/2000], Avg Train Loss: 3.5208\n",
      "Epoch [1334/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6029\n",
      "Epoch [1335/2000], Avg Train Loss: 3.6029\n",
      "Epoch [1335/2000], Avg Val Loss: 2.3962\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5638\n",
      "Epoch [1336/2000], Avg Train Loss: 3.5638\n",
      "Epoch [1336/2000], Avg Val Loss: 2.3961\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5781\n",
      "Epoch [1337/2000], Avg Train Loss: 3.5781\n",
      "Epoch [1337/2000], Avg Val Loss: 2.3960\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5998\n",
      "Epoch [1338/2000], Avg Train Loss: 3.5998\n",
      "Epoch [1338/2000], Avg Val Loss: 2.3959\n",
      "Validation loss improved from 2.3959 to 2.3959. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5624\n",
      "Epoch [1339/2000], Avg Train Loss: 3.5624\n",
      "Epoch [1339/2000], Avg Val Loss: 2.3959\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5483\n",
      "Epoch [1340/2000], Avg Train Loss: 3.5483\n",
      "Epoch [1340/2000], Avg Val Loss: 2.3960\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5402\n",
      "Epoch [1341/2000], Avg Train Loss: 3.5402\n",
      "Epoch [1341/2000], Avg Val Loss: 2.3959\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5516\n",
      "Epoch [1342/2000], Avg Train Loss: 3.5516\n",
      "Epoch [1342/2000], Avg Val Loss: 2.3959\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5698\n",
      "Epoch [1343/2000], Avg Train Loss: 3.5698\n",
      "Epoch [1343/2000], Avg Val Loss: 2.3958\n",
      "Validation loss improved from 2.3959 to 2.3958. Saving model...\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5883\n",
      "Epoch [1344/2000], Avg Train Loss: 3.5883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1344/2000], Avg Val Loss: 2.3957\n",
      "Validation loss improved from 2.3958 to 2.3957. Saving model...\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5274\n",
      "Epoch [1345/2000], Avg Train Loss: 3.5274\n",
      "Epoch [1345/2000], Avg Val Loss: 2.3955\n",
      "Validation loss improved from 2.3957 to 2.3955. Saving model...\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5234\n",
      "Epoch [1346/2000], Avg Train Loss: 3.5234\n",
      "Epoch [1346/2000], Avg Val Loss: 2.3953\n",
      "Validation loss improved from 2.3955 to 2.3953. Saving model...\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5470\n",
      "Epoch [1347/2000], Avg Train Loss: 3.5470\n",
      "Epoch [1347/2000], Avg Val Loss: 2.3952\n",
      "Validation loss improved from 2.3953 to 2.3952. Saving model...\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5861\n",
      "Epoch [1348/2000], Avg Train Loss: 3.5861\n",
      "Epoch [1348/2000], Avg Val Loss: 2.3951\n",
      "Validation loss improved from 2.3952 to 2.3951. Saving model...\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5766\n",
      "Epoch [1349/2000], Avg Train Loss: 3.5766\n",
      "Epoch [1349/2000], Avg Val Loss: 2.3949\n",
      "Validation loss improved from 2.3951 to 2.3949. Saving model...\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5877\n",
      "Epoch [1350/2000], Avg Train Loss: 3.5877\n",
      "Epoch [1350/2000], Avg Val Loss: 2.3947\n",
      "Validation loss improved from 2.3949 to 2.3947. Saving model...\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5702\n",
      "Epoch [1351/2000], Avg Train Loss: 3.5702\n",
      "Epoch [1351/2000], Avg Val Loss: 2.3946\n",
      "Validation loss improved from 2.3947 to 2.3946. Saving model...\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5772\n",
      "Epoch [1352/2000], Avg Train Loss: 3.5772\n",
      "Epoch [1352/2000], Avg Val Loss: 2.3947\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5814\n",
      "Epoch [1353/2000], Avg Train Loss: 3.5814\n",
      "Epoch [1353/2000], Avg Val Loss: 2.3949\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5513\n",
      "Epoch [1354/2000], Avg Train Loss: 3.5513\n",
      "Epoch [1354/2000], Avg Val Loss: 2.3952\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5749\n",
      "Epoch [1355/2000], Avg Train Loss: 3.5749\n",
      "Epoch [1355/2000], Avg Val Loss: 2.3955\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5659\n",
      "Epoch [1356/2000], Avg Train Loss: 3.5659\n",
      "Epoch [1356/2000], Avg Val Loss: 2.3956\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5693\n",
      "Epoch [1357/2000], Avg Train Loss: 3.5693\n",
      "Epoch [1357/2000], Avg Val Loss: 2.3958\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5655\n",
      "Epoch [1358/2000], Avg Train Loss: 3.5655\n",
      "Epoch [1358/2000], Avg Val Loss: 2.3958\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5702\n",
      "Epoch [1359/2000], Avg Train Loss: 3.5702\n",
      "Epoch [1359/2000], Avg Val Loss: 2.3957\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5729\n",
      "Epoch [1360/2000], Avg Train Loss: 3.5729\n",
      "Epoch [1360/2000], Avg Val Loss: 2.3955\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5379\n",
      "Epoch [1361/2000], Avg Train Loss: 3.5379\n",
      "Epoch [1361/2000], Avg Val Loss: 2.3952\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5205\n",
      "Epoch [1362/2000], Avg Train Loss: 3.5205\n",
      "Epoch [1362/2000], Avg Val Loss: 2.3950\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5362\n",
      "Epoch [1363/2000], Avg Train Loss: 3.5362\n",
      "Epoch [1363/2000], Avg Val Loss: 2.3947\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5546\n",
      "Epoch [1364/2000], Avg Train Loss: 3.5546\n",
      "Epoch [1364/2000], Avg Val Loss: 2.3944\n",
      "Validation loss improved from 2.3946 to 2.3944. Saving model...\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5496\n",
      "Epoch [1365/2000], Avg Train Loss: 3.5496\n",
      "Epoch [1365/2000], Avg Val Loss: 2.3940\n",
      "Validation loss improved from 2.3944 to 2.3940. Saving model...\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5945\n",
      "Epoch [1366/2000], Avg Train Loss: 3.5945\n",
      "Epoch [1366/2000], Avg Val Loss: 2.3936\n",
      "Validation loss improved from 2.3940 to 2.3936. Saving model...\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5771\n",
      "Epoch [1367/2000], Avg Train Loss: 3.5771\n",
      "Epoch [1367/2000], Avg Val Loss: 2.3932\n",
      "Validation loss improved from 2.3936 to 2.3932. Saving model...\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5806\n",
      "Epoch [1368/2000], Avg Train Loss: 3.5806\n",
      "Epoch [1368/2000], Avg Val Loss: 2.3929\n",
      "Validation loss improved from 2.3932 to 2.3929. Saving model...\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5564\n",
      "Epoch [1369/2000], Avg Train Loss: 3.5564\n",
      "Epoch [1369/2000], Avg Val Loss: 2.3925\n",
      "Validation loss improved from 2.3929 to 2.3925. Saving model...\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5635\n",
      "Epoch [1370/2000], Avg Train Loss: 3.5635\n",
      "Epoch [1370/2000], Avg Val Loss: 2.3920\n",
      "Validation loss improved from 2.3925 to 2.3920. Saving model...\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5867\n",
      "Epoch [1371/2000], Avg Train Loss: 3.5867\n",
      "Epoch [1371/2000], Avg Val Loss: 2.3916\n",
      "Validation loss improved from 2.3920 to 2.3916. Saving model...\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5632\n",
      "Epoch [1372/2000], Avg Train Loss: 3.5632\n",
      "Epoch [1372/2000], Avg Val Loss: 2.3912\n",
      "Validation loss improved from 2.3916 to 2.3912. Saving model...\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5355\n",
      "Epoch [1373/2000], Avg Train Loss: 3.5355\n",
      "Epoch [1373/2000], Avg Val Loss: 2.3909\n",
      "Validation loss improved from 2.3912 to 2.3909. Saving model...\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5350\n",
      "Epoch [1374/2000], Avg Train Loss: 3.5350\n",
      "Epoch [1374/2000], Avg Val Loss: 2.3906\n",
      "Validation loss improved from 2.3909 to 2.3906. Saving model...\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5764\n",
      "Epoch [1375/2000], Avg Train Loss: 3.5764\n",
      "Epoch [1375/2000], Avg Val Loss: 2.3905\n",
      "Validation loss improved from 2.3906 to 2.3905. Saving model...\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5620\n",
      "Epoch [1376/2000], Avg Train Loss: 3.5620\n",
      "Epoch [1376/2000], Avg Val Loss: 2.3905\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5453\n",
      "Epoch [1377/2000], Avg Train Loss: 3.5453\n",
      "Epoch [1377/2000], Avg Val Loss: 2.3906\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5459\n",
      "Epoch [1378/2000], Avg Train Loss: 3.5459\n",
      "Epoch [1378/2000], Avg Val Loss: 2.3907\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6077\n",
      "Epoch [1379/2000], Avg Train Loss: 3.6077\n",
      "Epoch [1379/2000], Avg Val Loss: 2.3908\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5599\n",
      "Epoch [1380/2000], Avg Train Loss: 3.5599\n",
      "Epoch [1380/2000], Avg Val Loss: 2.3909\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5111\n",
      "Epoch [1381/2000], Avg Train Loss: 3.5111\n",
      "Epoch [1381/2000], Avg Val Loss: 2.3909\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5449\n",
      "Epoch [1382/2000], Avg Train Loss: 3.5449\n",
      "Epoch [1382/2000], Avg Val Loss: 2.3911\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5641\n",
      "Epoch [1383/2000], Avg Train Loss: 3.5641\n",
      "Epoch [1383/2000], Avg Val Loss: 2.3913\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5564\n",
      "Epoch [1384/2000], Avg Train Loss: 3.5564\n",
      "Epoch [1384/2000], Avg Val Loss: 2.3915\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5155\n",
      "Epoch [1385/2000], Avg Train Loss: 3.5155\n",
      "Epoch [1385/2000], Avg Val Loss: 2.3919\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5296\n",
      "Epoch [1386/2000], Avg Train Loss: 3.5296\n",
      "Epoch [1386/2000], Avg Val Loss: 2.3922\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5782\n",
      "Epoch [1387/2000], Avg Train Loss: 3.5782\n",
      "Epoch [1387/2000], Avg Val Loss: 2.3925\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5504\n",
      "Epoch [1388/2000], Avg Train Loss: 3.5504\n",
      "Epoch [1388/2000], Avg Val Loss: 2.3927\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5559\n",
      "Epoch [1389/2000], Avg Train Loss: 3.5559\n",
      "Epoch [1389/2000], Avg Val Loss: 2.3929\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5167\n",
      "Epoch [1390/2000], Avg Train Loss: 3.5167\n",
      "Epoch [1390/2000], Avg Val Loss: 2.3931\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5735\n",
      "Epoch [1391/2000], Avg Train Loss: 3.5735\n",
      "Epoch [1391/2000], Avg Val Loss: 2.3933\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5447\n",
      "Epoch [1392/2000], Avg Train Loss: 3.5447\n",
      "Epoch [1392/2000], Avg Val Loss: 2.3934\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5602\n",
      "Epoch [1393/2000], Avg Train Loss: 3.5602\n",
      "Epoch [1393/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5415\n",
      "Epoch [1394/2000], Avg Train Loss: 3.5415\n",
      "Epoch [1394/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5718\n",
      "Epoch [1395/2000], Avg Train Loss: 3.5718\n",
      "Epoch [1395/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5469\n",
      "Epoch [1396/2000], Avg Train Loss: 3.5469\n",
      "Epoch [1396/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5638\n",
      "Epoch [1397/2000], Avg Train Loss: 3.5638\n",
      "Epoch [1397/2000], Avg Val Loss: 2.3938\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5313\n",
      "Epoch [1398/2000], Avg Train Loss: 3.5313\n",
      "Epoch [1398/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5012\n",
      "Epoch [1399/2000], Avg Train Loss: 3.5012\n",
      "Epoch [1399/2000], Avg Val Loss: 2.3938\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5780\n",
      "Epoch [1400/2000], Avg Train Loss: 3.5780\n",
      "Epoch [1400/2000], Avg Val Loss: 2.3938\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5419\n",
      "Epoch [1401/2000], Avg Train Loss: 3.5419\n",
      "Epoch [1401/2000], Avg Val Loss: 2.3939\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5339\n",
      "Epoch [1402/2000], Avg Train Loss: 3.5339\n",
      "Epoch [1402/2000], Avg Val Loss: 2.3938\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [1403/2000], Avg Train Loss: 3.5321\n",
      "Epoch [1403/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5618\n",
      "Epoch [1404/2000], Avg Train Loss: 3.5618\n",
      "Epoch [1404/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5294\n",
      "Epoch [1405/2000], Avg Train Loss: 3.5294\n",
      "Epoch [1405/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5420\n",
      "Epoch [1406/2000], Avg Train Loss: 3.5420\n",
      "Epoch [1406/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5072\n",
      "Epoch [1407/2000], Avg Train Loss: 3.5072\n",
      "Epoch [1407/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4946\n",
      "Epoch [1408/2000], Avg Train Loss: 3.4946\n",
      "Epoch [1408/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5652\n",
      "Epoch [1409/2000], Avg Train Loss: 3.5652\n",
      "Epoch [1409/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5535\n",
      "Epoch [1410/2000], Avg Train Loss: 3.5535\n",
      "Epoch [1410/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5396\n",
      "Epoch [1411/2000], Avg Train Loss: 3.5396\n",
      "Epoch [1411/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5310\n",
      "Epoch [1412/2000], Avg Train Loss: 3.5310\n",
      "Epoch [1412/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5537\n",
      "Epoch [1413/2000], Avg Train Loss: 3.5537\n",
      "Epoch [1413/2000], Avg Val Loss: 2.3933\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5502\n",
      "Epoch [1414/2000], Avg Train Loss: 3.5502\n",
      "Epoch [1414/2000], Avg Val Loss: 2.3929\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5516\n",
      "Epoch [1415/2000], Avg Train Loss: 3.5516\n",
      "Epoch [1415/2000], Avg Val Loss: 2.3925\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5257\n",
      "Epoch [1416/2000], Avg Train Loss: 3.5257\n",
      "Epoch [1416/2000], Avg Val Loss: 2.3922\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5419\n",
      "Epoch [1417/2000], Avg Train Loss: 3.5419\n",
      "Epoch [1417/2000], Avg Val Loss: 2.3920\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4774\n",
      "Epoch [1418/2000], Avg Train Loss: 3.4774\n",
      "Epoch [1418/2000], Avg Val Loss: 2.3918\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5746\n",
      "Epoch [1419/2000], Avg Train Loss: 3.5746\n",
      "Epoch [1419/2000], Avg Val Loss: 2.3917\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5351\n",
      "Epoch [1420/2000], Avg Train Loss: 3.5351\n",
      "Epoch [1420/2000], Avg Val Loss: 2.3915\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5169\n",
      "Epoch [1421/2000], Avg Train Loss: 3.5169\n",
      "Epoch [1421/2000], Avg Val Loss: 2.3913\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5327\n",
      "Epoch [1422/2000], Avg Train Loss: 3.5327\n",
      "Epoch [1422/2000], Avg Val Loss: 2.3911\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5150\n",
      "Epoch [1423/2000], Avg Train Loss: 3.5150\n",
      "Epoch [1423/2000], Avg Val Loss: 2.3909\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5204\n",
      "Epoch [1424/2000], Avg Train Loss: 3.5204\n",
      "Epoch [1424/2000], Avg Val Loss: 2.3909\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5149\n",
      "Epoch [1425/2000], Avg Train Loss: 3.5149\n",
      "Epoch [1425/2000], Avg Val Loss: 2.3910\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5435\n",
      "Epoch [1426/2000], Avg Train Loss: 3.5435\n",
      "Epoch [1426/2000], Avg Val Loss: 2.3911\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4986\n",
      "Epoch [1427/2000], Avg Train Loss: 3.4986\n",
      "Epoch [1427/2000], Avg Val Loss: 2.3913\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5278\n",
      "Epoch [1428/2000], Avg Train Loss: 3.5278\n",
      "Epoch [1428/2000], Avg Val Loss: 2.3913\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5380\n",
      "Epoch [1429/2000], Avg Train Loss: 3.5380\n",
      "Epoch [1429/2000], Avg Val Loss: 2.3914\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5306\n",
      "Epoch [1430/2000], Avg Train Loss: 3.5306\n",
      "Epoch [1430/2000], Avg Val Loss: 2.3914\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5592\n",
      "Epoch [1431/2000], Avg Train Loss: 3.5592\n",
      "Epoch [1431/2000], Avg Val Loss: 2.3916\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5207\n",
      "Epoch [1432/2000], Avg Train Loss: 3.5207\n",
      "Epoch [1432/2000], Avg Val Loss: 2.3919\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5097\n",
      "Epoch [1433/2000], Avg Train Loss: 3.5097\n",
      "Epoch [1433/2000], Avg Val Loss: 2.3921\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5067\n",
      "Epoch [1434/2000], Avg Train Loss: 3.5067\n",
      "Epoch [1434/2000], Avg Val Loss: 2.3923\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5152\n",
      "Epoch [1435/2000], Avg Train Loss: 3.5152\n",
      "Epoch [1435/2000], Avg Val Loss: 2.3923\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5134\n",
      "Epoch [1436/2000], Avg Train Loss: 3.5134\n",
      "Epoch [1436/2000], Avg Val Loss: 2.3925\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5497\n",
      "Epoch [1437/2000], Avg Train Loss: 3.5497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1437/2000], Avg Val Loss: 2.3926\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5682\n",
      "Epoch [1438/2000], Avg Train Loss: 3.5682\n",
      "Epoch [1438/2000], Avg Val Loss: 2.3927\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5549\n",
      "Epoch [1439/2000], Avg Train Loss: 3.5549\n",
      "Epoch [1439/2000], Avg Val Loss: 2.3928\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5325\n",
      "Epoch [1440/2000], Avg Train Loss: 3.5325\n",
      "Epoch [1440/2000], Avg Val Loss: 2.3929\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5305\n",
      "Epoch [1441/2000], Avg Train Loss: 3.5305\n",
      "Epoch [1441/2000], Avg Val Loss: 2.3931\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5226\n",
      "Epoch [1442/2000], Avg Train Loss: 3.5226\n",
      "Epoch [1442/2000], Avg Val Loss: 2.3933\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5114\n",
      "Epoch [1443/2000], Avg Train Loss: 3.5114\n",
      "Epoch [1443/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5032\n",
      "Epoch [1444/2000], Avg Train Loss: 3.5032\n",
      "Epoch [1444/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5081\n",
      "Epoch [1445/2000], Avg Train Loss: 3.5081\n",
      "Epoch [1445/2000], Avg Val Loss: 2.3938\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5071\n",
      "Epoch [1446/2000], Avg Train Loss: 3.5071\n",
      "Epoch [1446/2000], Avg Val Loss: 2.3939\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5493\n",
      "Epoch [1447/2000], Avg Train Loss: 3.5493\n",
      "Epoch [1447/2000], Avg Val Loss: 2.3940\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5118\n",
      "Epoch [1448/2000], Avg Train Loss: 3.5118\n",
      "Epoch [1448/2000], Avg Val Loss: 2.3942\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5301\n",
      "Epoch [1449/2000], Avg Train Loss: 3.5301\n",
      "Epoch [1449/2000], Avg Val Loss: 2.3941\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5180\n",
      "Epoch [1450/2000], Avg Train Loss: 3.5180\n",
      "Epoch [1450/2000], Avg Val Loss: 2.3941\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5593\n",
      "Epoch [1451/2000], Avg Train Loss: 3.5593\n",
      "Epoch [1451/2000], Avg Val Loss: 2.3939\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5342\n",
      "Epoch [1452/2000], Avg Train Loss: 3.5342\n",
      "Epoch [1452/2000], Avg Val Loss: 2.3939\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5521\n",
      "Epoch [1453/2000], Avg Train Loss: 3.5521\n",
      "Epoch [1453/2000], Avg Val Loss: 2.3939\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5379\n",
      "Epoch [1454/2000], Avg Train Loss: 3.5379\n",
      "Epoch [1454/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5385\n",
      "Epoch [1455/2000], Avg Train Loss: 3.5385\n",
      "Epoch [1455/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5077\n",
      "Epoch [1456/2000], Avg Train Loss: 3.5077\n",
      "Epoch [1456/2000], Avg Val Loss: 2.3937\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5166\n",
      "Epoch [1457/2000], Avg Train Loss: 3.5166\n",
      "Epoch [1457/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5382\n",
      "Epoch [1458/2000], Avg Train Loss: 3.5382\n",
      "Epoch [1458/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5165\n",
      "Epoch [1459/2000], Avg Train Loss: 3.5165\n",
      "Epoch [1459/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5335\n",
      "Epoch [1460/2000], Avg Train Loss: 3.5335\n",
      "Epoch [1460/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4825\n",
      "Epoch [1461/2000], Avg Train Loss: 3.4825\n",
      "Epoch [1461/2000], Avg Val Loss: 2.3936\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5494\n",
      "Epoch [1462/2000], Avg Train Loss: 3.5494\n",
      "Epoch [1462/2000], Avg Val Loss: 2.3935\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4843\n",
      "Epoch [1463/2000], Avg Train Loss: 3.4843\n",
      "Epoch [1463/2000], Avg Val Loss: 2.3933\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5124\n",
      "Epoch [1464/2000], Avg Train Loss: 3.5124\n",
      "Epoch [1464/2000], Avg Val Loss: 2.3929\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5373\n",
      "Epoch [1465/2000], Avg Train Loss: 3.5373\n",
      "Epoch [1465/2000], Avg Val Loss: 2.3928\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5095\n",
      "Epoch [1466/2000], Avg Train Loss: 3.5095\n",
      "Epoch [1466/2000], Avg Val Loss: 2.3926\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5259\n",
      "Epoch [1467/2000], Avg Train Loss: 3.5259\n",
      "Epoch [1467/2000], Avg Val Loss: 2.3923\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5505\n",
      "Epoch [1468/2000], Avg Train Loss: 3.5505\n",
      "Epoch [1468/2000], Avg Val Loss: 2.3922\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5134\n",
      "Epoch [1469/2000], Avg Train Loss: 3.5134\n",
      "Epoch [1469/2000], Avg Val Loss: 2.3921\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5233\n",
      "Epoch [1470/2000], Avg Train Loss: 3.5233\n",
      "Epoch [1470/2000], Avg Val Loss: 2.3921\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5376\n",
      "Epoch [1471/2000], Avg Train Loss: 3.5376\n",
      "Epoch [1471/2000], Avg Val Loss: 2.3921\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5363\n",
      "Epoch [1472/2000], Avg Train Loss: 3.5363\n",
      "Epoch [1472/2000], Avg Val Loss: 2.3921\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5239\n",
      "Epoch [1473/2000], Avg Train Loss: 3.5239\n",
      "Epoch [1473/2000], Avg Val Loss: 2.3922\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5241\n",
      "Epoch [1474/2000], Avg Train Loss: 3.5241\n",
      "Epoch [1474/2000], Avg Val Loss: 2.3922\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5130\n",
      "Epoch [1475/2000], Avg Train Loss: 3.5130\n",
      "Epoch [1475/2000], Avg Val Loss: 2.3922\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1475. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:56.777599Z",
     "iopub.status.busy": "2025-05-08T18:54:56.777599Z",
     "iopub.status.idle": "2025-05-08T18:54:56.908766Z",
     "shell.execute_reply": "2025-05-08T18:54:56.908766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/12], Loss: 5.2896\n",
      "\n",
      "Test Loss: 5.0315\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:56.911770Z",
     "iopub.status.busy": "2025-05-08T18:54:56.910770Z",
     "iopub.status.idle": "2025-05-08T18:54:56.980134Z",
     "shell.execute_reply": "2025-05-08T18:54:56.980134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:56.983139Z",
     "iopub.status.busy": "2025-05-08T18:54:56.982139Z",
     "iopub.status.idle": "2025-05-08T18:54:56.986421Z",
     "shell.execute_reply": "2025-05-08T18:54:56.986421Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:56.988430Z",
     "iopub.status.busy": "2025-05-08T18:54:56.988430Z",
     "iopub.status.idle": "2025-05-08T18:54:57.138215Z",
     "shell.execute_reply": "2025-05-08T18:54:57.138215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:57.141222Z",
     "iopub.status.busy": "2025-05-08T18:54:57.140221Z",
     "iopub.status.idle": "2025-05-08T18:54:57.193199Z",
     "shell.execute_reply": "2025-05-08T18:54:57.192687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 87.14%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       0.75      0.60      0.67         5\n",
      "           5       0.75      0.60      0.67         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.80      0.80      0.80         5\n",
      "           9       0.71      1.00      0.83         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.60      0.60      0.60         5\n",
      "          13       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.87        70\n",
      "   macro avg       0.88      0.87      0.87        70\n",
      "weighted avg       0.88      0.87      0.87        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 86.23%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       245\n",
      "           1       0.63      0.95      0.75        76\n",
      "           2       0.93      0.91      0.92       226\n",
      "           3       0.81      0.99      0.89       190\n",
      "           4       0.87      0.64      0.74       244\n",
      "           5       0.70      0.73      0.72       244\n",
      "           6       0.94      0.93      0.94       234\n",
      "           7       0.86      0.96      0.91       178\n",
      "           8       0.89      0.71      0.79       289\n",
      "           9       0.74      0.97      0.84       223\n",
      "          10       0.97      0.86      0.91       280\n",
      "          11       0.96      0.96      0.96       156\n",
      "          12       0.82      0.82      0.82       243\n",
      "          13       1.00      0.93      0.96        70\n",
      "\n",
      "    accuracy                           0.86      2898\n",
      "   macro avg       0.87      0.88      0.87      2898\n",
      "weighted avg       0.87      0.86      0.86      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:57.195205Z",
     "iopub.status.busy": "2025-05-08T18:54:57.195205Z",
     "iopub.status.idle": "2025-05-08T18:54:57.199170Z",
     "shell.execute_reply": "2025-05-08T18:54:57.199170Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:57.201175Z",
     "iopub.status.busy": "2025-05-08T18:54:57.201175Z",
     "iopub.status.idle": "2025-05-08T18:54:57.210056Z",
     "shell.execute_reply": "2025-05-08T18:54:57.210056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:57.213065Z",
     "iopub.status.busy": "2025-05-08T18:54:57.212068Z",
     "iopub.status.idle": "2025-05-08T18:54:57.217268Z",
     "shell.execute_reply": "2025-05-08T18:54:57.217268Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:54:57.220372Z",
     "iopub.status.busy": "2025-05-08T18:54:57.219370Z",
     "iopub.status.idle": "2025-05-08T18:55:01.388902Z",
     "shell.execute_reply": "2025-05-08T18:55:01.388902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6925  |  Val Loss: 2.6720\n",
      "Validation loss improved from inf to 2.6720.\n",
      "[Epoch 2/1000] Train Loss: 2.6631  |  Val Loss: 2.6454\n",
      "Validation loss improved from 2.6720 to 2.6454.\n",
      "[Epoch 3/1000] Train Loss: 2.6342  |  Val Loss: 2.6179\n",
      "Validation loss improved from 2.6454 to 2.6179.\n",
      "[Epoch 4/1000] Train Loss: 2.6055  |  Val Loss: 2.5905\n",
      "Validation loss improved from 2.6179 to 2.5905.\n",
      "[Epoch 5/1000] Train Loss: 2.5755  |  Val Loss: 2.5619\n",
      "Validation loss improved from 2.5905 to 2.5619.\n",
      "[Epoch 6/1000] Train Loss: 2.5455  |  Val Loss: 2.5355\n",
      "Validation loss improved from 2.5619 to 2.5355.\n",
      "[Epoch 7/1000] Train Loss: 2.5195  |  Val Loss: 2.5099\n",
      "Validation loss improved from 2.5355 to 2.5099.\n",
      "[Epoch 8/1000] Train Loss: 2.4942  |  Val Loss: 2.4847\n",
      "Validation loss improved from 2.5099 to 2.4847.\n",
      "[Epoch 9/1000] Train Loss: 2.4676  |  Val Loss: 2.4613\n",
      "Validation loss improved from 2.4847 to 2.4613.\n",
      "[Epoch 10/1000] Train Loss: 2.4432  |  Val Loss: 2.4381\n",
      "Validation loss improved from 2.4613 to 2.4381.\n",
      "[Epoch 11/1000] Train Loss: 2.4190  |  Val Loss: 2.4150\n",
      "Validation loss improved from 2.4381 to 2.4150.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/1000] Train Loss: 2.3949  |  Val Loss: 2.3921\n",
      "Validation loss improved from 2.4150 to 2.3921.\n",
      "[Epoch 13/1000] Train Loss: 2.3709  |  Val Loss: 2.3705\n",
      "Validation loss improved from 2.3921 to 2.3705.\n",
      "[Epoch 14/1000] Train Loss: 2.3494  |  Val Loss: 2.3495\n",
      "Validation loss improved from 2.3705 to 2.3495.\n",
      "[Epoch 15/1000] Train Loss: 2.3279  |  Val Loss: 2.3297\n",
      "Validation loss improved from 2.3495 to 2.3297.\n",
      "[Epoch 16/1000] Train Loss: 2.3067  |  Val Loss: 2.3106\n",
      "Validation loss improved from 2.3297 to 2.3106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/1000] Train Loss: 2.2868  |  Val Loss: 2.2918\n",
      "Validation loss improved from 2.3106 to 2.2918.\n",
      "[Epoch 18/1000] Train Loss: 2.2670  |  Val Loss: 2.2739\n",
      "Validation loss improved from 2.2918 to 2.2739.\n",
      "[Epoch 19/1000] Train Loss: 2.2483  |  Val Loss: 2.2566\n",
      "Validation loss improved from 2.2739 to 2.2566.\n",
      "[Epoch 20/1000] Train Loss: 2.2289  |  Val Loss: 2.2398\n",
      "Validation loss improved from 2.2566 to 2.2398.\n",
      "[Epoch 21/1000] Train Loss: 2.2111  |  Val Loss: 2.2228\n",
      "Validation loss improved from 2.2398 to 2.2228.\n",
      "[Epoch 22/1000] Train Loss: 2.1927  |  Val Loss: 2.2060\n",
      "Validation loss improved from 2.2228 to 2.2060.\n",
      "[Epoch 23/1000] Train Loss: 2.1745  |  Val Loss: 2.1889\n",
      "Validation loss improved from 2.2060 to 2.1889.\n",
      "[Epoch 24/1000] Train Loss: 2.1564  |  Val Loss: 2.1719\n",
      "Validation loss improved from 2.1889 to 2.1719.\n",
      "[Epoch 25/1000] Train Loss: 2.1381  |  Val Loss: 2.1549\n",
      "Validation loss improved from 2.1719 to 2.1549.\n",
      "[Epoch 26/1000] Train Loss: 2.1198  |  Val Loss: 2.1376\n",
      "Validation loss improved from 2.1549 to 2.1376.\n",
      "[Epoch 27/1000] Train Loss: 2.1014  |  Val Loss: 2.1202\n",
      "Validation loss improved from 2.1376 to 2.1202.\n",
      "[Epoch 28/1000] Train Loss: 2.0823  |  Val Loss: 2.1028\n",
      "Validation loss improved from 2.1202 to 2.1028.\n",
      "[Epoch 29/1000] Train Loss: 2.0633  |  Val Loss: 2.0848\n",
      "Validation loss improved from 2.1028 to 2.0848.\n",
      "[Epoch 30/1000] Train Loss: 2.0438  |  Val Loss: 2.0663\n",
      "Validation loss improved from 2.0848 to 2.0663.\n",
      "[Epoch 31/1000] Train Loss: 2.0238  |  Val Loss: 2.0472\n",
      "Validation loss improved from 2.0663 to 2.0472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/1000] Train Loss: 2.0029  |  Val Loss: 2.0274\n",
      "Validation loss improved from 2.0472 to 2.0274.\n",
      "[Epoch 33/1000] Train Loss: 1.9818  |  Val Loss: 2.0077\n",
      "Validation loss improved from 2.0274 to 2.0077.\n",
      "[Epoch 34/1000] Train Loss: 1.9601  |  Val Loss: 1.9882\n",
      "Validation loss improved from 2.0077 to 1.9882.\n",
      "[Epoch 35/1000] Train Loss: 1.9383  |  Val Loss: 1.9685\n",
      "Validation loss improved from 1.9882 to 1.9685.\n",
      "[Epoch 36/1000] Train Loss: 1.9168  |  Val Loss: 1.9490\n",
      "Validation loss improved from 1.9685 to 1.9490.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/1000] Train Loss: 1.8944  |  Val Loss: 1.9298\n",
      "Validation loss improved from 1.9490 to 1.9298.\n",
      "[Epoch 38/1000] Train Loss: 1.8728  |  Val Loss: 1.9098\n",
      "Validation loss improved from 1.9298 to 1.9098.\n",
      "[Epoch 39/1000] Train Loss: 1.8507  |  Val Loss: 1.8905\n",
      "Validation loss improved from 1.9098 to 1.8905.\n",
      "[Epoch 40/1000] Train Loss: 1.8290  |  Val Loss: 1.8710\n",
      "Validation loss improved from 1.8905 to 1.8710.\n",
      "[Epoch 41/1000] Train Loss: 1.8073  |  Val Loss: 1.8513\n",
      "Validation loss improved from 1.8710 to 1.8513.\n",
      "[Epoch 42/1000] Train Loss: 1.7857  |  Val Loss: 1.8320\n",
      "Validation loss improved from 1.8513 to 1.8320.\n",
      "[Epoch 43/1000] Train Loss: 1.7642  |  Val Loss: 1.8127\n",
      "Validation loss improved from 1.8320 to 1.8127.\n",
      "[Epoch 44/1000] Train Loss: 1.7426  |  Val Loss: 1.7932\n",
      "Validation loss improved from 1.8127 to 1.7932.\n",
      "[Epoch 45/1000] Train Loss: 1.7214  |  Val Loss: 1.7737\n",
      "Validation loss improved from 1.7932 to 1.7737.\n",
      "[Epoch 46/1000] Train Loss: 1.6998  |  Val Loss: 1.7549\n",
      "Validation loss improved from 1.7737 to 1.7549.\n",
      "[Epoch 47/1000] Train Loss: 1.6787  |  Val Loss: 1.7358\n",
      "Validation loss improved from 1.7549 to 1.7358.\n",
      "[Epoch 48/1000] Train Loss: 1.6571  |  Val Loss: 1.7163\n",
      "Validation loss improved from 1.7358 to 1.7163.\n",
      "[Epoch 49/1000] Train Loss: 1.6360  |  Val Loss: 1.6962\n",
      "Validation loss improved from 1.7163 to 1.6962.\n",
      "[Epoch 50/1000] Train Loss: 1.6145  |  Val Loss: 1.6769\n",
      "Validation loss improved from 1.6962 to 1.6769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51/1000] Train Loss: 1.5930  |  Val Loss: 1.6585\n",
      "Validation loss improved from 1.6769 to 1.6585.\n",
      "[Epoch 52/1000] Train Loss: 1.5718  |  Val Loss: 1.6394\n",
      "Validation loss improved from 1.6585 to 1.6394.\n",
      "[Epoch 53/1000] Train Loss: 1.5504  |  Val Loss: 1.6204\n",
      "Validation loss improved from 1.6394 to 1.6204.\n",
      "[Epoch 54/1000] Train Loss: 1.5292  |  Val Loss: 1.6015\n",
      "Validation loss improved from 1.6204 to 1.6015.\n",
      "[Epoch 55/1000] Train Loss: 1.5090  |  Val Loss: 1.5822\n",
      "Validation loss improved from 1.6015 to 1.5822.\n",
      "[Epoch 56/1000] Train Loss: 1.4879  |  Val Loss: 1.5632\n",
      "Validation loss improved from 1.5822 to 1.5632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] Train Loss: 1.4676  |  Val Loss: 1.5445\n",
      "Validation loss improved from 1.5632 to 1.5445.\n",
      "[Epoch 58/1000] Train Loss: 1.4473  |  Val Loss: 1.5263\n",
      "Validation loss improved from 1.5445 to 1.5263.\n",
      "[Epoch 59/1000] Train Loss: 1.4270  |  Val Loss: 1.5082\n",
      "Validation loss improved from 1.5263 to 1.5082.\n",
      "[Epoch 60/1000] Train Loss: 1.4072  |  Val Loss: 1.4908\n",
      "Validation loss improved from 1.5082 to 1.4908.\n",
      "[Epoch 61/1000] Train Loss: 1.3869  |  Val Loss: 1.4735\n",
      "Validation loss improved from 1.4908 to 1.4735.\n",
      "[Epoch 62/1000] Train Loss: 1.3669  |  Val Loss: 1.4567\n",
      "Validation loss improved from 1.4735 to 1.4567.\n",
      "[Epoch 63/1000] Train Loss: 1.3474  |  Val Loss: 1.4391\n",
      "Validation loss improved from 1.4567 to 1.4391.\n",
      "[Epoch 64/1000] Train Loss: 1.3282  |  Val Loss: 1.4220\n",
      "Validation loss improved from 1.4391 to 1.4220.\n",
      "[Epoch 65/1000] Train Loss: 1.3092  |  Val Loss: 1.4050\n",
      "Validation loss improved from 1.4220 to 1.4050.\n",
      "[Epoch 66/1000] Train Loss: 1.2898  |  Val Loss: 1.3879\n",
      "Validation loss improved from 1.4050 to 1.3879.\n",
      "[Epoch 67/1000] Train Loss: 1.2710  |  Val Loss: 1.3712\n",
      "Validation loss improved from 1.3879 to 1.3712.\n",
      "[Epoch 68/1000] Train Loss: 1.2521  |  Val Loss: 1.3552\n",
      "Validation loss improved from 1.3712 to 1.3552.\n",
      "[Epoch 69/1000] Train Loss: 1.2338  |  Val Loss: 1.3391\n",
      "Validation loss improved from 1.3552 to 1.3391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70/1000] Train Loss: 1.2153  |  Val Loss: 1.3231\n",
      "Validation loss improved from 1.3391 to 1.3231.\n",
      "[Epoch 71/1000] Train Loss: 1.1968  |  Val Loss: 1.3070\n",
      "Validation loss improved from 1.3231 to 1.3070.\n",
      "[Epoch 72/1000] Train Loss: 1.1785  |  Val Loss: 1.2909\n",
      "Validation loss improved from 1.3070 to 1.2909.\n",
      "[Epoch 73/1000] Train Loss: 1.1607  |  Val Loss: 1.2756\n",
      "Validation loss improved from 1.2909 to 1.2756.\n",
      "[Epoch 74/1000] Train Loss: 1.1431  |  Val Loss: 1.2604\n",
      "Validation loss improved from 1.2756 to 1.2604.\n",
      "[Epoch 75/1000] Train Loss: 1.1256  |  Val Loss: 1.2456\n",
      "Validation loss improved from 1.2604 to 1.2456.\n",
      "[Epoch 76/1000] Train Loss: 1.1083  |  Val Loss: 1.2304\n",
      "Validation loss improved from 1.2456 to 1.2304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 1.0917  |  Val Loss: 1.2154\n",
      "Validation loss improved from 1.2304 to 1.2154.\n",
      "[Epoch 78/1000] Train Loss: 1.0752  |  Val Loss: 1.2013\n",
      "Validation loss improved from 1.2154 to 1.2013.\n",
      "[Epoch 79/1000] Train Loss: 1.0590  |  Val Loss: 1.1874\n",
      "Validation loss improved from 1.2013 to 1.1874.\n",
      "[Epoch 80/1000] Train Loss: 1.0432  |  Val Loss: 1.1735\n",
      "Validation loss improved from 1.1874 to 1.1735.\n",
      "[Epoch 81/1000] Train Loss: 1.0274  |  Val Loss: 1.1597\n",
      "Validation loss improved from 1.1735 to 1.1597.\n",
      "[Epoch 82/1000] Train Loss: 1.0121  |  Val Loss: 1.1458\n",
      "Validation loss improved from 1.1597 to 1.1458.\n",
      "[Epoch 83/1000] Train Loss: 0.9967  |  Val Loss: 1.1334\n",
      "Validation loss improved from 1.1458 to 1.1334.\n",
      "[Epoch 84/1000] Train Loss: 0.9818  |  Val Loss: 1.1205\n",
      "Validation loss improved from 1.1334 to 1.1205.\n",
      "[Epoch 85/1000] Train Loss: 0.9673  |  Val Loss: 1.1080\n",
      "Validation loss improved from 1.1205 to 1.1080.\n",
      "[Epoch 86/1000] Train Loss: 0.9523  |  Val Loss: 1.0958\n",
      "Validation loss improved from 1.1080 to 1.0958.\n",
      "[Epoch 87/1000] Train Loss: 0.9380  |  Val Loss: 1.0838\n",
      "Validation loss improved from 1.0958 to 1.0838.\n",
      "[Epoch 88/1000] Train Loss: 0.9238  |  Val Loss: 1.0721\n",
      "Validation loss improved from 1.0838 to 1.0721.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 89/1000] Train Loss: 0.9097  |  Val Loss: 1.0601\n",
      "Validation loss improved from 1.0721 to 1.0601.\n",
      "[Epoch 90/1000] Train Loss: 0.8958  |  Val Loss: 1.0486\n",
      "Validation loss improved from 1.0601 to 1.0486.\n",
      "[Epoch 91/1000] Train Loss: 0.8821  |  Val Loss: 1.0372\n",
      "Validation loss improved from 1.0486 to 1.0372.\n",
      "[Epoch 92/1000] Train Loss: 0.8684  |  Val Loss: 1.0266\n",
      "Validation loss improved from 1.0372 to 1.0266.\n",
      "[Epoch 93/1000] Train Loss: 0.8549  |  Val Loss: 1.0154\n",
      "Validation loss improved from 1.0266 to 1.0154.\n",
      "[Epoch 94/1000] Train Loss: 0.8415  |  Val Loss: 1.0041\n",
      "Validation loss improved from 1.0154 to 1.0041.\n",
      "[Epoch 95/1000] Train Loss: 0.8285  |  Val Loss: 0.9921\n",
      "Validation loss improved from 1.0041 to 0.9921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/1000] Train Loss: 0.8150  |  Val Loss: 0.9808\n",
      "Validation loss improved from 0.9921 to 0.9808.\n",
      "[Epoch 97/1000] Train Loss: 0.8022  |  Val Loss: 0.9698\n",
      "Validation loss improved from 0.9808 to 0.9698.\n",
      "[Epoch 98/1000] Train Loss: 0.7894  |  Val Loss: 0.9592\n",
      "Validation loss improved from 0.9698 to 0.9592.\n",
      "[Epoch 99/1000] Train Loss: 0.7769  |  Val Loss: 0.9490\n",
      "Validation loss improved from 0.9592 to 0.9490.\n",
      "[Epoch 100/1000] Train Loss: 0.7642  |  Val Loss: 0.9383\n",
      "Validation loss improved from 0.9490 to 0.9383.\n",
      "[Epoch 101/1000] Train Loss: 0.7520  |  Val Loss: 0.9279\n",
      "Validation loss improved from 0.9383 to 0.9279.\n",
      "[Epoch 102/1000] Train Loss: 0.7396  |  Val Loss: 0.9181\n",
      "Validation loss improved from 0.9279 to 0.9181.\n",
      "[Epoch 103/1000] Train Loss: 0.7274  |  Val Loss: 0.9080\n",
      "Validation loss improved from 0.9181 to 0.9080.\n",
      "[Epoch 104/1000] Train Loss: 0.7153  |  Val Loss: 0.8980\n",
      "Validation loss improved from 0.9080 to 0.8980.\n",
      "[Epoch 105/1000] Train Loss: 0.7037  |  Val Loss: 0.8882\n",
      "Validation loss improved from 0.8980 to 0.8882.\n",
      "[Epoch 106/1000] Train Loss: 0.6918  |  Val Loss: 0.8784\n",
      "Validation loss improved from 0.8882 to 0.8784.\n",
      "[Epoch 107/1000] Train Loss: 0.6799  |  Val Loss: 0.8684\n",
      "Validation loss improved from 0.8784 to 0.8684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/1000] Train Loss: 0.6686  |  Val Loss: 0.8597\n",
      "Validation loss improved from 0.8684 to 0.8597.\n",
      "[Epoch 109/1000] Train Loss: 0.6571  |  Val Loss: 0.8506\n",
      "Validation loss improved from 0.8597 to 0.8506.\n",
      "[Epoch 110/1000] Train Loss: 0.6457  |  Val Loss: 0.8410\n",
      "Validation loss improved from 0.8506 to 0.8410.\n",
      "[Epoch 111/1000] Train Loss: 0.6344  |  Val Loss: 0.8321\n",
      "Validation loss improved from 0.8410 to 0.8321.\n",
      "[Epoch 112/1000] Train Loss: 0.6234  |  Val Loss: 0.8236\n",
      "Validation loss improved from 0.8321 to 0.8236.\n",
      "[Epoch 113/1000] Train Loss: 0.6127  |  Val Loss: 0.8152\n",
      "Validation loss improved from 0.8236 to 0.8152.\n",
      "[Epoch 114/1000] Train Loss: 0.6018  |  Val Loss: 0.8059\n",
      "Validation loss improved from 0.8152 to 0.8059.\n",
      "[Epoch 115/1000] Train Loss: 0.5914  |  Val Loss: 0.7967\n",
      "Validation loss improved from 0.8059 to 0.7967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 116/1000] Train Loss: 0.5810  |  Val Loss: 0.7880\n",
      "Validation loss improved from 0.7967 to 0.7880.\n",
      "[Epoch 117/1000] Train Loss: 0.5708  |  Val Loss: 0.7806\n",
      "Validation loss improved from 0.7880 to 0.7806.\n",
      "[Epoch 118/1000] Train Loss: 0.5606  |  Val Loss: 0.7723\n",
      "Validation loss improved from 0.7806 to 0.7723.\n",
      "[Epoch 119/1000] Train Loss: 0.5508  |  Val Loss: 0.7637\n",
      "Validation loss improved from 0.7723 to 0.7637.\n",
      "[Epoch 120/1000] Train Loss: 0.5409  |  Val Loss: 0.7558\n",
      "Validation loss improved from 0.7637 to 0.7558.\n",
      "[Epoch 121/1000] Train Loss: 0.5315  |  Val Loss: 0.7478\n",
      "Validation loss improved from 0.7558 to 0.7478.\n",
      "[Epoch 122/1000] Train Loss: 0.5216  |  Val Loss: 0.7400\n",
      "Validation loss improved from 0.7478 to 0.7400.\n",
      "[Epoch 123/1000] Train Loss: 0.5121  |  Val Loss: 0.7318\n",
      "Validation loss improved from 0.7400 to 0.7318.\n",
      "[Epoch 124/1000] Train Loss: 0.5026  |  Val Loss: 0.7243\n",
      "Validation loss improved from 0.7318 to 0.7243.\n",
      "[Epoch 125/1000] Train Loss: 0.4940  |  Val Loss: 0.7158\n",
      "Validation loss improved from 0.7243 to 0.7158.\n",
      "[Epoch 126/1000] Train Loss: 0.4846  |  Val Loss: 0.7080\n",
      "Validation loss improved from 0.7158 to 0.7080.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/1000] Train Loss: 0.4760  |  Val Loss: 0.7020\n",
      "Validation loss improved from 0.7080 to 0.7020.\n",
      "[Epoch 128/1000] Train Loss: 0.4671  |  Val Loss: 0.6959\n",
      "Validation loss improved from 0.7020 to 0.6959.\n",
      "[Epoch 129/1000] Train Loss: 0.4588  |  Val Loss: 0.6896\n",
      "Validation loss improved from 0.6959 to 0.6896.\n",
      "[Epoch 130/1000] Train Loss: 0.4506  |  Val Loss: 0.6837\n",
      "Validation loss improved from 0.6896 to 0.6837.\n",
      "[Epoch 131/1000] Train Loss: 0.4424  |  Val Loss: 0.6786\n",
      "Validation loss improved from 0.6837 to 0.6786.\n",
      "[Epoch 132/1000] Train Loss: 0.4347  |  Val Loss: 0.6732\n",
      "Validation loss improved from 0.6786 to 0.6732.\n",
      "[Epoch 133/1000] Train Loss: 0.4266  |  Val Loss: 0.6669\n",
      "Validation loss improved from 0.6732 to 0.6669.\n",
      "[Epoch 134/1000] Train Loss: 0.4189  |  Val Loss: 0.6593\n",
      "Validation loss improved from 0.6669 to 0.6593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 135/1000] Train Loss: 0.4113  |  Val Loss: 0.6525\n",
      "Validation loss improved from 0.6593 to 0.6525.\n",
      "[Epoch 136/1000] Train Loss: 0.4039  |  Val Loss: 0.6470\n",
      "Validation loss improved from 0.6525 to 0.6470.\n",
      "[Epoch 137/1000] Train Loss: 0.3966  |  Val Loss: 0.6424\n",
      "Validation loss improved from 0.6470 to 0.6424.\n",
      "[Epoch 138/1000] Train Loss: 0.3894  |  Val Loss: 0.6367\n",
      "Validation loss improved from 0.6424 to 0.6367.\n",
      "[Epoch 139/1000] Train Loss: 0.3824  |  Val Loss: 0.6327\n",
      "Validation loss improved from 0.6367 to 0.6327.\n",
      "[Epoch 140/1000] Train Loss: 0.3755  |  Val Loss: 0.6287\n",
      "Validation loss improved from 0.6327 to 0.6287.\n",
      "[Epoch 141/1000] Train Loss: 0.3687  |  Val Loss: 0.6234\n",
      "Validation loss improved from 0.6287 to 0.6234.\n",
      "[Epoch 142/1000] Train Loss: 0.3622  |  Val Loss: 0.6163\n",
      "Validation loss improved from 0.6234 to 0.6163.\n",
      "[Epoch 143/1000] Train Loss: 0.3556  |  Val Loss: 0.6113\n",
      "Validation loss improved from 0.6163 to 0.6113.\n",
      "[Epoch 144/1000] Train Loss: 0.3493  |  Val Loss: 0.6069\n",
      "Validation loss improved from 0.6113 to 0.6069.\n",
      "[Epoch 145/1000] Train Loss: 0.3432  |  Val Loss: 0.6042\n",
      "Validation loss improved from 0.6069 to 0.6042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 146/1000] Train Loss: 0.3372  |  Val Loss: 0.6016\n",
      "Validation loss improved from 0.6042 to 0.6016.\n",
      "[Epoch 147/1000] Train Loss: 0.3311  |  Val Loss: 0.5979\n",
      "Validation loss improved from 0.6016 to 0.5979.\n",
      "[Epoch 148/1000] Train Loss: 0.3254  |  Val Loss: 0.5933\n",
      "Validation loss improved from 0.5979 to 0.5933.\n",
      "[Epoch 149/1000] Train Loss: 0.3197  |  Val Loss: 0.5875\n",
      "Validation loss improved from 0.5933 to 0.5875.\n",
      "[Epoch 150/1000] Train Loss: 0.3147  |  Val Loss: 0.5821\n",
      "Validation loss improved from 0.5875 to 0.5821.\n",
      "[Epoch 151/1000] Train Loss: 0.3091  |  Val Loss: 0.5779\n",
      "Validation loss improved from 0.5821 to 0.5779.\n",
      "[Epoch 152/1000] Train Loss: 0.3039  |  Val Loss: 0.5742\n",
      "Validation loss improved from 0.5779 to 0.5742.\n",
      "[Epoch 153/1000] Train Loss: 0.2986  |  Val Loss: 0.5707\n",
      "Validation loss improved from 0.5742 to 0.5707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 154/1000] Train Loss: 0.2937  |  Val Loss: 0.5669\n",
      "Validation loss improved from 0.5707 to 0.5669.\n",
      "[Epoch 155/1000] Train Loss: 0.2892  |  Val Loss: 0.5647\n",
      "Validation loss improved from 0.5669 to 0.5647.\n",
      "[Epoch 156/1000] Train Loss: 0.2841  |  Val Loss: 0.5609\n",
      "Validation loss improved from 0.5647 to 0.5609.\n",
      "[Epoch 157/1000] Train Loss: 0.2794  |  Val Loss: 0.5564\n",
      "Validation loss improved from 0.5609 to 0.5564.\n",
      "[Epoch 158/1000] Train Loss: 0.2748  |  Val Loss: 0.5527\n",
      "Validation loss improved from 0.5564 to 0.5527.\n",
      "[Epoch 159/1000] Train Loss: 0.2701  |  Val Loss: 0.5516\n",
      "Validation loss improved from 0.5527 to 0.5516.\n",
      "[Epoch 160/1000] Train Loss: 0.2656  |  Val Loss: 0.5503\n",
      "Validation loss improved from 0.5516 to 0.5503.\n",
      "[Epoch 161/1000] Train Loss: 0.2617  |  Val Loss: 0.5484\n",
      "Validation loss improved from 0.5503 to 0.5484.\n",
      "[Epoch 162/1000] Train Loss: 0.2573  |  Val Loss: 0.5442\n",
      "Validation loss improved from 0.5484 to 0.5442.\n",
      "[Epoch 163/1000] Train Loss: 0.2530  |  Val Loss: 0.5387\n",
      "Validation loss improved from 0.5442 to 0.5387.\n",
      "[Epoch 164/1000] Train Loss: 0.2488  |  Val Loss: 0.5340\n",
      "Validation loss improved from 0.5387 to 0.5340.\n",
      "[Epoch 165/1000] Train Loss: 0.2450  |  Val Loss: 0.5296\n",
      "Validation loss improved from 0.5340 to 0.5296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 166/1000] Train Loss: 0.2413  |  Val Loss: 0.5280\n",
      "Validation loss improved from 0.5296 to 0.5280.\n",
      "[Epoch 167/1000] Train Loss: 0.2374  |  Val Loss: 0.5266\n",
      "Validation loss improved from 0.5280 to 0.5266.\n",
      "[Epoch 168/1000] Train Loss: 0.2338  |  Val Loss: 0.5252\n",
      "Validation loss improved from 0.5266 to 0.5252.\n",
      "[Epoch 169/1000] Train Loss: 0.2300  |  Val Loss: 0.5245\n",
      "Validation loss improved from 0.5252 to 0.5245.\n",
      "[Epoch 170/1000] Train Loss: 0.2262  |  Val Loss: 0.5218\n",
      "Validation loss improved from 0.5245 to 0.5218.\n",
      "[Epoch 171/1000] Train Loss: 0.2231  |  Val Loss: 0.5195\n",
      "Validation loss improved from 0.5218 to 0.5195.\n",
      "[Epoch 172/1000] Train Loss: 0.2199  |  Val Loss: 0.5180\n",
      "Validation loss improved from 0.5195 to 0.5180.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 173/1000] Train Loss: 0.2161  |  Val Loss: 0.5160\n",
      "Validation loss improved from 0.5180 to 0.5160.\n",
      "[Epoch 174/1000] Train Loss: 0.2130  |  Val Loss: 0.5134\n",
      "Validation loss improved from 0.5160 to 0.5134.\n",
      "[Epoch 175/1000] Train Loss: 0.2099  |  Val Loss: 0.5110\n",
      "Validation loss improved from 0.5134 to 0.5110.\n",
      "[Epoch 176/1000] Train Loss: 0.2067  |  Val Loss: 0.5102\n",
      "Validation loss improved from 0.5110 to 0.5102.\n",
      "[Epoch 177/1000] Train Loss: 0.2036  |  Val Loss: 0.5093\n",
      "Validation loss improved from 0.5102 to 0.5093.\n",
      "[Epoch 178/1000] Train Loss: 0.2007  |  Val Loss: 0.5077\n",
      "Validation loss improved from 0.5093 to 0.5077.\n",
      "[Epoch 179/1000] Train Loss: 0.1978  |  Val Loss: 0.5056\n",
      "Validation loss improved from 0.5077 to 0.5056.\n",
      "[Epoch 180/1000] Train Loss: 0.1949  |  Val Loss: 0.5054\n",
      "Validation loss improved from 0.5056 to 0.5054.\n",
      "[Epoch 181/1000] Train Loss: 0.1921  |  Val Loss: 0.5043\n",
      "Validation loss improved from 0.5054 to 0.5043.\n",
      "[Epoch 182/1000] Train Loss: 0.1895  |  Val Loss: 0.5029\n",
      "Validation loss improved from 0.5043 to 0.5029.\n",
      "[Epoch 183/1000] Train Loss: 0.1869  |  Val Loss: 0.5016\n",
      "Validation loss improved from 0.5029 to 0.5016.\n",
      "[Epoch 184/1000] Train Loss: 0.1842  |  Val Loss: 0.5003\n",
      "Validation loss improved from 0.5016 to 0.5003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 185/1000] Train Loss: 0.1819  |  Val Loss: 0.4996\n",
      "Validation loss improved from 0.5003 to 0.4996.\n",
      "[Epoch 186/1000] Train Loss: 0.1791  |  Val Loss: 0.4978\n",
      "Validation loss improved from 0.4996 to 0.4978.\n",
      "[Epoch 187/1000] Train Loss: 0.1767  |  Val Loss: 0.4945\n",
      "Validation loss improved from 0.4978 to 0.4945.\n",
      "[Epoch 188/1000] Train Loss: 0.1741  |  Val Loss: 0.4925\n",
      "Validation loss improved from 0.4945 to 0.4925.\n",
      "[Epoch 189/1000] Train Loss: 0.1717  |  Val Loss: 0.4915\n",
      "Validation loss improved from 0.4925 to 0.4915.\n",
      "[Epoch 190/1000] Train Loss: 0.1694  |  Val Loss: 0.4905\n",
      "Validation loss improved from 0.4915 to 0.4905.\n",
      "[Epoch 191/1000] Train Loss: 0.1671  |  Val Loss: 0.4906\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 192/1000] Train Loss: 0.1649  |  Val Loss: 0.4913\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 193/1000] Train Loss: 0.1630  |  Val Loss: 0.4896\n",
      "Validation loss improved from 0.4905 to 0.4896.\n",
      "[Epoch 194/1000] Train Loss: 0.1608  |  Val Loss: 0.4876\n",
      "Validation loss improved from 0.4896 to 0.4876.\n",
      "[Epoch 195/1000] Train Loss: 0.1588  |  Val Loss: 0.4865\n",
      "Validation loss improved from 0.4876 to 0.4865.\n",
      "[Epoch 196/1000] Train Loss: 0.1565  |  Val Loss: 0.4842\n",
      "Validation loss improved from 0.4865 to 0.4842.\n",
      "[Epoch 197/1000] Train Loss: 0.1543  |  Val Loss: 0.4816\n",
      "Validation loss improved from 0.4842 to 0.4816.\n",
      "[Epoch 198/1000] Train Loss: 0.1523  |  Val Loss: 0.4806\n",
      "Validation loss improved from 0.4816 to 0.4806.\n",
      "[Epoch 199/1000] Train Loss: 0.1505  |  Val Loss: 0.4811\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 200/1000] Train Loss: 0.1486  |  Val Loss: 0.4808\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 201/1000] Train Loss: 0.1467  |  Val Loss: 0.4792\n",
      "Validation loss improved from 0.4806 to 0.4792.\n",
      "[Epoch 202/1000] Train Loss: 0.1449  |  Val Loss: 0.4788\n",
      "Validation loss improved from 0.4792 to 0.4788.\n",
      "[Epoch 203/1000] Train Loss: 0.1433  |  Val Loss: 0.4783\n",
      "Validation loss improved from 0.4788 to 0.4783.\n",
      "[Epoch 204/1000] Train Loss: 0.1416  |  Val Loss: 0.4776\n",
      "Validation loss improved from 0.4783 to 0.4776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 205/1000] Train Loss: 0.1401  |  Val Loss: 0.4763\n",
      "Validation loss improved from 0.4776 to 0.4763.\n",
      "[Epoch 206/1000] Train Loss: 0.1383  |  Val Loss: 0.4771\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 207/1000] Train Loss: 0.1369  |  Val Loss: 0.4774\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 208/1000] Train Loss: 0.1352  |  Val Loss: 0.4750\n",
      "Validation loss improved from 0.4763 to 0.4750.\n",
      "[Epoch 209/1000] Train Loss: 0.1333  |  Val Loss: 0.4723\n",
      "Validation loss improved from 0.4750 to 0.4723.\n",
      "[Epoch 210/1000] Train Loss: 0.1319  |  Val Loss: 0.4702\n",
      "Validation loss improved from 0.4723 to 0.4702.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 211/1000] Train Loss: 0.1305  |  Val Loss: 0.4688\n",
      "Validation loss improved from 0.4702 to 0.4688.\n",
      "[Epoch 212/1000] Train Loss: 0.1290  |  Val Loss: 0.4695\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 213/1000] Train Loss: 0.1276  |  Val Loss: 0.4702\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 214/1000] Train Loss: 0.1261  |  Val Loss: 0.4701\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 215/1000] Train Loss: 0.1247  |  Val Loss: 0.4711\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 216/1000] Train Loss: 0.1234  |  Val Loss: 0.4716\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 217/1000] Train Loss: 0.1219  |  Val Loss: 0.4718\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 218/1000] Train Loss: 0.1207  |  Val Loss: 0.4718\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 219/1000] Train Loss: 0.1197  |  Val Loss: 0.4714\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 220/1000] Train Loss: 0.1182  |  Val Loss: 0.4711\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 221/1000] Train Loss: 0.1169  |  Val Loss: 0.4707\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 222/1000] Train Loss: 0.1158  |  Val Loss: 0.4694\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 223/1000] Train Loss: 0.1146  |  Val Loss: 0.4680\n",
      "Validation loss improved from 0.4688 to 0.4680.\n",
      "[Epoch 224/1000] Train Loss: 0.1135  |  Val Loss: 0.4691\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 225/1000] Train Loss: 0.1123  |  Val Loss: 0.4697\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 226/1000] Train Loss: 0.1111  |  Val Loss: 0.4682\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 227/1000] Train Loss: 0.1101  |  Val Loss: 0.4673\n",
      "Validation loss improved from 0.4680 to 0.4673.\n",
      "[Epoch 228/1000] Train Loss: 0.1090  |  Val Loss: 0.4640\n",
      "Validation loss improved from 0.4673 to 0.4640.\n",
      "[Epoch 229/1000] Train Loss: 0.1079  |  Val Loss: 0.4631\n",
      "Validation loss improved from 0.4640 to 0.4631.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 230/1000] Train Loss: 0.1070  |  Val Loss: 0.4631\n",
      "Validation loss improved from 0.4631 to 0.4631.\n",
      "[Epoch 231/1000] Train Loss: 0.1059  |  Val Loss: 0.4637\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 232/1000] Train Loss: 0.1049  |  Val Loss: 0.4644\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 233/1000] Train Loss: 0.1039  |  Val Loss: 0.4654\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 234/1000] Train Loss: 0.1028  |  Val Loss: 0.4653\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 235/1000] Train Loss: 0.1018  |  Val Loss: 0.4668\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 236/1000] Train Loss: 0.1011  |  Val Loss: 0.4671\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 237/1000] Train Loss: 0.1001  |  Val Loss: 0.4672\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 238/1000] Train Loss: 0.0993  |  Val Loss: 0.4671\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 239/1000] Train Loss: 0.0984  |  Val Loss: 0.4656\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 240/1000] Train Loss: 0.0976  |  Val Loss: 0.4616\n",
      "Validation loss improved from 0.4631 to 0.4616.\n",
      "[Epoch 241/1000] Train Loss: 0.0967  |  Val Loss: 0.4608\n",
      "Validation loss improved from 0.4616 to 0.4608.\n",
      "[Epoch 242/1000] Train Loss: 0.0959  |  Val Loss: 0.4607\n",
      "Validation loss improved from 0.4608 to 0.4607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 243/1000] Train Loss: 0.0951  |  Val Loss: 0.4610\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 244/1000] Train Loss: 0.0941  |  Val Loss: 0.4619\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 245/1000] Train Loss: 0.0932  |  Val Loss: 0.4618\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 246/1000] Train Loss: 0.0925  |  Val Loss: 0.4624\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 247/1000] Train Loss: 0.0915  |  Val Loss: 0.4639\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 248/1000] Train Loss: 0.0908  |  Val Loss: 0.4646\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 249/1000] Train Loss: 0.0900  |  Val Loss: 0.4639\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 250/1000] Train Loss: 0.0892  |  Val Loss: 0.4631\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 251/1000] Train Loss: 0.0885  |  Val Loss: 0.4619\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 252/1000] Train Loss: 0.0879  |  Val Loss: 0.4617\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 253/1000] Train Loss: 0.0869  |  Val Loss: 0.4612\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 254/1000] Train Loss: 0.0863  |  Val Loss: 0.4624\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 255/1000] Train Loss: 0.0858  |  Val Loss: 0.4623\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 256/1000] Train Loss: 0.0850  |  Val Loss: 0.4631\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 257/1000] Train Loss: 0.0846  |  Val Loss: 0.4654\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 258/1000] Train Loss: 0.0837  |  Val Loss: 0.4651\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 259/1000] Train Loss: 0.0830  |  Val Loss: 0.4639\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 260/1000] Train Loss: 0.0823  |  Val Loss: 0.4639\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 261/1000] Train Loss: 0.0819  |  Val Loss: 0.4612\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 262/1000] Train Loss: 0.0811  |  Val Loss: 0.4615\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 263/1000] Train Loss: 0.0805  |  Val Loss: 0.4600\n",
      "Validation loss improved from 0.4607 to 0.4600.\n",
      "[Epoch 264/1000] Train Loss: 0.0799  |  Val Loss: 0.4605\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 265/1000] Train Loss: 0.0794  |  Val Loss: 0.4624\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 266/1000] Train Loss: 0.0788  |  Val Loss: 0.4635\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 267/1000] Train Loss: 0.0781  |  Val Loss: 0.4633\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 268/1000] Train Loss: 0.0776  |  Val Loss: 0.4628\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 269/1000] Train Loss: 0.0769  |  Val Loss: 0.4642\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 270/1000] Train Loss: 0.0762  |  Val Loss: 0.4646\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 271/1000] Train Loss: 0.0757  |  Val Loss: 0.4653\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 272/1000] Train Loss: 0.0753  |  Val Loss: 0.4658\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 273/1000] Train Loss: 0.0748  |  Val Loss: 0.4652\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 274/1000] Train Loss: 0.0743  |  Val Loss: 0.4642\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 275/1000] Train Loss: 0.0736  |  Val Loss: 0.4649\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 276/1000] Train Loss: 0.0731  |  Val Loss: 0.4657\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 277/1000] Train Loss: 0.0726  |  Val Loss: 0.4663\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 278/1000] Train Loss: 0.0722  |  Val Loss: 0.4644\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 279/1000] Train Loss: 0.0715  |  Val Loss: 0.4621\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 280/1000] Train Loss: 0.0710  |  Val Loss: 0.4622\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 281/1000] Train Loss: 0.0706  |  Val Loss: 0.4616\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 282/1000] Train Loss: 0.0702  |  Val Loss: 0.4609\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 283/1000] Train Loss: 0.0697  |  Val Loss: 0.4624\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 284/1000] Train Loss: 0.0690  |  Val Loss: 0.4631\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 285/1000] Train Loss: 0.0684  |  Val Loss: 0.4639\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 286/1000] Train Loss: 0.0682  |  Val Loss: 0.4655\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 287/1000] Train Loss: 0.0676  |  Val Loss: 0.4650\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 288/1000] Train Loss: 0.0671  |  Val Loss: 0.4655\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 289/1000] Train Loss: 0.0667  |  Val Loss: 0.4663\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 290/1000] Train Loss: 0.0662  |  Val Loss: 0.4656\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 291/1000] Train Loss: 0.0657  |  Val Loss: 0.4653\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 292/1000] Train Loss: 0.0654  |  Val Loss: 0.4660\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 293/1000] Train Loss: 0.0649  |  Val Loss: 0.4670\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 294/1000] Train Loss: 0.0643  |  Val Loss: 0.4685\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 295/1000] Train Loss: 0.0643  |  Val Loss: 0.4682\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 296/1000] Train Loss: 0.0636  |  Val Loss: 0.4665\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 297/1000] Train Loss: 0.0634  |  Val Loss: 0.4637\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 298/1000] Train Loss: 0.0629  |  Val Loss: 0.4640\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 299/1000] Train Loss: 0.0626  |  Val Loss: 0.4654\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 300/1000] Train Loss: 0.0621  |  Val Loss: 0.4665\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 301/1000] Train Loss: 0.0618  |  Val Loss: 0.4683\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 302/1000] Train Loss: 0.0613  |  Val Loss: 0.4686\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 303/1000] Train Loss: 0.0609  |  Val Loss: 0.4692\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 304/1000] Train Loss: 0.0606  |  Val Loss: 0.4702\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 305/1000] Train Loss: 0.0601  |  Val Loss: 0.4705\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 306/1000] Train Loss: 0.0597  |  Val Loss: 0.4719\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 307/1000] Train Loss: 0.0594  |  Val Loss: 0.4736\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 308/1000] Train Loss: 0.0592  |  Val Loss: 0.4741\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 309/1000] Train Loss: 0.0587  |  Val Loss: 0.4750\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 310/1000] Train Loss: 0.0586  |  Val Loss: 0.4762\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 311/1000] Train Loss: 0.0582  |  Val Loss: 0.4746\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 312/1000] Train Loss: 0.0577  |  Val Loss: 0.4732\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 313/1000] Train Loss: 0.0575  |  Val Loss: 0.4701\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 314/1000] Train Loss: 0.0571  |  Val Loss: 0.4701\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 315/1000] Train Loss: 0.0568  |  Val Loss: 0.4716\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 316/1000] Train Loss: 0.0563  |  Val Loss: 0.4719\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 317/1000] Train Loss: 0.0561  |  Val Loss: 0.4739\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 318/1000] Train Loss: 0.0558  |  Val Loss: 0.4729\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 319/1000] Train Loss: 0.0553  |  Val Loss: 0.4723\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 320/1000] Train Loss: 0.0550  |  Val Loss: 0.4732\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 321/1000] Train Loss: 0.0549  |  Val Loss: 0.4724\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 322/1000] Train Loss: 0.0546  |  Val Loss: 0.4735\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 323/1000] Train Loss: 0.0543  |  Val Loss: 0.4721\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 324/1000] Train Loss: 0.0539  |  Val Loss: 0.4717\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 325/1000] Train Loss: 0.0536  |  Val Loss: 0.4732\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 326/1000] Train Loss: 0.0533  |  Val Loss: 0.4732\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 327/1000] Train Loss: 0.0529  |  Val Loss: 0.4726\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 328/1000] Train Loss: 0.0528  |  Val Loss: 0.4740\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 329/1000] Train Loss: 0.0524  |  Val Loss: 0.4777\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 330/1000] Train Loss: 0.0521  |  Val Loss: 0.4795\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 331/1000] Train Loss: 0.0518  |  Val Loss: 0.4797\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 332/1000] Train Loss: 0.0515  |  Val Loss: 0.4781\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 333/1000] Train Loss: 0.0512  |  Val Loss: 0.4769\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 334/1000] Train Loss: 0.0509  |  Val Loss: 0.4768\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 335/1000] Train Loss: 0.0506  |  Val Loss: 0.4760\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 336/1000] Train Loss: 0.0504  |  Val Loss: 0.4760\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 337/1000] Train Loss: 0.0501  |  Val Loss: 0.4755\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 338/1000] Train Loss: 0.0499  |  Val Loss: 0.4746\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 339/1000] Train Loss: 0.0496  |  Val Loss: 0.4761\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 340/1000] Train Loss: 0.0493  |  Val Loss: 0.4769\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 341/1000] Train Loss: 0.0491  |  Val Loss: 0.4776\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 342/1000] Train Loss: 0.0488  |  Val Loss: 0.4799\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 343/1000] Train Loss: 0.0487  |  Val Loss: 0.4805\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 344/1000] Train Loss: 0.0483  |  Val Loss: 0.4795\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 345/1000] Train Loss: 0.0482  |  Val Loss: 0.4790\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 346/1000] Train Loss: 0.0480  |  Val Loss: 0.4808\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 347/1000] Train Loss: 0.0477  |  Val Loss: 0.4804\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 348/1000] Train Loss: 0.0474  |  Val Loss: 0.4824\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 349/1000] Train Loss: 0.0471  |  Val Loss: 0.4821\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 350/1000] Train Loss: 0.0469  |  Val Loss: 0.4824\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 351/1000] Train Loss: 0.0467  |  Val Loss: 0.4824\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 352/1000] Train Loss: 0.0464  |  Val Loss: 0.4813\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 353/1000] Train Loss: 0.0462  |  Val Loss: 0.4806\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 354/1000] Train Loss: 0.0462  |  Val Loss: 0.4809\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 355/1000] Train Loss: 0.0458  |  Val Loss: 0.4835\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 356/1000] Train Loss: 0.0456  |  Val Loss: 0.4867\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 357/1000] Train Loss: 0.0455  |  Val Loss: 0.4885\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 358/1000] Train Loss: 0.0452  |  Val Loss: 0.4877\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 359/1000] Train Loss: 0.0449  |  Val Loss: 0.4874\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 360/1000] Train Loss: 0.0447  |  Val Loss: 0.4876\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 361/1000] Train Loss: 0.0445  |  Val Loss: 0.4876\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 362/1000] Train Loss: 0.0442  |  Val Loss: 0.4855\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 363/1000] Train Loss: 0.0442  |  Val Loss: 0.4843\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 363 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACG80lEQVR4nOzdd3RU1d7G8e+ZyaQ3EkgIELr03osUXxAEQRC7KKJYsCNWsIDliuXau1cBu6igooKAUhWUjoUqvSSUAOmZyZT3j5MEIhBCSHJSns9aszKzT/slE3Se7H32Nnw+nw8RERERERE5JZvVBYiIiIiIiJR1Ck4iIiIiIiKnoeAkIiIiIiJyGgpOIiIiIiIip6HgJCIiIiIichoKTiIiIiIiIqeh4CQiIiIiInIaCk4iIiIiIiKnoeAkIiIiIiJyGgpOIiJnwDCMQj0WLlx4VteZOHEihmEU6diFCxcWSw1l3ciRI6lbt+4ptx88eBB/f3+uvPLKU+6TkpJCcHAwF110UaGvO3XqVAzDYMeOHYWu5XiGYTBx4sRCXy/Xvn37mDhxImvXrj1h29n8vpytunXrMmjQIEuuLSJSmvysLkBEpDxZtmxZvtdPPvkkCxYsYP78+fnamzVrdlbXufHGG7nggguKdGy7du1YtmzZWddQ3lWrVo2LLrqIb775hiNHjlClSpUT9vn888/JzMxk1KhRZ3WtRx99lLvvvvusznE6+/bt4/HHH6du3bq0adMm37az+X0REZHCUXASETkDXbp0yfe6WrVq2Gy2E9r/LSMjg+Dg4EJfp1atWtSqVatINYaHh5+2nspi1KhRTJ8+nU8++YQ77rjjhO2TJ08mNjaWCy+88Kyu06BBg7M6/mydze+LiIgUjobqiYgUs969e9OiRQsWL15Mt27dCA4O5oYbbgBg2rRp9OvXj7i4OIKCgmjatCkPPfQQ6enp+c5xsqFXuUOifvzxR9q1a0dQUBBNmjRh8uTJ+fY72VC9kSNHEhoayj///MPAgQMJDQ0lPj6ee++9F6fTme/4PXv2cOmllxIWFkZkZCTDhw9nxYoVGIbB1KlTC/zeDx48yG233UazZs0IDQ0lJiaG//u//2PJkiX59tuxYweGYfDf//6XF198kXr16hEaGkrXrl357bffTjjv1KlTady4MQEBATRt2pQPP/ywwDpy9e/fn1q1ajFlypQTtm3YsIHff/+dESNG4Ofnx7x58xgyZAi1atUiMDCQhg0bcsstt3Do0KHTXudkQ/VSUlK46aabiI6OJjQ0lAsuuIDNmzefcOw///zD9ddfzznnnENwcDA1a9Zk8ODB/Pnnn3n7LFy4kI4dOwJw/fXX5w0JzR3yd7LfF6/Xy3PPPUeTJk0ICAggJiaGESNGsGfPnnz75f6+rlixgh49ehAcHEz9+vV55pln8Hq9p/3eCyMrK4tx48ZRr149/P39qVmzJrfffjtHjx7Nt9/8+fPp3bs30dHRBAUFUbt2bS655BIyMjLy9nnrrbdo3bo1oaGhhIWF0aRJE8aPH18sdYqIFEQ9TiIiJSAhIYFrrrmGBx54gKeffhqbzfw71ZYtWxg4cCBjxowhJCSEjRs38uyzz7J8+fIThvudzLp167j33nt56KGHiI2N5b333mPUqFE0bNiQnj17FnhsdnY2F110EaNGjeLee+9l8eLFPPnkk0RERPDYY48BkJ6eznnnncfhw4d59tlnadiwIT/++CNXXHFFob7vw4cPAzBhwgSqV69OWloaX3/9Nb179+bnn3+md+/e+fZ/4403aNKkCS+//DJgDnkbOHAg27dvJyIiAjBD0/XXX8+QIUN44YUXSE5OZuLEiTidzryf66nYbDZGjhzJU089xbp162jdunXettwwlRtqt27dSteuXbnxxhuJiIhgx44dvPjii5x77rn8+eefOByOQv0MAHw+H0OHDmXp0qU89thjdOzYkV9//ZUBAwacsO++ffuIjo7mmWeeoVq1ahw+fJgPPviAzp07s2bNGho3bky7du2YMmUK119/PY888kheD1lBvUy33nor7777LnfccQeDBg1ix44dPProoyxcuJDVq1dTtWrVvH0TExMZPnw49957LxMmTODrr79m3Lhx1KhRgxEjRhT6+y7oZ/Hzzz8zbtw4evTowR9//MGECRNYtmwZy5YtIyAggB07dnDhhRfSo0cPJk+eTGRkJHv37uXHH3/E5XIRHBzM559/zm233cadd97Jf//7X2w2G//88w/r168/qxpFRArFJyIiRXbdddf5QkJC8rX16tXLB/h+/vnnAo/1er2+7Oxs36JFi3yAb926dXnbJkyY4Pv3f6Lr1KnjCwwM9O3cuTOvLTMz0xcVFeW75ZZb8toWLFjgA3wLFizIVyfg++KLL/Kdc+DAgb7GjRvnvX7jjTd8gG/27Nn59rvlllt8gG/KlCkFfk//5na7fdnZ2b4+ffr4Lr744rz27du3+wBfy5YtfW63O699+fLlPsD32Wef+Xw+n8/j8fhq1Kjha9eunc/r9ebtt2PHDp/D4fDVqVPntDVs27bNZxiG76677spry87O9lWvXt3XvXv3kx6T+97s3LnTB/i+/fbbvG1TpkzxAb7t27fntV133XX5apk9e7YP8L3yyiv5zvuf//zHB/gmTJhwynrdbrfP5XL5zjnnHN8999yT175ixYpTvgf//n3ZsGGDD/Dddttt+fb7/ffffYBv/PjxeW25v6+///57vn2bNWvm69+//ynrzFWnTh3fhRdeeMrtP/74ow/wPffcc/nap02b5gN87777rs/n8/m++uorH+Bbu3btKc91xx13+CIjI09bk4hISdBQPRGRElClShX+7//+74T2bdu2cfXVV1O9enXsdjsOh4NevXoB5tCx02nTpg21a9fOex0YGEijRo3YuXPnaY81DIPBgwfna2vVqlW+YxctWkRYWNgJEw1cddVVpz1/rrfffpt27doRGBiIn58fDoeDn3/++aTf34UXXojdbs9XD5BX06ZNm9i3bx9XX311vqFoderUoVu3boWqp169epx33nl88sknuFwuAGbPnk1iYmJebxPAgQMHGD16NPHx8Xl116lTByjce3O8BQsWADB8+PB87VdfffUJ+7rdbp5++mmaNWuGv78/fn5++Pv7s2XLljO+7r+vP3LkyHztnTp1omnTpvz888/52qtXr06nTp3ytf37d6OocntS/13LZZddRkhISF4tbdq0wd/fn5tvvpkPPviAbdu2nXCuTp06cfToUa666iq+/fbbQg2jFBEpLgpOIiIlIC4u7oS2tLQ0evTowe+//85TTz3FwoULWbFiBTNmzAAgMzPztOeNjo4+oS0gIKBQxwYHBxMYGHjCsVlZWXmvk5KSiI2NPeHYk7WdzIsvvsitt95K586dmT59Or/99hsrVqzgggsuOGmN//5+AgICgGM/i6SkJMD8YP9vJ2s7lVGjRpGUlMTMmTMBc5heaGgol19+OWDeD9SvXz9mzJjBAw88wM8//8zy5cvz7rcqzM/3eElJSfj5+Z3w/Z2s5rFjx/Loo48ydOhQvvvuO37//XdWrFhB69atz/i6x18fTv57WKNGjbztuc7m96owtfj5+VGtWrV87YZhUL169bxaGjRowE8//URMTAy33347DRo0oEGDBrzyyit5x1x77bVMnjyZnTt3cskllxATE0Pnzp2ZN2/eWdcpInI6usdJRKQEnGxNnfnz57Nv3z4WLlyY18sEnHCDvJWio6NZvnz5Ce2JiYmFOv7jjz+md+/evPXWW/naU1NTi1zPqa5f2JoAhg0bRpUqVZg8eTK9evXi+++/Z8SIEYSGhgLw119/sW7dOqZOncp1112Xd9w///xT5LrdbjdJSUn5QsnJav74448ZMWIETz/9dL72Q4cOERkZWeTrg3mv3b/vg9q3b1+++5tKWu7P4uDBg/nCk8/nIzExMW/SC4AePXrQo0cPPB4PK1eu5LXXXmPMmDHExsbmrcd1/fXXc/3115Oens7ixYuZMGECgwYNYvPmzXk9hCIiJUE9TiIipSQ3TOX2quR65513rCjnpHr16kVqaiqzZ8/O1/75558X6njDME74/v74448T1r8qrMaNGxMXF8dnn32Gz+fLa9+5cydLly4t9HkCAwO5+uqrmTt3Ls8++yzZ2dn5hukV93tz3nnnAfDJJ5/ka//0009P2PdkP7MffviBvXv35mv7d29cQXKHiX788cf52lesWMGGDRvo06fPac9RXHKv9e9apk+fTnp6+klrsdvtdO7cmTfeeAOA1atXn7BPSEgIAwYM4OGHH8blcvH333+XQPUiIseox0lEpJR069aNKlWqMHr0aCZMmIDD4eCTTz5h3bp1VpeW57rrruOll17immuu4amnnqJhw4bMnj2bOXPmAJx2FrtBgwbx5JNPMmHCBHr16sWmTZt44oknqFevHm63+4zrsdlsPPnkk9x4441cfPHF3HTTTRw9epSJEyee0VA9MIfrvfHGG7z44os0adIk3z1STZo0oUGDBjz00EP4fD6ioqL47rvvijwErF+/fvTs2ZMHHniA9PR0OnTowK+//spHH310wr6DBg1i6tSpNGnShFatWrFq1Sqef/75E3qKGjRoQFBQEJ988glNmzYlNDSUGjVqUKNGjRPO2bhxY26++WZee+01bDYbAwYMyJtVLz4+nnvuuadI39epJCYm8tVXX53QXrduXc4//3z69+/Pgw8+SEpKCt27d8+bVa9t27Zce+21gHlv3Pz587nwwgupXbs2WVlZeVPt9+3bF4CbbrqJoKAgunfvTlxcHImJiUyaNImIiIh8PVciIiVBwUlEpJRER0fzww8/cO+993LNNdcQEhLCkCFDmDZtGu3atbO6PMD8K/78+fMZM2YMDzzwAIZh0K9fP958800GDhx42qFjDz/8MBkZGbz//vs899xzNGvWjLfffpuvv/4637pSZ2LUqFEAPPvsswwbNoy6desyfvx4Fi1adEbnbNu2LW3btmXNmjX5epsAHA4H3333HXfffTe33HILfn5+9O3bl59++infZByFZbPZmDlzJmPHjuW5557D5XLRvXt3Zs2aRZMmTfLt+8orr+BwOJg0aRJpaWm0a9eOGTNm8Mgjj+TbLzg4mMmTJ/P444/Tr18/srOzmTBhQt5aTv/21ltv0aBBA95//33eeOMNIiIiuOCCC5g0adJJ72k6G6tWreKyyy47of26665j6tSpfPPNN0ycOJEpU6bwn//8h6pVq3Lttdfy9NNP5/WktWnThrlz5zJhwgQSExMJDQ2lRYsWzJw5k379+gHmUL6pU6fyxRdfcOTIEapWrcq5557Lhx9+eMI9VCIixc3wHT/2QURE5CSefvppHnnkEXbt2lXg2kEiIiIVlXqcREQkn9dffx0wh69lZ2czf/58Xn31Va655hqFJhERqbQUnEREJJ/g4GBeeuklduzYgdPppHbt2jz44IMnDB0TERGpTDRUT0RERERE5DQ0HbmIiIiIiMhpKDiJiIiIiIichoKTiIiIiIjIaVS6ySG8Xi/79u0jLCwsb6V4ERERERGpfHw+H6mpqdSoUeO0i7xXuuC0b98+4uPjrS5DRERERETKiN27d592yY1KF5zCwsIA84cTHh5ucTUiIiIiImKVlJQU4uPj8zJCQSpdcModnhceHq7gJCIiIiIihbqFR5NDiIiIiIiInIaCk4iIiIiIyGkoOImIiIiIiJxGpbvHSURERESkID6fD7fbjcfjsboUKQYOhwO73X7W51FwEhERERHJ4XK5SEhIICMjw+pSpJgYhkGtWrUIDQ09q/MoOImIiIiIAF6vl+3bt2O326lRowb+/v6Fmm1Nyi6fz8fBgwfZs2cP55xzzln1PCk4iYiIiIhg9jZ5vV7i4+MJDg62uhwpJtWqVWPHjh1kZ2efVXDS5BAiIiIiIsex2fQRuSIprl5D/VaIiIiIiIichoKTiIiIiIjIaSg4iYiIiIjICXr37s2YMWOsLqPM0OQQIiIiIiLl2Onu4bnuuuuYOnXqGZ93xowZOByOIlZlGjlyJEePHuWbb745q/OUBQpOIiIiIiLlWEJCQt7zadOm8dhjj7Fp06a8tqCgoHz7Z2dnFyoQRUVFFV+RFYCG6omIiIiInILP5yPD5bbk4fP5ClVj9erV8x4REREYhpH3Oisri8jISL744gt69+5NYGAgH3/8MUlJSVx11VXUqlWL4OBgWrZsyWeffZbvvP8eqle3bl2efvppbrjhBsLCwqhduzbvvvvuWf18Fy1aRKdOnQgICCAuLo6HHnoIt9udt/2rr76iZcuWBAUFER0dTd++fUlPTwdg4cKFdOrUiZCQECIjI+nevTs7d+48q3oKoh4nEREREZFTyMz20OyxOZZce/0T/Qn2L56P6w8++CAvvPACU6ZMISAggKysLNq3b8+DDz5IeHg4P/zwA9deey3169enc+fOpzzPCy+8wJNPPsn48eP56quvuPXWW+nZsydNmjQ545r27t3LwIEDGTlyJB9++CEbN27kpptuIjAwkIkTJ5KQkMBVV13Fc889x8UXX0xqaipLlizB5/PhdrsZOnQoN910E5999hkul4vly5eX6ILFCk4iIiIiIhXcmDFjGDZsWL62++67L+/5nXfeyY8//siXX35ZYHAaOHAgt912G2CGsZdeeomFCxcWKTi9+eabxMfH8/rrr2MYBk2aNGHfvn08+OCDPPbYYyQkJOB2uxk2bBh16tQBoGXLlgAcPnyY5ORkBg0aRIMGDQBo2rTpGddwJhScLOR0e5j9ZyL1q4XQqlak1eWIiIiIyL8EOeysf6K/ZdcuLh06dMj32uPx8MwzzzBt2jT27t2L0+nE6XQSEhJS4HlatWqV9zx3SOCBAweKVNOGDRvo2rVrvl6i7t27k5aWxp49e2jdujV9+vShZcuW9O/fn379+nHppZdSpUoVoqKiGDlyJP379+f888+nb9++XH755cTFxRWplsLQPU4Wenb2JsZMW8vbi7ZaXYqIiIiInIRhGAT7+1nyKM5hZ/8ORC+88AIvvfQSDzzwAPPnz2ft2rX0798fl8tV4Hn+PamEYRh4vd4i1eTz+U74HnPv6zIMA7vdzrx585g9ezbNmjXjtddeo3Hjxmzfvh2AKVOmsGzZMrp168a0adNo1KgRv/32W5FqKQwFJwtd1qEWAHP+3k9icpbF1YiIiIhIZbFkyRKGDBnCNddcQ+vWralfvz5btmwp1RqaNWvG0qVL802CsXTpUsLCwqhZsyZgBqju3bvz+OOPs2bNGvz9/fn666/z9m/bti3jxo1j6dKltGjRgk8//bTE6lVwslDTuHAurOUkynuEz5bvsrocEREREakkGjZsyLx581i6dCkbNmzglltuITExsUSulZyczNq1a/M9du3axW233cbu3bu588472bhxI99++y0TJkxg7Nix2Gw2fv/9d55++mlWrlzJrl27mDFjBgcPHqRp06Zs376dcePGsWzZMnbu3MncuXPZvHlzid7npHucrLTkBV4/9BST/frzzvJY7vi/hjjsyrIiIiIiUrIeffRRtm/fTv/+/QkODubmm29m6NChJCcnF/u1Fi5cSNu2bfO15S7KO2vWLO6//35at25NVFQUo0aN4pFHHgEgPDycxYsX8/LLL5OSkkKdOnV44YUXGDBgAPv372fjxo188MEHJCUlERcXxx133MEtt9xS7PXnMnyFnSC+gkhJSSEiIoLk5GTCw8OtLeafn+DjS0gnkK5Zr/H01ecyqFUNa2sSERERqaSysrLYvn079erVIzAw0OpypJgU9L6eSTZQ94aVGvSBmGaEkMVV9vl8uKzkFuwSEREREZGiU3CykmFA1zsAuN7vR9ZsP8DGxBSLixIRERERkX9TcLJay0shtDrVjSMMsi3jI/U6iYiIiIiUOQpOVvMLgM7mTWw3+/3A12v2kJqVbXFRIiIiIiJyPAWnsqDD9fgcITS17aKdex0zVu+1uiIRERERETmOglNZEFQFo921ANxs/56PfttJJZvsUERERESkTFNwKiu63IrPsNHT/id+B9ezbGuS1RWJiIiIiEgOBaeyokpdjGZDALjRb5amJhcRERERKUMUnMqSrncCcJHtV9Zt2EBCcqbFBYmIiIiICCg4lS212kPtbvgbHq61zeGz33dZXZGIiIiIVBK9e/dmzJgxVpdRZik4lTXdzF6n4faf+Ob3zbjcXosLEhEREZGybPDgwfTt2/ek25YtW4ZhGKxevfqsrzN16lQiIyPP+jzllYJTWdPoAnxRDYkwMuiTNYcf/060uiIRERERKcNGjRrF/Pnz2bnzxHvkJ0+eTJs2bWjXrp0FlVUsCk5ljc2G0fU2AEbY5/Lx0m0WFyQiIiJSifl84Eq35lHI5WkGDRpETEwMU6dOzdeekZHBtGnTGDVqFElJSVx11VXUqlWL4OBgWrZsyWeffVasP6pdu3YxZMgQQkNDCQ8P5/LLL2f//v1529etW8d5551HWFgY4eHhtG/fnpUrVwKwc+dOBg8eTJUqVQgJCaF58+bMmjWrWOs7W35WFyAn0fpKvD9NpJ5zP8G7F7IhoRVN48KtrkpERESk8snOgKdrWHPt8fvAP+S0u/n5+TFixAimTp3KY489hmEYAHz55Ze4XC6GDx9ORkYG7du358EHHyQ8PJwffviBa6+9lvr169O5c+ezLtXn8zF06FBCQkJYtGgRbreb2267jSuuuIKFCxcCMHz4cNq2bctbb72F3W5n7dq1OBwOAG6//XZcLheLFy8mJCSE9evXExoaetZ1FScFp7LIPwRbuxGw7HWut8/ho9+G8PTFLa2uSkRERETKqBtuuIHnn3+ehQsXct555wHmML1hw4ZRpUoVqlSpwn333Ze3/5133smPP/7Il19+WSzB6aeffuKPP/5g+/btxMfHA/DRRx/RvHlzVqxYQceOHdm1axf3338/TZo0AeCcc87JO37Xrl1ccskltGxpfuatX7/+WddU3BScyqqON+Jb9ga97H/w7JoVpAxoQnigw+qqRERERCoXR7DZ82PVtQupSZMmdOvWjcmTJ3PeeeexdetWlixZwty5cwHweDw888wzTJs2jb179+J0OnE6nYSEnL5HqzA2bNhAfHx8XmgCaNasGZGRkWzYsIGOHTsyduxYbrzxRj766CP69u3LZZddRoMGDQC46667uPXWW5k7dy59+/blkksuoVWrVsVSW3HRPU5lVVQ9aHwBANd4v2P6qj0WFyQiIiJSCRmGOVzOikfOkLvCGjVqFNOnTyclJYUpU6ZQp04d+vTpA8ALL7zASy+9xAMPPMD8+fNZu3Yt/fv3x+VyFcuPyefz5Q0RPFX7xIkT+fvvv7nwwguZP38+zZo14+uvvwbgxhtvZNu2bVx77bX8+eefdOjQgddee61YaisuCk5lmNHtLgAusS9m1tLV+Ap5g6CIiIiIVD6XX345drudTz/9lA8++IDrr78+L7QsWbKEIUOGcM0119C6dWvq16/Pli1biu3azZo1Y9euXezevTuvbf369SQnJ9O0adO8tkaNGnHPPfcwd+5chg0bxpQpU/K2xcfHM3r0aGbMmMG9997L//73v2KrrzhoqF5ZVqcbnlqdCdjzO32SZ/DLPz3pcU41q6sSERERkTIoNDSUK664gvHjx5OcnMzIkSPztjVs2JDp06ezdOlSqlSpwosvvkhiYmK+UFMYHo+HtWvX5mvz9/enb9++tGrViuHDh/Pyyy/nTQ7Rq1cvOnToQGZmJvfffz+XXnop9erVY8+ePaxYsYJLLrkEgDFjxjBgwAAaNWrEkSNHmD9//hnXVtLU41TG2XveC8A19p/4cP5aa4sRERERkTJt1KhRHDlyhL59+1K7du289kcffZR27drRv39/evfuTfXq1Rk6dOgZnz8tLY22bdvmewwcOBDDMPjmm2+oUqUKPXv2pG/fvtSvX59p06YBYLfbSUpKYsSIETRq1IjLL7+cAQMG8PjjjwNmILv99ttp2rQpF1xwAY0bN+bNN98slp9JcTF8lWz8V0pKChERESQnJxMeXg6m+Pb5yH6jK45DG/hv9mX83y3P0652FaurEhEREalwsrKy2L59O/Xq1SMwMNDqcqSYFPS+nkk2UI9TWWcYOHJ6na73+5H//fSXxQWJiIiIiFQ+lganSZMm0bFjR8LCwoiJiWHo0KFs2rSpwGMWLlyIYRgnPDZu3FhKVVug+cVkh9ch2kglZuuXrN+XYnVFIiIiIiKViqXBadGiRdx+++389ttvzJs3D7fbTb9+/UhPTz/tsZs2bSIhISHvcfwCWhWO3Q9Hj7sBuMnvB95aUIFDooiIiIhIGWTprHo//vhjvtdTpkwhJiaGVatW0bNnzwKPjYmJITIysgSrK2PaDMc9fxK1Mg8SsP4rth1sRv1qoVZXJSIiIiJSKZSpe5ySk5MBiIqKOu2+bdu2JS4ujj59+rBgwYJT7ud0OklJScn3KJccgfideycAt9m/5e0Fmy0uSERERKRiqmRzp1V4xfV+lpng5PP5GDt2LOeeey4tWrQ45X5xcXG8++67TJ8+nRkzZtC4cWP69OnD4sWLT7r/pEmTiIiIyHvEx8eX1LdQ8jqMwh0QSX1bIq4/prPnSIbVFYmIiIhUGA6HA4CMDH3GqkhcLhdgTol+NsrMdOS33347P/zwA7/88gu1atU6o2MHDx6MYRjMnDnzhG1OpxOn05n3OiUlhfj4+PIzHfm/LXoeFjzFJm8tPm33GY8PbWV1RSIiIiIVRkJCAkePHiUmJobg4GAMw7C6JDkLXq+Xffv24XA4qF279gnv55lMR27pPU657rzzTmbOnMnixYvPODQBdOnShY8//vik2wICAggICDjbEsuOzjfj/uUVGmfvIXnVlxzo04iYMK0zICIiIlIcqlevDsCBAwcsrkSKi81mO2loOlOWBiefz8edd97J119/zcKFC6lXr16RzrNmzRri4uKKuboyKjACe/c7YOEk7jK+YMqiy3lwUEurqxIRERGpEAzDIC4ujpiYGLKzs60uR4qBv78/NtvZ36FkaXC6/fbb+fTTT/n2228JCwsjMTERgIiICIKCggAYN24ce/fu5cMPPwTg5Zdfpm7dujRv3hyXy8XHH3/M9OnTmT59umXfR2kzut6Oa9k71HcmkrH8Q47+33+IDPa3uiwRERGRCsNut5/1PTFSsVg6OcRbb71FcnIyvXv3Ji4uLu8xbdq0vH0SEhLYtWtX3muXy8V9991Hq1at6NGjB7/88gs//PADw4YNs+JbsEZAGI7e9wNwq/ElHy7Wuk4iIiIiIiWpzEwOUVrO5AawMs3tJOOF1gRnJvAi13DzuFcIDSgTt6yJiIiIiJQLZ5INysx05HKG/AII7PcoADf4vuaLJX9ZXJCIiIiISMWl4FSO2VpfSXJoAyKNdHy/vkpWtsfqkkREREREKiQFp/LMZidkwOMAXOX9nhmLV1tckIiIiIhIxaTgVM75NRvEochWBBtO7L+8QIbLbXVJIiIiIiIVjoJTeWcYRA7+DwAXe+fyzfxfLS5IRERERKTiUXCqAPwa9CSxWjf8DQ/hvz1PmlO9TiIiIiIixUnBqYKoOsTsdRro+4Xv5s6zuBoRERERkYpFwamC8KvVjj01LsBm+Ihb9TwpWdlWlyQiIiIiUmEoOFUgcRc/hQcbvVnF7FnfWF2OiIiIiEiFoeBUgdirncOeupcA0HDdCySnuyyuSERERESkYlBwqmDih07EiT/tjQ0snDnZ6nJERERERCoEBacKxhZZi91NRgHQduOLHE5OsbgiEREREZHyT8GpAmpw8SMcMqKpbeznj68mWV2OiIiIiEi5p+BUARkBoSR2egiAjrve58DenRZXJCIiIiJSvik4VVDN+49ik6MJIYaTHV88YHU5IiIiIiLlmoJTBWXY7BgDngWgU/KPbFq10NqCRERERETKMQWnCqxRu96siOhvvpj9ID6vx9qCRERERETKKQWnCq7uFc+R7guksXsj6759xepyRERERETKJQWnCq5ajbqsang7AA3WPU/G4T0WVyQiIiIiUv4oOFUCnS5/iA1GQ8LIYM8nd1tdjoiIiIhIuaPgVAkEBvhz6LzncftsNEr6iaTV31pdkoiIiIhIuaLgVEmc2+M8fggdBoAx6z5wpllckYiIiIhI+aHgVEkYhkHDy55it68aUe4D7P/2EatLEhEREREpNxScKpHmdeOYU9dcDLfa+ql4diy1uCIRERERkfJBwamSuejSEXxLL2z4SJt2M7gyrC5JRERERKTMU3CqZGLCAsnq8x8SfVWIyNxN2uwJVpckIiIiIlLmKThVQpd1b8F7Ve4BIHjN//Dt+NXiikREREREyjYFp0rIZjO47Mob+NJjDtnL+OpWDdkTERERESmAglMl1bh6GIldHiPBF0VI2k6ccx6zuiQRERERkTJLwakSu6lfW14KvAOAgFX/g81zLa5IRERERKRsUnCqxAIddoZcdh1T3P0ByJ5xK6QdsLgqEREREZGyR8GpkuvesCobWtzLBm88jqxDeL8eDV6v1WWJiIiIiJQpCk7CQ4Pb8oj9HrJ8Dmxbf4bf37K6JBERERGRMkXBSYgK8efqQf150n0tAL55EyBhncVViYiIiIiUHQpOAsCwdjXZWfcK5ng6YHiz8X01ClzpVpclIiIiIlImKDgJAIZh8J9hLZnALST4ojCStsCPD1ldloiIiIhImaDgJHnqRIcwsm97xmbfihcDVn8If39jdVkiIiIiIpZTcJJ8bjy3Hhk1u/OWezAAvu/uguQ9FlclIiIiImItBSfJx89u44XLWvMml7PW2wAjKxlm3Axej9WliYiIiIhYRsFJTtAwJpR7+jfnruw7SPMFwc5fYcmLVpclIiIiImIZBSc5qeu71yO2ThMeyb4eAN/CSbB7ucVViYiIiIhYQ8FJTspuM/jvZa2ZY+/F157uGD4PTB8FWclWlyYiIiIiUuoUnOSU6kSHMH5gEx7Nvp7dvhg4ugu+Hws+n9WliYiIiIiUKgUnKdDwznVo3TCeu1y348EGf30F6z63uiwRERERkVKl4CQFstkMnru0NVv8m/Ji9qVm46z7IGmrtYWJiIiIiJQiBSc5rZqRQTw6qClveS7id19TcKWZ9zu5XVaXJiIiIiJSKhScpFAu7xBPr8axjHHeRqoRCvvWwIL/WF2WiIiIiEipUHCSQjEMg2cuaUV6YCz3OW80G399BbYttLQuEREREZHSoOAkhRYbHsjjQ5ozx9uJzz19AB98PRrSk6wuTURERESkRCk4yRkZ2qYmfZvGMDH7Gnbba0FqAsy8Q1OUi4iIiEiFpuAkZ8QwDP5zcUv8A0O4JeM2PIYDNs2ClZOtLk1EREREpMQoOMkZiw0P5LHBzVnvq8uz7ivNxrmPaIpyEREREamwFJykSC5pV5PzGlfjf9n9WedoDdkZMONm8LitLk1EREREpNgpOEmRGIbBpGGtCA30Z3TqjTj9QmHvSljygtWliYiIiIgUOwUnKbLqEYE8emEzEohmnHOk2bjoWdi7ytK6RERERESKm4KTnJXLOtSiZ6NqzMjuyi8BPcHnMYfsuTKsLk1EREREpNgoOMlZMQyDZ4a1JDTAwe3J15AeEANJ/8C8R60uTURERESk2Cg4yVmrERnEwxc2JZlQ7si40Wxc8R5smWdtYSIiIiIixUTBSYrFlR3jObdhVRZkt+CHoCFm47e3Q8ZhawsTERERESkGCk5SLAzD4JlLWhLib2fskYs5GlIP0vbDnPFWlyYiIiIictYUnKTY1KoSzIMDmuDEn9vTRuHDgHWfacieiIiIiJR7Ck5SrK7pXId2tSP51Vmfn8KHmY3fjYGsFEvrEhERERE5GwpOUqxsNoNnLmmFw25w14ELSQ+Jh5Q98NNEq0sTERERESkyBScpdo1iw7i1VwMyCeS+rFFm48r3Yccv1hYmIiIiIlJECk5SIm7/v4Y0qBbC7PRGLI8abDbOvBOyM60tTERERESkCBScpEQE+Nl55pJWAIzaNwRXcHU4vA0WP29xZSIiIiIiZ07BSUpMx7pRXNkxnlSCeda4wWz89RU4sMHawkREREREzpCCk5SoBy5oQkSQg/eTWrCr2nngdZuz7Hm9VpcmIiIiIlJoCk5SoqJC/HnggsYA3HDwMnyOYNj9G6z+wOLKREREREQKz9LgNGnSJDp27EhYWBgxMTEMHTqUTZs2nfa4RYsW0b59ewIDA6lfvz5vv/12KVQrRXVlx9q0qhXBP1mRfBuVM2TvpwmQut/awkRERERECsnS4LRo0SJuv/12fvvtN+bNm4fb7aZfv36kp6ef8pjt27czcOBAevTowZo1axg/fjx33XUX06dPL8XK5UzYbQZPDGmBYcDYnV1Ij24JWckwZ5zVpYmIiIiIFIrh8/l8VheR6+DBg8TExLBo0SJ69ux50n0efPBBZs6cyYYNxyYYGD16NOvWrWPZsmWnvUZKSgoREREkJycTHh5ebLXL6Y2b8QefLd/NoKr7eS39XgyfF4ZPh3P6Wl2aiIiIiFRCZ5INytQ9TsnJyQBERUWdcp9ly5bRr1+/fG39+/dn5cqVZGdnn7C/0+kkJSUl30Os8UB/c6KI7w/FsqnOcLPxh7HgyrC2MBERERGR0ygzwcnn8zF27FjOPfdcWrRoccr9EhMTiY2NzdcWGxuL2+3m0KFDJ+w/adIkIiIi8h7x8fHFXrsUTpUQf+7pew4AN+7qhze8JhzdCYuetbgyEREREZGClZngdMcdd/DHH3/w2WefnXZfwzDyvc4dbfjvdoBx48aRnJyc99i9e3fxFCxFMrxLHRpUC2FPhp3psWPMxmWvw/6/La1LRERERKQgZSI43XnnncycOZMFCxZQq1atAvetXr06iYmJ+doOHDiAn58f0dHRJ+wfEBBAeHh4vodYx2G38ciFzQAYv74W6fUH5qztdLfWdhIRERGRMsvS4OTz+bjjjjuYMWMG8+fPp169eqc9pmvXrsybNy9f29y5c+nQoQMOh6OkSpVi1LtxNXo2qka2x8cTnhHgHwZ7VsCqyVaXJiIiIiJyUpYGp9tvv52PP/6YTz/9lLCwMBITE0lMTCQzMzNvn3HjxjFixIi816NHj2bnzp2MHTuWDRs2MHnyZN5//33uu+8+K74FKQLDMHjkwqbYbQbTNnnZ1nqsueGnxyElwdriREREREROwtLg9NZbb5GcnEzv3r2Ji4vLe0ybNi1vn4SEBHbt2pX3ul69esyaNYuFCxfSpk0bnnzySV599VUuueQSK74FKaJGsWFc3ak2AHdtaYevRntwpsCPD1lcmYiIiIjIicrUOk6lQes4lR2H0130en4BqVlu3jnfn/6/XAE+D1z9BTTqb3V5IiIiIlLBldt1nKRyiQrx5+4+5vTkDy8zcHW61dzww33gSrewMhERERGR/BScxFIjutalbnQwh9KcvOa5FCJqQ/IuWDjJ6tJERERERPIoOIml/P1sPJwzPfk7vyVysNfT5oZlb0LCHxZWJiIiIiJyjIKTWK5v0xi61o/G5fbyxKZa0Pxi816n7+4Gr8fq8kREREREFJzEeoZh8PCFTTEM+G7dPta1GAcBEbBvNax43+ryREREREQUnKRsaFEzgkvb1QJg4oJD+PpOMDf8/ASk7LOwMhERERERBScpQ+7r35ggh501u47yvaM/1OoErlSY/YDVpYmIiIhIJafgJGVGbHggo3s1AOCZHzfjHPAi2Pxgw3ewcZbF1YmIiIhIZabgJGXKTT3rUT08kL1HM5m8JRi63WlumHUfOFOtLU5EREREKi0FJylTgv39uL9/YwDeWPAPh9rfDVXqQspeWPC0tcWJiIiISKWl4CRlzsVta9KiZjhpTjcvL9oDF75obvj9bdi3xtriRERERKRSUnCSMsdmM3gkZ1HcT3/fxeawTtDyMvB5zbWdPG6LKxQRERGRykbBScqkLvWj6d88Fq8P/vPDBuj/NARGQMI6WP6u1eWJiIiISCWj4CRl1rgBTXHYDRZtPsiifQac/6S5Yf5TkLzH2uJEREREpFJRcJIyq27VEEZ0rQvAf35Yj7v1cKjdFbLTYdb94PNZW6CIiIiIVBoKTlKm3fV/5xAZ7GDz/jSmrdoLg14GmwM2zTLXdxIRERERKQUKTlKmRQQ7uLvPOQC8OHczqeEN4Nwx5sZZ90NWsnXFiYiIiEiloeAkZd41XepQv2oISeku3ly4FXrcB9ENIS0RfppodXkiIiIiUgkoOEmZ57DbGD+wKQDv/7Kd3aleGPyKuXHlZNi5zMLqRERERKQyUHCScqFP0xi6NYjG5fby7I8boe650G6EufG7u8DttLZAEREREanQFJykXDAMg4cvbIphwPd/JLBq5xE4/wkIiYFDm2HJi1aXKCIiIiIVmIKTlBvNa0Rweft4AJ78fj2+wEgY+Jy5cckLcGCjdcWJiIiISIWm4CTlyr39GhHsb2ft7qN890cCNBsKjQaAN9scsuf1Wl2iiIiIiFRACk5SrsSEB3JrrwYAPDt7I1luL1z4X/APhd2/w6rJFlcoIiIiIhWRgpOUOzf2qE9cRCB7j2by/i/bIaIW9JlgbvzpcUjZZ22BIiIiIlLhKDhJuRPkb+fBC5oA8OaCfziY6oSOo6BmB3CmmAvjioiIiIgUIwUnKZcual2D1rUiSHd5eGHuJrDZ4aJXweYHG7+HDd9ZXaKIiIiIVCAKTlIu2WwGjw5qBsC0lbv5a28yxDaH7mPMHX64D7KSrStQRERERCoUBScptzrUjWJw6xr4fPDE9+vx+XzQ836IbghpifDTRKtLFBEREZEKQsFJyrWHBjQh0GFj+fbDzP4rERyBMPgVc+PKybBzmbUFioiIiEiFoOAk5VrNyCBu7mlOT/70rA1kZXug7rnQboS5w3d3gdtpYYUiIiIiUhEoOEm5N7pXfaqHB7LnSM705ADnPwEhMXBoMyx50doCRURERKTcU3CSci/Y348HBzQG4I0F/3AgJQuCqsDA58wdlrwABzZaWKGIiIiIlHcKTlIhDGldkzbxkWS4PDw3Z5PZ2GwoNBoA3mxzyJ7Xa2mNIiIiIlJ+KThJhWCzGUwYbE5P/tWqPfyx5ygYBlz4X/APhd2/w6rJ1hYpIiIiIuWWgpNUGG1rV+HitjUBeOK7nOnJI2pBn8fMHeZNhJR91hUoIiIiIuWWgpNUKA9e0IQgh52VO4/w3R8JZmPHG6FmB3Clwqz7rS1QRERERMolBSepUKpHBHJrb3N68mdmbSDT5QGbHS56FWx+sPF7WD/T4ipFREREpLxRcJIK5+ae9akZGcS+5CzeXbzNbIxtDt3HmM9n3Q9ZyZbVJyIiIiLlj4KTVDiBDjsPDWgCwNuLtpKQnGlu6Hk/RDeEtET4aaJ1BYqIiIhIuaPgJBXSoFZxdKxbhcxsD8/9mDM9uSMQBr9iPl85GXYus65AERERESlXFJykQjIMg8cGNccw4Os1e1m964i5oe650G6E+fy7u8DttK5IERERESk3FJykwmpZK4JL2tUCzOnJvV6fueH8JyAkBg5thiUvWlihiIiIiJQXCk5SoT3QvzEh/nbW7j7Kt+v2mo1BVWDgc+bzJS/AgY3WFSgiIiIi5YKCk1RoMeGB3HZeQwCenb2JDJfb3NBsKDQaAN5sc8ie12tdkSIiIiJS5ik4SYU36tx6xEcFkZiSxdsLt5qNhgEX/hf8Q2H377BqsrVFioiIiEiZpuAkFV6gw874AU0BeGfxNvYcyTA3RNSCPo+Zz+dNhOS91hQoIiIiImWegpNUChe0qE7nelE43V6emX3cPU0db4RaHcGVCj/cCz6fdUWKiIiISJml4CSVgmEYPDa4GYYB3/+RwModh80NNjtc9BrYHLB5Nvw9w9pCRURERKRMUnCSSqN5jQiu7BgPwOPHT08e0xR63mc+n/UAZBy2qEIRERERKasUnKRSubdfY0ID/PhzbzLTV+85tuHcsRDTDDIOwY/jrCtQRERERMokBSepVKqGBnDn/5nTkz83ZxNpzpzpyf38zSF7GPDH57DlJ+uKFBEREZEyR8FJKp2R3etSJzqYg6lO3lzwz7ENtTpAl1vN59+PAWeqJfWJiIiISNmj4CSVToCfnYcHmtOTv/fLdnYfzji28f8egcjakLwbfn7SogpFREREpKxRcJJK6fxmsXRvGI3L7eXpWRuObfAPgcGvms+Xvwu7l1tToIiIiIiUKQpOUikZhsGjg5phM2D2X4n8ti3p2MYG50Gb4YAPvr0D3E7L6hQRERGRskHBSSqtJtXDubpzbcCcntzjPW7x235PQUgMHNoEi/9rUYUiIiIiUlYoOEmlNvb8xoQH+rEhIYUvV+4+tiE4CgY+bz7/5UXY/7c1BYqIiIhImaDgJJVaVIg/d/dtBMB/524iNSv72MZmQ6DJIPC6Yead4PVYVKWIiIiIWE3BSSq9EV3rUL9aCIfSXLw+/7jpyQ0DBv4XAiJg7yr4/W3rihQRERERSyk4SaXnsNt45EJzevLJv25nx6H0YxvD46BfzrTkPz8Jh7dbUKGIiIiIWE3BSQQ4r3EMPRtVI9vj4z/HT08O0G4E1O0B7kxzYVyf76TnEBEREZGKS8FJhJzpyS9sit1mMG/9fn7959DxG2HwK+AXCNsWwtpPLKtTRERERKyh4CSS45zYMK7tUgeAJ75bj9vjPbYxugGc97D5fM54SE20oEIRERERsYqCk8hxxvQ9h8hgB5v2p/Lxbzvzb+xyG8S1gaxk+OFeDdkTERERqUQUnESOExnsz339GgPw4rzNJKU5j220+8GQN8DmgI3fw7rPLapSREREREqbgpPIv1zVqTbNa4STkuXm+Tmb8m+s3gLOG2c+n/0AHN194glEREREpMJRcBL5F7vN4PGLmgMwbeVu/thzNP8O3e6GWh3BmQLf3g5e74knEREREZEKxdLgtHjxYgYPHkyNGjUwDINvvvmmwP0XLlyIYRgnPDZu3Fg6BUul0aFuFBe3rYnPBxNm/o3Xe9z9THY/uPgdcATD9kWw4n/WFSoiIiIipcLS4JSenk7r1q15/fXXz+i4TZs2kZCQkPc455xzSqhCqcweGtCEEH87a3YdZcaavfk3RjeA858wn8+bAIe2lH6BIiIiIlJqLA1OAwYM4KmnnmLYsGFndFxMTAzVq1fPe9jt9hKqUCqz2PBA7uxjhvJnZm8kJSs7/w4dRkH988yFcb++BTxuC6oUERERkdJQLu9xatu2LXFxcfTp04cFCxYUuK/T6SQlJSXfQ6Swbuhej/pVQziU5uTVn/7Vq2SzmbPsBUTA3lXw60vWFCkiIiIiJa5cBae4uDjeffddpk+fzowZM2jcuDF9+vRh8eLFpzxm0qRJRERE5D3i4+NLsWIp7/z9bDw2uBkAU5fu4J8Dqfl3iKgJA583ny98BhLWlXKFIiIiIlIaDJ+vbKziaRgGX3/9NUOHDj2j4wYPHoxhGMycOfOk251OJ07nsbV4UlJSiI+PJzk5mfDw8LMpWSqRGz9YwU8bDtC9YTQfj+qMYRjHNvp88MUI2DATqjaCmxeBf7B1xYqIiIhIoaSkpBAREVGobFCuepxOpkuXLmzZcuob8wMCAggPD8/3EDlTjw1qToCfjV//SeK7PxLybzQMGPQyhFaHQ5thznhLahQRERGRklPug9OaNWuIi4uzugyp4GpHB3P7eQ0BePL79SdOFBESDRe/bT5fNQU2fF/KFYqIiIhISbI0OKWlpbF27VrWrl0LwPbt21m7di27du0CYNy4cYwYMSJv/5dffplvvvmGLVu28PfffzNu3DimT5/OHXfcYUX5Usnc0qs+9aqGcDDVyYtzN5+4Q4PzoNud5vOZd0JKwon7iIiIiEi5ZGlwWrlyJW3btqVt27YAjB07lrZt2/LYY48BkJCQkBeiAFwuF/fddx+tWrWiR48e/PLLL/zwww9nPJ25SFEE+Nl5ckgLAD5ctoO/9iafuNP/PQZxrSHzsDlFuddbylWKiIiISEkoM5NDlJYzuQFM5GTu/GwN363bR+v4SL6+tRs2m5F/h0Nb4J2ekJ1hLpLb/W5rChURERGRAlWqySFEStsjFzYlNMCPdbuP8tmKXSfuUPUcuGCS+fznJ2Hf2lKtT0RERESKn4KTyBmKDQ/k3n6NAHjux00cSnOeuFO766DJIPBmw/RR4Eov5SpFREREpDgVKTjt3r2bPXv25L1evnw5Y8aM4d133y22wkTKsmu71KFZXDjJmdlMmrXxxB0MAy56DcJqQNI/8OO40i9SRERERIpNkYLT1VdfzYIFCwBITEzk/PPPZ/ny5YwfP54nnniiWAsUKYv87Db+c3ELDAOmr97D79uSTtwpOCpninIDVn8A60++SLOIiIiIlH1FCk5//fUXnTp1AuCLL76gRYsWLF26lE8//ZSpU6cWZ30iZVbb2lW4smNtAB755i+yPSeZQa9+r2OTQ8y8E5L3lmKFIiIiIlJcihScsrOzCQgIAOCnn37ioosuAqBJkyYkJGjtGqk8HrygMVEh/mw5kMb7v2w/+U7nPQxxbSDraM4U5Z7SLFFEREREikGRglPz5s15++23WbJkCfPmzeOCCy4AYN++fURHRxdrgSJlWWSwP+MGNAHglZ+2sPdo5ok7+fnDJe+DIxh2LIGlr5ZylSIiIiJytooUnJ599lneeecdevfuzVVXXUXr1q0BmDlzZt4QPpHK4tL2tehUN4rMbA+Pz/z75DtVbQgDnjWfz38K9q4uvQJFRERE5KwVeQFcj8dDSkoKVapUyWvbsWMHwcHBxMTEFFuBxU0L4EpJ2JSYyoWvLsHt9fH+dR3o0zT2xJ18PvjyOlj/LUQ1gFsWQ0Bo6RcrIiIiIkApLICbmZmJ0+nMC007d+7k5ZdfZtOmTWU6NImUlMbVwxh1bj0AJsz8m0zXSe5jMgwY/AqE14TDW+HHB0u5ShEREREpqiIFpyFDhvDhhx8CcPToUTp37swLL7zA0KFDeeutt4q1QJHy4q4+51AjIpA9RzJ5Y8E/J98pqAoMexcwYM3H8OdXpVqjiIiIiBRNkYLT6tWr6dGjBwBfffUVsbGx7Ny5kw8//JBXX9WN71I5hQT48djg5gC8s3gr/xxIO/mOdc+FnveZz7+7Gw6dImSJiIiISJlRpOCUkZFBWFgYAHPnzmXYsGHYbDa6dOnCzp07i7VAkfKkf/NY/q9JDNkeH499+xenvIWw10NQ51xwpZn3PWWfZDY+ERERESkzihScGjZsyDfffMPu3buZM2cO/fr1A+DAgQOacEEqNcMwmDi4OQF+NpZuTWLmun0n39HuB5e8B8FVYf9f8ONDpVuoiIiIiJyRIgWnxx57jPvuu4+6devSqVMnunbtCpi9T23bti3WAkXKm9rRwdz5fw0BePL7DSRnZp98x/A4uOR/gAGrpsIfX5ZajSIiIiJyZooUnC699FJ27drFypUrmTNnTl57nz59eOmll4qtOJHy6qae9alfLYRDaU5enLvp1Ds2+D/oeb/5/Lu74WAB+4qIiIiIZYoUnACqV69O27Zt2bdvH3v37gWgU6dONGnSpNiKEymvAvzsPDWkBQAf/baTP/YcPfXOvR+Cuj0gOx2mXQvOU0wqISIiIiKWKVJw8nq9PPHEE0RERFCnTh1q165NZGQkTz75JF6vt7hrFCmXujWsypA2NfD64IGv/iDbc4p/GzY7XDoZQqvDoU1mz1PR1qUWERERkRJSpOD08MMP8/rrr/PMM8+wZs0aVq9ezdNPP81rr73Go48+Wtw1ipRbjw5qRmSwg42Jqby7eNupdwyNgcumgmGHv76C5f8rtRpFRERE5PQM3ynnSz61GjVq8Pbbb3PRRRfla//222+57bbb8obulUUpKSlERESQnJysGQClVMxYvYexX6zD38/G7Lt70KBa6Kl3Xvo6zH0YbA64fjbEdyy9QkVEREQqmTPJBkXqcTp8+PBJ72Vq0qQJhw8fLsopRSqsi9vWpGejarjcXsZN/xOvt4C/VXS9HZpeBN5sc32n9EOlV6iIiIiInFKRglPr1q15/fXXT2h//fXXadWq1VkXJVKRGIbB0xe3INjfzvIdh/l0+a6CdoYhb0B0Q0jZC9NvBK+n9IoVERERkZMq0lC9RYsWceGFF1K7dm26du2KYRgsXbqU3bt3M2vWLHr06FEStRYLDdUTq0z5dTuPf7ee0AA/5o3tSVxE0Kl33r8e3usD2RnQ60E4b3zpFSoiIiJSSZT4UL1evXqxefNmLr74Yo4ePcrhw4cZNmwYf//9N1OmTClS0SIV3YiudWlbO5I0p5tHv/mLAv9mEdsMBr1sPl/0LGyZVyo1ioiIiMjJFanH6VTWrVtHu3bt8HjK7tAi9TiJlTbvT+XCV5eQ7fHx2lVtGdy6RsEHfD8WVr4PQVXg5kVQpU7pFCoiIiJSCZR4j5OIFE2j2DBuP68hABNn/s2RdFfBB1wwCWq0g8wj5mQRbmcpVCkiIiIi/6bgJFLKbu3dgHNiQklKd/HUDxsK3tkvAC7/wOxx2rcGfnyodIoUERERkXwUnERKWYCfnWcuaYVhwPTVe1i8+WDBB0TWhmHvAQasnAxrPyuVOkVERETkGL8z2XnYsGEFbj969OjZ1CJSabSvU4XrutZl6tIdjP/6T+aM6UlIQAH/HM/pa86ut+gZ+H4MVGsMNduVWr0iIiIild0Z9ThFREQU+KhTpw4jRowoqVpFKpT7+zemZmQQe45k8sLczac/oNcDcE5/cGfB58MhdX/JFykiIiIiQDHPqlceaFY9KUsWbT7IdZOXYxgw49ZutK1dpeADspLhvb5waDPU6gQjvzfvgxIRERGRM6ZZ9UTKiV6NqjGsbU18Pnho+p843aeZyj8wAq763Py6Zzn8MBYq198+RERERCyh4CRisUcHNSM6xJ9N+1N59ectpz8gugFcOhkMG6z5GH5/p+SLFBEREankFJxELFYlxJ//XNwCgLcWbmXt7qOnP6hhXzj/CfP5nPGwbWGJ1SciIiIiCk4iZcIFLeIY0qYGXh/c+8VasrJPM2QPoOsd0OpK8Hngy5FweHuJ1ykiIiJSWSk4iZQRj1/UnGphAWw9mM4Lczed/gDDgMGvQM32kHkEPrsKnKklX6iIiIhIJaTgJFJGRAb788ywlgC898t2Vuw4fPqDHIFwxScQWh0OboAZt4DXW8KVioiIiFQ+Ck4iZUifprFc2r4WPh/c/+U6Mlzu0x8UHgdXfgL2ANj0A8x/suQLFREREalkFJxEypjHBjcjLiKQHUkZPPdjIYbsAdTqYA7bA/jlRVg5peQKFBEREamEFJxEypjwQAfPXtIKgKlLd7B066HCHdjmKug9znz+w1jYPKeEKhQRERGpfBScRMqgno2qcXXn2gA88NUfpDkLMWQPoNeD0PYa8HnNmfb2ri65IkVEREQqEQUnkTJq/MCm1KoSxJ4jmfznhw2FO8gwYNDL0KAPZGfAp5drmnIRERGRYqDgJFJGhQb48fylrQH4bPkuFm0+WLgD7Q64/AOo3hLSD8Inl0JGIWboExEREZFTUnASKcO6NohmZLe6ADz41R8kZ2YX7sCAMLj6S4iIh6R/zDWesjNLrlARERGRCk7BSaSMe+CCxtSNDiYxJYsnvltf+APD42D4lxAYAbt/g6+1xpOIiIhIUSk4iZRxwf5+/Pey1hgGTF+9h3nr9xf+4JimcOWnYPeH9d/C3EdKrlARERGRCkzBSaQc6FA3ipt61Adg3Iw/OZLuKvzBdc+FoW+Zz397A5a9UQIVioiIiFRsCk4i5cTY8xvRMCaUQ2lOHpv595kd3PJSOP8J8/mc8fDX9OIvUERERKQCU3ASKScCHXZeuKw1dpvBd+v2MevPhDM7Qbe7oNMt5vOvR8M/Pxd/kSIiIiIVlIKTSDnSOj6SW3s1AGD813+SmJxV+IMNAy6YBM2GgMcFn18NWxeUUKUiIiIiFYuCk0g5c1efc2hZM4KjGdmM/WItXq+v8Afb7DDsPWg8ENxZ5jTl2xaVXLEiIiIiFYSCk0g54+9n4+Ur2xDksLN0axLvLtl2Zifw84fLpsI5/cGdCZ9eAduXlEitIiIiIhWFgpNIOdSgWigTBjcD4L9zNvHnnuQzO4FfAFzxETQ8Pyc8XQ47fi2BSkVEREQqBgUnkXLqio7xXNC8Om6vj7s/X0OGy31mJ/ALgCs+hgZ9IDsDPrkMdi4rmWJFREREyjkFJ5FyyjAMnrmkJdXDA9l2KJ0nvlt/5idxBMKVn0D98yA7HT65FHb9XvzFioiIiJRzCk4i5VhksD8vXdEGw4DPV+xm9plOUQ7gCIIrP4V6PcGVBh9fArtXFH+xIiIiIuWYgpNIOde1QTSjc6Yof2jGnyQkZ575SfyD4appULcHuFLh42GwZ1UxVyoiIiJSfik4iVQA9/RtRKtaESRnZnPXZ2twe7xnfhL/YLh6GtTpDs4U+Ohi2Lu6+IsVERERKYcUnEQqAH8/G69e2ZbQAD9W7DjCf+duLuKJQuDqL6B2V3Amw0dDNWxPREREBAUnkQqjbtUQnr+0FQBvL9rKzxv2F+1EAaEw/EuI7wJZyfDhEC2SKyIiIpWegpNIBTKgZRzXd68LwNgv1rH7cEbRThQQBtfOgPq9c2bbuww2zym2OkVERETKGwUnkQpm3ICmtImPJDkzmzs+XY3T7SnaifxDzAkjGl8IHid8fjX8NaN4ixUREREpJxScRCoYfz8bbwxvR2Swg3V7kpk0a2PRT+YIhMs/gJaXg9cN00fB6o+Kr1gRERGRckLBSaQCqhkZxIuXtwZg6tId/PBHEdZ3ymV3wMXvQPvrweeFmXfAb28XU6UiIiIi5YOCk0gF9X9NYrm1t7m+04PT/2DbwbSin8xmg0EvQdc7zNc/PgiLnwefrxgqFRERESn7FJxEKrB7z29E53pRpDnd3PLRKtKc7qKfzDCg31PQe7z5ev5TMO9R8BZhzSgRERGRckbBSaQC87PbeO3qtsSGB7DlQBoPfLUO39n0EhkG9H4Q+j9tvl76Gnx9C7hdxVOwiIiISBml4CRSwcWEBfLm8PY47Aaz/kzk7UXbzv6kXW+HoW+DzQ/+/AI+uRSyUs7+vCIiIiJllKXBafHixQwePJgaNWpgGAbffPPNaY9ZtGgR7du3JzAwkPr16/P227pJXeR02tepwoTBzQF4fs5Glmw5ePYnbXMVXP0F+IfC9kUwZSCknMUkFCIiIiJlmKXBKT09ndatW/P6668Xav/t27czcOBAevTowZo1axg/fjx33XUX06dPL+FKRcq/4Z1rc3mHWnh9cOdna4q+OO7xGvaBkT9ASAzs/xPe7weH/jn784qIiIiUMYbvrG54KD6GYfD1118zdOjQU+7z4IMPMnPmTDZs2JDXNnr0aNatW8eyZcsKdZ2UlBQiIiJITk4mPDz8bMsWKVeysj1c8c4y1u1JpllcONNv7UaQv/3sT3xkB3w0DA5vheCqcM1XUKPt2Z9XREREpASdSTYoV/c4LVu2jH79+uVr69+/PytXriQ7O/ukxzidTlJSUvI9RCqrQIedt65pT3SIP+sTUhj/9Z9nN1lErip14YY5ENcaMg7B1MGwbdHZn1dERESkjChXwSkxMZHY2Nh8bbGxsbjdbg4dOnTSYyZNmkRERETeIz4+vjRKFSmzakQG8drVbbHbDL5es5f3lmwvnhOHVoPrvoe6PcCVak4Ysf7b4jm3iIiIiMXKVXACc0jf8XL/Wv7v9lzjxo0jOTk577F79+4Sr1GkrOvWoCoPD2wKwNOzN/Dzhv3Fc+LAcBj+FTQdDB4XfDkSVk4pnnOLiIiIWKhcBafq1auTmJiYr+3AgQP4+fkRHR190mMCAgIIDw/P9xARuL57Xa7qVBufD+76bA0bE4tpGKsjEC77ANqPBJ8Xvh8Di5+HsnE7pYiIiEiRlKvg1LVrV+bNm5evbe7cuXTo0AGHw2FRVSLlk2EYPDGkOV3qR5Hu8jBq6koOpTmL5+Q2Owx6GXrcZ76e/xT8OA683uI5v4iIiEgpszQ4paWlsXbtWtauXQuY042vXbuWXbt2AeYwuxEjRuTtP3r0aHbu3MnYsWPZsGEDkydP5v333+e+++6zonyRcs9ht/HW8PbUjQ5m79FMbvloFU63p3hObhjQ51G44Bnz9e9vwde3gOfkE7mIiIiIlGWWBqeVK1fStm1b2rY1py0eO3Ysbdu25bHHHgMgISEhL0QB1KtXj1mzZrFw4ULatGnDk08+yauvvsoll1xiSf0iFUGVEH/eu64jYYF+rNp5hHEzimmmvVxdboVh/wObH/z5BXx2FbjSi+/8IiIiIqWgzKzjVFq0jpPIyS3ZcpCRU1bg8fp48IIm3Nq7QfFeYMs8mHYtuDOheku48jOI1CyXIiIiYp0Ku46TiJScHudUY8LgZgA8N2cjc/5OPM0RZ+ic8+G6mRBSDRL/hHd7w67fivcaIiIiIiVEwUlE8ozoWpdru9TB54N7pq3l733JxXuB+E5w0wKzxynjEEwdBKs/Kt5riIiIiJQABScRyWfC4Gac27AqGS4PN36wkv0pWcV7gch4uGEONBsC3myYeYc5457HXbzXERERESlGCk4iko+f3cYbV7ejfrUQEpKzGDllBWnOYg41/iFw6VToPc58/dub8OllkHmkeK8jIiIiUkwUnETkBBHBDj64vhNVQ/3ZkJDCrR+vIttTzGsw2WzQ+yFzsVxHMGydD+/1hUNbivc6IiIiIsVAwUlETio+KpjJIzsS5LCzZMshxhf3NOW5mg81h+6F14Kkf+B/feCfn4r/OiIiIiJnQcFJRE6pVa1IXr+6LTYDvly1h1d+LqHeoLhWcPMCiO8MzmT45DJY+jpUrtUSREREpAxTcBKRAvVpGsuTQ1sA8PJPW/hi5e6SuVBoDFz3HbS9BnxemPswfHs7uJ0lcz0RERGRM6DgJCKnNbxzHW7LWRB3/Iw/Wbz5YMlcyC8ALnod+k8CwwZrP4EPBkPagZK5noiIiEghKTiJSKHc378xQ9vUwO31cevHq4p/jadchgFdb4PhX0JABOz+Hd49DxLWlcz1RERERApBwUlECsUwDJ67tDVd60eT7vJw/ZQV7D2aWXIXbNgXbpoP0Q0hZQ9MvgD+/qbkriciIiJSAAUnESk0fz8bb1/bnkaxoRxIdTJy8nKOZrhK7oJVG8KNP0ODPpCdAV9eBwueBm8xT40uIiIichoKTiJyRiKCHEy9vhPVwwPZciCNUR+sJNPlKbkLBkXC1V9A1zvM14uehS+uBWdayV1TRERE5F8UnETkjNWIDOKDGzoRHujHqp1HuOPT1biLe4Hc49n9oP9/YMgbYPeHjd/De31g//qSu6aIiIjIcRScRKRIGlcP4/2RHQnws/HzxgOMK6kFco/X9hoY+QOExsLBjfBub1j+P633JCIiIiVOwUlEiqxj3Shev7oddpvBl6v28NycTSV/0fhOMPpXaHg+eJww6z74/GpITyr5a4uIiEilpeAkImfl/GaxTLq4JQBvLdzK+79sL/mLhlYz73vqP8kcurdpFrx9Luz6reSvLSIiIpWSgpOInLXLO8Zzf//GADz5/Xq+WbO35C9qs5nrPd34M0SfA6n7YMpA+OVlzbonIiIixU7BSUSKxW29GzCyW10A7v1yHXP/TiydC8e1gpsXQMvLwOeBnybAZ1dCxuHSub6IiIhUCgpOIlIsDMPgsUHNGNa2Jh6vjzs+XcOSLQdL5+IBYTDsfzDoZbAHwJY58FZ32L64dK4vIiIiFZ6Ck4gUG5vN4LlLWzGgRXVcHi83fbiS5dtLqefHMKDD9XDjTxDd0By698FFMO8xcJfgIr0iIiJSKSg4iUix8rPbeOXKtvRuXI2sbC83TF3BH3uOll4Bca3glsXQ7jrAB7++Au/3hYObS68GERERqXAUnESk2Pn72Xj7mvZ0qR9FmtPNiMnL2ZSYWooFhMBFr8IVH0NQFUhYB+/0hJWTteaTiIiIFImCk4iUiECHnfeu60ib+EiOZmQz/L3f2X4ovXSLaDoYbl0G9XuDOxO+vwemXaOJI0REROSMKTiJSIkJDfDjg+s70TQunENpTob/7zf2HMko3SLC4+Car6HfU2BzwMbv4e0esHNZ6dYhIiIi5ZqCk4iUqIhgBx+N6kT9aiHsS85i+Hu/cyAlq3SLsNmg253mxBFRDSBlD0wdCAufBa+ndGsRERGRcknBSURKXNXQAD69sQvxUUHsTMrgmvd/53C6BTPd1WgDtyyCVleCzwsLn4Z3e8Gu30u/FhERESlXFJxEpFRUjwjk0xu7UD08kM370xgx+XdSsrJLv5CAMBj2Dlz8DgRGQOKfMLkf/HAvONNKvx4REREpFxScRKTUxEcF8/GNnYkO8eevvSncMGUFGS63NcW0vhLuXA1trzFfr3gP3uoG25dYU4+IiIiUaQpOIlKqGsaE8uGoToQH+rFy5xFu/nAVWdkW3WcUUhWGvAEjvoWIeDi6Ez4YBLPuB1cpzwAoIiIiZZqCk4iUuuY1Iph6QydC/O388s8hbvpwpXXhCczpym9bBu2vN18vf9fsfdrxi3U1iYiISJmi4CQilmhXuwqTR3Yk2N/Oki2HuGGqhcP2wLz3afDLcO3XEF4LjuyAqRfCrAfU+yQiIiIKTiJinc71o/kgp+dp6dYkRk5ZQbrTwvAE0OD/zN6ndteZr5e/k3Pv02Jr6xIRERFLKTiJiKU61o3ioxs7Exbgx/Lth7lu8nJSrZht73iB4XDRq3DNjGO9Tx8Mhu/uhqxka2sTERERSyg4iYjl2tWuwsc3ds6bMGLE5OXWTFX+bw37mL1PHUaZr1dNhTc6w6bZlpYlIiIipU/BSUTKhNbxkXx6Uxcigx2s2XWUa977neSMMhCeAsNh0IswchZENYDUBPjsSvjqBkg7aHV1IiIiUkoUnESkzGhRM4JPb+xCVIg/f+xJ5ur3fuNIusvqskx1u8Otv0L3MWDY4a/p8EYn+OML8Pmsrk5ERERKmIKTiJQpzWqE89lNXaga6s/f+1K46n+/kZTmtLoskyMIzn8cbvoZYltC5mGYcRN8ejkk77G6OhERESlBCk4iUuY0rh7G5zd3oVpYABsTU7nqf79xMLWMhCeAGm3h5gXwf4+C3R+2zDXvfVr2BrgyrK5ORERESoCCk4iUSQ1jzPAUGx7A5v1pXPnuMg6kZFld1jF2B/S8D0b/AvGdwZUGc8bDK61gyYuQlWJ1hSIiIlKMFJxEpMxqUC2UaTd3pUZEIFsPpnPlu7+RmFyGwhNAtcZw/Y8w+BWIrA3pB+Hnx+GlFjD/KUhPsrpCERERKQaGz1e57mpOSUkhIiKC5ORkwsPDrS5HRAph9+EMrnz3N/YezaROdDCf3tSFmpFBVpd1Ik82/PkV/PIiHNpstjmCof310O0OCK9hbX0iIiKSz5lkAwUnESkX9hzJ4Or//c6uwxnUqhLEZzd1IT4q2OqyTs7rhY3fw5L/QsI6s83uD22uNmfli6pnaXkiIiJiUnAqgIKTSPmVkJzJVe/+xo6kDGpEBPLhqM40jAm1uqxT8/lg68+w+AXYtdRsM2zQbCh0uQ3iO1panoiISGWn4FQABSeR8m1/ShZX/+83th5Mp0qwg8kjO9K2dhWryzq9nUthyQvwz0/H2ur2gD6PQXwn6+oSERGpxBScCqDgJFL+HU53cf3UFazbfZQgh523r21Pr0bVrC6rcBL/hN/eMhfO9WabbU0HQ7//QJU61tYmIiJSyZxJNtCseiJS7kSF+PPpjZ3p2agamdkeRk1dwbdr91pdVuFUbwlD34S71kC7EWDYYcN38EYnmP8frQMlIiJSRik4iUi5FBLgx3sjOnBR6xq4vT7u/nwtU37dbnVZhRcZDxe9Zq4DVa8nuLNg8XPwekdY/j9wpVtdoYiIiBxHQ/VEpFzzen088f16pi7dAcAd5zXk3n6NMAzD2sLOhM8HG2bCnEcgeZfZFhgJrS43Z+Kr0dbS8kRERCoq3eNUAAUnkYrH5/Px5sKtPD9nEwBXdYrnySEt8LOXs0717ExY8zEsewOOHNd7VrsbdL8LGvYFu8O6+kRERCoYBacCKDiJVFyfLd/Fw1//idcH/ZvH8sqVbQl02K0u68x5PbBtAaz9DNZ/e2wSiaAq0ORCczrzer3Az9/SMkVERMo7BacCKDiJVGw//pXIXZ+vweX20rleFP+7rgPhgeW4lyZlH/z2phmiMg4daw+qYk4u0fEm834pEREROWMKTgVQcBKp+JZtTeKmD1eS5nTTNC6cD27oSExYoNVlnR2P21xEd/23sH4mpB8w220O6Hob9LwfAsKsrVFERKScUXAqgIKTSOXw195kRk5ZwaE0J7Wjgvnwhk7UrRpidVnFw+uBzT+a60HtWGK2BUZCqyug7XCIa21peSIiIuWFglMBFJxEKo+dSelc+/5ydh3OICrEn/+N6ED7OlWsLqv4+HyweQ7MGQ+Htx5rr97SvA+qVkeo2U49USIiIqeg4FQABSeRyuVAahajpq7kz73J+PvZeOnyNlzYKs7qsoqX1wNbF8Daj2HjD+BxHbfRgGpNoF4PaDwA6vbQzHwiIiI5FJwKoOAkUvlkuNzc9dkaftpg3hf04AVNGN2rfvla66mwMg7DX9Nhxy+wdxUk786/PTgaWl4OHa6Hao2tqVFERKSMUHAqgIKTSOXk8fp48riFcq/qFM8TQ1rgKG9rPZ2p1P2wZzlsmQubZkP6wWPbGl0A3e6COt2gIoZIERGR01BwKoCCk0jlNuXX7Tz5/Xq8PuhxTlXeGN6ufE9XfiY8btg6H1Z/YA7pI+c//zXbQ9trzTWiQmMsLVFERKQ0KTgVQMFJROat389dn60hM9tDg2ohvHddR+pVlBn3CuvQP/DbG7D2U3Bn5TQaULsLNB1s3g8VVd/SEkVEREqaglMBFJxEBODPPcnc9OFKElOyCA/04/Wr29GzUTWryyp9aQdhzUew4TvYtzr/tqqNoVF/8xHXWrPziYhIhaPgVAAFJxHJdSAli9Efr2L1rqPYDBg/sCmjzq1XMSeNKIyju80hfBu/h13LwOvOvz2qvnlfVLMhUKsT2Cr4/WEiIlLhKTgVQMFJRI7ndHt49Ju/+GLlHgCGtavJ0xe3JNBht7gyi2Ueha0/m+tEbV8MqQn5t4dWh6aDzBBVuxvY/SwpU0RE5GwoOBVAwUlE/s3n8zF16Q6e+mEDHq+P1vGRvHtte2LDA60urezIOAw7l8KGmbDpR3AmH9vmCIawOAirDqGxEFHLnOq8RjuIaaoZ+0REpMxScCqAgpOInMqv/xzitk9Wk5yZTUxYAO9c2562tatYXVbZ43bB9kWw/htzaF/mkVPvW7URtLoCOtwAwVGlVqKIiEhhKDgVQMFJRAqyMymdmz5cyeb9afj72Zg4uDlXdYqvvPc9nY7HDUd3QmoipCWaX4/shIMbYNfv4HGa+/kFQavLoM1wiO+sXigRESkTFJwKoOAkIqeT5nRzz7S1zFu/H4BhbWvy1MUtCPbXfTxnJCvFnGji97chYd2x9qgG0PoqqNcTIuPN4X22Sn5PmYiIWELBqQAKTiJSGF6vj3eXbOP5OZvweH00ig3lzeHtaRgTanVp5Y/PBzt/hTWfwPpvITs9/3abH4TXgIjaEFETgqIgKDLnPqm2EFlHPVQiIlIiFJwKoOAkImfi921J3PHZGg6mOgnxtzPpklZc1LqG1WWVX840c82ov76Cg5shZS/4PAUfE1QF4tpA1XPM3qqo+hDdAKrU05ToIiJyVspVcHrzzTd5/vnnSUhIoHnz5rz88sv06NHjpPsuXLiQ884774T2DRs20KRJk0JdT8FJRM7UgdQs7v5sLcu2JQFwXdc6jL+wKQF+Gl521rwec6rz5D05j93mVOgZSbD/L0j8C7zZJz82IAJqtDZ7pWJbQHC0GbKCIiEkBgLUOygiIgU7k2xg6YD9adOmMWbMGN588026d+/OO++8w4ABA1i/fj21a9c+5XGbNm3K941Vq1atNMoVkUoqJiyQj0Z14qWfNvPGgq18sGwna3cf5Y3h7ahVJdjq8so3m92cvjyi1sm3u51wYD0k/AGHt8LhbZC0DZL+MadE377YfJxMWBxENzR7qsLiwLCBfyiExhybOj00BgLCSu77ExGRCsPSHqfOnTvTrl073nrrrby2pk2bMnToUCZNmnTC/rk9TkeOHCEyMrJQ13A6nTidzrzXKSkpxMfHq8dJRIpk/sb93DNtHcmZ2UQEOXj5ijac1yTG6rIqH082HNwI+9aYj0NbzGnRcx/ZGYU/lyPkuDAVYwaqyDpm6KrVAUKqltz3ISIilioXQ/VcLhfBwcF8+eWXXHzxxXntd999N2vXrmXRokUnHJMbnOrWrUtWVhbNmjXjkUceOenwvVwTJ07k8ccfP6FdwUlEimr34Qzu+HQ16/aYi8Defl4D7unbCD+77rcpMzKPQNJWM1AlbTGH/nk94EyFtAPm1OlpB8CVdvpzVW9pDges2tgMV8FR5rDAwEjwusHjAneWuW9kHa1XJSJSjpSL4LRv3z5q1qzJr7/+Srdu3fLan376aT744AM2bdp0wjGbNm1i8eLFtG/fHqfTyUcffcTbb7/NwoUL6dmz50mvox4nESkJTreH//ywgQ+X7QSga/1oXrmqDTFhgRZXJmfEmQZp+3PCVM7X1AQ4sh0ObDTXozpTQVXMCSyiGpiTWEQ1gOj6EH0OBOr/OyJSQXiyYf/fsG817F0NhzaD3R/8Q8yHI8icVdXnNf9w5edv/gGqaqNjw6VDqoHd2qU+ys09TsAJi0r6fL5TLjTZuHFjGjdunPe6a9eu7N69m//+97+nDE4BAQEEBAQUX8EiIkCAn50nhrSgQ90oHpr+B8u2JTHwlSU8e0kr+jSNtbo8KayAUPMR3eDk29MOmFOpH9hgfihIP2T2XmUkQVYy2BzmhwF7gDk7YNp+s7dr7yrz8W/R50BMU/PDgl8AuHKmZvcLNHuqIuuYQwMdwcd9+Mh5HhiRf1p2n8/8MGLxhw4ROQOebDi83bxPM+uo2WvtH3rsXs+zWdfO44b0g+bEOoe3gzPFPH9AmPnfj4Bws4c8aav53y+/APO/Vwc3ma9Pxj/E/G9TUNSx3nRXmjlxT+KfxxY5L6oR30L93md3jlJk2X9tq1atit1uJzExMV/7gQMHiI0t/IeOLl268PHHHxd3eSIihXJR6xo0iwvj9k/WsGl/KqM+WMmVHeN5ZFAzQgP0gbbcC42B5hebj8JwpedMYJEzkcXhreZkFoe3mqEqKWfoYFHY/SG0uhnQXGnmtbxuqFIX4lofe1RvDaGFnDTJk20uVOzONP8qnPuX4dy/GgeEgd1RtHpFSorPZ37Qz0jK+WPGoeO+JuV/bdjNhbYja5trxcU2g5odwBF47FwZh8GVCtmZZuA4vM0MFYGR5iydAWHmMF9ninlPpCPQDByudHMGz7BY8w8cXk/OzKBHzH839pw/qrgz4ehu2P0b/DPfvNapGHYzSPn55xyfex5/sz0w3AxAjiDzOmn7zUf6oTO7t7O4BEaYQ5lrtIPqLcyfZ3aG+bPJzjAn5TFs5vflTDXvTT28zfyjVPpB879p5Yjlk0O0b9+eN998M6+tWbNmDBky5KSTQ5zMpZdeyuHDh5k/f36h9td05CJSErKyPfx3zibe/3U7Ph/Ujgrmxctb06Gu7neRHOmHzF6ow9tz7rnKNj+EGUB2FqQfgCM7j01u4cr98JETkM5EaHWoUse8F8uVbn7gc6aa1zFsZvjKSi7cPV72ALNXzj8E/MPM56ExEF7T/Ot17oQcWSnmh8ywOPOv5uE1IL6zOVV8Qett+Xzm7Im5H0zzfU01r3G8wEjzQ3C1xuaHR6tlHDbfL7u/WZuff8ldy+czw643O+er27xuQJjZG+l2mu+DM+XY+xsSY/aoFjUAO9PMAOIXZC5W7Uoz3xdXmnl9R5AZGhxBZnDIOprzO3HUHPZ6dJdZl93f/L2pUs+8b7Bqo2O/F24XpO7LWZJgrxk+UhPMfwPuTPN4V5r5s87t9T3VMgWF4Rdo/o7isyZw+Of0codUM3+mmUfNNe1S9p1+XbvTMWxmz3a1RmaosfmZ71fu74VhM4cPh0SbP1f/EKjWJGcSnON6tA3D/H3L/blnJJnvq2GYP7/oc6BmO3NYclEXKPd6zGtavB5fuRmqN3bsWK699lo6dOhA165deffdd9m1axejR48GYNy4cezdu5cPP/wQgJdffpm6devSvHlzXC4XH3/8MdOnT2f69OlWfhsiIgQ67DwyqBl9msZy35fr2HU4g8vfWcboXg0Y07cR/n6aOKLSC6kKjfoX7djcYJW63xya558TZAy7+RfchHXHHkn/5Ex+kXj68+ay+5vnyv3rsMd1bAiOxwkZTvODU1EERpohKiDs2GQanmzzr/u54agoH4IdwdCwL8Q0+9eH92zz5+XOPPGrMy3nA2qCGSzcmebPMiDcrO+kj3Cz7rREs2abnzkZSOZRc/KRlD356wqKygl0BkTVg1odzffK5zU/KIfXNM+XddR8rw5vMz+8Zx01z20PMMOX12PWmp50LCid6kO1zWF+eP13yDx+e9VGZtj0DwYfZo0Boeb36BdoBpWUBLOOrORjPTpFfd9PJzDS/NlmZ+Rcowh/x/cPNf84EFIVgqvmfI0+9jW4qvmzO7rbDGNHdsKeFea/paM785/LL8jsZYqMN2fUzAuBR83f0dzfhex08/cgKMr8Wabth7SD5u8SQES8eW2v2wwmnpzQGBFvBpRG/SCu7cnDgteTM2lNes6/k+Me7iyzPTcAuTIguErOsgo59wrl/h6XZHgvTkUdkmihMrEA7nPPPUdCQgItWrTgpZdeyrtfaeTIkezYsYOFCxcC8Nxzz/Huu++yd+9egoKCaN68OePGjWPgwIGFvp56nESkpKVkZTNx5t/MWL0XgGZx4bx0RRsaV9d6QVIKnKlwcHPOkKHD+YNB7s3aNpv51+jcD68nu0/Kk53Ts5Ce08uQZg4xcqaaAS5lr/mBO6iK+QgIyxk6lGhuP7wNdi41P2gWlv9xgSUwp2b7cfcp+7zmh+wj20vuA31R2P1PHVqs4J/z8/MPMcNQQUPDCsMv0AwB+MyAERBq/l7ZHWaIyM4wvxq2Y8PbgqqYPUyRtc2eVXcWpCaaw1b3rT0WNHLZAyCiZs69PvFmz2VAqHk9R6AZjIOj8gekovQ4+nw59/gcNZ8HR5nX9NP98JVVuZhVzyoKTiJSWmb/mcD4r//kSEY2/n427j2/EaPOradpy6XycLvMHrHMw2bgsjmO3bPhF3Dsr/gBYeYH8cIO2fH5IGEtbJ5j/oU+O/NYT4DNYX7Qzv3A7RdofsD2CzSDRHgNCK9lfrj3CzQ/9B8/NDDvcVwbmMMfA0KP3QMWFGl+wK/ewgyhXu+x4Ohxmfsl/mn2AnrdZqhITTSHpOUOf8ydfTGsev7p7XNDWHhNM3zYHcd+djb7cc8dZiDJDZGB4WZoOv7n6POZIfrABnMSAG82YBzr8cu9tyd3eGVQVE6ojjDDT2S8+Tx3drTi6CXwZJsLW3vc5u9BaKwZhoo65EvkLCg4FUDBSURK04HULB786g8WbDoIQKtaETx3aSuaVNd/f0RERKx2JtlAf/YUESlBMWGBTB7ZkecuaUVYoB9/7Elm0Ku/8OK8zbjcXqvLExERkUJScBIRKWGGYXB5x3h+GtuLfs1icXt9vPrzFga9toS1u49aXZ6IiIgUgoKTiEgpiQ0P5J1r2/P61W2JDvFn8/40hr35KxNn/k1q1llMrSsiIiIlTsFJRKQUGYbBoFY1+GlsLy5uWxOvD6Yu3UGfFxbx3bp9VLLbTkVERMoNBScREQtUCfHnpSva8NGoTtSrGsKBVCd3fraGEZOXs/3QGUzfLCIiIqVCwUlExEI9zqnG7Lt7cE/OIrlLthyi/0uLeXHeZrKyz3IFeRERESk2Ck4iIhYLdNi5u+85zB3Tk56NquHyeHn15y30f3kxCzcdsLo8ERERQcFJRKTMqFs1hA+u78ibw9sRGx7AzqQMRk5ZwY0frNTwPREREYtpAVwRkTIozenmpXmbmbp0Bx6vD4fdYGS3utzZ5xzCAx1WlyciIlIhnEk2UHASESnD/jmQypPfb2DR5oMARIf4M7ZfI67sWBu7zbC4OhERkfJNwakACk4iUh4t2HSAp75fz9aD5pC9JtXDePCCJvRuXA3DUIASEREpCgWnAig4iUh5le3x8vFvO3lp3mZSstwAdKoXxYMXNKF9nSoWVyciIlL+KDgVQMFJRMq7I+ku3lq0lalLd+ByewE4v1ks9/dvTKPYMIurExERKT8UnAqg4CQiFcW+o5m88tMWvly1G68PbAYMa1eLMX3PoVaVYKvLExERKfMUnAqg4CQiFc0/B9L475xN/Ph3IgD+dhvDu9RmdK8GxIYHWlydiIhI2aXgVAAFJxGpqNbuPsqzszeybFsSYAaoyzvWYnSvBuqBEhEROQkFpwIoOIlIRebz+fj1nyRe/XkLy3ccBsDPZnBJu1rc2rsBdauGWFyhiIhI2aHgVAAFJxGpLH7blsRr87fw6z9mD5TNgCFtanL7eQ1pGBNqcXUiIiLWU3AqgIKTiFQ2q3Ye4bX5W1i4yVxE1zCgX7NYRp1bn451q2gdKBERqbQUnAqg4CQildWfe5J5bf4W5q7fn9fWomY4N3Svx6BWNfD3s1lYnYiISOlTcCqAgpOIVHZb9qcy+dcdzFi9B2fOOlDVwgK4tksdru5cm6qhARZXKCIiUjoUnAqg4CQiYjqS7uLT5bv4aNlOElOyAPD3szGkdQ2u716PZjX030gREanYFJwKoOAkIpJftsfL7L8Sef+X7azbfTSvvUv9KIZ3rkO/5rEE+NmtK1BERKSEKDgVQMFJROTUVu86wuRftjP7r0Q8XvN/D5HBDoa2qckVHeNpGqf/boqISMWh4FQABScRkdPbdzSTz5fv4stVe0hIzsprb1Urgss7xHNRmxqEBzosrFBEROTsKTgVQMFJRKTwPF4fS7Yc5IuVu5m3fj/ZHvN/GYEOGwNbxHF5x3g614vSlOYiIlIuKTgVQMFJRKRoktKcfL1mL9NW7GbLgbS89rrRwVzWIZ5L2tWiekSghRWKiIicGQWnAig4iYicHZ/Px5rdR/lixW6+W7ePdJcHMBfW7VwvisGtazCgRRxRIf4WVyoiIlIwBacCKDiJiBSfdKebH/5M4IsVu1m580heu91m0L1hVYa0rkG/5rGE6X4oEREpgxScCqDgJCJSMnYfzuCHPxP4/o99/LU3Ja89wM9G36axDG5dg96NqxHo0NTmIiJSNig4FUDBSUSk5G0/lM536/bxzdq9bDuYntceFujH+c1i6dcslh7nVCMkwM/CKkVEpLJTcCqAgpOISOnx+Xz8vS+Fmev2MXPtPhJTjk1t7u9no3uDaPo2i6Vv01hiwzWxhIiIlC4FpwIoOImIWMPr9bFix2Hmrt/PvPX72XU4I9/21rUi6Ns0lvObx9I4NkxTnIuISIlTcCqAgpOIiPV8Ph9bDqQxb/1+ftqwnzW7jubbXqtKEH2bmkP62tetQoCf7osSEZHip+BUAAUnEZGy50BqFvM3HGDe+v388s8hnG5v3rZAh40OdaLo2iCaLvWjaVUrAofdZmG1IiJSUSg4FUDBSUSkbMtwufllyyHmrd/Pgk0HOJTmyrc9xN9Ox3pRdK0fTbcGVWlWIxy7TcP6RETkzCk4FUDBSUSk/Mgd0rdsaxLLtibx2/YkjmZk59snPNCPTvWi6dYgmq4NomkcG4ZNQUpERApBwakACk4iIuWX1+tjQ2KKGaK2JfH7tsOkOt359okK8adLfbNHqmuDaBpUC9VEEyIiclIKTgVQcBIRqTjcHi9/70th6dYklm1LYuWOw2S4PPn2qRYWkBeiOteLol7VEAUpEREBFJwKpOAkIlJxudxe/thz1Bzaty2JVTuP5JtoAiAy2EHb+Eja1q5C29qRtI6PJDzQYVHFIiJiJQWnAig4iYhUHlnZHtbsOsqybUn8tjWJtXuO4vpXkDIMOCcmlLbxVWgdH0mrWhE0ig3D308z94mIVHQKTgVQcBIRqbxcbi8bElJYs+sIa3YfZfWuI+w+nHnCfv52G03jwmhZK4JWNSNpUTOCc2JDNQ26iEgFo+BUAAUnERE53sFUJ2t3H2XNriP8uTeZP/Ykk5yZfcJ+/nYbjauH0aJmOM1rRNCiZgRNqocR6NDivCIi5ZWCUwEUnEREpCA+n4/dhzP5Y+9R/tyTzLo9R/l7XwqpWe4T9rXbDBpWC6VJXBiNYsNoHBtG4+ph1IwM0pToIiLlgIJTARScRETkTOWGqb/2JfPX3mT+3pfCX3uTSUp3nXT/EH8758SG0aR6TqDK+VotLKCUKxcRkYIoOBVAwUlERIqDz+djf4qTv/cls2l/KpsTU9mYmMq2g+m4PN6THhMd4p8XpBrGhFI3OoQ60cHUiAzCrh4qEZFSp+BUAAUnEREpSdkeLzuT0tmYaIapTftT2bw/jR1J6Zzq/7gOu0F8VDB1o0OoHRVM3ehg6lQNoW50CLWqBGlSChGREnIm2cCvlGoSERGpFBx2Gw1jwmgYEwatjrVnujz8cyCNTftT2ZSYwraD6exISmf34UxcHi/bDqaz7WD6Ceez2wxqRgZRJzo4r4eqTnQIdaODiY8K1uQUIiKlRD1OIiIiFvJ4fSSmZLHzUDo7kjLYmWQGqp1JGexISicr++TD/sBcgyouPNAMUlWDqR0VQo3IQGpEBlEjMojYsAD81FslInJKGqpXAAUnEREpL3w+HwdTnezICVFmqDLD1c5DGaQ6T5zp73g2A2LCAonLDVMRgcRFBOWFq7iIIKJD/DUDoIhUWgpOBVBwEhGRisDn83E43cXOwzm9VIcy2HU4g31HM9mXnElichbZntP/L97fbqN6RKAZpiKCiIsMpHqE2VsVGx5IbHggVUP91XMlIhWS7nESERGp4AzDIDo0gOjQANrVrnLCdq/Xx6F0JwlHs3LCVBYJOaFq39EsEpIzOZDqxOXxsuuwGbpOfS1zRsBqYYHEhAWYj/AAqoYe//CnamgAEUEO9WCJSIWk4CQiIlIB2WwGMWGBxIQF0jo+8qT7ZHu8JCZnkZBsBql9OSFrf0oW+1OdHEjJ4kCqE4/Xx6E0F4fSXGxIKPi6fjaD6FB/okMCqBpmBqpqoQFE5wSr44NWZLA//n7qyRKR8kHBSUREpJJy2G3ER5mz852Kx2sOCTyQaoaogzmPAylZHEpzcTDNyaE0J0lpLpIzs3F7zfWt9qc44TQhC8zFgiOD/akS4qBKsBmmqgQ78r6abce+Rgb7Ex7oh2GoV0tESpeCk4iIiJyS3WZQLSyAamEBND/Nvi63l6R0J4dSXRxKd3Io1cmhNBdJOeHK7LUyvx5Od+L1QbrLQ7ork71HM8+opsggx3GBKidkhfgTEeQgPMhBeKAf4UEO83Wgg/AgP8IDHZq+XUSKTMFJREREioW/n424CHO2vtPxen2kZrk5kuHiSIaLoxnZOc+zOZrTlvc8Pbctm8xsDx6vj6R0F0npLuDEta8KEuBnO2WwOvbc/GqGML/j2vw0SYZIJabgJCIiIqXOZjOICHYQEeygLiGFPi4r23NcyDoWuI5mZHMk3UVKVjbJmdmkZLpJyco2X2dkk+p04/OB0+3NG25YFCH+9rxgFRboR2igH6EB5iMk9+FvJzjAj9AAO8H+5rZgf7v5NcCPUH8/ggPsOBTCRMoVBScREREpNwIddqpH2KkeEXhGx3m9PtJcbpIzzDCVG6zMkJVNSpbb/Jp5bHty3vNs0l0eIHdooYeE5Kyz/l787TZCjg9XAfa8kGUGsJw2f78TgliQv50gh50gfzuBfnYC/W3ma4ddvWIiJUTBSURERCo8m80wh9wFOop0fLbHS2puuMoJXGlZblKdbtKdbtKy3KS7PGS43KQ53WQ4PaS7zG3pxz93eXC5vQC4PF5cGV6OZGQX57eKn80gyGEnMCdcBTpsOV+PBa0g/5zXx23PbcttD/K35X/9r6Dmb7dpkg6pVBScRERERE7DYbcRFeJPVIj/WZ8r2+Mlw+khzeUmw5kTtFyenK85QSsnZKXntKU5Pfn2TXe5cWZ7ycz2kOnykOX24MtZ79jt9ZHqNENdSbIZ5AWy3FCWG8QC/xW0Tghq+V6fOqgFOuwE+Nm0NpiUCQpOIiIiIqXIYbcREWwjIrhovV8n4/P5cLq9ZGV7yMz2kJXtJdOV+9yT126GLC9ZOdvybXcdd+xxbVluD5muY+f2eM2EdmxWRE+xfR+n4rAbBPiZISrAz0ZATqDyz32du81hPnfYDfzsNhw2A4fdhuO4/Y4dk3u83TzObr522M2Hv5/Zq+bwM/LaAnK22xXkKiUFJxEREZFyzjCMvN6ayBK+VrYnJ1j9K2hluv4V0nLanO5jIe5UQS3ruG3meby4PN7jrukj2+MmrWhzehQ7m2EGYP+cUHZ8wPI/PnQdt93/uO3H2mw47Ab+djsOP+O4tmP7OWxmCPSzGzhsZmjLDYZ+OcEwb5vdOGF/P7uBn83QsMpioOAkIiIiIoWW2/tS1PvFCsvj9ZGZbd4T5nR7cGZ7cbq9x17/q93pzt3XfLg9PrI9XrK9XrLdvn9tz79v7nmyPV6yPT5cnpznbm/Oc1++2rw5MzQ63V4oI2HudOw2I1/Q8rPZcgKY+dwvJ3A5coLWsee524714h2/7fggd7qQ52c3sBnHjutSP4rI4LMf/lpaFJxEREREpMyx2wxCA/wgwOpKzKGQ2blBzHMsTLlyglxemzs3eHlwuX3HtZnbXblBzO3L15btyX8eV+52txe31zyn22uGQbfXh9uTvy3b481pN9u8vhO/B4/Xh8drDuksK2bc1o12tRWcREREREQqBMMw8Pcz8PcrH1O9e70+snODlue458d9zS7Ettznnrw2M6DlPs/2mtvM8Hb8sTlB7l8hLze85T7CAspXFClf1YqIiIiISIFsNoMAm51ylkvKvPIRm0VERERERCxkeXB68803qVevHoGBgbRv354lS5YUuP+iRYto3749gYGB1K9fn7fffruUKhURERERkcrK0uA0bdo0xowZw8MPP8yaNWvo0aMHAwYMYNeuXSfdf/v27QwcOJAePXqwZs0axo8fz1133cX06dNLuXIREREREalMDJ/Pd5J5N0pH586dadeuHW+99VZeW9OmTRk6dCiTJk06Yf8HH3yQmTNnsmHDhry20aNHs27dOpYtW1aoa6akpBAREUFycjLh4eFn/02IiIiIiEi5dCbZwLIeJ5fLxapVq+jXr1++9n79+rF06dKTHrNs2bIT9u/fvz8rV64kOzv7pMc4nU5SUlLyPURERERERM6EZcHp0KFDeDweYmNj87XHxsaSmJh40mMSExNPur/b7ebQoUMnPWbSpElERETkPeLj44vnGxARERERkUrD8skhDMPI99rn853Qdrr9T9aea9y4cSQnJ+c9du/efZYVi4iIiIhIZWPZ7O5Vq1bFbref0Lt04MCBE3qVclWvXv2k+/v5+REdHX3SYwICAggIKANLTouIiIiISLllWY+Tv78/7du3Z968efna582bR7du3U56TNeuXU/Yf+7cuXTo0AGHw1FitYqIiIiISOVm6VC9sWPH8t577zF58mQ2bNjAPffcw65duxg9ejRgDrMbMWJE3v6jR49m586djB07lg0bNjB58mTef/997rvvPqu+BRERERERqQQsG6oHcMUVV5CUlMQTTzxBQkICLVq0YNasWdSpUweAhISEfGs61atXj1mzZnHPPffwxhtvUKNGDV599VUuueQSq74FERERERGpBCxdx8kKWsdJRERERESgnKzjJCIiIiIiUl4oOImIiIiIiJyGgpOIiIiIiMhpKDiJiIiIiIichoKTiIiIiIjIaSg4iYiIiIiInIal6zhZIXf29ZSUFIsrERERERERK+VmgsKs0FTpglNqaioA8fHxFlciIiIiIiJlQWpqKhEREQXuU+kWwPV6vezbt4+wsDAMw7C6HFJSUoiPj2f37t1akNcieg+sp/egbND7YD29B9bTe1A26H2wXmV5D3w+H6mpqdSoUQObreC7mCpdj5PNZqNWrVpWl3GC8PDwCv1LWR7oPbCe3oOyQe+D9fQeWE/vQdmg98F6leE9OF1PUy5NDiEiIiIiInIaCk4iIiIiIiKnoeBksYCAACZMmEBAQIDVpVRaeg+sp/egbND7YD29B9bTe1A26H2wnt6DE1W6ySFERERERETOlHqcRERERERETkPBSURERERE5DQUnERERERERE5DwUlEREREROQ0FJws9Oabb1KvXj0CAwNp3749S5YssbqkCmvixIkYhpHvUb169bztPp+PiRMnUqNGDYKCgujduzd///23hRVXDIsXL2bw4MHUqFEDwzD45ptv8m0vzM/d6XRy5513UrVqVUJCQrjooovYs2dPKX4X5dvp3oORI0ee8G+jS5cu+fbRe3B2Jk2aRMeOHQkLCyMmJoahQ4eyadOmfPvo30LJKsx7oH8LJeutt96iVatWeYupdu3aldmzZ+dt17+B0nG690H/Dgqm4GSRadOmMWbMGB5++GHWrFlDjx49GDBgALt27bK6tAqrefPmJCQk5D3+/PPPvG3PPfccL774Iq+//jorVqygevXqnH/++aSmplpYcfmXnp5O69atef3110+6/f/buf+QuOs4juOvs52XXiKam3dOMmm5YS5hsx+3RpED0TBWW7XGiltBw5rSaMEqEhcN8q9Ff5RBrVE0EKQZQrJypcY2pGaa17IQZmu0ma1aOU1t+u6P2MFN3VnpfdM9H3Dwvc/nc/r+ft68wbff+36ns+/btm1TfX29amtrdejQIZ07d06lpaUaGxuL1WnMadFyIEnFxcURtdHY2BgxTw7+m9bWVm3dulVtbW1qamrS+fPnVVRUpMHBwfAaamF2TScHErUwmzIzM1VdXa2jR4/q6NGjKiws1Nq1a8PNETUQG9HyIFEHl2RwxM0332xlZWURY8uWLbNnnnnGoYjmt6qqKsvPz590bnx83Hw+n1VXV4fHhoeHLTk52V5//fUYRTj/SbL6+vrw++ns+9mzZ83tdlttbW14zQ8//GBxcXF24MCBmMU+X1ycAzOzYDBoa9eunfIz5GDm9ff3myRrbW01M2rBCRfnwIxacEJKSoq9+eab1IDDLuTBjDqIhitODhgdHVV7e7uKiooixouKinTkyBGHopr/enp6lJGRoezsbD344IM6fvy4JKm3t1d9fX0R+fB4PLrjjjvIxyyazr63t7frzz//jFiTkZGhvLw8cjODWlpatGjRIuXk5Oixxx5Tf39/eI4czLzffvtNkpSamiqJWnDCxTm4gFqIjbGxMdXW1mpwcFCBQIAacMjFebiAOpjaAqcDuBydOXNGY2NjSk9PjxhPT09XX1+fQ1HNb7fccoveeecd5eTk6Mcff9SuXbu0atUqHTt2LLznk+XjxIkTToR7WZjOvvf19Sk+Pl4pKSkT1lArM6OkpET333+/srKy1Nvbq8rKShUWFqq9vV0ej4cczDAz01NPPaXVq1crLy9PErUQa5PlQKIWYiEUCikQCGh4eFhXXXWV6uvrlZubG/6DmxqIjanyIFEH0dA4OcjlckW8N7MJY5gZJSUl4ePly5crEAjouuuu09tvvx2+6ZF8OOPf7Du5mTkbNmwIH+fl5amgoEBZWVn64IMPtG7duik/Rw7+nfLycnV1denQoUMT5qiF2JgqB9TC7Fu6dKk6Ozt19uxZvffeewoGg2ptbQ3PUwOxMVUecnNzqYMo+KqeA9LS0nTFFVdM6Mz7+/sn/LcFs8Pr9Wr58uXq6ekJP12PfMTWdPbd5/NpdHRUv/7665RrMLP8fr+ysrLU09MjiRzMpIqKCjU0NKi5uVmZmZnhcWohdqbKwWSohZkXHx+vJUuWqKCgQC+99JLy8/P1yiuvUAMxNlUeJkMdRKJxckB8fLxWrlyppqamiPGmpiatWrXKoaguLyMjI+ru7pbf71d2drZ8Pl9EPkZHR9Xa2ko+ZtF09n3lypVyu90Ra06fPq2vvvqK3MySn3/+WSdPnpTf75dEDmaCmam8vFz79+/XJ598ouzs7Ih5amH2RcvBZKiF2WdmGhkZoQYcdiEPk6EOLhLzx1HAzMxqa2vN7Xbbnj177Ouvv7Zt27aZ1+u17777zunQ5qXt27dbS0uLHT9+3Nra2qy0tNSSkpLC+11dXW3Jycm2f/9+C4VCtnHjRvP7/fb77787HPncNjAwYB0dHdbR0WGSbPfu3dbR0WEnTpwws+nte1lZmWVmZtrBgwftiy++sMLCQsvPz7fz5887dVpzyqVyMDAwYNu3b7cjR45Yb2+vNTc3WyAQsMWLF5ODGfT4449bcnKytbS02OnTp8OvoaGh8BpqYXZFywG1MPueffZZ+/TTT623t9e6urrsueees7i4OPvoo4/MjBqIlUvlgTqIjsbJQa+++qplZWVZfHy8rVixIuKxqJhZGzZsML/fb2632zIyMmzdunV27Nix8Pz4+LhVVVWZz+czj8djt99+u4VCIQcjnh+am5tN0oRXMBg0s+nt+x9//GHl5eWWmppqCQkJVlpaat9//70DZzM3XSoHQ0NDVlRUZAsXLjS3223XXHONBYPBCftLDv6byfZfku3duze8hlqYXdFyQC3MvkcffTT8N8/ChQttzZo14abJjBqIlUvlgTqIzmVmFrvrWwAAAAAw93CPEwAAAABEQeMEAAAAAFHQOAEAAABAFDROAAAAABAFjRMAAAAAREHjBAAAAABR0DgBAAAAQBQ0TgAAAAAQBY0TAAD/gMvl0vvvv+90GACAGKNxAgDMGZs3b5bL5ZrwKi4udjo0AMA8t8DpAAAA+CeKi4u1d+/eiDGPx+NQNACAywVXnAAAc4rH45HP54t4paSkSPr7a3Q1NTUqKSlRQkKCsrOzVVdXF/H5UCikwsJCJSQk6Oqrr9aWLVt07ty5iDVvvfWWbrjhBnk8Hvn9fpWXl0fMnzlzRvfee68SExN1/fXXq6GhYXZPGgDgOBonAMC8UllZqfXr1+vLL7/UQw89pI0bN6q7u1uSNDQ0pOLiYqWkpOjzzz9XXV2dDh48GNEY1dTUaOvWrdqyZYtCoZAaGhq0ZMmSiN/xwgsv6IEHHlBXV5fuuusubdq0Sb/88ktMzxMAEFsuMzOngwAAYDo2b96sd999V1deeWXE+I4dO1RZWSmXy6WysjLV1NSE52699VatWLFCr732mt544w3t2LFDJ0+elNfrlSQ1Njbq7rvv1qlTp5Senq7FixfrkUce0a5duyaNweVy6fnnn9eLL74oSRocHFRSUpIaGxu51woA5jHucQIAzCl33nlnRGMkSampqeHjQCAQMRcIBNTZ2SlJ6u7uVn5+frhpkqTbbrtN4+Pj+vbbb+VyuXTq1CmtWbPmkjHceOON4WOv16ukpCT19/f/21MCAMwBNE4AgDnF6/VO+OpcNC6XS5JkZuHjydYkJCRM6+e53e4Jnx0fH/9HMQEA5hbucQIAzCttbW0T3i9btkySlJubq87OTg0ODobnDx8+rLi4OOXk5CgpKUnXXnutPv7445jGDAD4/+OKEwBgThkZGVFfX1/E2IIFC5SWliZJqqurU0FBgVavXq19+/bps88+0549eyRJmzZtUlVVlYLBoHbu3KmffvpJFRUVevjhh5Weni5J2rlzp8rKyrRo0SKVlJRoYGBAhw8fVkVFRWxPFADwv0LjBACYUw4cOCC/3x8xtnTpUn3zzTeS/n7iXW1trZ544gn5fD7t27dPubm5kqTExER9+OGHevLJJ3XTTTcpMTFR69ev1+7du8M/KxgManh4WC+//LKefvpppaWl6b777ovdCQIA/pd4qh4AYN5wuVyqr6/XPffc43QoAIB5hnucAAAAACAKGicAAAAAiIJ7nAAA8wbfPgcAzBauOAEAAABAFDROAAAAABAFjRMAAAAAREHjBAAAAABR0DgBAAAAQBQ0TgAAAAAQBY0TAAAAAERB4wQAAAAAUfwF43kHu42vGD8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:55:01.391909Z",
     "iopub.status.busy": "2025-05-08T18:55:01.391909Z",
     "iopub.status.idle": "2025-05-08T18:55:01.536141Z",
     "shell.execute_reply": "2025-05-08T18:55:01.536141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.5375 | Test Accuracy: 85.89%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:55:01.539145Z",
     "iopub.status.busy": "2025-05-08T18:55:01.539145Z",
     "iopub.status.idle": "2025-05-08T18:55:01.547890Z",
     "shell.execute_reply": "2025-05-08T18:55:01.547890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:55:01.550403Z",
     "iopub.status.busy": "2025-05-08T18:55:01.550403Z",
     "iopub.status.idle": "2025-05-08T18:55:01.559926Z",
     "shell.execute_reply": "2025-05-08T18:55:01.559926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:55:01.562931Z",
     "iopub.status.busy": "2025-05-08T18:55:01.562931Z",
     "iopub.status.idle": "2025-05-08T18:55:01.567040Z",
     "shell.execute_reply": "2025-05-08T18:55:01.567040Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:55:01.569256Z",
     "iopub.status.busy": "2025-05-08T18:55:01.569256Z",
     "iopub.status.idle": "2025-05-08T18:55:01.576040Z",
     "shell.execute_reply": "2025-05-08T18:55:01.576040Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:55:01.579045Z",
     "iopub.status.busy": "2025-05-08T18:55:01.578046Z",
     "iopub.status.idle": "2025-05-08T19:03:20.804548Z",
     "shell.execute_reply": "2025-05-08T19:03:20.804548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4805\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4714\n",
      "    Batch [2/2], Val Loss: 0.2470\n",
      "Epoch [1/2000], Avg Train Loss: 0.4805, Avg Val Loss: 0.3592\n",
      "\n",
      "Validation loss improved from inf to 0.3592. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4822\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4711\n",
      "    Batch [2/2], Val Loss: 0.2488\n",
      "Epoch [2/2000], Avg Train Loss: 0.4822, Avg Val Loss: 0.3599\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4819\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4710\n",
      "    Batch [2/2], Val Loss: 0.2507\n",
      "Epoch [3/2000], Avg Train Loss: 0.4819, Avg Val Loss: 0.3608\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4807\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4712\n",
      "    Batch [2/2], Val Loss: 0.2527\n",
      "Epoch [4/2000], Avg Train Loss: 0.4807, Avg Val Loss: 0.3620\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4845\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4710\n",
      "    Batch [2/2], Val Loss: 0.2542\n",
      "Epoch [5/2000], Avg Train Loss: 0.4845, Avg Val Loss: 0.3626\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [6/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4788\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4709\n",
      "    Batch [2/2], Val Loss: 0.2560\n",
      "Epoch [6/2000], Avg Train Loss: 0.4788, Avg Val Loss: 0.3635\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4793\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4705\n",
      "    Batch [2/2], Val Loss: 0.2578\n",
      "Epoch [7/2000], Avg Train Loss: 0.4793, Avg Val Loss: 0.3642\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [8/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4759\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4700\n",
      "    Batch [2/2], Val Loss: 0.2593\n",
      "Epoch [8/2000], Avg Train Loss: 0.4759, Avg Val Loss: 0.3647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4776\n",
      "LOG: Epoch [9/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4696\n",
      "    Batch [2/2], Val Loss: 0.2612\n",
      "Epoch [9/2000], Avg Train Loss: 0.4776, Avg Val Loss: 0.3654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4747\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4688\n",
      "    Batch [2/2], Val Loss: 0.2615\n",
      "Epoch [10/2000], Avg Train Loss: 0.4747, Avg Val Loss: 0.3651\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4734\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4675\n",
      "    Batch [2/2], Val Loss: 0.2605\n",
      "Epoch [11/2000], Avg Train Loss: 0.4734, Avg Val Loss: 0.3640\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4740\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4664\n",
      "    Batch [2/2], Val Loss: 0.2608\n",
      "Epoch [12/2000], Avg Train Loss: 0.4740, Avg Val Loss: 0.3636\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [13/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4719\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4655\n",
      "    Batch [2/2], Val Loss: 0.2611\n",
      "Epoch [13/2000], Avg Train Loss: 0.4719, Avg Val Loss: 0.3633\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4766\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4648\n",
      "    Batch [2/2], Val Loss: 0.2609\n",
      "Epoch [14/2000], Avg Train Loss: 0.4766, Avg Val Loss: 0.3628\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4718\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4636\n",
      "    Batch [2/2], Val Loss: 0.2586\n",
      "Epoch [15/2000], Avg Train Loss: 0.4718, Avg Val Loss: 0.3611\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4716\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4629\n",
      "    Batch [2/2], Val Loss: 0.2557\n",
      "Epoch [16/2000], Avg Train Loss: 0.4716, Avg Val Loss: 0.3593\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4715\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4615\n",
      "    Batch [2/2], Val Loss: 0.2528\n",
      "Epoch [17/2000], Avg Train Loss: 0.4715, Avg Val Loss: 0.3571\n",
      "\n",
      "Validation loss improved from 0.3592 to 0.3571. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4683\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4597\n",
      "    Batch [2/2], Val Loss: 0.2506\n",
      "Epoch [18/2000], Avg Train Loss: 0.4683, Avg Val Loss: 0.3552\n",
      "\n",
      "Validation loss improved from 0.3571 to 0.3552. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4668\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4577\n",
      "    Batch [2/2], Val Loss: 0.2477\n",
      "Epoch [19/2000], Avg Train Loss: 0.4668, Avg Val Loss: 0.3527\n",
      "\n",
      "Validation loss improved from 0.3552 to 0.3527. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4661\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4564\n",
      "    Batch [2/2], Val Loss: 0.2429\n",
      "Epoch [20/2000], Avg Train Loss: 0.4661, Avg Val Loss: 0.3497\n",
      "\n",
      "Validation loss improved from 0.3527 to 0.3497. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4668\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4555\n",
      "    Batch [2/2], Val Loss: 0.2378\n",
      "Epoch [21/2000], Avg Train Loss: 0.4668, Avg Val Loss: 0.3467\n",
      "\n",
      "Validation loss improved from 0.3497 to 0.3467. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4687\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4549\n",
      "    Batch [2/2], Val Loss: 0.2334\n",
      "Epoch [22/2000], Avg Train Loss: 0.4687, Avg Val Loss: 0.3441\n",
      "\n",
      "Validation loss improved from 0.3467 to 0.3441. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4686\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4535\n",
      "    Batch [2/2], Val Loss: 0.2291\n",
      "Epoch [23/2000], Avg Train Loss: 0.4686, Avg Val Loss: 0.3413\n",
      "\n",
      "Validation loss improved from 0.3441 to 0.3413. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4675\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4522\n",
      "    Batch [2/2], Val Loss: 0.2244\n",
      "Epoch [24/2000], Avg Train Loss: 0.4675, Avg Val Loss: 0.3383\n",
      "\n",
      "Validation loss improved from 0.3413 to 0.3383. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4675\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4512\n",
      "    Batch [2/2], Val Loss: 0.2191\n",
      "Epoch [25/2000], Avg Train Loss: 0.4675, Avg Val Loss: 0.3352\n",
      "\n",
      "Validation loss improved from 0.3383 to 0.3352. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4662\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4502\n",
      "    Batch [2/2], Val Loss: 0.2128\n",
      "Epoch [26/2000], Avg Train Loss: 0.4662, Avg Val Loss: 0.3315\n",
      "\n",
      "Validation loss improved from 0.3352 to 0.3315. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4599\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4493\n",
      "    Batch [2/2], Val Loss: 0.2056\n",
      "Epoch [27/2000], Avg Train Loss: 0.4599, Avg Val Loss: 0.3275\n",
      "\n",
      "Validation loss improved from 0.3315 to 0.3275. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4604\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4480\n",
      "    Batch [2/2], Val Loss: 0.1995\n",
      "Epoch [28/2000], Avg Train Loss: 0.4604, Avg Val Loss: 0.3237\n",
      "\n",
      "Validation loss improved from 0.3275 to 0.3237. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4639\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4466\n",
      "    Batch [2/2], Val Loss: 0.1932\n",
      "Epoch [29/2000], Avg Train Loss: 0.4639, Avg Val Loss: 0.3199\n",
      "\n",
      "Validation loss improved from 0.3237 to 0.3199. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4604\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4455\n",
      "    Batch [2/2], Val Loss: 0.1863\n",
      "Epoch [30/2000], Avg Train Loss: 0.4604, Avg Val Loss: 0.3159\n",
      "\n",
      "Validation loss improved from 0.3199 to 0.3159. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4587\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4448\n",
      "    Batch [2/2], Val Loss: 0.1799\n",
      "Epoch [31/2000], Avg Train Loss: 0.4587, Avg Val Loss: 0.3124\n",
      "\n",
      "Validation loss improved from 0.3159 to 0.3124. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4612\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4441\n",
      "    Batch [2/2], Val Loss: 0.1744\n",
      "Epoch [32/2000], Avg Train Loss: 0.4612, Avg Val Loss: 0.3093\n",
      "\n",
      "Validation loss improved from 0.3124 to 0.3093. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4604\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4432\n",
      "    Batch [2/2], Val Loss: 0.1701\n",
      "Epoch [33/2000], Avg Train Loss: 0.4604, Avg Val Loss: 0.3066\n",
      "\n",
      "Validation loss improved from 0.3093 to 0.3066. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4592\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4421\n",
      "    Batch [2/2], Val Loss: 0.1667\n",
      "Epoch [34/2000], Avg Train Loss: 0.4592, Avg Val Loss: 0.3044\n",
      "\n",
      "Validation loss improved from 0.3066 to 0.3044. Saving model...\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4594\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4407\n",
      "    Batch [2/2], Val Loss: 0.1640\n",
      "Epoch [35/2000], Avg Train Loss: 0.4594, Avg Val Loss: 0.3024\n",
      "\n",
      "Validation loss improved from 0.3044 to 0.3024. Saving model...\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4570\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4396\n",
      "    Batch [2/2], Val Loss: 0.1624\n",
      "Epoch [36/2000], Avg Train Loss: 0.4570, Avg Val Loss: 0.3010\n",
      "\n",
      "Validation loss improved from 0.3024 to 0.3010. Saving model...\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4546\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4385\n",
      "    Batch [2/2], Val Loss: 0.1614\n",
      "Epoch [37/2000], Avg Train Loss: 0.4546, Avg Val Loss: 0.2999\n",
      "\n",
      "Validation loss improved from 0.3010 to 0.2999. Saving model...\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4557\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4376\n",
      "    Batch [2/2], Val Loss: 0.1607\n",
      "Epoch [38/2000], Avg Train Loss: 0.4557, Avg Val Loss: 0.2991\n",
      "\n",
      "Validation loss improved from 0.2999 to 0.2991. Saving model...\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4591\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4368\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [39/2000], Avg Train Loss: 0.4591, Avg Val Loss: 0.2986\n",
      "\n",
      "Validation loss improved from 0.2991 to 0.2986. Saving model...\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4577\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4360\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [40/2000], Avg Train Loss: 0.4577, Avg Val Loss: 0.2983\n",
      "\n",
      "Validation loss improved from 0.2986 to 0.2983. Saving model...\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4547\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4352\n",
      "    Batch [2/2], Val Loss: 0.1608\n",
      "Epoch [41/2000], Avg Train Loss: 0.4547, Avg Val Loss: 0.2980\n",
      "\n",
      "Validation loss improved from 0.2983 to 0.2980. Saving model...\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4520\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4344\n",
      "    Batch [2/2], Val Loss: 0.1614\n",
      "Epoch [42/2000], Avg Train Loss: 0.4520, Avg Val Loss: 0.2979\n",
      "\n",
      "Validation loss improved from 0.2980 to 0.2979. Saving model...\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4537\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4335\n",
      "    Batch [2/2], Val Loss: 0.1620\n",
      "Epoch [43/2000], Avg Train Loss: 0.4537, Avg Val Loss: 0.2977\n",
      "\n",
      "Validation loss improved from 0.2979 to 0.2977. Saving model...\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4510\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4325\n",
      "    Batch [2/2], Val Loss: 0.1630\n",
      "Epoch [44/2000], Avg Train Loss: 0.4510, Avg Val Loss: 0.2977\n",
      "\n",
      "Validation loss improved from 0.2977 to 0.2977. Saving model...\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4533\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4315\n",
      "    Batch [2/2], Val Loss: 0.1641\n",
      "Epoch [45/2000], Avg Train Loss: 0.4533, Avg Val Loss: 0.2978\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4522\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4305\n",
      "    Batch [2/2], Val Loss: 0.1653\n",
      "Epoch [46/2000], Avg Train Loss: 0.4522, Avg Val Loss: 0.2979\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4520\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4296\n",
      "    Batch [2/2], Val Loss: 0.1664\n",
      "Epoch [47/2000], Avg Train Loss: 0.4520, Avg Val Loss: 0.2980\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [48/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4523\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4287\n",
      "    Batch [2/2], Val Loss: 0.1676\n",
      "Epoch [48/2000], Avg Train Loss: 0.4523, Avg Val Loss: 0.2982\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4538\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4277\n",
      "    Batch [2/2], Val Loss: 0.1687\n",
      "Epoch [49/2000], Avg Train Loss: 0.4538, Avg Val Loss: 0.2982\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4510\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4266\n",
      "    Batch [2/2], Val Loss: 0.1698\n",
      "Epoch [50/2000], Avg Train Loss: 0.4510, Avg Val Loss: 0.2982\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4491\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1711\n",
      "Epoch [51/2000], Avg Train Loss: 0.4491, Avg Val Loss: 0.2984\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4478\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4246\n",
      "    Batch [2/2], Val Loss: 0.1721\n",
      "Epoch [52/2000], Avg Train Loss: 0.4478, Avg Val Loss: 0.2984\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [53/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4490\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4236\n",
      "    Batch [2/2], Val Loss: 0.1734\n",
      "Epoch [53/2000], Avg Train Loss: 0.4490, Avg Val Loss: 0.2985\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4455\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4227\n",
      "    Batch [2/2], Val Loss: 0.1746\n",
      "Epoch [54/2000], Avg Train Loss: 0.4455, Avg Val Loss: 0.2986\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4528\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4217\n",
      "    Batch [2/2], Val Loss: 0.1759\n",
      "Epoch [55/2000], Avg Train Loss: 0.4528, Avg Val Loss: 0.2988\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4420\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4209\n",
      "    Batch [2/2], Val Loss: 0.1770\n",
      "Epoch [56/2000], Avg Train Loss: 0.4420, Avg Val Loss: 0.2990\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4467\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4204\n",
      "    Batch [2/2], Val Loss: 0.1781\n",
      "Epoch [57/2000], Avg Train Loss: 0.4467, Avg Val Loss: 0.2992\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4442\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4197\n",
      "    Batch [2/2], Val Loss: 0.1790\n",
      "Epoch [58/2000], Avg Train Loss: 0.4442, Avg Val Loss: 0.2993\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4461\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1799\n",
      "Epoch [59/2000], Avg Train Loss: 0.4461, Avg Val Loss: 0.2995\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4444\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4184\n",
      "    Batch [2/2], Val Loss: 0.1809\n",
      "Epoch [60/2000], Avg Train Loss: 0.4444, Avg Val Loss: 0.2996\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [61/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4420\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4177\n",
      "    Batch [2/2], Val Loss: 0.1817\n",
      "Epoch [61/2000], Avg Train Loss: 0.4420, Avg Val Loss: 0.2997\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4410\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1824\n",
      "Epoch [62/2000], Avg Train Loss: 0.4410, Avg Val Loss: 0.2997\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4426\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4163\n",
      "    Batch [2/2], Val Loss: 0.1832\n",
      "Epoch [63/2000], Avg Train Loss: 0.4426, Avg Val Loss: 0.2997\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4385\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4157\n",
      "    Batch [2/2], Val Loss: 0.1840\n",
      "Epoch [64/2000], Avg Train Loss: 0.4385, Avg Val Loss: 0.2998\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4427\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4150\n",
      "    Batch [2/2], Val Loss: 0.1847\n",
      "Epoch [65/2000], Avg Train Loss: 0.4427, Avg Val Loss: 0.2999\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4409\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4142\n",
      "    Batch [2/2], Val Loss: 0.1855\n",
      "Epoch [66/2000], Avg Train Loss: 0.4409, Avg Val Loss: 0.2999\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [67/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4383\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4134\n",
      "    Batch [2/2], Val Loss: 0.1862\n",
      "Epoch [67/2000], Avg Train Loss: 0.4383, Avg Val Loss: 0.2998\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4406\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4128\n",
      "    Batch [2/2], Val Loss: 0.1868\n",
      "Epoch [68/2000], Avg Train Loss: 0.4406, Avg Val Loss: 0.2998\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4364\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4121\n",
      "    Batch [2/2], Val Loss: 0.1875\n",
      "Epoch [69/2000], Avg Train Loss: 0.4364, Avg Val Loss: 0.2998\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4377\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4114\n",
      "    Batch [2/2], Val Loss: 0.1867\n",
      "Epoch [70/2000], Avg Train Loss: 0.4377, Avg Val Loss: 0.2990\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4390\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1860\n",
      "Epoch [71/2000], Avg Train Loss: 0.4390, Avg Val Loss: 0.2983\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4384\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4100\n",
      "    Batch [2/2], Val Loss: 0.1853\n",
      "Epoch [72/2000], Avg Train Loss: 0.4384, Avg Val Loss: 0.2976\n",
      "\n",
      "Validation loss improved from 0.2977 to 0.2976. Saving model...\n",
      "LOG: Epoch [73/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4347\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [73/2000], Avg Train Loss: 0.4347, Avg Val Loss: 0.2972\n",
      "\n",
      "Validation loss improved from 0.2976 to 0.2972. Saving model...\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4363\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1847\n",
      "Epoch [74/2000], Avg Train Loss: 0.4363, Avg Val Loss: 0.2968\n",
      "\n",
      "Validation loss improved from 0.2972 to 0.2968. Saving model...\n",
      "LOG: Epoch [75/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4390\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4085\n",
      "    Batch [2/2], Val Loss: 0.1845\n",
      "Epoch [75/2000], Avg Train Loss: 0.4390, Avg Val Loss: 0.2965\n",
      "\n",
      "Validation loss improved from 0.2968 to 0.2965. Saving model...\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4387\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4080\n",
      "    Batch [2/2], Val Loss: 0.1843\n",
      "Epoch [76/2000], Avg Train Loss: 0.4387, Avg Val Loss: 0.2962\n",
      "\n",
      "Validation loss improved from 0.2965 to 0.2962. Saving model...\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4381\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4076\n",
      "    Batch [2/2], Val Loss: 0.1841\n",
      "Epoch [77/2000], Avg Train Loss: 0.4381, Avg Val Loss: 0.2959\n",
      "\n",
      "Validation loss improved from 0.2962 to 0.2959. Saving model...\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4386\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4074\n",
      "    Batch [2/2], Val Loss: 0.1841\n",
      "Epoch [78/2000], Avg Train Loss: 0.4386, Avg Val Loss: 0.2957\n",
      "\n",
      "Validation loss improved from 0.2959 to 0.2957. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4411\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1840\n",
      "Epoch [79/2000], Avg Train Loss: 0.4411, Avg Val Loss: 0.2955\n",
      "\n",
      "Validation loss improved from 0.2957 to 0.2955. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4395\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4067\n",
      "    Batch [2/2], Val Loss: 0.1841\n",
      "Epoch [80/2000], Avg Train Loss: 0.4395, Avg Val Loss: 0.2954\n",
      "\n",
      "Validation loss improved from 0.2955 to 0.2954. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4368\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4065\n",
      "    Batch [2/2], Val Loss: 0.1842\n",
      "Epoch [81/2000], Avg Train Loss: 0.4368, Avg Val Loss: 0.2953\n",
      "\n",
      "Validation loss improved from 0.2954 to 0.2953. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4365\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1844\n",
      "Epoch [82/2000], Avg Train Loss: 0.4365, Avg Val Loss: 0.2953\n",
      "\n",
      "Validation loss improved from 0.2953 to 0.2953. Saving model...\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4368\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1846\n",
      "Epoch [83/2000], Avg Train Loss: 0.4368, Avg Val Loss: 0.2953\n",
      "\n",
      "Validation loss improved from 0.2953 to 0.2953. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4389\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1848\n",
      "Epoch [84/2000], Avg Train Loss: 0.4389, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [85/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4397\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [85/2000], Avg Train Loss: 0.4397, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4406\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1851\n",
      "Epoch [86/2000], Avg Train Loss: 0.4406, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [87/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4352\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [87/2000], Avg Train Loss: 0.4352, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4339\n",
      "LOG: Epoch [88/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1854\n",
      "Epoch [88/2000], Avg Train Loss: 0.4339, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [89/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4346\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1855\n",
      "Epoch [89/2000], Avg Train Loss: 0.4346, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4329\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1856\n",
      "Epoch [90/2000], Avg Train Loss: 0.4329, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4385\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1856\n",
      "Epoch [91/2000], Avg Train Loss: 0.4385, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [92/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4327\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1857\n",
      "Epoch [92/2000], Avg Train Loss: 0.4327, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4361\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1857\n",
      "Epoch [93/2000], Avg Train Loss: 0.4361, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4366\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [94/2000], Avg Train Loss: 0.4366, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [95/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [95/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2954\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4370\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [96/2000], Avg Train Loss: 0.4370, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [97/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4327\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [97/2000], Avg Train Loss: 0.4327, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [98/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [99/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4398\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [99/2000], Avg Train Loss: 0.4398, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4415\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4047\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [100/2000], Avg Train Loss: 0.4415, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4346\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4047\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [101/2000], Avg Train Loss: 0.4346, Avg Val Loss: 0.2953\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4046\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [102/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2953\n",
      "\n",
      "Validation loss improved from 0.2953 to 0.2953. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4357\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4046\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [103/2000], Avg Train Loss: 0.4357, Avg Val Loss: 0.2952\n",
      "\n",
      "Validation loss improved from 0.2953 to 0.2952. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4045\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [104/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2952\n",
      "\n",
      "Validation loss improved from 0.2952 to 0.2952. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4356\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4045\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [105/2000], Avg Train Loss: 0.4356, Avg Val Loss: 0.2952\n",
      "\n",
      "Validation loss improved from 0.2952 to 0.2952. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4361\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4045\n",
      "    Batch [2/2], Val Loss: 0.1858\n",
      "Epoch [106/2000], Avg Train Loss: 0.4361, Avg Val Loss: 0.2951\n",
      "\n",
      "Validation loss improved from 0.2952 to 0.2951. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4390\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4044\n",
      "    Batch [2/2], Val Loss: 0.1857\n",
      "Epoch [107/2000], Avg Train Loss: 0.4390, Avg Val Loss: 0.2951\n",
      "\n",
      "Validation loss improved from 0.2951 to 0.2951. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4355\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4044\n",
      "    Batch [2/2], Val Loss: 0.1856\n",
      "Epoch [108/2000], Avg Train Loss: 0.4355, Avg Val Loss: 0.2950\n",
      "\n",
      "Validation loss improved from 0.2951 to 0.2950. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4360\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4043\n",
      "    Batch [2/2], Val Loss: 0.1856\n",
      "Epoch [109/2000], Avg Train Loss: 0.4360, Avg Val Loss: 0.2949\n",
      "\n",
      "Validation loss improved from 0.2950 to 0.2949. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4384\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4043\n",
      "    Batch [2/2], Val Loss: 0.1855\n",
      "Epoch [110/2000], Avg Train Loss: 0.4384, Avg Val Loss: 0.2949\n",
      "\n",
      "Validation loss improved from 0.2949 to 0.2949. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4387\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4042\n",
      "    Batch [2/2], Val Loss: 0.1855\n",
      "Epoch [111/2000], Avg Train Loss: 0.4387, Avg Val Loss: 0.2948\n",
      "\n",
      "Validation loss improved from 0.2949 to 0.2948. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4041\n",
      "    Batch [2/2], Val Loss: 0.1854\n",
      "Epoch [112/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.2948\n",
      "\n",
      "Validation loss improved from 0.2948 to 0.2948. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4362\n",
      "LOG: Epoch [113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4041\n",
      "    Batch [2/2], Val Loss: 0.1853\n",
      "Epoch [113/2000], Avg Train Loss: 0.4362, Avg Val Loss: 0.2947\n",
      "\n",
      "Validation loss improved from 0.2948 to 0.2947. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4371\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4040\n",
      "    Batch [2/2], Val Loss: 0.1853\n",
      "Epoch [114/2000], Avg Train Loss: 0.4371, Avg Val Loss: 0.2946\n",
      "\n",
      "Validation loss improved from 0.2947 to 0.2946. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4375\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4039\n",
      "    Batch [2/2], Val Loss: 0.1853\n",
      "Epoch [115/2000], Avg Train Loss: 0.4375, Avg Val Loss: 0.2946\n",
      "\n",
      "Validation loss improved from 0.2946 to 0.2946. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4382\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4038\n",
      "    Batch [2/2], Val Loss: 0.1853\n",
      "Epoch [116/2000], Avg Train Loss: 0.4382, Avg Val Loss: 0.2945\n",
      "\n",
      "Validation loss improved from 0.2946 to 0.2945. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4326\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4037\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [117/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.2945\n",
      "\n",
      "Validation loss improved from 0.2945 to 0.2945. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4400\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4036\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [118/2000], Avg Train Loss: 0.4400, Avg Val Loss: 0.2944\n",
      "\n",
      "Validation loss improved from 0.2945 to 0.2944. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4371\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4035\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [119/2000], Avg Train Loss: 0.4371, Avg Val Loss: 0.2944\n",
      "\n",
      "Validation loss improved from 0.2944 to 0.2944. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4035\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [120/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2943\n",
      "\n",
      "Validation loss improved from 0.2944 to 0.2943. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4368\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4034\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [121/2000], Avg Train Loss: 0.4368, Avg Val Loss: 0.2943\n",
      "\n",
      "Validation loss improved from 0.2943 to 0.2943. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4341\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4034\n",
      "    Batch [2/2], Val Loss: 0.1852\n",
      "Epoch [122/2000], Avg Train Loss: 0.4341, Avg Val Loss: 0.2943\n",
      "\n",
      "Validation loss improved from 0.2943 to 0.2943. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4365\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4033\n",
      "    Batch [2/2], Val Loss: 0.1851\n",
      "Epoch [123/2000], Avg Train Loss: 0.4365, Avg Val Loss: 0.2942\n",
      "\n",
      "Validation loss improved from 0.2943 to 0.2942. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4373\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4032\n",
      "    Batch [2/2], Val Loss: 0.1851\n",
      "Epoch [124/2000], Avg Train Loss: 0.4373, Avg Val Loss: 0.2942\n",
      "\n",
      "Validation loss improved from 0.2942 to 0.2942. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4333\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4032\n",
      "    Batch [2/2], Val Loss: 0.1851\n",
      "Epoch [125/2000], Avg Train Loss: 0.4333, Avg Val Loss: 0.2941\n",
      "\n",
      "Validation loss improved from 0.2942 to 0.2941. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4341\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4031\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [126/2000], Avg Train Loss: 0.4341, Avg Val Loss: 0.2941\n",
      "\n",
      "Validation loss improved from 0.2941 to 0.2941. Saving model...\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4398\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4031\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [127/2000], Avg Train Loss: 0.4398, Avg Val Loss: 0.2940\n",
      "\n",
      "Validation loss improved from 0.2941 to 0.2940. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4030\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [128/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2940\n",
      "\n",
      "Validation loss improved from 0.2940 to 0.2940. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4371\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4030\n",
      "    Batch [2/2], Val Loss: 0.1850\n",
      "Epoch [129/2000], Avg Train Loss: 0.4371, Avg Val Loss: 0.2940\n",
      "\n",
      "Validation loss improved from 0.2940 to 0.2940. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4362\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4030\n",
      "    Batch [2/2], Val Loss: 0.1849\n",
      "Epoch [130/2000], Avg Train Loss: 0.4362, Avg Val Loss: 0.2940\n",
      "\n",
      "Validation loss improved from 0.2940 to 0.2940. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4379\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4029\n",
      "    Batch [2/2], Val Loss: 0.1849\n",
      "Epoch [131/2000], Avg Train Loss: 0.4379, Avg Val Loss: 0.2939\n",
      "\n",
      "Validation loss improved from 0.2940 to 0.2939. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4355\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4029\n",
      "    Batch [2/2], Val Loss: 0.1849\n",
      "Epoch [132/2000], Avg Train Loss: 0.4355, Avg Val Loss: 0.2939\n",
      "\n",
      "Validation loss improved from 0.2939 to 0.2939. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4364\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4028\n",
      "    Batch [2/2], Val Loss: 0.1848\n",
      "Epoch [133/2000], Avg Train Loss: 0.4364, Avg Val Loss: 0.2938\n",
      "\n",
      "Validation loss improved from 0.2939 to 0.2938. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4348\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4028\n",
      "    Batch [2/2], Val Loss: 0.1848\n",
      "Epoch [134/2000], Avg Train Loss: 0.4348, Avg Val Loss: 0.2938\n",
      "\n",
      "Validation loss improved from 0.2938 to 0.2938. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4352\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4027\n",
      "    Batch [2/2], Val Loss: 0.1847\n",
      "Epoch [135/2000], Avg Train Loss: 0.4352, Avg Val Loss: 0.2937\n",
      "\n",
      "Validation loss improved from 0.2938 to 0.2937. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4345\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4027\n",
      "    Batch [2/2], Val Loss: 0.1846\n",
      "Epoch [136/2000], Avg Train Loss: 0.4345, Avg Val Loss: 0.2937\n",
      "\n",
      "Validation loss improved from 0.2937 to 0.2937. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4026\n",
      "    Batch [2/2], Val Loss: 0.1845\n",
      "Epoch [137/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2936\n",
      "\n",
      "Validation loss improved from 0.2937 to 0.2936. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4354\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4026\n",
      "    Batch [2/2], Val Loss: 0.1844\n",
      "Epoch [138/2000], Avg Train Loss: 0.4354, Avg Val Loss: 0.2935\n",
      "\n",
      "Validation loss improved from 0.2936 to 0.2935. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4352\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4025\n",
      "    Batch [2/2], Val Loss: 0.1843\n",
      "Epoch [139/2000], Avg Train Loss: 0.4352, Avg Val Loss: 0.2934\n",
      "\n",
      "Validation loss improved from 0.2935 to 0.2934. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4365\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4025\n",
      "    Batch [2/2], Val Loss: 0.1843\n",
      "Epoch [140/2000], Avg Train Loss: 0.4365, Avg Val Loss: 0.2934\n",
      "\n",
      "Validation loss improved from 0.2934 to 0.2934. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4343\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4024\n",
      "    Batch [2/2], Val Loss: 0.1842\n",
      "Epoch [141/2000], Avg Train Loss: 0.4343, Avg Val Loss: 0.2933\n",
      "\n",
      "Validation loss improved from 0.2934 to 0.2933. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4363\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4024\n",
      "    Batch [2/2], Val Loss: 0.1842\n",
      "Epoch [142/2000], Avg Train Loss: 0.4363, Avg Val Loss: 0.2933\n",
      "\n",
      "Validation loss improved from 0.2933 to 0.2933. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4351\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4023\n",
      "    Batch [2/2], Val Loss: 0.1841\n",
      "Epoch [143/2000], Avg Train Loss: 0.4351, Avg Val Loss: 0.2932\n",
      "\n",
      "Validation loss improved from 0.2933 to 0.2932. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4321\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4022\n",
      "    Batch [2/2], Val Loss: 0.1841\n",
      "Epoch [144/2000], Avg Train Loss: 0.4321, Avg Val Loss: 0.2931\n",
      "\n",
      "Validation loss improved from 0.2932 to 0.2931. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4350\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4021\n",
      "    Batch [2/2], Val Loss: 0.1840\n",
      "Epoch [145/2000], Avg Train Loss: 0.4350, Avg Val Loss: 0.2931\n",
      "\n",
      "Validation loss improved from 0.2931 to 0.2931. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4021\n",
      "    Batch [2/2], Val Loss: 0.1840\n",
      "Epoch [146/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2931\n",
      "\n",
      "Validation loss improved from 0.2931 to 0.2931. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4343\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4020\n",
      "    Batch [2/2], Val Loss: 0.1840\n",
      "Epoch [147/2000], Avg Train Loss: 0.4343, Avg Val Loss: 0.2930\n",
      "\n",
      "Validation loss improved from 0.2931 to 0.2930. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4334\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4020\n",
      "    Batch [2/2], Val Loss: 0.1839\n",
      "Epoch [148/2000], Avg Train Loss: 0.4334, Avg Val Loss: 0.2929\n",
      "\n",
      "Validation loss improved from 0.2930 to 0.2929. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4315\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4019\n",
      "    Batch [2/2], Val Loss: 0.1838\n",
      "Epoch [149/2000], Avg Train Loss: 0.4315, Avg Val Loss: 0.2929\n",
      "\n",
      "Validation loss improved from 0.2929 to 0.2929. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4358\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4018\n",
      "    Batch [2/2], Val Loss: 0.1838\n",
      "Epoch [150/2000], Avg Train Loss: 0.4358, Avg Val Loss: 0.2928\n",
      "\n",
      "Validation loss improved from 0.2929 to 0.2928. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4344\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4018\n",
      "    Batch [2/2], Val Loss: 0.1837\n",
      "Epoch [151/2000], Avg Train Loss: 0.4344, Avg Val Loss: 0.2928\n",
      "\n",
      "Validation loss improved from 0.2928 to 0.2928. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4018\n",
      "    Batch [2/2], Val Loss: 0.1837\n",
      "Epoch [152/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2927\n",
      "\n",
      "Validation loss improved from 0.2928 to 0.2927. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4017\n",
      "    Batch [2/2], Val Loss: 0.1836\n",
      "Epoch [153/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2927\n",
      "\n",
      "Validation loss improved from 0.2927 to 0.2927. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4332\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4017\n",
      "    Batch [2/2], Val Loss: 0.1836\n",
      "Epoch [154/2000], Avg Train Loss: 0.4332, Avg Val Loss: 0.2926\n",
      "\n",
      "Validation loss improved from 0.2927 to 0.2926. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4332\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4016\n",
      "    Batch [2/2], Val Loss: 0.1835\n",
      "Epoch [155/2000], Avg Train Loss: 0.4332, Avg Val Loss: 0.2926\n",
      "\n",
      "Validation loss improved from 0.2926 to 0.2926. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4359\n",
      "LOG: Epoch [156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4016\n",
      "    Batch [2/2], Val Loss: 0.1835\n",
      "Epoch [156/2000], Avg Train Loss: 0.4359, Avg Val Loss: 0.2925\n",
      "\n",
      "Validation loss improved from 0.2926 to 0.2925. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4302\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4016\n",
      "    Batch [2/2], Val Loss: 0.1834\n",
      "Epoch [157/2000], Avg Train Loss: 0.4302, Avg Val Loss: 0.2925\n",
      "\n",
      "Validation loss improved from 0.2925 to 0.2925. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4314\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4016\n",
      "    Batch [2/2], Val Loss: 0.1834\n",
      "Epoch [158/2000], Avg Train Loss: 0.4314, Avg Val Loss: 0.2925\n",
      "\n",
      "Validation loss improved from 0.2925 to 0.2925. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4347\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4016\n",
      "    Batch [2/2], Val Loss: 0.1833\n",
      "Epoch [159/2000], Avg Train Loss: 0.4347, Avg Val Loss: 0.2924\n",
      "\n",
      "Validation loss improved from 0.2925 to 0.2924. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4364\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4015\n",
      "    Batch [2/2], Val Loss: 0.1833\n",
      "Epoch [160/2000], Avg Train Loss: 0.4364, Avg Val Loss: 0.2924\n",
      "\n",
      "Validation loss improved from 0.2924 to 0.2924. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4015\n",
      "    Batch [2/2], Val Loss: 0.1833\n",
      "Epoch [161/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2924\n",
      "\n",
      "Validation loss improved from 0.2924 to 0.2924. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4329\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4014\n",
      "    Batch [2/2], Val Loss: 0.1832\n",
      "Epoch [162/2000], Avg Train Loss: 0.4329, Avg Val Loss: 0.2923\n",
      "\n",
      "Validation loss improved from 0.2924 to 0.2923. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4014\n",
      "    Batch [2/2], Val Loss: 0.1832\n",
      "Epoch [163/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2923\n",
      "\n",
      "Validation loss improved from 0.2923 to 0.2923. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4324\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4013\n",
      "    Batch [2/2], Val Loss: 0.1831\n",
      "Epoch [164/2000], Avg Train Loss: 0.4324, Avg Val Loss: 0.2922\n",
      "\n",
      "Validation loss improved from 0.2923 to 0.2922. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4303\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4013\n",
      "    Batch [2/2], Val Loss: 0.1831\n",
      "Epoch [165/2000], Avg Train Loss: 0.4303, Avg Val Loss: 0.2922\n",
      "\n",
      "Validation loss improved from 0.2922 to 0.2922. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4308\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4013\n",
      "    Batch [2/2], Val Loss: 0.1831\n",
      "Epoch [166/2000], Avg Train Loss: 0.4308, Avg Val Loss: 0.2922\n",
      "\n",
      "Validation loss improved from 0.2922 to 0.2922. Saving model...\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4311\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4012\n",
      "    Batch [2/2], Val Loss: 0.1830\n",
      "Epoch [167/2000], Avg Train Loss: 0.4311, Avg Val Loss: 0.2921\n",
      "\n",
      "Validation loss improved from 0.2922 to 0.2921. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4332\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4012\n",
      "    Batch [2/2], Val Loss: 0.1830\n",
      "Epoch [168/2000], Avg Train Loss: 0.4332, Avg Val Loss: 0.2921\n",
      "\n",
      "Validation loss improved from 0.2921 to 0.2921. Saving model...\n",
      "LOG: Epoch [169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4334\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4012\n",
      "    Batch [2/2], Val Loss: 0.1829\n",
      "Epoch [169/2000], Avg Train Loss: 0.4334, Avg Val Loss: 0.2920\n",
      "\n",
      "Validation loss improved from 0.2921 to 0.2920. Saving model...\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4011\n",
      "    Batch [2/2], Val Loss: 0.1828\n",
      "Epoch [170/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2920\n",
      "\n",
      "Validation loss improved from 0.2920 to 0.2920. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4307\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4011\n",
      "    Batch [2/2], Val Loss: 0.1828\n",
      "Epoch [171/2000], Avg Train Loss: 0.4307, Avg Val Loss: 0.2919\n",
      "\n",
      "Validation loss improved from 0.2920 to 0.2919. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4355\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4010\n",
      "    Batch [2/2], Val Loss: 0.1828\n",
      "Epoch [172/2000], Avg Train Loss: 0.4355, Avg Val Loss: 0.2919\n",
      "\n",
      "Validation loss improved from 0.2919 to 0.2919. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4334\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4009\n",
      "    Batch [2/2], Val Loss: 0.1828\n",
      "Epoch [173/2000], Avg Train Loss: 0.4334, Avg Val Loss: 0.2918\n",
      "\n",
      "Validation loss improved from 0.2919 to 0.2918. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4367\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4008\n",
      "    Batch [2/2], Val Loss: 0.1827\n",
      "Epoch [174/2000], Avg Train Loss: 0.4367, Avg Val Loss: 0.2918\n",
      "\n",
      "Validation loss improved from 0.2918 to 0.2918. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4355\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4008\n",
      "    Batch [2/2], Val Loss: 0.1827\n",
      "Epoch [175/2000], Avg Train Loss: 0.4355, Avg Val Loss: 0.2917\n",
      "\n",
      "Validation loss improved from 0.2918 to 0.2917. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4334\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4007\n",
      "    Batch [2/2], Val Loss: 0.1827\n",
      "Epoch [176/2000], Avg Train Loss: 0.4334, Avg Val Loss: 0.2917\n",
      "\n",
      "Validation loss improved from 0.2917 to 0.2917. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4006\n",
      "    Batch [2/2], Val Loss: 0.1827\n",
      "Epoch [177/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.2916\n",
      "\n",
      "Validation loss improved from 0.2917 to 0.2916. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4302\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4005\n",
      "    Batch [2/2], Val Loss: 0.1826\n",
      "Epoch [178/2000], Avg Train Loss: 0.4302, Avg Val Loss: 0.2916\n",
      "\n",
      "Validation loss improved from 0.2916 to 0.2916. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4345\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4004\n",
      "    Batch [2/2], Val Loss: 0.1826\n",
      "Epoch [179/2000], Avg Train Loss: 0.4345, Avg Val Loss: 0.2915\n",
      "\n",
      "Validation loss improved from 0.2916 to 0.2915. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4003\n",
      "    Batch [2/2], Val Loss: 0.1825\n",
      "Epoch [180/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2914\n",
      "\n",
      "Validation loss improved from 0.2915 to 0.2914. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4296\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4002\n",
      "    Batch [2/2], Val Loss: 0.1825\n",
      "Epoch [181/2000], Avg Train Loss: 0.4296, Avg Val Loss: 0.2914\n",
      "\n",
      "Validation loss improved from 0.2914 to 0.2914. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4311\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4002\n",
      "    Batch [2/2], Val Loss: 0.1825\n",
      "Epoch [182/2000], Avg Train Loss: 0.4311, Avg Val Loss: 0.2913\n",
      "\n",
      "Validation loss improved from 0.2914 to 0.2913. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4285\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4001\n",
      "    Batch [2/2], Val Loss: 0.1824\n",
      "Epoch [183/2000], Avg Train Loss: 0.4285, Avg Val Loss: 0.2912\n",
      "\n",
      "Validation loss improved from 0.2913 to 0.2912. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4318\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4000\n",
      "    Batch [2/2], Val Loss: 0.1824\n",
      "Epoch [184/2000], Avg Train Loss: 0.4318, Avg Val Loss: 0.2912\n",
      "\n",
      "Validation loss improved from 0.2912 to 0.2912. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3999\n",
      "    Batch [2/2], Val Loss: 0.1822\n",
      "Epoch [185/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2911\n",
      "\n",
      "Validation loss improved from 0.2912 to 0.2911. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4333\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3999\n",
      "    Batch [2/2], Val Loss: 0.1821\n",
      "Epoch [186/2000], Avg Train Loss: 0.4333, Avg Val Loss: 0.2910\n",
      "\n",
      "Validation loss improved from 0.2911 to 0.2910. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4301\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3998\n",
      "    Batch [2/2], Val Loss: 0.1820\n",
      "Epoch [187/2000], Avg Train Loss: 0.4301, Avg Val Loss: 0.2909\n",
      "\n",
      "Validation loss improved from 0.2910 to 0.2909. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4326\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3998\n",
      "    Batch [2/2], Val Loss: 0.1819\n",
      "Epoch [188/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.2908\n",
      "\n",
      "Validation loss improved from 0.2909 to 0.2908. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3998\n",
      "    Batch [2/2], Val Loss: 0.1818\n",
      "Epoch [189/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2908\n",
      "\n",
      "Validation loss improved from 0.2908 to 0.2908. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3997\n",
      "    Batch [2/2], Val Loss: 0.1817\n",
      "Epoch [190/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.2907\n",
      "\n",
      "Validation loss improved from 0.2908 to 0.2907. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4323\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3996\n",
      "    Batch [2/2], Val Loss: 0.1816\n",
      "Epoch [191/2000], Avg Train Loss: 0.4323, Avg Val Loss: 0.2906\n",
      "\n",
      "Validation loss improved from 0.2907 to 0.2906. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4311\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3996\n",
      "    Batch [2/2], Val Loss: 0.1815\n",
      "Epoch [192/2000], Avg Train Loss: 0.4311, Avg Val Loss: 0.2905\n",
      "\n",
      "Validation loss improved from 0.2906 to 0.2905. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4332\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3995\n",
      "    Batch [2/2], Val Loss: 0.1814\n",
      "Epoch [193/2000], Avg Train Loss: 0.4332, Avg Val Loss: 0.2904\n",
      "\n",
      "Validation loss improved from 0.2905 to 0.2904. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3995\n",
      "    Batch [2/2], Val Loss: 0.1812\n",
      "Epoch [194/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2904\n",
      "\n",
      "Validation loss improved from 0.2904 to 0.2904. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3995\n",
      "    Batch [2/2], Val Loss: 0.1811\n",
      "Epoch [195/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2903\n",
      "\n",
      "Validation loss improved from 0.2904 to 0.2903. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3994\n",
      "    Batch [2/2], Val Loss: 0.1810\n",
      "Epoch [196/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2902\n",
      "\n",
      "Validation loss improved from 0.2903 to 0.2902. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4315\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3994\n",
      "    Batch [2/2], Val Loss: 0.1809\n",
      "Epoch [197/2000], Avg Train Loss: 0.4315, Avg Val Loss: 0.2902\n",
      "\n",
      "Validation loss improved from 0.2902 to 0.2902. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4309\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3994\n",
      "    Batch [2/2], Val Loss: 0.1809\n",
      "Epoch [198/2000], Avg Train Loss: 0.4309, Avg Val Loss: 0.2901\n",
      "\n",
      "Validation loss improved from 0.2902 to 0.2901. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3993\n",
      "    Batch [2/2], Val Loss: 0.1808\n",
      "Epoch [199/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2901\n",
      "\n",
      "Validation loss improved from 0.2901 to 0.2901. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4344\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3993\n",
      "    Batch [2/2], Val Loss: 0.1807\n",
      "Epoch [200/2000], Avg Train Loss: 0.4344, Avg Val Loss: 0.2900\n",
      "\n",
      "Validation loss improved from 0.2901 to 0.2900. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4307\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3993\n",
      "    Batch [2/2], Val Loss: 0.1807\n",
      "Epoch [201/2000], Avg Train Loss: 0.4307, Avg Val Loss: 0.2900\n",
      "\n",
      "Validation loss improved from 0.2900 to 0.2900. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4266\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3992\n",
      "    Batch [2/2], Val Loss: 0.1806\n",
      "Epoch [202/2000], Avg Train Loss: 0.4266, Avg Val Loss: 0.2899\n",
      "\n",
      "Validation loss improved from 0.2900 to 0.2899. Saving model...\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4341\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3992\n",
      "    Batch [2/2], Val Loss: 0.1806\n",
      "Epoch [203/2000], Avg Train Loss: 0.4341, Avg Val Loss: 0.2899\n",
      "\n",
      "Validation loss improved from 0.2899 to 0.2899. Saving model...\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4296\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3992\n",
      "    Batch [2/2], Val Loss: 0.1806\n",
      "Epoch [204/2000], Avg Train Loss: 0.4296, Avg Val Loss: 0.2899\n",
      "\n",
      "Validation loss improved from 0.2899 to 0.2899. Saving model...\n",
      "LOG: Epoch [205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4307\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3992\n",
      "    Batch [2/2], Val Loss: 0.1805\n",
      "Epoch [205/2000], Avg Train Loss: 0.4307, Avg Val Loss: 0.2898\n",
      "\n",
      "Validation loss improved from 0.2899 to 0.2898. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4272\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3991\n",
      "    Batch [2/2], Val Loss: 0.1805\n",
      "Epoch [206/2000], Avg Train Loss: 0.4272, Avg Val Loss: 0.2898\n",
      "\n",
      "Validation loss improved from 0.2898 to 0.2898. Saving model...\n",
      "LOG: Epoch [207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3991\n",
      "    Batch [2/2], Val Loss: 0.1804\n",
      "Epoch [207/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2897\n",
      "\n",
      "Validation loss improved from 0.2898 to 0.2897. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4321\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3990\n",
      "    Batch [2/2], Val Loss: 0.1804\n",
      "Epoch [208/2000], Avg Train Loss: 0.4321, Avg Val Loss: 0.2897\n",
      "\n",
      "Validation loss improved from 0.2897 to 0.2897. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3989\n",
      "    Batch [2/2], Val Loss: 0.1803\n",
      "Epoch [209/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2896\n",
      "\n",
      "Validation loss improved from 0.2897 to 0.2896. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4288\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3989\n",
      "    Batch [2/2], Val Loss: 0.1803\n",
      "Epoch [210/2000], Avg Train Loss: 0.4288, Avg Val Loss: 0.2896\n",
      "\n",
      "Validation loss improved from 0.2896 to 0.2896. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4267\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3989\n",
      "    Batch [2/2], Val Loss: 0.1802\n",
      "Epoch [211/2000], Avg Train Loss: 0.4267, Avg Val Loss: 0.2896\n",
      "\n",
      "Validation loss improved from 0.2896 to 0.2896. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4303\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3988\n",
      "    Batch [2/2], Val Loss: 0.1802\n",
      "Epoch [212/2000], Avg Train Loss: 0.4303, Avg Val Loss: 0.2895\n",
      "\n",
      "Validation loss improved from 0.2896 to 0.2895. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3987\n",
      "    Batch [2/2], Val Loss: 0.1802\n",
      "Epoch [213/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2894\n",
      "\n",
      "Validation loss improved from 0.2895 to 0.2894. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4338\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3987\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [214/2000], Avg Train Loss: 0.4338, Avg Val Loss: 0.2894\n",
      "\n",
      "Validation loss improved from 0.2894 to 0.2894. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4312\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3986\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [215/2000], Avg Train Loss: 0.4312, Avg Val Loss: 0.2894\n",
      "\n",
      "Validation loss improved from 0.2894 to 0.2894. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4310\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3985\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [216/2000], Avg Train Loss: 0.4310, Avg Val Loss: 0.2893\n",
      "\n",
      "Validation loss improved from 0.2894 to 0.2893. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3985\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [217/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.2893\n",
      "\n",
      "Validation loss improved from 0.2893 to 0.2893. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3985\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [218/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2893\n",
      "\n",
      "Validation loss improved from 0.2893 to 0.2893. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3985\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [219/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2892\n",
      "\n",
      "Validation loss improved from 0.2893 to 0.2892. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4304\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3984\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [220/2000], Avg Train Loss: 0.4304, Avg Val Loss: 0.2892\n",
      "\n",
      "Validation loss improved from 0.2892 to 0.2892. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4313\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3984\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [221/2000], Avg Train Loss: 0.4313, Avg Val Loss: 0.2892\n",
      "\n",
      "Validation loss improved from 0.2892 to 0.2892. Saving model...\n",
      "LOG: Epoch [222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3983\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [222/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.2892\n",
      "\n",
      "Validation loss improved from 0.2892 to 0.2892. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3982\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [223/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2891\n",
      "\n",
      "Validation loss improved from 0.2892 to 0.2891. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3982\n",
      "    Batch [2/2], Val Loss: 0.1800\n",
      "Epoch [224/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2891\n",
      "\n",
      "Validation loss improved from 0.2891 to 0.2891. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3981\n",
      "    Batch [2/2], Val Loss: 0.1799\n",
      "Epoch [225/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2890\n",
      "\n",
      "Validation loss improved from 0.2891 to 0.2890. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4294\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3981\n",
      "    Batch [2/2], Val Loss: 0.1798\n",
      "Epoch [226/2000], Avg Train Loss: 0.4294, Avg Val Loss: 0.2889\n",
      "\n",
      "Validation loss improved from 0.2890 to 0.2889. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3980\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [227/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2889\n",
      "\n",
      "Validation loss improved from 0.2889 to 0.2889. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4255\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3980\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [228/2000], Avg Train Loss: 0.4255, Avg Val Loss: 0.2889\n",
      "\n",
      "Validation loss improved from 0.2889 to 0.2889. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3979\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [229/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2888\n",
      "\n",
      "Validation loss improved from 0.2889 to 0.2888. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3979\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [230/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2888\n",
      "\n",
      "Validation loss improved from 0.2888 to 0.2888. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4301\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3978\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [231/2000], Avg Train Loss: 0.4301, Avg Val Loss: 0.2887\n",
      "\n",
      "Validation loss improved from 0.2888 to 0.2887. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4281\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3977\n",
      "    Batch [2/2], Val Loss: 0.1797\n",
      "Epoch [232/2000], Avg Train Loss: 0.4281, Avg Val Loss: 0.2887\n",
      "\n",
      "Validation loss improved from 0.2887 to 0.2887. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3976\n",
      "    Batch [2/2], Val Loss: 0.1796\n",
      "Epoch [233/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2886\n",
      "\n",
      "Validation loss improved from 0.2887 to 0.2886. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3975\n",
      "    Batch [2/2], Val Loss: 0.1796\n",
      "Epoch [234/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2886\n",
      "\n",
      "Validation loss improved from 0.2886 to 0.2886. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3974\n",
      "    Batch [2/2], Val Loss: 0.1796\n",
      "Epoch [235/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2885\n",
      "\n",
      "Validation loss improved from 0.2886 to 0.2885. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3974\n",
      "    Batch [2/2], Val Loss: 0.1795\n",
      "Epoch [236/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2884\n",
      "\n",
      "Validation loss improved from 0.2885 to 0.2884. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4284\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3973\n",
      "    Batch [2/2], Val Loss: 0.1794\n",
      "Epoch [237/2000], Avg Train Loss: 0.4284, Avg Val Loss: 0.2884\n",
      "\n",
      "Validation loss improved from 0.2884 to 0.2884. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3972\n",
      "    Batch [2/2], Val Loss: 0.1794\n",
      "Epoch [238/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2883\n",
      "\n",
      "Validation loss improved from 0.2884 to 0.2883. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4368\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3972\n",
      "    Batch [2/2], Val Loss: 0.1793\n",
      "Epoch [239/2000], Avg Train Loss: 0.4368, Avg Val Loss: 0.2883\n",
      "\n",
      "Validation loss improved from 0.2883 to 0.2883. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4278\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3972\n",
      "    Batch [2/2], Val Loss: 0.1793\n",
      "Epoch [240/2000], Avg Train Loss: 0.4278, Avg Val Loss: 0.2882\n",
      "\n",
      "Validation loss improved from 0.2883 to 0.2882. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4310\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3972\n",
      "    Batch [2/2], Val Loss: 0.1792\n",
      "Epoch [241/2000], Avg Train Loss: 0.4310, Avg Val Loss: 0.2882\n",
      "\n",
      "Validation loss improved from 0.2882 to 0.2882. Saving model...\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4302\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3972\n",
      "    Batch [2/2], Val Loss: 0.1792\n",
      "Epoch [242/2000], Avg Train Loss: 0.4302, Avg Val Loss: 0.2882\n",
      "\n",
      "Validation loss improved from 0.2882 to 0.2882. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4291\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3971\n",
      "    Batch [2/2], Val Loss: 0.1791\n",
      "Epoch [243/2000], Avg Train Loss: 0.4291, Avg Val Loss: 0.2881\n",
      "\n",
      "Validation loss improved from 0.2882 to 0.2881. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4281\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3971\n",
      "    Batch [2/2], Val Loss: 0.1790\n",
      "Epoch [244/2000], Avg Train Loss: 0.4281, Avg Val Loss: 0.2881\n",
      "\n",
      "Validation loss improved from 0.2881 to 0.2881. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4288\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3971\n",
      "    Batch [2/2], Val Loss: 0.1789\n",
      "Epoch [245/2000], Avg Train Loss: 0.4288, Avg Val Loss: 0.2880\n",
      "\n",
      "Validation loss improved from 0.2881 to 0.2880. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4270\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3970\n",
      "    Batch [2/2], Val Loss: 0.1788\n",
      "Epoch [246/2000], Avg Train Loss: 0.4270, Avg Val Loss: 0.2879\n",
      "\n",
      "Validation loss improved from 0.2880 to 0.2879. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3970\n",
      "    Batch [2/2], Val Loss: 0.1788\n",
      "Epoch [247/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.2879\n",
      "\n",
      "Validation loss improved from 0.2879 to 0.2879. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4296\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3969\n",
      "    Batch [2/2], Val Loss: 0.1787\n",
      "Epoch [248/2000], Avg Train Loss: 0.4296, Avg Val Loss: 0.2878\n",
      "\n",
      "Validation loss improved from 0.2879 to 0.2878. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4304\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3969\n",
      "    Batch [2/2], Val Loss: 0.1786\n",
      "Epoch [249/2000], Avg Train Loss: 0.4304, Avg Val Loss: 0.2877\n",
      "\n",
      "Validation loss improved from 0.2878 to 0.2877. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4296\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3969\n",
      "    Batch [2/2], Val Loss: 0.1785\n",
      "Epoch [250/2000], Avg Train Loss: 0.4296, Avg Val Loss: 0.2877\n",
      "\n",
      "Validation loss improved from 0.2877 to 0.2877. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4270\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3969\n",
      "    Batch [2/2], Val Loss: 0.1783\n",
      "Epoch [251/2000], Avg Train Loss: 0.4270, Avg Val Loss: 0.2876\n",
      "\n",
      "Validation loss improved from 0.2877 to 0.2876. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4322\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3968\n",
      "    Batch [2/2], Val Loss: 0.1782\n",
      "Epoch [252/2000], Avg Train Loss: 0.4322, Avg Val Loss: 0.2875\n",
      "\n",
      "Validation loss improved from 0.2876 to 0.2875. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4309\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3968\n",
      "    Batch [2/2], Val Loss: 0.1781\n",
      "Epoch [253/2000], Avg Train Loss: 0.4309, Avg Val Loss: 0.2874\n",
      "\n",
      "Validation loss improved from 0.2875 to 0.2874. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4264\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3967\n",
      "    Batch [2/2], Val Loss: 0.1780\n",
      "Epoch [254/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2873\n",
      "\n",
      "Validation loss improved from 0.2874 to 0.2873. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4254\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3967\n",
      "    Batch [2/2], Val Loss: 0.1779\n",
      "Epoch [255/2000], Avg Train Loss: 0.4254, Avg Val Loss: 0.2873\n",
      "\n",
      "Validation loss improved from 0.2873 to 0.2873. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4291\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3966\n",
      "    Batch [2/2], Val Loss: 0.1778\n",
      "Epoch [256/2000], Avg Train Loss: 0.4291, Avg Val Loss: 0.2872\n",
      "\n",
      "Validation loss improved from 0.2873 to 0.2872. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4285\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3966\n",
      "    Batch [2/2], Val Loss: 0.1778\n",
      "Epoch [257/2000], Avg Train Loss: 0.4285, Avg Val Loss: 0.2872\n",
      "\n",
      "Validation loss improved from 0.2872 to 0.2872. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4324\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3965\n",
      "    Batch [2/2], Val Loss: 0.1777\n",
      "Epoch [258/2000], Avg Train Loss: 0.4324, Avg Val Loss: 0.2871\n",
      "\n",
      "Validation loss improved from 0.2872 to 0.2871. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4282\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3965\n",
      "    Batch [2/2], Val Loss: 0.1777\n",
      "Epoch [259/2000], Avg Train Loss: 0.4282, Avg Val Loss: 0.2871\n",
      "\n",
      "Validation loss improved from 0.2871 to 0.2871. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4311\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3964\n",
      "    Batch [2/2], Val Loss: 0.1777\n",
      "Epoch [260/2000], Avg Train Loss: 0.4311, Avg Val Loss: 0.2870\n",
      "\n",
      "Validation loss improved from 0.2871 to 0.2870. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3964\n",
      "    Batch [2/2], Val Loss: 0.1776\n",
      "Epoch [261/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2870\n",
      "\n",
      "Validation loss improved from 0.2870 to 0.2870. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4299\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3963\n",
      "    Batch [2/2], Val Loss: 0.1776\n",
      "Epoch [262/2000], Avg Train Loss: 0.4299, Avg Val Loss: 0.2870\n",
      "\n",
      "Validation loss improved from 0.2870 to 0.2870. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3962\n",
      "    Batch [2/2], Val Loss: 0.1776\n",
      "Epoch [263/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2869\n",
      "\n",
      "Validation loss improved from 0.2870 to 0.2869. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3962\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [264/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2869\n",
      "\n",
      "Validation loss improved from 0.2869 to 0.2869. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3961\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [265/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.2868\n",
      "\n",
      "Validation loss improved from 0.2869 to 0.2868. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4272\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3960\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [266/2000], Avg Train Loss: 0.4272, Avg Val Loss: 0.2868\n",
      "\n",
      "Validation loss improved from 0.2868 to 0.2868. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4255\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3959\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [267/2000], Avg Train Loss: 0.4255, Avg Val Loss: 0.2867\n",
      "\n",
      "Validation loss improved from 0.2868 to 0.2867. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3959\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [268/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2867\n",
      "\n",
      "Validation loss improved from 0.2867 to 0.2867. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3959\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [269/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2867\n",
      "\n",
      "Validation loss improved from 0.2867 to 0.2867. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3958\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [270/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.2866\n",
      "\n",
      "Validation loss improved from 0.2867 to 0.2866. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4262\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3957\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [271/2000], Avg Train Loss: 0.4262, Avg Val Loss: 0.2866\n",
      "\n",
      "Validation loss improved from 0.2866 to 0.2866. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3957\n",
      "    Batch [2/2], Val Loss: 0.1775\n",
      "Epoch [272/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2866\n",
      "\n",
      "Validation loss improved from 0.2866 to 0.2866. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4293\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3956\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [273/2000], Avg Train Loss: 0.4293, Avg Val Loss: 0.2865\n",
      "\n",
      "Validation loss improved from 0.2866 to 0.2865. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4291\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3955\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [274/2000], Avg Train Loss: 0.4291, Avg Val Loss: 0.2865\n",
      "\n",
      "Validation loss improved from 0.2865 to 0.2865. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4281\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3955\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [275/2000], Avg Train Loss: 0.4281, Avg Val Loss: 0.2865\n",
      "\n",
      "Validation loss improved from 0.2865 to 0.2865. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4261\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3954\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [276/2000], Avg Train Loss: 0.4261, Avg Val Loss: 0.2864\n",
      "\n",
      "Validation loss improved from 0.2865 to 0.2864. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4269\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3954\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [277/2000], Avg Train Loss: 0.4269, Avg Val Loss: 0.2864\n",
      "\n",
      "Validation loss improved from 0.2864 to 0.2864. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3953\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [278/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.2863\n",
      "\n",
      "Validation loss improved from 0.2864 to 0.2863. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3952\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [279/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2863\n",
      "\n",
      "Validation loss improved from 0.2863 to 0.2863. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3952\n",
      "    Batch [2/2], Val Loss: 0.1774\n",
      "Epoch [280/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.2863\n",
      "\n",
      "Validation loss improved from 0.2863 to 0.2863. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3951\n",
      "    Batch [2/2], Val Loss: 0.1773\n",
      "Epoch [281/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2862\n",
      "\n",
      "Validation loss improved from 0.2863 to 0.2862. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3950\n",
      "    Batch [2/2], Val Loss: 0.1773\n",
      "Epoch [282/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2862\n",
      "\n",
      "Validation loss improved from 0.2862 to 0.2862. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3949\n",
      "    Batch [2/2], Val Loss: 0.1773\n",
      "Epoch [283/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2861\n",
      "\n",
      "Validation loss improved from 0.2862 to 0.2861. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3949\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [284/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2861\n",
      "\n",
      "Validation loss improved from 0.2861 to 0.2861. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4224\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3948\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [285/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.2860\n",
      "\n",
      "Validation loss improved from 0.2861 to 0.2860. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3947\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [286/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2860\n",
      "\n",
      "Validation loss improved from 0.2860 to 0.2860. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4229\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3947\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [287/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2859\n",
      "\n",
      "Validation loss improved from 0.2860 to 0.2859. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3946\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [288/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.2859\n",
      "\n",
      "Validation loss improved from 0.2859 to 0.2859. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4288\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3945\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [289/2000], Avg Train Loss: 0.4288, Avg Val Loss: 0.2858\n",
      "\n",
      "Validation loss improved from 0.2859 to 0.2858. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3945\n",
      "    Batch [2/2], Val Loss: 0.1771\n",
      "Epoch [290/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2858\n",
      "\n",
      "Validation loss improved from 0.2858 to 0.2858. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4266\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3944\n",
      "    Batch [2/2], Val Loss: 0.1771\n",
      "Epoch [291/2000], Avg Train Loss: 0.4266, Avg Val Loss: 0.2858\n",
      "\n",
      "Validation loss improved from 0.2858 to 0.2858. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4271\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3944\n",
      "    Batch [2/2], Val Loss: 0.1770\n",
      "Epoch [292/2000], Avg Train Loss: 0.4271, Avg Val Loss: 0.2857\n",
      "\n",
      "Validation loss improved from 0.2858 to 0.2857. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4251\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3944\n",
      "    Batch [2/2], Val Loss: 0.1768\n",
      "Epoch [293/2000], Avg Train Loss: 0.4251, Avg Val Loss: 0.2856\n",
      "\n",
      "Validation loss improved from 0.2857 to 0.2856. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3943\n",
      "    Batch [2/2], Val Loss: 0.1767\n",
      "Epoch [294/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2855\n",
      "\n",
      "Validation loss improved from 0.2856 to 0.2855. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4223\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3943\n",
      "    Batch [2/2], Val Loss: 0.1766\n",
      "Epoch [295/2000], Avg Train Loss: 0.4223, Avg Val Loss: 0.2855\n",
      "\n",
      "Validation loss improved from 0.2855 to 0.2855. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4284\n",
      "LOG: Epoch [296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3943\n",
      "    Batch [2/2], Val Loss: 0.1766\n",
      "Epoch [296/2000], Avg Train Loss: 0.4284, Avg Val Loss: 0.2854\n",
      "\n",
      "Validation loss improved from 0.2855 to 0.2854. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4273\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3943\n",
      "    Batch [2/2], Val Loss: 0.1765\n",
      "Epoch [297/2000], Avg Train Loss: 0.4273, Avg Val Loss: 0.2854\n",
      "\n",
      "Validation loss improved from 0.2854 to 0.2854. Saving model...\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4258\n",
      "LOG: Epoch [298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.1764\n",
      "Epoch [298/2000], Avg Train Loss: 0.4258, Avg Val Loss: 0.2853\n",
      "\n",
      "Validation loss improved from 0.2854 to 0.2853. Saving model...\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.1763\n",
      "Epoch [299/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2852\n",
      "\n",
      "Validation loss improved from 0.2853 to 0.2852. Saving model...\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4271\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.1762\n",
      "Epoch [300/2000], Avg Train Loss: 0.4271, Avg Val Loss: 0.2852\n",
      "\n",
      "Validation loss improved from 0.2852 to 0.2852. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.1762\n",
      "Epoch [301/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2852\n",
      "\n",
      "Validation loss improved from 0.2852 to 0.2852. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.1761\n",
      "Epoch [302/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2852\n",
      "\n",
      "Validation loss improved from 0.2852 to 0.2852. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.1760\n",
      "Epoch [303/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2851\n",
      "\n",
      "Validation loss improved from 0.2852 to 0.2851. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4224\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3941\n",
      "    Batch [2/2], Val Loss: 0.1760\n",
      "Epoch [304/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.2850\n",
      "\n",
      "Validation loss improved from 0.2851 to 0.2850. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4311\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3941\n",
      "    Batch [2/2], Val Loss: 0.1759\n",
      "Epoch [305/2000], Avg Train Loss: 0.4311, Avg Val Loss: 0.2850\n",
      "\n",
      "Validation loss improved from 0.2850 to 0.2850. Saving model...\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4254\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3940\n",
      "    Batch [2/2], Val Loss: 0.1759\n",
      "Epoch [306/2000], Avg Train Loss: 0.4254, Avg Val Loss: 0.2849\n",
      "\n",
      "Validation loss improved from 0.2850 to 0.2849. Saving model...\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4221\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3940\n",
      "    Batch [2/2], Val Loss: 0.1758\n",
      "Epoch [307/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2849\n",
      "\n",
      "Validation loss improved from 0.2849 to 0.2849. Saving model...\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4282\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3940\n",
      "    Batch [2/2], Val Loss: 0.1757\n",
      "Epoch [308/2000], Avg Train Loss: 0.4282, Avg Val Loss: 0.2848\n",
      "\n",
      "Validation loss improved from 0.2849 to 0.2848. Saving model...\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3939\n",
      "    Batch [2/2], Val Loss: 0.1757\n",
      "Epoch [309/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.2848\n",
      "\n",
      "Validation loss improved from 0.2848 to 0.2848. Saving model...\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3939\n",
      "    Batch [2/2], Val Loss: 0.1756\n",
      "Epoch [310/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2847\n",
      "\n",
      "Validation loss improved from 0.2848 to 0.2847. Saving model...\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3938\n",
      "    Batch [2/2], Val Loss: 0.1755\n",
      "Epoch [311/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2847\n",
      "\n",
      "Validation loss improved from 0.2847 to 0.2847. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3938\n",
      "    Batch [2/2], Val Loss: 0.1755\n",
      "Epoch [312/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2846\n",
      "\n",
      "Validation loss improved from 0.2847 to 0.2846. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.1754\n",
      "Epoch [313/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2846\n",
      "\n",
      "Validation loss improved from 0.2846 to 0.2846. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4267\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.1754\n",
      "Epoch [314/2000], Avg Train Loss: 0.4267, Avg Val Loss: 0.2845\n",
      "\n",
      "Validation loss improved from 0.2846 to 0.2845. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4276\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [315/2000], Avg Train Loss: 0.4276, Avg Val Loss: 0.2845\n",
      "\n",
      "Validation loss improved from 0.2845 to 0.2845. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4285\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [316/2000], Avg Train Loss: 0.4285, Avg Val Loss: 0.2845\n",
      "\n",
      "Validation loss improved from 0.2845 to 0.2845. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [317/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2845\n",
      "\n",
      "Validation loss improved from 0.2845 to 0.2845. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [318/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2845\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3936\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [319/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2844\n",
      "\n",
      "Validation loss improved from 0.2845 to 0.2844. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3936\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [320/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2844\n",
      "\n",
      "Validation loss improved from 0.2844 to 0.2844. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3935\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [321/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2844\n",
      "\n",
      "Validation loss improved from 0.2844 to 0.2844. Saving model...\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4270\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3934\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [322/2000], Avg Train Loss: 0.4270, Avg Val Loss: 0.2843\n",
      "\n",
      "Validation loss improved from 0.2844 to 0.2843. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4274\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3933\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [323/2000], Avg Train Loss: 0.4274, Avg Val Loss: 0.2843\n",
      "\n",
      "Validation loss improved from 0.2843 to 0.2843. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3932\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [324/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2842\n",
      "\n",
      "Validation loss improved from 0.2843 to 0.2842. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3932\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [325/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.2842\n",
      "\n",
      "Validation loss improved from 0.2842 to 0.2842. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3931\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [326/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2842\n",
      "\n",
      "Validation loss improved from 0.2842 to 0.2842. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4256\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3930\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [327/2000], Avg Train Loss: 0.4256, Avg Val Loss: 0.2841\n",
      "\n",
      "Validation loss improved from 0.2842 to 0.2841. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3929\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [328/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2841\n",
      "\n",
      "Validation loss improved from 0.2841 to 0.2841. Saving model...\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4238\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3928\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [329/2000], Avg Train Loss: 0.4238, Avg Val Loss: 0.2840\n",
      "\n",
      "Validation loss improved from 0.2841 to 0.2840. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3927\n",
      "    Batch [2/2], Val Loss: 0.1752\n",
      "Epoch [330/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2840\n",
      "\n",
      "Validation loss improved from 0.2840 to 0.2840. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3927\n",
      "    Batch [2/2], Val Loss: 0.1751\n",
      "Epoch [331/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.2839\n",
      "\n",
      "Validation loss improved from 0.2840 to 0.2839. Saving model...\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3927\n",
      "    Batch [2/2], Val Loss: 0.1750\n",
      "Epoch [332/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2839\n",
      "\n",
      "Validation loss improved from 0.2839 to 0.2839. Saving model...\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4225\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3927\n",
      "    Batch [2/2], Val Loss: 0.1750\n",
      "Epoch [333/2000], Avg Train Loss: 0.4225, Avg Val Loss: 0.2838\n",
      "\n",
      "Validation loss improved from 0.2839 to 0.2838. Saving model...\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3926\n",
      "    Batch [2/2], Val Loss: 0.1749\n",
      "Epoch [334/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2837\n",
      "\n",
      "Validation loss improved from 0.2838 to 0.2837. Saving model...\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4236\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3926\n",
      "    Batch [2/2], Val Loss: 0.1748\n",
      "Epoch [335/2000], Avg Train Loss: 0.4236, Avg Val Loss: 0.2837\n",
      "\n",
      "Validation loss improved from 0.2837 to 0.2837. Saving model...\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4215\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3925\n",
      "    Batch [2/2], Val Loss: 0.1747\n",
      "Epoch [336/2000], Avg Train Loss: 0.4215, Avg Val Loss: 0.2836\n",
      "\n",
      "Validation loss improved from 0.2837 to 0.2836. Saving model...\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4285\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3924\n",
      "    Batch [2/2], Val Loss: 0.1746\n",
      "Epoch [337/2000], Avg Train Loss: 0.4285, Avg Val Loss: 0.2835\n",
      "\n",
      "Validation loss improved from 0.2836 to 0.2835. Saving model...\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3923\n",
      "    Batch [2/2], Val Loss: 0.1744\n",
      "Epoch [338/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2834\n",
      "\n",
      "Validation loss improved from 0.2835 to 0.2834. Saving model...\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3923\n",
      "    Batch [2/2], Val Loss: 0.1744\n",
      "Epoch [339/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2833\n",
      "\n",
      "Validation loss improved from 0.2834 to 0.2833. Saving model...\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4257\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3921\n",
      "    Batch [2/2], Val Loss: 0.1742\n",
      "Epoch [340/2000], Avg Train Loss: 0.4257, Avg Val Loss: 0.2832\n",
      "\n",
      "Validation loss improved from 0.2833 to 0.2832. Saving model...\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4255\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3921\n",
      "    Batch [2/2], Val Loss: 0.1741\n",
      "Epoch [341/2000], Avg Train Loss: 0.4255, Avg Val Loss: 0.2831\n",
      "\n",
      "Validation loss improved from 0.2832 to 0.2831. Saving model...\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4229\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3920\n",
      "    Batch [2/2], Val Loss: 0.1740\n",
      "Epoch [342/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2830\n",
      "\n",
      "Validation loss improved from 0.2831 to 0.2830. Saving model...\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4256\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3919\n",
      "    Batch [2/2], Val Loss: 0.1739\n",
      "Epoch [343/2000], Avg Train Loss: 0.4256, Avg Val Loss: 0.2829\n",
      "\n",
      "Validation loss improved from 0.2830 to 0.2829. Saving model...\n",
      "LOG: Epoch [344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3918\n",
      "    Batch [2/2], Val Loss: 0.1739\n",
      "Epoch [344/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2828\n",
      "\n",
      "Validation loss improved from 0.2829 to 0.2828. Saving model...\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3917\n",
      "    Batch [2/2], Val Loss: 0.1738\n",
      "Epoch [345/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2828\n",
      "\n",
      "Validation loss improved from 0.2828 to 0.2828. Saving model...\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4243\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3916\n",
      "    Batch [2/2], Val Loss: 0.1738\n",
      "Epoch [346/2000], Avg Train Loss: 0.4243, Avg Val Loss: 0.2827\n",
      "\n",
      "Validation loss improved from 0.2828 to 0.2827. Saving model...\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3915\n",
      "    Batch [2/2], Val Loss: 0.1737\n",
      "Epoch [347/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2826\n",
      "\n",
      "Validation loss improved from 0.2827 to 0.2826. Saving model...\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4262\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3914\n",
      "    Batch [2/2], Val Loss: 0.1737\n",
      "Epoch [348/2000], Avg Train Loss: 0.4262, Avg Val Loss: 0.2825\n",
      "\n",
      "Validation loss improved from 0.2826 to 0.2825. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4266\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3913\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [349/2000], Avg Train Loss: 0.4266, Avg Val Loss: 0.2825\n",
      "\n",
      "Validation loss improved from 0.2825 to 0.2825. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4204\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3912\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [350/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2824\n",
      "\n",
      "Validation loss improved from 0.2825 to 0.2824. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3912\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [351/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2824\n",
      "\n",
      "Validation loss improved from 0.2824 to 0.2824. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4229\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3911\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [352/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2823\n",
      "\n",
      "Validation loss improved from 0.2824 to 0.2823. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4264\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.1735\n",
      "Epoch [353/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2823\n",
      "\n",
      "Validation loss improved from 0.2823 to 0.2823. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.1735\n",
      "Epoch [354/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2823 to 0.2822. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3909\n",
      "    Batch [2/2], Val Loss: 0.1735\n",
      "Epoch [355/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2822. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4208\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3909\n",
      "    Batch [2/2], Val Loss: 0.1734\n",
      "Epoch [356/2000], Avg Train Loss: 0.4208, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2822. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3909\n",
      "    Batch [2/2], Val Loss: 0.1734\n",
      "Epoch [357/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2822. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3909\n",
      "    Batch [2/2], Val Loss: 0.1734\n",
      "Epoch [358/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.2821\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2821. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4230\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3909\n",
      "    Batch [2/2], Val Loss: 0.1734\n",
      "Epoch [359/2000], Avg Train Loss: 0.4230, Avg Val Loss: 0.2821\n",
      "\n",
      "Validation loss improved from 0.2821 to 0.2821. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3908\n",
      "    Batch [2/2], Val Loss: 0.1734\n",
      "Epoch [360/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2821\n",
      "\n",
      "Validation loss improved from 0.2821 to 0.2821. Saving model...\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3908\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [361/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2821\n",
      "\n",
      "Validation loss improved from 0.2821 to 0.2821. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3908\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [362/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2821\n",
      "\n",
      "Validation loss improved from 0.2821 to 0.2821. Saving model...\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3907\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [363/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2820\n",
      "\n",
      "Validation loss improved from 0.2821 to 0.2820. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4255\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3907\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [364/2000], Avg Train Loss: 0.4255, Avg Val Loss: 0.2820\n",
      "\n",
      "Validation loss improved from 0.2820 to 0.2820. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3907\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [365/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2820\n",
      "\n",
      "Validation loss improved from 0.2820 to 0.2820. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [366/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2820\n",
      "\n",
      "Validation loss improved from 0.2820 to 0.2820. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4216\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [367/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.2819\n",
      "\n",
      "Validation loss improved from 0.2820 to 0.2819. Saving model...\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4224\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1732\n",
      "Epoch [368/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.2819\n",
      "\n",
      "Validation loss improved from 0.2819 to 0.2819. Saving model...\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3905\n",
      "    Batch [2/2], Val Loss: 0.1732\n",
      "Epoch [369/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2819\n",
      "\n",
      "Validation loss improved from 0.2819 to 0.2819. Saving model...\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4254\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3905\n",
      "    Batch [2/2], Val Loss: 0.1731\n",
      "Epoch [370/2000], Avg Train Loss: 0.4254, Avg Val Loss: 0.2818\n",
      "\n",
      "Validation loss improved from 0.2819 to 0.2818. Saving model...\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4223\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3904\n",
      "    Batch [2/2], Val Loss: 0.1731\n",
      "Epoch [371/2000], Avg Train Loss: 0.4223, Avg Val Loss: 0.2818\n",
      "\n",
      "Validation loss improved from 0.2818 to 0.2818. Saving model...\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.1731\n",
      "Epoch [372/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2817\n",
      "\n",
      "Validation loss improved from 0.2818 to 0.2817. Saving model...\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4216\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.1730\n",
      "Epoch [373/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.2816\n",
      "\n",
      "Validation loss improved from 0.2817 to 0.2816. Saving model...\n",
      "LOG: Epoch [374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.1729\n",
      "Epoch [374/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.2815\n",
      "\n",
      "Validation loss improved from 0.2816 to 0.2815. Saving model...\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.1728\n",
      "Epoch [375/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2815\n",
      "\n",
      "Validation loss improved from 0.2815 to 0.2815. Saving model...\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4258\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.1727\n",
      "Epoch [376/2000], Avg Train Loss: 0.4258, Avg Val Loss: 0.2814\n",
      "\n",
      "Validation loss improved from 0.2815 to 0.2814. Saving model...\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.1727\n",
      "Epoch [377/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2813\n",
      "\n",
      "Validation loss improved from 0.2814 to 0.2813. Saving model...\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3899\n",
      "    Batch [2/2], Val Loss: 0.1726\n",
      "Epoch [378/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2813\n",
      "\n",
      "Validation loss improved from 0.2813 to 0.2813. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3899\n",
      "    Batch [2/2], Val Loss: 0.1726\n",
      "Epoch [379/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2813\n",
      "\n",
      "Validation loss improved from 0.2813 to 0.2813. Saving model...\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4233\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3899\n",
      "    Batch [2/2], Val Loss: 0.1726\n",
      "Epoch [380/2000], Avg Train Loss: 0.4233, Avg Val Loss: 0.2812\n",
      "\n",
      "Validation loss improved from 0.2813 to 0.2812. Saving model...\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4208\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1725\n",
      "Epoch [381/2000], Avg Train Loss: 0.4208, Avg Val Loss: 0.2812\n",
      "\n",
      "Validation loss improved from 0.2812 to 0.2812. Saving model...\n",
      "LOG: Epoch [382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4215\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1725\n",
      "Epoch [382/2000], Avg Train Loss: 0.4215, Avg Val Loss: 0.2811\n",
      "\n",
      "Validation loss improved from 0.2812 to 0.2811. Saving model...\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1724\n",
      "Epoch [383/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2811\n",
      "\n",
      "Validation loss improved from 0.2811 to 0.2811. Saving model...\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3897\n",
      "    Batch [2/2], Val Loss: 0.1724\n",
      "Epoch [384/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2811\n",
      "\n",
      "Validation loss improved from 0.2811 to 0.2811. Saving model...\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4231\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3897\n",
      "    Batch [2/2], Val Loss: 0.1724\n",
      "Epoch [385/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2810\n",
      "\n",
      "Validation loss improved from 0.2811 to 0.2810. Saving model...\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3897\n",
      "    Batch [2/2], Val Loss: 0.1724\n",
      "Epoch [386/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2810\n",
      "\n",
      "Validation loss improved from 0.2810 to 0.2810. Saving model...\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4231\n",
      "LOG: Epoch [387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [387/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2810\n",
      "\n",
      "Validation loss improved from 0.2810 to 0.2810. Saving model...\n",
      "LOG: Epoch [388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [388/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2810\n",
      "\n",
      "Validation loss improved from 0.2810 to 0.2810. Saving model...\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4191\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3895\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [389/2000], Avg Train Loss: 0.4191, Avg Val Loss: 0.2809\n",
      "\n",
      "Validation loss improved from 0.2810 to 0.2809. Saving model...\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3895\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [390/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2809\n",
      "\n",
      "Validation loss improved from 0.2809 to 0.2809. Saving model...\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [391/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2809\n",
      "\n",
      "Validation loss improved from 0.2809 to 0.2809. Saving model...\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1723\n",
      "Epoch [392/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.2809\n",
      "\n",
      "Validation loss improved from 0.2809 to 0.2809. Saving model...\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4218\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1722\n",
      "Epoch [393/2000], Avg Train Loss: 0.4218, Avg Val Loss: 0.2808\n",
      "\n",
      "Validation loss improved from 0.2809 to 0.2808. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1722\n",
      "Epoch [394/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2808\n",
      "\n",
      "Validation loss improved from 0.2808 to 0.2808. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4184\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1721\n",
      "Epoch [395/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2808\n",
      "\n",
      "Validation loss improved from 0.2808 to 0.2808. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4207\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1721\n",
      "Epoch [396/2000], Avg Train Loss: 0.4207, Avg Val Loss: 0.2807\n",
      "\n",
      "Validation loss improved from 0.2808 to 0.2807. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.1720\n",
      "Epoch [397/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2807\n",
      "\n",
      "Validation loss improved from 0.2807 to 0.2807. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.1719\n",
      "Epoch [398/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.2806\n",
      "\n",
      "Validation loss improved from 0.2807 to 0.2806. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.1719\n",
      "Epoch [399/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2806\n",
      "\n",
      "Validation loss improved from 0.2806 to 0.2806. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3892\n",
      "    Batch [2/2], Val Loss: 0.1718\n",
      "Epoch [400/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2805\n",
      "\n",
      "Validation loss improved from 0.2806 to 0.2805. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4218\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3892\n",
      "    Batch [2/2], Val Loss: 0.1717\n",
      "Epoch [401/2000], Avg Train Loss: 0.4218, Avg Val Loss: 0.2805\n",
      "\n",
      "Validation loss improved from 0.2805 to 0.2805. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3891\n",
      "    Batch [2/2], Val Loss: 0.1717\n",
      "Epoch [402/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2804\n",
      "\n",
      "Validation loss improved from 0.2805 to 0.2804. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3891\n",
      "    Batch [2/2], Val Loss: 0.1716\n",
      "Epoch [403/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2803\n",
      "\n",
      "Validation loss improved from 0.2804 to 0.2803. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3890\n",
      "    Batch [2/2], Val Loss: 0.1715\n",
      "Epoch [404/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2803\n",
      "\n",
      "Validation loss improved from 0.2803 to 0.2803. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3890\n",
      "    Batch [2/2], Val Loss: 0.1715\n",
      "Epoch [405/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2802\n",
      "\n",
      "Validation loss improved from 0.2803 to 0.2802. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3889\n",
      "    Batch [2/2], Val Loss: 0.1714\n",
      "Epoch [406/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2802\n",
      "\n",
      "Validation loss improved from 0.2802 to 0.2802. Saving model...\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4236\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3888\n",
      "    Batch [2/2], Val Loss: 0.1714\n",
      "Epoch [407/2000], Avg Train Loss: 0.4236, Avg Val Loss: 0.2801\n",
      "\n",
      "Validation loss improved from 0.2802 to 0.2801. Saving model...\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4215\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3888\n",
      "    Batch [2/2], Val Loss: 0.1714\n",
      "Epoch [408/2000], Avg Train Loss: 0.4215, Avg Val Loss: 0.2801\n",
      "\n",
      "Validation loss improved from 0.2801 to 0.2801. Saving model...\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4162\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3887\n",
      "    Batch [2/2], Val Loss: 0.1713\n",
      "Epoch [409/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2800\n",
      "\n",
      "Validation loss improved from 0.2801 to 0.2800. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3886\n",
      "    Batch [2/2], Val Loss: 0.1713\n",
      "Epoch [410/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2800\n",
      "\n",
      "Validation loss improved from 0.2800 to 0.2800. Saving model...\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4197\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3886\n",
      "    Batch [2/2], Val Loss: 0.1712\n",
      "Epoch [411/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.2799\n",
      "\n",
      "Validation loss improved from 0.2800 to 0.2799. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1712\n",
      "Epoch [412/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2799\n",
      "\n",
      "Validation loss improved from 0.2799 to 0.2799. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4158\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1712\n",
      "Epoch [413/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2798\n",
      "\n",
      "Validation loss improved from 0.2799 to 0.2798. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3884\n",
      "    Batch [2/2], Val Loss: 0.1711\n",
      "Epoch [414/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2798\n",
      "\n",
      "Validation loss improved from 0.2798 to 0.2798. Saving model...\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3884\n",
      "    Batch [2/2], Val Loss: 0.1711\n",
      "Epoch [415/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2797\n",
      "\n",
      "Validation loss improved from 0.2798 to 0.2797. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4204\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3883\n",
      "    Batch [2/2], Val Loss: 0.1711\n",
      "Epoch [416/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2797\n",
      "\n",
      "Validation loss improved from 0.2797 to 0.2797. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.1711\n",
      "Epoch [417/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2797\n",
      "\n",
      "Validation loss improved from 0.2797 to 0.2797. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [418/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2796\n",
      "\n",
      "Validation loss improved from 0.2797 to 0.2796. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3881\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [419/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2796\n",
      "\n",
      "Validation loss improved from 0.2796 to 0.2796. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4181\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3881\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [420/2000], Avg Train Loss: 0.4181, Avg Val Loss: 0.2795\n",
      "\n",
      "Validation loss improved from 0.2796 to 0.2795. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3880\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [421/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2795\n",
      "\n",
      "Validation loss improved from 0.2795 to 0.2795. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4224\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3880\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [422/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2795 to 0.2794. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3879\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [423/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2794. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4191\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3878\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [424/2000], Avg Train Loss: 0.4191, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2794. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3878\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [425/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2794. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3877\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [426/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2793\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2793. Saving model...\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4219\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3877\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [427/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2793\n",
      "\n",
      "Validation loss improved from 0.2793 to 0.2793. Saving model...\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [428/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2793\n",
      "\n",
      "Validation loss improved from 0.2793 to 0.2793. Saving model...\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4183\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3875\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [429/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2793\n",
      "\n",
      "Validation loss improved from 0.2793 to 0.2793. Saving model...\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [430/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2792\n",
      "\n",
      "Validation loss improved from 0.2793 to 0.2792. Saving model...\n",
      "LOG: Epoch [431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4177\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [431/2000], Avg Train Loss: 0.4177, Avg Val Loss: 0.2792\n",
      "\n",
      "Validation loss improved from 0.2792 to 0.2792. Saving model...\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4211\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [432/2000], Avg Train Loss: 0.4211, Avg Val Loss: 0.2791\n",
      "\n",
      "Validation loss improved from 0.2792 to 0.2791. Saving model...\n",
      "LOG: Epoch [433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [433/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2791\n",
      "\n",
      "Validation loss improved from 0.2791 to 0.2791. Saving model...\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [434/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2790\n",
      "\n",
      "Validation loss improved from 0.2791 to 0.2790. Saving model...\n",
      "LOG: Epoch [435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3870\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [435/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2790\n",
      "\n",
      "Validation loss improved from 0.2790 to 0.2790. Saving model...\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [436/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2789\n",
      "\n",
      "Validation loss improved from 0.2790 to 0.2789. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3868\n",
      "    Batch [2/2], Val Loss: 0.1709\n",
      "Epoch [437/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2789\n",
      "\n",
      "Validation loss improved from 0.2789 to 0.2789. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1708\n",
      "Epoch [438/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2788\n",
      "\n",
      "Validation loss improved from 0.2789 to 0.2788. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1707\n",
      "Epoch [439/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2787\n",
      "\n",
      "Validation loss improved from 0.2788 to 0.2787. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.1707\n",
      "Epoch [440/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2786\n",
      "\n",
      "Validation loss improved from 0.2787 to 0.2786. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4208\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.1706\n",
      "Epoch [441/2000], Avg Train Loss: 0.4208, Avg Val Loss: 0.2786\n",
      "\n",
      "Validation loss improved from 0.2786 to 0.2786. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3865\n",
      "    Batch [2/2], Val Loss: 0.1704\n",
      "Epoch [442/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2785\n",
      "\n",
      "Validation loss improved from 0.2786 to 0.2785. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3865\n",
      "    Batch [2/2], Val Loss: 0.1703\n",
      "Epoch [443/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2784\n",
      "\n",
      "Validation loss improved from 0.2785 to 0.2784. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3864\n",
      "    Batch [2/2], Val Loss: 0.1702\n",
      "Epoch [444/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2783\n",
      "\n",
      "Validation loss improved from 0.2784 to 0.2783. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4206\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3864\n",
      "    Batch [2/2], Val Loss: 0.1701\n",
      "Epoch [445/2000], Avg Train Loss: 0.4206, Avg Val Loss: 0.2782\n",
      "\n",
      "Validation loss improved from 0.2783 to 0.2782. Saving model...\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3864\n",
      "    Batch [2/2], Val Loss: 0.1699\n",
      "Epoch [446/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2781\n",
      "\n",
      "Validation loss improved from 0.2782 to 0.2781. Saving model...\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4184\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3863\n",
      "    Batch [2/2], Val Loss: 0.1698\n",
      "Epoch [447/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2781\n",
      "\n",
      "Validation loss improved from 0.2781 to 0.2781. Saving model...\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3863\n",
      "    Batch [2/2], Val Loss: 0.1697\n",
      "Epoch [448/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2780\n",
      "\n",
      "Validation loss improved from 0.2781 to 0.2780. Saving model...\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4183\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1696\n",
      "Epoch [449/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2779\n",
      "\n",
      "Validation loss improved from 0.2780 to 0.2779. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1696\n",
      "Epoch [450/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2779\n",
      "\n",
      "Validation loss improved from 0.2779 to 0.2779. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1695\n",
      "Epoch [451/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2779\n",
      "\n",
      "Validation loss improved from 0.2779 to 0.2779. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4170\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1695\n",
      "Epoch [452/2000], Avg Train Loss: 0.4170, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2779 to 0.2778. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1695\n",
      "Epoch [453/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2778. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4159\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.1694\n",
      "Epoch [454/2000], Avg Train Loss: 0.4159, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2778. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3861\n",
      "    Batch [2/2], Val Loss: 0.1694\n",
      "Epoch [455/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2778. Saving model...\n",
      "LOG: Epoch [456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3861\n",
      "    Batch [2/2], Val Loss: 0.1693\n",
      "Epoch [456/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.2777\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2777. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4151\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3860\n",
      "    Batch [2/2], Val Loss: 0.1693\n",
      "Epoch [457/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2777\n",
      "\n",
      "Validation loss improved from 0.2777 to 0.2777. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3860\n",
      "    Batch [2/2], Val Loss: 0.1693\n",
      "Epoch [458/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2777 to 0.2776. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3859\n",
      "    Batch [2/2], Val Loss: 0.1693\n",
      "Epoch [459/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2776. Saving model...\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3859\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [460/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2776. Saving model...\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3858\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [461/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2775\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2775. Saving model...\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4216\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3858\n",
      "    Batch [2/2], Val Loss: 0.1692\n",
      "Epoch [462/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.2775\n",
      "\n",
      "Validation loss improved from 0.2775 to 0.2775. Saving model...\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3857\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [463/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2774\n",
      "\n",
      "Validation loss improved from 0.2775 to 0.2774. Saving model...\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4146\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3857\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [464/2000], Avg Train Loss: 0.4146, Avg Val Loss: 0.2774\n",
      "\n",
      "Validation loss improved from 0.2774 to 0.2774. Saving model...\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4177\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3856\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [465/2000], Avg Train Loss: 0.4177, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2774 to 0.2773. Saving model...\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4154\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3856\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [466/2000], Avg Train Loss: 0.4154, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2773. Saving model...\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4144\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3856\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [467/2000], Avg Train Loss: 0.4144, Avg Val Loss: 0.2773\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3855\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [468/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2773\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3855\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [469/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2773. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4176\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3855\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [470/2000], Avg Train Loss: 0.4176, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2773. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [471/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.2772\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2772. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [472/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2772\n",
      "\n",
      "Validation loss improved from 0.2772 to 0.2772. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [473/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2772\n",
      "\n",
      "Validation loss improved from 0.2772 to 0.2772. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [474/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.2771\n",
      "\n",
      "Validation loss improved from 0.2772 to 0.2771. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4116\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [475/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2771\n",
      "\n",
      "Validation loss improved from 0.2771 to 0.2771. Saving model...\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.1689\n",
      "Epoch [476/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2771\n",
      "\n",
      "Validation loss improved from 0.2771 to 0.2771. Saving model...\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.1688\n",
      "Epoch [477/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2770\n",
      "\n",
      "Validation loss improved from 0.2771 to 0.2770. Saving model...\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4145\n",
      "LOG: Epoch [478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.1687\n",
      "Epoch [478/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.2769\n",
      "\n",
      "Validation loss improved from 0.2770 to 0.2769. Saving model...\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3851\n",
      "    Batch [2/2], Val Loss: 0.1686\n",
      "Epoch [479/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2768\n",
      "\n",
      "Validation loss improved from 0.2769 to 0.2768. Saving model...\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1685\n",
      "Epoch [480/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2768\n",
      "\n",
      "Validation loss improved from 0.2768 to 0.2768. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4142\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1685\n",
      "Epoch [481/2000], Avg Train Loss: 0.4142, Avg Val Loss: 0.2767\n",
      "\n",
      "Validation loss improved from 0.2768 to 0.2767. Saving model...\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4188\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1684\n",
      "Epoch [482/2000], Avg Train Loss: 0.4188, Avg Val Loss: 0.2767\n",
      "\n",
      "Validation loss improved from 0.2767 to 0.2767. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4181\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1683\n",
      "Epoch [483/2000], Avg Train Loss: 0.4181, Avg Val Loss: 0.2767\n",
      "\n",
      "Validation loss improved from 0.2767 to 0.2767. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4188\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1683\n",
      "Epoch [484/2000], Avg Train Loss: 0.4188, Avg Val Loss: 0.2766\n",
      "\n",
      "Validation loss improved from 0.2767 to 0.2766. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1682\n",
      "Epoch [485/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2766\n",
      "\n",
      "Validation loss improved from 0.2766 to 0.2766. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [486/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2766\n",
      "\n",
      "Validation loss improved from 0.2766 to 0.2766. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [487/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2766 to 0.2765. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3849\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [488/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2765. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3849\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [489/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2765. Saving model...\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3849\n",
      "    Batch [2/2], Val Loss: 0.1682\n",
      "Epoch [490/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2765\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3849\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [491/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2765. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3848\n",
      "    Batch [2/2], Val Loss: 0.1682\n",
      "Epoch [492/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2765. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4197\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3848\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [493/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2765. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4151\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3848\n",
      "    Batch [2/2], Val Loss: 0.1681\n",
      "Epoch [494/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2764\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2764. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3847\n",
      "    Batch [2/2], Val Loss: 0.1680\n",
      "Epoch [495/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2764\n",
      "\n",
      "Validation loss improved from 0.2764 to 0.2764. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3847\n",
      "    Batch [2/2], Val Loss: 0.1679\n",
      "Epoch [496/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2763\n",
      "\n",
      "Validation loss improved from 0.2764 to 0.2763. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3846\n",
      "    Batch [2/2], Val Loss: 0.1679\n",
      "Epoch [497/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2763\n",
      "\n",
      "Validation loss improved from 0.2763 to 0.2763. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4179\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3846\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [498/2000], Avg Train Loss: 0.4179, Avg Val Loss: 0.2762\n",
      "\n",
      "Validation loss improved from 0.2763 to 0.2762. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3845\n",
      "    Batch [2/2], Val Loss: 0.1678\n",
      "Epoch [499/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2761\n",
      "\n",
      "Validation loss improved from 0.2762 to 0.2761. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.1677\n",
      "Epoch [500/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2761\n",
      "\n",
      "Validation loss improved from 0.2761 to 0.2761. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.1677\n",
      "Epoch [501/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2761 to 0.2760. Saving model...\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4201\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.1677\n",
      "Epoch [502/2000], Avg Train Loss: 0.4201, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2760. Saving model...\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4175\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.1676\n",
      "Epoch [503/2000], Avg Train Loss: 0.4175, Avg Val Loss: 0.2759\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2759. Saving model...\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3841\n",
      "    Batch [2/2], Val Loss: 0.1676\n",
      "Epoch [504/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2759\n",
      "\n",
      "Validation loss improved from 0.2759 to 0.2759. Saving model...\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3841\n",
      "    Batch [2/2], Val Loss: 0.1676\n",
      "Epoch [505/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2758\n",
      "\n",
      "Validation loss improved from 0.2759 to 0.2758. Saving model...\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3841\n",
      "    Batch [2/2], Val Loss: 0.1675\n",
      "Epoch [506/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2758\n",
      "\n",
      "Validation loss improved from 0.2758 to 0.2758. Saving model...\n",
      "LOG: Epoch [507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3840\n",
      "    Batch [2/2], Val Loss: 0.1674\n",
      "Epoch [507/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2757\n",
      "\n",
      "Validation loss improved from 0.2758 to 0.2757. Saving model...\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3840\n",
      "    Batch [2/2], Val Loss: 0.1673\n",
      "Epoch [508/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2756\n",
      "\n",
      "Validation loss improved from 0.2757 to 0.2756. Saving model...\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1673\n",
      "Epoch [509/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2756\n",
      "\n",
      "Validation loss improved from 0.2756 to 0.2756. Saving model...\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1672\n",
      "Epoch [510/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2755\n",
      "\n",
      "Validation loss improved from 0.2756 to 0.2755. Saving model...\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1671\n",
      "Epoch [511/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2755\n",
      "\n",
      "Validation loss improved from 0.2755 to 0.2755. Saving model...\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1670\n",
      "Epoch [512/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2755 to 0.2754. Saving model...\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4145\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1670\n",
      "Epoch [513/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2754. Saving model...\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1670\n",
      "Epoch [514/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2754. Saving model...\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4137\n",
      "LOG: Epoch [515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1669\n",
      "Epoch [515/2000], Avg Train Loss: 0.4137, Avg Val Loss: 0.2753\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2753. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4178\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1669\n",
      "Epoch [516/2000], Avg Train Loss: 0.4178, Avg Val Loss: 0.2753\n",
      "\n",
      "Validation loss improved from 0.2753 to 0.2753. Saving model...\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4142\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1668\n",
      "Epoch [517/2000], Avg Train Loss: 0.4142, Avg Val Loss: 0.2753\n",
      "\n",
      "Validation loss improved from 0.2753 to 0.2753. Saving model...\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4124\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1668\n",
      "Epoch [518/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2753 to 0.2752. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1667\n",
      "Epoch [519/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2752. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1667\n",
      "Epoch [520/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2752. Saving model...\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4146\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1666\n",
      "Epoch [521/2000], Avg Train Loss: 0.4146, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2752. Saving model...\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4162\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1665\n",
      "Epoch [522/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2752. Saving model...\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1664\n",
      "Epoch [523/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2751. Saving model...\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1663\n",
      "Epoch [524/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2751. Saving model...\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1662\n",
      "Epoch [525/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2750\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2750. Saving model...\n",
      "LOG: Epoch [526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1662\n",
      "Epoch [526/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2750\n",
      "\n",
      "Validation loss improved from 0.2750 to 0.2750. Saving model...\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4124\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [527/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2750\n",
      "\n",
      "Validation loss improved from 0.2750 to 0.2750. Saving model...\n",
      "LOG: Epoch [528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3838\n",
      "    Batch [2/2], Val Loss: 0.1661\n",
      "Epoch [528/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2749\n",
      "\n",
      "Validation loss improved from 0.2750 to 0.2749. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1660\n",
      "Epoch [529/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2749\n",
      "\n",
      "Validation loss improved from 0.2749 to 0.2749. Saving model...\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1659\n",
      "Epoch [530/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2748\n",
      "\n",
      "Validation loss improved from 0.2749 to 0.2748. Saving model...\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.1658\n",
      "Epoch [531/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2747\n",
      "\n",
      "Validation loss improved from 0.2748 to 0.2747. Saving model...\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3836\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [532/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2747\n",
      "\n",
      "Validation loss improved from 0.2747 to 0.2747. Saving model...\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4107\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3836\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [533/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2747 to 0.2746. Saving model...\n",
      "LOG: Epoch [534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4146\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3836\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [534/2000], Avg Train Loss: 0.4146, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2746. Saving model...\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3835\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [535/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2745\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2745. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3834\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [536/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2744\n",
      "\n",
      "Validation loss improved from 0.2745 to 0.2744. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3833\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [537/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2744\n",
      "\n",
      "Validation loss improved from 0.2744 to 0.2744. Saving model...\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3831\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [538/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2744 to 0.2743. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3830\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [539/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2742. Saving model...\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3829\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [540/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2742. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3828\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [541/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2741\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2741. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4121\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3827\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [542/2000], Avg Train Loss: 0.4121, Avg Val Loss: 0.2741\n",
      "\n",
      "Validation loss improved from 0.2741 to 0.2741. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4166\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3826\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [543/2000], Avg Train Loss: 0.4166, Avg Val Loss: 0.2740\n",
      "\n",
      "Validation loss improved from 0.2741 to 0.2740. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3825\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [544/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2740\n",
      "\n",
      "Validation loss improved from 0.2740 to 0.2740. Saving model...\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3824\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [545/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2740\n",
      "\n",
      "Validation loss improved from 0.2740 to 0.2740. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3823\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [546/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2739\n",
      "\n",
      "Validation loss improved from 0.2740 to 0.2739. Saving model...\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4161\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3823\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [547/2000], Avg Train Loss: 0.4161, Avg Val Loss: 0.2739\n",
      "\n",
      "Validation loss improved from 0.2739 to 0.2739. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3822\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [548/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2739\n",
      "\n",
      "Validation loss improved from 0.2739 to 0.2739. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4115\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3821\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [549/2000], Avg Train Loss: 0.4115, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2739 to 0.2738. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3820\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [550/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2738. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3819\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [551/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2738. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3818\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [552/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2738. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4177\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3818\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [553/2000], Avg Train Loss: 0.4177, Avg Val Loss: 0.2737\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2737. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3817\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [554/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2737\n",
      "\n",
      "Validation loss improved from 0.2737 to 0.2737. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3816\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [555/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2737\n",
      "\n",
      "Validation loss improved from 0.2737 to 0.2737. Saving model...\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3816\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [556/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2736\n",
      "\n",
      "Validation loss improved from 0.2737 to 0.2736. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3815\n",
      "    Batch [2/2], Val Loss: 0.1657\n",
      "Epoch [557/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2736\n",
      "\n",
      "Validation loss improved from 0.2736 to 0.2736. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3814\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [558/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2736 to 0.2735. Saving model...\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3814\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [559/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4149\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3814\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [560/2000], Avg Train Loss: 0.4149, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4149\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1656\n",
      "Epoch [561/2000], Avg Train Loss: 0.4149, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1655\n",
      "Epoch [562/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2734\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2734. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4118\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1654\n",
      "Epoch [563/2000], Avg Train Loss: 0.4118, Avg Val Loss: 0.2733\n",
      "\n",
      "Validation loss improved from 0.2734 to 0.2733. Saving model...\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1653\n",
      "Epoch [564/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2733\n",
      "\n",
      "Validation loss improved from 0.2733 to 0.2733. Saving model...\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [565/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2733\n",
      "\n",
      "Validation loss improved from 0.2733 to 0.2733. Saving model...\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4122\n",
      "LOG: Epoch [566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [566/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2733 to 0.2732. Saving model...\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [567/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2732. Saving model...\n",
      "LOG: Epoch [568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3812\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [568/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2732. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3812\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [569/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2732. Saving model...\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3811\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [570/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2731. Saving model...\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3811\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [571/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2731. Saving model...\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3810\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [572/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2731. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3810\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [573/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2731. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [574/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2731. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4122\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [575/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2730\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2730. Saving model...\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4154\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1652\n",
      "Epoch [576/2000], Avg Train Loss: 0.4154, Avg Val Loss: 0.2730\n",
      "\n",
      "Validation loss improved from 0.2730 to 0.2730. Saving model...\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4133\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [577/2000], Avg Train Loss: 0.4133, Avg Val Loss: 0.2730\n",
      "\n",
      "Validation loss improved from 0.2730 to 0.2730. Saving model...\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4156\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1650\n",
      "Epoch [578/2000], Avg Train Loss: 0.4156, Avg Val Loss: 0.2729\n",
      "\n",
      "Validation loss improved from 0.2730 to 0.2729. Saving model...\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1649\n",
      "Epoch [579/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2728\n",
      "\n",
      "Validation loss improved from 0.2729 to 0.2728. Saving model...\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1648\n",
      "Epoch [580/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2728 to 0.2727. Saving model...\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1648\n",
      "Epoch [581/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2727. Saving model...\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1647\n",
      "Epoch [582/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2726\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2726. Saving model...\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1646\n",
      "Epoch [583/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2726\n",
      "\n",
      "Validation loss improved from 0.2726 to 0.2726. Saving model...\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1646\n",
      "Epoch [584/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2726\n",
      "\n",
      "Validation loss improved from 0.2726 to 0.2726. Saving model...\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1645\n",
      "Epoch [585/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2726 to 0.2725. Saving model...\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1644\n",
      "Epoch [586/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2725. Saving model...\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1643\n",
      "Epoch [587/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2725. Saving model...\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4098\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1642\n",
      "Epoch [588/2000], Avg Train Loss: 0.4098, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2724. Saving model...\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4122\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1641\n",
      "Epoch [589/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2724. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1640\n",
      "Epoch [590/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2724. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1639\n",
      "Epoch [591/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2724. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4107\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1638\n",
      "Epoch [592/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2723. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [593/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2723. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4139\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [594/2000], Avg Train Loss: 0.4139, Avg Val Loss: 0.2722\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2722. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [595/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2722\n",
      "\n",
      "Validation loss improved from 0.2722 to 0.2722. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [596/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2721\n",
      "\n",
      "Validation loss improved from 0.2722 to 0.2721. Saving model...\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [597/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2721\n",
      "\n",
      "Validation loss improved from 0.2721 to 0.2721. Saving model...\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [598/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2721\n",
      "\n",
      "Validation loss improved from 0.2721 to 0.2721. Saving model...\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3805\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [599/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2720\n",
      "\n",
      "Validation loss improved from 0.2721 to 0.2720. Saving model...\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3805\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [600/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2720\n",
      "\n",
      "Validation loss improved from 0.2720 to 0.2720. Saving model...\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3804\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [601/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2719\n",
      "\n",
      "Validation loss improved from 0.2720 to 0.2719. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3803\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [602/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2719\n",
      "\n",
      "Validation loss improved from 0.2719 to 0.2719. Saving model...\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [603/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2718\n",
      "\n",
      "Validation loss improved from 0.2719 to 0.2718. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [604/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2718\n",
      "\n",
      "Validation loss improved from 0.2718 to 0.2718. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [605/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2718\n",
      "\n",
      "Validation loss improved from 0.2718 to 0.2718. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [606/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2718 to 0.2717. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [607/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2717. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4088\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3797\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [608/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2717. Saving model...\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3796\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [609/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2717. Saving model...\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3796\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [610/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2716\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2716. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3795\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [611/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2716\n",
      "\n",
      "Validation loss improved from 0.2716 to 0.2716. Saving model...\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3794\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [612/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2715\n",
      "\n",
      "Validation loss improved from 0.2716 to 0.2715. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3793\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [613/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2715\n",
      "\n",
      "Validation loss improved from 0.2715 to 0.2715. Saving model...\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3792\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [614/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2714\n",
      "\n",
      "Validation loss improved from 0.2715 to 0.2714. Saving model...\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3792\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [615/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2714\n",
      "\n",
      "Validation loss improved from 0.2714 to 0.2714. Saving model...\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3791\n",
      "    Batch [2/2], Val Loss: 0.1636\n",
      "Epoch [616/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2713\n",
      "\n",
      "Validation loss improved from 0.2714 to 0.2713. Saving model...\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3791\n",
      "    Batch [2/2], Val Loss: 0.1635\n",
      "Epoch [617/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2713\n",
      "\n",
      "Validation loss improved from 0.2713 to 0.2713. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1634\n",
      "Epoch [618/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2712\n",
      "\n",
      "Validation loss improved from 0.2713 to 0.2712. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4111\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1633\n",
      "Epoch [619/2000], Avg Train Loss: 0.4111, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2712 to 0.2711. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1632\n",
      "Epoch [620/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2711. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1631\n",
      "Epoch [621/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2711. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1630\n",
      "Epoch [622/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2710\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2710. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1629\n",
      "Epoch [623/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2710 to 0.2709. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1628\n",
      "Epoch [624/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2709. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1626\n",
      "Epoch [625/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2708\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2708. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1625\n",
      "Epoch [626/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2708\n",
      "\n",
      "Validation loss improved from 0.2708 to 0.2708. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [627/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2707\n",
      "\n",
      "Validation loss improved from 0.2708 to 0.2707. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1622\n",
      "Epoch [628/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2706\n",
      "\n",
      "Validation loss improved from 0.2707 to 0.2706. Saving model...\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1622\n",
      "Epoch [629/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2706\n",
      "\n",
      "Validation loss improved from 0.2706 to 0.2706. Saving model...\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.1621\n",
      "Epoch [630/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2706 to 0.2705. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3789\n",
      "    Batch [2/2], Val Loss: 0.1620\n",
      "Epoch [631/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2705. Saving model...\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3788\n",
      "    Batch [2/2], Val Loss: 0.1620\n",
      "Epoch [632/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2704\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2704. Saving model...\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3788\n",
      "    Batch [2/2], Val Loss: 0.1620\n",
      "Epoch [633/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2704\n",
      "\n",
      "Validation loss improved from 0.2704 to 0.2704. Saving model...\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4107\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.1619\n",
      "Epoch [634/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2703\n",
      "\n",
      "Validation loss improved from 0.2704 to 0.2703. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3786\n",
      "    Batch [2/2], Val Loss: 0.1619\n",
      "Epoch [635/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2702\n",
      "\n",
      "Validation loss improved from 0.2703 to 0.2702. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1618\n",
      "Epoch [636/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2702\n",
      "\n",
      "Validation loss improved from 0.2702 to 0.2702. Saving model...\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4124\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.1618\n",
      "Epoch [637/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2701\n",
      "\n",
      "Validation loss improved from 0.2702 to 0.2701. Saving model...\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3784\n",
      "    Batch [2/2], Val Loss: 0.1617\n",
      "Epoch [638/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2701\n",
      "\n",
      "Validation loss improved from 0.2701 to 0.2701. Saving model...\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3784\n",
      "    Batch [2/2], Val Loss: 0.1617\n",
      "Epoch [639/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2700\n",
      "\n",
      "Validation loss improved from 0.2701 to 0.2700. Saving model...\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1616\n",
      "Epoch [640/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2699\n",
      "\n",
      "Validation loss improved from 0.2700 to 0.2699. Saving model...\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1615\n",
      "Epoch [641/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2699\n",
      "\n",
      "Validation loss improved from 0.2699 to 0.2699. Saving model...\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1614\n",
      "Epoch [642/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2698\n",
      "\n",
      "Validation loss improved from 0.2699 to 0.2698. Saving model...\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [643/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2698\n",
      "\n",
      "Validation loss improved from 0.2698 to 0.2698. Saving model...\n",
      "LOG: Epoch [644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [644/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2698\n",
      "\n",
      "Validation loss improved from 0.2698 to 0.2698. Saving model...\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [645/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2698 to 0.2697. Saving model...\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [646/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2697. Saving model...\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [647/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2697. Saving model...\n",
      "LOG: Epoch [648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4080\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [648/2000], Avg Train Loss: 0.4080, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2697. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1613\n",
      "Epoch [649/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2697\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4112\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1612\n",
      "Epoch [650/2000], Avg Train Loss: 0.4112, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2697. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1611\n",
      "Epoch [651/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2697. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1610\n",
      "Epoch [652/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2696\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2696. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1609\n",
      "Epoch [653/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2696\n",
      "\n",
      "Validation loss improved from 0.2696 to 0.2696. Saving model...\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1608\n",
      "Epoch [654/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2695\n",
      "\n",
      "Validation loss improved from 0.2696 to 0.2695. Saving model...\n",
      "LOG: Epoch [655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1607\n",
      "Epoch [655/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2695\n",
      "\n",
      "Validation loss improved from 0.2695 to 0.2695. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3783\n",
      "    Batch [2/2], Val Loss: 0.1607\n",
      "Epoch [656/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2695\n",
      "\n",
      "Validation loss improved from 0.2695 to 0.2695. Saving model...\n",
      "LOG: Epoch [657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1606\n",
      "Epoch [657/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2694\n",
      "\n",
      "Validation loss improved from 0.2695 to 0.2694. Saving model...\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.1605\n",
      "Epoch [658/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2693\n",
      "\n",
      "Validation loss improved from 0.2694 to 0.2693. Saving model...\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3781\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [659/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2693\n",
      "\n",
      "Validation loss improved from 0.2693 to 0.2693. Saving model...\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3781\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [660/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2692\n",
      "\n",
      "Validation loss improved from 0.2693 to 0.2692. Saving model...\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3780\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [661/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2692\n",
      "\n",
      "Validation loss improved from 0.2692 to 0.2692. Saving model...\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3780\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [662/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2692 to 0.2691. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3780\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [663/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2691. Saving model...\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [664/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2691. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [665/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2691. Saving model...\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [666/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2691. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [667/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2691. Saving model...\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.1603\n",
      "Epoch [668/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2690\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2690. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.1602\n",
      "Epoch [669/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2690\n",
      "\n",
      "Validation loss improved from 0.2690 to 0.2690. Saving model...\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3777\n",
      "    Batch [2/2], Val Loss: 0.1602\n",
      "Epoch [670/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2690 to 0.2689. Saving model...\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3777\n",
      "    Batch [2/2], Val Loss: 0.1601\n",
      "Epoch [671/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2689. Saving model...\n",
      "LOG: Epoch [672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3776\n",
      "    Batch [2/2], Val Loss: 0.1600\n",
      "Epoch [672/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2688\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2688. Saving model...\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3775\n",
      "    Batch [2/2], Val Loss: 0.1599\n",
      "Epoch [673/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2687\n",
      "\n",
      "Validation loss improved from 0.2688 to 0.2687. Saving model...\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3775\n",
      "    Batch [2/2], Val Loss: 0.1598\n",
      "Epoch [674/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2686\n",
      "\n",
      "Validation loss improved from 0.2687 to 0.2686. Saving model...\n",
      "LOG: Epoch [675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3774\n",
      "    Batch [2/2], Val Loss: 0.1597\n",
      "Epoch [675/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2685\n",
      "\n",
      "Validation loss improved from 0.2686 to 0.2685. Saving model...\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3774\n",
      "    Batch [2/2], Val Loss: 0.1596\n",
      "Epoch [676/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2685\n",
      "\n",
      "Validation loss improved from 0.2685 to 0.2685. Saving model...\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.1594\n",
      "Epoch [677/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2684\n",
      "\n",
      "Validation loss improved from 0.2685 to 0.2684. Saving model...\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.1593\n",
      "Epoch [678/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2683\n",
      "\n",
      "Validation loss improved from 0.2684 to 0.2683. Saving model...\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.1591\n",
      "Epoch [679/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2682\n",
      "\n",
      "Validation loss improved from 0.2683 to 0.2682. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.1589\n",
      "Epoch [680/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2681\n",
      "\n",
      "Validation loss improved from 0.2682 to 0.2681. Saving model...\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.1588\n",
      "Epoch [681/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2680\n",
      "\n",
      "Validation loss improved from 0.2681 to 0.2680. Saving model...\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3772\n",
      "    Batch [2/2], Val Loss: 0.1587\n",
      "Epoch [682/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2680\n",
      "\n",
      "Validation loss improved from 0.2680 to 0.2680. Saving model...\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3772\n",
      "    Batch [2/2], Val Loss: 0.1586\n",
      "Epoch [683/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2679\n",
      "\n",
      "Validation loss improved from 0.2680 to 0.2679. Saving model...\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3770\n",
      "    Batch [2/2], Val Loss: 0.1586\n",
      "Epoch [684/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2678\n",
      "\n",
      "Validation loss improved from 0.2679 to 0.2678. Saving model...\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3770\n",
      "    Batch [2/2], Val Loss: 0.1586\n",
      "Epoch [685/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2678\n",
      "\n",
      "Validation loss improved from 0.2678 to 0.2678. Saving model...\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3769\n",
      "    Batch [2/2], Val Loss: 0.1586\n",
      "Epoch [686/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2678 to 0.2677. Saving model...\n",
      "LOG: Epoch [687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3768\n",
      "    Batch [2/2], Val Loss: 0.1585\n",
      "Epoch [687/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2677. Saving model...\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3767\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [688/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2676\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2676. Saving model...\n",
      "LOG: Epoch [689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3767\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [689/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2675\n",
      "\n",
      "Validation loss improved from 0.2676 to 0.2675. Saving model...\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3766\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [690/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2675\n",
      "\n",
      "Validation loss improved from 0.2675 to 0.2675. Saving model...\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [691/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2674\n",
      "\n",
      "Validation loss improved from 0.2675 to 0.2674. Saving model...\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [692/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2674\n",
      "\n",
      "Validation loss improved from 0.2674 to 0.2674. Saving model...\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [693/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2674 to 0.2673. Saving model...\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [694/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [695/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [696/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2673\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [697/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2673\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [698/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [699/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [700/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [701/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [702/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2672\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2672. Saving model...\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [703/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2672\n",
      "\n",
      "Validation loss improved from 0.2672 to 0.2672. Saving model...\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [704/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2672\n",
      "\n",
      "Validation loss improved from 0.2672 to 0.2672. Saving model...\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1580\n",
      "Epoch [705/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2672\n",
      "\n",
      "Validation loss improved from 0.2672 to 0.2672. Saving model...\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.1580\n",
      "Epoch [706/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2671\n",
      "\n",
      "Validation loss improved from 0.2672 to 0.2671. Saving model...\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [707/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2671 to 0.2670. Saving model...\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [708/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2670. Saving model...\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [709/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2669\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2669. Saving model...\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3758\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [710/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2669\n",
      "\n",
      "Validation loss improved from 0.2669 to 0.2669. Saving model...\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [711/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2668\n",
      "\n",
      "Validation loss improved from 0.2669 to 0.2668. Saving model...\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3756\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [712/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2667\n",
      "\n",
      "Validation loss improved from 0.2668 to 0.2667. Saving model...\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3755\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [713/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2667\n",
      "\n",
      "Validation loss improved from 0.2667 to 0.2667. Saving model...\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3754\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [714/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2667\n",
      "\n",
      "Validation loss improved from 0.2667 to 0.2667. Saving model...\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [715/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2667 to 0.2666. Saving model...\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.1580\n",
      "Epoch [716/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3752\n",
      "    Batch [2/2], Val Loss: 0.1580\n",
      "Epoch [717/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3751\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [718/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3750\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [719/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3750\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [720/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [721/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [722/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [723/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [724/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [725/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.1584\n",
      "Epoch [726/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [727/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [728/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2665. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [729/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [730/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [731/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [732/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [733/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [734/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.1582\n",
      "Epoch [735/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2664. Saving model...\n",
      "LOG: Epoch [736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3746\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [736/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2664. Saving model...\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3746\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [737/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2664. Saving model...\n",
      "LOG: Epoch [738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3745\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [738/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2663\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2663. Saving model...\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3745\n",
      "    Batch [2/2], Val Loss: 0.1581\n",
      "Epoch [739/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2663\n",
      "\n",
      "Validation loss improved from 0.2663 to 0.2663. Saving model...\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1580\n",
      "Epoch [740/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2662\n",
      "\n",
      "Validation loss improved from 0.2663 to 0.2662. Saving model...\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [741/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2662 to 0.2661. Saving model...\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3743\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [742/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2661. Saving model...\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [743/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2661. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1579\n",
      "Epoch [744/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2660. Saving model...\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [745/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2660. Saving model...\n",
      "LOG: Epoch [746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [746/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2659\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2659. Saving model...\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3739\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [747/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2659\n",
      "\n",
      "Validation loss improved from 0.2659 to 0.2659. Saving model...\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3739\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [748/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2658\n",
      "\n",
      "Validation loss improved from 0.2659 to 0.2658. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3738\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [749/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2658\n",
      "\n",
      "Validation loss improved from 0.2658 to 0.2658. Saving model...\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3738\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [750/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2658\n",
      "\n",
      "Validation loss improved from 0.2658 to 0.2658. Saving model...\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3737\n",
      "    Batch [2/2], Val Loss: 0.1578\n",
      "Epoch [751/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2658\n",
      "\n",
      "Validation loss improved from 0.2658 to 0.2658. Saving model...\n",
      "LOG: Epoch [752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3737\n",
      "    Batch [2/2], Val Loss: 0.1577\n",
      "Epoch [752/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2657\n",
      "\n",
      "Validation loss improved from 0.2658 to 0.2657. Saving model...\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3736\n",
      "    Batch [2/2], Val Loss: 0.1577\n",
      "Epoch [753/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2657\n",
      "\n",
      "Validation loss improved from 0.2657 to 0.2657. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3736\n",
      "    Batch [2/2], Val Loss: 0.1576\n",
      "Epoch [754/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2656\n",
      "\n",
      "Validation loss improved from 0.2657 to 0.2656. Saving model...\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3735\n",
      "    Batch [2/2], Val Loss: 0.1574\n",
      "Epoch [755/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2655\n",
      "\n",
      "Validation loss improved from 0.2656 to 0.2655. Saving model...\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3735\n",
      "    Batch [2/2], Val Loss: 0.1573\n",
      "Epoch [756/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2654\n",
      "\n",
      "Validation loss improved from 0.2655 to 0.2654. Saving model...\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3734\n",
      "    Batch [2/2], Val Loss: 0.1572\n",
      "Epoch [757/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2653\n",
      "\n",
      "Validation loss improved from 0.2654 to 0.2653. Saving model...\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3734\n",
      "    Batch [2/2], Val Loss: 0.1571\n",
      "Epoch [758/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2652\n",
      "\n",
      "Validation loss improved from 0.2653 to 0.2652. Saving model...\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3733\n",
      "    Batch [2/2], Val Loss: 0.1570\n",
      "Epoch [759/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2651\n",
      "\n",
      "Validation loss improved from 0.2652 to 0.2651. Saving model...\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3732\n",
      "    Batch [2/2], Val Loss: 0.1569\n",
      "Epoch [760/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2651\n",
      "\n",
      "Validation loss improved from 0.2651 to 0.2651. Saving model...\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3732\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [761/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2650\n",
      "\n",
      "Validation loss improved from 0.2651 to 0.2650. Saving model...\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3731\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [762/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2649\n",
      "\n",
      "Validation loss improved from 0.2650 to 0.2649. Saving model...\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3731\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [763/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2648\n",
      "\n",
      "Validation loss improved from 0.2649 to 0.2648. Saving model...\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1565\n",
      "Epoch [764/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2648\n",
      "\n",
      "Validation loss improved from 0.2648 to 0.2648. Saving model...\n",
      "LOG: Epoch [765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [765/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2647\n",
      "\n",
      "Validation loss improved from 0.2648 to 0.2647. Saving model...\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [766/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2647\n",
      "\n",
      "Validation loss improved from 0.2647 to 0.2647. Saving model...\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [767/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2647\n",
      "\n",
      "Validation loss improved from 0.2647 to 0.2647. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [768/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2647\n",
      "\n",
      "Validation loss improved from 0.2647 to 0.2647. Saving model...\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [769/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2647 to 0.2646. Saving model...\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [770/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2646. Saving model...\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.1565\n",
      "Epoch [771/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2646\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.1565\n",
      "Epoch [772/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [773/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [774/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [775/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [776/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1568\n",
      "Epoch [777/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1568\n",
      "Epoch [778/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2648\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1568\n",
      "Epoch [779/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2648\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.1568\n",
      "Epoch [780/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2648\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.1568\n",
      "Epoch [781/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2648\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1568\n",
      "Epoch [782/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2648\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [783/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.1567\n",
      "Epoch [784/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2647\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3726\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [785/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2646. Saving model...\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3726\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [786/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2646. Saving model...\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [787/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2646. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [788/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2645. Saving model...\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [789/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2645\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3724\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [790/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2645. Saving model...\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3724\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [791/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2645. Saving model...\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3723\n",
      "    Batch [2/2], Val Loss: 0.1566\n",
      "Epoch [792/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2645. Saving model...\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3723\n",
      "    Batch [2/2], Val Loss: 0.1565\n",
      "Epoch [793/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2644. Saving model...\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3723\n",
      "    Batch [2/2], Val Loss: 0.1565\n",
      "Epoch [794/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2644. Saving model...\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3722\n",
      "    Batch [2/2], Val Loss: 0.1565\n",
      "Epoch [795/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2644. Saving model...\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3722\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [796/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2643\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2643. Saving model...\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3722\n",
      "    Batch [2/2], Val Loss: 0.1564\n",
      "Epoch [797/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2643\n",
      "\n",
      "Validation loss improved from 0.2643 to 0.2643. Saving model...\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.1563\n",
      "Epoch [798/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2642\n",
      "\n",
      "Validation loss improved from 0.2643 to 0.2642. Saving model...\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.1562\n",
      "Epoch [799/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2642\n",
      "\n",
      "Validation loss improved from 0.2642 to 0.2642. Saving model...\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.1561\n",
      "Epoch [800/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2641\n",
      "\n",
      "Validation loss improved from 0.2642 to 0.2641. Saving model...\n",
      "LOG: Epoch [801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.1560\n",
      "Epoch [801/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2640\n",
      "\n",
      "Validation loss improved from 0.2641 to 0.2640. Saving model...\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3720\n",
      "    Batch [2/2], Val Loss: 0.1559\n",
      "Epoch [802/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2640\n",
      "\n",
      "Validation loss improved from 0.2640 to 0.2640. Saving model...\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3720\n",
      "    Batch [2/2], Val Loss: 0.1559\n",
      "Epoch [803/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2639\n",
      "\n",
      "Validation loss improved from 0.2640 to 0.2639. Saving model...\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1558\n",
      "Epoch [804/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2639\n",
      "\n",
      "Validation loss improved from 0.2639 to 0.2639. Saving model...\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1558\n",
      "Epoch [805/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2639 to 0.2638. Saving model...\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1557\n",
      "Epoch [806/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2638. Saving model...\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [807/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2638. Saving model...\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [808/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2638. Saving model...\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [809/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2638. Saving model...\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [810/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2638. Saving model...\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3719\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [811/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2637\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2637. Saving model...\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3718\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [812/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2637\n",
      "\n",
      "Validation loss improved from 0.2637 to 0.2637. Saving model...\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3717\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [813/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2636\n",
      "\n",
      "Validation loss improved from 0.2637 to 0.2636. Saving model...\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3715\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [814/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2636\n",
      "\n",
      "Validation loss improved from 0.2636 to 0.2636. Saving model...\n",
      "LOG: Epoch [815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3714\n",
      "    Batch [2/2], Val Loss: 0.1556\n",
      "Epoch [815/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2635\n",
      "\n",
      "Validation loss improved from 0.2636 to 0.2635. Saving model...\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3714\n",
      "    Batch [2/2], Val Loss: 0.1555\n",
      "Epoch [816/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2635 to 0.2634. Saving model...\n",
      "LOG: Epoch [817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1554\n",
      "Epoch [817/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.1553\n",
      "Epoch [818/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2633\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2633. Saving model...\n",
      "LOG: Epoch [819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3712\n",
      "    Batch [2/2], Val Loss: 0.1552\n",
      "Epoch [819/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2633 to 0.2632. Saving model...\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3712\n",
      "    Batch [2/2], Val Loss: 0.1551\n",
      "Epoch [820/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3712\n",
      "    Batch [2/2], Val Loss: 0.1551\n",
      "Epoch [821/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2631. Saving model...\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3711\n",
      "    Batch [2/2], Val Loss: 0.1550\n",
      "Epoch [822/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2631. Saving model...\n",
      "LOG: Epoch [823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3711\n",
      "    Batch [2/2], Val Loss: 0.1549\n",
      "Epoch [823/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2630\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2630. Saving model...\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3710\n",
      "    Batch [2/2], Val Loss: 0.1549\n",
      "Epoch [824/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2630\n",
      "\n",
      "Validation loss improved from 0.2630 to 0.2630. Saving model...\n",
      "LOG: Epoch [825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3710\n",
      "    Batch [2/2], Val Loss: 0.1548\n",
      "Epoch [825/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2629\n",
      "\n",
      "Validation loss improved from 0.2630 to 0.2629. Saving model...\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3709\n",
      "    Batch [2/2], Val Loss: 0.1548\n",
      "Epoch [826/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2629 to 0.2628. Saving model...\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3709\n",
      "    Batch [2/2], Val Loss: 0.1547\n",
      "Epoch [827/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2628. Saving model...\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3979\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3709\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [828/2000], Avg Train Loss: 0.3979, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2627. Saving model...\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3708\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [829/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2627. Saving model...\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3708\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [830/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2627. Saving model...\n",
      "LOG: Epoch [831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3707\n",
      "    Batch [2/2], Val Loss: 0.1545\n",
      "Epoch [831/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2626. Saving model...\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3707\n",
      "    Batch [2/2], Val Loss: 0.1545\n",
      "Epoch [832/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2626. Saving model...\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3706\n",
      "    Batch [2/2], Val Loss: 0.1545\n",
      "Epoch [833/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2626. Saving model...\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3706\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [834/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2626. Saving model...\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3705\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [835/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2626. Saving model...\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3705\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [836/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2625. Saving model...\n",
      "LOG: Epoch [837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1547\n",
      "Epoch [837/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2626\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1547\n",
      "Epoch [838/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2626\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [839/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2625. Saving model...\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [840/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2625. Saving model...\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3703\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [841/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2625. Saving model...\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3703\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [842/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2624. Saving model...\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [843/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2624. Saving model...\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1545\n",
      "Epoch [844/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2624. Saving model...\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.1545\n",
      "Epoch [845/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2623. Saving model...\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.1544\n",
      "Epoch [846/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2623. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.1544\n",
      "Epoch [847/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2623. Saving model...\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.1544\n",
      "Epoch [848/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2622\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2622. Saving model...\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.1543\n",
      "Epoch [849/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2622\n",
      "\n",
      "Validation loss improved from 0.2622 to 0.2622. Saving model...\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.1542\n",
      "Epoch [850/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2621\n",
      "\n",
      "Validation loss improved from 0.2622 to 0.2621. Saving model...\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.1542\n",
      "Epoch [851/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2620\n",
      "\n",
      "Validation loss improved from 0.2621 to 0.2620. Saving model...\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.1540\n",
      "Epoch [852/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2619\n",
      "\n",
      "Validation loss improved from 0.2620 to 0.2619. Saving model...\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3697\n",
      "    Batch [2/2], Val Loss: 0.1539\n",
      "Epoch [853/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2618\n",
      "\n",
      "Validation loss improved from 0.2619 to 0.2618. Saving model...\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3697\n",
      "    Batch [2/2], Val Loss: 0.1538\n",
      "Epoch [854/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2617\n",
      "\n",
      "Validation loss improved from 0.2618 to 0.2617. Saving model...\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.1537\n",
      "Epoch [855/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2617\n",
      "\n",
      "Validation loss improved from 0.2617 to 0.2617. Saving model...\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.1537\n",
      "Epoch [856/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2616\n",
      "\n",
      "Validation loss improved from 0.2617 to 0.2616. Saving model...\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3695\n",
      "    Batch [2/2], Val Loss: 0.1536\n",
      "Epoch [857/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2616\n",
      "\n",
      "Validation loss improved from 0.2616 to 0.2616. Saving model...\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3695\n",
      "    Batch [2/2], Val Loss: 0.1536\n",
      "Epoch [858/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2615\n",
      "\n",
      "Validation loss improved from 0.2616 to 0.2615. Saving model...\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3694\n",
      "    Batch [2/2], Val Loss: 0.1535\n",
      "Epoch [859/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2615\n",
      "\n",
      "Validation loss improved from 0.2615 to 0.2615. Saving model...\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3693\n",
      "    Batch [2/2], Val Loss: 0.1534\n",
      "Epoch [860/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2615 to 0.2614. Saving model...\n",
      "LOG: Epoch [861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3693\n",
      "    Batch [2/2], Val Loss: 0.1534\n",
      "Epoch [861/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2613\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2613. Saving model...\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3692\n",
      "    Batch [2/2], Val Loss: 0.1533\n",
      "Epoch [862/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2613\n",
      "\n",
      "Validation loss improved from 0.2613 to 0.2613. Saving model...\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3692\n",
      "    Batch [2/2], Val Loss: 0.1532\n",
      "Epoch [863/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2612\n",
      "\n",
      "Validation loss improved from 0.2613 to 0.2612. Saving model...\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3691\n",
      "    Batch [2/2], Val Loss: 0.1532\n",
      "Epoch [864/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2612\n",
      "\n",
      "Validation loss improved from 0.2612 to 0.2612. Saving model...\n",
      "LOG: Epoch [865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3691\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [865/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2611\n",
      "\n",
      "Validation loss improved from 0.2612 to 0.2611. Saving model...\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3690\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [866/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2611\n",
      "\n",
      "Validation loss improved from 0.2611 to 0.2611. Saving model...\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3690\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [867/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2610\n",
      "\n",
      "Validation loss improved from 0.2611 to 0.2610. Saving model...\n",
      "LOG: Epoch [868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3689\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [868/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2610\n",
      "\n",
      "Validation loss improved from 0.2610 to 0.2610. Saving model...\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3689\n",
      "    Batch [2/2], Val Loss: 0.1531\n",
      "Epoch [869/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2610\n",
      "\n",
      "Validation loss improved from 0.2610 to 0.2610. Saving model...\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3689\n",
      "    Batch [2/2], Val Loss: 0.1530\n",
      "Epoch [870/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2610\n",
      "\n",
      "Validation loss improved from 0.2610 to 0.2610. Saving model...\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3688\n",
      "    Batch [2/2], Val Loss: 0.1530\n",
      "Epoch [871/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2609\n",
      "\n",
      "Validation loss improved from 0.2610 to 0.2609. Saving model...\n",
      "LOG: Epoch [872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3688\n",
      "    Batch [2/2], Val Loss: 0.1529\n",
      "Epoch [872/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2609\n",
      "\n",
      "Validation loss improved from 0.2609 to 0.2609. Saving model...\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3688\n",
      "    Batch [2/2], Val Loss: 0.1529\n",
      "Epoch [873/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2609 to 0.2608. Saving model...\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.1528\n",
      "Epoch [874/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2607\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2607. Saving model...\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.1527\n",
      "Epoch [875/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2607\n",
      "\n",
      "Validation loss improved from 0.2607 to 0.2607. Saving model...\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.1526\n",
      "Epoch [876/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2606\n",
      "\n",
      "Validation loss improved from 0.2607 to 0.2606. Saving model...\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.1526\n",
      "Epoch [877/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2606\n",
      "\n",
      "Validation loss improved from 0.2606 to 0.2606. Saving model...\n",
      "LOG: Epoch [878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3686\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [878/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2606\n",
      "\n",
      "Validation loss improved from 0.2606 to 0.2606. Saving model...\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3686\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [879/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2606\n",
      "\n",
      "Validation loss improved from 0.2606 to 0.2606. Saving model...\n",
      "LOG: Epoch [880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3686\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [880/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2606 to 0.2605. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3685\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [881/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2605. Saving model...\n",
      "LOG: Epoch [882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [882/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2604. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [883/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [884/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [885/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2603. Saving model...\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3682\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [886/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [887/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [888/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [889/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [890/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3682\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [891/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [892/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [893/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [894/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2602. Saving model...\n",
      "LOG: Epoch [895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3958\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3680\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [895/2000], Avg Train Loss: 0.3958, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3680\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [896/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [897/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [898/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [899/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2601. Saving model...\n",
      "LOG: Epoch [900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [900/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2601. Saving model...\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [901/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2601. Saving model...\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [902/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2601. Saving model...\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.1523\n",
      "Epoch [903/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2600. Saving model...\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.1523\n",
      "Epoch [904/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2600. Saving model...\n",
      "LOG: Epoch [905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [905/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2599\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2599. Saving model...\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3676\n",
      "    Batch [2/2], Val Loss: 0.1521\n",
      "Epoch [906/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2599\n",
      "\n",
      "Validation loss improved from 0.2599 to 0.2599. Saving model...\n",
      "LOG: Epoch [907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3676\n",
      "    Batch [2/2], Val Loss: 0.1520\n",
      "Epoch [907/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2599 to 0.2598. Saving model...\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3675\n",
      "    Batch [2/2], Val Loss: 0.1519\n",
      "Epoch [908/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2597. Saving model...\n",
      "LOG: Epoch [909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3675\n",
      "    Batch [2/2], Val Loss: 0.1518\n",
      "Epoch [909/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2597. Saving model...\n",
      "LOG: Epoch [910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3674\n",
      "    Batch [2/2], Val Loss: 0.1517\n",
      "Epoch [910/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2596\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2596. Saving model...\n",
      "LOG: Epoch [911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3673\n",
      "    Batch [2/2], Val Loss: 0.1516\n",
      "Epoch [911/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2595\n",
      "\n",
      "Validation loss improved from 0.2596 to 0.2595. Saving model...\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3673\n",
      "    Batch [2/2], Val Loss: 0.1515\n",
      "Epoch [912/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2594\n",
      "\n",
      "Validation loss improved from 0.2595 to 0.2594. Saving model...\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3672\n",
      "    Batch [2/2], Val Loss: 0.1514\n",
      "Epoch [913/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2593\n",
      "\n",
      "Validation loss improved from 0.2594 to 0.2593. Saving model...\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3671\n",
      "    Batch [2/2], Val Loss: 0.1513\n",
      "Epoch [914/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2593 to 0.2592. Saving model...\n",
      "LOG: Epoch [915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3670\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [915/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2591\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2591. Saving model...\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3958\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3669\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [916/2000], Avg Train Loss: 0.3958, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2591 to 0.2590. Saving model...\n",
      "LOG: Epoch [917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3668\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [917/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2590. Saving model...\n",
      "LOG: Epoch [918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3667\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [918/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2590. Saving model...\n",
      "LOG: Epoch [919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3667\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [919/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2589. Saving model...\n",
      "LOG: Epoch [920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3666\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [920/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2589. Saving model...\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3666\n",
      "    Batch [2/2], Val Loss: 0.1512\n",
      "Epoch [921/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2589. Saving model...\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3665\n",
      "    Batch [2/2], Val Loss: 0.1511\n",
      "Epoch [922/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2588. Saving model...\n",
      "LOG: Epoch [923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1511\n",
      "Epoch [923/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2588. Saving model...\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1511\n",
      "Epoch [924/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2587. Saving model...\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [925/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2587. Saving model...\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [926/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2586. Saving model...\n",
      "LOG: Epoch [927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3662\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [927/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2586. Saving model...\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [928/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2585. Saving model...\n",
      "LOG: Epoch [929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [929/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2585. Saving model...\n",
      "LOG: Epoch [930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3659\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [930/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2585. Saving model...\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [931/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2584. Saving model...\n",
      "LOG: Epoch [932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [932/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2583\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2583. Saving model...\n",
      "LOG: Epoch [933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1509\n",
      "Epoch [933/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2582\n",
      "\n",
      "Validation loss improved from 0.2583 to 0.2582. Saving model...\n",
      "LOG: Epoch [934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1508\n",
      "Epoch [934/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2582\n",
      "\n",
      "Validation loss improved from 0.2582 to 0.2582. Saving model...\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.1506\n",
      "Epoch [935/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2582 to 0.2581. Saving model...\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.1505\n",
      "Epoch [936/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2580. Saving model...\n",
      "LOG: Epoch [937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1504\n",
      "Epoch [937/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2580. Saving model...\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1503\n",
      "Epoch [938/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2579. Saving model...\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3858\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1502\n",
      "Epoch [939/2000], Avg Train Loss: 0.3858, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2579. Saving model...\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1502\n",
      "Epoch [940/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2579. Saving model...\n",
      "LOG: Epoch [941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3863\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1501\n",
      "Epoch [941/2000], Avg Train Loss: 0.3863, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2579. Saving model...\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1500\n",
      "Epoch [942/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2578. Saving model...\n",
      "LOG: Epoch [943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1500\n",
      "Epoch [943/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1499\n",
      "Epoch [944/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1499\n",
      "Epoch [945/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [946/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3860\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [947/2000], Avg Train Loss: 0.3860, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [948/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [949/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2577\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2577. Saving model...\n",
      "LOG: Epoch [950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [950/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2577\n",
      "\n",
      "Validation loss improved from 0.2577 to 0.2577. Saving model...\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [951/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2577 to 0.2576. Saving model...\n",
      "LOG: Epoch [952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.1497\n",
      "Epoch [952/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2576. Saving model...\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3653\n",
      "    Batch [2/2], Val Loss: 0.1496\n",
      "Epoch [953/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2575\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2575. Saving model...\n",
      "LOG: Epoch [954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3652\n",
      "    Batch [2/2], Val Loss: 0.1495\n",
      "Epoch [954/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2574\n",
      "\n",
      "Validation loss improved from 0.2575 to 0.2574. Saving model...\n",
      "LOG: Epoch [955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3651\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [955/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2573\n",
      "\n",
      "Validation loss improved from 0.2574 to 0.2573. Saving model...\n",
      "LOG: Epoch [956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3650\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [956/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2572\n",
      "\n",
      "Validation loss improved from 0.2573 to 0.2572. Saving model...\n",
      "LOG: Epoch [957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3650\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [957/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2571\n",
      "\n",
      "Validation loss improved from 0.2572 to 0.2571. Saving model...\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3649\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [958/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2571\n",
      "\n",
      "Validation loss improved from 0.2571 to 0.2571. Saving model...\n",
      "LOG: Epoch [959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3649\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [959/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2571 to 0.2570. Saving model...\n",
      "LOG: Epoch [960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [960/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [961/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3647\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [962/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3647\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [963/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2570\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3646\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [964/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3645\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [965/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3644\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [966/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2569. Saving model...\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3644\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [967/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2569. Saving model...\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [968/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2569. Saving model...\n",
      "LOG: Epoch [969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [969/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2568. Saving model...\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3870\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3642\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [970/2000], Avg Train Loss: 0.3870, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2568. Saving model...\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3642\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [971/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2567\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2567. Saving model...\n",
      "LOG: Epoch [972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3641\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [972/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2566\n",
      "\n",
      "Validation loss improved from 0.2567 to 0.2566. Saving model...\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [973/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2566\n",
      "\n",
      "Validation loss improved from 0.2566 to 0.2566. Saving model...\n",
      "LOG: Epoch [974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [974/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2566 to 0.2565. Saving model...\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [975/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2564. Saving model...\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3638\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [976/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2564. Saving model...\n",
      "LOG: Epoch [977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [977/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2563. Saving model...\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1489\n",
      "Epoch [978/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2563. Saving model...\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [979/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2563. Saving model...\n",
      "LOG: Epoch [980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [980/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2563. Saving model...\n",
      "LOG: Epoch [981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [981/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [982/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3634\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [983/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3634\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [984/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3634\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [985/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [986/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [987/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.1493\n",
      "Epoch [988/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [989/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2562\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2562. Saving model...\n",
      "LOG: Epoch [990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [990/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2562\n",
      "\n",
      "Validation loss improved from 0.2562 to 0.2562. Saving model...\n",
      "LOG: Epoch [991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [991/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2561\n",
      "\n",
      "Validation loss improved from 0.2562 to 0.2561. Saving model...\n",
      "LOG: Epoch [992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1491\n",
      "Epoch [992/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2561\n",
      "\n",
      "Validation loss improved from 0.2561 to 0.2561. Saving model...\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [993/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2560\n",
      "\n",
      "Validation loss improved from 0.2561 to 0.2560. Saving model...\n",
      "LOG: Epoch [994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1490\n",
      "Epoch [994/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2560\n",
      "\n",
      "Validation loss improved from 0.2560 to 0.2560. Saving model...\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1489\n",
      "Epoch [995/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2560\n",
      "\n",
      "Validation loss improved from 0.2560 to 0.2560. Saving model...\n",
      "LOG: Epoch [996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.1488\n",
      "Epoch [996/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2559\n",
      "\n",
      "Validation loss improved from 0.2560 to 0.2559. Saving model...\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.1487\n",
      "Epoch [997/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2559 to 0.2558. Saving model...\n",
      "LOG: Epoch [998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1486\n",
      "Epoch [998/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2558. Saving model...\n",
      "LOG: Epoch [999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1484\n",
      "Epoch [999/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2557. Saving model...\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3870\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1483\n",
      "Epoch [1000/2000], Avg Train Loss: 0.3870, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2557. Saving model...\n",
      "LOG: Epoch [1001/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1482\n",
      "Epoch [1001/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2556. Saving model...\n",
      "LOG: Epoch [1002/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1481\n",
      "Epoch [1002/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2556. Saving model...\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1481\n",
      "Epoch [1003/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2556. Saving model...\n",
      "LOG: Epoch [1004/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1480\n",
      "Epoch [1004/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2556. Saving model...\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3850\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1480\n",
      "Epoch [1005/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2556. Saving model...\n",
      "LOG: Epoch [1006/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.1479\n",
      "Epoch [1006/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2555. Saving model...\n",
      "LOG: Epoch [1007/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1007/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1479\n",
      "Epoch [1007/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2555. Saving model...\n",
      "LOG: Epoch [1008/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.1479\n",
      "Epoch [1008/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2554. Saving model...\n",
      "LOG: Epoch [1009/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1009/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.1479\n",
      "Epoch [1009/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2554. Saving model...\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.1478\n",
      "Epoch [1010/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2553. Saving model...\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3845\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [1011/2000], Avg Train Loss: 0.3845, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [1012/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2552. Saving model...\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1013/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1014/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2551. Saving model...\n",
      "LOG: Epoch [1015/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1015/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1016/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3626\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1016/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [1017/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3626\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1017/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2550. Saving model...\n",
      "LOG: Epoch [1018/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1018/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3851\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1019/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [1020/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1020/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3862\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1021/2000], Avg Train Loss: 0.3862, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2549. Saving model...\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3870\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1022/2000], Avg Train Loss: 0.3870, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [1023/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1023/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [1024/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1024/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2548. Saving model...\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1025/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [1026/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3827\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [1026/2000], Avg Train Loss: 0.3827, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2547. Saving model...\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3845\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [1027/2000], Avg Train Loss: 0.3845, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [1028/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3850\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3621\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [1028/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3621\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1029/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1030/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1031/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2546. Saving model...\n",
      "LOG: Epoch [1032/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3826\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [1032/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3839\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1033/2000], Avg Train Loss: 0.3839, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [1034/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3827\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3618\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1034/2000], Avg Train Loss: 0.3827, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2545. Saving model...\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1035/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [1036/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1036/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2544. Saving model...\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3868\n",
      "LOG: Epoch [1037/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1037/2000], Avg Train Loss: 0.3868, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [1038/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3850\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1038/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [1039/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3855\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1039/2000], Avg Train Loss: 0.3855, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2543. Saving model...\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3826\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1040/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1041/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3845\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1041/2000], Avg Train Loss: 0.3845, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1042/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3873\n",
      "LOG: Epoch [1042/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1042/2000], Avg Train Loss: 0.3873, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1043/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3846\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1043/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1044/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3842\n",
      "LOG: Epoch [1044/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [1044/2000], Avg Train Loss: 0.3842, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1045/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3870\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [1045/2000], Avg Train Loss: 0.3870, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2542. Saving model...\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.1477\n",
      "Epoch [1046/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1047/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1048/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3838\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1048/2000], Avg Train Loss: 0.3838, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.1476\n",
      "Epoch [1049/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2541. Saving model...\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3861\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1050/2000], Avg Train Loss: 0.3861, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3856\n",
      "LOG: Epoch [1051/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [1051/2000], Avg Train Loss: 0.3856, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2540. Saving model...\n",
      "LOG: Epoch [1052/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3861\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1052/2000], Avg Train Loss: 0.3861, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2539. Saving model...\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3851\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1053/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2539. Saving model...\n",
      "LOG: Epoch [1054/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1054/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2539. Saving model...\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1055/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2538\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2538. Saving model...\n",
      "LOG: Epoch [1056/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3601\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1056/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2538\n",
      "\n",
      "Validation loss improved from 0.2538 to 0.2538. Saving model...\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3601\n",
      "    Batch [2/2], Val Loss: 0.1474\n",
      "Epoch [1057/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2538\n",
      "\n",
      "Validation loss improved from 0.2538 to 0.2538. Saving model...\n",
      "LOG: Epoch [1058/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3824\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3601\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1058/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.2537\n",
      "\n",
      "Validation loss improved from 0.2538 to 0.2537. Saving model...\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3866\n",
      "LOG: Epoch [1059/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3601\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [1059/2000], Avg Train Loss: 0.3866, Avg Val Loss: 0.2537\n",
      "\n",
      "Validation loss improved from 0.2537 to 0.2537. Saving model...\n",
      "LOG: Epoch [1060/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3601\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [1060/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2536\n",
      "\n",
      "Validation loss improved from 0.2537 to 0.2536. Saving model...\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3817\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3601\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [1061/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.2536\n",
      "\n",
      "Validation loss improved from 0.2536 to 0.2536. Saving model...\n",
      "LOG: Epoch [1062/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3600\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [1062/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2536 to 0.2535. Saving model...\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3857\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3600\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [1063/2000], Avg Train Loss: 0.3857, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2535. Saving model...\n",
      "LOG: Epoch [1064/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3599\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [1064/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2535. Saving model...\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3849\n",
      "LOG: Epoch [1065/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3598\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [1065/2000], Avg Train Loss: 0.3849, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2535. Saving model...\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3863\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3598\n",
      "    Batch [2/2], Val Loss: 0.1471\n",
      "Epoch [1066/2000], Avg Train Loss: 0.3863, Avg Val Loss: 0.2534\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2534. Saving model...\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3597\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [1067/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2534\n",
      "\n",
      "Validation loss improved from 0.2534 to 0.2534. Saving model...\n",
      "LOG: Epoch [1068/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3864\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3597\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [1068/2000], Avg Train Loss: 0.3864, Avg Val Loss: 0.2533\n",
      "\n",
      "Validation loss improved from 0.2534 to 0.2533. Saving model...\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3846\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3597\n",
      "    Batch [2/2], Val Loss: 0.1470\n",
      "Epoch [1069/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2533\n",
      "\n",
      "Validation loss improved from 0.2533 to 0.2533. Saving model...\n",
      "LOG: Epoch [1070/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3839\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [1070/2000], Avg Train Loss: 0.3839, Avg Val Loss: 0.2533\n",
      "\n",
      "Validation loss improved from 0.2533 to 0.2533. Saving model...\n",
      "LOG: Epoch [1071/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3856\n",
      "LOG: Epoch [1071/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [1071/2000], Avg Train Loss: 0.3856, Avg Val Loss: 0.2532\n",
      "\n",
      "Validation loss improved from 0.2533 to 0.2532. Saving model...\n",
      "LOG: Epoch [1072/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3863\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1469\n",
      "Epoch [1072/2000], Avg Train Loss: 0.3863, Avg Val Loss: 0.2532\n",
      "\n",
      "Validation loss improved from 0.2532 to 0.2532. Saving model...\n",
      "LOG: Epoch [1073/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3596\n",
      "    Batch [2/2], Val Loss: 0.1468\n",
      "Epoch [1073/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2532\n",
      "\n",
      "Validation loss improved from 0.2532 to 0.2532. Saving model...\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3846\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1468\n",
      "Epoch [1074/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2531\n",
      "\n",
      "Validation loss improved from 0.2532 to 0.2531. Saving model...\n",
      "LOG: Epoch [1075/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3810\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [1075/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.2531\n",
      "\n",
      "Validation loss improved from 0.2531 to 0.2531. Saving model...\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [1076/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2531\n",
      "\n",
      "Validation loss improved from 0.2531 to 0.2531. Saving model...\n",
      "LOG: Epoch [1077/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1467\n",
      "Epoch [1077/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2531 to 0.2530. Saving model...\n",
      "LOG: Epoch [1078/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3808\n",
      "LOG: Epoch [1078/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1466\n",
      "Epoch [1078/2000], Avg Train Loss: 0.3808, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2530. Saving model...\n",
      "LOG: Epoch [1079/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1466\n",
      "Epoch [1079/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2530. Saving model...\n",
      "LOG: Epoch [1080/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3834\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1465\n",
      "Epoch [1080/2000], Avg Train Loss: 0.3834, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2529. Saving model...\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3839\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1465\n",
      "Epoch [1081/2000], Avg Train Loss: 0.3839, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2529. Saving model...\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3838\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1464\n",
      "Epoch [1082/2000], Avg Train Loss: 0.3838, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2529. Saving model...\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3813\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1083/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2529. Saving model...\n",
      "LOG: Epoch [1084/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3832\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1084/2000], Avg Train Loss: 0.3832, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2529. Saving model...\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1462\n",
      "Epoch [1085/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1086/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1086/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3859\n",
      "LOG: Epoch [1087/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1087/2000], Avg Train Loss: 0.3859, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1088/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3862\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1088/2000], Avg Train Loss: 0.3862, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1089/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3850\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1089/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1090/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3824\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1091/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3826\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1092/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1093/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3865\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1093/2000], Avg Train Loss: 0.3865, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3863\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1463\n",
      "Epoch [1094/2000], Avg Train Loss: 0.3863, Avg Val Loss: 0.2529\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1095/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1462\n",
      "Epoch [1095/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2528\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2528. Saving model...\n",
      "LOG: Epoch [1096/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3806\n",
      "LOG: Epoch [1096/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1461\n",
      "Epoch [1096/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2528\n",
      "\n",
      "Validation loss improved from 0.2528 to 0.2528. Saving model...\n",
      "LOG: Epoch [1097/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3831\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1459\n",
      "Epoch [1097/2000], Avg Train Loss: 0.3831, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2528 to 0.2527. Saving model...\n",
      "LOG: Epoch [1098/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3833\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1458\n",
      "Epoch [1098/2000], Avg Train Loss: 0.3833, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2527. Saving model...\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3868\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1458\n",
      "Epoch [1099/2000], Avg Train Loss: 0.3868, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2527. Saving model...\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1456\n",
      "Epoch [1100/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2526\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2526. Saving model...\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3779\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1101/2000], Avg Train Loss: 0.3779, Avg Val Loss: 0.2525\n",
      "\n",
      "Validation loss improved from 0.2526 to 0.2525. Saving model...\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1102/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2525\n",
      "\n",
      "Validation loss improved from 0.2525 to 0.2525. Saving model...\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3824\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1103/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2525 to 0.2524. Saving model...\n",
      "LOG: Epoch [1104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3796\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1104/2000], Avg Train Loss: 0.3796, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2524. Saving model...\n",
      "LOG: Epoch [1105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3827\n",
      "LOG: Epoch [1105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3595\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1105/2000], Avg Train Loss: 0.3827, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2524. Saving model...\n",
      "LOG: Epoch [1106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1106/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2524. Saving model...\n",
      "LOG: Epoch [1107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3835\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3594\n",
      "    Batch [2/2], Val Loss: 0.1452\n",
      "Epoch [1107/2000], Avg Train Loss: 0.3835, Avg Val Loss: 0.2523\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2523. Saving model...\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3852\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1452\n",
      "Epoch [1108/2000], Avg Train Loss: 0.3852, Avg Val Loss: 0.2523\n",
      "\n",
      "Validation loss improved from 0.2523 to 0.2523. Saving model...\n",
      "LOG: Epoch [1109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1451\n",
      "Epoch [1109/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2522\n",
      "\n",
      "Validation loss improved from 0.2523 to 0.2522. Saving model...\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1450\n",
      "Epoch [1110/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2522\n",
      "\n",
      "Validation loss improved from 0.2522 to 0.2522. Saving model...\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3813\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3593\n",
      "    Batch [2/2], Val Loss: 0.1450\n",
      "Epoch [1111/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2521\n",
      "\n",
      "Validation loss improved from 0.2522 to 0.2521. Saving model...\n",
      "LOG: Epoch [1112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3840\n",
      "LOG: Epoch [1112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3592\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1112/2000], Avg Train Loss: 0.3840, Avg Val Loss: 0.2521\n",
      "\n",
      "Validation loss improved from 0.2521 to 0.2521. Saving model...\n",
      "LOG: Epoch [1113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3803\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3592\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1113/2000], Avg Train Loss: 0.3803, Avg Val Loss: 0.2521\n",
      "\n",
      "Validation loss improved from 0.2521 to 0.2521. Saving model...\n",
      "LOG: Epoch [1114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3853\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3592\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1114/2000], Avg Train Loss: 0.3853, Avg Val Loss: 0.2520\n",
      "\n",
      "Validation loss improved from 0.2521 to 0.2520. Saving model...\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3846\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3591\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1115/2000], Avg Train Loss: 0.3846, Avg Val Loss: 0.2520\n",
      "\n",
      "Validation loss improved from 0.2520 to 0.2520. Saving model...\n",
      "LOG: Epoch [1116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3833\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3590\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1116/2000], Avg Train Loss: 0.3833, Avg Val Loss: 0.2520\n",
      "\n",
      "Validation loss improved from 0.2520 to 0.2520. Saving model...\n",
      "LOG: Epoch [1117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3790\n",
      "LOG: Epoch [1117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3590\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1117/2000], Avg Train Loss: 0.3790, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2520 to 0.2519. Saving model...\n",
      "LOG: Epoch [1118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3808\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3589\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1118/2000], Avg Train Loss: 0.3808, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3850\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3588\n",
      "    Batch [2/2], Val Loss: 0.1450\n",
      "Epoch [1119/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3819\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3588\n",
      "    Batch [2/2], Val Loss: 0.1450\n",
      "Epoch [1120/2000], Avg Train Loss: 0.3819, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3827\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3587\n",
      "    Batch [2/2], Val Loss: 0.1451\n",
      "Epoch [1121/2000], Avg Train Loss: 0.3827, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3792\n",
      "LOG: Epoch [1122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3586\n",
      "    Batch [2/2], Val Loss: 0.1451\n",
      "Epoch [1122/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3835\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3586\n",
      "    Batch [2/2], Val Loss: 0.1452\n",
      "Epoch [1123/2000], Avg Train Loss: 0.3835, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3831\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3585\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1124/2000], Avg Train Loss: 0.3831, Avg Val Loss: 0.2519\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3832\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3585\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1125/2000], Avg Train Loss: 0.3832, Avg Val Loss: 0.2519\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3864\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3584\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1126/2000], Avg Train Loss: 0.3864, Avg Val Loss: 0.2519\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3826\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3584\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1127/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2519\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3810\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3583\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1128/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2519. Saving model...\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3821\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3582\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1129/2000], Avg Train Loss: 0.3821, Avg Val Loss: 0.2518\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2518. Saving model...\n",
      "LOG: Epoch [1130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3825\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3581\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1130/2000], Avg Train Loss: 0.3825, Avg Val Loss: 0.2518\n",
      "\n",
      "Validation loss improved from 0.2518 to 0.2518. Saving model...\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3765\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3580\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1131/2000], Avg Train Loss: 0.3765, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2518 to 0.2517. Saving model...\n",
      "LOG: Epoch [1132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3579\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1132/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2517. Saving model...\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3806\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3579\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1133/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2517. Saving model...\n",
      "LOG: Epoch [1134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3824\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3578\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1134/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.2517\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2517. Saving model...\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3821\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1135/2000], Avg Train Loss: 0.3821, Avg Val Loss: 0.2516\n",
      "\n",
      "Validation loss improved from 0.2517 to 0.2516. Saving model...\n",
      "LOG: Epoch [1136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3577\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [1136/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2516\n",
      "\n",
      "Validation loss improved from 0.2516 to 0.2516. Saving model...\n",
      "LOG: Epoch [1137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3807\n",
      "LOG: Epoch [1137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3576\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1137/2000], Avg Train Loss: 0.3807, Avg Val Loss: 0.2515\n",
      "\n",
      "Validation loss improved from 0.2516 to 0.2515. Saving model...\n",
      "LOG: Epoch [1138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3794\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3575\n",
      "    Batch [2/2], Val Loss: 0.1454\n",
      "Epoch [1138/2000], Avg Train Loss: 0.3794, Avg Val Loss: 0.2514\n",
      "\n",
      "Validation loss improved from 0.2515 to 0.2514. Saving model...\n",
      "LOG: Epoch [1139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3810\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3575\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1139/2000], Avg Train Loss: 0.3810, Avg Val Loss: 0.2514\n",
      "\n",
      "Validation loss improved from 0.2514 to 0.2514. Saving model...\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3777\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3574\n",
      "    Batch [2/2], Val Loss: 0.1453\n",
      "Epoch [1140/2000], Avg Train Loss: 0.3777, Avg Val Loss: 0.2514\n",
      "\n",
      "Validation loss improved from 0.2514 to 0.2514. Saving model...\n",
      "LOG: Epoch [1141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3840\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3574\n",
      "    Batch [2/2], Val Loss: 0.1452\n",
      "Epoch [1141/2000], Avg Train Loss: 0.3840, Avg Val Loss: 0.2513\n",
      "\n",
      "Validation loss improved from 0.2514 to 0.2513. Saving model...\n",
      "LOG: Epoch [1142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3797\n",
      "LOG: Epoch [1142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3573\n",
      "    Batch [2/2], Val Loss: 0.1451\n",
      "Epoch [1142/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2512\n",
      "\n",
      "Validation loss improved from 0.2513 to 0.2512. Saving model...\n",
      "LOG: Epoch [1143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3828\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3572\n",
      "    Batch [2/2], Val Loss: 0.1450\n",
      "Epoch [1143/2000], Avg Train Loss: 0.3828, Avg Val Loss: 0.2511\n",
      "\n",
      "Validation loss improved from 0.2512 to 0.2511. Saving model...\n",
      "LOG: Epoch [1144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [1144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3572\n",
      "    Batch [2/2], Val Loss: 0.1449\n",
      "Epoch [1144/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2510\n",
      "\n",
      "Validation loss improved from 0.2511 to 0.2510. Saving model...\n",
      "LOG: Epoch [1145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3764\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3571\n",
      "    Batch [2/2], Val Loss: 0.1448\n",
      "Epoch [1145/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2509\n",
      "\n",
      "Validation loss improved from 0.2510 to 0.2509. Saving model...\n",
      "LOG: Epoch [1146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3787\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3570\n",
      "    Batch [2/2], Val Loss: 0.1447\n",
      "Epoch [1146/2000], Avg Train Loss: 0.3787, Avg Val Loss: 0.2508\n",
      "\n",
      "Validation loss improved from 0.2509 to 0.2508. Saving model...\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3794\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3568\n",
      "    Batch [2/2], Val Loss: 0.1445\n",
      "Epoch [1147/2000], Avg Train Loss: 0.3794, Avg Val Loss: 0.2507\n",
      "\n",
      "Validation loss improved from 0.2508 to 0.2507. Saving model...\n",
      "LOG: Epoch [1148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3851\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3567\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [1148/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2505\n",
      "\n",
      "Validation loss improved from 0.2507 to 0.2505. Saving model...\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3798\n",
      "LOG: Epoch [1149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3566\n",
      "    Batch [2/2], Val Loss: 0.1442\n",
      "Epoch [1149/2000], Avg Train Loss: 0.3798, Avg Val Loss: 0.2504\n",
      "\n",
      "Validation loss improved from 0.2505 to 0.2504. Saving model...\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3800\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3566\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1150/2000], Avg Train Loss: 0.3800, Avg Val Loss: 0.2503\n",
      "\n",
      "Validation loss improved from 0.2504 to 0.2503. Saving model...\n",
      "LOG: Epoch [1151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3773\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3565\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1151/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2503\n",
      "\n",
      "Validation loss improved from 0.2503 to 0.2503. Saving model...\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3816\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3564\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1152/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.2503\n",
      "\n",
      "Validation loss improved from 0.2503 to 0.2503. Saving model...\n",
      "LOG: Epoch [1153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3808\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3564\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [1153/2000], Avg Train Loss: 0.3808, Avg Val Loss: 0.2502\n",
      "\n",
      "Validation loss improved from 0.2503 to 0.2502. Saving model...\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3563\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [1154/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2501\n",
      "\n",
      "Validation loss improved from 0.2502 to 0.2501. Saving model...\n",
      "LOG: Epoch [1155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3806\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3563\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1155/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2501\n",
      "\n",
      "Validation loss improved from 0.2501 to 0.2501. Saving model...\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3796\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3562\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1156/2000], Avg Train Loss: 0.3796, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2501 to 0.2500. Saving model...\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3786\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1157/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2500. Saving model...\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3811\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1158/2000], Avg Train Loss: 0.3811, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2500. Saving model...\n",
      "LOG: Epoch [1159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3763\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1159/2000], Avg Train Loss: 0.3763, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2500. Saving model...\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3760\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1160/2000], Avg Train Loss: 0.3760, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2499. Saving model...\n",
      "LOG: Epoch [1161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3821\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1161/2000], Avg Train Loss: 0.3821, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2499. Saving model...\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3809\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [1162/2000], Avg Train Loss: 0.3809, Avg Val Loss: 0.2499\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3848\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3558\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1163/2000], Avg Train Loss: 0.3848, Avg Val Loss: 0.2500\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3803\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3558\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1164/2000], Avg Train Loss: 0.3803, Avg Val Loss: 0.2499\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3851\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1165/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2499. Saving model...\n",
      "LOG: Epoch [1166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3791\n",
      "LOG: Epoch [1166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1441\n",
      "Epoch [1166/2000], Avg Train Loss: 0.3791, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2499. Saving model...\n",
      "LOG: Epoch [1167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3805\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [1167/2000], Avg Train Loss: 0.3805, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2499. Saving model...\n",
      "LOG: Epoch [1168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3751\n",
      "LOG: Epoch [1168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1440\n",
      "Epoch [1168/2000], Avg Train Loss: 0.3751, Avg Val Loss: 0.2498\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2498. Saving model...\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3777\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [1169/2000], Avg Train Loss: 0.3777, Avg Val Loss: 0.2498\n",
      "\n",
      "Validation loss improved from 0.2498 to 0.2498. Saving model...\n",
      "LOG: Epoch [1170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3815\n",
      "LOG: Epoch [1170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1438\n",
      "Epoch [1170/2000], Avg Train Loss: 0.3815, Avg Val Loss: 0.2497\n",
      "\n",
      "Validation loss improved from 0.2498 to 0.2497. Saving model...\n",
      "LOG: Epoch [1171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3764\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1437\n",
      "Epoch [1171/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2497\n",
      "\n",
      "Validation loss improved from 0.2497 to 0.2497. Saving model...\n",
      "LOG: Epoch [1172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3849\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3558\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [1172/2000], Avg Train Loss: 0.3849, Avg Val Loss: 0.2497\n",
      "\n",
      "Validation loss improved from 0.2497 to 0.2497. Saving model...\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3813\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [1173/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2497\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3792\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [1174/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2497\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3798\n",
      "LOG: Epoch [1175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [1175/2000], Avg Train Loss: 0.3798, Avg Val Loss: 0.2498\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3779\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [1176/2000], Avg Train Loss: 0.3779, Avg Val Loss: 0.2498\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3786\n",
      "LOG: Epoch [1177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1436\n",
      "Epoch [1177/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2498\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3816\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1435\n",
      "Epoch [1178/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.2498\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3814\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1435\n",
      "Epoch [1179/2000], Avg Train Loss: 0.3814, Avg Val Loss: 0.2498\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3817\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1433\n",
      "Epoch [1180/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.2497\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3770\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1432\n",
      "Epoch [1181/2000], Avg Train Loss: 0.3770, Avg Val Loss: 0.2497\n",
      "\n",
      "Validation loss improved from 0.2497 to 0.2497. Saving model...\n",
      "LOG: Epoch [1182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3865\n",
      "LOG: Epoch [1182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3561\n",
      "    Batch [2/2], Val Loss: 0.1432\n",
      "Epoch [1182/2000], Avg Train Loss: 0.3865, Avg Val Loss: 0.2496\n",
      "\n",
      "Validation loss improved from 0.2497 to 0.2496. Saving model...\n",
      "LOG: Epoch [1183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3746\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1431\n",
      "Epoch [1183/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.2496\n",
      "\n",
      "Validation loss improved from 0.2496 to 0.2496. Saving model...\n",
      "LOG: Epoch [1184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3739\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [1184/2000], Avg Train Loss: 0.3739, Avg Val Loss: 0.2495\n",
      "\n",
      "Validation loss improved from 0.2496 to 0.2495. Saving model...\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3814\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3560\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [1185/2000], Avg Train Loss: 0.3814, Avg Val Loss: 0.2495\n",
      "\n",
      "Validation loss improved from 0.2495 to 0.2495. Saving model...\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3752\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [1186/2000], Avg Train Loss: 0.3752, Avg Val Loss: 0.2495\n",
      "\n",
      "Validation loss improved from 0.2495 to 0.2495. Saving model...\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3769\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [1187/2000], Avg Train Loss: 0.3769, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2495 to 0.2494. Saving model...\n",
      "LOG: Epoch [1188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1430\n",
      "Epoch [1188/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2494. Saving model...\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3784\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3559\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1189/2000], Avg Train Loss: 0.3784, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2494. Saving model...\n",
      "LOG: Epoch [1190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3771\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3558\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1190/2000], Avg Train Loss: 0.3771, Avg Val Loss: 0.2494\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2494. Saving model...\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3773\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3558\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1191/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2493\n",
      "\n",
      "Validation loss improved from 0.2494 to 0.2493. Saving model...\n",
      "LOG: Epoch [1192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3849\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1192/2000], Avg Train Loss: 0.3849, Avg Val Loss: 0.2493\n",
      "\n",
      "Validation loss improved from 0.2493 to 0.2493. Saving model...\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3776\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3557\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1193/2000], Avg Train Loss: 0.3776, Avg Val Loss: 0.2493\n",
      "\n",
      "Validation loss improved from 0.2493 to 0.2493. Saving model...\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3798\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3556\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1194/2000], Avg Train Loss: 0.3798, Avg Val Loss: 0.2492\n",
      "\n",
      "Validation loss improved from 0.2493 to 0.2492. Saving model...\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3792\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3556\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1195/2000], Avg Train Loss: 0.3792, Avg Val Loss: 0.2492\n",
      "\n",
      "Validation loss improved from 0.2492 to 0.2492. Saving model...\n",
      "LOG: Epoch [1196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3741\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3555\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1196/2000], Avg Train Loss: 0.3741, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2492 to 0.2491. Saving model...\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3781\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3555\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1197/2000], Avg Train Loss: 0.3781, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2491. Saving model...\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3823\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3554\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1198/2000], Avg Train Loss: 0.3823, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2491. Saving model...\n",
      "LOG: Epoch [1199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3770\n",
      "LOG: Epoch [1199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3554\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1199/2000], Avg Train Loss: 0.3770, Avg Val Loss: 0.2491\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3771\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3553\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1200/2000], Avg Train Loss: 0.3771, Avg Val Loss: 0.2491\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3785\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3553\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1201/2000], Avg Train Loss: 0.3785, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2491. Saving model...\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3775\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3552\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1202/2000], Avg Train Loss: 0.3775, Avg Val Loss: 0.2491\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2491. Saving model...\n",
      "LOG: Epoch [1203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3806\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1203/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2490\n",
      "\n",
      "Validation loss improved from 0.2491 to 0.2490. Saving model...\n",
      "LOG: Epoch [1204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3774\n",
      "LOG: Epoch [1204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1429\n",
      "Epoch [1204/2000], Avg Train Loss: 0.3774, Avg Val Loss: 0.2490\n",
      "\n",
      "Validation loss improved from 0.2490 to 0.2490. Saving model...\n",
      "LOG: Epoch [1205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3765\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3551\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [1205/2000], Avg Train Loss: 0.3765, Avg Val Loss: 0.2489\n",
      "\n",
      "Validation loss improved from 0.2490 to 0.2489. Saving model...\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3769\n",
      "LOG: Epoch [1206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3550\n",
      "    Batch [2/2], Val Loss: 0.1427\n",
      "Epoch [1206/2000], Avg Train Loss: 0.3769, Avg Val Loss: 0.2489\n",
      "\n",
      "Validation loss improved from 0.2489 to 0.2489. Saving model...\n",
      "LOG: Epoch [1207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3549\n",
      "    Batch [2/2], Val Loss: 0.1427\n",
      "Epoch [1207/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2488\n",
      "\n",
      "Validation loss improved from 0.2489 to 0.2488. Saving model...\n",
      "LOG: Epoch [1208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3749\n",
      "LOG: Epoch [1208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3549\n",
      "    Batch [2/2], Val Loss: 0.1426\n",
      "Epoch [1208/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2487\n",
      "\n",
      "Validation loss improved from 0.2488 to 0.2487. Saving model...\n",
      "LOG: Epoch [1209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3797\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1424\n",
      "Epoch [1209/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2486\n",
      "\n",
      "Validation loss improved from 0.2487 to 0.2486. Saving model...\n",
      "LOG: Epoch [1210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3751\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1424\n",
      "Epoch [1210/2000], Avg Train Loss: 0.3751, Avg Val Loss: 0.2486\n",
      "\n",
      "Validation loss improved from 0.2486 to 0.2486. Saving model...\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1423\n",
      "Epoch [1211/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2485\n",
      "\n",
      "Validation loss improved from 0.2486 to 0.2485. Saving model...\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3793\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1422\n",
      "Epoch [1212/2000], Avg Train Loss: 0.3793, Avg Val Loss: 0.2485\n",
      "\n",
      "Validation loss improved from 0.2485 to 0.2485. Saving model...\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3763\n",
      "LOG: Epoch [1213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [1213/2000], Avg Train Loss: 0.3763, Avg Val Loss: 0.2484\n",
      "\n",
      "Validation loss improved from 0.2485 to 0.2484. Saving model...\n",
      "LOG: Epoch [1214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3784\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3548\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [1214/2000], Avg Train Loss: 0.3784, Avg Val Loss: 0.2484\n",
      "\n",
      "Validation loss improved from 0.2484 to 0.2484. Saving model...\n",
      "LOG: Epoch [1215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3753\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3547\n",
      "    Batch [2/2], Val Loss: 0.1421\n",
      "Epoch [1215/2000], Avg Train Loss: 0.3753, Avg Val Loss: 0.2484\n",
      "\n",
      "Validation loss improved from 0.2484 to 0.2484. Saving model...\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3774\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3547\n",
      "    Batch [2/2], Val Loss: 0.1420\n",
      "Epoch [1216/2000], Avg Train Loss: 0.3774, Avg Val Loss: 0.2484\n",
      "\n",
      "Validation loss improved from 0.2484 to 0.2484. Saving model...\n",
      "LOG: Epoch [1217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3797\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1420\n",
      "Epoch [1217/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2483\n",
      "\n",
      "Validation loss improved from 0.2484 to 0.2483. Saving model...\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3782\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1420\n",
      "Epoch [1218/2000], Avg Train Loss: 0.3782, Avg Val Loss: 0.2483\n",
      "\n",
      "Validation loss improved from 0.2483 to 0.2483. Saving model...\n",
      "LOG: Epoch [1219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3730\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1419\n",
      "Epoch [1219/2000], Avg Train Loss: 0.3730, Avg Val Loss: 0.2483\n",
      "\n",
      "Validation loss improved from 0.2483 to 0.2483. Saving model...\n",
      "LOG: Epoch [1220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3817\n",
      "LOG: Epoch [1220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1419\n",
      "Epoch [1220/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.2482\n",
      "\n",
      "Validation loss improved from 0.2483 to 0.2482. Saving model...\n",
      "LOG: Epoch [1221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3858\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3546\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [1221/2000], Avg Train Loss: 0.3858, Avg Val Loss: 0.2482\n",
      "\n",
      "Validation loss improved from 0.2482 to 0.2482. Saving model...\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3724\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3545\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1222/2000], Avg Train Loss: 0.3724, Avg Val Loss: 0.2481\n",
      "\n",
      "Validation loss improved from 0.2482 to 0.2481. Saving model...\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3746\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3545\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1223/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.2481\n",
      "\n",
      "Validation loss improved from 0.2481 to 0.2481. Saving model...\n",
      "LOG: Epoch [1224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3803\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1224/2000], Avg Train Loss: 0.3803, Avg Val Loss: 0.2481\n",
      "\n",
      "Validation loss improved from 0.2481 to 0.2481. Saving model...\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3756\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1225/2000], Avg Train Loss: 0.3756, Avg Val Loss: 0.2480\n",
      "\n",
      "Validation loss improved from 0.2481 to 0.2480. Saving model...\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3772\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1226/2000], Avg Train Loss: 0.3772, Avg Val Loss: 0.2480\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3793\n",
      "LOG: Epoch [1227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3544\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1227/2000], Avg Train Loss: 0.3793, Avg Val Loss: 0.2481\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3764\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3543\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [1228/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2481\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3784\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3543\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [1229/2000], Avg Train Loss: 0.3784, Avg Val Loss: 0.2480\n",
      "\n",
      "Validation loss improved from 0.2480 to 0.2480. Saving model...\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3809\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1418\n",
      "Epoch [1230/2000], Avg Train Loss: 0.3809, Avg Val Loss: 0.2480\n",
      "\n",
      "Validation loss improved from 0.2480 to 0.2480. Saving model...\n",
      "LOG: Epoch [1231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3728\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [1231/2000], Avg Train Loss: 0.3728, Avg Val Loss: 0.2479\n",
      "\n",
      "Validation loss improved from 0.2480 to 0.2479. Saving model...\n",
      "LOG: Epoch [1232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3769\n",
      "LOG: Epoch [1232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3542\n",
      "    Batch [2/2], Val Loss: 0.1416\n",
      "Epoch [1232/2000], Avg Train Loss: 0.3769, Avg Val Loss: 0.2479\n",
      "\n",
      "Validation loss improved from 0.2479 to 0.2479. Saving model...\n",
      "LOG: Epoch [1233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3771\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1415\n",
      "Epoch [1233/2000], Avg Train Loss: 0.3771, Avg Val Loss: 0.2478\n",
      "\n",
      "Validation loss improved from 0.2479 to 0.2478. Saving model...\n",
      "LOG: Epoch [1234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3752\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1415\n",
      "Epoch [1234/2000], Avg Train Loss: 0.3752, Avg Val Loss: 0.2478\n",
      "\n",
      "Validation loss improved from 0.2478 to 0.2478. Saving model...\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3775\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1415\n",
      "Epoch [1235/2000], Avg Train Loss: 0.3775, Avg Val Loss: 0.2478\n",
      "\n",
      "Validation loss improved from 0.2478 to 0.2478. Saving model...\n",
      "LOG: Epoch [1236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3762\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [1236/2000], Avg Train Loss: 0.3762, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2478 to 0.2477. Saving model...\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [1237/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2477. Saving model...\n",
      "LOG: Epoch [1238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3778\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [1238/2000], Avg Train Loss: 0.3778, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2477. Saving model...\n",
      "LOG: Epoch [1239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3764\n",
      "LOG: Epoch [1239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1413\n",
      "Epoch [1239/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2477\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2477. Saving model...\n",
      "LOG: Epoch [1240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1413\n",
      "Epoch [1240/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2476\n",
      "\n",
      "Validation loss improved from 0.2477 to 0.2476. Saving model...\n",
      "LOG: Epoch [1241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3760\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [1241/2000], Avg Train Loss: 0.3760, Avg Val Loss: 0.2476\n",
      "\n",
      "Validation loss improved from 0.2476 to 0.2476. Saving model...\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3776\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [1242/2000], Avg Train Loss: 0.3776, Avg Val Loss: 0.2475\n",
      "\n",
      "Validation loss improved from 0.2476 to 0.2475. Saving model...\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3803\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3540\n",
      "    Batch [2/2], Val Loss: 0.1409\n",
      "Epoch [1243/2000], Avg Train Loss: 0.3803, Avg Val Loss: 0.2474\n",
      "\n",
      "Validation loss improved from 0.2475 to 0.2474. Saving model...\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3789\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [1244/2000], Avg Train Loss: 0.3789, Avg Val Loss: 0.2474\n",
      "\n",
      "Validation loss improved from 0.2474 to 0.2474. Saving model...\n",
      "LOG: Epoch [1245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3761\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1408\n",
      "Epoch [1245/2000], Avg Train Loss: 0.3761, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2474 to 0.2473. Saving model...\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [1246/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2473. Saving model...\n",
      "LOG: Epoch [1247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3758\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [1247/2000], Avg Train Loss: 0.3758, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2473. Saving model...\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3771\n",
      "LOG: Epoch [1248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3539\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [1248/2000], Avg Train Loss: 0.3771, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2473. Saving model...\n",
      "LOG: Epoch [1249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3786\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3538\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [1249/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2472\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2472. Saving model...\n",
      "LOG: Epoch [1250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3755\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3538\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [1250/2000], Avg Train Loss: 0.3755, Avg Val Loss: 0.2472\n",
      "\n",
      "Validation loss improved from 0.2472 to 0.2472. Saving model...\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3774\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3537\n",
      "    Batch [2/2], Val Loss: 0.1406\n",
      "Epoch [1251/2000], Avg Train Loss: 0.3774, Avg Val Loss: 0.2472\n",
      "\n",
      "Validation loss improved from 0.2472 to 0.2472. Saving model...\n",
      "LOG: Epoch [1252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3753\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3537\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [1252/2000], Avg Train Loss: 0.3753, Avg Val Loss: 0.2471\n",
      "\n",
      "Validation loss improved from 0.2472 to 0.2471. Saving model...\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3698\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3537\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [1253/2000], Avg Train Loss: 0.3698, Avg Val Loss: 0.2471\n",
      "\n",
      "Validation loss improved from 0.2471 to 0.2471. Saving model...\n",
      "LOG: Epoch [1254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3784\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3536\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [1254/2000], Avg Train Loss: 0.3784, Avg Val Loss: 0.2470\n",
      "\n",
      "Validation loss improved from 0.2471 to 0.2470. Saving model...\n",
      "LOG: Epoch [1255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3748\n",
      "LOG: Epoch [1255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3535\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [1255/2000], Avg Train Loss: 0.3748, Avg Val Loss: 0.2470\n",
      "\n",
      "Validation loss improved from 0.2470 to 0.2470. Saving model...\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3730\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3535\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [1256/2000], Avg Train Loss: 0.3730, Avg Val Loss: 0.2469\n",
      "\n",
      "Validation loss improved from 0.2470 to 0.2469. Saving model...\n",
      "LOG: Epoch [1257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3727\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3534\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [1257/2000], Avg Train Loss: 0.3727, Avg Val Loss: 0.2469\n",
      "\n",
      "Validation loss improved from 0.2469 to 0.2469. Saving model...\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3767\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3533\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [1258/2000], Avg Train Loss: 0.3767, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2469 to 0.2468. Saving model...\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3755\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3532\n",
      "    Batch [2/2], Val Loss: 0.1404\n",
      "Epoch [1259/2000], Avg Train Loss: 0.3755, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2468. Saving model...\n",
      "LOG: Epoch [1260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3773\n",
      "LOG: Epoch [1260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3532\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1260/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2468\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2468. Saving model...\n",
      "LOG: Epoch [1261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3739\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3531\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1261/2000], Avg Train Loss: 0.3739, Avg Val Loss: 0.2467\n",
      "\n",
      "Validation loss improved from 0.2468 to 0.2467. Saving model...\n",
      "LOG: Epoch [1262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3812\n",
      "LOG: Epoch [1262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3530\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1262/2000], Avg Train Loss: 0.3812, Avg Val Loss: 0.2467\n",
      "\n",
      "Validation loss improved from 0.2467 to 0.2467. Saving model...\n",
      "LOG: Epoch [1263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3750\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3530\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1263/2000], Avg Train Loss: 0.3750, Avg Val Loss: 0.2466\n",
      "\n",
      "Validation loss improved from 0.2467 to 0.2466. Saving model...\n",
      "LOG: Epoch [1264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3759\n",
      "LOG: Epoch [1264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3529\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1264/2000], Avg Train Loss: 0.3759, Avg Val Loss: 0.2466\n",
      "\n",
      "Validation loss improved from 0.2466 to 0.2466. Saving model...\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3764\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3528\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [1265/2000], Avg Train Loss: 0.3764, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2466 to 0.2465. Saving model...\n",
      "LOG: Epoch [1266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3727\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3528\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1266/2000], Avg Train Loss: 0.3727, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2465. Saving model...\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3745\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3527\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1267/2000], Avg Train Loss: 0.3745, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2465. Saving model...\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3527\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1268/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2465. Saving model...\n",
      "LOG: Epoch [1269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3745\n",
      "LOG: Epoch [1269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3526\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1269/2000], Avg Train Loss: 0.3745, Avg Val Loss: 0.2465\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2465. Saving model...\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3746\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3526\n",
      "    Batch [2/2], Val Loss: 0.1403\n",
      "Epoch [1270/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.2464\n",
      "\n",
      "Validation loss improved from 0.2465 to 0.2464. Saving model...\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3756\n",
      "LOG: Epoch [1271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3525\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [1271/2000], Avg Train Loss: 0.3756, Avg Val Loss: 0.2464\n",
      "\n",
      "Validation loss improved from 0.2464 to 0.2464. Saving model...\n",
      "LOG: Epoch [1272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3723\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3525\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [1272/2000], Avg Train Loss: 0.3723, Avg Val Loss: 0.2463\n",
      "\n",
      "Validation loss improved from 0.2464 to 0.2463. Saving model...\n",
      "LOG: Epoch [1273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3741\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [1273/2000], Avg Train Loss: 0.3741, Avg Val Loss: 0.2463\n",
      "\n",
      "Validation loss improved from 0.2463 to 0.2463. Saving model...\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3743\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1400\n",
      "Epoch [1274/2000], Avg Train Loss: 0.3743, Avg Val Loss: 0.2462\n",
      "\n",
      "Validation loss improved from 0.2463 to 0.2462. Saving model...\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3791\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1399\n",
      "Epoch [1275/2000], Avg Train Loss: 0.3791, Avg Val Loss: 0.2462\n",
      "\n",
      "Validation loss improved from 0.2462 to 0.2462. Saving model...\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3779\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1398\n",
      "Epoch [1276/2000], Avg Train Loss: 0.3779, Avg Val Loss: 0.2461\n",
      "\n",
      "Validation loss improved from 0.2462 to 0.2461. Saving model...\n",
      "LOG: Epoch [1277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3741\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1397\n",
      "Epoch [1277/2000], Avg Train Loss: 0.3741, Avg Val Loss: 0.2461\n",
      "\n",
      "Validation loss improved from 0.2461 to 0.2461. Saving model...\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3738\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1396\n",
      "Epoch [1278/2000], Avg Train Loss: 0.3738, Avg Val Loss: 0.2460\n",
      "\n",
      "Validation loss improved from 0.2461 to 0.2460. Saving model...\n",
      "LOG: Epoch [1279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3742\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3525\n",
      "    Batch [2/2], Val Loss: 0.1394\n",
      "Epoch [1279/2000], Avg Train Loss: 0.3742, Avg Val Loss: 0.2459\n",
      "\n",
      "Validation loss improved from 0.2460 to 0.2459. Saving model...\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3760\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3525\n",
      "    Batch [2/2], Val Loss: 0.1393\n",
      "Epoch [1280/2000], Avg Train Loss: 0.3760, Avg Val Loss: 0.2459\n",
      "\n",
      "Validation loss improved from 0.2459 to 0.2459. Saving model...\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3723\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3525\n",
      "    Batch [2/2], Val Loss: 0.1392\n",
      "Epoch [1281/2000], Avg Train Loss: 0.3723, Avg Val Loss: 0.2458\n",
      "\n",
      "Validation loss improved from 0.2459 to 0.2458. Saving model...\n",
      "LOG: Epoch [1282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3748\n",
      "LOG: Epoch [1282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3525\n",
      "    Batch [2/2], Val Loss: 0.1390\n",
      "Epoch [1282/2000], Avg Train Loss: 0.3748, Avg Val Loss: 0.2457\n",
      "\n",
      "Validation loss improved from 0.2458 to 0.2457. Saving model...\n",
      "LOG: Epoch [1283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3757\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [1283/2000], Avg Train Loss: 0.3757, Avg Val Loss: 0.2456\n",
      "\n",
      "Validation loss improved from 0.2457 to 0.2456. Saving model...\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3730\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [1284/2000], Avg Train Loss: 0.3730, Avg Val Loss: 0.2455\n",
      "\n",
      "Validation loss improved from 0.2456 to 0.2455. Saving model...\n",
      "LOG: Epoch [1285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3745\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1285/2000], Avg Train Loss: 0.3745, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2455 to 0.2454. Saving model...\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3717\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1286/2000], Avg Train Loss: 0.3717, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [1287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3689\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1287/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2454. Saving model...\n",
      "LOG: Epoch [1288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3710\n",
      "LOG: Epoch [1288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3523\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1288/2000], Avg Train Loss: 0.3710, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2453. Saving model...\n",
      "LOG: Epoch [1289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3720\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3523\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1289/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2453. Saving model...\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3763\n",
      "LOG: Epoch [1290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3523\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1290/2000], Avg Train Loss: 0.3763, Avg Val Loss: 0.2453\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3717\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3522\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1291/2000], Avg Train Loss: 0.3717, Avg Val Loss: 0.2453\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3719\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3522\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1292/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2453\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3788\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3522\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1293/2000], Avg Train Loss: 0.3788, Avg Val Loss: 0.2453\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3724\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3522\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1294/2000], Avg Train Loss: 0.3724, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2453. Saving model...\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3760\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3521\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1295/2000], Avg Train Loss: 0.3760, Avg Val Loss: 0.2453\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2453. Saving model...\n",
      "LOG: Epoch [1296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3752\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3521\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1296/2000], Avg Train Loss: 0.3752, Avg Val Loss: 0.2452\n",
      "\n",
      "Validation loss improved from 0.2453 to 0.2452. Saving model...\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3749\n",
      "LOG: Epoch [1297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1297/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2452\n",
      "\n",
      "Validation loss improved from 0.2452 to 0.2452. Saving model...\n",
      "LOG: Epoch [1298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3766\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1298/2000], Avg Train Loss: 0.3766, Avg Val Loss: 0.2452\n",
      "\n",
      "Validation loss improved from 0.2452 to 0.2452. Saving model...\n",
      "LOG: Epoch [1299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3683\n",
      "LOG: Epoch [1299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1299/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2452 to 0.2451. Saving model...\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3729\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3520\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1300/2000], Avg Train Loss: 0.3729, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2451. Saving model...\n",
      "LOG: Epoch [1301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3713\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1301/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2451. Saving model...\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3689\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [1302/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2451. Saving model...\n",
      "LOG: Epoch [1303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3734\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [1303/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2451. Saving model...\n",
      "LOG: Epoch [1304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3720\n",
      "LOG: Epoch [1304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3518\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [1304/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2450. Saving model...\n",
      "LOG: Epoch [1305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3758\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3518\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [1305/2000], Avg Train Loss: 0.3758, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2450. Saving model...\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3674\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3518\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [1306/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2449\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2449. Saving model...\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3687\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3517\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1307/2000], Avg Train Loss: 0.3687, Avg Val Loss: 0.2449\n",
      "\n",
      "Validation loss improved from 0.2449 to 0.2449. Saving model...\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3683\n",
      "LOG: Epoch [1308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3517\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1308/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2448\n",
      "\n",
      "Validation loss improved from 0.2449 to 0.2448. Saving model...\n",
      "LOG: Epoch [1309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3733\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3516\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1309/2000], Avg Train Loss: 0.3733, Avg Val Loss: 0.2448\n",
      "\n",
      "Validation loss improved from 0.2448 to 0.2448. Saving model...\n",
      "LOG: Epoch [1310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3765\n",
      "LOG: Epoch [1310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3516\n",
      "    Batch [2/2], Val Loss: 0.1379\n",
      "Epoch [1310/2000], Avg Train Loss: 0.3765, Avg Val Loss: 0.2448\n",
      "\n",
      "Validation loss improved from 0.2448 to 0.2448. Saving model...\n",
      "LOG: Epoch [1311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3744\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3515\n",
      "    Batch [2/2], Val Loss: 0.1379\n",
      "Epoch [1311/2000], Avg Train Loss: 0.3744, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2448 to 0.2447. Saving model...\n",
      "LOG: Epoch [1312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3756\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1312/2000], Avg Train Loss: 0.3756, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2447. Saving model...\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3717\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1313/2000], Avg Train Loss: 0.3717, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2447. Saving model...\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3687\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3512\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [1314/2000], Avg Train Loss: 0.3687, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2447. Saving model...\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3700\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3511\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [1315/2000], Avg Train Loss: 0.3700, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2447. Saving model...\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3728\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3510\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1316/2000], Avg Train Loss: 0.3728, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2446. Saving model...\n",
      "LOG: Epoch [1317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3509\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1317/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2446. Saving model...\n",
      "LOG: Epoch [1318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3734\n",
      "LOG: Epoch [1318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3509\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1318/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2446. Saving model...\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3713\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1319/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2446\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3720\n",
      "LOG: Epoch [1320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3508\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1320/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2446\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3749\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [1321/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3736\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3507\n",
      "    Batch [2/2], Val Loss: 0.1387\n",
      "Epoch [1322/2000], Avg Train Loss: 0.3736, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3506\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [1323/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3734\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3506\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [1324/2000], Avg Train Loss: 0.3734, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3722\n",
      "LOG: Epoch [1325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [1325/2000], Avg Train Loss: 0.3722, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3699\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1387\n",
      "Epoch [1326/2000], Avg Train Loss: 0.3699, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2446. Saving model...\n",
      "LOG: Epoch [1327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3811\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3504\n",
      "    Batch [2/2], Val Loss: 0.1387\n",
      "Epoch [1327/2000], Avg Train Loss: 0.3811, Avg Val Loss: 0.2446\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2446. Saving model...\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3727\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3504\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [1328/2000], Avg Train Loss: 0.3727, Avg Val Loss: 0.2445\n",
      "\n",
      "Validation loss improved from 0.2446 to 0.2445. Saving model...\n",
      "LOG: Epoch [1329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3735\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3503\n",
      "    Batch [2/2], Val Loss: 0.1386\n",
      "Epoch [1329/2000], Avg Train Loss: 0.3735, Avg Val Loss: 0.2445\n",
      "\n",
      "Validation loss improved from 0.2445 to 0.2445. Saving model...\n",
      "LOG: Epoch [1330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3737\n",
      "LOG: Epoch [1330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3503\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1330/2000], Avg Train Loss: 0.3737, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2445 to 0.2444. Saving model...\n",
      "LOG: Epoch [1331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3697\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3502\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [1331/2000], Avg Train Loss: 0.3697, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2444. Saving model...\n",
      "LOG: Epoch [1332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3719\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3502\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [1332/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2443\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2443. Saving model...\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3741\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3502\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1333/2000], Avg Train Loss: 0.3741, Avg Val Loss: 0.2443\n",
      "\n",
      "Validation loss improved from 0.2443 to 0.2443. Saving model...\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3700\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3501\n",
      "    Batch [2/2], Val Loss: 0.1383\n",
      "Epoch [1334/2000], Avg Train Loss: 0.3700, Avg Val Loss: 0.2442\n",
      "\n",
      "Validation loss improved from 0.2443 to 0.2442. Saving model...\n",
      "LOG: Epoch [1335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3737\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3501\n",
      "    Batch [2/2], Val Loss: 0.1382\n",
      "Epoch [1335/2000], Avg Train Loss: 0.3737, Avg Val Loss: 0.2441\n",
      "\n",
      "Validation loss improved from 0.2442 to 0.2441. Saving model...\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3715\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3500\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [1336/2000], Avg Train Loss: 0.3715, Avg Val Loss: 0.2441\n",
      "\n",
      "Validation loss improved from 0.2441 to 0.2441. Saving model...\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3698\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3499\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1337/2000], Avg Train Loss: 0.3698, Avg Val Loss: 0.2440\n",
      "\n",
      "Validation loss improved from 0.2441 to 0.2440. Saving model...\n",
      "LOG: Epoch [1338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3710\n",
      "LOG: Epoch [1338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3499\n",
      "    Batch [2/2], Val Loss: 0.1380\n",
      "Epoch [1338/2000], Avg Train Loss: 0.3710, Avg Val Loss: 0.2439\n",
      "\n",
      "Validation loss improved from 0.2440 to 0.2439. Saving model...\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3688\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3498\n",
      "    Batch [2/2], Val Loss: 0.1379\n",
      "Epoch [1339/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.2439\n",
      "\n",
      "Validation loss improved from 0.2439 to 0.2439. Saving model...\n",
      "LOG: Epoch [1340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3679\n",
      "LOG: Epoch [1340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3498\n",
      "    Batch [2/2], Val Loss: 0.1379\n",
      "Epoch [1340/2000], Avg Train Loss: 0.3679, Avg Val Loss: 0.2438\n",
      "\n",
      "Validation loss improved from 0.2439 to 0.2438. Saving model...\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3497\n",
      "    Batch [2/2], Val Loss: 0.1378\n",
      "Epoch [1341/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2438\n",
      "\n",
      "Validation loss improved from 0.2438 to 0.2438. Saving model...\n",
      "LOG: Epoch [1342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3695\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3496\n",
      "    Batch [2/2], Val Loss: 0.1378\n",
      "Epoch [1342/2000], Avg Train Loss: 0.3695, Avg Val Loss: 0.2437\n",
      "\n",
      "Validation loss improved from 0.2438 to 0.2437. Saving model...\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3750\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3496\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1343/2000], Avg Train Loss: 0.3750, Avg Val Loss: 0.2436\n",
      "\n",
      "Validation loss improved from 0.2437 to 0.2436. Saving model...\n",
      "LOG: Epoch [1344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3683\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3495\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1344/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2436\n",
      "\n",
      "Validation loss improved from 0.2436 to 0.2436. Saving model...\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3705\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3494\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1345/2000], Avg Train Loss: 0.3705, Avg Val Loss: 0.2436\n",
      "\n",
      "Validation loss improved from 0.2436 to 0.2436. Saving model...\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3720\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3494\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1346/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2435\n",
      "\n",
      "Validation loss improved from 0.2436 to 0.2435. Saving model...\n",
      "LOG: Epoch [1347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3708\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3494\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1347/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2435\n",
      "\n",
      "Validation loss improved from 0.2435 to 0.2435. Saving model...\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3784\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3493\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1348/2000], Avg Train Loss: 0.3784, Avg Val Loss: 0.2435\n",
      "\n",
      "Validation loss improved from 0.2435 to 0.2435. Saving model...\n",
      "LOG: Epoch [1349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3680\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3493\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1349/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2435\n",
      "\n",
      "Validation loss improved from 0.2435 to 0.2435. Saving model...\n",
      "LOG: Epoch [1350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3701\n",
      "LOG: Epoch [1350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3492\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1350/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2435\n",
      "\n",
      "Validation loss improved from 0.2435 to 0.2435. Saving model...\n",
      "LOG: Epoch [1351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3677\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3492\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1351/2000], Avg Train Loss: 0.3677, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2435 to 0.2434. Saving model...\n",
      "LOG: Epoch [1352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3729\n",
      "LOG: Epoch [1352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1377\n",
      "Epoch [1352/2000], Avg Train Loss: 0.3729, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2434. Saving model...\n",
      "LOG: Epoch [1353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3691\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1353/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2434. Saving model...\n",
      "LOG: Epoch [1354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3726\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1354/2000], Avg Train Loss: 0.3726, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2434. Saving model...\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3675\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1355/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2434. Saving model...\n",
      "LOG: Epoch [1356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3720\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1356/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2433. Saving model...\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3719\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1357/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2433. Saving model...\n",
      "LOG: Epoch [1358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3691\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1358/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2433. Saving model...\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3718\n",
      "LOG: Epoch [1359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1359/2000], Avg Train Loss: 0.3718, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2433. Saving model...\n",
      "LOG: Epoch [1360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3741\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1360/2000], Avg Train Loss: 0.3741, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2433. Saving model...\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3713\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1361/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3701\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1362/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3701\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1363/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3715\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1364/2000], Avg Train Loss: 0.3715, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3701\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1365/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3677\n",
      "LOG: Epoch [1366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1366/2000], Avg Train Loss: 0.3677, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3721\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1367/2000], Avg Train Loss: 0.3721, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3692\n",
      "LOG: Epoch [1368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3491\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1368/2000], Avg Train Loss: 0.3692, Avg Val Loss: 0.2434\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3690\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3490\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1369/2000], Avg Train Loss: 0.3690, Avg Val Loss: 0.2433\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3687\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3489\n",
      "    Batch [2/2], Val Loss: 0.1376\n",
      "Epoch [1370/2000], Avg Train Loss: 0.3687, Avg Val Loss: 0.2433\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2433. Saving model...\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3665\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1371/2000], Avg Train Loss: 0.3665, Avg Val Loss: 0.2432\n",
      "\n",
      "Validation loss improved from 0.2433 to 0.2432. Saving model...\n",
      "LOG: Epoch [1372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3678\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3488\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1372/2000], Avg Train Loss: 0.3678, Avg Val Loss: 0.2431\n",
      "\n",
      "Validation loss improved from 0.2432 to 0.2431. Saving model...\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3708\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1373/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2431\n",
      "\n",
      "Validation loss improved from 0.2431 to 0.2431. Saving model...\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3636\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1374/2000], Avg Train Loss: 0.3636, Avg Val Loss: 0.2431\n",
      "\n",
      "Validation loss improved from 0.2431 to 0.2431. Saving model...\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3694\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3486\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1375/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2430\n",
      "\n",
      "Validation loss improved from 0.2431 to 0.2430. Saving model...\n",
      "LOG: Epoch [1376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3695\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3485\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1376/2000], Avg Train Loss: 0.3695, Avg Val Loss: 0.2430\n",
      "\n",
      "Validation loss improved from 0.2430 to 0.2430. Saving model...\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3714\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3484\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1377/2000], Avg Train Loss: 0.3714, Avg Val Loss: 0.2430\n",
      "\n",
      "Validation loss improved from 0.2430 to 0.2430. Saving model...\n",
      "LOG: Epoch [1378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3699\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3483\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [1378/2000], Avg Train Loss: 0.3699, Avg Val Loss: 0.2429\n",
      "\n",
      "Validation loss improved from 0.2430 to 0.2429. Saving model...\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3702\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3482\n",
      "    Batch [2/2], Val Loss: 0.1374\n",
      "Epoch [1379/2000], Avg Train Loss: 0.3702, Avg Val Loss: 0.2428\n",
      "\n",
      "Validation loss improved from 0.2429 to 0.2428. Saving model...\n",
      "LOG: Epoch [1380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3603\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1373\n",
      "Epoch [1380/2000], Avg Train Loss: 0.3603, Avg Val Loss: 0.2427\n",
      "\n",
      "Validation loss improved from 0.2428 to 0.2427. Saving model...\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3657\n",
      "LOG: Epoch [1381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [1381/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2427\n",
      "\n",
      "Validation loss improved from 0.2427 to 0.2427. Saving model...\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3713\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3481\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [1382/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2427 to 0.2426. Saving model...\n",
      "LOG: Epoch [1383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3712\n",
      "LOG: Epoch [1383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [1383/2000], Avg Train Loss: 0.3712, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2426. Saving model...\n",
      "LOG: Epoch [1384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3694\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [1384/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2425\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2425. Saving model...\n",
      "LOG: Epoch [1385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3680\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3480\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [1385/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2425\n",
      "\n",
      "Validation loss improved from 0.2425 to 0.2425. Saving model...\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3657\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [1386/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2424\n",
      "\n",
      "Validation loss improved from 0.2425 to 0.2424. Saving model...\n",
      "LOG: Epoch [1387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3691\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1368\n",
      "Epoch [1387/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2424\n",
      "\n",
      "Validation loss improved from 0.2424 to 0.2424. Saving model...\n",
      "LOG: Epoch [1388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3661\n",
      "LOG: Epoch [1388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [1388/2000], Avg Train Loss: 0.3661, Avg Val Loss: 0.2423\n",
      "\n",
      "Validation loss improved from 0.2424 to 0.2423. Saving model...\n",
      "LOG: Epoch [1389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3636\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [1389/2000], Avg Train Loss: 0.3636, Avg Val Loss: 0.2423\n",
      "\n",
      "Validation loss improved from 0.2423 to 0.2423. Saving model...\n",
      "LOG: Epoch [1390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3689\n",
      "LOG: Epoch [1390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [1390/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2423 to 0.2422. Saving model...\n",
      "LOG: Epoch [1391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3713\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [1391/2000], Avg Train Loss: 0.3713, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2422. Saving model...\n",
      "LOG: Epoch [1392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3681\n",
      "LOG: Epoch [1392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [1392/2000], Avg Train Loss: 0.3681, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2422. Saving model...\n",
      "LOG: Epoch [1393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3634\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1365\n",
      "Epoch [1393/2000], Avg Train Loss: 0.3634, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2422. Saving model...\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [1394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1365\n",
      "Epoch [1394/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2421\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2421. Saving model...\n",
      "LOG: Epoch [1395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3671\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1364\n",
      "Epoch [1395/2000], Avg Train Loss: 0.3671, Avg Val Loss: 0.2421\n",
      "\n",
      "Validation loss improved from 0.2421 to 0.2421. Saving model...\n",
      "LOG: Epoch [1396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3671\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1364\n",
      "Epoch [1396/2000], Avg Train Loss: 0.3671, Avg Val Loss: 0.2421\n",
      "\n",
      "Validation loss improved from 0.2421 to 0.2421. Saving model...\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3657\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1397/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2421 to 0.2420. Saving model...\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3653\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1398/2000], Avg Train Loss: 0.3653, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2420. Saving model...\n",
      "LOG: Epoch [1399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3717\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3478\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1399/2000], Avg Train Loss: 0.3717, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2420. Saving model...\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3674\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3477\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1400/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2420. Saving model...\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3657\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3477\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1401/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2420. Saving model...\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3705\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3476\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1402/2000], Avg Train Loss: 0.3705, Avg Val Loss: 0.2419\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2419. Saving model...\n",
      "LOG: Epoch [1403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3658\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3475\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1403/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2419\n",
      "\n",
      "Validation loss improved from 0.2419 to 0.2419. Saving model...\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3631\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3474\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1404/2000], Avg Train Loss: 0.3631, Avg Val Loss: 0.2418\n",
      "\n",
      "Validation loss improved from 0.2419 to 0.2418. Saving model...\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3657\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3473\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1405/2000], Avg Train Loss: 0.3657, Avg Val Loss: 0.2417\n",
      "\n",
      "Validation loss improved from 0.2418 to 0.2417. Saving model...\n",
      "LOG: Epoch [1406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3694\n",
      "LOG: Epoch [1406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3473\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [1406/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2417\n",
      "\n",
      "Validation loss improved from 0.2417 to 0.2417. Saving model...\n",
      "LOG: Epoch [1407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3654\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3472\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [1407/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.2417\n",
      "\n",
      "Validation loss improved from 0.2417 to 0.2417. Saving model...\n",
      "LOG: Epoch [1408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3683\n",
      "LOG: Epoch [1408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3472\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1408/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2417 to 0.2416. Saving model...\n",
      "LOG: Epoch [1409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3696\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3472\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1409/2000], Avg Train Loss: 0.3696, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2416. Saving model...\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3607\n",
      "LOG: Epoch [1410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3472\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1410/2000], Avg Train Loss: 0.3607, Avg Val Loss: 0.2416\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2416. Saving model...\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3717\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3471\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1411/2000], Avg Train Loss: 0.3717, Avg Val Loss: 0.2415\n",
      "\n",
      "Validation loss improved from 0.2416 to 0.2415. Saving model...\n",
      "LOG: Epoch [1412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3693\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3470\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1412/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2415\n",
      "\n",
      "Validation loss improved from 0.2415 to 0.2415. Saving model...\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3674\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3470\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1413/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2415\n",
      "\n",
      "Validation loss improved from 0.2415 to 0.2415. Saving model...\n",
      "LOG: Epoch [1414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3638\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1414/2000], Avg Train Loss: 0.3638, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2415 to 0.2414. Saving model...\n",
      "LOG: Epoch [1415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3652\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1415/2000], Avg Train Loss: 0.3652, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2414. Saving model...\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3684\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1416/2000], Avg Train Loss: 0.3684, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2414. Saving model...\n",
      "LOG: Epoch [1417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1417/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2413\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2413. Saving model...\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3703\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1358\n",
      "Epoch [1418/2000], Avg Train Loss: 0.3703, Avg Val Loss: 0.2413\n",
      "\n",
      "Validation loss improved from 0.2413 to 0.2413. Saving model...\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3634\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1358\n",
      "Epoch [1419/2000], Avg Train Loss: 0.3634, Avg Val Loss: 0.2413\n",
      "\n",
      "Validation loss improved from 0.2413 to 0.2413. Saving model...\n",
      "LOG: Epoch [1420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3602\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1420/2000], Avg Train Loss: 0.3602, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3668\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1421/2000], Avg Train Loss: 0.3668, Avg Val Loss: 0.2413\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3674\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1422/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3641\n",
      "LOG: Epoch [1423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1423/2000], Avg Train Loss: 0.3641, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3675\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1424/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [1425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1425/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3663\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [1426/2000], Avg Train Loss: 0.3663, Avg Val Loss: 0.2415\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3653\n",
      "LOG: Epoch [1427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [1427/2000], Avg Train Loss: 0.3653, Avg Val Loss: 0.2415\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3680\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1428/2000], Avg Train Loss: 0.3680, Avg Val Loss: 0.2416\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3691\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3469\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1429/2000], Avg Train Loss: 0.3691, Avg Val Loss: 0.2416\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3605\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1430/2000], Avg Train Loss: 0.3605, Avg Val Loss: 0.2416\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3700\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3468\n",
      "    Batch [2/2], Val Loss: 0.1363\n",
      "Epoch [1431/2000], Avg Train Loss: 0.3700, Avg Val Loss: 0.2415\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3683\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3467\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1432/2000], Avg Train Loss: 0.3683, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3660\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3466\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1433/2000], Avg Train Loss: 0.3660, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3645\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3465\n",
      "    Batch [2/2], Val Loss: 0.1362\n",
      "Epoch [1434/2000], Avg Train Loss: 0.3645, Avg Val Loss: 0.2414\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3630\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3465\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [1435/2000], Avg Train Loss: 0.3630, Avg Val Loss: 0.2413\n",
      "\n",
      "Validation loss improved from 0.2413 to 0.2413. Saving model...\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3642\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3464\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [1436/2000], Avg Train Loss: 0.3642, Avg Val Loss: 0.2412\n",
      "\n",
      "Validation loss improved from 0.2413 to 0.2412. Saving model...\n",
      "LOG: Epoch [1437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3665\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3464\n",
      "    Batch [2/2], Val Loss: 0.1359\n",
      "Epoch [1437/2000], Avg Train Loss: 0.3665, Avg Val Loss: 0.2411\n",
      "\n",
      "Validation loss improved from 0.2412 to 0.2411. Saving model...\n",
      "LOG: Epoch [1438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3720\n",
      "LOG: Epoch [1438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3463\n",
      "    Batch [2/2], Val Loss: 0.1358\n",
      "Epoch [1438/2000], Avg Train Loss: 0.3720, Avg Val Loss: 0.2411\n",
      "\n",
      "Validation loss improved from 0.2411 to 0.2411. Saving model...\n",
      "LOG: Epoch [1439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3628\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3463\n",
      "    Batch [2/2], Val Loss: 0.1357\n",
      "Epoch [1439/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2410\n",
      "\n",
      "Validation loss improved from 0.2411 to 0.2410. Saving model...\n",
      "LOG: Epoch [1440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3620\n",
      "LOG: Epoch [1440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3463\n",
      "    Batch [2/2], Val Loss: 0.1355\n",
      "Epoch [1440/2000], Avg Train Loss: 0.3620, Avg Val Loss: 0.2409\n",
      "\n",
      "Validation loss improved from 0.2410 to 0.2409. Saving model...\n",
      "LOG: Epoch [1441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3675\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3462\n",
      "    Batch [2/2], Val Loss: 0.1355\n",
      "Epoch [1441/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2409\n",
      "\n",
      "Validation loss improved from 0.2409 to 0.2409. Saving model...\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3678\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3463\n",
      "    Batch [2/2], Val Loss: 0.1354\n",
      "Epoch [1442/2000], Avg Train Loss: 0.3678, Avg Val Loss: 0.2408\n",
      "\n",
      "Validation loss improved from 0.2409 to 0.2408. Saving model...\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3629\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3463\n",
      "    Batch [2/2], Val Loss: 0.1353\n",
      "Epoch [1443/2000], Avg Train Loss: 0.3629, Avg Val Loss: 0.2408\n",
      "\n",
      "Validation loss improved from 0.2408 to 0.2408. Saving model...\n",
      "LOG: Epoch [1444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3658\n",
      "LOG: Epoch [1444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3462\n",
      "    Batch [2/2], Val Loss: 0.1353\n",
      "Epoch [1444/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2408\n",
      "\n",
      "Validation loss improved from 0.2408 to 0.2408. Saving model...\n",
      "LOG: Epoch [1445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3708\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3462\n",
      "    Batch [2/2], Val Loss: 0.1352\n",
      "Epoch [1445/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2407\n",
      "\n",
      "Validation loss improved from 0.2408 to 0.2407. Saving model...\n",
      "LOG: Epoch [1446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3660\n",
      "LOG: Epoch [1446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3462\n",
      "    Batch [2/2], Val Loss: 0.1351\n",
      "Epoch [1446/2000], Avg Train Loss: 0.3660, Avg Val Loss: 0.2406\n",
      "\n",
      "Validation loss improved from 0.2407 to 0.2406. Saving model...\n",
      "LOG: Epoch [1447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3638\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3462\n",
      "    Batch [2/2], Val Loss: 0.1351\n",
      "Epoch [1447/2000], Avg Train Loss: 0.3638, Avg Val Loss: 0.2406\n",
      "\n",
      "Validation loss improved from 0.2406 to 0.2406. Saving model...\n",
      "LOG: Epoch [1448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3639\n",
      "LOG: Epoch [1448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3461\n",
      "    Batch [2/2], Val Loss: 0.1351\n",
      "Epoch [1448/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2406\n",
      "\n",
      "Validation loss improved from 0.2406 to 0.2406. Saving model...\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3646\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3461\n",
      "    Batch [2/2], Val Loss: 0.1351\n",
      "Epoch [1449/2000], Avg Train Loss: 0.3646, Avg Val Loss: 0.2406\n",
      "\n",
      "Validation loss improved from 0.2406 to 0.2406. Saving model...\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3637\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3460\n",
      "    Batch [2/2], Val Loss: 0.1351\n",
      "Epoch [1450/2000], Avg Train Loss: 0.3637, Avg Val Loss: 0.2406\n",
      "\n",
      "Validation loss improved from 0.2406 to 0.2406. Saving model...\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3667\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3460\n",
      "    Batch [2/2], Val Loss: 0.1350\n",
      "Epoch [1451/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2405\n",
      "\n",
      "Validation loss improved from 0.2406 to 0.2405. Saving model...\n",
      "LOG: Epoch [1452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3662\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3459\n",
      "    Batch [2/2], Val Loss: 0.1350\n",
      "Epoch [1452/2000], Avg Train Loss: 0.3662, Avg Val Loss: 0.2404\n",
      "\n",
      "Validation loss improved from 0.2405 to 0.2404. Saving model...\n",
      "LOG: Epoch [1453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3635\n",
      "LOG: Epoch [1453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3458\n",
      "    Batch [2/2], Val Loss: 0.1349\n",
      "Epoch [1453/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2403\n",
      "\n",
      "Validation loss improved from 0.2404 to 0.2403. Saving model...\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3741\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3457\n",
      "    Batch [2/2], Val Loss: 0.1348\n",
      "Epoch [1454/2000], Avg Train Loss: 0.3741, Avg Val Loss: 0.2402\n",
      "\n",
      "Validation loss improved from 0.2403 to 0.2402. Saving model...\n",
      "LOG: Epoch [1455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3670\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3456\n",
      "    Batch [2/2], Val Loss: 0.1347\n",
      "Epoch [1455/2000], Avg Train Loss: 0.3670, Avg Val Loss: 0.2402\n",
      "\n",
      "Validation loss improved from 0.2402 to 0.2402. Saving model...\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3681\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3455\n",
      "    Batch [2/2], Val Loss: 0.1346\n",
      "Epoch [1456/2000], Avg Train Loss: 0.3681, Avg Val Loss: 0.2401\n",
      "\n",
      "Validation loss improved from 0.2402 to 0.2401. Saving model...\n",
      "LOG: Epoch [1457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3628\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3454\n",
      "    Batch [2/2], Val Loss: 0.1345\n",
      "Epoch [1457/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2399\n",
      "\n",
      "Validation loss improved from 0.2401 to 0.2399. Saving model...\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3634\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3453\n",
      "    Batch [2/2], Val Loss: 0.1344\n",
      "Epoch [1458/2000], Avg Train Loss: 0.3634, Avg Val Loss: 0.2399\n",
      "\n",
      "Validation loss improved from 0.2399 to 0.2399. Saving model...\n",
      "LOG: Epoch [1459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3618\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3452\n",
      "    Batch [2/2], Val Loss: 0.1343\n",
      "Epoch [1459/2000], Avg Train Loss: 0.3618, Avg Val Loss: 0.2398\n",
      "\n",
      "Validation loss improved from 0.2399 to 0.2398. Saving model...\n",
      "LOG: Epoch [1460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3624\n",
      "LOG: Epoch [1460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3452\n",
      "    Batch [2/2], Val Loss: 0.1342\n",
      "Epoch [1460/2000], Avg Train Loss: 0.3624, Avg Val Loss: 0.2397\n",
      "\n",
      "Validation loss improved from 0.2398 to 0.2397. Saving model...\n",
      "LOG: Epoch [1461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3686\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3451\n",
      "    Batch [2/2], Val Loss: 0.1341\n",
      "Epoch [1461/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2396\n",
      "\n",
      "Validation loss improved from 0.2397 to 0.2396. Saving model...\n",
      "LOG: Epoch [1462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3647\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3450\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [1462/2000], Avg Train Loss: 0.3647, Avg Val Loss: 0.2395\n",
      "\n",
      "Validation loss improved from 0.2396 to 0.2395. Saving model...\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3648\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3450\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1463/2000], Avg Train Loss: 0.3648, Avg Val Loss: 0.2394\n",
      "\n",
      "Validation loss improved from 0.2395 to 0.2394. Saving model...\n",
      "LOG: Epoch [1464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3692\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3449\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1464/2000], Avg Train Loss: 0.3692, Avg Val Loss: 0.2394\n",
      "\n",
      "Validation loss improved from 0.2394 to 0.2394. Saving model...\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3623\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3449\n",
      "    Batch [2/2], Val Loss: 0.1337\n",
      "Epoch [1465/2000], Avg Train Loss: 0.3623, Avg Val Loss: 0.2393\n",
      "\n",
      "Validation loss improved from 0.2394 to 0.2393. Saving model...\n",
      "LOG: Epoch [1466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3650\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1466/2000], Avg Train Loss: 0.3650, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2393 to 0.2392. Saving model...\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3678\n",
      "LOG: Epoch [1467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1467/2000], Avg Train Loss: 0.3678, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2392. Saving model...\n",
      "LOG: Epoch [1468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3613\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1468/2000], Avg Train Loss: 0.3613, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2392. Saving model...\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3576\n",
      "LOG: Epoch [1469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1335\n",
      "Epoch [1469/2000], Avg Train Loss: 0.3576, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2392. Saving model...\n",
      "LOG: Epoch [1470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3674\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1470/2000], Avg Train Loss: 0.3674, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2392. Saving model...\n",
      "LOG: Epoch [1471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3669\n",
      "LOG: Epoch [1471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1471/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2392\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3653\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1472/2000], Avg Train Loss: 0.3653, Avg Val Loss: 0.2392\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3603\n",
      "LOG: Epoch [1473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1337\n",
      "Epoch [1473/2000], Avg Train Loss: 0.3603, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3575\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1474/2000], Avg Train Loss: 0.3575, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3643\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3448\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1475/2000], Avg Train Loss: 0.3643, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3667\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3447\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1476/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3675\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3447\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1477/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3627\n",
      "LOG: Epoch [1478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3447\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1478/2000], Avg Train Loss: 0.3627, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3632\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3447\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [1479/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3654\n",
      "LOG: Epoch [1480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3446\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1480/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3645\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3446\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1481/2000], Avg Train Loss: 0.3645, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3639\n",
      "LOG: Epoch [1482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3446\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1482/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3636\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3446\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [1483/2000], Avg Train Loss: 0.3636, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [1484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3446\n",
      "    Batch [2/2], Val Loss: 0.1340\n",
      "Epoch [1484/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3669\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3445\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1485/2000], Avg Train Loss: 0.3669, Avg Val Loss: 0.2392\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3655\n",
      "LOG: Epoch [1486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3445\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1486/2000], Avg Train Loss: 0.3655, Avg Val Loss: 0.2392\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3614\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3444\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [1487/2000], Avg Train Loss: 0.3614, Avg Val Loss: 0.2391\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2391. Saving model...\n",
      "LOG: Epoch [1488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3622\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3443\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1488/2000], Avg Train Loss: 0.3622, Avg Val Loss: 0.2391\n",
      "\n",
      "Validation loss improved from 0.2391 to 0.2391. Saving model...\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3665\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3443\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1489/2000], Avg Train Loss: 0.3665, Avg Val Loss: 0.2390\n",
      "\n",
      "Validation loss improved from 0.2391 to 0.2390. Saving model...\n",
      "LOG: Epoch [1490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3672\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3442\n",
      "    Batch [2/2], Val Loss: 0.1338\n",
      "Epoch [1490/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2390\n",
      "\n",
      "Validation loss improved from 0.2390 to 0.2390. Saving model...\n",
      "LOG: Epoch [1491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3635\n",
      "LOG: Epoch [1491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3442\n",
      "    Batch [2/2], Val Loss: 0.1337\n",
      "Epoch [1491/2000], Avg Train Loss: 0.3635, Avg Val Loss: 0.2390\n",
      "\n",
      "Validation loss improved from 0.2390 to 0.2390. Saving model...\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3658\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3442\n",
      "    Batch [2/2], Val Loss: 0.1337\n",
      "Epoch [1492/2000], Avg Train Loss: 0.3658, Avg Val Loss: 0.2389\n",
      "\n",
      "Validation loss improved from 0.2390 to 0.2389. Saving model...\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3607\n",
      "LOG: Epoch [1493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3441\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1493/2000], Avg Train Loss: 0.3607, Avg Val Loss: 0.2389\n",
      "\n",
      "Validation loss improved from 0.2389 to 0.2389. Saving model...\n",
      "LOG: Epoch [1494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3591\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3441\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1494/2000], Avg Train Loss: 0.3591, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2389 to 0.2388. Saving model...\n",
      "LOG: Epoch [1495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3626\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3441\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1495/2000], Avg Train Loss: 0.3626, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2388. Saving model...\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3637\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3441\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1496/2000], Avg Train Loss: 0.3637, Avg Val Loss: 0.2388\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3671\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3440\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1497/2000], Avg Train Loss: 0.3671, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2388. Saving model...\n",
      "LOG: Epoch [1498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3614\n",
      "LOG: Epoch [1498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3440\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [1498/2000], Avg Train Loss: 0.3614, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2388. Saving model...\n",
      "LOG: Epoch [1499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3614\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3439\n",
      "    Batch [2/2], Val Loss: 0.1335\n",
      "Epoch [1499/2000], Avg Train Loss: 0.3614, Avg Val Loss: 0.2387\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2387. Saving model...\n",
      "LOG: Epoch [1500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3667\n",
      "LOG: Epoch [1500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3439\n",
      "    Batch [2/2], Val Loss: 0.1334\n",
      "Epoch [1500/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2387\n",
      "\n",
      "Validation loss improved from 0.2387 to 0.2387. Saving model...\n",
      "LOG: Epoch [1501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3645\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3439\n",
      "    Batch [2/2], Val Loss: 0.1334\n",
      "Epoch [1501/2000], Avg Train Loss: 0.3645, Avg Val Loss: 0.2386\n",
      "\n",
      "Validation loss improved from 0.2387 to 0.2386. Saving model...\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3605\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3438\n",
      "    Batch [2/2], Val Loss: 0.1333\n",
      "Epoch [1502/2000], Avg Train Loss: 0.3605, Avg Val Loss: 0.2386\n",
      "\n",
      "Validation loss improved from 0.2386 to 0.2386. Saving model...\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3626\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3438\n",
      "    Batch [2/2], Val Loss: 0.1332\n",
      "Epoch [1503/2000], Avg Train Loss: 0.3626, Avg Val Loss: 0.2385\n",
      "\n",
      "Validation loss improved from 0.2386 to 0.2385. Saving model...\n",
      "LOG: Epoch [1504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3631\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3438\n",
      "    Batch [2/2], Val Loss: 0.1331\n",
      "Epoch [1504/2000], Avg Train Loss: 0.3631, Avg Val Loss: 0.2384\n",
      "\n",
      "Validation loss improved from 0.2385 to 0.2384. Saving model...\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3654\n",
      "LOG: Epoch [1505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3437\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1505/2000], Avg Train Loss: 0.3654, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2384 to 0.2383. Saving model...\n",
      "LOG: Epoch [1506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3597\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3437\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1506/2000], Avg Train Loss: 0.3597, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2383. Saving model...\n",
      "LOG: Epoch [1507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3633\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3437\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1507/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2383. Saving model...\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3628\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3436\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1508/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2383. Saving model...\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3640\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3436\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [1509/2000], Avg Train Loss: 0.3640, Avg Val Loss: 0.2382\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2382. Saving model...\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3667\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [1510/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2382\n",
      "\n",
      "Validation loss improved from 0.2382 to 0.2382. Saving model...\n",
      "LOG: Epoch [1511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3583\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [1511/2000], Avg Train Loss: 0.3583, Avg Val Loss: 0.2381\n",
      "\n",
      "Validation loss improved from 0.2382 to 0.2381. Saving model...\n",
      "LOG: Epoch [1512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3616\n",
      "LOG: Epoch [1512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [1512/2000], Avg Train Loss: 0.3616, Avg Val Loss: 0.2381\n",
      "\n",
      "Validation loss improved from 0.2381 to 0.2381. Saving model...\n",
      "LOG: Epoch [1513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3641\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [1513/2000], Avg Train Loss: 0.3641, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2381 to 0.2380. Saving model...\n",
      "LOG: Epoch [1514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3611\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1325\n",
      "Epoch [1514/2000], Avg Train Loss: 0.3611, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2380. Saving model...\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3621\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1515/2000], Avg Train Loss: 0.3621, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2380. Saving model...\n",
      "LOG: Epoch [1516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3611\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1516/2000], Avg Train Loss: 0.3611, Avg Val Loss: 0.2380\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2380. Saving model...\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3590\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1517/2000], Avg Train Loss: 0.3590, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3639\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1518/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3638\n",
      "LOG: Epoch [1519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1519/2000], Avg Train Loss: 0.3638, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2380 to 0.2379. Saving model...\n",
      "LOG: Epoch [1520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3632\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1520/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3666\n",
      "LOG: Epoch [1521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1521/2000], Avg Train Loss: 0.3666, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3618\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1522/2000], Avg Train Loss: 0.3618, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3577\n",
      "LOG: Epoch [1523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1323\n",
      "Epoch [1523/2000], Avg Train Loss: 0.3577, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3609\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1323\n",
      "Epoch [1524/2000], Avg Train Loss: 0.3609, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3587\n",
      "LOG: Epoch [1525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1322\n",
      "Epoch [1525/2000], Avg Train Loss: 0.3587, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3609\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1322\n",
      "Epoch [1526/2000], Avg Train Loss: 0.3609, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3630\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3436\n",
      "    Batch [2/2], Val Loss: 0.1322\n",
      "Epoch [1527/2000], Avg Train Loss: 0.3630, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3610\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3436\n",
      "    Batch [2/2], Val Loss: 0.1323\n",
      "Epoch [1528/2000], Avg Train Loss: 0.3610, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3621\n",
      "LOG: Epoch [1529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1323\n",
      "Epoch [1529/2000], Avg Train Loss: 0.3621, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3622\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3435\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1530/2000], Avg Train Loss: 0.3622, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3628\n",
      "LOG: Epoch [1531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3434\n",
      "    Batch [2/2], Val Loss: 0.1325\n",
      "Epoch [1531/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3630\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3433\n",
      "    Batch [2/2], Val Loss: 0.1325\n",
      "Epoch [1532/2000], Avg Train Loss: 0.3630, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3638\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3432\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [1533/2000], Avg Train Loss: 0.3638, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3619\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3431\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [1534/2000], Avg Train Loss: 0.3619, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3618\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3430\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [1535/2000], Avg Train Loss: 0.3618, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3569\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3429\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1536/2000], Avg Train Loss: 0.3569, Avg Val Loss: 0.2379\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3642\n",
      "LOG: Epoch [1537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3428\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1537/2000], Avg Train Loss: 0.3642, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2379. Saving model...\n",
      "LOG: Epoch [1538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3612\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3428\n",
      "    Batch [2/2], Val Loss: 0.1329\n",
      "Epoch [1538/2000], Avg Train Loss: 0.3612, Avg Val Loss: 0.2378\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2378. Saving model...\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3560\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3427\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [1539/2000], Avg Train Loss: 0.3560, Avg Val Loss: 0.2378\n",
      "\n",
      "Validation loss improved from 0.2378 to 0.2378. Saving model...\n",
      "LOG: Epoch [1540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3637\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3427\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [1540/2000], Avg Train Loss: 0.3637, Avg Val Loss: 0.2377\n",
      "\n",
      "Validation loss improved from 0.2378 to 0.2377. Saving model...\n",
      "LOG: Epoch [1541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3632\n",
      "LOG: Epoch [1541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3426\n",
      "    Batch [2/2], Val Loss: 0.1328\n",
      "Epoch [1541/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2377\n",
      "\n",
      "Validation loss improved from 0.2377 to 0.2377. Saving model...\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3628\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3426\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [1542/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2377\n",
      "\n",
      "Validation loss improved from 0.2377 to 0.2377. Saving model...\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3632\n",
      "LOG: Epoch [1543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3426\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [1543/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2376\n",
      "\n",
      "Validation loss improved from 0.2377 to 0.2376. Saving model...\n",
      "LOG: Epoch [1544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3661\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3425\n",
      "    Batch [2/2], Val Loss: 0.1326\n",
      "Epoch [1544/2000], Avg Train Loss: 0.3661, Avg Val Loss: 0.2375\n",
      "\n",
      "Validation loss improved from 0.2376 to 0.2375. Saving model...\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3621\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3424\n",
      "    Batch [2/2], Val Loss: 0.1325\n",
      "Epoch [1545/2000], Avg Train Loss: 0.3621, Avg Val Loss: 0.2375\n",
      "\n",
      "Validation loss improved from 0.2375 to 0.2375. Saving model...\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3607\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3424\n",
      "    Batch [2/2], Val Loss: 0.1324\n",
      "Epoch [1546/2000], Avg Train Loss: 0.3607, Avg Val Loss: 0.2374\n",
      "\n",
      "Validation loss improved from 0.2375 to 0.2374. Saving model...\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3571\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3423\n",
      "    Batch [2/2], Val Loss: 0.1323\n",
      "Epoch [1547/2000], Avg Train Loss: 0.3571, Avg Val Loss: 0.2373\n",
      "\n",
      "Validation loss improved from 0.2374 to 0.2373. Saving model...\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3595\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3423\n",
      "    Batch [2/2], Val Loss: 0.1322\n",
      "Epoch [1548/2000], Avg Train Loss: 0.3595, Avg Val Loss: 0.2372\n",
      "\n",
      "Validation loss improved from 0.2373 to 0.2372. Saving model...\n",
      "LOG: Epoch [1549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3620\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3422\n",
      "    Batch [2/2], Val Loss: 0.1321\n",
      "Epoch [1549/2000], Avg Train Loss: 0.3620, Avg Val Loss: 0.2372\n",
      "\n",
      "Validation loss improved from 0.2372 to 0.2372. Saving model...\n",
      "LOG: Epoch [1550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3660\n",
      "LOG: Epoch [1550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3422\n",
      "    Batch [2/2], Val Loss: 0.1320\n",
      "Epoch [1550/2000], Avg Train Loss: 0.3660, Avg Val Loss: 0.2371\n",
      "\n",
      "Validation loss improved from 0.2372 to 0.2371. Saving model...\n",
      "LOG: Epoch [1551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3647\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3422\n",
      "    Batch [2/2], Val Loss: 0.1319\n",
      "Epoch [1551/2000], Avg Train Loss: 0.3647, Avg Val Loss: 0.2370\n",
      "\n",
      "Validation loss improved from 0.2371 to 0.2370. Saving model...\n",
      "LOG: Epoch [1552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [1552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3421\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [1552/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2370\n",
      "\n",
      "Validation loss improved from 0.2370 to 0.2370. Saving model...\n",
      "LOG: Epoch [1553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3606\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [1553/2000], Avg Train Loss: 0.3606, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2370 to 0.2369. Saving model...\n",
      "LOG: Epoch [1554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3603\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [1554/2000], Avg Train Loss: 0.3603, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2369. Saving model...\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3621\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1317\n",
      "Epoch [1555/2000], Avg Train Loss: 0.3621, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2369. Saving model...\n",
      "LOG: Epoch [1556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3620\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [1556/2000], Avg Train Loss: 0.3620, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2369. Saving model...\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3617\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [1557/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.2369\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3626\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [1558/2000], Avg Train Loss: 0.3626, Avg Val Loss: 0.2369\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3573\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1317\n",
      "Epoch [1559/2000], Avg Train Loss: 0.3573, Avg Val Loss: 0.2368\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2368. Saving model...\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3548\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3420\n",
      "    Batch [2/2], Val Loss: 0.1317\n",
      "Epoch [1560/2000], Avg Train Loss: 0.3548, Avg Val Loss: 0.2368\n",
      "\n",
      "Validation loss improved from 0.2368 to 0.2368. Saving model...\n",
      "LOG: Epoch [1561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3629\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1317\n",
      "Epoch [1561/2000], Avg Train Loss: 0.3629, Avg Val Loss: 0.2368\n",
      "\n",
      "Validation loss improved from 0.2368 to 0.2368. Saving model...\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3589\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1316\n",
      "Epoch [1562/2000], Avg Train Loss: 0.3589, Avg Val Loss: 0.2368\n",
      "\n",
      "Validation loss improved from 0.2368 to 0.2368. Saving model...\n",
      "LOG: Epoch [1563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3556\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1316\n",
      "Epoch [1563/2000], Avg Train Loss: 0.3556, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2368 to 0.2367. Saving model...\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3606\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1315\n",
      "Epoch [1564/2000], Avg Train Loss: 0.3606, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2367. Saving model...\n",
      "LOG: Epoch [1565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3559\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1565/2000], Avg Train Loss: 0.3559, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2367. Saving model...\n",
      "LOG: Epoch [1566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3611\n",
      "LOG: Epoch [1566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1566/2000], Avg Train Loss: 0.3611, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2367. Saving model...\n",
      "LOG: Epoch [1567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3660\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1567/2000], Avg Train Loss: 0.3660, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2367. Saving model...\n",
      "LOG: Epoch [1568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3577\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1568/2000], Avg Train Loss: 0.3577, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2367. Saving model...\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3571\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1569/2000], Avg Train Loss: 0.3571, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3646\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1570/2000], Avg Train Loss: 0.3646, Avg Val Loss: 0.2367\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2367. Saving model...\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3546\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1315\n",
      "Epoch [1571/2000], Avg Train Loss: 0.3546, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3623\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3418\n",
      "    Batch [2/2], Val Loss: 0.1315\n",
      "Epoch [1572/2000], Avg Train Loss: 0.3623, Avg Val Loss: 0.2367\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3622\n",
      "LOG: Epoch [1573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3418\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1573/2000], Avg Train Loss: 0.3622, Avg Val Loss: 0.2366\n",
      "\n",
      "Validation loss improved from 0.2367 to 0.2366. Saving model...\n",
      "LOG: Epoch [1574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3568\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3417\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1574/2000], Avg Train Loss: 0.3568, Avg Val Loss: 0.2366\n",
      "\n",
      "Validation loss improved from 0.2366 to 0.2366. Saving model...\n",
      "LOG: Epoch [1575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3588\n",
      "LOG: Epoch [1575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3417\n",
      "    Batch [2/2], Val Loss: 0.1314\n",
      "Epoch [1575/2000], Avg Train Loss: 0.3588, Avg Val Loss: 0.2365\n",
      "\n",
      "Validation loss improved from 0.2366 to 0.2365. Saving model...\n",
      "LOG: Epoch [1576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3593\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3417\n",
      "    Batch [2/2], Val Loss: 0.1313\n",
      "Epoch [1576/2000], Avg Train Loss: 0.3593, Avg Val Loss: 0.2365\n",
      "\n",
      "Validation loss improved from 0.2365 to 0.2365. Saving model...\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3612\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3416\n",
      "    Batch [2/2], Val Loss: 0.1312\n",
      "Epoch [1577/2000], Avg Train Loss: 0.3612, Avg Val Loss: 0.2364\n",
      "\n",
      "Validation loss improved from 0.2365 to 0.2364. Saving model...\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3585\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3415\n",
      "    Batch [2/2], Val Loss: 0.1311\n",
      "Epoch [1578/2000], Avg Train Loss: 0.3585, Avg Val Loss: 0.2363\n",
      "\n",
      "Validation loss improved from 0.2364 to 0.2363. Saving model...\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3575\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3415\n",
      "    Batch [2/2], Val Loss: 0.1310\n",
      "Epoch [1579/2000], Avg Train Loss: 0.3575, Avg Val Loss: 0.2363\n",
      "\n",
      "Validation loss improved from 0.2363 to 0.2363. Saving model...\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3591\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3415\n",
      "    Batch [2/2], Val Loss: 0.1309\n",
      "Epoch [1580/2000], Avg Train Loss: 0.3591, Avg Val Loss: 0.2362\n",
      "\n",
      "Validation loss improved from 0.2363 to 0.2362. Saving model...\n",
      "LOG: Epoch [1581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3571\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3414\n",
      "    Batch [2/2], Val Loss: 0.1308\n",
      "Epoch [1581/2000], Avg Train Loss: 0.3571, Avg Val Loss: 0.2361\n",
      "\n",
      "Validation loss improved from 0.2362 to 0.2361. Saving model...\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3634\n",
      "LOG: Epoch [1582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3414\n",
      "    Batch [2/2], Val Loss: 0.1307\n",
      "Epoch [1582/2000], Avg Train Loss: 0.3634, Avg Val Loss: 0.2360\n",
      "\n",
      "Validation loss improved from 0.2361 to 0.2360. Saving model...\n",
      "LOG: Epoch [1583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3595\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3413\n",
      "    Batch [2/2], Val Loss: 0.1306\n",
      "Epoch [1583/2000], Avg Train Loss: 0.3595, Avg Val Loss: 0.2359\n",
      "\n",
      "Validation loss improved from 0.2360 to 0.2359. Saving model...\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3627\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3413\n",
      "    Batch [2/2], Val Loss: 0.1305\n",
      "Epoch [1584/2000], Avg Train Loss: 0.3627, Avg Val Loss: 0.2359\n",
      "\n",
      "Validation loss improved from 0.2359 to 0.2359. Saving model...\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3606\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3412\n",
      "    Batch [2/2], Val Loss: 0.1304\n",
      "Epoch [1585/2000], Avg Train Loss: 0.3606, Avg Val Loss: 0.2358\n",
      "\n",
      "Validation loss improved from 0.2359 to 0.2358. Saving model...\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3570\n",
      "LOG: Epoch [1586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3412\n",
      "    Batch [2/2], Val Loss: 0.1303\n",
      "Epoch [1586/2000], Avg Train Loss: 0.3570, Avg Val Loss: 0.2358\n",
      "\n",
      "Validation loss improved from 0.2358 to 0.2358. Saving model...\n",
      "LOG: Epoch [1587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3614\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3412\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1587/2000], Avg Train Loss: 0.3614, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2358 to 0.2357. Saving model...\n",
      "LOG: Epoch [1588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3545\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3412\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1588/2000], Avg Train Loss: 0.3545, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2357. Saving model...\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3619\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3411\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1589/2000], Avg Train Loss: 0.3619, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2357. Saving model...\n",
      "LOG: Epoch [1590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3611\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3410\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1590/2000], Avg Train Loss: 0.3611, Avg Val Loss: 0.2356\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2356. Saving model...\n",
      "LOG: Epoch [1591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3633\n",
      "LOG: Epoch [1591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3410\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1591/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2356\n",
      "\n",
      "Validation loss improved from 0.2356 to 0.2356. Saving model...\n",
      "LOG: Epoch [1592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3553\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3409\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1592/2000], Avg Train Loss: 0.3553, Avg Val Loss: 0.2356\n",
      "\n",
      "Validation loss improved from 0.2356 to 0.2356. Saving model...\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3583\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3409\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1593/2000], Avg Train Loss: 0.3583, Avg Val Loss: 0.2355\n",
      "\n",
      "Validation loss improved from 0.2356 to 0.2355. Saving model...\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3550\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3409\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1594/2000], Avg Train Loss: 0.3550, Avg Val Loss: 0.2355\n",
      "\n",
      "Validation loss improved from 0.2355 to 0.2355. Saving model...\n",
      "LOG: Epoch [1595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3610\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3408\n",
      "    Batch [2/2], Val Loss: 0.1302\n",
      "Epoch [1595/2000], Avg Train Loss: 0.3610, Avg Val Loss: 0.2355\n",
      "\n",
      "Validation loss improved from 0.2355 to 0.2355. Saving model...\n",
      "LOG: Epoch [1596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3619\n",
      "LOG: Epoch [1596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3408\n",
      "    Batch [2/2], Val Loss: 0.1301\n",
      "Epoch [1596/2000], Avg Train Loss: 0.3619, Avg Val Loss: 0.2354\n",
      "\n",
      "Validation loss improved from 0.2355 to 0.2354. Saving model...\n",
      "LOG: Epoch [1597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3617\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3407\n",
      "    Batch [2/2], Val Loss: 0.1301\n",
      "Epoch [1597/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.2354\n",
      "\n",
      "Validation loss improved from 0.2354 to 0.2354. Saving model...\n",
      "LOG: Epoch [1598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3604\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3406\n",
      "    Batch [2/2], Val Loss: 0.1300\n",
      "Epoch [1598/2000], Avg Train Loss: 0.3604, Avg Val Loss: 0.2353\n",
      "\n",
      "Validation loss improved from 0.2354 to 0.2353. Saving model...\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3626\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3406\n",
      "    Batch [2/2], Val Loss: 0.1299\n",
      "Epoch [1599/2000], Avg Train Loss: 0.3626, Avg Val Loss: 0.2352\n",
      "\n",
      "Validation loss improved from 0.2353 to 0.2352. Saving model...\n",
      "LOG: Epoch [1600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3553\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3406\n",
      "    Batch [2/2], Val Loss: 0.1298\n",
      "Epoch [1600/2000], Avg Train Loss: 0.3553, Avg Val Loss: 0.2352\n",
      "\n",
      "Validation loss improved from 0.2352 to 0.2352. Saving model...\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3617\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3405\n",
      "    Batch [2/2], Val Loss: 0.1297\n",
      "Epoch [1601/2000], Avg Train Loss: 0.3617, Avg Val Loss: 0.2351\n",
      "\n",
      "Validation loss improved from 0.2352 to 0.2351. Saving model...\n",
      "LOG: Epoch [1602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3576\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3405\n",
      "    Batch [2/2], Val Loss: 0.1296\n",
      "Epoch [1602/2000], Avg Train Loss: 0.3576, Avg Val Loss: 0.2350\n",
      "\n",
      "Validation loss improved from 0.2351 to 0.2350. Saving model...\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3565\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3404\n",
      "    Batch [2/2], Val Loss: 0.1295\n",
      "Epoch [1603/2000], Avg Train Loss: 0.3565, Avg Val Loss: 0.2349\n",
      "\n",
      "Validation loss improved from 0.2350 to 0.2349. Saving model...\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3595\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3404\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [1604/2000], Avg Train Loss: 0.3595, Avg Val Loss: 0.2349\n",
      "\n",
      "Validation loss improved from 0.2349 to 0.2349. Saving model...\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3559\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3404\n",
      "    Batch [2/2], Val Loss: 0.1293\n",
      "Epoch [1605/2000], Avg Train Loss: 0.3559, Avg Val Loss: 0.2348\n",
      "\n",
      "Validation loss improved from 0.2349 to 0.2348. Saving model...\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3598\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3404\n",
      "    Batch [2/2], Val Loss: 0.1292\n",
      "Epoch [1606/2000], Avg Train Loss: 0.3598, Avg Val Loss: 0.2348\n",
      "\n",
      "Validation loss improved from 0.2348 to 0.2348. Saving model...\n",
      "LOG: Epoch [1607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3599\n",
      "LOG: Epoch [1607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3403\n",
      "    Batch [2/2], Val Loss: 0.1291\n",
      "Epoch [1607/2000], Avg Train Loss: 0.3599, Avg Val Loss: 0.2347\n",
      "\n",
      "Validation loss improved from 0.2348 to 0.2347. Saving model...\n",
      "LOG: Epoch [1608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3569\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3402\n",
      "    Batch [2/2], Val Loss: 0.1291\n",
      "Epoch [1608/2000], Avg Train Loss: 0.3569, Avg Val Loss: 0.2346\n",
      "\n",
      "Validation loss improved from 0.2347 to 0.2346. Saving model...\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3551\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3402\n",
      "    Batch [2/2], Val Loss: 0.1290\n",
      "Epoch [1609/2000], Avg Train Loss: 0.3551, Avg Val Loss: 0.2346\n",
      "\n",
      "Validation loss improved from 0.2346 to 0.2346. Saving model...\n",
      "LOG: Epoch [1610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3401\n",
      "    Batch [2/2], Val Loss: 0.1290\n",
      "Epoch [1610/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2345\n",
      "\n",
      "Validation loss improved from 0.2346 to 0.2345. Saving model...\n",
      "LOG: Epoch [1611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3589\n",
      "LOG: Epoch [1611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3400\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [1611/2000], Avg Train Loss: 0.3589, Avg Val Loss: 0.2345\n",
      "\n",
      "Validation loss improved from 0.2345 to 0.2345. Saving model...\n",
      "LOG: Epoch [1612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3543\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3399\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [1612/2000], Avg Train Loss: 0.3543, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2345 to 0.2344. Saving model...\n",
      "LOG: Epoch [1613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3600\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3398\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [1613/2000], Avg Train Loss: 0.3600, Avg Val Loss: 0.2344\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2344. Saving model...\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3603\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3397\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [1614/2000], Avg Train Loss: 0.3603, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2344 to 0.2343. Saving model...\n",
      "LOG: Epoch [1615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3611\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3397\n",
      "    Batch [2/2], Val Loss: 0.1289\n",
      "Epoch [1615/2000], Avg Train Loss: 0.3611, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2343. Saving model...\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3571\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3396\n",
      "    Batch [2/2], Val Loss: 0.1288\n",
      "Epoch [1616/2000], Avg Train Loss: 0.3571, Avg Val Loss: 0.2342\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2342. Saving model...\n",
      "LOG: Epoch [1617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3580\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3396\n",
      "    Batch [2/2], Val Loss: 0.1288\n",
      "Epoch [1617/2000], Avg Train Loss: 0.3580, Avg Val Loss: 0.2342\n",
      "\n",
      "Validation loss improved from 0.2342 to 0.2342. Saving model...\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3395\n",
      "    Batch [2/2], Val Loss: 0.1287\n",
      "Epoch [1618/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2342 to 0.2341. Saving model...\n",
      "LOG: Epoch [1619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3582\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3395\n",
      "    Batch [2/2], Val Loss: 0.1286\n",
      "Epoch [1619/2000], Avg Train Loss: 0.3582, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2341. Saving model...\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3589\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3394\n",
      "    Batch [2/2], Val Loss: 0.1286\n",
      "Epoch [1620/2000], Avg Train Loss: 0.3589, Avg Val Loss: 0.2340\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2340. Saving model...\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3552\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3394\n",
      "    Batch [2/2], Val Loss: 0.1285\n",
      "Epoch [1621/2000], Avg Train Loss: 0.3552, Avg Val Loss: 0.2339\n",
      "\n",
      "Validation loss improved from 0.2340 to 0.2339. Saving model...\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3596\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3394\n",
      "    Batch [2/2], Val Loss: 0.1284\n",
      "Epoch [1622/2000], Avg Train Loss: 0.3596, Avg Val Loss: 0.2339\n",
      "\n",
      "Validation loss improved from 0.2339 to 0.2339. Saving model...\n",
      "LOG: Epoch [1623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3562\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3393\n",
      "    Batch [2/2], Val Loss: 0.1283\n",
      "Epoch [1623/2000], Avg Train Loss: 0.3562, Avg Val Loss: 0.2338\n",
      "\n",
      "Validation loss improved from 0.2339 to 0.2338. Saving model...\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3550\n",
      "LOG: Epoch [1624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3392\n",
      "    Batch [2/2], Val Loss: 0.1282\n",
      "Epoch [1624/2000], Avg Train Loss: 0.3550, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2338 to 0.2337. Saving model...\n",
      "LOG: Epoch [1625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3588\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3392\n",
      "    Batch [2/2], Val Loss: 0.1282\n",
      "Epoch [1625/2000], Avg Train Loss: 0.3588, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2337. Saving model...\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3579\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1282\n",
      "Epoch [1626/2000], Avg Train Loss: 0.3579, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2337. Saving model...\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3573\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1283\n",
      "Epoch [1627/2000], Avg Train Loss: 0.3573, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3567\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1283\n",
      "Epoch [1628/2000], Avg Train Loss: 0.3567, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3604\n",
      "LOG: Epoch [1629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1283\n",
      "Epoch [1629/2000], Avg Train Loss: 0.3604, Avg Val Loss: 0.2337\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3559\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1282\n",
      "Epoch [1630/2000], Avg Train Loss: 0.3559, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2337. Saving model...\n",
      "LOG: Epoch [1631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3557\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1282\n",
      "Epoch [1631/2000], Avg Train Loss: 0.3557, Avg Val Loss: 0.2336\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2336. Saving model...\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1281\n",
      "Epoch [1632/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2336\n",
      "\n",
      "Validation loss improved from 0.2336 to 0.2336. Saving model...\n",
      "LOG: Epoch [1633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3560\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1281\n",
      "Epoch [1633/2000], Avg Train Loss: 0.3560, Avg Val Loss: 0.2335\n",
      "\n",
      "Validation loss improved from 0.2336 to 0.2335. Saving model...\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3605\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1280\n",
      "Epoch [1634/2000], Avg Train Loss: 0.3605, Avg Val Loss: 0.2335\n",
      "\n",
      "Validation loss improved from 0.2335 to 0.2335. Saving model...\n",
      "LOG: Epoch [1635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3600\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1279\n",
      "Epoch [1635/2000], Avg Train Loss: 0.3600, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2335 to 0.2334. Saving model...\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3585\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1278\n",
      "Epoch [1636/2000], Avg Train Loss: 0.3585, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2334. Saving model...\n",
      "LOG: Epoch [1637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3560\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1277\n",
      "Epoch [1637/2000], Avg Train Loss: 0.3560, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2333. Saving model...\n",
      "LOG: Epoch [1638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3616\n",
      "LOG: Epoch [1638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1276\n",
      "Epoch [1638/2000], Avg Train Loss: 0.3616, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2333. Saving model...\n",
      "LOG: Epoch [1639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3586\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1275\n",
      "Epoch [1639/2000], Avg Train Loss: 0.3586, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2333. Saving model...\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3552\n",
      "LOG: Epoch [1640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1274\n",
      "Epoch [1640/2000], Avg Train Loss: 0.3552, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2332. Saving model...\n",
      "LOG: Epoch [1641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1273\n",
      "Epoch [1641/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2332. Saving model...\n",
      "LOG: Epoch [1642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3566\n",
      "LOG: Epoch [1642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1272\n",
      "Epoch [1642/2000], Avg Train Loss: 0.3566, Avg Val Loss: 0.2331\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2331. Saving model...\n",
      "LOG: Epoch [1643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3545\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1643/2000], Avg Train Loss: 0.3545, Avg Val Loss: 0.2331\n",
      "\n",
      "Validation loss improved from 0.2331 to 0.2331. Saving model...\n",
      "LOG: Epoch [1644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3588\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3391\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1644/2000], Avg Train Loss: 0.3588, Avg Val Loss: 0.2330\n",
      "\n",
      "Validation loss improved from 0.2331 to 0.2330. Saving model...\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3572\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1645/2000], Avg Train Loss: 0.3572, Avg Val Loss: 0.2330\n",
      "\n",
      "Validation loss improved from 0.2330 to 0.2330. Saving model...\n",
      "LOG: Epoch [1646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3574\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1646/2000], Avg Train Loss: 0.3574, Avg Val Loss: 0.2329\n",
      "\n",
      "Validation loss improved from 0.2330 to 0.2329. Saving model...\n",
      "LOG: Epoch [1647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3572\n",
      "LOG: Epoch [1647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [1647/2000], Avg Train Loss: 0.3572, Avg Val Loss: 0.2329\n",
      "\n",
      "Validation loss improved from 0.2329 to 0.2329. Saving model...\n",
      "LOG: Epoch [1648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3566\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3390\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [1648/2000], Avg Train Loss: 0.3566, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2329 to 0.2328. Saving model...\n",
      "LOG: Epoch [1649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3593\n",
      "LOG: Epoch [1649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [1649/2000], Avg Train Loss: 0.3593, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2328. Saving model...\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3550\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [1650/2000], Avg Train Loss: 0.3550, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2328. Saving model...\n",
      "LOG: Epoch [1651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [1651/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1652/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3554\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1653/2000], Avg Train Loss: 0.3554, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3569\n",
      "LOG: Epoch [1654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1654/2000], Avg Train Loss: 0.3569, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3607\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1655/2000], Avg Train Loss: 0.3607, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [1656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1656/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1657/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1658/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3535\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1659/2000], Avg Train Loss: 0.3535, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3588\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1660/2000], Avg Train Loss: 0.3588, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3572\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3389\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1661/2000], Avg Train Loss: 0.3572, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3582\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3388\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1662/2000], Avg Train Loss: 0.3582, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3616\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3388\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1663/2000], Avg Train Loss: 0.3616, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3576\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3387\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1664/2000], Avg Train Loss: 0.3576, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3558\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3387\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1665/2000], Avg Train Loss: 0.3558, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2328. Saving model...\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3571\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3387\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1666/2000], Avg Train Loss: 0.3571, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2327. Saving model...\n",
      "LOG: Epoch [1667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [1667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3386\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1667/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2327. Saving model...\n",
      "LOG: Epoch [1668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3386\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1668/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2327. Saving model...\n",
      "LOG: Epoch [1669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3571\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3386\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1669/2000], Avg Train Loss: 0.3571, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3385\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1670/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3568\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3385\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1671/2000], Avg Train Loss: 0.3568, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3578\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3384\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1672/2000], Avg Train Loss: 0.3578, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3542\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3384\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1673/2000], Avg Train Loss: 0.3542, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3552\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3384\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1674/2000], Avg Train Loss: 0.3552, Avg Val Loss: 0.2328\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [1675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3383\n",
      "    Batch [2/2], Val Loss: 0.1272\n",
      "Epoch [1675/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3585\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3382\n",
      "    Batch [2/2], Val Loss: 0.1272\n",
      "Epoch [1676/2000], Avg Train Loss: 0.3585, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2327. Saving model...\n",
      "LOG: Epoch [1677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3536\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3382\n",
      "    Batch [2/2], Val Loss: 0.1272\n",
      "Epoch [1677/2000], Avg Train Loss: 0.3536, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2327. Saving model...\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3552\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3381\n",
      "    Batch [2/2], Val Loss: 0.1271\n",
      "Epoch [1678/2000], Avg Train Loss: 0.3552, Avg Val Loss: 0.2326\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2326. Saving model...\n",
      "LOG: Epoch [1679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3540\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3380\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1679/2000], Avg Train Loss: 0.3540, Avg Val Loss: 0.2325\n",
      "\n",
      "Validation loss improved from 0.2326 to 0.2325. Saving model...\n",
      "LOG: Epoch [1680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [1680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3379\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1680/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2325\n",
      "\n",
      "Validation loss improved from 0.2325 to 0.2325. Saving model...\n",
      "LOG: Epoch [1681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3582\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3379\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1681/2000], Avg Train Loss: 0.3582, Avg Val Loss: 0.2324\n",
      "\n",
      "Validation loss improved from 0.2325 to 0.2324. Saving model...\n",
      "LOG: Epoch [1682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3536\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3378\n",
      "    Batch [2/2], Val Loss: 0.1270\n",
      "Epoch [1682/2000], Avg Train Loss: 0.3536, Avg Val Loss: 0.2324\n",
      "\n",
      "Validation loss improved from 0.2324 to 0.2324. Saving model...\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3548\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3378\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1683/2000], Avg Train Loss: 0.3548, Avg Val Loss: 0.2323\n",
      "\n",
      "Validation loss improved from 0.2324 to 0.2323. Saving model...\n",
      "LOG: Epoch [1684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3531\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [1684/2000], Avg Train Loss: 0.3531, Avg Val Loss: 0.2323\n",
      "\n",
      "Validation loss improved from 0.2323 to 0.2323. Saving model...\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3564\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1268\n",
      "Epoch [1685/2000], Avg Train Loss: 0.3564, Avg Val Loss: 0.2323\n",
      "\n",
      "Validation loss improved from 0.2323 to 0.2323. Saving model...\n",
      "LOG: Epoch [1686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3596\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1267\n",
      "Epoch [1686/2000], Avg Train Loss: 0.3596, Avg Val Loss: 0.2322\n",
      "\n",
      "Validation loss improved from 0.2323 to 0.2322. Saving model...\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1266\n",
      "Epoch [1687/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2322\n",
      "\n",
      "Validation loss improved from 0.2322 to 0.2322. Saving model...\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1688/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2322 to 0.2321. Saving model...\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1689/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2321. Saving model...\n",
      "LOG: Epoch [1690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3600\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1690/2000], Avg Train Loss: 0.3600, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [1691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3378\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1691/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2321. Saving model...\n",
      "LOG: Epoch [1692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3547\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [1692/2000], Avg Train Loss: 0.3547, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2321. Saving model...\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3598\n",
      "LOG: Epoch [1693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3376\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [1693/2000], Avg Train Loss: 0.3598, Avg Val Loss: 0.2320\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2320. Saving model...\n",
      "LOG: Epoch [1694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3603\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [1694/2000], Avg Train Loss: 0.3603, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2320 to 0.2319. Saving model...\n",
      "LOG: Epoch [1695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [1695/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2319. Saving model...\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3567\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1696/2000], Avg Train Loss: 0.3567, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2318. Saving model...\n",
      "LOG: Epoch [1697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3374\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1697/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3374\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1698/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [1699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3374\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1699/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2318\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3525\n",
      "LOG: Epoch [1700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1700/2000], Avg Train Loss: 0.3525, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3569\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1701/2000], Avg Train Loss: 0.3569, Avg Val Loss: 0.2317\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2317. Saving model...\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3574\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1702/2000], Avg Train Loss: 0.3574, Avg Val Loss: 0.2317\n",
      "\n",
      "Validation loss improved from 0.2317 to 0.2317. Saving model...\n",
      "LOG: Epoch [1703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3548\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1703/2000], Avg Train Loss: 0.3548, Avg Val Loss: 0.2317\n",
      "\n",
      "Validation loss improved from 0.2317 to 0.2317. Saving model...\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3576\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1704/2000], Avg Train Loss: 0.3576, Avg Val Loss: 0.2316\n",
      "\n",
      "Validation loss improved from 0.2317 to 0.2316. Saving model...\n",
      "LOG: Epoch [1705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3525\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1705/2000], Avg Train Loss: 0.3525, Avg Val Loss: 0.2316\n",
      "\n",
      "Validation loss improved from 0.2316 to 0.2316. Saving model...\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3375\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1706/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2316\n",
      "\n",
      "Validation loss improved from 0.2316 to 0.2316. Saving model...\n",
      "LOG: Epoch [1707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3547\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3374\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1707/2000], Avg Train Loss: 0.3547, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2316 to 0.2315. Saving model...\n",
      "LOG: Epoch [1708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3374\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1708/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3562\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3373\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1709/2000], Avg Train Loss: 0.3562, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [1710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3373\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1710/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3559\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3372\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1711/2000], Avg Train Loss: 0.3559, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3541\n",
      "LOG: Epoch [1712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3372\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [1712/2000], Avg Train Loss: 0.3541, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [1713/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1714/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3558\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1715/2000], Avg Train Loss: 0.3558, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1716/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [1717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1717/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [1718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1718/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1719/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3536\n",
      "LOG: Epoch [1720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1720/2000], Avg Train Loss: 0.3536, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3558\n",
      "LOG: Epoch [1721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [1721/2000], Avg Train Loss: 0.3558, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2315. Saving model...\n",
      "LOG: Epoch [1722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3564\n",
      "LOG: Epoch [1722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3371\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1722/2000], Avg Train Loss: 0.3564, Avg Val Loss: 0.2314\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2314. Saving model...\n",
      "LOG: Epoch [1723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3526\n",
      "LOG: Epoch [1723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3370\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1723/2000], Avg Train Loss: 0.3526, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2314 to 0.2313. Saving model...\n",
      "LOG: Epoch [1724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [1724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3370\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1724/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2313. Saving model...\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [1725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3369\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1725/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2313. Saving model...\n",
      "LOG: Epoch [1726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3538\n",
      "LOG: Epoch [1726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3368\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1726/2000], Avg Train Loss: 0.3538, Avg Val Loss: 0.2312\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2312. Saving model...\n",
      "LOG: Epoch [1727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3367\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1727/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2312\n",
      "\n",
      "Validation loss improved from 0.2312 to 0.2312. Saving model...\n",
      "LOG: Epoch [1728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3564\n",
      "LOG: Epoch [1728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3366\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1728/2000], Avg Train Loss: 0.3564, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2312 to 0.2311. Saving model...\n",
      "LOG: Epoch [1729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3534\n",
      "LOG: Epoch [1729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3365\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1729/2000], Avg Train Loss: 0.3534, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [1730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3593\n",
      "LOG: Epoch [1730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3364\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [1730/2000], Avg Train Loss: 0.3593, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [1731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [1731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3363\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1731/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3363\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1732/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3517\n",
      "LOG: Epoch [1733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3363\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1733/2000], Avg Train Loss: 0.3517, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3362\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1734/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3362\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1735/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3569\n",
      "LOG: Epoch [1736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3362\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1736/2000], Avg Train Loss: 0.3569, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3361\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1737/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3568\n",
      "LOG: Epoch [1738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3361\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1738/2000], Avg Train Loss: 0.3568, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [1739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3360\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1739/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1740/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [1741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3559\n",
      "LOG: Epoch [1741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1741/2000], Avg Train Loss: 0.3559, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2310. Saving model...\n",
      "LOG: Epoch [1742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3520\n",
      "LOG: Epoch [1742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1742/2000], Avg Train Loss: 0.3520, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2310. Saving model...\n",
      "LOG: Epoch [1743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [1743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1743/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2310. Saving model...\n",
      "LOG: Epoch [1744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1744/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2310\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [1745/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3555\n",
      "LOG: Epoch [1746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [1746/2000], Avg Train Loss: 0.3555, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [1747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [1747/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [1748/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [1749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [1749/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1750/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1751/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1265\n",
      "Epoch [1752/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1264\n",
      "Epoch [1753/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3550\n",
      "LOG: Epoch [1754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1263\n",
      "Epoch [1754/2000], Avg Train Loss: 0.3550, Avg Val Loss: 0.2311\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3555\n",
      "LOG: Epoch [1755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3359\n",
      "    Batch [2/2], Val Loss: 0.1262\n",
      "Epoch [1755/2000], Avg Train Loss: 0.3555, Avg Val Loss: 0.2310\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1261\n",
      "Epoch [1756/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2310. Saving model...\n",
      "LOG: Epoch [1757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3358\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [1757/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2309\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2309. Saving model...\n",
      "LOG: Epoch [1758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3357\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1758/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2309 to 0.2308. Saving model...\n",
      "LOG: Epoch [1759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [1759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3357\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [1759/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2308. Saving model...\n",
      "LOG: Epoch [1760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3357\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [1760/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2307. Saving model...\n",
      "LOG: Epoch [1761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [1761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3356\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1761/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2307. Saving model...\n",
      "LOG: Epoch [1762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3356\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1762/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2306\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2306. Saving model...\n",
      "LOG: Epoch [1763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3543\n",
      "LOG: Epoch [1763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3355\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1763/2000], Avg Train Loss: 0.3543, Avg Val Loss: 0.2305\n",
      "\n",
      "Validation loss improved from 0.2306 to 0.2305. Saving model...\n",
      "LOG: Epoch [1764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3354\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1764/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2305\n",
      "\n",
      "Validation loss improved from 0.2305 to 0.2305. Saving model...\n",
      "LOG: Epoch [1765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3353\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1765/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2305\n",
      "\n",
      "Validation loss improved from 0.2305 to 0.2305. Saving model...\n",
      "LOG: Epoch [1766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3353\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1766/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2304\n",
      "\n",
      "Validation loss improved from 0.2305 to 0.2304. Saving model...\n",
      "LOG: Epoch [1767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3557\n",
      "LOG: Epoch [1767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3352\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1767/2000], Avg Train Loss: 0.3557, Avg Val Loss: 0.2304\n",
      "\n",
      "Validation loss improved from 0.2304 to 0.2304. Saving model...\n",
      "LOG: Epoch [1768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3535\n",
      "LOG: Epoch [1768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3351\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1768/2000], Avg Train Loss: 0.3535, Avg Val Loss: 0.2304\n",
      "\n",
      "Validation loss improved from 0.2304 to 0.2304. Saving model...\n",
      "LOG: Epoch [1769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3350\n",
      "    Batch [2/2], Val Loss: 0.1257\n",
      "Epoch [1769/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2303\n",
      "\n",
      "Validation loss improved from 0.2304 to 0.2303. Saving model...\n",
      "LOG: Epoch [1770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3350\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1770/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2303\n",
      "\n",
      "Validation loss improved from 0.2303 to 0.2303. Saving model...\n",
      "LOG: Epoch [1771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3554\n",
      "LOG: Epoch [1771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [1771/2000], Avg Train Loss: 0.3554, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2303 to 0.2302. Saving model...\n",
      "LOG: Epoch [1772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [1772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [1772/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2302. Saving model...\n",
      "LOG: Epoch [1773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3541\n",
      "LOG: Epoch [1773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1254\n",
      "Epoch [1773/2000], Avg Train Loss: 0.3541, Avg Val Loss: 0.2301\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2301. Saving model...\n",
      "LOG: Epoch [1774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3551\n",
      "LOG: Epoch [1774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1252\n",
      "Epoch [1774/2000], Avg Train Loss: 0.3551, Avg Val Loss: 0.2301\n",
      "\n",
      "Validation loss improved from 0.2301 to 0.2301. Saving model...\n",
      "LOG: Epoch [1775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [1775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1250\n",
      "Epoch [1775/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2300\n",
      "\n",
      "Validation loss improved from 0.2301 to 0.2300. Saving model...\n",
      "LOG: Epoch [1776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1249\n",
      "Epoch [1776/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2300 to 0.2299. Saving model...\n",
      "LOG: Epoch [1777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1247\n",
      "Epoch [1777/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2298\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2298. Saving model...\n",
      "LOG: Epoch [1778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1246\n",
      "Epoch [1778/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2297\n",
      "\n",
      "Validation loss improved from 0.2298 to 0.2297. Saving model...\n",
      "LOG: Epoch [1779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [1779/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2296\n",
      "\n",
      "Validation loss improved from 0.2297 to 0.2296. Saving model...\n",
      "LOG: Epoch [1780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3535\n",
      "LOG: Epoch [1780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1780/2000], Avg Train Loss: 0.3535, Avg Val Loss: 0.2296\n",
      "\n",
      "Validation loss improved from 0.2296 to 0.2296. Saving model...\n",
      "LOG: Epoch [1781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3517\n",
      "LOG: Epoch [1781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1242\n",
      "Epoch [1781/2000], Avg Train Loss: 0.3517, Avg Val Loss: 0.2295\n",
      "\n",
      "Validation loss improved from 0.2296 to 0.2295. Saving model...\n",
      "LOG: Epoch [1782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [1782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [1782/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2295\n",
      "\n",
      "Validation loss improved from 0.2295 to 0.2295. Saving model...\n",
      "LOG: Epoch [1783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [1783/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2294\n",
      "\n",
      "Validation loss improved from 0.2295 to 0.2294. Saving model...\n",
      "LOG: Epoch [1784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3524\n",
      "LOG: Epoch [1784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1240\n",
      "Epoch [1784/2000], Avg Train Loss: 0.3524, Avg Val Loss: 0.2294\n",
      "\n",
      "Validation loss improved from 0.2294 to 0.2294. Saving model...\n",
      "LOG: Epoch [1785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [1785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3347\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [1785/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2294 to 0.2293. Saving model...\n",
      "LOG: Epoch [1786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3347\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [1786/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2293. Saving model...\n",
      "LOG: Epoch [1787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [1787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3347\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [1787/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2292. Saving model...\n",
      "LOG: Epoch [1788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [1788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [1788/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2292. Saving model...\n",
      "LOG: Epoch [1789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [1789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1789/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2292. Saving model...\n",
      "LOG: Epoch [1790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [1790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1790/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3526\n",
      "LOG: Epoch [1791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1791/2000], Avg Train Loss: 0.3526, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3534\n",
      "LOG: Epoch [1792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1792/2000], Avg Train Loss: 0.3534, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1793/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [1794/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [1795/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3349\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [1796/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2293\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3526\n",
      "LOG: Epoch [1797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [1797/2000], Avg Train Loss: 0.3526, Avg Val Loss: 0.2293\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3562\n",
      "LOG: Epoch [1798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1240\n",
      "Epoch [1798/2000], Avg Train Loss: 0.3562, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [1799/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [1800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3347\n",
      "    Batch [2/2], Val Loss: 0.1242\n",
      "Epoch [1800/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2295\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3347\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1801/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2295\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3346\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1802/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2295\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3522\n",
      "LOG: Epoch [1803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3345\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1803/2000], Avg Train Loss: 0.3522, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3344\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1804/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3344\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1805/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [1806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3344\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [1806/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [1807/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [1808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [1808/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [1809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [1809/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [1810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [1810/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3344\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [1811/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [1812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3344\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [1812/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [1813/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [1814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [1814/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2294\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [1815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [1815/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2293\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3343\n",
      "    Batch [2/2], Val Loss: 0.1242\n",
      "Epoch [1816/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2292\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [1817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3342\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [1817/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2291. Saving model...\n",
      "LOG: Epoch [1818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [1818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3342\n",
      "    Batch [2/2], Val Loss: 0.1240\n",
      "Epoch [1818/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2291. Saving model...\n",
      "LOG: Epoch [1819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3342\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [1819/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2290\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2290. Saving model...\n",
      "LOG: Epoch [1820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [1820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [1820/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2290\n",
      "\n",
      "Validation loss improved from 0.2290 to 0.2290. Saving model...\n",
      "LOG: Epoch [1821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [1821/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2289\n",
      "\n",
      "Validation loss improved from 0.2290 to 0.2289. Saving model...\n",
      "LOG: Epoch [1822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [1822/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2289\n",
      "\n",
      "Validation loss improved from 0.2289 to 0.2289. Saving model...\n",
      "LOG: Epoch [1823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [1823/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2289\n",
      "\n",
      "Validation loss improved from 0.2289 to 0.2289. Saving model...\n",
      "LOG: Epoch [1824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [1824/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2289 to 0.2288. Saving model...\n",
      "LOG: Epoch [1825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1825/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2288. Saving model...\n",
      "LOG: Epoch [1826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [1826/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2288. Saving model...\n",
      "LOG: Epoch [1827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1234\n",
      "Epoch [1827/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2288. Saving model...\n",
      "LOG: Epoch [1828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1234\n",
      "Epoch [1828/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2287. Saving model...\n",
      "LOG: Epoch [1829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3499\n",
      "LOG: Epoch [1829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1234\n",
      "Epoch [1829/2000], Avg Train Loss: 0.3499, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [1830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [1830/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [1831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [1831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [1831/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [1832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [1832/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [1833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [1833/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [1834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3558\n",
      "LOG: Epoch [1834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [1834/2000], Avg Train Loss: 0.3558, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2286. Saving model...\n",
      "LOG: Epoch [1835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [1835/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [1836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [1836/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [1837/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3538\n",
      "LOG: Epoch [1838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [1838/2000], Avg Train Loss: 0.3538, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [1839/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [1840/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1841/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [1842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [1842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1842/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2285. Saving model...\n",
      "LOG: Epoch [1843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1843/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1844/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3341\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1845/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [1846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1846/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [1847/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1848/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1849/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1850/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1851/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [1852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1852/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3528\n",
      "LOG: Epoch [1853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1853/2000], Avg Train Loss: 0.3528, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1854/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3541\n",
      "LOG: Epoch [1855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1855/2000], Avg Train Loss: 0.3541, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1856/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [1857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1857/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1858/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2285. Saving model...\n",
      "LOG: Epoch [1859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1859/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2284. Saving model...\n",
      "LOG: Epoch [1860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [1860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1860/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1861/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1862/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1863/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1864/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3532\n",
      "LOG: Epoch [1865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1865/2000], Avg Train Loss: 0.3532, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1866/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1867/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3525\n",
      "LOG: Epoch [1868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1868/2000], Avg Train Loss: 0.3525, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [1869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1869/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3540\n",
      "LOG: Epoch [1870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1870/2000], Avg Train Loss: 0.3540, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1871/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1872/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [1873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1873/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3499\n",
      "LOG: Epoch [1874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1874/2000], Avg Train Loss: 0.3499, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [1875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1875/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1876/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1877/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1878/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1879/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1880/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1881/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1882/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1883/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1884/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1885/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1886/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1887/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1888/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1889/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1890/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1891/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [1892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1892/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [1893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1893/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1894/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1895/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [1896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1896/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1897/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1898/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [1899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1899/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1900/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1901/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [1902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1902/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [1903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1903/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [1904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1904/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1905/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1906/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1907/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1908/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1909/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1910/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1911/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3520\n",
      "LOG: Epoch [1912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1912/2000], Avg Train Loss: 0.3520, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1913/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1914/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1915/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1916/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1917/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [1918/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [1919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1919/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1920/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2284\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1921/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1922/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2284. Saving model...\n",
      "LOG: Epoch [1923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1923/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2283. Saving model...\n",
      "LOG: Epoch [1924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3522\n",
      "LOG: Epoch [1924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1924/2000], Avg Train Loss: 0.3522, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1925/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3339\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1926/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1927/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1928/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [1929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1929/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1930/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1931/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1932/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [1933/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1934/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1935/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1936/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1937/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1938/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [1939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1939/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2282. Saving model...\n",
      "LOG: Epoch [1940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [1940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1940/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1941/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [1942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1942/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1943/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3525\n",
      "LOG: Epoch [1944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1944/2000], Avg Train Loss: 0.3525, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1945/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1946/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [1947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1947/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1948/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1949/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1950/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1951/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1952/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1953/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1954/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1955/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1956/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [1957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1957/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3534\n",
      "LOG: Epoch [1958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1958/2000], Avg Train Loss: 0.3534, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3544\n",
      "LOG: Epoch [1959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1959/2000], Avg Train Loss: 0.3544, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3528\n",
      "LOG: Epoch [1960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1960/2000], Avg Train Loss: 0.3528, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1961/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3525\n",
      "LOG: Epoch [1962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1962/2000], Avg Train Loss: 0.3525, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1963/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [1964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1964/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [1965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1965/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1966/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1967/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [1968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1968/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [1969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1969/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1970/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1971/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1972/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1973/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [1974/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1975/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [1976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1976/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1977/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [1978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1978/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [1979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1979/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [1980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1980/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1981/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1982/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1983/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [1984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1984/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1985/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1986/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1987/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1988/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1989/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1990/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1991/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2282\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1992/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [1993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1993/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1994/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [1995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3568\n",
      "LOG: Epoch [1995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1995/2000], Avg Train Loss: 0.3568, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2281. Saving model...\n",
      "LOG: Epoch [1996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [1996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3337\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1996/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2281. Saving model...\n",
      "LOG: Epoch [1997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3336\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1997/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2281. Saving model...\n",
      "LOG: Epoch [1998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [1998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3336\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1998/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2281. Saving model...\n",
      "LOG: Epoch [1999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [1999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3336\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [1999/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2281. Saving model...\n",
      "LOG: Epoch [2000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [2000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3336\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [2000/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2281. Saving model...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:20.807553Z",
     "iopub.status.busy": "2025-05-08T19:03:20.807553Z",
     "iopub.status.idle": "2025-05-08T19:03:21.046635Z",
     "shell.execute_reply": "2025-05-08T19:03:21.046635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/46], Loss: 0.2179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [20/46], Loss: 0.2116\n",
      "Test Batch [30/46], Loss: 0.3057\n",
      "Test Batch [40/46], Loss: 0.2386\n",
      "\n",
      "Test Loss: 0.2547\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC9oUlEQVR4nOzdd3hT1RsH8G9Gm+5NB9DFLNDBhjLL3oqAIBsEWYI/xAWCCIjiBEQBRRQUFVFRHMzK3rtlb0qB7kL3SpP7+yM0bZqkTduEdHw/z9OH3HPPvffkpIW+nHPeIxIEQQARERERERFViNjcDSAiIiIiIqoOGFwREREREREZAYMrIiIiIiIiI2BwRUREREREZAQMroiIiIiIiIyAwRUREREREZERMLgiIiIiIiIyAgZXRERERERERsDgioiIiIiIyAgYXBFRhYhEIoO+Dhw4UKHnLFq0CCKRqFzXHjhwwChtMIbIyEiIRCLMnTtXb52bN29CJBLhlVdeMfi+uvonLCwMYWFhpV4bFRUFkUiEjRs3Gvy8AleuXMGiRYsQFRWldW7ChAnw8/Mr8z2rA5FIhEWLFuk9HxYWZtDPTUn3KIs1a9aU6fP18/PDwIEDjfLsqqrg58LUn01F8HMiqnyk5m4AEVVtx48f1zh+7733sH//fuzbt0+jvGnTphV6zuTJk9G3b99yXduyZUscP368wm0whpCQELRq1Qo//PAD3n//fUgkEq06GzZsAABMmjSpQs9as2ZNha43xJUrV7B48WKEhYVpBVLvvPMO/ve//5m8DVXRmjVrkJaWpj7evn07li5dig0bNiAgIEBdXrduXaM9z83NDRMmTDDK/WqSWbNmYdSoUVrlxvpsiKh6YXBFRBXSvn17jeNatWpBLBZrlReXlZUFGxsbg59Tt27dcv8y4+DgUGp7nqZJkyZhxowZ2Llzp9b/OisUCvzwww9o1aoVQkJCKvQccweT9evXN+vzK7Pin821a9cAAIGBgWjdurU5mkR6+Pj4VKq/P4iocuO0QCIyubCwMAQGBuLQoUPo0KEDbGxs8OKLLwIAtmzZgt69e8PLywvW1tZo0qQJ5s6di8zMTI176Jr2VjAlZteuXWjZsiWsra0REBCA7777TqOermmBEyZMgJ2dHW7duoX+/fvDzs4O3t7eeO2115Cbm6tx/YMHDzBs2DDY29vDyckJo0ePxunTp8s9lW7UqFGwtrZWj1AVtWfPHjx8+LDM/aOLrmmBMTExGD58OOzt7eHo6IgRI0YgLi5O69ozZ87ghRdegJ+fH6ytreHn54eRI0fi3r176jobN27E888/DwDo1q2berpUQZ/omhaYk5ODefPmwd/fH5aWlqhTpw5efvllpKSkaNQz9LMti/DwcDz77LOoW7curKys0KBBA0ydOhVJSUka9Qq+1y5fvoyRI0fC0dERHh4eePHFF5GamqpRNy0tDS+99BJcXV1hZ2eHvn374saNG+VuY3FbtmxBaGgobG1tYWdnhz59+uD8+fMade7cuYMXXngBtWvXhkwmg4eHB3r06IGIiAgAqr68fPkyDh48qP6MjDFd09DPct++fQgLC4Orqyusra3h4+ODoUOHIisrS11n7dq1CAkJgZ2dHezt7REQEIC3335b77Plcjnc3d0xduxYrXMpKSmwtrbGnDlzAABKpRJLly5F48aNYW1tDScnJwQHB+Pzzz+vcB8UKPg77vDhw2jfvj2sra1Rp04dvPPOO1AoFBp1Hz16hBkzZqBOnTqwtLREvXr1MH/+fK2/d5RKJb744gs0b95c3e727dvj77//1np+aT8nWVlZeP311+Hv7w8rKyu4uLigdevW2Lx5s9H6gIhUOHJFRE9FbGwsxowZgzfffBMffPABxGLV/+3cvHkT/fv3x+zZs2Fra4tr167ho48+wqlTp7SmFuoSGRmJ1157DXPnzoWHhwfWr1+PSZMmoUGDBujSpUuJ18rlcjzzzDOYNGkSXnvtNRw6dAjvvfceHB0dsXDhQgBAZmYmunXrhkePHuGjjz5CgwYNsGvXLowYMaLcfeHo6IihQ4diy5YtSExMRK1atdTnNmzYACsrK/U0pIr2T1HZ2dno2bMnYmJisGzZMjRq1Ajbt2/X+V6ioqLQuHFjvPDCC3BxcUFsbCzWrl2LNm3a4MqVK3Bzc8OAAQPwwQcf4O2338bq1avRsmVLAPpHrARBwODBg7F3717MmzcPnTt3xoULF/Duu+/i+PHjOH78OGQymbp+RT5bXW7fvo3Q0FBMnjwZjo6OiIqKwvLly9GpUydcvHgRFhYWGvWHDh2KESNGYNKkSbh48SLmzZsHAOpfXAvez7Fjx7Bw4UK0adMGR48eRb9+/crcNl0++OADLFiwABMnTsSCBQuQl5eHTz75BJ07d8apU6fUo1/9+/eHQqHAxx9/DB8fHyQlJeHYsWPqIOfPP//EsGHD4OjoqJ4qWrSfy8PQzzIqKgoDBgxA586d8d1338HJyQkPHz7Erl27kJeXBxsbG/zyyy+YMWMGZs2ahU8//RRisRi3bt3ClStX9D7fwsICY8aMwVdffYXVq1fDwcFBfW7z5s3IycnBxIkTAQAff/wxFi1ahAULFqBLly6Qy+W4du2aVhCoj1KpRH5+vla5VKr5K1RcXBxeeOEFzJ07F0uWLFFP9Xz8+DG+/PJLAKqAtFu3brh9+zYWL16M4OBgHD58GMuWLUNERAS2b9+uvt+ECRPw448/YtKkSViyZAksLS1x7tw5rfWNhvyczJkzB5s2bcLSpUvRokULZGZm4tKlS0hOTjaoD4ioDAQiIiMaP368YGtrq1HWtWtXAYCwd+/eEq9VKpWCXC4XDh48KAAQIiMj1efeffddofhfWb6+voKVlZVw7949dVl2drbg4uIiTJ06VV22f/9+AYCwf/9+jXYCEH799VeNe/bv319o3Lix+nj16tUCAGHnzp0a9aZOnSoAEDZs2FDie9KnoE3Lly9XlyUnJwsymUwYPXq0zmvK2j9du3YVunbtqj5eu3atAED466+/NOq99NJLpb6X/Px8ISMjQ7C1tRU+//xzdflvv/2m1bcFxo8fL/j6+qqPd+3aJQAQPv74Y416W7ZsEQAI69atU5cZ+tmWV0Ff3rt3T6tPCvqyeDtnzJghWFlZCUqlUhAEQdi5c6cAQKM/BEEQ3n//fQGA8O677xrcng0bNggAhNOnTwuCIAjR0dGCVCoVZs2apVEvPT1d8PT0FIYPHy4IgiAkJSUJAISVK1eWeP9mzZppfC+UxtfXVxgwYIDe84Z+lr///rsAQIiIiNB7r5kzZwpOTk4Gt63AhQsXtL5vBEEQ2rZtK7Rq1Up9PHDgQKF58+Zlvv/du3cFAHq/Dh8+rK5b8Hecrp8tsVis/j7+6quvdP6989FHHwkAhD179giCIAiHDh0SAAjz588vsY2G/pwEBgYKgwcPLnMfEFHZcVogET0Vzs7O6N69u1b5nTt3MGrUKHh6ekIikcDCwgJdu3YFAFy9erXU+zZv3hw+Pj7qYysrKzRq1Ehj+po+IpEIgwYN0igLDg7WuPbgwYOwt7fXSqYxcuTIUu9fkq5du6J+/foaUwN/+ukn5ObmqqcEAhXvn6L2798Pe3t7PPPMMxrluhbrZ2Rk4K233kKDBg0glUohlUphZ2eHzMzMMj+3QMFIW/GkCs8//zxsbW2xd+9ejfKKfLa6JCQkYNq0afD29oZUKoWFhQV8fX0B6O7L4v0UHByMnJwcJCQkAFD1JwCMHj1ao56u/iyr3bt3Iz8/H+PGjUN+fr76y8rKCl27dlVPcXVxcUH9+vXxySefYPny5Th//jyUSmWFn18aQz/L5s2bw9LSElOmTMH333+PO3fuaN2rbdu2SElJwciRI/HXX39pTdPUJygoCK1atdL4Gbp69SpOnTql8TPUtm1bREZGYsaMGdi9e7dGIhFD/O9//8Pp06e1vpo3b65RT9/PllKpxKFDhwCo+s3W1hbDhg3TqFfQjwX9tnPnTgDAyy+/XGr7DPk5adu2LXbu3Im5c+fiwIEDyM7ONuzNE1GZMbgioqfCy8tLqywjIwOdO3fGyZMnsXTpUhw4cACnT5/GH3/8AQAG/QLg6uqqVSaTyQy61sbGBlZWVlrX5uTkqI+Tk5Ph4eGhda2usrIQiUR48cUXcfHiRZw5cwaAakqgv78/unXrBsA4/VOUvvfi6empVTZq1Ch8+eWXmDx5Mnbv3o1Tp07h9OnTqFWrVrl/MUtOToZUKtWYBgmo+sLT01NrilJFPtvilEolevfujT/++ANvvvkm9u7di1OnTuHEiRMAdPdl8ecXTKUrqFvwforX09WfZRUfHw8AaNOmDSwsLDS+tmzZog5ARCIR9u7diz59+uDjjz9Gy5YtUatWLbzyyitIT0+vcDv0MfSzrF+/Pv777z+4u7vj5ZdfRv369VG/fn2N9U5jx47Fd999h3v37mHo0KFwd3dHu3btEB4eXmo7XnzxRRw/flydEGTDhg2QyWQa//kxb948fPrppzhx4gT69esHV1dX9OjRQ/1zV5q6deuidevWWl92dnYa9Ur62Sroj+TkZHh6emqtH3V3d4dUKlXXS0xMhEQiMeh7yZCfk1WrVuGtt97Ctm3b0K1bN7i4uGDw4MG4efNmqfcnorJhcEVET4WuPar27duHmJgYfPfdd5g8eTK6dOmC1q1bw97e3gwt1M3V1VX9i25RupJAlNWECRMgkUjw3XffITIyEufPn8eLL76o7itj94+h7yU1NRX//vsv3nzzTcydOxc9evRAmzZtEBQUhEePHpXr2QXPz8/PR2Jioka5IAiIi4uDm5tbue9dmkuXLiEyMhKffPIJZs2ahbCwMLRp00bnL6aGKng/xYNCY3xvFPTF77//rnPU5OTJk+q6vr6++PbbbxEXF4fr16/j1VdfxZo1a/DGG29UuB36lOWz7Ny5M/755x+kpqbixIkTCA0NxezZs/HLL7+o60ycOBHHjh1Damoqtm/fDkEQMHDgwFJHKUeOHAmZTIaNGzdCoVBg06ZNGDx4MJydndV1pFIp5syZg3PnzuHRo0fYvHkz7t+/jz59+mgk1aiokn62Cr7PCn4GBUHQqJeQkID8/Hx1v9WqVQsKhcIo30sAYGtri8WLF+PatWuIi4vD2rVrceLECa2ReyKqOAZXRGQ2BUFE8cX1X3/9tTmao1PXrl2Rnp6unqZToOgvhuVVu3Zt9O3bF5s3b8bq1ashFosxfvx49Xlj90+3bt2Qnp6ulW3s559/1jgWiUQQBEHruevXr9fKfFZ8NKckPXr0AAD8+OOPGuVbt25FZmam+rwpmOJ7rWCE8aefftIoL96f5dGnTx9IpVLcvn1b56iJvnTtjRo1woIFCxAUFIRz586py8s74qdPeT5LiUSCdu3aYfXq1QCg0b4Ctra26NevH+bPn4+8vDxcvny5xHY4Oztj8ODB+OGHH/Dvv/8iLi5OY0pgcU5OThg2bBhefvllPHr0SOfm1+Wl72dLLBarE0v06NEDGRkZ2LZtm0a9H374QX0egDopytq1a43WvgIeHh6YMGECRo4cievXrxs1wCQiZgskIjPq0KEDnJ2dMW3aNLz77ruwsLDATz/9hMjISHM3TW38+PFYsWIFxowZg6VLl6JBgwbYuXMndu/eDQDqrIeAKsOev78/xo8fb3CK9kmTJmH79u1Yv349+vTpA29vb/U5Y/fPuHHjsGLFCowbNw7vv/8+GjZsiB07dqjfSwEHBwd06dIFn3zyCdzc3ODn54eDBw/i22+/hZOTk0bdwMBAAMC6detgb28PKysr+Pv76xwR6tWrF/r06YO33noLaWlp6NixozrDXIsWLXSm1TZEQVrxkn5RDggIQP369TF37lwIggAXFxf8888/Bk0906d3797o0qUL3nzzTWRmZqJ169Y4evQoNm3aVO57FvDz88OSJUswf/583LlzB3379oWzszPi4+Nx6tQp9UjEhQsXMHPmTDz//PNo2LAhLC0tsW/fPly4cAFz585V3y8oKAi//PILtmzZgnr16sHKygpBQUEltiEuLg6///67zrYZ+ll+9dVX2LdvHwYMGAAfHx/k5OSosy327NkTAPDSSy/B2toaHTt2hJeXF+Li4rBs2TI4OjqiTZs2pfbViy++iC1btmDmzJmoW7eu+r4FBg0apN4/rFatWrh37x5WrlwJX19fNGzYsNT7R0dHq6ePFlWrVi2NzJiurq6YPn06oqOj0ahRI+zYsQPffPMNpk+frl4TNW7cOKxevRrjx49HVFQUgoKCcOTIEXzwwQfo37+/uu2dO3fG2LFjsXTpUsTHx2PgwIGQyWQ4f/48bGxsMGvWrFLbXVS7du0wcOBABAcHw9nZGVevXsWmTZsQGhpapv0GicgA5symQUTVj75sgc2aNdNZ/9ixY0JoaKhgY2Mj1KpVS5g8ebJw7tw5rex1+rIF6spoVjxLnr5sgcXbqe850dHRwpAhQwQ7OzvB3t5eGDp0qLBjxw6t7GAXL14UAAhz587V+V51ycvLEzw8PHRmEBOEivVP8X4QBEF48OCBMHToUI33cuzYMa37FdRzdnYW7O3thb59+wqXLl0SfH19hfHjx2vcc+XKlYK/v78gkUg07lM8W6AgqDKZvfXWW4Kvr69gYWEheHl5CdOnTxceP36sUc/Qz1YQBMHNzU1o3769Vt3irly5IvTq1Uuwt7cXnJ2dheeff16Ijo7WyuxX0JeJiYka1xdk9Lt79666LCUlRXjxxRcFJycnwcbGRujVq5dw7dq1CmcLLLBt2zahW7dugoODgyCTyQRfX19h2LBhwn///ScIgiDEx8cLEyZMEAICAgRbW1vBzs5OCA4OFlasWCHk5+er7xMVFSX07t1bsLe3FwBofS7F+fr66s2SV/D5G/JZHj9+XHjuuecEX19fQSaTCa6urkLXrl2Fv//+W13n+++/F7p16yZ4eHgIlpaWQu3atYXhw4cLFy5cMKjvFAqF4O3trTe73meffSZ06NBBcHNzEywtLQUfHx9h0qRJQlRUVIn3LS1bYNGsngV/xx04cEBo3bq1IJPJBC8vL+Htt98W5HK5xn2Tk5OFadOmCV5eXoJUKhV8fX2FefPmCTk5OVrva8WKFUJgYKBgaWkpODo6CqGhocI///yjrmPoz8ncuXOF1q1bC87OzoJMJhPq1asnvPrqq0JSUlKJfUBEZScShGITf4mIqFQFexBFR0ejbt26AIA1a9bgzTffxO3btyuc8IIMc+XKFTRr1gz//vsvBgwYYO7mUA0VFhaGpKQkXLp0ydxNISIz47RAIqJSFGwAGhAQALlcjn379mHVqlUYM2aMOrACVKm5X3nlFQZWT9H+/fsRGhrKwIqIiCoFjlwREZXiu+++w4oVKxAVFYXc3Fz4+Phg1KhRWLBgASwtLc3dPCIyM45cEVEBBldERERERERGwFTsRERERERERsDgioiIiIiIyAgYXBERERERERkBswXqoFQqERMTA3t7e4hEInM3h4iIiIiIzEQQBKSnp6N27doQi0sem2JwpUNMTAy8vb3N3QwiIiIiIqok7t+/r7EFiy4MrnSwt7cHoOpABwcHs7ZFLpdjz5496N27NywsLMzaluqI/Wta7F/TYv+aHvvYtNi/psX+NS32r2lVpv5NS0uDt7e3OkYoCYMrHQqmAjo4OFSK4MrGxgYODg5m/8aqjti/psX+NS32r+mxj02L/Wta7F/TYv+aVmXsX0OWCzGhBRERERERkREwuCIiIiIiIjICBldERERERERGwDVXRERERERlJAgCxGIxcnNzoVAozN2cakcul0MqlSInJ+ep9K+FhQUkEkmF78PgioiIiIioDPLy8vDw4UN4eXkhOjqa+6KagCAI8PT0xP37959K/4pEItStWxd2dnYVug+DKyIiIiIiAymVSty9exdisRi1a9eGo6OjUUY8SJNSqURGRgbs7OxK3bi3ogRBQGJiIh48eICGDRtW6PNkcEVEREREZKC8vDwolUrUqVMH+fn5sLa2Nvkv/zWRUqlEXl4erKysnkr/1qpVC1FRUZDL5RUKrvidQERERERURgyoqhdjTT3kdwUREREREZERMLgiIiIiIiIyAgZXRERERERULmFhYZg9e7a5m1FpMKEFEREREVE1V9qaovHjx2Pjxo1lvu8ff/wBCwuLcrZKZcKECUhJScG2bdsqdJ/KgMEVEREREVE1Fxsbq369ZcsWLFy4ENevX1eXWVtba9SXy+UGBU0uLi7Ga2Q1wGmBREREREQVIAgCsvLyn/qXIAgGt9HT01P95ejoCJFIpD7OycmBk5MTfv31V4SFhcHKygo//vgjkpOTMXLkSNStWxc2NjYICgrC5s2bNe5bfFqgn58fPvjgA7z44ouwt7eHj48P1q1bV6H+PXjwINq2bQuZTAYvLy/MnTsX+fn56vO///47goKCYG1tDVdXV/Ts2ROZmZkAgAMHDqBt27awtbWFk5MTOnbsiHv37lWoPSXhyBURERERUQVkyxVounD3U3/ulSV9YGNpvF/n33rrLXz22WfYsGEDZDIZcnJy0KpVK7z11ltwcHDA9u3bMXbsWNSrVw/t2rXTe5/PPvsM7733Ht5++238/vvvmD59Orp06YKAgIAyt+nhw4fo378/JkyYgB9++AHXrl3DSy+9BCsrKyxatAixsbEYOXIkPv74Yzz33HNIT0/H4cOHIQgC8vPzMXjwYLz00kvYvHkz8vLycOrUKaOlXdeFwRUREREREWH27NkYMmSIRtnrr7+ufj1r1izs2rULv/32W4nBVf/+/TFjxgwAqoBtxYoVOHDgQLmCq7Vr18Lb2xtffvklRCIRAgICEBMTg7feegsLFy5EbGws8vPzMWTIEPj6+gIAgoKCAACPHj1CamoqBg4ciPr16wMAmjRpUuY2lAWDqyridmImnO2s4OFgZe6mEBEREVER1hYSXFnSxyzPNabWrVtrHCsUCnz44YfYsmULHj58iNzcXOTm5sLW1rbE+wQHB6tfF0w/TEhIKFebrl69itDQUI3Rpo4dOyIjIwMPHjxASEgIevTogaCgIPTp0we9e/fGsGHD4OzsDBcXF0yYMAF9+vRBr1690LNnTwwfPhxeXl7laoshuOaqCkjLA/quOop2H+w1d1OIiIiIqBiRSAQbS+lT/zL29LbiQdNnn32GFStW4M0338S+ffsQERGBPn36IC8vr8T7FE+EIRKJoFQqy9UmQRC03mfBWjORSASJRILw8HDs3LkTTZs2xRdffIHGjRvj7t27AIANGzbg+PHj6NChA7Zs2YJGjRrhxIkT5WqLIRhcVQExWYXfUGVZuEhEREREVF6HDx/Gs88+izFjxiAkJAT16tXDzZs3n2obmjZtimPHjmn8Dnzs2DHY29ujTp06AFRBVseOHbF48WKcP38elpaW+PPPP9X1W7RogXnz5uHYsWMIDAzEzz//bLL2clpgFaAoEk/JFQIspaZbhEdEREREBAANGjTA1q1bcezYMTg7O2P58uWIi4szybql1NRUREREqI+VSiUsLCwwffp0fP7555g1axZmzpyJ69ev491338WcOXMgFotx8uRJ7N27F71794a7uztOnjyJxMRENGnSBHfv3sW6devwzDPPoHbt2rh+/Tpu3LiBcePGGb39BRhcVQFnkwqDqWy5ApZSDjgSERERkWm98847uHv3Lvr06QMbGxtMmTIFgwcPRmpqqtGfdeDAAbRo0UKjbOTIkfjxxx+xY8cOvPHGGwgJCYGLiwsmTZqEBQsWAAAcHBxw6NAhrFy5EmlpafD19cVnn32Gfv36IT4+HteuXcP333+P5ORkeHl5YebMmZg6darR21+AwVUldzsxE2eTCoOpXLkCsK7YLthEREREVHNNmDABEyZMUB/7+fnpXHri4uKCbdu2lXivAwcOaBxHRUVp1Sk6IqXLxo0bsXHjRo0ypVKJtLQ0AEDXrl1x6tQpndc2adIEu3bt0nnOw8NDY3rg08AhkEruVkKGxnG2XGGmlhARERERUUkYXFVyD1KyNY4ZXBERERERVU4Mriq5h481g6scefnSWBIRERERkWkxuKrkxrb3wYRGhaNVR28lmbE1RERERESkD4OrSs7fzRYtXAsXGH6y+7oZW0NERERERPowuKoiajtaAQBcbC3N3BIiIiIiItKFwVUVseQZ1WZtjzLzEJWUaebWEBERERFRcQyuqgiHIntbvfprBC7HGH/zNiIiIiIiKj8GV1WEg1VhcHU+OgUDVh1BXGqOGVtERERERERFMbiqImxlEq2yO4kZOmoSEREREZlGWFgYZs+ebe5mVFoMrqoID3uZuZtARERERFXUoEGD0LNnT53njh8/DpFIhHPnzlX4ORs3boSTk1OF71NVMbiqIkQiET4cEqRRJuipS0RERERU1KRJk7Bv3z7cu3dP69x3332H5s2bo2XLlmZoWfXC4KoK8XG10TjOzlPoqUlERERET40gAHmZT/9LMPy/2gcOHAh3d3ds3LhRozwrKwtbtmzBpEmTkJycjJEjR6Ju3bqwsbFBUFAQNm/ebNSuio6OxrPPPgs7Ozs4ODhg+PDhiI+PV5+PjIxEt27d4OjoCB8fH7Rp0wZnzpwBANy7dw+DBg2Cs7MzbG1t0axZM+zYscOo7asoqbkbQIZr5GGvcZyZl2+mlhARERGRmjwL+KD203/u2zGApa1BVaVSKcaNG4eNGzdi4cKFEIlEAIDffvsNeXl5GD16NLKystCqVSu89dZbcHBwwPbt2zF27FjUq1cP7dq1q3BzBUHA4MGDYWtri4MHDyI/Px8zZszAiBEjcODAAQDA6NGj0aJFC6xevRrZ2dm4desWLCxUid1efvll5OXl4dChQ7C1tcWVK1dgZ2dX4XYZE4OrKsTNTnPdFUeuiIiIiMhQL774Ij755BMcOHAA3bp1A6CaEjhkyBA4OzvD2dkZr7/+urr+rFmzsGvXLvz2229GCa7+++8/XLhwAXfv3oW3tzcAYNOmTWjWrBlOnz6NNm3aIDo6Gm+88QYCAgKQlpaGFi1aQCxWTbaLjo7G0KFDERSkWipTr169CrfJ2BhcVTH9Aj2x81IcACA9hyNXRERERGZnYaMaRTLHc8sgICAAHTp0wHfffYdu3brh9u3bOHz4MPbs2QMAUCgU+PDDD7FlyxY8fPgQubm5yM3Nha2tYaNjpbl69Sq8vb3VgRUANG3aFE5OTrh69SratGmDOXPmYPLkydi0aRM6duyIMWPGoGHDhgCAV155BdOnT8eePXvQs2dPDB06FMHBwUZpm7FwzVUV0y/IS/36q4O3kZ4jN2NriIiIiAgikWp63tP+ejK1rywmTZqErVu3Ii0tDRs2bICvry969OgBAPjss8+wYsUKvPnmm9i3bx8iIiLQp08f5OXlGaWbBEFQT0fUV75o0SJcvnwZ/fv3x+HDhxEYGIg///wTADB58mTcuXMHY8eOxcWLF9G6dWt88cUXRmmbsTC4qmIGBXth4cCmAIDkzDzcTOBeV0RERERkmOHDh0MikeDnn3/G999/j4kTJ6oDm8OHD+PZZ5/FmDFjEBISgnr16uHmzZtGe3bTpk0RHR2N+/fvq8uuXLmC1NRUNGnSRF3WqFEjzJ49G3/88Qeee+45bNiwQX3O29sb06ZNwx9//IHXXnsN33zzjdHaZwycFljFiEQivNjJH1vPPcDlmDSkZnHkioiIiIgMY2dnhxEjRuDtt99GamoqJkyYoD7XoEEDbN26FceOHYOzszOWL1+OuLg4jcDHEAqFAhERERpllpaW6NmzJ4KDgzF69GisXLlSndCia9euaN26NbKzs/HGG29g2LBh8PX1xfXr13HmzBkMHToUADB79mz069cPjRo1wuPHj7Fv374yt83UGFxVUU42qqwpqdkMroiIiIjIcJMmTcK3336L3r17w8fHR13+zjvv4O7du+jTpw9sbGwwZcoUDB48GKmpqWW6f0ZGBlq0aKFR5uvri6ioKGzbtg2zZs1Cly5dIBaL0bdvX/XUPolEguTkZIwbNw7x8fFwdXXFkCFDsHjxYgCqoO3ll1/GgwcP4ODggL59+2LFihUV7A3jYnBVRTlZWwIANp24B0drC3QLcDdzi4iIiIioKggNDYWgY48sFxcXbNu2rcRrC1Km6zNhwgSN0bDifHx88Ndff+k8Z2lpqd5XS6lUIi0tDQ4ODupsgZVtfZUuXHNVRTk+Gbk6e+8xJm48jYj7KeZtEBERERFRDcfgqopys7XUOP5g+1UztYSIiIiIiAAGV1WWt4vmvganoh4hR85NhYmIiIiIzIXBVRXl46K9adydxEwztISIiIiIiAAGV1VWYB1HrbI7SdzzioiIiIjIXBhcVVG2Mine7h+AsMa10NbfBQCQmZtv5lYREREREdVcDK6qsCld6mPjxLZws1Mlt8iRK83cIiIiIiKimovBVTVgJZUAAN79+zJSs7ipMBERERGROTC4qgZkFhL166Xbr5ixJURERERENReDq2rAyqLwY+RmwkRERERE5sHgqhqQSSWlVyIiIiKiGkskEpX4NWHChHLf28/PDytXrjRavapMau4GUMUVHbm6lZgBQRAgEonM2CIiIiIiqkxiY2PVr7ds2YKFCxfi+vXr6jJra2tzNKva4chVNWBVZM2VIAA/nrhnxtYQERER1VCZmfq/cnIMr5udXXrdMvL09FR/OTo6QiQSaZQdOnQIrVq1gpWVFerVq4fFixcjP79wm59FixbBx8cHMpkMtWvXxiuvvAIACAsLw7179/Dqq6+qR8HKa+3atahfvz4sLS3RpEkT/PLLLxrn9bUBANasWYOGDRvCysoKHh4eGDZsWLnbUREcuaoGZFLNGPmdvy5jbKifeRpDREREVFPZ2ek/178/sH174bG7O5CVpbtu167AgQOFx35+QFKSZh1BKG8rtezevRtjxozBqlWr0LlzZ9y+fRtTpkwBALz77rv4/fffsWLFCvzyyy9o1qwZ4uLiEBkZCQD4448/EBISgilTpuCll14qdxv+/PNP/O9//8PKlSvRs2dP/PPPP5g5cyYaNmyIHj16lNiGM2fO4JVXXsGmTZvQoUMHPHr0CIcPH654x5QDg6tqICNHe/NghVKARMypgURERERUsvfffx9z587F+PHjAQD16tXDe++9hzfffBPvvvsuoqOj4enpiZ49e8LCwgI+Pj5o27YtAMDFxQUSiQT29vbw9PQsdxs+/fRTTJgwATNmzAAAvPrqqzhy5Ag+++wz9OjRo8Q2REdHw9bWFgMHDoS9vT18fX3RokWLCvZK+XBaYDUwINhLq6zpwl34K+KhGVpDREREVENlZOj/2rpVs25Cgv66O3dq1o2K0q5jRGfPnsWSJUtgZ2en/nrppZcQGxuLrKwsPP/888jOzka9evXw0ksv4c8//9SYMmgMV69eRceOHTXK2rVrh2vXrgFAiW3o1asXfH19Ua9ePYwdOxY//fQTsvSNCpoYg6tqoF4tO1xd0lejLDdfif/9EgGl0nhDxkRERERUAltb/V9WVobXLZ5cQlcdI1IqlVi8eDEiIiLUXxcvXsTNmzdhZWUFb29vXL9+HatXr4a1tTVmzJiBLl26QC6XG7UdxddrFU3SVlIb7O3tce7cOWzevBleXl5YuHAhQkJCkJKSYtT2GYLBVTVhbSlB/yDtodiHKdk6ahMRERERqbRs2RLXr19HgwYNtL7EYlW4YG1tjWeeeQarVq3CgQMHcPz4cVy8eBEAYGlpCYVCUaE2NGnSBEeOHNEoO3XqFAICAtTHJbVBKpWiZ8+e+Pjjj3HhwgVERUVh3759FWpTeXDNVTWyZnQr7LoUi2k/nlOX3U3KhLeLjRlbRURERESV2cKFCzFw4EB4e3vj+eefh1gsxoULF3Dx4kUsXboUGzduhEKhQLt27WBjY4NNmzbB2toavr6+AFT7Vx06dAgvvPACZDIZ3Nzc9D7r4cOHiIiI0Cjz8fHBG2+8geHDh6Nly5bo0aMH/v77b/zzzz/Ys2cPAJTYhn///Rd37txBly5d4OzsjB07dkCpVKJx48Ym6zN9OHJVzbjZyTSOkzNzzdQSIiIiIqoK+vTpg3///Rfh4eFo06YN2rdvj+XLl6uDJycnJ3zzzTfo2LEjgoODsXfvXvzzzz9wdXUFACxZsgRRUVGoX78+atWqVeKzPv30U7Ro0ULj6++//8bgwYPx+eef45NPPkGzZs2wbt06fPnllwgLCyu1DU5OTvjjjz/QvXt3NGnSBF999RU2b96MZs2ambTfdOHIVTVTPLh6lGncubBEREREVLVNmDABEyZM0Cjr06cP+vTpo7P+4MGDMXjwYL33a9++vTotekmioqJKPD99+nRMnz4dgGodWFpamkFt6NSpEw4UTV1vRhy5qmbc7DWDq5SsPDO1hIiIiIioZmFwVc3YWko0jh9lMrgiIiIiInoaGFxVM8VTWKZkqaYF5sgrlsGFiIiIiIhKxuCqGvr8heaweTKCtf1iLJb+ewXN3t2NgzcSzdwyIiIiIqLqi8FVNfRs8zr4akwr9fH6I3ehUAp4dUsE/jz/AKlZTHJBREREVBGCIJi7CWRExvo8GVxVUy62llpljzLz8OqWSMz4+awZWkRERERU9VlYWAAAsrKyzNwSMqa8PFWeAolEUkrNkpk9FfuaNWvwySefIDY2Fs2aNcPKlSvRuXPnUq87evQounbtisDAQI2NyDZu3IiJEydq1c/OzoaVlZUxm16p2cn0f7RHbyU/xZYQERERVR8SiQROTk5ITEyEvb09LCwsKvwLOWlTKpXIy8tDTk4OxGLTjgcplUokJibCxsYGUmnFwiOzBldbtmzB7NmzsWbNGnTs2BFff/01+vXrhytXrsDHx0fvdampqRg3bhx69OiB+Ph4rfMODg64fv26RllNCqwAwNfVxtxNICIiIqqWPD09oVAoEBsbi/T0dK2EYlRxgiAgOzsb1tbWT6V/xWIxfHx8KvwsswZXy5cvx6RJkzB58mQAwMqVK7F7926sXbsWy5Yt03vd1KlTMWrUKEgkEmzbtk3rvEgkgqenp6maXSWIRCK82NEf3x29a+6mEBEREVUrIpEIHh4eOHfuHLp3717h0Q7SJpfLcejQIXTp0kU9FdOULC0tjTJCZrbvhLy8PJw9exZz587VKO/duzeOHTum97oNGzbg9u3b+PHHH7F06VKddTIyMuDr6wuFQoHmzZvjvffeQ4sWLfTeMzc3F7m5uerjgt2g5XI55HLzJn8oeH552jEzzB8iKNHQ3Q5z/7ys8741XUX6l0rH/jUt9q/psY9Ni/1rWuxf05LL5RAEAWKxmNMCTUCpVCI/Px8SieSp9K9CoYBCoXvrorL8DJktuEpKSoJCoYCHh4dGuYeHB+Li4nRec/PmTcydOxeHDx/W+z8EAQEB2LhxI4KCgpCWlobPP/8cHTt2RGRkJBo2bKjzmmXLlmHx4sVa5Xv27IGNTeWYXhceHl6u64IBZD0Ain/UO3bsqHCbqpPy9i8Zhv1rWuxf02Mfmxb717TYv6bF/jWtytC/ZUleYvYxzOLzGgVB0DnXUaFQYNSoUVi8eDEaNWqk937t27dH+/bt1ccdO3ZEy5Yt8cUXX2DVqlU6r5k3bx7mzJmjPk5LS4O3tzd69+4NBweHsr4lo5LL5QgPD0evXr3KPSQqCALmndb8xuzfv78xmlflGaN/ST/2r2mxf02PfWxa7F/TYv+aFvvXtCpT/xbMajOE2YIrNzc3SCQSrVGqhIQErdEsAEhPT8eZM2dw/vx5zJw5E4BquFAQBEilUuzZswfdu3fXuk4sFqNNmza4efOm3rbIZDLIZDKtcgsLC7N/mAWM3ZbK8r4qi8r0WVdH7F/TYv+aHvvYtNi/psX+NS32r2lVhv4ty/PNts+VpaUlWrVqpTXUFx4ejg4dOmjVd3BwwMWLFxEREaH+mjZtGho3boyIiAi0a9dO53MEQUBERAS8vLxM8j6IiIiIiIgAM08LnDNnDsaOHYvWrVsjNDQU69atQ3R0NKZNmwZANV3v4cOH+OGHHyAWixEYGKhxvbu7O6ysrDTKFy9ejPbt26Nhw4ZIS0vDqlWrEBERgdWrVz/V91bZ/DipHcZ8e9LczSAiIiIiqrbMGlyNGDECycnJWLJkCWJjYxEYGIgdO3bA19cXABAbG4vo6Ogy3TMlJQVTpkxBXFwcHB0d0aJFCxw6dAht27Y1xVuoMjo2cNU43nD0LiZ29DdTa4iIiIiIqh+zJ7SYMWMGZsyYofPcxo0bS7x20aJFWLRokUbZihUrsGLFCiO1rvooniRk8T9XMD7UD2IxN70jIiIiIjIGs625IvNLSM8tvRIRERERERmEwVUNMiOsvsZx9CPDc/YTEREREVHJGFzVIN0C3DWOH6YwuCIiIiIiMhYGVzVYckaeuZtARERERFRtMLiqQfLylRrHS7dfxcs/n4MgCGZqERERERFR9cHgqgYpHlwBwPYLsbj4MNUMrSEiIiIiql4YXNUgDdztdJbHpxVmDYxLzUFcao7OekdvJWHcd6cQncy1WkRERERExTG4qkG8XWzwz8xO2DCxjUb5XxEPAQC5+Qq0X7YX7ZftRWJ6Lv48/wCZufnqeqPXn8ShG4lY8u/lp9puIiIiIqKqgMFVDRNU1xFhjWpplP17IRZ3EjOQVCTBRb/PD+PVLZH4cv8trXukZedrHAuCgD2X4/AwJRsAIFcooVRyHRcRERER1SwMrmogkUiEvs08NcruPcrCoyLBVVKGaqrg7stxWtfXcpBpHO+6FIcpm86i00f7kCNXoPNH+zFq/QkTtJyIiIiIqPKSmrsBVDlM//EscuTaCS+C6jhCEATkFxmJsrWU4N2/LqGBux06NnDDiTvJAABBAM5EPUZcWg7i0nSv2yIiIiIiqq4YXNVQ4mJjlroCKwD4KyIGx28n49epoeqygzcSNZJg2Fvp/jZSKAVIxKKKN5aIiIiIqArgtMAa6vXejQ2um5Cei68O3tY4Lio9p3ANloDCEa4WS/bgTmJGBVpJRERERFR1MLiqoerVssOt9/sZXH/PlXj165L2HB777Sn167ScfCwPv1Gu9plSeo7c3E0gIiIiomqIwVUNJpVof/ydGrjprPsoM09neWkO3UjErYQMDP/qODYevat1PiUrD18fvI34Imu09l6NR/sP9uLwzcRyPbMkn+y+hqBFe7D/WoLR701ERERENRvXXNVwfZp5YPflwlGpQSFeiLifgozc/BKuMlxaTj6e/fIIMvMUOBX1CI087JGSLYdcoUSuXIk3t14AAIRficfv0zsAAKb/eA55CiXGfnsKUR8OMEo7Cqzer5reuPify+gW4G7UexMRERFRzcbgqob7cEgwJOKL2HFRlXK9hY8z/p3VCXuvJeC9f68Y5RmZeQr169UHbuHorWStOmfuPQagSgGfp9CdXMOYuAsXERERERkbpwXWcM62lhjRxkd9XNfZGn5utmjl62yS5+kKrIr65VS0xvGxW0kQdCzyEgQBZ+89QnaRwI2IiIiIyJwYXBHqudmqX9tYqgYz/YuU6dPA3c7obbEotg5s1PqTOHhDtfbqrd8vYMCqw8iRK/DTyWgMXXscTRbuwqEn5wVBwM34dOQ/hZEvIiIiIqLiGFwRvF1ssHV6Bxx8I0xd5mhtUep1b/UNKPH8kmeblakdv599gC/23dIqP3QjCbsuxWLLmfu4HJOGb4/c1ZiyOO47VYbCH0/cQ68Vh/DOX5fU5xb/cxl9VhxCVl4+jt1OKlN7iIiIiIjKgsEVAQBa+TrD11VztGpw89p669evZYteTT1wbG53ned9XGwwup1vmdrw+m+ROhNp/B35ENN+PKc+/mT3deTma49OrfjvJgBg86n76rINR6NwPT4dOy/GYdQ3J8vUHiIiIiKismBCC9Lrtd6NsS0iRqPsmZDamNa1Puq7qwKx2k7W6nM9m7hjeGtvHL+TjLf7N4FELDJKO5IySk8Dv/K/Gxrp4vdfT0DXhrXUx6ISmrL3oQiPT93HuehU3E3KxB8zOmhNTyQiIiIiKg2DK9LL28UGf8/siB0X49Cungsu3E/F1K71YGUh0ai37eWO+PHEPbzZtzHc7a3Qu5mnQfdvVtsBl2PSjNLWlU9GrQpM3HAa7xWZllg8WCqItR5l5uHvaAn+jr6qPnfu3mO0q+dqlHYRERERUc3B4IpKFFzXCcF1nQAA3Rrr3hequbcTmns7lXgfO5kUy4YEYf3hO4h8kAqxCMiWF2b6s5SKkadjql9FvPPXZfXr4sFVVHIWlEpBow0FNp24V67g6v6jLPzvl/N4qXM99AvyKnuDiYiIiKhK49wneipsLCUYFFIbv0wJxeyeDbHjf53x4HG2+ryxA6virsRqj5Dtu5aABX9p7+X174VYCIKAVzafxzvbLmmd12fR35dxLjoF0386V3plIiIiIqp2GFyRSa0d3RJ1nKyxdkwrAIC1pQSzezZCgKcDmnjaA1DtrdWxQeFIkZ1MCqmR1msVWLX3plbZF/tu4oiefbe2RTzE35Ex2HTiHnKKjG4t33MdHT/ch4S0HK1rUrLlxmswEREREVU5nBZIJtUvyEvvFLkVI5rjm8N3MSOsPkQi4Fx0Cvo08wAAdP/0IB6mZOu8zlgiH6TqPffqlkj16x6fHURDDzscuJ6oLvvt7IMn7S4MAiUlZc0o4lFmHuytpEyaQURERFTNMLgis6lXyw7LhgSpj+s626hf17KXmTy4MtTDlGyttnyy+zr2Xo3Hholtsf9aAno19YC4SKykVApISM/F+sN38GzzOsjKy0dbfxc8eJyNzh/vR0hdR4xs6wNXOxl6NfV4yu+IiIiIiEyBwRVVSp8MC0avFYcqdI/+QZ7YeSkOgmCkRhVzLjoF0388i2O3tacWvvzzOdxJzMT1+HSsP3IXALB6VEtEP8oCoBo1i3xwEQAQ9eEA0zSQiIiIiJ4qzkuiSqmhhz1e7OivPj78Zjf8Ni0Up+f3xJj2PnhvcGCp91gzuhVcbWWmbKbOwAoAdl6Kw/X4dI2yl38+BwHakZ6pk3kQERER0dPBkSuqtOb0bgQfF2v0buaJ2k7W8HZRTRtcOlg1lbCkTH4TOvgBALLz8rXOScUijAv1w3dH7xq/0aXIyNFuT3xaDm4lZsBeJsX9x1no28wL1pYSHVcTERERUWXG4IoqLTuZFBOKjF6VxNnGAo+z5OgR4I6PhwXDxdYSAJClYx+rWx/0R16+EneTMiAVixB+NcGo7S7JmgO3tcrGfHsS95Kz1MevIhKLBjXV+97vJWfCy9EallLVwPO1uDS8/NM5vNqrEQYG1wagGg07eTcZrX1dGKgRERERPSUMrqjK+mdmJ/wV8RCv9GwIANhxIRZ9Az3hZGOprqNvvZWlVIwNE9tCLpdj+c87sfaqKgBp6+eCU1GPTN72oooGVgUW/XMFw9t446+IGETeT8Hodr44f/8xHKwsMHtLBHo2ccf68W0AAG/8dgG3EzMx8+fz6uDqw53X8N3RuxgQ7IXVo1o+1fdDREREVFMxuKIqK6iuI4LqOqqPX2jro1Vnapd6+PrQnRLv42NXGIF9M641HKyl6PbpAUQlZ2FkW28093aCt7MNRq0/abzGG2Daj+dw6IYq/fsvp+9rnPvvagLy8pW48CAFFx9qp5QvmPK4/UIsVo+qWDty5ApYSsQQG3nvMSIiIqLqhsEVVWtv9GmMPoGeeGXzeTx4rDu1u40U+GRoIPKUgKONBQDgr5c7ISo5EyHeTup6Q1rWwR/nHuq8R6+mHgi/Em/UthcEVvqM/+4Ujt/RnVDDWFKz5Gi1NBzNvZ3w+/QOAFRr3W7Ep+Onye0g5V5dRERERGr8zYiqNalEjJY+zrAsJQgY3Lw2RrfzVR872lhoBFYA8P7gII1jR2sL9WuXIlMRnxZDA6v4tJwSzyuVAj7edQ3/6QgOD9xIQL5SwJl7j9Vlm07cw8m7j3DiztOdPklERERU2TG4ohpBZIQZbdaWEjSr7aA+9nK0Ur92sNYeBG7kYYcLi3rj8uI+FX94BQz/+niJ5/+5EIM1B25j8g9nIAgCcookARGV0HEKU20gRkRERFRFMbiiGuHdQc0AANPD6lfoPll5hYFHpwZu6te61iPlKwQ4WFnAVmbY7NuC7H8VkZevxMUHmmuwiifM2HI6GkduJqmPbxTZj2vKprMIXrQHn/93U+f9hSIBFVdgEREREWlicEU1QpdGtXBhUW+81TegQvcZFFJb/frVXo3Urz0drLTqypWFmwOvGBGCOk7WqONkjSZeDhr1xrT3wZYp7Y2ymfCgL45g0JdHdJ5LzZZj3h8X8dbWixjz7Um8uiUCJ+8kIy27cO+t8CvxyFMoseK/GwA0A6jrcem4FpcOIiIiItKNCS2oxnCwsii9UilmdmuApl72aF/PFbYyKb4a0xK3EjI0RrEK5CsKR3mea1EXz7Wo+6RciQbzd6rPLS22lqsirsfrD37e+v0Cdl2OUx//ef4h/jyvO0EHoBql+upg4b5cfVYe0jhvjKmWRERERNUJgyuiMrCUitE30Et9XPA6KilTq27TYiNUBaQSMf6e2RGvbD6Pef2bmKahxeTIFRqBlSF2XorD5Zg0E7WIiIiIqPrhtEAiI/B1tUGvph4Y3c4HO17pjNHtfLBsqP4RqeC6TjjwRjf0aeapcY/i/N1sS3zuKz0aGtS+gHd2GVSvqFN3S84GGHk/BRuP3tVYh1UgNVuuTowR/lCEd/6+orMeERERUXXCkSsiIxCJRPhmXGv18fvPlX2q37fj22DV3ptwsbVEUy8HPN+6LkQiEfzmbtdZv56bLZ4J8cKqvbqTT1TUg8dZJZ7/dI9qXVYteysMCC4czUvLkSNk8R4AwIHXOuPfaAkQ/QDDWnmjtZ+LSdpKREREVBkwuCKqJBq422HVyBZa5cNb18XJu4+0sv6JxSL4uJQ8slUR9x/p3nS5uN2X45AjV2DR35exZkxL/HwyWn1u2Ncn1a/f235VNdo1sQ3CGrtr3efSw1T8dzUe08PqI0euhL1MqjMLIxEREVFlxWmBRJXcx8NCcOD1MK1yP1dbWErF+PyF5hrlId5O+HdWpwo/t6TkGEX9HRmD136LRHpuPsZ+ewo7LxWu7UrKyFO/jryfAgCYsOE0cvMVGvtpAcDAL45g5X838dqvkQhZvAcvfn+6wu+hQHxaDk4auOkyERERUXkxuCKqAopu5uvraoOBwV54/7lAAMCzzeto1F36bCCa1XbA1K71nmobyyJk8R50/HAfbiWka63F+vdCLADgwPVERCVlIikjFwDw3r9XMGvz+XKt3Wr3wV6MWHcCJxhgERERkQkxuCKqYtr6ueDLUS3hoWNvrc4N3RBU1xEikQjz+mlnItw9uwueKbJXl7nkyJVIzsxDz+WH8POpaL31wj49gFHfnIAgCPj2yF38ExmDG/EZ5X7usdsMroiIiMh0GFwRVTEl7S8lKmXzqcae9hje2lujbJCZg635f14q8fyN+Aw8TClc/5WvLH2z5ew8BZbvuY5LD1Mr3D4iIiIiQzG4Iqoi2vqrMu2NaOOjt44h6R/srDTz2HwyLBi33u+HC4t6V6R5FXItruT9tDp9tF/9WqTnXcoVSnx75C5ORz3C2gO3sGrfLQz84ohR20lERERUEmYLJKoifprcDonpuajtZK23Tr1amtkDf50aiv/9ch6xqTkI8LQHAFhZFP6fyl8vd4SVhQQA4CAR47VejfDDiXsIruOIvdcSTPAudDsT9djguuk5cvwV8RDNvZ3g61r4fpst3I08hWpUq2ujWkZvIxEREVFpGFwRVREWErHewGrLlPb4OzIGc3o10ihv6++CY3O74/z9FDRwtwMAOFhZqM8H1nHUqD+rR0PM7N4Ai/6+bOTWlywuNcfguiPWnQAA1K9li72vhSE5Ixetlv6nUaeU2ZFEREREJsFpgUTVQLt6rnj/uSDYFwmcCohEIrT0cVYHVbWdrPHZ8yFYP641JDr2kRKJRJBKtP9q+HZ8a60yXexlUnw5Snu/rpLcMDDte1G3EzMBAPuvJ2qdy8orTPN+/5H2Zsiv/RqJ59YcRb6i9PVbRERERIZicEVUAw1tVRc9m3roPT+1Sz3UdizMRuhkY4EeTTywe3YXnfX93Qqn57nZy9Dc20lnvTHtfeDraqNVvudKvIEt1+Q3dzv+PP9AqzwtW65+PWr9CY1zSqWArece4Hx0Cs7fTylXanciIiIiXRhcEZEWdwcrHJ3bHf/O6oQO9V2xcWJbAKpsgxsmtlFPMSyw//UwbJrUFsF1HfHlqBawtdQ949jFVoZ/jLDBcVFHb2mnV78WVzgSdv9RYabBVXtv4ofjUerjpf9eQftlexGTko3l4TdwNVY7scb6w3fQYdneUpNuEBERETG4IiKdRCIRAus44ueX2muMRHVr7I7/5nSFraVEo37nhrXw98xOaFbbEc62llg9qqXWPWVSMRysLDChg5+6rHuAu6negk6L/rmifh35IBXxabno8OE+rNp7Uyu74Lnox1i6/SpiUnOwcNvTXYdGREREVQ+DKyIqF2Ups+kGBHtpJZaQSVV/5czq3gBt/Vzw8bBgrBjevMT7ONloryMzFUWxN/Xhzmvq18on0wfz8pVlSsBBRERENQeDKyIql9WjVUkrljzbTG+dzg1cNY4tnwRXrnYy/DotFMNbe8PRxgJj2uvfu2vxM/rvX9S7g5ri7IKeBtUtSVqOHA8eZ0GuUOLU3Ufq8oKU9aO+OYH2y/bickzpGxSv3n8Lo9efQI5cUWpdIiIiqvoYXBFRuXQP8MD1pX0xLtRPb50PnwvEs76FgYWljiyEALB0cBAuLe6jVd6tcS0MCq4NqY6shsXVdbaBq51M7zMMNXDVEXT6aD8azt+pUV4QXJ25p9qTa+vZh6Xe65Pd13H0VjL+joipUJuIiIioamBwRUTlJpNKSjxfy16G7rULp9rVL5YIoyg7mRQ+LoWZBF/uVh9rx7SCWCzCFyNLT+1uJ1Ml0bCVldymkkjEIkTrSN0OADILzb8u9cV7SRm5mPfHBRy+WZgiPjMvv9xtAoAjN5MQk5JdekUiIiIyKwZXRGRyP77YGsuGBKGNn0uJ9cYXSXTRP8hLPVrUN9Cz1GfYW6mCq+LrpsqipGtlUjGURc6vP3IXAPDOtkto/8FepGbLkZWXj7f/uIjNp+7jrd8vaFxf3qmBR28lYcy3J9Hhw33lup6IiIieHgZXRGRy7fxdMLKt/nVVBfyK7IHVrLaj+rVIJMIr3RsAAOq52WJ6WH208nXWuNb6SfbCtJzCUaIBQV4AgJFtvdVlu2Z3Lsc7AP449xCTfzijUfY4Mw+bTtxDXFoOQhbvQdOFu9V7dsUUSXpx8EYighfvwZoDt8r83IM3tDdJLu7B42zu10VERFQJ6N6MhojIDLoHuOPT50PQzl97hGtO78Z4sZM/nGws1WV+c7erX7vaWqrvse9aAiZ08MPb/ZtgUmd/BNdxxJj2vrCXWcDH1QabX2qPkd+c0HpGafZdS9A4nrDxtEHXHbiuCpA+3nUdM8IalOmZWaVMKTwaL8L/lh/G1C71MK9/kzLdm4iIiIyLwRURVRoikQjDWtXVe75oYKXv3OJnmmFIyzroF+gFiViElj6qEa6iI2G6grfyiLyfUuZrLsekolltR+TIFfj97AN4OlhBKhFhzYHb+HhoMPzcbAEAv5yKhsxCXGra97+iVBMQvj50h8EVERGRmTG4IqIqa37/Jvhi3038MiVUXebtYgPvIokxdBEbkH2wwLIhQZj3x8Vyt7G4AauOoLm3EyJ0BGZv/B6J36Z1QEJaDuYa+EwbKZCbp3qdr1BCWsFsiURERFR+/FeYiKqsl7rUQ8TC3mha26HM107o4IcmXqVf17OJB9zsZOVpnl66AisASEzPBQAkZ+bpPD907TGcvfcYJ+8k48jNJACAbZE9lp/58qhBz7+TmIGR607g6K0kwxtNREREpWJwRURVWllGoYpa9Ewz7PxfZ3g4aAdOn7/QXP3a0doC4a920Tj/dv+Acj2zNFHJWZj8/Wn8eOKezvNn7z3G8K+PY8S6Exjz7Ul8se82rCWFiSyuxKZh7YHbpa7TmvHTORy/k4zR608atf1EREQ1HYMrIqrRJCLt4MzRunA4yFIqhpONhcb5KV3q48yCniZpz39XE/DTyWi954umi1+1/zakxf4W/2jXNXy6+0aJz7iZkFGhNhIREZFuDK6IqEYTFQuuBoXURvt6rqjrbI3uAe5adb4a0woASpwqOLVrPRO0VDddA3eHbibin8gYXI5JBQBcjU1D/88P47M916FUChoBWnRyFoIX7caEDafU0xKJiIiofJjQgohqNEmR6CRiYS84WFlALBbhwOthGude7lYfFx6kokcTd3VZA3c73HoyCmRvJUV6wR5bT3HLKV3/Q3YrIQOzNp8HAHw9thWmbjoLQDVtsOioHAA8u/oI0nLyceB6Ir7YdxNLng0s8XlHbibh60O38cFzQaUmDiEiIqppOHJFRDXaa70bAQBeaOMNJxtL9RouqUSsMWL1Rp8AbJrUDhZFsvGtGN4cbnaqFPC/Ti3MWJiaLdd4xmfPh8DeSopGHnZGb7+ilECuILAqsPbAbY3jx1mFbS3ebl3GfHsSh28m4dUtEQa3kYiIqKbgyBUR1WjPNq+D1n4u8HKwKvO1QXUdcWZBL63yhh72eK5FHfx5/iGmda2Poa3qYmiruniYko2OH+4zRrPV0uRlS+ihFPRHY8XvNHfrBVyLS8evU0NhWWxxF9dtERERaTP7yNWaNWvg7+8PKysrtGrVCocPHzbouqNHj0IqlaJ58+Za57Zu3YqmTZtCJpOhadOm+PPPP43caiKqTuo4WZc762BR/87qhNd7N8KY9j5YNiQIP7/UTj0yBgAuJWyCXJyuLIa6PMgsW7uLjlQVl6/UDLx+OX0fEfdTcPhmInLkCvUUSADIzC05IyEREVFNZNbgasuWLZg9ezbmz5+P8+fPo3PnzujXrx+io/VnygKA1NRUjBs3Dj169NA6d/z4cYwYMQJjx45FZGQkxo4di+HDh+PkSaYcJiLTCqzjiJndG0ImlcDKQoIO9d00phFaW0rUr4PrOqpf9wgoXMc1tWs9/DGjA5RPcd1WgX8vxCIlS7XHVnaeQl2ekZuPUd+cQM/lB9VlxQMxIiIiMnNwtXz5ckyaNAmTJ09GkyZNsHLlSnh7e2Pt2rUlXjd16lSMGjUKoaGhWudWrlyJXr16Yd68eQgICMC8efPQo0cPrFy50kTvgojIcMuHh+B/PRrir5c7YtOktvhnZidM7OgPAPB0sMK8fk3Q0sdZZ+a+0e18TN6+5kvCsf7wHTRZuEtdlp2nwLnoFJM/m4iIqKoz25qrvLw8nD17FnPnztUo7927N44dO6b3ug0bNuD27dv48ccfsXTpUq3zx48fx6uvvqpR1qdPnxKDq9zcXOTmFv4ik5aWBgCQy+WQy0tf4G1KBc83dzuqK/avabF/tQ0K8gAA5Ofno72fEwBAEAT8NqUt/FxttfrKQiKC/EnWiobutvBztUFUcpZJ27h0+1WN492XY3XWK97WnZfiEJ+eiwmhvqU+49LDNCgEASFFRvAqI34Pmxb717TYv6bF/jWtytS/ZWmD2YKrpKQkKBQKeHh4aJR7eHggLi5O5zU3b97E3LlzcfjwYUilupseFxdXpnsCwLJly7B48WKt8j179sDGpnKkGg4PDzd3E6o19q9psX8NE6NxpPo7zkqshFyhWld199oleIhFiHrKkw72X0/SWb59+w4U3Sbsf8dVbc5/eBm19fzVmZKr2pvrnbOquh+3zYdMortuZcLvYdNi/5oW+9e02L+mVRn6NyvL8P/UNHu2wOIbeAqCoFUGAAqFAqNGjcLixYvRqFEjrfPluWeBefPmYc6cOerjtLQ0eHt7o3fv3nBwcDDkbZiMXC5HeHg4evXqBQsLi9IvoDJh/5oW+7f8/nd8DwCglqMdpreqjfPRqZg7IhhZeQp8uPsGfjv7UKP+0meb4uLDVOy4FF+435aJ1W/VGV8fuotpXfzRyMMO/zuu+gcwqFV7tPN3wf3HWbCQiOH5JBNjcmYe2n94QOMeHcN6wN2+5OQdtxIy4Otqo7F+7Wnh97BpsX9Ni/1rWuxf06pM/Vswq80QZguu3NzcIJFItEaUEhIStEaeACA9PR1nzpzB+fPnMXPmTACAUqmEIAiQSqXYs2cPunfvDk9PT4PvWUAmk0Em0/7H3cLCwuwfZoHK1JbqiP1rWuzf8nOyscCMboX/oWRtBXzyfHMkpOfh4I1EdflzLb0xJtQfHw0D/OZuBwCIREAJmdcrbNDq4wCAfy/G4dp7fdXllhYWyJID3ZcfAQDcXdYfIpEItxJTte6hEMS4EJMOL0dr1HayVpcX/KfYZ3uu44t9t9CpgRvqOFljbr8AONsannXRWPg9bFrsX9Ni/5oW+9e0KkP/luX5ZktoYWlpiVatWmkN9YWHh6NDhw5a9R0cHHDx4kVERESov6ZNm4bGjRsjIiIC7dq1AwCEhoZq3XPPnj0670lEVFlN61ofADB/QFOd578Y1ULj2Fam/X9lhgRWX41pqVVmWY4RopQiKd7f/fsyQpbsUR8XrBmzstC+7/n7jzF07XF0eLL/l1IpICE9B/7zdsBv7nZ8se8WAODIrSRsOXMfH+++Xua2ERERPS1mnRY4Z84cjB07Fq1bt0ZoaCjWrVuH6OhoTJs2DYBqut7Dhw/xww8/QCwWIzAwUON6d3d3WFlZaZT/73//Q5cuXfDRRx/h2WefxV9//YX//vsPR44cearvjYioIt7q2xizujfQGTQBgIOVBeq52eBOUhaaeNrrvc/PL7XDqG8Kt6KY3MkfzX2c8OHOa+jbzBN9mnliUEht/BNZuOJr72td0fnj/WVq74sbT6tfX43VnD6Rp1DCUipGbr5S67qfThZuvfH9sSi8+/flEp9zN4mbFxMRUeVl1uBqxIgRSE5OxpIlSxAbG4vAwEDs2LEDvr6qTFOxsbGl7nlVXIcOHfDLL79gwYIFeOedd1C/fn1s2bJFPbJFRFQViEQivYFVgfXjWmLxz4ewZHRzjXJLiRh5CiU8HGToUN9NXR5c1xELBqpGwgYG11aXrxzRXCO4Kjo9r7hhreri97MPtMqvxOqfjy7PVyIT+Ri9Xnu/wVN3H6lflxZYAYCVRWH2i8eZebCUikvtJyIioqfFrPtcAcCMGTMQFRWF3NxcnD17Fl26dFGf27hxIw4cOKD32kWLFiEiIkKrfNiwYbh27Rry8vJw9epVDBkyxAQtJyIyL29nGwzxV2oFQ1und0BY41r4/sW2GuX6pglKxCJ8MiwYAPDuoKaQiPUnAFo2JEgjfbqHQ8nJKADVyNXOS/oztpaFTKr6Zys9R44W74WjeZHphwWy8xRYd+g2dl6MRVbe00nuQUREBFSC4IqIiIwrqK4jNk5siwBPVbbT51rUAQDM7N5A7zXPt/ZG5MLe6g2NBwR5qc8tHVw49dpCIkbR/OtejvpHuQpEJWXi9d8iy/Ym9Nh9OR65+QrcSlBND5QrBCiVmlHje9uv4IMd1zD9p3MY+Y32aBkREZGpMLgiIqrmPns+BCfm9UCfZp4l1nO0KcyG5OtauFHVcy3qoI6TNdr5uwAA4lNz1OcMSX7xx7mHpdYpi92X4zXSsmfLFRrnfz19X/068n6K+vU/kTF46YczuJuUadT2EBERFeBEdSKiak4sFsHT0apM18zo1gA34tMxINgLtjIpDr4Rpt4vMC6tMLjKNGDa3ZYz90utUxbrDt3GlC711cePMvMw74+L6Bvoif5BXshX6p7/OGvzeQBA+JV4fDQ0CDEpORjfwQ8utpbYfz0Bv595gKWDA9Wp3lOz5LgVr50+noiISB8GV0REpMVOJsX68W3Ux1I9I1Qd6rvicozhmysaw6WHaXjlSaAEAMt2XsWOi3H4OzIGUR8O0Kqfmi2Hg5XmP3dvbb0IALj/OAvLhzfHxA2qbIfbL8bizIKecLOToffKg4hPy8XLTUXob8L3Q0RE1QenBRIRUZm80acxAGDxM80wu2cjLBjQBN4upa+9AlBisozShHg76Sw/fCNJ/XrZjqva1y3eA/95O3Ree+7eY62yT3dfR26+AvFpuQCAi4/K32YiIqpZOHJFRERlMiOsPp4JqY26ztYQiUSY3LkeJnXyx4rwG1j1ZNPf4ka29UEDdzv0auKBLp+UbQ+tAh3qu2qsoSqQnls4NfHrQ3fKdE9d0yVvJmTg2S+Pqo9FAHLzlbCw0KpKRESkgSNXRERUJiKRCN4uNuo1WAVl08MaoH+Q7qQZw1rVwaRO/vBxtcHBN8JwfF531ClhPy1dKjDopZeFRIzbiZobE8ukYlyLS1cfH4wTI3Dxf3jv3yvGbwAREVUrHLkiIiKjsLaUYNGgZthxMQ4tfZxwLjpFfc7R2lL92tfVFgCwZWp7/BMZi1HtfNTp1QUB2HT8HpYMbgYHKwvEpGSj+2cHAejfp6siDt9MQo8n9y+QmafQWffbI3dx9FYSxoX6YVQ7HyRl5MLV1lIdZAqCgBXhN3D8TjLWjG6FWval7wFGRETVC0euiIjIaNwdrHBhUW/8OjVUo9zJRntOXV1nG0wPqw9Hawu421uhQ303dGzghq/GtoK7vRWsLCSoV8sOc3o1wvvPBWJMe1+dz/z4yQbIxpKalaf33LW4dLz950X4zd2O1kv/w7w/VIkxrsSk4Xp8Olbtu4XTUY9x7HaS3nsUuPggFZuOR0EQBOy/loDnvzqGKAPTxB+9lYSXfjiDuCJp8YmIyPw4ckVEREblYKUKpJxsLJCSJUcDdzu42ZV/FOeVHg3Vr2+93w+n7j7CqPWFmwOH1nMtf2N1iC1DwPLL6ft4sZM/+q86rFGekVtyinqlUsCgL48AAFztZJjx0zkAqnTx/8zqVOpzRz95/2IR8PXY1ga3l4iITIvBFRERmcTO/3XG6ajH6B9Y8ubFZSGViNGhgRukYpF6PytLqXEnYeTmK8tU/9TdR1plmU+CK6VSwObT0fB3tUWHBm4AVJsZzyqSSv5qbGEq+xvx6SiLxPTcMtUnIiLTYnBFREQm4eVojWdCypa0wlBisQgoCK707MEFQCMIM5UF2y5plWXk5ONRZh5avheuLpvapR5cbC2xbOc1jbpF15LpC+zkCiVm/xKBlr7OmNTJX11ubSmpYOuJiMiYGFwREVGVIymSqbCkkStRCRkG97zaBT4uNgh4Z5cxmwZAlR5+49G7GmX60sQL0Az+Lj1MhaO1BbLyFNh7LR4vdvTHXxEPsf1iLLZfjNUMriz4zzgRUWXCv5WJiKjKKboZcUnBVStfZ5y4o5q2187fBbcTM5GUoZpKZyWVwMpCgq3TO2Do2mMGP7vIoJleG45GGXy/9BzN9VkDvziicaxQCEjNluu8liNXRESVC7MFEhFRlfPZ8BAAwNx+AZDq2QDrxY7++HpMYbKHdwY2xdG53dTHdlaq/19s5euMD54LwucvNIedrPT/czT2LMMfjt8r8fxn4Tew/3qC+jg3vzBVvI2FZnC16cQ9fH8syijtys5T4I3fIhF+Jd4o9yMiqgk4ckVERFVOn2aeuLy4D2xLCIYWDmoKAPj5pXa4lZCBZrUdIBKJ8O341sjNV8LFtnDvrVHtfAAAIXWdsOnEPczs1gAZufk4dD0e8/8y/+bBtxMLU7THpBRmMyw6cpWZm493nqz/erZ5bTjZFL6/8vj2yB38dvYBfjv7AFEfDjD4upiUbPx44h7GhvrCy9E0a+6IiCorjlwREVGVpCuweqNPY/i52qBzQzd1WYf6bhgX6qfe7LdHEw/0D/LSeU8/N1u8M7ApnG0t4e1ig+Gt65qm8RVw/1GW+vXGY1H49cx93E7MQEqRqYO6NkIWBAG/n32AWwmaGQmVSgG/nr6Pm/HpEAQBWXmqaYoPUzRT0iuUgkHZCcd/dwprDtzG9B/Plel9ERFVBxy5IiKiKu/fWZ2QlJGLsMbumNa1PvTMFKwW7j/O0jh+8/cLAKARUGbkaO+z9e+FWLz+WyQAaIxE1Xt7h/r1MyG18XdkDA6/2Q2CoDn/ceLG0zh0IxHbXu6I5t5Oett3MyEDABBxP8WwN0REVI1w5IqIiKq8wDqOCGvsDkCV7EJUUprAMpodmI+hLWujkYcdAKBvM0/89XJHjGnvU6b7jGjtbZT26NpXCwAO30xSv07JylOPQB27nYS3/7yIo7eStK7JK5b6/e/IGADQuW7r0I1EAMCmUtaIFTDiR0BEVGVw5IqIiKgE/vbAy/0DkZEnYOelOAwI9oKjtQWa1XbAjyeiDbpHA3c7vNqrEbacua8u2zixDSZsOF3m9vwVEVNqnRHrTgAAzr/TC6O+Oam3XsFmx8Xl5CsgVDBxh7UFMxkSUc3DkSsiIiIDONtaYlQ7HzhaWwAApCVsXlzg8JvdMLmTPzZMaKMzbfqeV7tgQLDu9V/GsO9aQonnM/QEV7lyJZQVjK6sGFwRUQ3E4IqIiKicPn+heYnnvV1ssGBgU3i72OgcyWnkYY+Z3RqYqHXAa0/WWOlz8WGqzvKcfCX0hVZ/RTxE10/241pcWon3tiph/zEiouqK0wKJiIjKaWBwbcSn5aCtvyv2XI7DuejH+OC5IGw6cU8rI6GlVIzODd001kYBgMOTkTBdrC0kyJZrZ/6rqJk/n8Onz4dgxk+6M/r9E6k59fDWkyQVAJCvFHAvOQtv/n4Bf8/spPcZ5Rm5UigFiEUw6po5IqKnicEVERFROUnEIkzpUh8ANDLovTuomc76P7zYFhM3nsbN+Ay0r+cKALC30v1P8fWlfSERidBg/k7jNhqqzIEFCSoM0XP5Qa2yzNx8yBVKWOiZHmkpFSNHrsCm4/fQo4k76tWyK/EZcoUS/T8/DHcHGX6a3N7gthkiL1+J8d+dQht/F8zp1cio9yYiKopj9kRERE+JSCTChgltcPCNMPXIjq2lZnDlbi/Dqz0bQSaV6F3XNdAI67TSdKRrL4vbiZkIXbYPqUX21yrqWlw65vwagfd3XMXAL46oyw/dSMSivy8jN19zRO5abDpuJmTg6K1kKJUVzKZRzK7LcTh+Jxmr9t406n2JiIrjyBUREdFTJBKJIJUUTnuTiEXY+1pX/BURAwcrKSZ3rqdR//MXmmPR35fxOKswiHGwtkBbPxecitJOyx5azxXH7ySb7g0UkZSRi+V7rsPLyRqTO/nj1zMPNM7vuBgHAMgqsqnxuO9OAQBqO1lhYmhhOvuiMwFz85U6E4CUV/GU80REpsLgioiIyMzq17LTO13t2eZ18ExIbfjPK9zst6G7Hd7qE4C3tl7ArstxGvUbedg9teAKAL5/su/Vhzuvlem6iw/1J8TIkStgbSlBQloOfjh+DyPb+aCOk7VGnay8fMikEkgM2DGaK7iI6GnhtEAiIqJKrniCh9HtfOFoY4GJHf00yl9o461Rt3uA+9NonsGKTgUMvxKHlzdHIDJZhB0X46AoMhUw98lI04Jtl/Dl/lsY9c0JjfukZOWh6cLdGLLmqEHPFZfy2879R1nYeTEWQkU39yKiGo8jV0RERFXIqz0bwfJJmvO2/i54b3AgAjzt4WYng4+LDd7794q67rSu9Uvd66rgPqfuak8xNKbY1GyNNU85ciX2XEkAIAFuXMC7g5oWOacKws7eewwAuJecpXGvg0+ScUQ+0J1KvjhRkbErpVKAuNhoV+eP9wMAvhjZAoNCahv4joiItDG4IiIiqgIsJWLkKZTo0shNXSYSiTC2va9GPXGRkata9jKD7h1S19HkwVXosn0lnv/64B3165wnI1y1nayRnJlX4WcXHfjLUyhhJda9nuvk3WQGV0RUIZwWSEREVAUcn9cdf73cES18nEusVzSQ8HezxYIBTSAtZV2Sk42lxvHa0S3L3c7yikvLUb+OSsoEAPUIHQCNKXtFpz5+/t9N3E4s3Idr//UE3IhP17h30fp5Cv3JLSTcX4uIKojBFRERURXgaidDSJG9tPTxdbXROJ7cuR5e7OSvPtaVOKP4hr/9grywZYr2XlNFk0cE13UstS3lNe3Hc5ArlBrPW7DtEh6mZCMlKw+vbD6vLl/x3w2M+Po4cuQKnLr7CBM3nEbvFYc07lc0ZJKXkDmQmxcTUUVxWiAREVE1MrKtD6KTs9C5US112Yyw+riblIkhLepA1xZSRUOKBQOaAADaPdnkuKiwRrWw98karr9e7qiRwdDYmi/eg8wiKdx/OhmNn05Go2cT7SQdSRl56PrJfsSn5arLDlxPQFhjVd2iyTIKRq4USgGr9t5Eu3ou6nOMrYioohhcERERVSMWEjEWDGyqUeZkY4lvxrUGAFyOKUwC8e341pBKxIhOzlSXFd9nq6iicZlIJMKEDn7YeCzKKO0urmhgVdR/V3Un6CgaWAHAhA2nce29vli6/QrSsgs3TJbnq97FtvMP8fnem8Dewms4LZCIKorTAomIiGqQZrUd8eWoFvhjRgf0aOKBro1qYXCLOmjgboepXfQHVptfaq8xAgQA4zv4lfisz54P0Vk+pGUdvP9cIHxcrHWeLysLie6gaHn4Dfx4Ihp/R8aoy07cScbFB6m49yhLq35BbJWQnoOvD97GIyMk0yivzNx8rD98B/d1tJOIKi8GV0RERDXMwODaaFkkMYa9lQX+m9MV8/o30Vm/UwM3hNZ3RSMPO41yfzdbrH8yIgYAE4oFW7WddAdP7f1dMbqdL0KMtG7LTqZ7Is66Q3e0yt7cegGDvjyC3ZfitM4VZFqc8eM5LNt5DXN+jTBK+8pj2c6rWLr9KgZ9ecRsbSCisuO0QCIiItLp2/GtsWznNbzWW5UE4389G0EpAAOCvdR1ejRxx+h2PrCTSbUSQtR1Lgyupnath03H76FXUw8MblEHgPGm4T3Okpf5muvFMgoCwN+RMRjXwQ9nnuyvdeB6YoXbVl5HbiYBAFLK8d6IyHwYXBEREZFOPZp4oEcTD/WxnUyKd4qt5xKJRHj/uSAAqjToXx28rT5XdJ+tyZ3qYV4/zZExSbHpfL9MaY8X1p3QakeItxMi76eU+30YKjY1Bx0/1NyPK0eugFQsglTydCf7FN/omIiqBk4LJCIiIqMIa1RLnW0QUKV4X/JsMywY0ETnhsZFR646N3RDc28nrB3dEi19nFDnyZTCHgHuaOfvonXt0xK6bC/6rCxM7Z6brzvRBgBcj0vHr6fvq/fkepiSjRXhN5CUkav3GqVSwMh1JzD5+zMa5WIm1yCqkjhyRUREREYhEokwuXM9dGlUCy62qo2Jx4X66a1fdB+rTZPaAVDtsdUvyAsJ6Tn463wMnm9dFxYSMRytLbD7chwuPCjMdmhlIUaOXP++VcbwOEuOx1lyZOcp8O+FGMz74yLCGtdCarYcb/YNgFyhxFcH7+C9Z5upgzBrSwkGhdTGpI2ncS0uHafuPsJmHfuGAUD0oywcv5MMQDVKJpOKIRKJwIEroqqJwRUREREZVSMPe4PqSUuIINztrfBSkeyFL3drgKSMXHVwNSDIC1O71sMzXx4t8RnWFhJky/WPNhnqmS+P4GZCBoDCdPBv/3FRXfbm7xfUdWdtPo8+zTxxLU61ruv4nWTcScyArUwKDwcrjfvKFYXB4dZzD/Dhzmv4emwrjlwRVVGcFkhERERmUdZ1RdYWEvXrD4YEwcay5P8jdrG1xOG3upWrbcUVBFH6yh6mZGuc23D0rsZx988Oot0HhZtq3U3KxOu/RWrcY/6fl5Cek4+pP5zVGNUjoqqDI1dERERkFvVr2ZapftFRHgcrKdKyS86kV8tOBjc7GfoFemKnjtTrxmRZLOHFsp3XdNYTBAEikQgDVh1GVp4Cv599oFUnT6HUCq4ux6TiweNs9GnmabxGE5HRMbgiIiIis3i+ZR0cPXcZY3u3LfO1IpEIFqVk8CtIovHp8yEYFFIbyRm5+OdCLPo088R7/14pV5v1sZQaNhkoXyngamwqsvJKnqpYNK399bh0DFil2u/q31mdEFjHOPuDEZHxcVogERERmYVUIkZ/b6XB2QAndvSHk40FJnfyBwAIEEqs36eZKo28rUyK/kFeGBvqh1+nhmLSk+tLsuTZZrCyMP6vSbn5Smw8FlViHQHQSGhRNFvhzQTt/bmIqPLgyBURERFVCbWdrHF2QS/1lDlXWxkkYlVmPbmiMND6dWoobsSnY1Rbn3I/a1yoH1aE3zA4G2F6Tr5B9cI+2Y+kjLxS6+nbYPnVLZGQ5wsYEOyF9/69gv5BXujSqBYAVVp3uVIJmVSi81oiMj0GV0RERFRlFF2LZCkVI/Ld3hCLgGFrj+NKbBoae9ijrb8L2pYyGrb9lU7YeDQK/+vZEE42lgh8d7f6nJudajrhsiFBmPbjOYPaVTyhhT6GBFZKpYDrcfpHqN7cegFvblVlJ/zl9H2cersHvj16F7cTMnHgegK2TG2P+X9eQiN3O7RTZcRHWo4clx6mor2/K8RiEQRBQLZcUWpSECIqG/5EERERUZVlJ1P9KrN2TEv8fDIakzqXPuUPAJrVdsQnz4eoj+8u64+0nHxcfJCKAC9VKvm+gV44/04vtHgv3PgNL0G+UkB6rmEjYQAw74+L2HstQX08dO1xAMC1uHTsEksw/Flg5LoTuByThmVDgjCyrQ9e+SUC2y/E4OAb3eDtYqN1z+SMXJyPTkFY41q4/zgbfq42GuvAlEoB0Y+y4FusnKim45qrqiQ/F3h8z9ytICIiqnR8XW0xr38TuNtblV5ZB5FIBEdrC3Rq6KYeuQIAZ1tLzO7Z0FjNNImigVVxeUoRkjJycTkmDQDwd0QMAOCfyBgoBeCnk9E6rxv21XFM/uEMOny4D90+PYANR6M0zi/+5zLCPj2A70tZP0ZU0zC4qkq2vwZ8Hgyc22TulhAREdUYs3s2MncTKiT0o4Pq13ZWmpOW9G3kfDcpEwCQkJ4LAFhSLLvi98dV/9n7ye7rRmsnUXXA4KqqyM8Bzj8JqnbNM29biIiIqEpSKgUIQmHyD6lEM7h68DgLaTkl7x9WVGaeAqejHhmtfURVHYOrKkJ0fXvhgSIPyC99QSwRERGZTqcGbhrHr/duhK3TO5ipNYbZey0Bw746rj4uGLm6/ygL0388i04f7Ufwoj1luueIr4+XXomohmBwVUWIbxVZTKvIBc58a77GEBEREXxdNRNBuDtYwdXWstTr/tfDvGu4zt57rH79OEuOo7eS0H/VYey8FFfqtUqlgPi0HM2yJwNhSRm5ePbLI/jxxD0olQJe/y0Saw7cMmrbiSq7cgVX9+/fx4MHD9THp06dwuzZs7Fu3TqjNYyKEJQQ3Tmgeh30vOrPAx8CeVlmaxIREVFN8tfLHfFMSG2Nsjf6NEbPJqqNit3sZOgb6AkXO+3gakRrb43j0hJkdG7oVuJ5Y/r2yF2MXn/SoH26zkU/Rr23d6DdB3t1nl+9/xYiH6RiwbZL2Hw6Gr+ffYCPd11Hdp4C8/+8iKO3kozdfKJKp1zB1ahRo7B//34AQFxcHHr16oVTp07h7bffxpIlS4zaQAKcs+5ClJUEWNoBz3wBWLsAOSlA8k1zN42IiKhGCPF2wqqRLWBtUbhBr5ONJdaPb407H/TH0bnd4GBlAQcrC3w1piXWjm6prtc/2AuW0sJfuUpKXf7uoKbYNKkdoj4cgP2vhxnUtkNvdCv7GyqHIWuO6T2353IcsvMU6uP5f15Sv+614iB+OhmN0etPmqRdCqVQeiWip6RcwdWlS5fQtm1bAMCvv/6KwMBAHDt2DD///DM2btxozPYRAPe0SNWLhr0BC2vA6cmO86kPzdcoIiKiGihfqdQqE4tFkEkLg66+gV7oF+SlPlYKgkZQVtTHQ4Mxq3sDAECApz0mdizcp8vfzRZ1nKwBAFYWun9lOzGvB3xctfepetpm/nwesak5Os89eFy4wfIf5wpnPskVSkQn65+Fs+dyHNq+/x+O3dY/4vXxrmto+V54ifcheprKFVzJ5XLIZKo9IP777z8888wzAICAgADExsYar3UEAHDKuqt64ROq+tOxrurPNAZXRERET5NcUY5REkF/cASo1mAtGxKEb8a11jr31ZhWGNPeByfm9cArT4KwojwdVft61a9lW/Z2GVGeQomDNxJLrbfwr8vq16//Fokun+zHIR3XCYKAKZvOIiE9F+O+PaVxLiUrD7+ffYDM3HysOXAbqdlyfLGPs3mocpCWXkVbs2bN8NVXX2HAgAEIDw/He++9BwCIiYmBq6urURtY4wlKOGfdUb2u3Vz1p0Md1Z+pD3ReQkRERJWHu4NMY2SrKGtLCaQSMUa29dF5PqiuI4LqBgEAZHpGvwBg06R2uBaXhvf+vareo6os3ujT+KnsWSVXKPE4Mw92VlL89WRD459PRqNLo1oAgK8O3sb3x6KgLJIuPr/YtL/J35/BmXuPcfJOsrqstJD3wPUEHLqRhOhHmVg9uqXez4Oooso1cvXRRx/h66+/RlhYGEaOHImQkBAAwN9//62eLkhGknAVsvx0CBa2QO0WqjLHJ8EVR66IiIieqo+GqgKdt/oGlFp3w8Q2WDo4EM1qO2JMe1Xw1NrXGQDwdv8A9Gzigb6BngY/26qE4Kq2kzW6B3jAvsgmwdumt4eF2LCRtpe7aY+KmUJuvhIt3gvHhA2Fo1F+brZ4f/sV7LoUiw93XkNsag7i03K1rs3LV+JWQgbOPMl2+M+FGPU5iZ51bGfvPUKb9//DhA2n8d3Ru/jvagJO3jF8X660HDny8rWnghLpU66Rq7CwMCQlJSEtLQ3Ozs7q8ilTpsDGxvzzfqsT8b3DAADBJxQiiYWqUD1yxeCKiIjoaRrRxge9m3rC2YCU690au6tfT+pUD028HBDi7QQAmNKlPqZ0Kduz9a3bKsrJprBdzWo74MM2Ciy7bIOkjMq1P+bRW4WjTl8dvA0A+ObwXb31j91Owhd7b+F4kdGqHHlh0CPWM1wwdK32Hlwl5BPRkJKVh+ZLwuHraoODTylpCFV95Rq5ys7ORm5urjqwunfvHlauXInr16/D3d29lKupTJJVf+EIvh0Ly9RrrjgtkIiI6GkzJLAqTiIWoXPDWnCwsij3c0tat1WgYA+tYa1UvytIxcCB17pgULE08lXNqG9OagRWxYmfREw5cgWe+fII3v7zIn46eU9n3XwD182dePK8e0yWQWVQrpGrZ599FkOGDMG0adOQkpKCdu3awcLCAklJSVi+fDmmT59u7HbWWMp+nyA8rwV6hPSB+v+rCkau0mIBpVL/f9cQERFRtVHStMACrXydcWp+D7jayqBUqPaukknF6NTAFf9ExkAmFeObca2Rki3HK5vPA1BNXzTs+WKN0aLKJF8h4FpcGgavPoocuRIXHqTqrStXKJGZm4/wK/Fo4++izshYnKJyvlWq5MoVXJ07dw4rVqwAAPz+++/w8PDA+fPnsXXrVixcuJDBlZHlWjgBNkUShdh7ASIxoJQDmQmAveHztYmIiKhq8nM1LCOgu70qg6CycNspDGvlDTuZBVr4OKG2kzViUgrTo4c9SSZRGjuZFDnyyjW9sMCWM/ex5cx9g+pm5uWj2bu7AQCWEjFuvN9PZz1FkaQaKVl5UAqASzlGLanscvMV5ZteVwmUK7jKysqCvb09AGDPnj0YMmQIxGIx2rdvj3v3dA/BkhFJpICdJ5Aeo0pqweCKiIio2mta2wGfPh8CmVSMPVfi8UIbb4OvlYhFGBBcuPdWbSdrfDehNRytLdSbGrvby5CQXphIol4tW9xJLMw86GBtUenWbpXHq1si1a/zFErcf5SFus7W6n44dfcR0nPkiIhOUddrviQcAPByt/p4o0/pyUwMlZSRCzuZ1KBRyZpi6b9X8O3Ru9j+cgdzN6VcyhUUNmjQANu2bcP9+/exe/du9O7dGwCQkJAABwcHozaQ9LD3UP2ZkWDedhAREdFTM6xVXQwKqY0vRrZAxwZuFbpX9wAPtPJ1UR//NLmdxvmfJ7fH+88Fqo/d7GR67/Vcizo4Nb8HVo5ojp5Nqtb6+84f74f/vB3490IM7iVnYvjXxzHp+zP47qh2go3V+2/j+O1kKJX6121dfJCKO4kZpT43NjUbrZf+h14rDhrc1ozcfPx6+j4eZ1b9IFef9UfuQhCAz/fdMndTyqVcwdXChQvx+uuvw8/PD23btkVoqGpz2z179qBFixZGbSDpYfdktCo9zrztICIiomqhoYc95vRqBAAYGOwFT0crjG7nqz7vbKM/GceKEc3hbm+FwS3qoGtj0wRXdrJyTbgy2Myfz6PrJwdKrTfymxMIWbIHOy/FISkHGLT6uDp5RnJGLgZ9eQTdPzuIyd+fxr5r8XoDsYPXVZsn33+UrfO8Lgv+vIg3t17ASz+cMfiaqiqvii56K1dwNWzYMERHR+PMmTPYvXu3urxHjx7qtVhkYuqRq3jztoOIiIiqjZe7NcAfMzrgs+EhWuecrDXXG83u2bDM9/9qTKsSz8ukhb+aBtVx1Djn4aB75Mwc66DSc/LxypYLWHNFgmtx6Zj/5yUAQExKjrrOf1cT8OLGM9gWoXvrHHkJo1/6bHuy8XLBXl+VnSCoEo3IyxEoyQ3M6ljZlHutmKenJ1q0aIGYmBg8fKj6pmnbti0CAow3D5VKwJErIiIiMjKJWISWPs6QSbXXADVwtwOg2m/rzgf90brIlMKiajtaqV9bSsSY2NEP4a92wR8zOpS4aXItexnWj29deK1U89fUgucXJRWLMKIMa8+MLTm3cNOsPZfjMOjLI1p11uvZv0teZHNiQdAOJHLkCvwV8RBJGdobKgNAZm6+VtmX+27ixxOa+Q/uJGbg78gYnc8oKjtPgcM3E426afJvZx+g78rDWLbjWpmvraqbN5drfFWpVGLp0qX47LPPkJGhmlNqb2+P1157DfPnz4eYqcFNz+7JkDtHroiIiOgpsLaUIPLd3hCLALFYhI4NXDGvXwAae9pr1Ose4I5XejREUB1H9GrqYdC93ewscXp+T42y4sHA6Ha+2H1Z8/ceawsJbCpJMogpm87qLM+WKzDn1wjMCGuABu52UCgFfHvkDi49TFPXyc1XaiW1+HzvTaw9cBsN3e0QPqcrANUGyAXdErhoN+4uG6CufycxA5/uuQEAGN3OByKRCI8z89D9M9WaLhsLCXqW8HnM3nIeuy/HY1Inf7wzsGnZO0CHBdtUI3rfHb2LhYPKds+qOi2wXMHV/Pnz8e233+LDDz9Ex44dIQgCjh49ikWLFiEnJwfvv/++sdtJxRVkCGRwRURERE+BRCyCo3XhuiuRSISpXetr1ROJROq1W7rIpGLkFhuVaOJVekI0B2vtNV/2VlLYmHgtVkXdTcrE3aRMHLieiBUjmmP8d6e06uTKtYOr7RdiAQA3E1QDGZH3U1A03hQEIF+hhFQi1qgPqKbUfX/sLt7fcVVddiU2TWdwdehGIj7fexNnn0w13HD0brmDK0EQ1FkXgdJHn47cTAIAdGqonZylPFMJK4NyDTF9//33WL9+PaZPn47g4GCEhIRgxowZ+Oabb7Bx40YjN5F0Uk8LZHBFREREptOrqQfsZVL0D/QqvbIB2vipphNKxSL8O6sThreui0+GFa7xeq1XI1hKxXh3UDON6+xk2iNUdZ1tYGNZOUauSvMoM09nYAUAy8Ov49LDVMz46Sx2XFQFSUViFADA818f17pu8+n7GPH1cfx7IQafhd9Ql+fmKzQCK0AViOoy7rtT6sCquNRsOR4VyUx46WEqvj54G/k6Ap8V4TfQaul/uF0kU2LRz2bdodsa9dNz5Bjz7UmM+fYkcuQKFFdVpwWWK7h69OiRzrVVAQEBePToUZnutWbNGvj7+8PKygqtWrXC4cOH9dY9cuQIOnbsCFdXV1hbWyMgIEArgcbGjRshEom0vnJycvTctYqycVb9mV01FjQSERFR1bRubCucfacXHEvIFlgWy4eHYERrb2x7uSMC6zji42Eh8CyyTmtWj4a4uKg3QrydNK6zk2k/v66LNZx0jGgVKCl9fGXy/fF7GPjFEey4GIcZP53D5//dxL3kLI06uoKNd7Zdwsm7jzDz5/Ma5cVHBgHAwcqwz08pAAlpORAEASGL96Dle+HIzlMFPwO/OIJlO69h82nNDZuP3U7C53tv4lFmHj7bc73IvQqH2j7YcU0jKCu6p1pWnq7gqgYltAgJCcGXX36pVf7ll18iODjY4Pts2bIFs2fPxvz583H+/Hl07twZ/fr1Q3R0tM76tra2mDlzJg4dOoSrV69iwYIFWLBgAdatW6dRz8HBAbGxsRpfVlZWOu9ZZVk/Ca7kmUB+9d3rgIiIiMxLJBJpJZeoCHcHK3w0LBiBxbIBFlWQUKOWvSo4sraQwFbHyFUjD3s09Chc8/XBc0Ea2QMd9IzWVHYr/rtReqUSFE9qAQAXH6bi7D3DBkEGrz6qEaA9TMnCpYep6uMrMWka9QuyJQKAuMiQW36xjH8N5u/Ewr9UdZOKBFe6Rq5y8rXLqoJy/aR8/PHH+O6779C0aVNMmjQJkydPRtOmTbFx40Z8+umnBt9n+fLl6uubNGmClStXwtvbG2vXrtVZv0WLFhg5ciSaNWsGPz8/jBkzBn369NEa7RKJRPD09NT4qnZkjgCefPPmpJizJUREREQmsWlSW3RtVAtbpraHraVmoCQRi9AjwB1+rjbqsuda1MHZBT3xRp/G8HGxwXcT2iDA077UEayiAdlzLeoY900YQbaOkZ2SrPzvplbZxmNRGLr2OHLzFZArlDh5Jxm5egKYmNQcpGXL1ccf7bqOgV8UZkIsGgyl58hxNylTfZyckYfV+28hMT0X+TrSzf9w/B5y8xWILxJc9V15CDfj0/HzycIBlvi0XOx+INK6vrIrVzjftWtX3LhxA6tXr8a1a9cgCAKGDBmCKVOmYNGiRejcuXOp98jLy8PZs2cxd+5cjfLevXvj2LFjBrXj/PnzOHbsGJYuXapRnpGRAV9fXygUCjRv3hzvvfdeiZsb5+bmIje38ANOS1NF43K5HHK5XN9lT0XB83W1Q2rlAFFOKuTpSYDM+Wk3rVooqX+p4ti/psX+NT32sWmxf02rOvRvfVdrrB+r+h1OocjHN2NbICtXgZa+TkjOyIOfixUEpQIHXusMuUIJqUiJ/HwlpnTyxZROqg2Qf5/aDgDQYulejb2Tlj7bFAv+ugIAGBjkiR9OqH6xH9O2Lv48r3tvKnNpsnCX0e71z/kHuBiThu+PR6Otn/7fH6/Fpqhfh1/RXOP/5/mHqOskw5h2Pmj34QGNc8fvJOP4nWR8svs69Jm39QLqOlmrj9Ny8jHwiyNaI6Q77kvwaSX4/i3Lz5BIKC3pfRlERkaiZcuWUChKj65jYmJQp04dHD16FB06dFCXf/DBB/j+++9x/br+D6Ru3bpITExEfn4+Fi1ahHfeeUd97sSJE7h16xaCgoKQlpaGzz//HDt27EBkZCQaNtS92d2iRYuwePFirfKff/4ZNjY2Oq6oHHpefh22eQk41OgdPLYt+0Z+RERERDXFiosSRGUUjoR83DYfb55SjTN081Jif6zqF/u3gvPx0QVV+auB+UjKEWHTraqRNMOYvG0F3M8seeSohasS55NNuwXT56Ha+3k9bVlZWRg1ahRSU1Ph4FByZkuzT0QVFUuFUjyFoy6HDx9GRkYGTpw4gblz56JBgwYYOXIkAKB9+/Zo3769um7Hjh3RsmVLfPHFF1i1apXO+82bNw9z5sxRH6elpcHb2xu9e/cutQNNTS6XIzw8HL169YKFheZCREnsZ0BcAjo0bwKhYW8ztbBqK6l/qeLYv6bF/jU99rFpsX9Ni/2rqUXHHHT59BAAVSa+Qf374s1T/wEAGjaoh/2xUQCAnt27onsYkJiRi3b+qsyGC5QCGr8bbo5mm01pgRUApMAOQFap9SqiMnz/FsxqM4TZgis3NzdIJBLExcVplCckJMDDo+QN5/z9/QEAQUFBiI+Px6JFi9TBVXFisRht2rTBzZvac08LyGQyyGTac3EtLCzM/mEW0NkWmyepTOUZQCVpZ1VVmT7r6oj9a1rsX9NjH5sW+9e02L8qPm4WiFjYCx/uvIYx7X1hbVX4u5+ltPBXYlsrGWo7WaOxidrxZt/G+HiX/hlar3RvgFX7bpno6cZ1N9m0gRVQOb5/y/J8047jlcDS0hKtWrVCeLjm/wKEh4drTBMsjSAIGuuldJ2PiIiAl5dx9maoVKydVH8yHTsRERFRqZxsLPHhUO1MhRJx4ShNRTMjbprUFs+1qIPfpoXqPD8jrEGJ18/uqX8DZqr8yjRyNWTIkBLPp6SklOnhc+bMwdixY9G6dWuEhoZi3bp1iI6OxrRp0wCopus9fPgQP/zwAwBg9erV8PHxUe+xdeTIEXz66aeYNWuW+p6LFy9G+/bt0bBhQ6SlpWHVqlWIiIjA6tWry9S2KqEgHTuzBRIRERGVW9EUBLJSgisvRyt89nwIRq0/qS7r2qgWPhwahPi0XDT3dkLnhrVKvIe7vUxjn6cCGye2gVhc9TLkUaEyBVeOjvr3Iyg4P27cOIPvN2LECCQnJ2PJkiWIjY1FYGAgduzYAV9fVXaX2NhYjT2vlEol5s2bh7t370IqlaJ+/fr48MMPMXXqVHWdlJQUTJkyBXFxcXB0dESLFi1w6NAhtG3btixvtWqwclL9yZErIiIionJr7uOkfl3ayJVCKcDKUjPBxfcvqn7P9HK01nUJAGBgsBemdKkHAHiuZR18ffCOVp329VwNbbJO4a92Qa8Vhyp0j9KsHd0S0386Z9JnVGVlCq42bNhg9AbMmDEDM2bM0Hlu48aNGsezZs3SGKXSZcWKFVixYoWxmle5qacFppizFURERERV0vl3eiElWw7bIsGSpUR3cOXvZou7SZno2dQD1hZlyx7oamuJL0e1VB9LiiRv83SwgsxCjN+ndYDVk/tOD6uP3ZfjUNvRGkduJRn8nIYe9lprtgI87XEtLr3E92So3k090DfQE6tHtcTLPxseYIU1roX3nwvC/UdZeGHdCYOvsxAbLan5U2O2NVdkBAXTAjlyRURERFRmzraW8HezhbuDFVaPaomNE9vozVq9ZUp7fPBcEBYMaAILSWGdT4YGlvqcvHylxnHRNV4H3wzD/tfCUMu+MMHGW30DsO+1MFhbagdxr3RvgObeTurj958LREN3Oxx+sxsAYE7vxni9d+G6LUkJ0wyXPNsM59/phda+mvtdeTpYqV93bVQ4xXFkOx+IRCL0DfTE0sH633fRLmzgboeNE9uijpN1mUfmFFUvtmJwVaUVTAvkmisiIiKiChkQ7IWwxu56z7s7WGFUOx/YWEphb1WYPe6Z4NKTpuUpNIMrfzdb9WuZVKJ3nVV+sesAoLGnA4KKJOQY3c4X4XO6wtulcG/Wl7rUw5j2Pvh2fGsolIURyuDmtTXuZWUhgbOtJX56qZ1G+bpxreBmZ4mXOvtj/fjWmB5WH239XNChvio4kohFGN3OR6ttdZysUdfZGrXsCgPFH17UvzRnRlh9vecAQCmINNpfFZh9nyuqAPXIVYpZm0FERERUk3g4WGHViGBcv3i+xAQUTbwccDU2Db2aam4z9GzzOriTmIm2T/bR0idfR2ChEAS81rsR8vKVGNqqrs7rZFIJlg4OAgB8sOOqRnlRDk+CxOLlwXWdcHp+T/Uo3lt9A7SeoWuEb9/rXaFUAr1XHlSX1XbSXIdmaylBZp4CdZ2tNYJEALCXSZGeq7lpcF6+ElbaOyZVWhy5qsqYip2IiIjILPoFeqKRY8mjKt9PbIMFA5rg/SeBTgGJWITX+zRGl0YlZxXM1zEvrrWvM5xsLPHRsOBSgzNAM0BTCgKeCSkcvfJ1LRztWjCgCQDgqzGqtWH6pkcWVTQ4GtPeBzKpBNaWEmTnaY+4Fdg6owM6N3TDFyNboK6zjca5md2109QXH/Wr7DhyVZUVTcUuCJoTXImIiIjIrNwdrDC5c71yX98/2AvH7yTDz9UG/8zqhLScfK2RoNLIi6z3UggCnm9dF39HxgCAOoEGAEzuXK/Mbf11aihSs+VITM9FEy97dXlqdp7eawI8HbBpkmoaYkqWZr2iafBFItWvt7n5DK7oaSlYc6XIA+RZgKVtidWJiIiIqOoY1dYHdZ2sEeLtBHsrC421XobKKzL6JQhApwZuWPJsMzSrXfIWS4awtlSNVHk6WmmUfza8OV7/NRIrX2he4vWO1hZo5GGHG/EZAID67nbqc4sHNcHVy5dgJytbZkZzY3BVlVnaAmIpoMxXrbticEVERERUbUjEInQL0J9kwxCv9mqI+X9eAqDao0skEmFcqJ8RWqffMyG10S/QExZ60toXEIlE2Pm/Ljh8MxHxaTno3LAWVo9qCUdrC7Tzc8SOxIuwsaxa4QrXXFVlIhHTsRMRERGRXqPaFmb1UwpPL/NeaYFVAYlYhLDG7hjRRtXOAcFe6NTQzZRNMykGV1Ud07ETERERkR4ikUi9j9ULbbTTp5NxVa1xNtLGkSsiIiIiKsHPL7VHbGo2fF25hMTUOHJV1anTsaeYsxVEREREVElZSsUMrJ4SBldVXdF07EREREREZDYMrqq6gjVXnBZIRERERGRWDK6qOvWaqxSzNoOIiIiIqKZjcFXVqddcceSKiIiIiMicGFxVdUzFTkRERERUKTC4quqYip2IiIiIqFJgcFXVMRU7EREREVGlwOCqqmMqdiIiIiKiSoHBVVWnTsWeAiiV5mwJEREREVGNxuCqqiuYFggByE0zZ0uIiIiIiGo0BldVnVQGWNioXjOpBRERERGR2TC4qg6Yjp2IiIiIyOwYXFUHTMdORERERGR2DK6qA6ZjJyIiIiIyOwZX1QFHroiIiIiIzI7BVXXANVdERERERGbH4Ko64LRAIiIiIiKzY3BVHaiDK04LJCIiIiIyFwZX1UHBtEAGV0REREREZsPgqjooSGiRk2redhARERER1WAMrqoDmYPqz9w087aDiIiIiKgGY3BVHVg9Ca5yGFwREREREZkLg6vqgCNXRERERERmx+CqOig6ciUI5m0LEREREVENxeCqOigYuVLKgfwc87aFiIiIiKiGYnBVHVjaAaInHyUzBhIRERERmQWDq+pALAZk9qrXTGpBRERERGQWDK6qC5mj6k8mtSAiIiIiMgsGV9WFOqkFpwUSEREREZkDg6vqgunYiYiIiIjMisFVdcGNhImIiIiIzIrBVXVh9WTNFacFEhERERGZBYOr6oLTAomIiIiIzIrBVXXBaYFERERERGbF4Kq64MgVEREREZFZMbiqLjhyRURERERkVgyuqguOXBERERERmRWDq+qC2QKJiIiIiMyKwVV1weCKiIiIiMisGFxVF5wWSERERERkVgyuqouiCS0EwbxtISIiIiKqgRhcVRcFI1eCApBnmbctREREREQ1EIOr6sLSFhBJVK+Zjp2IiIiI6KljcFVdiESAzF71muuuiIiIiIieOgZX1Yl63RUzBhIRERERPW0MrqoTdTp2jlwRERERET1tDK6qE9mT4CqXI1dERERERE8bg6vqpGg6diIiIiIieqoYXFUnMq65IiIiIiIyFwZX1YmNq+rPrGTztoOIiIiIqAZicFWd2NVS/ZmZaN52EBERERHVQAyuqhNbd9WfDK6IiIiIiJ46BlfVie2TkauMBPO2g4iIiIioBmJwVZ1wWiARERERkdkwuKpObIsEV4Jg3rYQEREREdUwDK6qk4LgSpkPZD82b1uIiIiIiGoYBlfViVQGWDmqXnNqIBERERHRU8XgqrpxqKP6M/W+edtBRERERFTDMLiqbpx8VH+mRJu3HURERERENQyDq+rGyVf1J4MrIiIiIqKnyuzB1Zo1a+Dv7w8rKyu0atUKhw8f1lv3yJEj6NixI1xdXWFtbY2AgACsWLFCq97WrVvRtGlTyGQyNG3aFH/++acp30LlwpErIiIiIiKzMGtwtWXLFsyePRvz58/H+fPn0blzZ/Tr1w/R0boDA1tbW8ycOROHDh3C1atXsWDBAixYsADr1q1T1zl+/DhGjBiBsWPHIjIyEmPHjsXw4cNx8uTJp/W2zIvBFRERERGRWZg1uFq+fDkmTZqEyZMno0mTJli5ciW8vb2xdu1anfVbtGiBkSNHolmzZvDz88OYMWPQp08fjdGulStXolevXpg3bx4CAgIwb9489OjRAytXrnxK78rMXPxVfybeAJRK87aFiIiIiKgGkZrrwXl5eTh79izmzp2rUd67d28cO3bMoHucP38ex44dw9KlS9Vlx48fx6uvvqpRr0+fPiUGV7m5ucjNzVUfp6WlAQDkcjnkcrlBbTGVgucb3A7nBpBa2EKUmwp57EXAval2naQbEEf+DNGDUxDlpkNwqQdF94WAS30jtrxqKHP/Upmwf02L/Wt67GPTYv+aFvvXtNi/plWZ+rcsbTBbcJWUlASFQgEPDw+Ncg8PD8TFxZV4bd26dZGYmIj8/HwsWrQIkydPVp+Li4sr8z2XLVuGxYsXa5Xv2bMHNjY2hrwdkwsPDze4bqiVH9zll3Fl57eIqtVD41y9hF1oFrMFYkGhLhMlXsX9xHRE+E4ufqsaoyz9S2XH/jUt9q/psY9Ni/1rWuxf02L/mlZl6N+srCyD65otuCogEok0jgVB0Cor7vDhw8jIyMCJEycwd+5cNGjQACNHjiz3PefNm4c5c+aoj9PS0uDt7Y3evXvDwcGhLG/H6ORyOcLDw9GrVy9YWFgYdI34yFXg4GUEKS+hab9PAQCi2AiIz6yH+OEWAICyXjcomw2F6OFZSM5tgE/uNdTu1xcQmT3HyVNVnv4lw7F/TYv9a3rsY9Ni/5oW+9e02L+mVZn6t2BWmyHMFly5ublBIpFojSglJCRojTwV5++vWlcUFBSE+Ph4LFq0SB1ceXp6lvmeMpkMMplMq9zCwsLsH2aBMrWl9UTg6EqIY85CvHUCkBoNxF0sPN/9HYg7vwaxSASEjAAub4UoMwEWCReBuq1N0v7KrjJ91tUR+9e02L+mxz42LfavabF/TYv9a1qVoX/L8nyzDVNYWlqiVatWWkN94eHh6NChg8H3EQRBY71UaGio1j337NlTpntWefYeQJfXVK+vb1cFVmILoEFPYOIuoMvrQMFIntQSaPBk6uClP8zTXiIiIiKiasCs0wLnzJmDsWPHonXr1ggNDcW6desQHR39//buPL6q8tz7/2ftZGckCRnIREgIYSaATAo4z4CotY7VY7FOpahHn9bnpz6n/sC2Rz21j9r+VOo5j2O1Yj0/p6McKFQUlEmBQJinkABJyACZp53s9fxxQ8ImI7p3dobv+/W6XiRrX3tnrdvFMhf3WtfN/PnzAXO73tGjR3n77bcBePnll0lNTWX06NGAWffqD3/4Aw899FDzZz788MNcdNFF/Nu//RvXX389n3zyCStXruTrr7/u/gP0pwsfhUGjYffn5s/JP4WwmLZzJ94OOz6C716H6b+AgUO6d19FRERERPoAvxZXt956K6WlpfzmN7+hoKCAzMxMli5dSlpaGgAFBQUea1653W6eeOIJcnJyCAwMJCMjg2effZaf//znzTkzZ85kyZIl/PrXv+bJJ58kIyOD999/n/POO6/bj8+vLAvGXGuiMyOuhNQZkLcOPpgHP/tvCGx9m6SIiIiIiLTP7w0tFixYwIIFC9p87c033/T4/qGHHvKYpWrPTTfdxE033eSN3esfLAtu+DO8ejEc3QR/mwfjfgRY4AiAACc4As2thQEn/4wdDpFJ/t5zEREREZEew+/FlfQQ0UPhxv8Df70V9v63ic7EDoe080/GDBiY6vPdFBERERHpqVRcSYsRV8I9f4dNb0L5EcAGdxO4G6HJBW6X+d5VC8cPQul+E5vfMu+PTIG0mTDkXEjIhISxEBLlzyMSEREREek2Kq7EU8rUrrVjrz0Buesgby3kroX8LKg4Atl/M3HKwFQYeiGMvgaGXQpBPWNRZhERERERb1NxJd9PaDSMnmMCoL4KjnxrmmIc3QxFO6HiKJTlQda7JgJDYcg00zxjyHmQMg1C/LtIs4iIiIiIt6i4Eu8IHgAZl5o4pfYEFGyFPctMS/jyPMhZbQLAckD8OEiZAoNPzpjFjQKH35ZfExERERH53lRcie+ERsOwS0zMegaKd5uZrbz1Jspy4Vi2iU1vmvcERcDgSabYGjzFPL81IN6PByEiIiIi0jUqrqR7WBbEjzEx9W6zrSLf3Ep4dBMc2QT5W6Ch0nN2CyDlXBh7HYy5DqLT/LP/IiIiIiKdUHEl/hOZDGOvNwHQ1Ghmt45+11JwFe2AIxtN/P3XMGQ6TLgZxt4A4bH+3X8RERERkdOouJKeIyAQEjNNTLnLbKsogN2fwc5P4NDXcHi9ic8fhfixkHoeJJ0DSRMhYZxZ8FhERERExA9UXEnPFpkE595noqIAtv//ptV7wVYzq1W0oyU3MBSSz4HE8eb2w7hRMGi0ZrhEREREpFuouJLeIzIJZj5oovIYHN5gbhcs2AYFWVBXfrJhxjrP90Wnm8YYqdMh7QKIG2GeARMRERER8SIVV9I7RSSYJhdjrzPfu91Qus+ssXVsOxTvgZI9Zp2tEzkmtr1vcgckQNrMk+ttnQ+27b/jEBEREZE+Q8WV9A0OBwwaZeJ0deUnFzfeYGa0Dm+EqmOw4yPY8RFO4PKgeBxBa2HMXFNw6bktEREREfkeVFxJ3xYSBcOvMAHgqjPdCPPWQe5a7EPfMKChCDa+aiI4CpInQuKEkzHe3EaogktEREREOqHiSvoXZwgMvcAE0Fh9gi3/+TxTI4px7P871JS2XmcrIMjMiCWMN8VWylTTnTAw2E8HISIiIiI9kYor6d+CBlAwcCpNc+bgCHBAYTYUbjN/FmyDYzvMwsaF2Sa2nnxfQJCZ2UqbAaPmQMo0zW6JiIiI9HMqrkROcQSYVu7J57Rsc7uhPA8Kt5tGGflZ5hmumpKTix1/B2v/P3CGQfIkU3ANmQYp50JUiroSioiIiPQjKq5EOuJwQPRQE2Pmmm22DScOmSJr/0rY93eoPQG535jYsNjkRSTB4CkQmXyyHfx5kDRBM1wiIiIifZSKK5GzZVkQk25iwi1mdqt4t1nYOH+z6UhYmA2VBbD7M8/3Boaagit1unnuK/0iM2MmIiIiIr2eiiuRH8rhgISxJs75idnWUG1uISzYam4hPLYD8tZDXRnkfm1izR8gKhWmzINJd5q1u0RERESk11JxJeILQeEw9HwTp7jdULIXDq83627tWWqe5/rit/DlMzD6Ghh/i3l2KyJRM1oiIiIivYyKK5Hu4nBA/GgTU+4CVy3s/AS+ex0ObzBf7/zkZK4TogZD1BAYmAaxwyBuJKSdD2Exfj0MEREREWmbiisRf3GGwsTbTBRuhy1/gQNfwPGD4HaZphknDgFrWt5jBUDaTBh5NcSPhdgMU4BplktERETE71RcifQEiZkw+9/M1+4m0wyjLA/KDpsC6/gBs+5W8S44tMbEKQFBppth3EgYNNo8+5VyLgwc4o8jEREREem3VFyJ9DSOALNGVlQKpJ3x2vEc86zWoa+h9ACcyIGmBvMsV8lez+6EUUNMV8LUGWa2K26UuTVRRERERHxCxZVIbxKTDjMeMAFmlqv8iJnZKt4LRTuhcJuZ5So/DNmHIfsDkxsabdbaShwP8WNO3lY4XOtuiYiIiHiJiiuR3swRANFpJjIua9neUG0WOc5dB3nrzNe1J2DvMhPN73dC3AhImgjDr4Dhl5siTERERETOmoorkb4oKByGXWICoMllZrQOf2tmt4p2mWioPPn9Ttj6HgQEw+g5MPF2U6wF6BIhIiIi0lX6zUmkPwhwwuApJk6xbXPr4LGdkLcW9i6H4t2w4yMTQQNg0CjTJGPQaDPDFTPMtIZ3hvjvWERERER6KBVXIv2VZcHAVBOjZsEVT5nZray/mue0akrh6CYTnm+EyGSIToekCaZgG3YJhMf54yhEREREegwVVyJiWJZ59ippIlz1r6ZJRtEuKN5jWsCXHjDdChsqoeKoidyvT73ZPPcVN8oUaxEJMCAR4seD7fbrYYmIiIh0FxVXItJaQODJWwJHeW63baguNmtwleyF/CzIXQvHsk9b9LiFE5gdEE5Azd8g/UIYegEkZKolvIiIiPRJKq5EpOssCwbEm0iZCufcbrZXl5hZrpI9UFEAVYVQdhj7yHcEuaph71ITACEDYci5pg38qdsSE8ebdbksy2+HJiIiIvJDqbgSkR8uPM7MTKVf6LG5sa6GdR/+mfMH2wQcPtkWvq4M9v3dxOlCY8yCxyOvNhGR2H37LyIiIuIFKq5ExHcCnJwIz8A9cw4Bzl9BUyMUboWjm6Es19xeePygmfWqPQ57PjcB5tmv5ElmseO4kaZbYeRgzW6JiIhIj6XiSkS6T0Bg65bwAK46OLYdDqwyixwf3QQFW02czhkGsRkQO8IUW7EjIG44xGRAcIQKLxEREfErFVci4n/OEPMMV8pUuPh/QlUR5KxuWfC4ZK9pluGqgcJsE60+IwySzoGh50P6RaZxRlhMdx+JiIiI9GMqrkSk5xkQD+Nv8tzW5DIFVsk+KN138s/9JqqLTeGVt9bE6ufMe8LjIX40DBoDCWNN44z4seAM7fZDEhERkb5PxZWI9A4BTnMrYNyI1q/VV0FFPhzeADlfQd4GKM+D6iLIOTkLdorlMM9wJWSaYitxvHm+S4sgi4iIyA+k4kpEer/gATBopInJd5pt9ZVQvBeKd5vbC4/tgMJtUFNqthXvhu3/2fIZ8eMg41IYeiGkTofQgX45FBEREem9VFyJSN8UHAEpU0ycYttQWWie2TqW3fL8Vul+KNphYt1LgAWJmZB2AaTNNKGZLREREemEiisR6T8sCyKTTIy8qmV7dYm5nfDAKshdC8cPtBReGxabnEGjTZEVN9IshByTblrFBwb75VBERESk51FxJSISHgeZN5oAqCgwjTEOfWOKreJdLbcSni4wBFKmmYgZZgqu6HSITFZbeBERkX5IxZWIyJkikzyLrerSk50I10PFUag9AYXboaYEDq0xcbrY4TD+Zsi8yazDJSIiIv2CiisRkc6Ex8KYa02cYttm/a3cb0yhdeIQnMiBsjzzDNeXz5hIOse0lR/3Y4ga7K8jEBERkW6g4kpE5PuwLBg0ysTp6ith91LI/gAOfAEFWSb+/qR5XmvwZIgcbDocBkdAZIpZPFkNM0RERHo9FVciIt4UHAETbzVRXQI7P4bs/4S8dVCyx0QrFiSfA6kzISIBwgdB0ACz2LEzFILCTUEWPkjPcomIiPRgKq5ERHwlPA6m3Wuiqgjyt0DBVlN01VdCfYW5hbB4t3ktf0vHnxcYAlFDzOxX6gxImoxlN3XPsYiIiEinVFyJiHSHAfEw8moTZ6oshP0roWiXKcKqi8FVC64aaKwzhVhlofm6dJ+Jbe/jBOZaAVhHR8DouTDpn0zHQhEREfELFVciIv4WkWgKo440NphOhaUH4PAGyFuHnb8ZR0N1S5v4NX+A9ItM84z4MebWwqZ6qDkODdXmcyIHm+fEQiJ9f1wiIiL9jIorEZHeIDDIzErFpMOIKwBobKhn1SfvcNnICAK3LTENNHJWm+hMZArEjzaLI8ePgcQJkJAJDoePD0RERKTvUnElItJbWQ5qg+Kwx86BibeYNvBZfzXrcZXuh8Z6CAiCsGgzi2XbUJYLlQVQccTE/pUtnxccadboGphqInU6DLvENNQQERGRTqm4EhHpKwamwiWPd55XcxyK90DxLijabf48utk02MjfbAJg7Z9ME430iyHjUhhyHiSOhwCnb49DRESkl1JxJSLS34TFQNoME6c0ucxsV+l+KDts/ty/wsyG7VtuAiAw1BRxEQkQHm/aw0cmmw6GyZM0yyUiIv2aiisRETGzUfFjTJxi26aD4b7lcOgbOLIR6srbX6/LCjALIk+5C0bNhtDobtt9ERGRnkDFlYiItM2yIGGsiQv+B7jdcPygeVbrVMv46mLTwfDoJtPN8PAGE5YDks6B9AvN7YSDRkP0UHAE+PuoREREfEbFlYiIdI3DAXHDTbSl7DBk/w22LoGSvZ7PbwE4w83tg4kTTMEWNwpiMyAkSkWXiIj0CSquRETEOwYOgQt/ZaIiH3LWwKHVULDNFFuuaji0xsSZAoLM81oRSWaGK34sJE2AjMsgOKLbD0VEROT7UHElIiLeF5kME281AeBuMs9v5W+Gwu1m0eOSvaYtPEBTA9Q2QO0JKNoJe5aa7YGhMGYuTLvX3F5oWf45HhERkS5QcSUiIr7nCIDETBOnc9WBqwYaqqG+EirzofQgHMuG3LWma2H2BybC4yFuhGm6kTrDrMMVleKf4xEREWmDiisREfEfZ4iJsBjzfcJYOPVIl22b9bc2vQ7Z/wnVRSZyv4Fv/4/JGZgGI66EEVeb2wjDB+n5LRER8RsVVyIi0jNZFqRMMTHnf0PhNjhxyBRceevM92W5ptA6VWxZARAeB2Fx5n3jboBhl+p2QhER6RYqrkREpOdzhsCQc01MuMVsq6+EQ1/D3uVw4AsoPwx2E1QdM1G0Aza/DVGpED8aBiSYwit+rLmtcOAQ/x6TiIj0OSquRESkdwqOMIsVj5ptvm9qPHnrYDGUH4UD/4Cs96A8z8SZYoebIit2ONhuU5jFDodBY0yL+ABn9x6PiIj0eiquRESkbwgINF0KI5MhaSKMngOX/79QsNUsdFxTAhUF5vv8zaZZRun+dj4rGOLHEJCQSXqJA+tIHCRPhOAB3XtMIiLSq6i46kh1NQS08WB0QACEhHjmtcfhgNDQ75dbUwMNDQTU1Zn3OU/7V1TLgrAwz1zbbvtzz8ytrQW3u/39CA//frl1ddDU5J3csLCWZyTq66Gx0Tu5oaFmnAEaGqCmpu3xbSvX5Wr/c0NCWs6Vs8l1uUx+e4KDITDw7HMbG81YtCcoqOV4zya3qcn8t2uP02nyT+VWV7c/vqfnut3mXOvK53aWGxhoxgLM34maGu/kns3f+268RrQ7vrpGnBQIQy+E9Is8c2vLIG8DHN0EVYVgOcz4VByE0r3QUAlHtuDI3cIEgINvARbEpEPCOEjIhMQREJsOsSPAEaJrBOgaoWuE0auuEWeZe8bvBu2Obxu5ukZw1teIDse3O68RHf29O5MtrZSXl9uAXW6GtHXMmeP5hrCwtvPAti++2DM3Lq793KlTPXPT0trPHTvWM3fs2PZz09I8c6dObT83Ls4z9+KL288NC/PMnTOn/dwzT7Wbbuo4t6qqJXfevI5zi4pachcs6Dg3J6cl99FHO87dvr0ld+HCjnM3bmzJ/f3vO85dtaol96WXOs797LOW3Dfe6Dj3b39ryf3b3zrOfeONltzPPus496WXWnJXreo49/e/b8nduLHj3IULW3K3b+8499FHW3JzcjrOXbCgJbeoqOPcefNacquqOs696SbbQ0e53XSNcOsaYXj7GtHUZNulB2z7Zz/qOPcX4ba9MNLElbEd5+oaYULXCBO6RpjordeIkxp/+cuOc/V7hInveY1wrV3bcW43XiPKwQbs8vJyuzOauRIRETmdwwExw8zzVx1JnAhhxaZ5RkNlx7nL/hdUX27W6aoo8N6+iohIj2LZtm37eyd6moqKCqKioijPzycyMrJ1QjdO57saGli+fDlXX301Tt0W+MNzz5iid9XUtD2+beRqOp+zns53VVa2P7665cf4AdcIV3k5y5cta3t8dY34frnf5xpRewLyd8GxnXA8F44fgJJ9pm1808m/W4GA4+Q+NNngdsDAVIgbbQquQaNg0EhT0EVE6xpxZq6uEd8rV9cI314jXNXVLP/ss7bH94xc/R5x9tcIV10dyz/5pP3x7cZrREVFBVHJyZSXl7ddG5z+9g5f7e/Cwz3/IneUdzaf2VVhYeB00hQSYt7X1ol1em5XnX6R9mbu6f+j8GZucHDLSe7N3KAgsKyujW9QUMtfyq58bldznc6Of+73zQ0MbLlAejM3IKDr5/DJ3C6Nr8PR9c89m1zL8k0u9IzcsLCuje/J3C7TNcLo6jUiNBoyZpo4ndsNFUdNsVW8B/KzWr6uK4PqXBO5yz3f5wgEZxgEhoC7EQKCTPGVNhPSzofkSW031tA14uxzdY3wyO0yXSOMoKCuj69+jzDO8hrR5fH19TWio0L+DCquREREfMHhMGtpDRwCwy5p2W7bUFUExbtNFO0yBVfxLjML5m6E+goTp1QVQs5XLd9HJJuCK2Gc6Y4YPsis4RUeb74OizXdE0VEpFv5/cr7yiuv8Nxzz1FQUMC4ceN48cUXufDCC9vM/fDDD1m8eDFZWVnU19czbtw4Fi1axNVXX92c8+abb/Kzn/2s1Xtra2sJOZt/5RAREfEFy4KIBBPDLm7ZbttmRquhBhrrwFULjgBw1ZhZr9xvIHctVBZAZb6Jg6va/zmhMTBotJnxGnYxpF3QcouSiIj4hF+Lq/fff59HHnmEV155hfPPP59XX32V2bNns3PnTlJTU1vlr169miuvvJKnn36agQMH8sYbb3DttdeyYcMGJk2a1JwXGRnJnj17PN6rwkpERHo0yzK3GIZGt35t8BSYdo/5uua4WZ+raCcU7TaLJp8eNaVgu6H2OOStNbHmDzAwDWY8AJN/Cs6zuFVLRES6zK/F1fPPP88999zDvffeC8CLL77I8uXLWbx4Mc8880yr/BdffNHj+6effppPPvmE//qv//IorizLIjEx0af7LiIi4hdhMRB2Lgw5t+3X3U3m9sLKQrOOV+43sHcZlOXCf/8/sOZ/Q+ZNkDAW4seahhrOMDNLJiIiP4jfiquGhgY2bdrE448/7rH9qquuYu3atV36DLfbTWVlJTExMR7bq6qqSEtLo6mpiXPOOYff/va3HsXXmerr66k/rctJRYW5z93lcuHqqFtLNzj18/29H32Vxte3NL6+pfH1vV47xkFREBsFsaNgwu3gqsGx7X0ca/+IVXEE1r/c6i12cAT2oDEQHAkNVWb2K2YYduI52INGYUcPNc96ebEI67Xj20tofH1L4+tbPWl8z2Yf/NaKPT8/n8GDB/PNN98wc2ZLh6Wnn36at956q9VtfW157rnnePbZZ9m1axfx8fEArF+/nv379zN+/HgqKir44x//yNKlS9m6dSsjRoxo83MWLVrEU0891Wr7X//6V8LOpnuOiIhID2a5G0ku20h0zUEia48QWXeY4MZO1ug6jdsKoDI4maqQJGqd0dQ5o6kITaV0wEjcji52NxMR6WVqamq4/fbbu9SK3e/F1dq1a5kxY0bz9n/913/lL3/5C7t37+7w/e+99x733nsvn3zyCVdccUW7eW63m8mTJ3PRRRfxpz/9qc2ctmauhgwZQklJSacD6Gsul4sVK1Zw5ZVXtt3jX34Qja9vaXx9S+Pre/1ijBuqoakBKguxindBYz0EhQM2VvFurIIsrOMHoSwPy932v97agaHYaedjJ03EjsmA2BHY8WMhsOOW1v1ifP1I4+tbGl/f6knjW1FRQVxcXM9e5youLo6AgAAKCws9thcVFZGQkNDhe99//33uuecePvjggw4LKwCHw8G0adPYt29fuznBwcEEt7GmgdPp9Pt/zFN60r70RRpf39L4+pbG1/f69Bg7B5o/I+Nh8IT289xNUH4Eju0wCyRX5pvvc9dhVRViHVgJB1a25FsBpiV8WCzEpEPiBNM+PnE8xAzzuL2wT49vD6Dx9S2Nr2/1hPE9m5/vt+IqKCiIKVOmsGLFCm644Ybm7StWrOD6669v933vvfced999N++99x7XXHNNpz/Htm2ysrIYP368V/ZbRESkX3IEQHSaidPZtulcePArKNkDJSc7GdYeh+oiE8W7YM/SlvcEhkL8GALix5JeYmEdiYMhUzud6RIR6en82i3wl7/8JXfeeSdTp05lxowZ/Pu//zt5eXnMnz8fgCeeeIKjR4/y9ttvA6aw+ulPf8of//hHpk+f3jzrFRoaSlRUFABPPfUU06dPZ8SIEVRUVPCnP/2JrKwsXn659cO7IiIi8gNZllnMOGFcyzbbNt0KT7WGL8w2hVfRLji2ExprIX8zjvzNTAB46y/gcELcSIgf09LJMH4sDEw1P0NEpBfwa3F16623Ulpaym9+8xsKCgrIzMxk6dKlpKWZfxUrKCggLy+vOf/VV1+lsbGRBx54gAceeKB5+7x583jzzTcBKCsr4/7776ewsJCoqCgmTZrE6tWrOffcdlrWioiIiHdZFkQmmQDIuLTlNXcTHD8Ix7bTlL+N4uwvSGg8glVTAkU7TGw/7bMGJMLwK2DEFZBxGYREdeuhiIicDb8WVwALFixgwYIFbb52qmA65csvv+z081544QVeeOEFL+yZiIiIeJ0jwKytFTcC98i5bKg5hzmzZ+OsKTw5s7Xj5ALJu6B4D1QVQtY7JoIiYPQ1EJkMgSGm8UZ0GkSnQ/RQCB7g76MTkX7O78WViIiI9HOWZW7/G5gKI69u2e6qg7y1sP8fsOe/4fgB2Lak/c+JTDFNMwaNhgGDwBFooskFUYMhdYYpzEREfETFlYiIiPRMzhBzK2DGZXDlb+HQasjbYJplNNZDXRmcyDXdC2uPQ8UREwf+0f5nDkyF1Jkw/HLIuBzCY7vraESkH1BxJSIiIj2fwwHDLjHRltoTULwXineb2wnrysDdaAKgdL9prFGWZ2LbEsCCwZMhaaJ5tisiwfwZHge227y3qcE020iaqNsORaRTKq5ERESk9wuNhtTzTLSnvhKOfAc5X8G+lXAsG45uMtEZK8Cs0ZU6HdJmQvrFEDrQa7svIn2DiisRERHpH4IjTOfCjEvhikVQkW/W5zqRY1rHVx0zf9YcNzNlDicEOE1RVn4YCrJMbPizKbaSJpgZrfix5jmvuJEQkajW8SL9mIorERER6Z8ik+Gcn3Qtt/woHF4PeetbFkzO32LidMGRJ7shjjRrf8WNgtgM86xXgBPcbvNc2PGD5tbDIeeZroci0ieouBIRERHpTNRgiLoRMm8035cdhiMbTev4YztNsXXiENRXtH2roSPQtI931Zii6pSAIHOrYcblpnFHQqaZNRORXknFlYiIiMjZGjjExKliC0wHw+MHoWQvFO2GY9uh9IDZ1lgLDVUmz+E063I11pnbDXNWm1i5EJzhED8GEjNh2KUw5lqzNpiI9AoqrkRERES8ITDYFEbxY2Ds9S3b3W6oLDDFlDMMwgdBQCDYtim+DvwDDnwBOWvAVQ1HvzOx6U2zQPK598OEW9U2XqQXUHElIiIi4ksOh7mt8EyWBXHDTZz3c2hqNAslH9sORzdD1l9Ns43lT5hZrZGzTBONwFBTrDVUQUAwBAaZbbEZprCLG2XWCBORbqfiSkRERKQnCAiEQaNMZN4Il/4v2LoENr9tuhTu+tREZywHxAwjICaDYTWxUDIcEseqi6FIN1BxJSIiItITBYXDtHtMFGbD7qVQngeuWrPYcUiUWeS4qR7qq6BkHxTtMAsql+7HUbqf8QCv/hVCBppmGYNGmUWSQ6PNtuAIs1hy7QkIGgAD4k07+ZgMU+yJyFnR3xoRERGRni5xvInO2LZZr6toF00F2yjd8D6DavZj1ZVB7tcmuiJoAAy9AEZfA6PmmIJMRDql4kpERESkr7AsM/MUkYg79QLWlQ5lztVX4Dyx37SNLz0AtcfNTFXtCWioMbcRhg6EhmqoKoKKo+Z5rr3LTFgPQ/Ik01wjKNzMekWlmJ8TEmXW9ooZBiGR/j56Eb9TcSUiIiLSlwUEQdJEE13hbjKF2N7lsPu/oGBr22t3nc4RCGnnw/DLYdglkDBe63VJv6TiSkRERERaOAJMV8KkCXDx/4TyI5C7DqqLzOxWTalZRLm6COoqoK7M3IqY85UJgLBYSL8YBk8xRV3ieDM7JtLHqbgSERERkfZFpcCEmzvOKT0A+/4OB7+EQ1+bAmzHhyZOSZ5k1v8aPRdih6t7ofRJKq5ERERE5IeJzYDYX8D0X0CTC458Z4qsgiwo2Ga6HOZvMbFyEUQNMQ0zhl5obiNsax0wkV5IxZWIiIiIeE+AE9JmmDilqgh2fwY7P4HctVB+GLa+ZwIgbqQptmIywBlqZraSzzENM0R6ERVXIiIiIuJbA+Jh6t0mGqohbz3kfgMHv4L8zVCy18SZYoeb2wkHTzENMxLGQc1xKMuD+grTMj42A8Jiuv+YRNqg4kpEREREuk9QuOkqOPxyuByoLYNDa8ythOVHwFUDx7abAqp0v4nsD06+2QLs1p8ZkWxaxAcEgsNpiq0h50LqTFOYOUO67/ikX1NxJSIiIiL+EzoQxlxr4nTVpVCwBY5ugcMbIG+dWX8LCyKSzPvqKqDiCFTmmzjdvr+bPx2BEJkMAxJMoTXkXIhKNdsiEk13RBEvUXElIiIiIj1PeCwMv8IEmPW3qoshZKDnTFRdBRTvMYVXkwvcrpPt49eaqC4ys2BleXDkW9jw55b3WgEtiyEHhphwhpjCK3myeRYsPM7kOU5GYCg0VGGVHSWhfAsUDIaUSSrSBFBxJSIiIiK9geNkIXSmkEgYMq319vN+DrYNFfmmgUb5ETP7VZhttlXkg90EFUdNnGnLOx3uTiAwHeDgC6Y4S7sA0i80HRDjx6jY6qdUXImIiIhI32RZps37qVbv429qec3dZLoYVuSb5hiN9dBYC646KNkDx3aaJhv1FSbXdpuZscZaCBqAHT6I8jqbqKYSrLpy2PO5CTCzW4njYdRsyLwRotO6/9jFL1RciYiIiEj/4wiAyCQTZ8O2wbJodLn4aulS5sy6CmfxTji0GnLWmE6Irmo4stHEP56CIeeZ9bxSp0NCJtRXmtm0sjwoP2qKwLBY04bedpvnxIZeCAOH+OTQxXdUXImIiIiIdJVleX7vCISUKSYu+B9mlut4jim2tn9oFlM+vMHE2Ro81TThiE4zDTnCB5muiEHhEBxhWtE7Q1vvk/iNiisREREREW9xBEDccBNT7zYzU/tXmCLryLdw4pC5bXBgqpmZikoBLKgpMbckOgKh9oQpxo5+Z6IjluO0IstxWlimEYfHtpPhcLQ06fD4s63tjjbyznb7GZ/bnNP+Z1g2JJVlgetScDq74T+cd6i4EhERERHxlajBMOUuE2Ce7QoI6ny2qSIfclabBhyVBeb5sKoiqCs3nREbqkye7TbPhdVX+PIoul0gcC7gqp8PYZH+3p0uU3ElIiIiItJdAoO7lheZDBNvM9EWt9ssuNxQBfVVptGGbZtiy2467evT4lRjDrvJvN9uOrmtqeU1j++9ub2tn9f+fribXJw4XkpkQBfHq4dQcSUiIiIi0ts4HBA8wESEv3fG+5pcLr5eupQ5oQP9vStnxeHvHRAREREREekLVFyJiIiIiIh4gYorERERERERL1BxJSIiIiIi4gUqrkRERERERLxAxZWIiIiIiIgXqLgSERERERHxAhVXIiIiIiIiXqDiSkRERERExAtUXImIiIiIiHiBiisREREREREvUHElIiIiIiLiBSquREREREREvEDFlYiIiIiIiBeouBIREREREfECFVciIiIiIiJeoOJKRERERETEC1RciYiIiIiIeEGgv3egJ7JtG4CKigo/7wm4XC5qamqoqKjA6XT6e3f6HI2vb2l8fUvj63saY9/S+PqWxte3NL6+1ZPG91RNcKpG6IiKqzZUVlYCMGTIED/viYiIiIiI9ASVlZVERUV1mGPZXSnB+hm3201+fj4RERFYluXXfamoqGDIkCEcPnyYyMhIv+5LX6Tx9S2Nr29pfH1PY+xbGl/f0vj6lsbXt3rS+Nq2TWVlJcnJyTgcHT9VpZmrNjgcDlJSUvy9Gx4iIyP9fmL1ZRpf39L4+pbG1/c0xr6l8fUtja9vaXx9q6eMb2czVqeooYWIiIiIiIgXqLgSERERERHxAhVXPVxwcDALFy4kODjY37vSJ2l8fUvj61saX9/TGPuWxte3NL6+pfH1rd46vmpoISIiIiIi4gWauRIREREREfECFVciIiIiIiJeoOJKRERERETEC1RciYiIiIiIeIGKqx7ulVdeIT09nZCQEKZMmcKaNWv8vUs93jPPPMO0adOIiIggPj6eH/3oR+zZs8cj56677sKyLI+YPn26R059fT0PPfQQcXFxhIeHc91113HkyJHuPJQeadGiRa3GLjExsfl127ZZtGgRycnJhIaGcskll7Bjxw6Pz9DYtm/o0KGtxteyLB544AFA5+7ZWr16Nddeey3JyclYlsXHH3/s8bq3ztcTJ05w5513EhUVRVRUFHfeeSdlZWU+PrqeoaMxdrlcPPbYY4wfP57w8HCSk5P56U9/Sn5+vsdnXHLJJa3O69tuu80jp7+OcWfnsLeuCRrftse3reuxZVk899xzzTk6f9vWld/H+uI1WMVVD/b+++/zyCOP8C//8i9s2bKFCy+8kNmzZ5OXl+fvXevRvvrqKx544AHWr1/PihUraGxs5KqrrqK6utojb9asWRQUFDTH0qVLPV5/5JFH+Oijj1iyZAlff/01VVVVzJ07l6ampu48nB5p3LhxHmOXnZ3d/Nrvf/97nn/+eV566SW+/fZbEhMTufLKK6msrGzO0di279tvv/UY2xUrVgBw8803N+fo3O266upqJk6cyEsvvdTm6946X2+//XaysrJYtmwZy5YtIysrizvvvNPnx9cTdDTGNTU1bN68mSeffJLNmzfz4YcfsnfvXq677rpWuffdd5/Hef3qq696vN5fx7izcxi8c03Q+LY9vqePa0FBAa+//jqWZXHjjTd65On8ba0rv4/1yWuwLT3Wueeea8+fP99j2+jRo+3HH3/cT3vUOxUVFdmA/dVXXzVvmzdvnn399de3+56ysjLb6XTaS5Ysad529OhR2+Fw2MuWLfPl7vZ4CxcutCdOnNjma263205MTLSfffbZ5m11dXV2VFSU/ec//9m2bY3t2Xr44YftjIwM2+1227atc/eHAOyPPvqo+Xtvna87d+60AXv9+vXNOevWrbMBe/fu3T4+qp7lzDFuy8aNG23Azs3Nbd528cUX2w8//HC779EYG22NrzeuCRpfoyvn7/XXX29fdtllHtt0/nbNmb+P9dVrsGaueqiGhgY2bdrEVVdd5bH9qquuYu3atX7aq96pvLwcgJiYGI/tX375JfHx8YwcOZL77ruPoqKi5tc2bdqEy+XyGP/k5GQyMzM1/sC+fftITk4mPT2d2267jYMHDwKQk5NDYWGhx7gFBwdz8cUXN4+bxrbrGhoaeOedd7j77ruxLKt5u85d7/DW+bpu3TqioqI477zzmnOmT59OVFSUxrwN5eXlWJbFwIEDPba/++67xMXFMW7cOB599FGPf7nWGHfsh14TNL5dc+zYMT7//HPuueeeVq/p/O3cmb+P9dVrcGC3/0TpkpKSEpqamkhISPDYnpCQQGFhoZ/2qvexbZtf/vKXXHDBBWRmZjZvnz17NjfffDNpaWnk5OTw5JNPctlll7Fp0yaCg4MpLCwkKCiI6Ohoj8/T+MN5553H22+/zciRIzl27Bi/+93vmDlzJjt27Ggem7bO29zcXACN7Vn4+OOPKSsr46677mrepnPXe7x1vhYWFhIfH9/q8+Pj4zXmZ6irq+Pxxx/n9ttvJzIysnn7HXfcQXp6OomJiWzfvp0nnniCrVu3Nt8WqzFunzeuCRrfrnnrrbeIiIjgxz/+scd2nb+da+v3sb56DVZx1cOd/q/VYE7OM7dJ+x588EG2bdvG119/7bH91ltvbf46MzOTqVOnkpaWxueff97qonk6jb/5H/kp48ePZ8aMGWRkZPDWW281P0T9fc5bjW1rr732GrNnzyY5Obl5m85d7/PG+dpWvsbck8vl4rbbbsPtdvPKK694vHbfffc1f52ZmcmIESOYOnUqmzdvZvLkyYDGuD3euiZofDv3+uuvc8cddxASEuKxXedv59r7fQz63jVYtwX2UHFxcQQEBLSquIuKilpV+NK2hx56iE8//ZRVq1aRkpLSYW5SUhJpaWns27cPgMTERBoaGjhx4oRHnsa/tfDwcMaPH8++ffuauwZ2dN5qbLsmNzeXlStXcu+993aYp3P3+/PW+ZqYmMixY8dafX5xcbHG/CSXy8Utt9xCTk4OK1as8Ji1asvkyZNxOp0e57XGuGu+zzVB49u5NWvWsGfPnk6vyaDz90zt/T7WV6/BKq56qKCgIKZMmdI8pXzKihUrmDlzpp/2qnewbZsHH3yQDz/8kC+++IL09PRO31NaWsrhw4dJSkoCYMqUKTidTo/xLygoYPv27Rr/M9TX17Nr1y6SkpKab4s4fdwaGhr46quvmsdNY9s1b7zxBvHx8VxzzTUd5unc/f68db7OmDGD8vJyNm7c2JyzYcMGysvLNea0FFb79u1j5cqVxMbGdvqeHTt24HK5ms9rjXHXfZ9rgsa3c6+99hpTpkxh4sSJnebq/DU6+32sz16Du7mBhpyFJUuW2E6n037ttdfsnTt32o888ogdHh5uHzp0yN+71qP94he/sKOiouwvv/zSLigoaI6amhrbtm27srLS/tWvfmWvXbvWzsnJsVetWmXPmDHDHjx4sF1RUdH8OfPnz7dTUlLslStX2ps3b7Yvu+wye+LEiXZjY6O/Dq1H+NWvfmV/+eWX9sGDB+3169fbc+fOtSMiIprPy2effdaOioqyP/zwQzs7O9v+yU9+YiclJWlsz0JTU5OdmppqP/bYYx7bde6evcrKSnvLli32li1bbMB+/vnn7S1btjR3qvPW+Tpr1ix7woQJ9rp16+x169bZ48ePt+fOndvtx+sPHY2xy+Wyr7vuOjslJcXOysryuCbX19fbtm3b+/fvt5966in722+/tXNycuzPP//cHj16tD1p0iSNsd3x+HrzmqDxbfsaYdu2XV5eboeFhdmLFy9u9X6dv+3r7Pcx2+6b12AVVz3cyy+/bKelpdlBQUH25MmTPdqJS9uANuONN96wbdu2a2pq7KuuusoeNGiQ7XQ67dTUVHvevHl2Xl6ex+fU1tbaDz74oB0TE2OHhobac+fObZXTH9166612UlKS7XQ67eTkZPvHP/6xvWPHjubX3W63vXDhQjsxMdEODg62L7roIjs7O9vjMzS2HVu+fLkN2Hv27PHYrnP37K1atarN68G8efNs2/be+VpaWmrfcccddkREhB0REWHfcccd9okTJ7rpKP2rozHOyclp95q8atUq27ZtOy8vz77ooovsmJgYOygoyM7IyLD/+Z//2S4tLfX4Of11jDsaX29eEzS+bV8jbNu2X331VTs0NNQuKytr9X6dv+3r7Pcx2+6b12DLtm3bR5NiIiIiIiIi/YaeuRIREREREfECFVciIiIiIiJeoOJKRERERETEC1RciYiIiIiIeIGKKxERERERES9QcSUiIiIiIuIFKq5ERERERES8QMWViIiIiIiIF6i4EhER8TLLsvj444/9vRsiItLNVFyJiEifctddd2FZVquYNWuWv3dNRET6uEB/74CIiIi3zZo1izfeeMNjW3BwsJ/2RkRE+gvNXImISJ8THBxMYmKiR0RHRwPmlr3Fixcze/ZsQkNDSU9P54MPPvB4f3Z2NpdddhmhoaHExsZy//33U1VV5ZHz+uuvM27cOIKDg0lKSuLBBx/0eL2kpIQbbriBsLAwRowYwaeffurbgxYREb9TcSUiIv3Ok08+yY033sjWrVv5p3/6J37yk5+wa9cuAGpqapg1axbR0dF8++23fPDBB6xcudKjeFq8eDEPPPAA999/P9nZ2Xz66acMHz7c42c89dRT3HLLLWzbto05c+Zwxx13cPz48W49ThER6V6Wbdu2v3dCRETEW+666y7eeecdQkJCPLY/9thjPPnkk1iWxfz581m8eHHza9OnT2fy5Mm88sor/Md//AePPfYYhw8fJjw8HIClS5dy7bXXkp+fT0JCAoMHD+ZnP/sZv/vd79rcB8uy+PWvf81vf/tbAKqrq4mIiGDp0qV69ktEpA/TM1ciItLnXHrppR7FE0BMTEzz1zNmzPB4bcaMGWRlZQGwa9cuJk6c2FxYAZx//vm43W727NmDZVnk5+dz+eWXd7gPEyZMaP46PDyciIgIioqKvu8hiYhIL6DiSkRE+pzw8PBWt+l1xrIsAGzbbv66rZzQ0NAufZ7T6Wz1XrfbfVb7JCIivYueuRIRkX5n/fr1rb4fPXo0AGPHjiUrK4vq6urm17/55hscDgcjR44kIiKCoUOH8o9//KNb91lERHo+zVyJiEifU19fT2Fhoce2wMBA4uLiAPjggw+YOnUqF1xwAe+++y4bN27ktddeA+COO+5g4cKFzJs3j0WLFlFcXMxDDz3EnXfeSUJCAgCLFi1i/vz5xMfHM3v2bCorK/nmm2946KGHuvdARUSkR1FxJSIifc6yZctISkry2DZq1Ch2794NmE5+S5YsYcGCBSQmJvLuu+8yduxYAMLCwli+fDkPP/ww06ZNIywsjBtvvJHnn3+++bPmzZtHXV0dL7zwAo8++ihxcXHcdNNN3XeAIiLSI6lboIiI9CuWZfHRRx/xox/9yN+7IiIifYyeuRIREREREfECFVciIiIiIiJeoGeuRESkX9Hd8CIi4iuauRIREREREfECFVciIiIiIiJeoOJKRERERETEC1RciYiIiIiIeIGKKxERERERES9QcSUiIiIiIuIFKq5ERERERES8QMWViIiIiIiIF/xf78/Go5Q3WNUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:21.048881Z",
     "iopub.status.busy": "2025-05-08T19:03:21.048881Z",
     "iopub.status.idle": "2025-05-08T19:03:21.397350Z",
     "shell.execute_reply": "2025-05-08T19:03:21.397350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/46 for test dataset.\n",
      "  Processed batch 20/46 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/46 for test dataset.\n",
      "  Processed batch 40/46 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:21.400357Z",
     "iopub.status.busy": "2025-05-08T19:03:21.399355Z",
     "iopub.status.idle": "2025-05-08T19:03:21.404413Z",
     "shell.execute_reply": "2025-05-08T19:03:21.404413Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:21.406426Z",
     "iopub.status.busy": "2025-05-08T19:03:21.406426Z",
     "iopub.status.idle": "2025-05-08T19:03:21.924445Z",
     "shell.execute_reply": "2025-05-08T19:03:21.924445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:21.926449Z",
     "iopub.status.busy": "2025-05-08T19:03:21.926449Z",
     "iopub.status.idle": "2025-05-08T19:03:21.974806Z",
     "shell.execute_reply": "2025-05-08T19:03:21.974806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 87.14%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.80      0.80      0.80         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       0.75      0.60      0.67         5\n",
      "           5       0.67      0.80      0.73         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       1.00      0.80      0.89         5\n",
      "           9       0.62      1.00      0.77         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.60      0.60      0.60         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.87        70\n",
      "   macro avg       0.89      0.87      0.87        70\n",
      "weighted avg       0.89      0.87      0.87        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 87.09%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       245\n",
      "           1       0.78      0.95      0.86        76\n",
      "           2       0.88      0.93      0.91       226\n",
      "           3       0.82      0.97      0.89       190\n",
      "           4       0.85      0.73      0.78       244\n",
      "           5       0.66      0.66      0.66       244\n",
      "           6       0.97      0.94      0.96       234\n",
      "           7       0.94      0.94      0.94       178\n",
      "           8       0.85      0.67      0.75       289\n",
      "           9       0.84      0.93      0.88       223\n",
      "          10       0.94      0.94      0.94       280\n",
      "          11       0.90      0.97      0.94       156\n",
      "          12       0.81      0.85      0.83       243\n",
      "          13       0.97      0.94      0.96        70\n",
      "\n",
      "    accuracy                           0.87      2898\n",
      "   macro avg       0.87      0.89      0.88      2898\n",
      "weighted avg       0.87      0.87      0.87      2898\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:21.977810Z",
     "iopub.status.busy": "2025-05-08T19:03:21.976810Z",
     "iopub.status.idle": "2025-05-08T19:03:21.994347Z",
     "shell.execute_reply": "2025-05-08T19:03:21.994347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:21.996359Z",
     "iopub.status.busy": "2025-05-08T19:03:21.996359Z",
     "iopub.status.idle": "2025-05-08T19:03:22.001416Z",
     "shell.execute_reply": "2025-05-08T19:03:22.001416Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:22.003930Z",
     "iopub.status.busy": "2025-05-08T19:03:22.003930Z",
     "iopub.status.idle": "2025-05-08T19:03:25.731431Z",
     "shell.execute_reply": "2025-05-08T19:03:25.731431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6535  |  Val Loss: 2.6180\n",
      "Validation loss improved from inf to 2.6180.\n",
      "[Epoch 2/1000] Train Loss: 2.6163  |  Val Loss: 2.5817\n",
      "Validation loss improved from 2.6180 to 2.5817.\n",
      "[Epoch 3/1000] Train Loss: 2.5789  |  Val Loss: 2.5470\n",
      "Validation loss improved from 2.5817 to 2.5470.\n",
      "[Epoch 4/1000] Train Loss: 2.5443  |  Val Loss: 2.5146\n",
      "Validation loss improved from 2.5470 to 2.5146.\n",
      "[Epoch 5/1000] Train Loss: 2.5098  |  Val Loss: 2.4836\n",
      "Validation loss improved from 2.5146 to 2.4836.\n",
      "[Epoch 6/1000] Train Loss: 2.4769  |  Val Loss: 2.4537\n",
      "Validation loss improved from 2.4836 to 2.4537.\n",
      "[Epoch 7/1000] Train Loss: 2.4463  |  Val Loss: 2.4260\n",
      "Validation loss improved from 2.4537 to 2.4260.\n",
      "[Epoch 8/1000] Train Loss: 2.4173  |  Val Loss: 2.4005\n",
      "Validation loss improved from 2.4260 to 2.4005.\n",
      "[Epoch 9/1000] Train Loss: 2.3919  |  Val Loss: 2.3757\n",
      "Validation loss improved from 2.4005 to 2.3757.\n",
      "[Epoch 10/1000] Train Loss: 2.3655  |  Val Loss: 2.3519\n",
      "Validation loss improved from 2.3757 to 2.3519.\n",
      "[Epoch 11/1000] Train Loss: 2.3411  |  Val Loss: 2.3289\n",
      "Validation loss improved from 2.3519 to 2.3289.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/1000] Train Loss: 2.3169  |  Val Loss: 2.3071\n",
      "Validation loss improved from 2.3289 to 2.3071.\n",
      "[Epoch 13/1000] Train Loss: 2.2943  |  Val Loss: 2.2856\n",
      "Validation loss improved from 2.3071 to 2.2856.\n",
      "[Epoch 14/1000] Train Loss: 2.2713  |  Val Loss: 2.2641\n",
      "Validation loss improved from 2.2856 to 2.2641.\n",
      "[Epoch 15/1000] Train Loss: 2.2488  |  Val Loss: 2.2424\n",
      "Validation loss improved from 2.2641 to 2.2424.\n",
      "[Epoch 16/1000] Train Loss: 2.2267  |  Val Loss: 2.2204\n",
      "Validation loss improved from 2.2424 to 2.2204.\n",
      "[Epoch 17/1000] Train Loss: 2.2037  |  Val Loss: 2.1992\n",
      "Validation loss improved from 2.2204 to 2.1992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 2.1822  |  Val Loss: 2.1780\n",
      "Validation loss improved from 2.1992 to 2.1780.\n",
      "[Epoch 19/1000] Train Loss: 2.1598  |  Val Loss: 2.1576\n",
      "Validation loss improved from 2.1780 to 2.1576.\n",
      "[Epoch 20/1000] Train Loss: 2.1385  |  Val Loss: 2.1370\n",
      "Validation loss improved from 2.1576 to 2.1370.\n",
      "[Epoch 21/1000] Train Loss: 2.1161  |  Val Loss: 2.1168\n",
      "Validation loss improved from 2.1370 to 2.1168.\n",
      "[Epoch 22/1000] Train Loss: 2.0952  |  Val Loss: 2.0962\n",
      "Validation loss improved from 2.1168 to 2.0962.\n",
      "[Epoch 23/1000] Train Loss: 2.0738  |  Val Loss: 2.0755\n",
      "Validation loss improved from 2.0962 to 2.0755.\n",
      "[Epoch 24/1000] Train Loss: 2.0517  |  Val Loss: 2.0551\n",
      "Validation loss improved from 2.0755 to 2.0551.\n",
      "[Epoch 25/1000] Train Loss: 2.0307  |  Val Loss: 2.0349\n",
      "Validation loss improved from 2.0551 to 2.0349.\n",
      "[Epoch 26/1000] Train Loss: 2.0091  |  Val Loss: 2.0161\n",
      "Validation loss improved from 2.0349 to 2.0161.\n",
      "[Epoch 27/1000] Train Loss: 1.9888  |  Val Loss: 1.9977\n",
      "Validation loss improved from 2.0161 to 1.9977.\n",
      "[Epoch 28/1000] Train Loss: 1.9691  |  Val Loss: 1.9796\n",
      "Validation loss improved from 1.9977 to 1.9796.\n",
      "[Epoch 29/1000] Train Loss: 1.9495  |  Val Loss: 1.9619\n",
      "Validation loss improved from 1.9796 to 1.9619.\n",
      "[Epoch 30/1000] Train Loss: 1.9302  |  Val Loss: 1.9440\n",
      "Validation loss improved from 1.9619 to 1.9440.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/1000] Train Loss: 1.9112  |  Val Loss: 1.9264\n",
      "Validation loss improved from 1.9440 to 1.9264.\n",
      "[Epoch 32/1000] Train Loss: 1.8920  |  Val Loss: 1.9091\n",
      "Validation loss improved from 1.9264 to 1.9091.\n",
      "[Epoch 33/1000] Train Loss: 1.8731  |  Val Loss: 1.8922\n",
      "Validation loss improved from 1.9091 to 1.8922.\n",
      "[Epoch 34/1000] Train Loss: 1.8544  |  Val Loss: 1.8751\n",
      "Validation loss improved from 1.8922 to 1.8751.\n",
      "[Epoch 35/1000] Train Loss: 1.8361  |  Val Loss: 1.8579\n",
      "Validation loss improved from 1.8751 to 1.8579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/1000] Train Loss: 1.8170  |  Val Loss: 1.8410\n",
      "Validation loss improved from 1.8579 to 1.8410.\n",
      "[Epoch 37/1000] Train Loss: 1.7983  |  Val Loss: 1.8243\n",
      "Validation loss improved from 1.8410 to 1.8243.\n",
      "[Epoch 38/1000] Train Loss: 1.7797  |  Val Loss: 1.8071\n",
      "Validation loss improved from 1.8243 to 1.8071.\n",
      "[Epoch 39/1000] Train Loss: 1.7609  |  Val Loss: 1.7900\n",
      "Validation loss improved from 1.8071 to 1.7900.\n",
      "[Epoch 40/1000] Train Loss: 1.7419  |  Val Loss: 1.7729\n",
      "Validation loss improved from 1.7900 to 1.7729.\n",
      "[Epoch 41/1000] Train Loss: 1.7231  |  Val Loss: 1.7558\n",
      "Validation loss improved from 1.7729 to 1.7558.\n",
      "[Epoch 42/1000] Train Loss: 1.7036  |  Val Loss: 1.7389\n",
      "Validation loss improved from 1.7558 to 1.7389.\n",
      "[Epoch 43/1000] Train Loss: 1.6846  |  Val Loss: 1.7219\n",
      "Validation loss improved from 1.7389 to 1.7219.\n",
      "[Epoch 44/1000] Train Loss: 1.6655  |  Val Loss: 1.7046\n",
      "Validation loss improved from 1.7219 to 1.7046.\n",
      "[Epoch 45/1000] Train Loss: 1.6461  |  Val Loss: 1.6873\n",
      "Validation loss improved from 1.7046 to 1.6873.\n",
      "[Epoch 46/1000] Train Loss: 1.6267  |  Val Loss: 1.6699\n",
      "Validation loss improved from 1.6873 to 1.6699.\n",
      "[Epoch 47/1000] Train Loss: 1.6075  |  Val Loss: 1.6526\n",
      "Validation loss improved from 1.6699 to 1.6526.\n",
      "[Epoch 48/1000] Train Loss: 1.5880  |  Val Loss: 1.6356\n",
      "Validation loss improved from 1.6526 to 1.6356.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/1000] Train Loss: 1.5690  |  Val Loss: 1.6184\n",
      "Validation loss improved from 1.6356 to 1.6184.\n",
      "[Epoch 50/1000] Train Loss: 1.5502  |  Val Loss: 1.6012\n",
      "Validation loss improved from 1.6184 to 1.6012.\n",
      "[Epoch 51/1000] Train Loss: 1.5304  |  Val Loss: 1.5840\n",
      "Validation loss improved from 1.6012 to 1.5840.\n",
      "[Epoch 52/1000] Train Loss: 1.5111  |  Val Loss: 1.5666\n",
      "Validation loss improved from 1.5840 to 1.5666.\n",
      "[Epoch 53/1000] Train Loss: 1.4915  |  Val Loss: 1.5494\n",
      "Validation loss improved from 1.5666 to 1.5494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/1000] Train Loss: 1.4720  |  Val Loss: 1.5323\n",
      "Validation loss improved from 1.5494 to 1.5323.\n",
      "[Epoch 55/1000] Train Loss: 1.4532  |  Val Loss: 1.5151\n",
      "Validation loss improved from 1.5323 to 1.5151.\n",
      "[Epoch 56/1000] Train Loss: 1.4334  |  Val Loss: 1.4979\n",
      "Validation loss improved from 1.5151 to 1.4979.\n",
      "[Epoch 57/1000] Train Loss: 1.4136  |  Val Loss: 1.4808\n",
      "Validation loss improved from 1.4979 to 1.4808.\n",
      "[Epoch 58/1000] Train Loss: 1.3946  |  Val Loss: 1.4633\n",
      "Validation loss improved from 1.4808 to 1.4633.\n",
      "[Epoch 59/1000] Train Loss: 1.3751  |  Val Loss: 1.4461\n",
      "Validation loss improved from 1.4633 to 1.4461.\n",
      "[Epoch 60/1000] Train Loss: 1.3555  |  Val Loss: 1.4289\n",
      "Validation loss improved from 1.4461 to 1.4289.\n",
      "[Epoch 61/1000] Train Loss: 1.3363  |  Val Loss: 1.4119\n",
      "Validation loss improved from 1.4289 to 1.4119.\n",
      "[Epoch 62/1000] Train Loss: 1.3166  |  Val Loss: 1.3949\n",
      "Validation loss improved from 1.4119 to 1.3949.\n",
      "[Epoch 63/1000] Train Loss: 1.2976  |  Val Loss: 1.3777\n",
      "Validation loss improved from 1.3949 to 1.3777.\n",
      "[Epoch 64/1000] Train Loss: 1.2781  |  Val Loss: 1.3609\n",
      "Validation loss improved from 1.3777 to 1.3609.\n",
      "[Epoch 65/1000] Train Loss: 1.2589  |  Val Loss: 1.3442\n",
      "Validation loss improved from 1.3609 to 1.3442.\n",
      "[Epoch 66/1000] Train Loss: 1.2400  |  Val Loss: 1.3278\n",
      "Validation loss improved from 1.3442 to 1.3278.\n",
      "[Epoch 67/1000] Train Loss: 1.2212  |  Val Loss: 1.3113\n",
      "Validation loss improved from 1.3278 to 1.3113.\n",
      "[Epoch 68/1000] Train Loss: 1.2025  |  Val Loss: 1.2949\n",
      "Validation loss improved from 1.3113 to 1.2949.\n",
      "[Epoch 69/1000] Train Loss: 1.1837  |  Val Loss: 1.2789\n",
      "Validation loss improved from 1.2949 to 1.2789.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70/1000] Train Loss: 1.1655  |  Val Loss: 1.2629\n",
      "Validation loss improved from 1.2789 to 1.2629.\n",
      "[Epoch 71/1000] Train Loss: 1.1476  |  Val Loss: 1.2469\n",
      "Validation loss improved from 1.2629 to 1.2469.\n",
      "[Epoch 72/1000] Train Loss: 1.1298  |  Val Loss: 1.2310\n",
      "Validation loss improved from 1.2469 to 1.2310.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/1000] Train Loss: 1.1120  |  Val Loss: 1.2155\n",
      "Validation loss improved from 1.2310 to 1.2155.\n",
      "[Epoch 74/1000] Train Loss: 1.0945  |  Val Loss: 1.2003\n",
      "Validation loss improved from 1.2155 to 1.2003.\n",
      "[Epoch 75/1000] Train Loss: 1.0775  |  Val Loss: 1.1852\n",
      "Validation loss improved from 1.2003 to 1.1852.\n",
      "[Epoch 76/1000] Train Loss: 1.0605  |  Val Loss: 1.1706\n",
      "Validation loss improved from 1.1852 to 1.1706.\n",
      "[Epoch 77/1000] Train Loss: 1.0438  |  Val Loss: 1.1562\n",
      "Validation loss improved from 1.1706 to 1.1562.\n",
      "[Epoch 78/1000] Train Loss: 1.0269  |  Val Loss: 1.1424\n",
      "Validation loss improved from 1.1562 to 1.1424.\n",
      "[Epoch 79/1000] Train Loss: 1.0104  |  Val Loss: 1.1286\n",
      "Validation loss improved from 1.1424 to 1.1286.\n",
      "[Epoch 80/1000] Train Loss: 0.9944  |  Val Loss: 1.1148\n",
      "Validation loss improved from 1.1286 to 1.1148.\n",
      "[Epoch 81/1000] Train Loss: 0.9785  |  Val Loss: 1.1014\n",
      "Validation loss improved from 1.1148 to 1.1014.\n",
      "[Epoch 82/1000] Train Loss: 0.9624  |  Val Loss: 1.0882\n",
      "Validation loss improved from 1.1014 to 1.0882.\n",
      "[Epoch 83/1000] Train Loss: 0.9472  |  Val Loss: 1.0753\n",
      "Validation loss improved from 1.0882 to 1.0753.\n",
      "[Epoch 84/1000] Train Loss: 0.9320  |  Val Loss: 1.0626\n",
      "Validation loss improved from 1.0753 to 1.0626.\n",
      "[Epoch 85/1000] Train Loss: 0.9172  |  Val Loss: 1.0501\n",
      "Validation loss improved from 1.0626 to 1.0501.\n",
      "[Epoch 86/1000] Train Loss: 0.9028  |  Val Loss: 1.0379\n",
      "Validation loss improved from 1.0501 to 1.0379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 87/1000] Train Loss: 0.8885  |  Val Loss: 1.0261\n",
      "Validation loss improved from 1.0379 to 1.0261.\n",
      "[Epoch 88/1000] Train Loss: 0.8747  |  Val Loss: 1.0150\n",
      "Validation loss improved from 1.0261 to 1.0150.\n",
      "[Epoch 89/1000] Train Loss: 0.8608  |  Val Loss: 1.0041\n",
      "Validation loss improved from 1.0150 to 1.0041.\n",
      "[Epoch 90/1000] Train Loss: 0.8473  |  Val Loss: 0.9933\n",
      "Validation loss improved from 1.0041 to 0.9933.\n",
      "[Epoch 91/1000] Train Loss: 0.8343  |  Val Loss: 0.9828\n",
      "Validation loss improved from 0.9933 to 0.9828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 92/1000] Train Loss: 0.8210  |  Val Loss: 0.9727\n",
      "Validation loss improved from 0.9828 to 0.9727.\n",
      "[Epoch 93/1000] Train Loss: 0.8083  |  Val Loss: 0.9626\n",
      "Validation loss improved from 0.9727 to 0.9626.\n",
      "[Epoch 94/1000] Train Loss: 0.7959  |  Val Loss: 0.9527\n",
      "Validation loss improved from 0.9626 to 0.9527.\n",
      "[Epoch 95/1000] Train Loss: 0.7839  |  Val Loss: 0.9425\n",
      "Validation loss improved from 0.9527 to 0.9425.\n",
      "[Epoch 96/1000] Train Loss: 0.7713  |  Val Loss: 0.9327\n",
      "Validation loss improved from 0.9425 to 0.9327.\n",
      "[Epoch 97/1000] Train Loss: 0.7592  |  Val Loss: 0.9230\n",
      "Validation loss improved from 0.9327 to 0.9230.\n",
      "[Epoch 98/1000] Train Loss: 0.7474  |  Val Loss: 0.9136\n",
      "Validation loss improved from 0.9230 to 0.9136.\n",
      "[Epoch 99/1000] Train Loss: 0.7353  |  Val Loss: 0.9042\n",
      "Validation loss improved from 0.9136 to 0.9042.\n",
      "[Epoch 100/1000] Train Loss: 0.7236  |  Val Loss: 0.8948\n",
      "Validation loss improved from 0.9042 to 0.8948.\n",
      "[Epoch 101/1000] Train Loss: 0.7120  |  Val Loss: 0.8854\n",
      "Validation loss improved from 0.8948 to 0.8854.\n",
      "[Epoch 102/1000] Train Loss: 0.7003  |  Val Loss: 0.8762\n",
      "Validation loss improved from 0.8854 to 0.8762.\n",
      "[Epoch 103/1000] Train Loss: 0.6891  |  Val Loss: 0.8674\n",
      "Validation loss improved from 0.8762 to 0.8674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 104/1000] Train Loss: 0.6779  |  Val Loss: 0.8589\n",
      "Validation loss improved from 0.8674 to 0.8589.\n",
      "[Epoch 105/1000] Train Loss: 0.6664  |  Val Loss: 0.8502\n",
      "Validation loss improved from 0.8589 to 0.8502.\n",
      "[Epoch 106/1000] Train Loss: 0.6554  |  Val Loss: 0.8415\n",
      "Validation loss improved from 0.8502 to 0.8415.\n",
      "[Epoch 107/1000] Train Loss: 0.6445  |  Val Loss: 0.8333\n",
      "Validation loss improved from 0.8415 to 0.8333.\n",
      "[Epoch 108/1000] Train Loss: 0.6341  |  Val Loss: 0.8249\n",
      "Validation loss improved from 0.8333 to 0.8249.\n",
      "[Epoch 109/1000] Train Loss: 0.6237  |  Val Loss: 0.8165\n",
      "Validation loss improved from 0.8249 to 0.8165.\n",
      "[Epoch 110/1000] Train Loss: 0.6138  |  Val Loss: 0.8084\n",
      "Validation loss improved from 0.8165 to 0.8084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 111/1000] Train Loss: 0.6035  |  Val Loss: 0.8006\n",
      "Validation loss improved from 0.8084 to 0.8006.\n",
      "[Epoch 112/1000] Train Loss: 0.5938  |  Val Loss: 0.7927\n",
      "Validation loss improved from 0.8006 to 0.7927.\n",
      "[Epoch 113/1000] Train Loss: 0.5840  |  Val Loss: 0.7853\n",
      "Validation loss improved from 0.7927 to 0.7853.\n",
      "[Epoch 114/1000] Train Loss: 0.5747  |  Val Loss: 0.7780\n",
      "Validation loss improved from 0.7853 to 0.7780.\n",
      "[Epoch 115/1000] Train Loss: 0.5652  |  Val Loss: 0.7712\n",
      "Validation loss improved from 0.7780 to 0.7712.\n",
      "[Epoch 116/1000] Train Loss: 0.5557  |  Val Loss: 0.7642\n",
      "Validation loss improved from 0.7712 to 0.7642.\n",
      "[Epoch 117/1000] Train Loss: 0.5468  |  Val Loss: 0.7577\n",
      "Validation loss improved from 0.7642 to 0.7577.\n",
      "[Epoch 118/1000] Train Loss: 0.5374  |  Val Loss: 0.7506\n",
      "Validation loss improved from 0.7577 to 0.7506.\n",
      "[Epoch 119/1000] Train Loss: 0.5285  |  Val Loss: 0.7438\n",
      "Validation loss improved from 0.7506 to 0.7438.\n",
      "[Epoch 120/1000] Train Loss: 0.5198  |  Val Loss: 0.7370\n",
      "Validation loss improved from 0.7438 to 0.7370.\n",
      "[Epoch 121/1000] Train Loss: 0.5110  |  Val Loss: 0.7303\n",
      "Validation loss improved from 0.7370 to 0.7303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 122/1000] Train Loss: 0.5025  |  Val Loss: 0.7241\n",
      "Validation loss improved from 0.7303 to 0.7241.\n",
      "[Epoch 123/1000] Train Loss: 0.4939  |  Val Loss: 0.7179\n",
      "Validation loss improved from 0.7241 to 0.7179.\n",
      "[Epoch 124/1000] Train Loss: 0.4856  |  Val Loss: 0.7114\n",
      "Validation loss improved from 0.7179 to 0.7114.\n",
      "[Epoch 125/1000] Train Loss: 0.4772  |  Val Loss: 0.7048\n",
      "Validation loss improved from 0.7114 to 0.7048.\n",
      "[Epoch 126/1000] Train Loss: 0.4685  |  Val Loss: 0.6988\n",
      "Validation loss improved from 0.7048 to 0.6988.\n",
      "[Epoch 127/1000] Train Loss: 0.4606  |  Val Loss: 0.6926\n",
      "Validation loss improved from 0.6988 to 0.6926.\n",
      "[Epoch 128/1000] Train Loss: 0.4525  |  Val Loss: 0.6865\n",
      "Validation loss improved from 0.6926 to 0.6865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/1000] Train Loss: 0.4447  |  Val Loss: 0.6803\n",
      "Validation loss improved from 0.6865 to 0.6803.\n",
      "[Epoch 130/1000] Train Loss: 0.4373  |  Val Loss: 0.6743\n",
      "Validation loss improved from 0.6803 to 0.6743.\n",
      "[Epoch 131/1000] Train Loss: 0.4294  |  Val Loss: 0.6684\n",
      "Validation loss improved from 0.6743 to 0.6684.\n",
      "[Epoch 132/1000] Train Loss: 0.4223  |  Val Loss: 0.6629\n",
      "Validation loss improved from 0.6684 to 0.6629.\n",
      "[Epoch 133/1000] Train Loss: 0.4145  |  Val Loss: 0.6575\n",
      "Validation loss improved from 0.6629 to 0.6575.\n",
      "[Epoch 134/1000] Train Loss: 0.4072  |  Val Loss: 0.6518\n",
      "Validation loss improved from 0.6575 to 0.6518.\n",
      "[Epoch 135/1000] Train Loss: 0.4000  |  Val Loss: 0.6467\n",
      "Validation loss improved from 0.6518 to 0.6467.\n",
      "[Epoch 136/1000] Train Loss: 0.3933  |  Val Loss: 0.6418\n",
      "Validation loss improved from 0.6467 to 0.6418.\n",
      "[Epoch 137/1000] Train Loss: 0.3866  |  Val Loss: 0.6364\n",
      "Validation loss improved from 0.6418 to 0.6364.\n",
      "[Epoch 138/1000] Train Loss: 0.3799  |  Val Loss: 0.6316\n",
      "Validation loss improved from 0.6364 to 0.6316.\n",
      "[Epoch 139/1000] Train Loss: 0.3735  |  Val Loss: 0.6270\n",
      "Validation loss improved from 0.6316 to 0.6270.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 140/1000] Train Loss: 0.3677  |  Val Loss: 0.6229\n",
      "Validation loss improved from 0.6270 to 0.6229.\n",
      "[Epoch 141/1000] Train Loss: 0.3616  |  Val Loss: 0.6181\n",
      "Validation loss improved from 0.6229 to 0.6181.\n",
      "[Epoch 142/1000] Train Loss: 0.3555  |  Val Loss: 0.6138\n",
      "Validation loss improved from 0.6181 to 0.6138.\n",
      "[Epoch 143/1000] Train Loss: 0.3498  |  Val Loss: 0.6096\n",
      "Validation loss improved from 0.6138 to 0.6096.\n",
      "[Epoch 144/1000] Train Loss: 0.3442  |  Val Loss: 0.6056\n",
      "Validation loss improved from 0.6096 to 0.6056.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 145/1000] Train Loss: 0.3393  |  Val Loss: 0.6016\n",
      "Validation loss improved from 0.6056 to 0.6016.\n",
      "[Epoch 146/1000] Train Loss: 0.3340  |  Val Loss: 0.5982\n",
      "Validation loss improved from 0.6016 to 0.5982.\n",
      "[Epoch 147/1000] Train Loss: 0.3288  |  Val Loss: 0.5949\n",
      "Validation loss improved from 0.5982 to 0.5949.\n",
      "[Epoch 148/1000] Train Loss: 0.3237  |  Val Loss: 0.5913\n",
      "Validation loss improved from 0.5949 to 0.5913.\n",
      "[Epoch 149/1000] Train Loss: 0.3188  |  Val Loss: 0.5877\n",
      "Validation loss improved from 0.5913 to 0.5877.\n",
      "[Epoch 150/1000] Train Loss: 0.3140  |  Val Loss: 0.5842\n",
      "Validation loss improved from 0.5877 to 0.5842.\n",
      "[Epoch 151/1000] Train Loss: 0.3095  |  Val Loss: 0.5811\n",
      "Validation loss improved from 0.5842 to 0.5811.\n",
      "[Epoch 152/1000] Train Loss: 0.3050  |  Val Loss: 0.5785\n",
      "Validation loss improved from 0.5811 to 0.5785.\n",
      "[Epoch 153/1000] Train Loss: 0.3007  |  Val Loss: 0.5760\n",
      "Validation loss improved from 0.5785 to 0.5760.\n",
      "[Epoch 154/1000] Train Loss: 0.2964  |  Val Loss: 0.5732\n",
      "Validation loss improved from 0.5760 to 0.5732.\n",
      "[Epoch 155/1000] Train Loss: 0.2920  |  Val Loss: 0.5697\n",
      "Validation loss improved from 0.5732 to 0.5697.\n",
      "[Epoch 156/1000] Train Loss: 0.2880  |  Val Loss: 0.5667\n",
      "Validation loss improved from 0.5697 to 0.5667.\n",
      "[Epoch 157/1000] Train Loss: 0.2840  |  Val Loss: 0.5642\n",
      "Validation loss improved from 0.5667 to 0.5642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 158/1000] Train Loss: 0.2799  |  Val Loss: 0.5616\n",
      "Validation loss improved from 0.5642 to 0.5616.\n",
      "[Epoch 159/1000] Train Loss: 0.2766  |  Val Loss: 0.5591\n",
      "Validation loss improved from 0.5616 to 0.5591.\n",
      "[Epoch 160/1000] Train Loss: 0.2729  |  Val Loss: 0.5564\n",
      "Validation loss improved from 0.5591 to 0.5564.\n",
      "[Epoch 161/1000] Train Loss: 0.2691  |  Val Loss: 0.5538\n",
      "Validation loss improved from 0.5564 to 0.5538.\n",
      "[Epoch 162/1000] Train Loss: 0.2655  |  Val Loss: 0.5517\n",
      "Validation loss improved from 0.5538 to 0.5517.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 163/1000] Train Loss: 0.2621  |  Val Loss: 0.5497\n",
      "Validation loss improved from 0.5517 to 0.5497.\n",
      "[Epoch 164/1000] Train Loss: 0.2591  |  Val Loss: 0.5476\n",
      "Validation loss improved from 0.5497 to 0.5476.\n",
      "[Epoch 165/1000] Train Loss: 0.2557  |  Val Loss: 0.5456\n",
      "Validation loss improved from 0.5476 to 0.5456.\n",
      "[Epoch 166/1000] Train Loss: 0.2523  |  Val Loss: 0.5440\n",
      "Validation loss improved from 0.5456 to 0.5440.\n",
      "[Epoch 167/1000] Train Loss: 0.2491  |  Val Loss: 0.5423\n",
      "Validation loss improved from 0.5440 to 0.5423.\n",
      "[Epoch 168/1000] Train Loss: 0.2461  |  Val Loss: 0.5408\n",
      "Validation loss improved from 0.5423 to 0.5408.\n",
      "[Epoch 169/1000] Train Loss: 0.2429  |  Val Loss: 0.5396\n",
      "Validation loss improved from 0.5408 to 0.5396.\n",
      "[Epoch 170/1000] Train Loss: 0.2402  |  Val Loss: 0.5385\n",
      "Validation loss improved from 0.5396 to 0.5385.\n",
      "[Epoch 171/1000] Train Loss: 0.2374  |  Val Loss: 0.5373\n",
      "Validation loss improved from 0.5385 to 0.5373.\n",
      "[Epoch 172/1000] Train Loss: 0.2346  |  Val Loss: 0.5362\n",
      "Validation loss improved from 0.5373 to 0.5362.\n",
      "[Epoch 173/1000] Train Loss: 0.2316  |  Val Loss: 0.5344\n",
      "Validation loss improved from 0.5362 to 0.5344.\n",
      "[Epoch 174/1000] Train Loss: 0.2287  |  Val Loss: 0.5323\n",
      "Validation loss improved from 0.5344 to 0.5323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 175/1000] Train Loss: 0.2263  |  Val Loss: 0.5306\n",
      "Validation loss improved from 0.5323 to 0.5306.\n",
      "[Epoch 176/1000] Train Loss: 0.2244  |  Val Loss: 0.5287\n",
      "Validation loss improved from 0.5306 to 0.5287.\n",
      "[Epoch 177/1000] Train Loss: 0.2215  |  Val Loss: 0.5276\n",
      "Validation loss improved from 0.5287 to 0.5276.\n",
      "[Epoch 178/1000] Train Loss: 0.2191  |  Val Loss: 0.5268\n",
      "Validation loss improved from 0.5276 to 0.5268.\n",
      "[Epoch 179/1000] Train Loss: 0.2165  |  Val Loss: 0.5257\n",
      "Validation loss improved from 0.5268 to 0.5257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 180/1000] Train Loss: 0.2140  |  Val Loss: 0.5242\n",
      "Validation loss improved from 0.5257 to 0.5242.\n",
      "[Epoch 181/1000] Train Loss: 0.2114  |  Val Loss: 0.5228\n",
      "Validation loss improved from 0.5242 to 0.5228.\n",
      "[Epoch 182/1000] Train Loss: 0.2093  |  Val Loss: 0.5217\n",
      "Validation loss improved from 0.5228 to 0.5217.\n",
      "[Epoch 183/1000] Train Loss: 0.2070  |  Val Loss: 0.5206\n",
      "Validation loss improved from 0.5217 to 0.5206.\n",
      "[Epoch 184/1000] Train Loss: 0.2050  |  Val Loss: 0.5200\n",
      "Validation loss improved from 0.5206 to 0.5200.\n",
      "[Epoch 185/1000] Train Loss: 0.2026  |  Val Loss: 0.5195\n",
      "Validation loss improved from 0.5200 to 0.5195.\n",
      "[Epoch 186/1000] Train Loss: 0.2006  |  Val Loss: 0.5186\n",
      "Validation loss improved from 0.5195 to 0.5186.\n",
      "[Epoch 187/1000] Train Loss: 0.1985  |  Val Loss: 0.5180\n",
      "Validation loss improved from 0.5186 to 0.5180.\n",
      "[Epoch 188/1000] Train Loss: 0.1966  |  Val Loss: 0.5169\n",
      "Validation loss improved from 0.5180 to 0.5169.\n",
      "[Epoch 189/1000] Train Loss: 0.1945  |  Val Loss: 0.5164\n",
      "Validation loss improved from 0.5169 to 0.5164.\n",
      "[Epoch 190/1000] Train Loss: 0.1926  |  Val Loss: 0.5159\n",
      "Validation loss improved from 0.5164 to 0.5159.\n",
      "[Epoch 191/1000] Train Loss: 0.1907  |  Val Loss: 0.5156\n",
      "Validation loss improved from 0.5159 to 0.5156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 192/1000] Train Loss: 0.1893  |  Val Loss: 0.5151\n",
      "Validation loss improved from 0.5156 to 0.5151.\n",
      "[Epoch 193/1000] Train Loss: 0.1869  |  Val Loss: 0.5150\n",
      "Validation loss improved from 0.5151 to 0.5150.\n",
      "[Epoch 194/1000] Train Loss: 0.1854  |  Val Loss: 0.5148\n",
      "Validation loss improved from 0.5150 to 0.5148.\n",
      "[Epoch 195/1000] Train Loss: 0.1834  |  Val Loss: 0.5137\n",
      "Validation loss improved from 0.5148 to 0.5137.\n",
      "[Epoch 196/1000] Train Loss: 0.1817  |  Val Loss: 0.5130\n",
      "Validation loss improved from 0.5137 to 0.5130.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/1000] Train Loss: 0.1802  |  Val Loss: 0.5125\n",
      "Validation loss improved from 0.5130 to 0.5125.\n",
      "[Epoch 198/1000] Train Loss: 0.1785  |  Val Loss: 0.5118\n",
      "Validation loss improved from 0.5125 to 0.5118.\n",
      "[Epoch 199/1000] Train Loss: 0.1771  |  Val Loss: 0.5107\n",
      "Validation loss improved from 0.5118 to 0.5107.\n",
      "[Epoch 200/1000] Train Loss: 0.1754  |  Val Loss: 0.5099\n",
      "Validation loss improved from 0.5107 to 0.5099.\n",
      "[Epoch 201/1000] Train Loss: 0.1738  |  Val Loss: 0.5095\n",
      "Validation loss improved from 0.5099 to 0.5095.\n",
      "[Epoch 202/1000] Train Loss: 0.1723  |  Val Loss: 0.5093\n",
      "Validation loss improved from 0.5095 to 0.5093.\n",
      "[Epoch 203/1000] Train Loss: 0.1707  |  Val Loss: 0.5085\n",
      "Validation loss improved from 0.5093 to 0.5085.\n",
      "[Epoch 204/1000] Train Loss: 0.1692  |  Val Loss: 0.5081\n",
      "Validation loss improved from 0.5085 to 0.5081.\n",
      "[Epoch 205/1000] Train Loss: 0.1679  |  Val Loss: 0.5075\n",
      "Validation loss improved from 0.5081 to 0.5075.\n",
      "[Epoch 206/1000] Train Loss: 0.1665  |  Val Loss: 0.5076\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 207/1000] Train Loss: 0.1647  |  Val Loss: 0.5079\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 208/1000] Train Loss: 0.1632  |  Val Loss: 0.5088\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 209/1000] Train Loss: 0.1620  |  Val Loss: 0.5093\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 210/1000] Train Loss: 0.1606  |  Val Loss: 0.5098\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 211/1000] Train Loss: 0.1591  |  Val Loss: 0.5105\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 212/1000] Train Loss: 0.1579  |  Val Loss: 0.5107\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 213/1000] Train Loss: 0.1566  |  Val Loss: 0.5102\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 214/1000] Train Loss: 0.1554  |  Val Loss: 0.5103\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 215/1000] Train Loss: 0.1543  |  Val Loss: 0.5105\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 216/1000] Train Loss: 0.1529  |  Val Loss: 0.5110\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 217/1000] Train Loss: 0.1518  |  Val Loss: 0.5109\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 218/1000] Train Loss: 0.1505  |  Val Loss: 0.5104\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 219/1000] Train Loss: 0.1494  |  Val Loss: 0.5100\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 220/1000] Train Loss: 0.1482  |  Val Loss: 0.5104\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 221/1000] Train Loss: 0.1471  |  Val Loss: 0.5109\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 222/1000] Train Loss: 0.1461  |  Val Loss: 0.5105\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 223/1000] Train Loss: 0.1451  |  Val Loss: 0.5095\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 224/1000] Train Loss: 0.1437  |  Val Loss: 0.5091\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 225/1000] Train Loss: 0.1428  |  Val Loss: 0.5087\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 226/1000] Train Loss: 0.1417  |  Val Loss: 0.5089\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 227/1000] Train Loss: 0.1406  |  Val Loss: 0.5101\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 228/1000] Train Loss: 0.1400  |  Val Loss: 0.5113\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 229/1000] Train Loss: 0.1387  |  Val Loss: 0.5114\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 230/1000] Train Loss: 0.1377  |  Val Loss: 0.5116\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 231/1000] Train Loss: 0.1367  |  Val Loss: 0.5113\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 232/1000] Train Loss: 0.1358  |  Val Loss: 0.5113\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 233/1000] Train Loss: 0.1347  |  Val Loss: 0.5111\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 234/1000] Train Loss: 0.1339  |  Val Loss: 0.5109\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 235/1000] Train Loss: 0.1329  |  Val Loss: 0.5113\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 236/1000] Train Loss: 0.1319  |  Val Loss: 0.5112\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 237/1000] Train Loss: 0.1311  |  Val Loss: 0.5112\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 238/1000] Train Loss: 0.1302  |  Val Loss: 0.5113\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 239/1000] Train Loss: 0.1293  |  Val Loss: 0.5121\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 240/1000] Train Loss: 0.1284  |  Val Loss: 0.5131\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 241/1000] Train Loss: 0.1274  |  Val Loss: 0.5143\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 242/1000] Train Loss: 0.1266  |  Val Loss: 0.5151\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 243/1000] Train Loss: 0.1260  |  Val Loss: 0.5156\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 244/1000] Train Loss: 0.1254  |  Val Loss: 0.5146\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 245/1000] Train Loss: 0.1240  |  Val Loss: 0.5148\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 246/1000] Train Loss: 0.1232  |  Val Loss: 0.5149\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 247/1000] Train Loss: 0.1224  |  Val Loss: 0.5145\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 248/1000] Train Loss: 0.1216  |  Val Loss: 0.5146\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 249/1000] Train Loss: 0.1211  |  Val Loss: 0.5147\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 250/1000] Train Loss: 0.1200  |  Val Loss: 0.5152\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 251/1000] Train Loss: 0.1195  |  Val Loss: 0.5150\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 252/1000] Train Loss: 0.1187  |  Val Loss: 0.5156\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 253/1000] Train Loss: 0.1179  |  Val Loss: 0.5163\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 254/1000] Train Loss: 0.1171  |  Val Loss: 0.5165\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 255/1000] Train Loss: 0.1162  |  Val Loss: 0.5175\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 256/1000] Train Loss: 0.1153  |  Val Loss: 0.5182\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 257/1000] Train Loss: 0.1146  |  Val Loss: 0.5185\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 258/1000] Train Loss: 0.1139  |  Val Loss: 0.5192\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 259/1000] Train Loss: 0.1132  |  Val Loss: 0.5196\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 260/1000] Train Loss: 0.1125  |  Val Loss: 0.5200\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 261/1000] Train Loss: 0.1118  |  Val Loss: 0.5205\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 262/1000] Train Loss: 0.1112  |  Val Loss: 0.5208\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 263/1000] Train Loss: 0.1106  |  Val Loss: 0.5206\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 264/1000] Train Loss: 0.1098  |  Val Loss: 0.5202\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 265/1000] Train Loss: 0.1091  |  Val Loss: 0.5204\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 266/1000] Train Loss: 0.1085  |  Val Loss: 0.5198\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 267/1000] Train Loss: 0.1082  |  Val Loss: 0.5199\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 268/1000] Train Loss: 0.1072  |  Val Loss: 0.5202\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 269/1000] Train Loss: 0.1066  |  Val Loss: 0.5210\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 270/1000] Train Loss: 0.1060  |  Val Loss: 0.5212\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 271/1000] Train Loss: 0.1053  |  Val Loss: 0.5224\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 272/1000] Train Loss: 0.1051  |  Val Loss: 0.5233\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 273/1000] Train Loss: 0.1042  |  Val Loss: 0.5234\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 274/1000] Train Loss: 0.1038  |  Val Loss: 0.5228\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 275/1000] Train Loss: 0.1029  |  Val Loss: 0.5233\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 276/1000] Train Loss: 0.1023  |  Val Loss: 0.5237\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 277/1000] Train Loss: 0.1017  |  Val Loss: 0.5238\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 278/1000] Train Loss: 0.1012  |  Val Loss: 0.5237\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 279/1000] Train Loss: 0.1005  |  Val Loss: 0.5240\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 280/1000] Train Loss: 0.0998  |  Val Loss: 0.5250\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 281/1000] Train Loss: 0.0993  |  Val Loss: 0.5252\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 282/1000] Train Loss: 0.0987  |  Val Loss: 0.5251\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 283/1000] Train Loss: 0.0980  |  Val Loss: 0.5257\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 284/1000] Train Loss: 0.0975  |  Val Loss: 0.5259\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 285/1000] Train Loss: 0.0970  |  Val Loss: 0.5265\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 286/1000] Train Loss: 0.0969  |  Val Loss: 0.5269\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 287/1000] Train Loss: 0.0964  |  Val Loss: 0.5269\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 288/1000] Train Loss: 0.0957  |  Val Loss: 0.5272\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 289/1000] Train Loss: 0.0953  |  Val Loss: 0.5274\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 290/1000] Train Loss: 0.0944  |  Val Loss: 0.5282\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 291/1000] Train Loss: 0.0939  |  Val Loss: 0.5286\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 292/1000] Train Loss: 0.0933  |  Val Loss: 0.5282\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 293/1000] Train Loss: 0.0926  |  Val Loss: 0.5287\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 294/1000] Train Loss: 0.0922  |  Val Loss: 0.5292\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 295/1000] Train Loss: 0.0915  |  Val Loss: 0.5291\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 296/1000] Train Loss: 0.0911  |  Val Loss: 0.5294\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 297/1000] Train Loss: 0.0908  |  Val Loss: 0.5298\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 298/1000] Train Loss: 0.0902  |  Val Loss: 0.5305\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 299/1000] Train Loss: 0.0898  |  Val Loss: 0.5314\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 300/1000] Train Loss: 0.0891  |  Val Loss: 0.5316\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 301/1000] Train Loss: 0.0887  |  Val Loss: 0.5320\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 302/1000] Train Loss: 0.0881  |  Val Loss: 0.5329\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 303/1000] Train Loss: 0.0879  |  Val Loss: 0.5344\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 304/1000] Train Loss: 0.0874  |  Val Loss: 0.5353\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 305/1000] Train Loss: 0.0869  |  Val Loss: 0.5355\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 305 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:25.733733Z",
     "iopub.status.busy": "2025-05-08T19:03:25.733733Z",
     "iopub.status.idle": "2025-05-08T19:03:25.880107Z",
     "shell.execute_reply": "2025-05-08T19:03:25.880107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.3939 | Test Accuracy: 87.44%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:25.882627Z",
     "iopub.status.busy": "2025-05-08T19:03:25.882627Z",
     "iopub.status.idle": "2025-05-08T19:03:25.888158Z",
     "shell.execute_reply": "2025-05-08T19:03:25.887641Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:25.890156Z",
     "iopub.status.busy": "2025-05-08T19:03:25.890156Z",
     "iopub.status.idle": "2025-05-08T19:03:30.615149Z",
     "shell.execute_reply": "2025-05-08T19:03:30.615149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 97.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADWa0lEQVR4nOzdd1QUVxsG8GfpiAgISlFRxIooIjZExK7YS+wtauyJvaHGrthi7733FhO7xl4SG0YFWyyooNJEEaTO94cfqytLWVl2ZvT5nTPnyLR9uLO7Xu6+c1chCIIAIiIiIiKSHD2xAxARERERkXrsrBMRERERSRQ760REREREEsXOOhERERGRRLGzTkREREQkUeysExERERFJFDvrREREREQSxc46EREREZFEsbNORERERCRR7KwTEYlkxYoVcHNzg4mJCRQKBYoUKaLTx69ZsyYUCgVOnz6t08f9XikUCigUCrFjEJHMsLNOlIkLFy6gd+/eKFWqFCwsLGBsbIwCBQqgSZMmWL16Nd6/f5/h8Xv27FH+Jz127NgM933y5Ily38yWJ0+efNXv8/ljZPUcRYoUSfP4JiYmcHJyQufOnXHlypV0j/3xxx+Vx3h4eGT4OP/++6/KY3xtJ/Ldu3eYO3cu6tSpA3t7exgZGcHCwgLly5fHwIEDcf369a86rzatWrUKffv2xe3bt1GiRAl4eXmhUqVKYseSnNQ/KBQKBVq3bp3hvr///rtWXiNfmjhxIiZOnKiVcxERacpA7ABEUhUbG4vu3btj586dAAATExM4OzvD1NQUL168wMGDB3Hw4EGMHz8eR48eRdmyZdWeZ9OmTcp/b968GVOnTs3S6FrFihVhbGyc7nYTExMNf6PsK168OPLnzw8AiI6OxsOHD7FlyxZs374d69atQ5cuXTI8/vr16wgMDISLi4va7Z+31dc6fPgwunbtivDwcABAgQIF4Obmhvfv3+PevXu4efMmFi1ahAEDBmDx4sXZfryvtWzZMgDAzp07M+2E5hRHR0eULFkSuXLlEuXxNfXnn38iKioKVlZWardv3rw5Rx530qRJAJDtDnvJkiW1kIaIvjsCEaWRkJAgeHl5CQAEOzs7YcOGDUJsbKzKPnfu3BH69OkjGBgYCPv27VN7nvDwcMHQ0FBQKBRCnjx5BADC6dOn033cx48fCwAEAMLjx4+1+Btl7zEKFy4sABDWrVunsj4yMlL44YcfBACCubm5EBkZmebYbt26CQCEkiVLCgCE0aNHq32M5ORkwcHBQTA3NxccHBwEAMKpU6c0+t0OHDgg6OvrCwCE9u3bC3fv3lXZHhMTI2zZskUoWbKk4ObmptG5tc3U1FQAkOZ5Rap8fHxUnj/Lly9Xu9+bN28EExMTwdnZWfkc0NZrKPX1QkQkBpbBEKkxadIkXLhwAba2trh06RK6du0KU1NTlX1cXFywfPlynDp1Sjna/KUdO3YgMTER1apVQ+fOnQFoZ/RYKqysrLBmzRqYmZnh3bt3OHbsWLr7tmzZEmZmZti6dSsEQUiz/a+//kJISAhat26dpq2z4vXr1+jWrRuSk5MxcuRIbNu2Lc1IppmZGTp27IibN2+ie/fuGj+GNsXFxQHAV/2u36NOnTpBoVCkO3q+a9cufPjwIdNPd4iI5IaddaIvREdHY+HChQCA+fPnZ3rTX/Xq1VGtWjW121I75h07dkSnTp0AfOpUfCvy5MmDEiVKAECGNcJmZmZo0aIFgoODcebMmTTbU9sq9Y8aTS1evBhRUVEoU6YMpk2bluG+xsbGGDRoUJr1ERERGDlyJEqWLAlTU1NYWVmhZs2a2LJli9o/MNavXw+FQoEff/wR8fHxmDhxIooVKwYTExMUKlQIQ4cOTXNPQ2r9f6rPa6zXr18P4FOdf+rPX5o4cSIUCkWasgxBELBx40bUqFEDlpaWMDIygp2dHTw8PDBy5Eg8f/5cZf+MbjAVBAGbN2+Gj48PLC0tYWpqilKlSmHUqFGIjIxUm+vzGygPHz6MGjVqwNzcHBYWFvD19cWNGzfUHpcVTk5OqFatGi5cuIDHjx+n2Z6V58/Lly+xaNEiNGjQAEWKFIGJiQmsrKzg4+Oj9o/o1Hb+8vf7sib+8+fB+/fvMWbMGJQoUQImJiaoWbNmmuM/l1oW5+rqqvZ9Ye3atVAoFHBwcEBERESGbURE3yZ21om+cPDgQbx79w758uXDDz/88NXnefDgAS5fvgwDAwO0bdsW1apVg5OTE96+fYsDBw5oMbH4YmNjASDT2ufUUc8vR0djY2Oxb98+FChQALVq1fqqDNu3bwcA9O7dGwYGmt+O8/DhQ7i7u2P27Nl48uQJXFxckDdvXpw5cwadO3fGjz/+qLbDDgCJiYmoX78+Jk+eDBMTExQpUgQhISGYN28eWrZsqbJvpUqV4OXlpfzZy8tLudja2mqc+3MjRoxAt27dcO7cOeUNtbly5cLt27cxe/ZsXL16NUvnEQQBnTt3RpcuXXD27FlYW1vDxcUFjx8/xqxZs1ChQgU8evQo3eOXL1+Oxo0b4+HDhyhRogSSk5Nx5MgR1KhRA3fv3v3q369Lly4QBAFbtmxRWR8cHIxz587B09MTzs7O6R6/evVqDBw4EOfOnYOBgQHKli2LPHny4OzZs+jatSv69eunsr+jo2O618rLyyvNfSNxcXGoUaMGZsyYAQMDA7i4uGR43wkA+Pn5wdPTE3fu3MHo0aNVtj158gSDBw8GAKxZswbW1tYZnouIvlEiluAQSdKAAQMEAEKLFi2ydZ5ff/1VACA0atRIuW7s2LECAKFJkyZqj5FbzbogCML9+/cFAwMDAYBw9uzZNNtTa9anTJkiJCUlCXZ2doKFhYUQFxen3GfLli0CAGHkyJGCIAiCs7OzRjXrYWFhyt8pICAgS8d8LiUlRahYsaIAQPDx8RFevnyp3Hb48GHBzMxMACAsXbpU5bh169YJAARDQ0PBxcVFuHfvnnLbpUuXlPcpHD58OM1jIoM66NQ2U9fegiAIEyZMEAAIEyZMUK57/fq1oKenJ1hYWAjnz59X2T8uLk7Ytm2bcPPmTZX1qfXgX7bzokWLlPchHDt2TLk+NDRUeS9HlSpV0v2dcuXKpZL97du3Qp06dQQAQrt27dT+TulJzbhp0yYhMjJSMDIyEkqUKKGyz7Rp01SuT3o16+fOnRP++usvISkpSWX9zZs3hdKlS6d7T0lG10oQPj0P9PX1hRIlSgiBgYHKbZ8/z9M7z8OHDwUzMzNBoVAIx48fFwTh4z0c3t7eAgChX79+6T42EX37OLJO9IUXL14A+Pixe3akjh537NhRuS61FObIkSMICwvL8HgnJ6d0p20sX758trJpw9u3b3HixAm0aNECSUlJ8PLygre3d4bH6Ovro0OHDoiOjlb5dCG7JTCp1wz4uut28uRJXL16FcbGxti+fbvKCHfDhg0xYcIEAMDMmTPVjq4nJSVhw4YNynIgAKhatSp++uknAB9LQnLaf//9h5SUFNSuXVtlNBj4OHNQ+/btUa5cuUzPIwgCZs2aBQCYPHky6tWrp9xmZ2eHHTt2wMjICH///Tf++usvtefo2bMnfvzxR+XP5ubmmDdvHoCPz/2vZWVlhcaNG+P+/fv4559/lOs3b94MQ0NDtG3bNsPjq1evjlq1akFfX19lfbly5bBo0SIASDNqr4nk5GRs27YNpUuXVq7LyqxNzs7OmDt3LgRBwI8//oioqCjMmjUL586dQ4kSJTBnzpyvzkRE8sfOOtEX3r17B+BjjfXXOn/+PB4/foxcuXKhRYsWyvWlS5dG+fLlkZSUpCzbSE/FihXTfOyeuri7u391tuzo3r278g8GCwsL1KtXD3fv3kW7du3wxx9/ZOkcX5bCvHr1CidOnICbm1u6019mJvWaAV933VJvjG3Tpg3s7OzSbO/bty+MjY3x9OlT3Lt3L8328uXLo2LFimnWp86bnlHJiLYUKlQIAPD3338jODj4q88TFBSEZ8+ewcTEBL169UqzvUCBAsqpJtO7oTj1j5TPlS1bFiYmJoiOjs5W7fWXz59r164hKCgIjRo1ylKZyLt377Bq1Sp069YN9evXh7e3N6pXr64sQbl58+ZXZytTpgwqVKjwVcf27t0bTZo0wYsXL9CyZUtMmDABBgYG2Lx5s2ym1iSinMF51om+YG5uDgCZftlRRlJHips1a5am89ipUycEBARg06ZN+OWXX9I9x65du3T+jZaZSZ1nXRAEvHz5Eo8ePYKhoSEqVaqU7tzXX3J3d0eZMmVw5MgRhIeHY9u2bUhKSvrqUXXg0zUDPl63PHnyaHT8/fv3ASDd+d/Nzc1RqFAhPHz4EPfv30epUqVUtqdXJ506S1BMTIxGeb5GgQIF0KZNG+zatQvFihVDrVq1ULNmTXh7e6Nq1apZruNPbQtHR8d0//ApU6aMyr5fSq898uXLh2fPniEmJuar668bN24MKysrbN++HXPnztXoU5kbN26gSZMmCAkJSXef9G6ezYrPR9S/xurVq1G2bFnlDdgTJ07kF2UREUfWib5UoEABAFA740RWxMfHK79I6fMSmFQdOnSAnp4erly5onaUVsrGjBmD8+fP48KFC/jvv/9w/vx5mJubY/jw4Rp9IU3nzp2RmJiIHTt2YPPmzdDT01PbVlmVes2Ar7tuqZ3p9KbgBKAsjfl8FD9Vep1aPb2Pb7HqSmdywsaNGzFhwgTkz58fx44dw5gxY+Dt7Q0HBwfMmTMHKSkpmZ4ju20B5Gx7GBkZoW3btggLC8PBgwexfft2WFpaomnTphkel5ycjLZt2yIkJASNGjXCmTNnEB4ejqSkJAiCgAcPHgD4eLPw18rOp3HAx3ZN/UNIT09PpZSIiL5f7KwTfSF1GsaLFy8iKSlJ4+P/+OMPvHnzBsDHkfUv680LFiyo7DTJfc51Ly8vrFq1CgAwaNAgvH37NkvHpc6ZPWvWLFy7dg116tSBg4PDV+ewsbFB8eLFAUDttJCZyZ07N4CPc7Wn59WrVwBUR/FzSur0ful1atP71MfExAQTJ07E8+fPERQUhBUrVqBp06aIiIjAiBEjMHfu3EwfW2ptoU5qKczAgQPx6tUrtGnTJtNZV/755x88fPgQhQsXxt69e1GjRg1YW1sr69efPXuW47kzs2TJEpw+fRp6enpISUlBr169dPaHHhFJFzvrRF9o1KgRcufOjdevX2P37t0aH5/aATc3N4etra3aJW/evAA+1t3K/T/jFi1aoGrVqoiMjMxSZxD4WF/t4+OjrK3OTglMqnbt2gEAVq5cieTkZI2OTb0xNDAwUO32d+/eKTtzn99EmlNSR2jTuwn54cOHmZ6jVKlS6N27Nw4cOIClS5cCgPIPq4yk/n7BwcHplu/cuXNHZV9d8/LygpOTk0bPn9Q50T08PNR27LNTq64N9+/fx8iRI6Gnp4cDBw7AyckJx48fx+LFi0XNRUTiY2ed6AuWlpbKWvLBgwdn+EU/AHDhwgVcvHgRwMcv1Umd+ePAgQN4+fKl2uXx48cwMTHB06dPce7cuRz9fXQh9ea8hQsXZrk+e+DAgahTpw7q16+PVq1aZTvDzz//DEtLS9y5cwdjx47NcN/4+HjlF18BQIMGDQB8vE/g5cuXafZfsWIF4uPjUbhw4TTfipoTihYtCgC4cuVKmm3Pnz/H0aNHNTpf1apVASDDWu1UpUuXhqOjIz58+IDVq1en2R4SEoI9e/YA+NRuYhg5ciTq1KmDVq1aZToLEfDpm2JTPxX4XGJiIubPn5/psanfOqttSUlJ6NKlC2JjYzFs2DA0btwYGzduhJ6eHkaNGiW7cjki0i521onUmDhxIjw9PfHq1St4enpi06ZNab5d8P79+xgwYABq1qypLBnYvn07EhMT4ejoCB8fn3TPnydPHmWNrdxLYYCP5T6lS5dGVFQUli1blqVjWrZsiRMnTuDo0aPK0ovssLW1xbp166Cvr4+ZM2eiY8eOaTo5cXFx2LlzJ9zd3bF27Vrl+tq1a6NSpUqIj49Hhw4dVEpAjh07hkmTJgH4+EfJl99AmRN8fX0BAPv378ehQ4eU60NDQ9GpUye15VknT57EiBEj0nw6EBMTg9mzZwNAlmYqUSgUGDFiBABgwoQJOHnypHLbq1ev0L59eyQkJKBq1apf/QVW2tC3b1+cOHECe/bsydI1Sb3J9sKFC9i4caNyfXR0NDp16qS2E58q9Y+nrymxyoqpU6fin3/+QdmyZTFlyhQAH6eZHD58OOLi4tC5c+evKskjom+EWBO8E0ndu3fvhNatWyu/yMTU1FRwdXUVKlWqJBQoUEC5vmDBgsKtW7cEQRCEKlWqCAAEPz+/TM//+++/CwBUviDo8y8sqlixouDl5ZXuou4LiLLi88ewsrISrK2t1S5FixZVHpPRlyKlWrNmjQBAsLOzU/kimM+/FCmrNP1SpM/98ccfgrW1tfJ3LFSokFCpUiXBxcVFMDExEQAICoVCGDhwoMpxDx48EAoWLCgAEIyNjYUKFSoIxYoVU56nS5cuQkpKisoxqV+G061bN7VZTp06pfyipS8hnS/ISdWzZ0/lPk5OTkL58uUFAwMDoVSpUsKgQYPSfCnSvn37lPvny5dPqFixouDm5ibkypVL+Ty7du2aymOk96VIKSkpQseOHZXnK1asmFChQgXByMhIACA4OjoK//33n8a/U+rzSJMv/Pr8S5GyKr0vRRo+fLgyo6Ojo+Dh4SGYmpoKhoaGwrJlywQAQuHChdOcb/LkycovPXJ3dxd8fHwEHx8fITQ0VBCEzJ8HqdS1z99//y0YGBgIRkZGab7QKz4+XnBzcxMACOPHj8/y709E3xZO3UiUjty5c2P37t04d+4cNmzYgHPnzuHJkydISEiAjY0NGjdujFatWqFDhw4wNTXFgwcP8PfffwPIWg2tr68vrK2tERERgT/++ANt2rRR2Z7ZV8NnZ67qVFFRUelu03Qkr3Pnzvj1118REhKCtWvXon///tmN91WaNGmCR48eYeXKlTh06BACAwMREBAAExMTlCpVCj4+PujRo0eaLwgqVqwYbty4gZkzZ+L333/HnTt3YGxsjBo1aqBXr17Km2J1Zfny5ShcuDA2bNiAZ8+eISEhAX369MHUqVPVlmx4e3tj4cKFOH78OG7fvo3AwEAYGhqiWLFiaNiwIYYMGaJ2Dnl1FAoFNm/ejIYNG2LVqlW4efMmnj17hsKFC6NFixYYNWrUV0+9KKZZs2ahYMGCWL58OR49eoTY2FjUrVsXY8eOVfkirC+NHj0aycnJ2L59OwIDAxEfHw8AaT5t01RsbCy6dOmCpKQk+Pv7w83NTWW7kZERNm/ejIoVK2L69Olo3LgxKleunK3HJCL5UQiCzO9uIyIiIiL6RrFmnYiIiIhIothZJyIiIiKSKNasE8nY2rVrVWY1ycz58+dzMA0RERFpGzvrRDIWHByMCxcuiB2DiIjom3f27FnMnj0b165dQ2hoKPbt24cWLVpkeMyZM2cwdOhQ3LlzBw4ODhg5ciT69u2r0eOyDIZIxiZOnAhBELK8EBER0dd5//493NzcsvzNwo8fP0ajRo3g7e2NGzduYMyYMRg4cKDyi+WyirPBEBERERFpQKFQZDqyPmrUKBw4cABBQUHKdX379sXNmzdx6dKlLD8WR9aJiIiI6LsUHx+Pt2/fqiyp36WQXZcuXUL9+vVV1jVo0ABXr15FYmJils/zzdasm7r/LHaELIm6krWPUoiIiIi+honEentS6qONam6DSZMmqaybMGECJk6cmO1zv3z5Ms0Xrtna2iIpKQnh4eGwt7fP0nkkdvmIiIiIiHTDz88PQ4cOVVlnbGystfN/+c3XqdXnmnwjNjvrRERERPRdMjY21mrn/HN2dnZ4+fKlyrrXr1/DwMAA1tbWWT4PO+tEREREpDuK7+OWSU9PT/zxxx8q644dO4aKFSvC0NAwy+f5PlqLiIiIiCgbYmJiEBAQgICAAAAfp2YMCAhAcHAwgI8lNV27dlXu37dvXzx9+hRDhw5FUFAQ1q5dizVr1mD48OEaPS5H1omIiIiIMnH16lXUqlVL+XNqrXu3bt2wfv16hIaGKjvuAODk5IRDhw5hyJAhWLJkCRwcHLBw4UK0bt1ao8f9ZudZl9KdxhnhbDBERESUkyQ3G4zHILEjKMVdWyB2hEyxDIaIiIiISKLYWSciIiIikiiJfTBCRERERN+072Q2GG1haxERERERSRRH1omIiIhIdzT49k7iyDoRERERkWSxs05EREREJFEsgyEiIiIi3eENphphaxERERERSRQ760REREREEsUyGCIiIiLSHc4GoxGOrBMRERERSdR33Vkf3qM+zm8egdfn5+DpSX/snNsLxQvnT3f/RWPbI+7GYvzcsabK+qOrBiHuxmKVZeOM7jmcPq0d27bAt35tVHIvi/ZtWuH6tas6z5AZOWQE5JFTDhkBeeSUQ0ZAHjnlkBGQR045ZATkkVMOGQH55Mw2hZ50FhmQR8oc4l2hGJbvOAufrnPQpN9i6Ovr489lPyOXiVGafZvWLIdKZYsg5PUbtedas+cCitT1Uy4/T92Ww+lVHTl8CLNm+KNX737YsXs/KlTwQP8+vRAaEqLTHBmRQ0ZAHjnlkBGQR045ZATkkVMOGQF55JRDRkAeOeWQEZBPTtK977qz3vznpdj8x98IevQSt+6/QJ+Jm+FonxfuLoVU9nPIZ4F5o9ug+5j1SExKVnuuuA8JeBXxTrm8jfmgi19BadOGdWjZujVa/dAGRZ2dMdJvLOzs7bBzh27/aMiIHDIC8sgph4yAPHLKISMgj5xyyAjII6ccMgLyyCmHjIB8cpLufded9S/lyW0CAIiKjlWuUygUWDO1K+ZtOImgRy/TPbZdo4p49tcMXNs9Fv5DWiJ3LuMcz5sqMSEBQYF34Fmtusp6z2peuBlwQ2c5MiKHjIA8csohIyCPnHLICMgjpxwyAvLIKYeMgDxyyiEjIJ+cWqNQSGeRAc4G85mZw1rjwvWHCPwvVLluWPd6SEpOwZJtp9M9bvuhK3gSEoFX4W9RppgDJv/SFGVLFECTfot1kBqIehOF5ORkWFtbq6y3trZBeHiYTjJkRg4ZAXnklENGQB455ZARkEdOOWQE5JFTDhkBeeSUQ0ZAPjlJHJLvrD979gwTJkzA2rVr090nPj4e8fHxKuuElGQo9PSz/DjzRrdF2eIOqNN9nnKde+lCGNChJqp1nJnhsev2XVT+O/C/UDwMfo2LW0ehfKmCCLj7PMsZskvxxV+IgiCkWSc2OWQE5JFTDhkBeeSUQ0ZAHjnlkBGQR045ZATkkVMOGQH55CTdknwZTGRkJDZs2JDhPv7+/rCwsFBZkl5dy/JjzB3VBk18yqJBr4V48dkNpF7uzsifNzfuH5qMd1cW4N2VBSjsYI0ZQ1vh7sFJ6Z7vRtAzJCQmoZhj+jPLaJOVpRX09fURHh6usj4yMgLW1jY6yZAZOWQE5JFTDhkBeeSUQ0ZAHjnlkBGQR045ZATkkVMOGQH55NQasWeA4Wwwmjlw4ECGy6lTpzI9h5+fH6Kjo1UWA1uPLD3+vFFt0Ly2Gxr2WYinIREq27YevIJKbf1Rpf0M5RLy+g3mbTyBpv2XpHtOF2d7GBkaIDQ8OksZssvQyAilXcrg8sULKusvX7wIt/LuOsmQGTlkBOSRUw4ZAXnklENGQB455ZARkEdOOWQE5JFTDhkB+eQkcYheBtOiRQsoFAoIgpDuPpl9BGRsbAxjY9UbOrNSAjPfry3a+VZEmyErEfP+A2ytzQEA0TEf8CE+EZHR7xEZ/V7lmMSkZLwKf4sHT18DAJwK2qB9o4o4ej4Q4VExKO1shxlDWuFG0DNcCniUaQZt6dKtO8aOHgkXV1e4ubljz64dCA0NRZt27XWWITNyyAjII6ccMgLyyCmHjIA8csohIyCPnHLICMgjpxwyAvLJSbonemfd3t4eS5YsQYsWLdRuDwgIgIdH1kbJNdWnbQ0AwPHVg1XW9xq/CZv/+DtL50hMTEKtyiUxoEMt5M5lhOcv3+DI+duYtuIwUlLS/wNE2xr6NkL0myisXLYUYWGvUax4CSxZvhIODgV0liEzcsgIyCOnHDIC8sgph4yAPHLKISMgj5xyyAjII6ccMgLyyakVrMPXiELIaEhbB5o1a4by5ctj8uTJarffvHkT7u7uSElJ0ei8pu4/ayNejou6opsZY4iIiOj7ZCL60KwqU6+xYkdQirswTewImRL98o0YMQLv379Pd3uxYsWyVLdORERERDIgkxs7pUL0zrq3t3eG283MzODj46OjNERERERE0sE/bYiIiIiIJEr0kXUiIiIi+o7wBlONcGSdiIiIiEii2FknIiIiIpIolsEQERERke5wNhiNsLWIiIiIiCSKnXUiIiIiIoliGQwRERER6Q7LYDTC1iIiIiIikiiOrBMRERGR7uhxnnVNcGSdiIiIiEii2FknIiIiIpIolsEQERERke7wBlONsLWIiIiIiCSKnXUiIiIiIoliGQwRERER6Y6Cs8FogiPrREREREQSxc46EREREZFEfbNlMFFXFosdIUusKv0sdoRMyaUtiYiISAY4G4xG2FpERERERBL1zY6sExEREZEE8QZTjXBknYiIiIhIothZJyIiIiKSKJbBEBEREZHu8AZTjbC1iIiIiIgkip11IiIiIiKJYhkMEREREekOZ4PRCEfWiYiIiIgkiiPrRERERKQ7vMFUI2wtIiIiIiKJYmediIiIiEiiWAZDRERERLrDG0w1wpF1IiIiIiKJYmediIiIiEiiWAZDRERERLrD2WA0wtYiIiIiIpIodtaJiIiIiCSKnfUs2LFtC3zr10Yl97Jo36YVrl+7KmqeuwcnIe7G4jTLvNFtlfuUdLLFrvl98PLsbLw+PwdnNgxDITsrEVN/JLW2TI8ccsohIyCPnHLICMgjpxwyAvLIKYeMgDxyyiEjIJ+c2aZQSGeRAXbWM3Hk8CHMmuGPXr37Ycfu/ahQwQP9+/RCaEiIaJmqd56NInX9lEujvosAAHuP3wAAOBW0wcm1Q3H/8Us06LUAldv5w3/VEXyITxQtMyDNtlRHDjnlkBGQR045ZATkkVMOGQF55JRDRkAeOeWQEZBPTtI9hSAIgtghcsKHJO2cp1P7Nijt4oJx4ycp17Vo6otateti0JBh2T6/VaWfs32O2cNbw9fbFa7NP2bcOKM7EhOT0fPXjdk+NwBEXVmslfPkdFtqixxyyiEjII+ccsgIyCOnHDIC8sgph4yAPHLKISOQszlNJDadiGkT7fQrtCHuz+z3w3IaR9YzkJiQgKDAO/CsVl1lvWc1L9wMuCFSKlWGBvpo36gSNvx+CQCgUCjQsHoZPAh+jQNLBuDpSX+c3TgcTWuWEzWnHNoSkEdOOWQE5JFTDhkBeeSUQ0ZAHjnlkBGQR045ZATkk5PEwc56BqLeRCE5ORnW1tYq662tbRAeHiZSKlXNapWDpbkpNv/xNwAgf97cMDczwfDu9XD8YiCa9luMA6duYvtvP6G6RzHRcsqhLQF55JRDRkAeOeWQEZBHTjlkBOSRUw4ZAXnklENGQD45SRyS+GAkLi4O165dQ968eeHi4qKy7cOHD9i5cye6du2a7vHx8fGIj49XWSfoG8PY2Fgr+RRf3IAgCEKadWLp1qIajl4IRGhYNABAT+/j319/nr6FRVtOAQD+vf8CVdyKotcP1XH+2kPRsgLSbsvPySGnHDIC8sgph4yAPHLKISMgj5xyyAjII6ccMgLyyZltnGddI6K31v3791G6dGnUqFEDZcuWRc2aNREaGqrcHh0dje7du2d4Dn9/f1hYWKgss2f6ZzublaUV9PX1ER4errI+MjIC1tY22T5/djnaW6F2lZJYv/+icl14VAwSE5MR9ChUZd97j16KOhuM1NsylRxyyiEjII+ccsgIyCOnHDIC8sgph4yAPHLKISMgn5wkDtE766NGjULZsmXx+vVr3Lt3D3ny5IGXlxeCg4OzfA4/Pz9ER0erLCNG+WU7m6GREUq7lMHlixdU1l++eBFu5d2zff7s6tLME68j3+HwuTvKdYlJybgW+BQlCtuq7Fu8cH4Eh0bpOqKS1NsylRxyyiEjII+ccsgIyCOnHDIC8sgph4yAPHLKISMgn5wkDtHLYC5evIgTJ07AxsYGNjY2OHDgAAYMGABvb2+cOnUKZmZmmZ7D2DhtyYu2ZoPp0q07xo4eCRdXV7i5uWPPrh0IDQ1Fm3bttfMAX0mhUKBr86rY8uffSE5OUdk2b8MJbJrZA+evP8SZq/dRv5oLGtVwRYNeC0RK+5FU2/JLcsgph4yAPHLKISMgj5xyyAjII6ccMgLyyCmHjIB8cmrFt1jak4NE76zHxcXBwEA1xpIlS6CnpwcfHx9s3bpVpGQfNfRthOg3UVi5bCnCwl6jWPESWLJ8JRwcCoiaq3aVknC0z4sN+y+n2Xbg1L/4Zdp2jOhRH7+N/AH3n75GhxGrcTHgkQhJP5FqW35JDjnlkBGQR045ZATkkVMOGQF55JRDRkAeOeWQEZBPTtI90edZr1y5Mn755Rd06dIlzbaff/4ZW7Zswdu3b5GcnKzRebU1sp7TtDHPek7T1jzrREREpHuSm2e92TKxIyjFHegndoRMiV6z3rJlS2zbtk3ttsWLF6NDhw74Rr+3iYiIiOj7o9CTziIDoo+s5xSOrGsPR9aJiIjkS3Ij681XiB1BKe73PmJHyJTELh8RERERfdN4g6lG5DH+T0RERET0HWJnnYiIiIhIolgGQ0RERES6I5MbO6WCrUVEREREJFHsrBMRERERSRTLYIiIiIhIdzgbjEY4sk5EREREJFEcWSciIiIinVFwZF0jHFknIiIiIpIodtaJiIiIiCSKZTBEREREpDMsg9EMR9aJiIiIiCSKnXUiIiIiIoliGQwRERER6Q6rYDTCkXUiIiIiIoliZ52IiIiISKJYBkNEREREOsPZYDTDzrrIoq4sFjtCphx77xQ7QpY8Wd5G7AiZ0tPjG5S2xCemiB0hS4wNpf8BZkRMgtgRsiSXkb7YETJlKoOMRCQv7KwTERERkc5wZF0z0h/yISIiIiL6TrGzTkREREQkUSyDISIiIiKdYRmMZjiyTkREREQkUeysExERERFJFMtgiIiIiEhnWAajGY6sExERERFJFDvrREREREQSxTIYIiIiItIdVsFohCPrREREREQSxZF1IiIiItIZ3mCqGY6sExERERFJFDvrREREREQSxTIYIiIiItIZlsFohiPrREREREQSxc46EREREZFEsQyGiIiIiHSGZTCa4ch6FuzYtgW+9WujkntZtG/TCtevXRU7klpi5qxawgabBlbHv3Ob4vXatvB1d1DZbmZsAP9O7giY0wRPl7fC+akN8WNNZ5V95nT1wD8zGuHp8lYIXNAMG37xQjE7c539DgCwc8c2tG3VDNWreqB6VQ907dQO58+d1WmGrOLzMvuSkpKwbPF8NG9UF95VyqNF43pYvWIJUlJSxI6mlpTacuv61ej3Y3s0rlUFrRr64NcRAxH89LFye1JSIlYunoueHVuikU9ltGlcG/4TxyA87LVOc964dhXDBvVHk3o+qOrugjOnTqhsFwQBq5YvRpN6PvCp6o5+P3XDo/8e6DRjeqR0vTMih5xyyAjIJyfpFjvrmThy+BBmzfBHr979sGP3flSo4IH+fXohNCRE7GgqxM6Zy9gAd569gd/m62q3T25fHrVd7dB/1d+oPvYIVhy/j+md3NGw/KdO/c2nURi49h9UH3sE7X47CwWAncNqQE+Hf4Hb2tril8HDsGX7bmzZvhuVq1TFkIED8N9DafznnUrs651VUs+5cd1q7N29AyNGj8OOvQfxy+Dh2LxhLXZu2yx2tDSk1pY3b1xF8x/aY/GaLZi9cCWSk5MxcmAfxMXFAgA+fPiAB/eC0KVHHyzfuAOTZszD8+CnGDf8F53mjIuLRfESJTFs9Di12zetX4Ntmzdg2OhxWLt5J6ytbTCw7094//69TnN+SWrXOz1yyCmHjIB8cpLuKQRBEMQOkRM+JGnnPJ3at0FpFxeMGz9Jua5FU1/Uql0Xg4YM086DaEFO5nTsvVOj/V+vbYtui87j8I1PbzBnJjfA71eeYe4fgcp1x8fXxYlbLzFz322153EpaIHTkxug8qiDeBKW+X+cT5a30ShnVvl4VcHgYSPQstUP2T6Xnp52/vDg8xKIT8z+6PeQX/oir7U1fp04Tblu1LCBMDExwaRps7J9fgAwNtTOmEhOtmVETEJ24+FNVCRaNfTBvOXr4OZeUe0+dwNvo3/3Dtj2+zHY2tlr/Bi5jPSzlbGquwtmzl0In1p1AXwcVW9S3wftOnZF1+4/AQASEhLQqI43BgwaipY/tNP4MUyzmTEVX+PaI4eMQM7mNJFY0bN1121iR1CK2NhB7AiZ4sh6BhITEhAUeAee1aqrrPes5oWbATdESpWWHHL+8yAcDco7wM7SFADgVSofnO3Mcfr2S7X75zLSR/vqTngaFoMXkXG6jKqUnJyMI4cPIi4uFuXcyouSQR05XG9AHjnLu3vg6t+X8fT/5Rv3793FzRvXUa26j8jJVMmhLd/HxAAA8uSxyGCfd1AoFMidW7flbekJefEcEeHhqOJZTbnOyMgI7h4VcetmgGi55HC9AXnklENGQD45SRwS+1tLWqLeRCE5ORnW1tYq662tbRAeHiZSqrTkkHPM1huY+2NF/Du3KRKTUpAiCBi6/ir+fhCusl/3Ws4Y36YczEwMcT/kLdrMOYPEZN3WDz+4fw/dOndAQkI8THPlwm/zF8PZuZhOM2REDtcbkEfOrt1/QkzMO7Rt0Rh6+vpISU5Gv58Ho4FvY7GjqZB6WwqCgKULZqOsWwU4ORdXu09CfDxWLZmPOg0awSx3bh0nVC8i/OP7T968Nirr81rb4GWoeKUHUr/eqeSQUw4ZAfnk1BreX6oRSXTWg4KCcPnyZXh6eqJUqVK4e/cuFixYgPj4eHTu3Bm1a9fO8Pj4+HjEx8errBP0jWFsbKyVfF/etSwIgiTvZJZyzl51i8PDOS86LziH5xGxqFoiH2Z2qYBX0XE4G/jphrPdl4Nx+s4r2FqaoH+DkljVzxNNpv+F+CTdddiLODlh++59ePfuLU4eP4bx40Zj9bpNkuqwA9K+3p+Tcs7jRw/h8ME/MMV/Noo6F8f9e0GYO9sfNvnyo0mzFmLHS0Oqbblw9jQ8engfC1dsULs9KSkRU8aNQIogYNAI9bXjYpJqu0o115fkkFMOGQH55CTdEr0M5siRIyhfvjyGDx8Od3d3HDlyBDVq1MDDhw8RHByMBg0a4K+//srwHP7+/rCwsFBZZs/0z3Y2K0sr6OvrIzxcdfQ3MjIC1tY26Ryle1LPaWKojzGtXTF++00cuxmKwOfRWPvXQ+z/5xn6Nyipsu+7uEQ8fh2Dy/fD0XPpJRSzz4NGHgV0mtfQ0AiOjoVRpkxZDBw8DCVKlMK2zRt1miEjUr/eqeSQc+G8OejW/SfUb9gYxYqXQKMmzdGhczdsWLtS7GgqpNyWC+dMx8VzpzF36Rrks7VLsz0pKRGTxgxHaMgLzF60UjKj6gBgbfOx7SIiVEcuoyIjkDevtbpDdELK1/tzcsgph4yAfHKSOETvrE+ePBkjRoxAREQE1q1bh44dO6JXr144fvw4Tpw4gZEjR2LGjBkZnsPPzw/R0dEqy4hRftnOZmhkhNIuZXD54gWV9ZcvXoRbefdsn19bpJ7TQF8BIwN9pHxxL3NKipDpTC8KAEYG2rlh6+sJSEjI/g142iL1651KDjk/fIiDQk/1bVBfT19yUzdKsS0FQcCC2dNw7vRJ/LZkDewdCqbZJ7Wj/uJZMOYsXgULC0vdB82AQ4GCsLaxwT+XLynXJSYm4Ma1qygr4n0qUrze6sghpxwyAvLJqS0KhUIyixyIXgZz584dbNz4cdSybdu26NKlC1q3bq3c3qFDB6xZsybDcxgbpy150dZsMF26dcfY0SPh4uoKNzd37Nm1A6GhoWjTrr12HkBLxM5pZmwAp/yfRswcbXLDtZAlot4n4EVkLC7cfY0JbdzwISEZzyNi4VkyH9pUK4wJ228CAArnM0PzSoVw+s4rRLyLh72VKX7xLYUPick4+W+oTn4HAFi0YC68qteAnZ0d3r9/j6NHDuHqlX+wZNkqnWXICrGvd1ZJPad3jVpYv3oF7OzsUdS5OO7dC8TWzevRtHkrsaOlIbW2XDB7Gk4ePYSpsxcgl5kZIiM+jgiameWGsYkJkpOSMHH0UDy4F4Tpv32cuz51H/M8FjA0NNRJztjY93j+LFj5c8iLF7h/Lwh58ljAzt4B7Tp2xYY1K1HIsTAKORbGhjUrYWJigvq+TXSSLz1Su97pkUNOOWQE5JOTdE/0zvrn9PT0YGJiAktLS+U6c3NzREdHi5apoW8jRL+JwsplSxEW9hrFipfAkuUr4eCg29KMzIid062IFfaPqqX8eUqH8gCA7ecfY+DaK+iz/DLG/lAWy3pXgaWZEZ5HxMJ/722sP/0fAOBDYjKqlsiHPvVKwMLMEGFv43H5XhgaT/8L4e/i1T1kjoiIiMC4MSMRHhaG3ObmKF68JJYsW4Wq1bx0liErxL7eWSX1nMNHj8OKJQswy38yoiIjYZMvP1q2bouf+vQXO1oaUmvLA3t2AACG9Ouhsn7kr1PQsEkLhL1+hYvnTgMAenVRnfZ07tK1KO9RSRcxERR4BwN6/aj8ecFvMwEAjZq2wPjJ09Hlx56Ij/+A2f6T8e7tW5RxLYcFy1bDzMxMJ/nSI7XrnR455JRDRkA+OUn3RJ9n3c3NDTNnzkTDhg0BALdv30apUqVgYPDx74jz58+ja9euePTokUbn1dbIOmk+z7pYcmqedW3S1jzrpJ151nVBW/Os5yRtzLOuC9mdZ10XtDXPOpE2SW2e9Xzdd4gdQSlsnebfp6Brol++fv36ITk5Wfmzq6uryvbDhw9nOhsMEREREdG3SPTOet++fTPcPm3atAy3ExEREZF8yOXGTqmQ/uezRERERETfKXbWiYiIiIgkSvQyGCIiIiL6jrAKRiMcWSciIiIikih21omIiIiIsmjp0qVwcnKCiYkJPDw8cO7cuQz337JlC9zc3JArVy7Y29uje/fuiIiIyPLjsbNORERERDqjUCgks2hqx44dGDx4MMaOHYsbN27A29sbvr6+CA4OVrt/6vcF9ezZE3fu3MGuXbtw5coV/PTTT1l+THbWiYiIiIiyYO7cuejZsyd++uknlC5dGvPnz0ehQoWwbNkytftfvnwZRYoUwcCBA+Hk5ITq1aujT58+uHr1apYfk511IiIiIvouxcfH4+3btypLfHy82n0TEhJw7do11K9fX2V9/fr1cfHiRbXHVKtWDc+fP8ehQ4cgCAJevXqF3bt3o3HjxlnOyM46EREREemM2KUvny/+/v6wsLBQWfz9/dXmDg8PR3JyMmxtbVXW29ra4uXLl2qPqVatGrZs2YJ27drByMgIdnZ2sLS0xKJFi7LcXuysExEREdF3yc/PD9HR0SqLn59fhsd8WesuCEK69e+BgYEYOHAgxo8fj2vXruHIkSN4/Pgx+vbtm+WMnGediIiIiHTma27szCnGxsYwNjbO0r42NjbQ19dPM4r++vXrNKPtqfz9/eHl5YURI0YAAMqVKwczMzN4e3tj6tSpsLe3z/RxObJORERERJQJIyMjeHh44Pjx4yrrjx8/jmrVqqk9JjY2Fnp6qt1tfX19AB9H5LOCnXUiIiIioiwYOnQoVq9ejbVr1yIoKAhDhgxBcHCwsqzFz88PXbt2Ve7ftGlT7N27F8uWLcOjR49w4cIFDBw4EJUrV4aDg0OWHpNlMERERESkM1Iqg9FUu3btEBERgcmTJyM0NBSurq44dOgQChcuDAAIDQ1VmXP9xx9/xLt377B48WIMGzYMlpaWqF27NmbOnJnlx1QIWR2Dl5kPSWIn+HY49t4pdoQsebK8jdgRMqWnJ983KKmJT0wRO0KWGBtK/wPMiJgEsSNkSS4jfbEjZMpUBhnp+2MisaFZhz57xY6gFLKildgRMiX9/0WIiIiIiL5TEvtbi4iIiIi+afyQWSMcWSciIiIikiiOrFOm/p3XUuwIWWLTYZ3YETIVvr272BGyRCGDYQ851ILLhbnUClrTYWTAa05E3x95vEMTERER0TdBzrPBiIHDFEREREREEsWRdSIiIiLSGY6sa4Yj60REREREEsXOOhERERGRRLEMhoiIiIh0hmUwmuHIOhERERGRRLGzTkREREQkUSyDISIiIiLdYRWMRjiyTkREREQkUeysExERERFJFMtgiIiIiEhnOBuMZjiyTkREREQkURxZJyIiIiKd4ci6ZjiyTkREREQkUeysExERERFJFMtgiIiIiEhnWAajGY6sExERERFJFDvrWbBj2xb41q+NSu5l0b5NK1y/dlXsSGpJLefN61cxeugAtGpUCz6VXXHu9Mk0+zx5/B/8hv2MRrWqomHNyujXoyNevQzNsUxeLrbY7VcX/61qj9g9PdC0smOafUoWsMCu0XURurEzXm3ugtP+TVDQxky5/cgkX8Tu6aGybBhSM8cyf2nNqhXo1O4HeFWugNo1qmHIwAF48viRzh4/q65dvYKBA/qiXq3qKO9aEn+dPCF2pHRJ7bWTHqnnfP3qFX71G4m6NaqiehV3dGzbEkGBd8SOpZbU2xKQR0ZAHjnlkBGQT07SLXbWM3Hk8CHMmuGPXr37Ycfu/ahQwQP9+/RCaEiI2NFUSDFn3Ic4FCteEoNHjFG7/cXzYPzSqyscCzth/vJ1WLtlD7r26AMjI6Mcy2RmbIhbTyIxdPUltdudbM1xYlpj3HvxBg0nHEKVYfsxY1cA4hOSVfZbe/wenHpuUy6/rLiQY5m/dP3qFbTr0BEbt+7AspVrkZyUhH69f0JcbKzOMmRFXFwsSpQsidFjxosdJUNSfO2oI/Wcb99G46cfO8LAwAALlqzEzr1/YvCwkTA3Nxc7WhpSb0tAHhkBeeSUQ0ZAPjm1QaFQSGaRA4UgCILYIXLChyTtnKdT+zYo7eKCceMnKde1aOqLWrXrYtCQYdp5EC3IyZxv3idmNx58Krti6qwF8K5ZR7lu0tjh0DcwwLhJM7J9fgAo2mOTRvvH7umBdjNP4I9/gpXrNgypicTkFPy08Gy6xx2Z5It/n0Ri5Lq/Nc4Yvr27xsdkJjIyEnVqVMPq9ZvgUbGSVs6pgHbfwMq7lsTcBUtQu05drZ1TW++xfI0DCUkp2Y2HRfN/w78BN7Bq/eZsnys9RgbaGV+SwzWXQ0ZAHjnlkBHI2ZwmErtD0WnwQbEjKD2e31jsCJmS5Mi6VP5+SExIQFDgHXhWq66y3rOaF24G3BApVVpyyfm5lJQUXLpwFoUci2D4L73RvEEN9O3eQW2pjK4oFEBDj0J4GBKN33+tjydrO+CMf1O1pTLtvIsieF1HXJ3fEtO7VkJuEd8JY2LeAQAsLCxEyyBXcnntyCHnuTOnULpMGYwePhj1a3qhU9tW2Ldnp9ix0pBDW8ohIyCPnHLICMgnp9YoJLTIgCQ768bGxggKChI7BqLeRCE5ORnW1tYq662tbRAeHiZSqrTkkvNzUZGRiIuNxdYNa1DZszrmLFoJ75p18OuowQi4fkWUTPktTGFuaohhLcvh+I0XaDb5KA788xTbRtRBdRc75X47zv2HH+efQcPxhzBjVwBaVC2CbSPrZHDmnCMIAn6bNQPuFTxQrHgJUTLImVxeO3LI+eL5M+zZuR2FHAtj0bJVaN2mHX6bOR0H/9gvdjQVcmhLOWQE5JFTDhkB+eQkcYj6wcjQoUPVrk9OTsaMGTOUT9q5c+dmeJ74+HjEx8errBP0jWFsbKyVnF/WNAmCIMk6J7nkBABB+Pixu1eNWmjbsSsAoHiJUrj9bwB+37sT5Stop5xDE3r/b6o/rwRj8Z8fb4r790kkqpbMj58alML5wJcAgHUn7iuPCXz2Bv+FvsWF2c1R3skaAY8jdJp5xrQpeHD/HtZt3KrTx/3WyOW1I+WcKSkCSpcpgwEDhwAASpZ2waP/HmLPzu1o3LSFuOHUkHJbppJDRkAeOeWQEZBPTtItUUfW58+fj1OnTuHGjRsqiyAICAoKwo0bNxAQEJDpefz9/WFhYaGyzJ7pn+18VpZW0NfXR3h4uMr6yMgIWFvbZPv82iKXnJ+zsLSCvr4Bijg5q6wvXKQoXufgbDAZCX8Xj8SkFNx99kZl/d3nb1Dos9lgvnTjUQQSEpPhbJ8nhxOqmjF9Cs6c+gur1m6ErZ1d5gdQGnJ57cghp00+GxQtqvp6LlK0KF6GivN6To8c2lIOGQF55JRDRkA+ObVF7JtK5XaDqaid9WnTpiE6Ohq//vorTp06pVz09fWxfv16nDp1Cn/99Vem5/Hz80N0dLTKMmKUX7bzGRoZobRLGVy+qDrTx+WLF+FW3j3b59cWueT8nKGhIUq5lEFw8GOV9c+Cn8DWzkGUTIlJKbj2MAzFC6jWfhd3sEBwWEy6x7kUsoSRoT5evtHNbCyCIGDGtMn468RxrFi7HgUKFtTJ436L5PLakUNOt/IV8PTJE5V1wU+fwM5BnNdzeuTQlnLICMgjpxwyAvLJSeIQtQzGz88PdevWRefOndG0aVP4+/vD0NBQ4/MYG6ctedHWbDBdunXH2NEj4eLqCjc3d+zZtQOhoaFo0669dh5AS6SYMzY2Fi+ef5ppJTTkBR7cv4s8eSxga2eP9p27Y9LY4XBzrwh3j8r459J5XDp/BvOXrcuxTGYmBnC2+zQCXji/OcoVyYvImHg8D3+P+b/fxsahNXEh8CXO3A5FffeCaFSxEBqMPwzg49SO7Ws44+j1Zwh/G4/ShSzh360yAh6F49Ld1zmW+3P+Uyfj8KE/MW/hEpiZmSnrGXPnNoeJiYlOMmRFbOx7BAd/uv4vXjzH3btBsLCwgL29dDpwUnztqCP1nB06d0PPbh2xbvUK1K3fEHdu38K+3bsw5rOZLaRC6m0JyCMjII+ccsgIyCcn6Z4kpm6MiYnBgAEDEBAQgM2bN8PDwwMBAQFwcXH56nNqq7MOfPySgvVr1yAs7DWKFS+BEaP8tDZFnjblVM6vnbrxxrV/MLhfjzTrGzZuDr8J0wAABw/sxZYNqxH2+hUcHYuge+8BqO5T+6seLytTN3qXscPRyY3SrN906gH6LD4HAOhauziGtyqHAnnN8CAkGlN33MCfVz52OgtYm2HtoBpwcbRCbhNDPA9/jyPXn2H6zhuIiknI9PG1MXWju2sptesnTZ2OZi1aZfv8gHambrzyz9/o1aNrmvVNm7fElGnZn65Tm59efu+vcW1M3Qh8nBFmycJ5eBb8FA4FCqJjl25o2bqtVs4NaG/qRkAe11wOGQF55JRDRiDnckpt6kbnYYfFjqD032++YkfIlCQ666m2b9+OwYMHIywsDLdu3ZJMZ/17p4151nVB03nWxZAT86znBG3Ps54TZFJqKAva6qznNG121om+J+ysp08OnXVJXb727dujevXquHbtGgoXLix2HCIiIiIiUUmqsw4ABQsWREHeMEdERET0TeIno5rhZ4pERERERBIluZF1IiIiIvp2yWV+c6ngyDoRERERkUSxs05EREREJFEsgyEiIiIinWEVjGY4sk5EREREJFHsrBMRERERSRTLYIiIiIhIZzgbjGY4sk5EREREJFHsrBMRERERSRTLYIiIiIhIZ1gFoxmOrBMRERERSRRH1omIiIhIZ/T0OLSuCY6sExERERFJFDvrREREREQSxTIYIiIiItIZ3mCqGY6sExERERFJFDvrREREREQSxTIYkYW/SxA7QqbymMrjaXJ/dSexI2Sq/+5bYkfIksWtyoodIVNJKSliR8gSE0N9sSNkSi4fSSclC2JHyJSBvkwaUwZevvkgdoRM2VmaiB1BlhRyedORCI6sExERERFJFDvrREREREQSJY/6BiIiIiL6JrAKRjMcWSciIiIikiiOrBMRERGRzvAGU81wZJ2IiIiISKLYWSciIiIikiiWwRARERGRzrAMRjMcWSciIiIikih21omIiIiIJIplMERERESkM6yC0QxH1omIiIiIJIoj60RERESkM7zBVDMcWSciIiIikih21omIiIiIJIplMERERESkM6yC0QxH1omIiIiIJIqddSIiIiIiiWIZTBbs2LYF69etQXhYGJyLFcfI0WNQwaOiaHm2bliN86dPIPjpYxgbm8ClrBt6DxiCQoWd1O4/d8YkHNy/G/0Hj0Tr9l10nPaTpKQkrFq+GEcO/omIiHBY2+RDk2Yt0LN3P+jpifN348e2PPn/tjSGS9ny6D1gsEpbzpw8DscOHVA5rnSZsli8ZkuOZCqRzwyNSudDYStTWOUyxMKzT3D9xVvl9hautqhS2AJ5cxkhKSUFTyLjsOffl3gUEafcx8c5LzwLW6JwXlOYGuqj/+7biE1MyZG86VmxdBFWLl+iss7a2gbHTp3XaY4v3bh2FZs3rMXdoDsIDwvDrLkL4VO7rnK7IAhYvXwJ9u/dhXdv36KMazmM8BuHosWKi5j6I6m9F33p9atXWDT/N1w8fxYf4uNRuHAR/DppKkq7lBE7mpJUn5fqSP16p5JSzj/27cTBfTvxKjQEAFDYyRmduvdBJc/qAD6+vjevXY5Dv+9BzLu3KFWmLAYM9UORosVEyfslKbVlTuJsMJrhyHomjhw+hFkz/NGrdz/s2L0fFSp4oH+fXggNCREt0783rqJZ6/ZYvHoLZi1cieTkZIwc1AdxcbFp9j1/5iTu3rkF63z5RUiqauO61dizawdG+I3Dzn0HMXDIcGzesBY7tm0WLdOnttz8WVv2TdOWlap6YdfBv5TL9LlLcyyTsYEegqPisPnaC7XbX76Lx6arIRh36D6mHf8P4e8TMbxmUZgb66uc41boO/x553WO5cwKZ+fiOPrXOeWyY8+BzA/KYXFxsSheoiSGjx6ndvum9WuwdfMGDB89Duu27EReGxv80u8nvH//XsdJVUnxvehzb99Go2e3jjAwMMCCpSuxa9+fGDxsJMzNzcWOloYUn5dfkvr1TiW1nPny5UePvoOwaM1WLFqzFW4elTFx9CA8efQQALBzyzrs3b4JA4aOxqI1W2CV1xp+g/siVuTXNyC9tiTpYGc9E5s2rEPL1q3R6oc2KOrsjJF+Y2Fnb4edO7aJlmnG/OVo2KQFihQtBufiJTFy3BS8fhmKB3cDVfYLe/0Ki+ZMx5hJM2CgL/6HKLduBsCnZm1Ur1ETDgUKoE69Bqji6YWgO7dFy/SxLZt/1paT1baloZER8lrbKJc8FhY5lulW6DvsvfUK156/Vbv98tM3CHwVg7D3CQh5G49t10OQy0gfBS1NlfscuxeOg0Fh+C8i7R9wuqRvoA8bm3zKxSpvXlHzAEC16jXQ9+dBqFWnXpptgiBg+5aN6P5TH9SqUw/OxYpjwhR/fIj7gKOH/xQh7SdSfC/63Ia1q2Fra48JU6bDtWw5OBQogMpVPVGwkKPY0dKQ4vPyS1K/3qmklrNq9ZqoXM0bBR2LoKBjEXTv8wtMTHPh7p1/IQgC9u/cgvbdfkL1mnVRpGhxDB83FfHxH3Dq+CFR8n5Oam1J0sHOegYSExIQFHgHntWqq6z3rOaFmwE3REqV1vuYGACAeZ5PHciUlBTMmDQGbTt3l8zHe27uHrjyz2U8ffIYAHD/3l3cvHEdXt4+Iif7RF1bAsDN61fR2tcHXds0xW/TJyIqMkKMeGno6ylQs1hexCYk41lUXOYH6Fjw06doUMcbTRvWgd/IoXj+/JnYkTIU8uI5IsLDUcWzmnKdkZER3CtWxK2AANFyyeG96OzpUyhdpgxGDRuMej5e6Ni2Ffbt3il2LLWk/ryUw/UGpJ8zOTkZp08cRvyHOJR2dcPLkBeIjAiHR2VP5T5GRkYoW94DgbduiphU+m2pbQqFdBY5EH+4VcKi3kQhOTkZ1tbWKuutrW0QHh4mUipVgiBg2YLZcHWrACfnTzW12zethb6+Plq17SRiOlXdevyEmJh3aNOiMfT09ZGSnIx+vwxGA9/GYkcD8Hlbuqu0ZWXP6vCpUx+2dvYIDXmB9SuXYPjPP2HZ+h0wMjISJaubgzn6VXOEkYEeouOSMPvUI8QkJIuSJT2uZd0wedoMOBYugsjICKxZuQw9unTAzn1/wNLSSux4akWEhwMA8ua1UVmfN68NXoaK91G0HN6LXjx/hj07t6NTlx/R/afeuHP7FubMnA5DIyM0adZC7HhKcnheyuF6A9LN+fi/BxjcpwsSEhJgapoL46fPQ2EnZ9y5FQAAsLJSzWuV1xqvX4pbaiLVtiRpkFxnPSoqChs2bMCDBw9gb2+Pbt26oVChQhkeEx8fj/j4eJV1gr4xjI2NtZLpyxshBEGQzM0RC+dMw6OH97Fg5Qbluvt372Dvjs1YvmGnZHICwPEjh3D44B+Y6j8bRYsVx/27QZg72x/58uWXxH/mC+dMx6OHD7Bg5XqV9bXqNVT+28m5OEqWLoOOLRrg7wtn4V2rLsQQ9CoG4488gLmxAXyc86K/V2FMPvYA7+Kl02H38q6h8nO5cuXRvHF9/HlgPzp37S5SqqxJ87qRyGteyu9FKSkCXMqUwYBBQwAApUq74NF/D7Fn53ZJvL5Tyel5KeXr/Tmp5SzoWARL1+/E+3fvcP70CcyZ9itmL17zaQc1eaUyxCq1tswp3+LvlJNEL4NxcHBARMTHkoLHjx/DxcUFM2fOxIMHD7BixQqULVsWd+/ezfAc/v7+sLCwUFlmz/TPdjYrSyvo6+sj/P+jbakiIyNgbW2TzlG6s2jOdFw6dxq/LV2DfPntlOtvBVzHm6hIdGhRH/W8yqOeV3m8ehmC5QvnoGOLBqLlXTBvDrr1+An1fRujWPESaNS0OTp07ob1a1aKlinVojn+/2/L1SptqY61TT7Y2jng+bNg3YRTIyFZwOuYBPwXEYu1/zxHsiCghrP06m4/Z5orF4oVL4Hgp0/FjpIua5uPr+uICNWRrMioCOTNa63uEJ2Q+nsRANjks4FTUWeVdU5ORfHyZahIibJGis9LOVxvQLo5DQ0NUaCgI0qULoMe/QbBqVgJ7N+1RfmJWVSkat43UZFpRtt1TaptSdIgemf95cuXSE7+OBo4ZswYlCpVCv/99x+OHTuGhw8fwtvbG7/++muG5/Dz80N0dLTKMmKUX7azGRoZobRLGVy+eEFl/eWLF+FW3j3b5/9agiBg4ZxpOHfmJOYsXgN7h4Iq2+v6NsWqzXuwcuMu5WKdLz/advoRMxcsFyk1EP8hLs0UjXr6+hBSdDul4Oc+tuX0/7fl6jRtqU509Bu8fv1S2bGTAgUAQ5Gmv8yqhIQEPH70H2zy5RM7SrocChSEtY0N/rl0SbkuMTEBN65eRdny5UXLJdX3os+5la+Ap0+eqKx7+vQJ7O0dxAmURVJ8XsrhegPyyQlBQGJCIuwcCiCvtQ2uX7ms3JSYmIhbAdfgUtZNxIAyaksShaTKYP7++2+sXr0auXLlAgAYGxtj3Lhx+OGHHzI8ztg4bcnLhyTtZOrSrTvGjh4JF1dXuLm5Y8+uHQgNDUWbdu218wBfYeHsaTh57BCmzFqAXGZmiIz4+Je4mVluGJuYwMLCEhYWlirHGOgbIK+1TbpzsetCdZ9aWLdqBezs7FHUuTju3Q3E1k3r0ax5K9EyfWzLw+m2ZVxsLDasXgrvWvVgbf2xbnnN8oWwsLBEdZ86OZLJ2EAPtrk/1cLb5DaCo6UJYhKSEROfhKZlbBHw4i3exCUit7EBahe3Rt5chvgn+I3yGAsTA1iYGCB/7o+vi4KWJviQmIKI2ES811Ft+7w5M1GjZi3Y2Tkoa4Pfv49BU5FLImJj3+N58KdPRUJevMD9u0HIY2EBO3sHtO/UFevXrEShwoVRyLEw1q9eCRNTEzTwbSJiamm+F32uY5du6NG1I9auWoF6DRrizq1b2Ld7F8ZOmCR2NBVSfV5+SerXO5XUcq5dvhCVqlZHPltbxMXG4vSJI/j3xlVM/W0pFAoFWrTthO0b16BAQUcUKOSIbRvXwNjYBLXqNRIl7+ek1pY5iVUwmpFEZz21dik+Ph62trYq22xtbREWJt7NFQ19GyH6TRRWLluKsLDXKFa8BJYsXwkHhwKiZTqwdwcAYGj/HirrR4ybgoZNWoiQKGtGjB6H5UsWYOb0yYiKjIRNvvxo9UNb/NSnv2iZDuz9OFuF+rZsDj09PTz+7yGOH/4DMe/eIa9NPpSvUAm/Tp2NXGZmOZLJKa8pRtf5VE7QscLHkcnzjyKx4coL2OcxRnWnwshtrI+Y+GQ8jozF9BP/IeTtp/s2ahWzRouyn15LY+p+nBFo9eVnOP84Kkdyf+n161cYM2oY3kS9gVVeK5Qt64b1m3fAXsTXDgAE3bmD/r1+VP48/7eZAIDGTVtg/JTp6PJjT8R/+IBZ0yd//FKksuWwcNlqmOXQ9c4qKb4Xfa6Ma1nMmbcQixfMw+oVS+FQoCCGjRwN38ZNxY6mQqrPyy9J/XqnklrON1ERmD1lLCIjwpDLLDecipXA1N+WKmeAadupOxLi47H4t+l49+4tSrmUhf/8ZTn2fq4JqbUlSYdCEARBzAB6enpwdXWFgYEBHjx4gI0bN6Jly5bK7WfPnkXHjh3x/Plzjc6rrZH1nBb+LkHsCJnKYyqJv+ky9TYuUewImRp35J7YEbJkcauyYkfIVJKI5VOaMDHUz3wnkSUmy6MtFZD+cJyBvvQzysXLNx/EjpApO0sTsSNkiYnE/huvPP202BGU/hlTU+wImRL98k2YMEHl59QSmFR//PEHvL29dRmJiIiIiHIIZ4PRjOQ661+aPXu2jpIQEREREUmLtKePICIiIiL6jok+sk5ERERE3w9WwWiGI+tERERERBLFkXUiIiIi0hneYKoZjqwTEREREUkUO+tERERERBLFMhgiIiIi0hlWwWiGI+tERERERBLFzjoRERERkUSxDIaIiIiIdIazwWiGI+tERERERBLFkXUiIiIi0hkOrGuGI+tERERERBLFzjoRERERkUSxDIaIiIiIdIY3mGqGI+tERERERBLFzjoRERERkUSxDIaIiIiIdIZlMJphZ11koVFxYkfIlI25hdgRssTUSF/sCJma2bi02BGyJPDFW7EjZKqcozyel3Jw6VGE2BGyxLtYPrEjkA4Z6PPDfyKAZTBERERERJLFkXUiIiIi0hlWwWiGI+tERERERBLFkXUiIiIi0hneYKoZjqwTEREREUkUO+tERERERBLFMhgiIiIi0hlWwWiGI+tERERERBLFzjoRERERkUSxDIaIiIiIdIazwWiGI+tERERERBLFzjoRERERkUSxDIaIiIiIdIZVMJrhyDoRERERkURxZJ2IiIiIdEaPQ+sa4cg6EREREZFEsbNORERERCRRLIMhIiIiIp1hFYxm2FnPgh3btmD9ujUIDwuDc7HiGDl6DCp4VBQtz57NK7Fvy2qVdRZWebFk6xEAQGffymqPa9/zFzT5oUuO58uI1NryxrWr2LpxLe4FBSI8PAz+vy2ET606avedOXUift+7C4OGjUK7Tl11mjPg+lVs37QO9+4GIiI8DNNmL4B3zU85IyPCsXzRPFz5+yJi3r2Dm7sHBo0Yg0KOhXWWcW86z8vF/39efoiLxY51S3Dt4hnEvItGPlt71GvWFnWb/KCzjOmR2vMyPVLKOaHXD4gMe5lmvbdvS7TtMwwBl87gwtHf8ey/e3j/Lhqj5q5DwaLFRUiq6trVK9iwbg2CAm8jLCwMcxcsQe06dcWOpZaUrndGpJRz64bVOH/6BIKfPoaxsQlcyrqh94AhKFTYSe3+c2dMwsH9u9F/8Ei0bi/u/4+AtNqSpIOd9UwcOXwIs2b4Y+yvE1DevQJ279yO/n16Yd+Bg7B3cBAtV8HCRTF6+mLlz3p6+sp/L95ySGXfm1cvYfX8qajsVVtn+dSRYlt++BCHYiVKonGzlhgzYnC6+505dRKBt/+FTb78ugv3mQ9xcXAuURK+TVvg11FDVLYJgoCxIwZB38AA0+cshJlZbuzYuhFDB/yEjTt/h6lpLp3lLJDB83LLynkIvHkN/UZOgo2tPW5d+xsblsyClXU+eHj66Czjl6T4vFRHajmHz1kFISVF+XNI8CMsmTAE7tVqAQASPsShaOmycPeqhW1LZuo8X3ri4mJRomRJNG/RCsOG/CJ2nHRJ7XqnR2o5/71xFc1at0cpF1ckJydjzfKFGDmoD9Zu25/mvfD8mZO4e+cWrEV6X/+S1NqSpIM165nYtGEdWrZujVY/tEFRZ2eM9BsLO3s77NyxTdRcevr6sMxro1zyWFopt32+3jKvDa5fPoPS5TyQ376AiIml2ZaeXt7oM2AQatapl+4+Ya9fYe7MaZgwbRYMDMT5+7aqlzd69RsIn9ppcz4Pfoo7t25i2KhfUbpMWTgWccLQUeMQFxeLk0cPqTlbztHP4Hn5IOgWvOs2RulyHshn64DajVrCsWhxPH4QpNOMX5Li81IdqeU0t7BCHitr5XLnykXY2BVAMVd3AEDlWg3h2647SpaT1qhgdW8f/DxwCOrUqy92lAxJ7XqnR2o5Z8xfjoZNWqBI0WJwLl4SI8dNweuXoXhwN1Blv7DXr7BoznSMmTQDBvrSGLeUWlvmJIVCIZlFDthZz0BiQgKCAu/As1p1lfWe1bxwM+CGSKk+evXiGX7u1AhDfmyOxf5j8Tr0hdr9oqMiEPDPBdRs0EzHCVVJuS0zkpKSgknjRqNj1+4o6lxM7DhqJSQmAACMjI2U6/T19WFgYIh/ddy2L188wy/pPC9LlnHD9ctnERn+GoIgIPDmVbx8EYyyFarqNOPn5PK8lHrOpMREXDlzDFXrNJbNf35SJvXrnUoOOd/HxAAAzPNYKNelpKRgxqQxaNu5O4oUlcb7uhzaksQjjT8nJSrqTRSSk5NhbW2tst7a2gbh4WEipQKKlXRFn+ETYV/AEdFvIrF/21pMGtYTM5Zvh3keS5V9z504CBNTM1T0qiVO2P+TaltmZvP6NdA3MEDbDp3FjpKuwkWcYGfvgJVLFmC433iYmObCji0bEBkRjogI3bWtc0lX9B0+EXb/f17+vm0tJg/rCf//Py+79B2ONQumYVCXJtDX14dCoYeeg8eipGt5nWX8klyel1LP+e/fZxH3PgZV6zQSO8o3QerXO5XUcwqCgGULZsPVrQKcnD/dL7F901ro6+ujVdtOIqZTJfW2JHGJ3lm/ceMGLC0t4eT08eaPzZs3Y9myZQgODkbhwoXx888/o3379hmeIz4+HvHx8SrrBH1jGBsbayXjlyNFgiCIOnrkVqma8t+FABQrXRbDerTEuRMH0aiV6pvPmWN/oFqtBjAy0k5bZJfU2jIjdwPvYOe2TVi3dbdkMwKAgYEhpsych5lTxqNxHS/o6+vDo1JVVKnmrdMc6p6Xw3u0xPkTB+HbqhOO/r4DD+/expAJv8HG1g73bt3AhiWzYJnXBq7u6m+K1hW5PC+lmvPSiYNwqVAFFnltxI7yTZHq9f6SVHMunDMNjx7ex4KVG5Tr7t+9g707NmP5hp2SyPglqbaltul9e79SjhK9DKZnz5548uQJAGD16tXo3bs3KlasiLFjx6JSpUro1asX1q5dm+E5/P39YWFhobLMnumf7WxWllbQ19dHeHi4yvrIyAhYW0vnPyUTE1MUKlIMr148U1l/9/YNhD5/ipoNm4uU7BO5tOXnbt64hqjISLRqVBfelcrBu1I5vAwNwaJ5s9Gqcfo17mIoWboM1m7dg0OnLmHf4VOYs2gF3ka/gb2DePcpmJiYomCRYnj54hkS4j9g14al6NR7MCpU9YajU3HUa9YWVWrUxaE9m0XLKJfnpZRzRr5+iXv/XoVnvaai5viWSPl6f07KORfNmY5L507jt6VrkC+/nXL9rYDreBMViQ4t6qOeV3nU8yqPVy9DsHzhHHRs0UC0vFJuSxKf6J31e/fuwdnZGQCwdOlSzJ8/HwsWLEDfvn0xb948rFixAr/99luG5/Dz80N0dLTKMmKUX7azGRoZobRLGVy+eEFl/eWLF+FW3j3b59eWxIQEvAh+AssvRrXOHD0Ap+KlULhoCZGSfSKXtvxcw8bNsHHHPqzftke52OTLj45du2PekpVix1Mrd25zWFrlxbPgp7gXdAfVfcQrf0pMSEDI/5+XyUlJSE5KgkKh+pajp6cPIUUQKaF8npdSznn55EGYW1ihTEVPUXN8S6R8vT8nxZyCIGDhnGk4d+Yk5ixeA3uHgirb6/o2xarNe7By4y7lYp0vP9p2+hEzFywXJTMgzbbMSWLfVJrdG0yXLl0KJycnmJiYwMPDA+fOnctw//j4eIwdOxaFCxeGsbExnJ2dMx2I/pzoZTCmpqYICwuDo6MjXrx4gSpVqqhsr1KlCh4/fpzhOYyN05a8fEjSTr4u3bpj7OiRcHF1hZubO/bs2oHQ0FC0aZdxaU5O2rpqAdyreMM6vy3evonC79vWIi72PbzrNlbuE/s+Bv+cO4mOvQaJlvNLUmzL2Nj3eP4sWPlz6IvnuH8vCHnyWMDO3gEWlpYq+xsYGMDa2gaFi6ifszfncsbixec5Q17gwb27yGNhAVs7e5w6cRSWVlawtbXHf/89wKLfZqC6T21Uruqls4wZPS9NzXKjVNkK2LZmIYyMjWGd3w53b93A+ZOHRH+OSvF5qY4Uc6akpODyX4dQuVZD6H8xo8b7d28RFfYK0ZEfRwpfhXx8/uaxyos8VtZpzqUrsbHvERz86bX04sVz3L0bBAsLC9jbS2d6PCleb3WklnPh7Gk4eewQpsxagFxmZoiM+Pj8MzPLDWMTE1hYWMLCwlLlGAN9A+S1tkl3LnZdkVpbkno7duzA4MGDsXTpUnh5eWHFihXw9fVFYGAgHB0d1R7Ttm1bvHr1CmvWrEGxYsXw+vVrJCVlvaMqemfd19cXy5Ytw+rVq+Hj44Pdu3fDzc1NuX3nzp0oVky8u7Ub+jZC9JsorFy2FGFhr1GseAksWb4SDiKWF0SGv8aSmePw7u0b5LGwQrFSrpg0bw1sbO2V+1w+cxwCBHjWFO9jvS9JsS3vBt7Bz727K39eOHcWAKBR0+YYN2m6WLHSuBd0G4P69lD+vHjex5wNGzfHmInTEBEehsXzZiEqMgLWNvnQoFEzdPupr04zRoa/xtLPnpfOpVwx8bPn5YDRU7Fz/VIsmzUeMe/ewia/Hdp064s6jVvrNOeXpPi8VEeKOe/dvIqosFfwrNM4zbZb/5zHlkWfXkPr50wAAPi2645GHXrqLOOX7ty+jV49Pn2p2W+zPpZMNm3eElOmzRArVhpSvN7qSC3ngb07AABD+/dQWT9i3BQ0bNJChERZJ7W2JPXmzp2Lnj174qeffgIAzJ8/H0ePHsWyZcvg75+2BPvIkSM4c+YMHj16hLx58wIAihQpotFjKgRBEO8zaAAhISHw8vKCo6MjKlasiGXLlsHDwwOlS5fGvXv3cPnyZezbtw+NGmk2y4C2RtZz2q3gaLEjZKqso0XmO0nA+3jpX/SkZFFfbln2NDxW7AiZKieT56UcnH0gj9kmvIvlEztCpr7BewFFE/4uQewImbIxN8p8JwkwEX1oVlXjFf+IHUFp749uaSYpUVexAQAJCQnIlSsXdu3ahZYtWyrXDxo0CAEBAThz5kyaY/r374/79++jYsWK2LRpE8zMzNCsWTNMmTIFpqamWcooes26g4MDbty4AU9PTxw5cgSCIOCff/7BsWPHULBgQVy4cEHjjjoRERERUWbUTVKiboQcAMLDw5GcnAxbW1uV9ba2tnj58qXaYx49eoTz58/j9u3b2LdvH+bPn4/du3djwIABWc4oib+1LC0tMWPGDMyYIZ2PIImIiIjo2+bn54ehQ4eqrMts6m9NpthMSUmBQqHAli1bYGHx8RPhuXPn4ocffsCSJUuyNLouic46EREREX0fFJBOvVh6JS/q2NjYQF9fP80o+uvXr9OMtqeyt7dHgQIFlB11AChdujQEQcDz589RvHhxtcd9TvQyGCIiIiIiqTMyMoKHhweOHz+usv748eOoVq2a2mO8vLwQEhKCmJgY5br79+9DT08PBQsWVHvMl9hZJyIiIiKd0VNIZ9HU0KFDsXr1aqxduxZBQUEYMmQIgoOD0bfvxxnY/Pz80LXrpxmnOnbsCGtra3Tv3h2BgYE4e/YsRowYgR49emT5BlOWwRARERERZUG7du0QERGByZMnIzQ0FK6urjh06BAKFy4MAAgNDVX5LofcuXPj+PHj+OWXX1CxYkVYW1ujbdu2mDp1apYfU/SpG3MKp27UHk7dqD2culF7OHWj9nDqRu3h1I3aw6kbtUdqUzc2W3lF7AhKB3pXEjtCpiR2+YiIiIjoW5bezCmkHmvWiYiIiIgkip11IiIiIiKJYhkMEREREekMq2A0w5F1IiIiIiKJYmediIiIiEiiWAZDRERERDqjxzoYjXBknYiIiIhIojiyTkREREQ6w4F1zXBknYiIiIhIothZJyIiIiKSKJbBEBEREZHOKFgHoxGOrBMRERERSRRH1kVWOF8usSNkKkUQxI6QJaZG+mJHyJQC8hhNKOdoIXaETFk1Xyh2hCyJ+n2g2BEyVaN4PrEjZIlM3opIS2zMjcSOQCQJ7KwTERERkc6wCkYzLIMhIiIiIpIodtaJiIiIiCSKZTBEREREpDN6rIPRCEfWiYiIiIgkiiPrRERERKQzHFfXDEfWiYiIiIgkip11IiIiIiKJylIZTHBwsEYndXR0/KowRERERPRtU/AGU41kqbNepEgRjRo2OTn5qwMREREREdFHWeqsr127ln8FERERERHpWJY66z/++GMOxyAiIiKi74Eex381kq0bTOPi4vDixQskJSVpKw8REREREf3fV3XWT506BU9PT5ibm6Nw4cL4999/AQADBgzA3r17tRqQiIiIiOh7pXFn/a+//kL9+vXx4cMHDB8+HCkpKcptNjY2WL9+vTbzEREREdE3RKFQSGaRA4076+PHj0ejRo1w48YNTJ06VWWbm5sbAgICtJWNiIiIiOi7lqUbTD9348YN7Nq1C0DaeTLz5cuH169faycZEREREX1zZDKgLRkaj6wbGBggMTFR7bbXr1/D3Nw826GIiIiIiOgrOuuVKlXCpk2b1G7bvXs3PD09sx1KanZs2wLf+rVRyb0s2rdphevXroqaJ+D6VYwaMgAtGtaCd0VXnD19UmW7d0VXtcvWjWtFSvzRmlUr0KndD/CqXAG1a1TDkIED8OTxI1EzfUkOGQHg2tUrGDigL+rVqo7yriXx18kTYkdKl5ivn+FtKuL8vHZ4vasvnm75CTvHNUbxApYq+zSv5owDk5vj2dZeiDs4EOWK2qQ5T4+GZXDUvxVe7eqLuIMDYWFmpKPfQJXU3ovUkXpGvna0Tw455ZARkE9O0i2NO+ujR4/Gvn370LJlSxw4cAAKhQJ///03fv75Z+zevRsjR47MiZyiOXL4EGbN8Eev3v2wY/d+VKjggf59eiE0JES0TB/i4lCseEkMGTlG7fb9R06rLKPHT4FCoUDN2vV0nFTV9atX0K5DR2zcugPLVq5FclIS+vX+CXGxsaLm+pwcMgJAXFwsSpQsidFjxosdJUNiv368yxbA8oP/wmfYTjQZtx/6+nr4c2oL5DL+VAGYy9gQl4JC8ev6i+meJ5exIY5ff4rZO6/oIrZaYrdlVsghI1872iWHnHLICMgnpzaIfVOp3G4wVQiCIGh60ObNmzF48GBERkYq11laWmLRokXo1KmTVgN+rQ9amvq9U/s2KO3ignHjJynXtWjqi1q162LQkGHZPv/bOPUlRVnlXdEV0+YsQI2addLdx2/YQMTGvseCZWu+6jFym2h8a0OWREZGok6Nali9fhM8KlbKkcfILm1nVED7bwzlXUti7oIlqF2nrtbOqa33r5x8/Vg1X6jxMTZ5TPFsWy/UHbkbF+6o/gfomN8c99Z1R5VftuLfR+Fqj/cuWwDHZrSGXdvliH6fkKXHjPp9oMY51cnp9yJtyOmMmv9vlbHv9bWjTXLIKYeMQM7mzKH/xr9a163/ih1BaWPHcmJHyNRXzbPeuXNnPHv2DMeOHcPmzZtx5MgRPHv2TDIddW1JTEhAUOAdeFarrrLes5oXbgbcECmVZiIjwnHp/Fk0ad5K7ChpxMS8AwBYWFiInCR9csgoVVJ8/eT5f/lKVMwHUR7/a0mxLb8kh4xyIZe2lENOOWQE5JOTxPHVf2uZmpqibt3sj0b88ssvaNu2Lby9vbN9Lm2LehOF5ORkWFtbq6y3trZBeHiYSKk0c/jPA8hllgs1amlv5EgbBEHAb7NmwL2CB4oVLyF2HLXkkFHKpPj6mdnLGxduv0Dg08jMd5YQKbbll+SQUS7k0pZyyCmHjIB8cmqLnjyqTyTjqzrrb9++xZIlS3Dq1ClERETA2toatWrVQr9+/WBpaanRuZYsWYKlS5fC2dkZPXv2RLdu3WBnZ6fROeLj4xEfH6+yTtA3hrGxsUbnSc+XNU2CIMimzunQgX2o17CJ1tpCW2ZMm4IH9+9h3catYkdJlxwyyoFUXj/z+tVE2SI2qDNit84fW1uk0pYZkUNGuZBLW8ohpxwyAvLJSbqlcRnM48ePUa5cOYwdOxYPHjyAkZERHjx4gLFjx8LNzQ2PHmk+c8axY8fQqFEjzJkzB46OjmjevDn+/PNPlW9HzYi/vz8sLCxUltkz/TXO8SUrSyvo6+sjPFy1fjUyMgLW1mlnjJCamzeuIfjpYzRtIa0SmBnTp+DMqb+wau1G2Gr4h5muyCGj1Enp9TO3rw+aVHFCA7+9eBERo9PH1gYptWV65JBRLuTSlnLIKYeMgHxyaovYN5XK7QZTjTvrgwYNwocPH3DhwgU8fvwYly5dwuPHj3H+/HnEx8dj8ODBGocoW7Ys5s+fj5CQEGzevBnx8fFo0aIFChUqhLFjx+Lhw4cZHu/n54fo6GiVZcQoP41zfMnQyAilXcrg8sULKusvX7wIt/Lu2T5/Tvvz970oWdoFxUqUEjsKgI8jBDOmTcZfJ45jxdr1KFCwoNiR0pBDRrmQyutnXl8fNPd0RsMxe/H01VudPa42SaUtMyKHjHIhl7aUQ045ZATkk5PEoXEZzF9//YUFCxakmU+9WrVqmDp16ld11lMZGhqibdu2aNu2LYKDg7F27VqsX78eM2bMQHJycrrHGRunLXnR1mwwXbp1x9jRI+Hi6go3N3fs2bUDoaGhaNOuvXYe4CvExsbixbNg5c+hL17gwb27yGNhAVs7ewDA+5gYnD5xDAMGDxcrZhr+Uyfj8KE/MW/hEpiZmSnr8HLnNoeJiYnI6T6SQ0YAiI19j+DgT8+BFy+e4+7dIFhYWMDe3kHEZKrEfv3M718T7XxKos2UPxETlwhbq1wAgOj38fiQ8PE9xSq3MQrlN4d9XjMAQIkCVgCAV1GxeBX1ccpOW6tcsLXKBWd7SwCAaxEbvItLwLPX7xAVEw9dELsts0IOGfna0S455JRDRkA+OUn3NJ660draGtu2bUP9+vXTbDt27Bg6dOiAiIiILJ9PT08PL1++RP78+dVuFwQBJ06cQL16ms0Rrq3OOvDxSwrWr12DsLDXKFa8BEaM8tPaVINfM3Xjjav/YGDfHmnWN2zSHGMnTgMAHNi7Cwt/m4n9R08hd+7sfaustqZudHdVP8I/aep0NJNIqU5OZ9TW1I1X/vkbvXp0TbO+afOWmDJtRrbPr81PBnPq9ZOVqRvjDqqfNrHXvOPYfCIIANC5bmmsGpL2/WXqlr8xbevfAICxHatgXKcqGZ4nPdqauhHI2fcibcnJjNqYupGvHe2TQ045ZARyLqfUpm7ssf2W2BGU1rYvK3aETGncWe/Rowf09fWxatWqNNt69eqFhIQEbNiwIcvnc3JywtWrV9PcAZ1d2uys56TszrOuCzk1z/r3KCfmWc8Jcijj+5p51sWgzc76907b86znBDm8duj7I7X/xtlZ10yWLt/169eV/+7YsSN69uyJNm3aoGPHjrCzs8PLly+xZcsWXL16FWvWaPbFO48fP9YsMRERERHRdyJLnfWKFSuq3DErCAKePXuGvXv3qqwDgPr162dYX05ERERE3y89fgSlkSx11tetW5fTOYiIiIiI6AtZ6qx369Ytp3MQEREREdEXJHbLARERERF9y1gFo5mv6qxHRkZi69atCAoKQlxcnMo2hUKh8U2mRERERESUlsad9eDgYFSqVAmxsbGIjY2FjY0NIiMjkZycDCsrK1hYWORETiIiIiL6Big4tK4RPU0PGD16NMqUKYNXr15BEAQcPnwY79+/x6JFi2BiYoKDBw/mRE4iIiIiou+Oxp31S5cuoV+/fsqvXhcEAUZGRhgwYAB69uyJESNGaD0kEREREdH3SOPO+qtXr2Bvbw89PT3o6+vj7du3ym0+Pj44f/68VgMSERER0bdDoZDOIgcad9ZtbW0RGRkJAChSpAiuXr2q3PbkyRMYGHCCGSIiIiIibdC4Z121alXcuHEDzZo1Q6tWrTB58mTEx8fDyMgIs2fPRu3atXMiJxERERHRd0fjzvrw4cPx5MkTAMD48eMRFBSECRMmQBAE1KhRA/Pnz9dyRCIiIiL6VujJpf5EIjTurHt4eMDDwwMAYGZmhgMHDuDt27dQKBQwNzfXekAiIiIiou+VxjXr6uTJkwfm5uY4e/Ysy2CIiIiIiLREq3eDhoWF4cyZM9o8JRERERF9Q1gFoxmtjKwTEREREZH2cZ5FIiIiItIZBYfWNcKRdSIiIiIiiWJnnYiIiIhIorJUBlOuXLksnezt27fZCvM9ymNqKHYEIlmK+n2g2BGyxOqHlWJHyFTU7t5iR8iS+KRksSNkKilZEDtCpkyN9MWOkCX6eiyV+FZxpFgzWeqs582bN0v1RdbW1nBycsp2KCIiIiIiymJn/fTp0zkcg4iIiIiIvsTZYIiIiIhIZzgbjGZYNkREREREJFEcWSciIiIineG9w5rhyDoRERERkUSxs05EREREJFEsgyEiIiIinWEZjGa+urN+9+5dnDlzBuHh4ejZsyfs7OwQEhICKysrmJqaajMjEREREdF3SePOenJyMnr37o3169dDEAQoFAr4+vrCzs4Offr0gbu7OyZPnpwTWYmIiIiIvisa16xPmzYNW7duxezZs3H79m0IwqevVvb19cWRI0e0GpCIiIiIvh0KhUIyixxoPLK+fv16/Prrrxg6dCiSk5NVtjk5OeHx48daC0dERERE9D3TeGT9xYsX8PT0VLvNxMQE7969y3YoIiIiIiL6is56/vz58ejRI7Xb7t27h4IFC2Y7FBERERF9m/QU0lnkQOPOeqNGjTBt2jS8ePFCuU6hUCA6OhoLFy5E06ZNtRqQiIiIiOh7pXFnffLkyUhKSoKLiwtat24NhUKBMWPGwNXVFR8+fMCvv/6aEzmJiIiI6BugUEhnkQONO+u2tra4cuUKOnTogGvXrkFfXx83b96Er68vLl68iLx58+ZETiIiIiKi785XfSmSra0tli9fru0sRERERET0GY1H1r9HO7ZtgW/92qjkXhbt27TC9WtXxY6klhxyyiEjII+ccsgIyCOn2Bm9XOywe2wDPFrbCXH7e6NplcIq21cO9EHc/t4qy5mZzZXbHfPnTrM9dWlVzUmnv4vYbZmZFr51UaW8S5pl1vQpomUKuH4VIwf3R7MGNeHlUQZnT51U2X76r+MYMqAXGtX2gpdHGdy/FyRSUlW7dmxD21bN4F3VA95VPdCtUztcOHdW7FhqSf15mUouObNLT6GQzCIHGo+s9+jRI8PtCoUCa9as+epAUnPk8CHMmuGPsb9OQHn3Cti9czv69+mFfQcOwt7BQex4SnLIKYeMgDxyyiEjII+cUshoZmKIW48jsOnkPWwfXV/tPkevBaPPojPKnxOSUpT/fh7+HkV+3KSyf4/6pTG0pRuOXn+WM6HVkEJbZmbdlp1ISfn0HSH/PXyAX/r+hDr1GoiWKS4uDsVKlESjZi0xdsTgNNs/xMWhrJs7atVtgJlTJ+g+YDry29pi4OBhKOToCAD448B+DBk4ANt27YVzseIip/tEDs9LQD45SfcUwudfQZoFRYoUSfONTxEREYiJiYGlpSUsLS3TndpRlz4kaec8ndq3QWkXF4wbP0m5rkVTX9SqXReDhgzTzoNogRxyyiEjII+ccsgIyCNnTme0+mGlRvvH7e+Ntv5H8cffT5XrVg70gaWZMdr6H8vyeS7NbYWAR+Hotzjzkc6o3b01ypienG7LD4nJme+kobmz/HHh3GnsPnBEK99mmJSs0X+paXh5lIH/nIWoUatOmm2hIS/wQ9P6WLd1N0qULP3Vj2FqpJ+diBmq6VUFg4eNQItWP2T7XPpamldPDu9DQM7mNPmqouecM/rQfbEjKM1oVELsCJnSuAzmyZMnePz4scry9u1bnDhxAvnz58fvv/+eEzlFkZiQgKDAO/CsVl1lvWc1L9wMuCFSqrTkkFMOGQF55JRDRkAeOeWQMZW3qz2eru+Cf5e0xZL+3shnYZLuvu7ONihf1AYbjt/TWT45tWWqxMQEHDn0B5o2byWbrx2XquTkZBw9fBBxcbEo51Ze7DhKcnleyiWntuhJaJEDreWsXbs2fv75ZwwaNEjjYxctWoRu3bph586dAIBNmzbBxcUFpUqVwpgxY5CUpKVhcg1FvYlCcnIyrK2tVdZbW9sgPDxMlEzqyCGnHDIC8sgph4yAPHLKISMAHLv2DN3n/gXf8X9i9PrL8CieD4cnN4GRgfq38G51SyLoWRQu33uls4xyacvPnfnrJGLevUPjZi3FjiJbD+7fg1flCqjqUQ7TpkzEb/MXo6hzMbFjKcnleSmXnCQOrX4w4uLigtGjR2t0zJQpUzB79mzUr18fgwYNwuPHjzF79mwMGTIEenp6mDdvHgwNDTFp0qR0zxEfH4/4+HiVdYK+MYyNjb/q9/jSlyMugiBIchRGDjnlkBGQR045ZATkkVPqGXdf+FRaGBgchesPw3BvZUf4VnTE75efqOxrYqSPdjWKYcbO6zpO+ZHU2/JzB/bvhaeXN/Llzy92FNkq4uSEbbv3IebdW5w8fgzjx43G6nWbJNVhB+TzvJRLTtItrX4CcObMGdjY2Gh0zPr167F+/Xrs3r0bR44cwdixY7FgwQKMHTsWfn5+WLFiBbZu3ZrhOfz9/WFhYaGyzJ7pn51fBQBgZWkFfX19hIeHq6yPjIyAtbVmv2dOkkNOOWQE5JFTDhkBeeSUQ0Z1XkbFITgsBsXsLdJsa1mtKHIZGWDLqQc6zSS3tgwNeYErf19Cs5atxY4ia4aGRnB0LAyXMmXxy+BhKFGiFLZu3ih2LCW5PC/lklNbxP4ipG/+S5EmT56cZhk7diyaNm2KadOmoUOHDhqdLzQ0FBUrVgQAuLm5QU9PD+XLl1dur1ChAkJCQjI8h5+fH6Kjo1WWEaP8NP3V0jA0MkJplzK4fPGCyvrLFy/Crbx7ts+vLXLIKYeMgDxyyiEjII+ccsioTl5zYxS0MUNoVGyabT/WLYmDV54i/O0HnWaSW1v++fs+WOXNCy9vH7GjfFMECEhMSBA7hpJcnpdyyUni0LgMZuLEiWnWGRsbo0iRIpg8eTJGjBih0fns7OwQGBgIR0dHPHjwAMnJyQgMDESZMmUAAHfu3EH+TD6iNDZOW/KirdlgunTrjrGjR8LF1RVubu7Ys2sHQkND0aZde+08gJbIIaccMgLyyCmHjIA8ckoho5mJAZw/GyUvkj8PyjlZI+rdB0TGxGNcew/sv/QYoVGxKJzfHJM7V0LE2w848EUJTFG7PKjuYo8WUw7rLPvnpNCWWZGSkoI/D+xD46YtYGAg/jQZsbHv8fxZsPLnkJDnuH8vCHnyWMDO3gFvo9/g5ctQhId9rF0OfvoEwMd6ZmubfGJEBgAsWjAXXtVrwM7ODu/fv8fRI4dw7co/WLxslWiZ1JHL81IuObVBLvObS4XG71IpKSmZ76SBjh07omvXrmjevDlOnjyJUaNGYfjw4YiIiIBCocC0adPwww/ZnwLqazX0bYToN1FYuWwpwsJeo1jxEliyfCUcHAqIlkkdOeSUQ0ZAHjnlkBGQR04pZKxQLB+OTW2q/HlWT08AwKa/7mHg8vMoUzgvOtYsAUszI7yMisWZ2yHoMuckYj4kqpynW92SCIl8jxMBz3WW/XNSaMus+OfyJbwMDUXTFq3EjgIAuBt4B7/06a78edHcWQAA3ybNMW7SdJw7cwrTJ41Tbp/gNxwA0KN3f/TsM0C3YT8TGRGBX8eMRHhYGHKbm6N48ZJYvGwVqlbzEi2TOnJ5XsolJ+meRvOsx8XFoWfPnujfvz+qV6+e+QFZkJycjBkzZuDy5cuoXr06Ro0ahe3bt2PkyJGIjY1F06ZNsXjxYpiZmWl0Xm2NrBMRZYem86yLQVvzrOe0nJhnXduyO8+6LuTkPOvapK151kl686z/ekS399RkZEpD6XyBV3o0/lIkMzMzHD58GDVq1MipTFrBzjoRSQE769rDzrp2sLP+/ZFaZ338Uel01ic3kH5nXeMbTMuXL4/bt2/nRBYiIiIiIvqMxp31GTNmYNasWThz5kxO5CEiIiIiov/L0gcjZ8+eRYUKFZA7d270798fMTExqF27NqysrGBvb68yYb9CocDNmzdzLDARERERyRcrnDSTpc56rVq1cOnSJVSuXBnW1tYaf/ERERERERFpLkud9c/vQT19+nROZSEiIiIios9I7P5gIiIiIvqW8UuRNJPlG0wVbFgiIiIiIp3K8sh6rVq1oKeXed9eoVAgOjo6W6GIiIiI6NvE8V/NZLmzXrNmTeTLly8nsxARERER0Wey3FkfP348KleunJNZiIiIiIjoM7zBlIiIiIh0hvOsa0bjbzAlIiIiIiLdYGediIiIiEiislQGk5KSktM5iIiIiOg7oADrYDTBkXUiIiIiIoniDaZEREREpDO8wVQzHFknIiIiIpIodtaJiIiIiCSKZTBEREREpDMsg9EMO+sii0tIFjtCppJSBLEjZImJgfQ/KJJLWybLIGduE3m8fUXt7i12hEyVHn5Q7AhZEjSnsdgRMmcodgAi+tZIv3dDRERERPSdksfQFBERERF9ExQK1sFogiPrREREREQSxc46EREREZFEsQyGiIiIiHSGs8FohiPrREREREQSxZF1IiIiItIZ3l+qGY6sExERERFJFDvrREREREQSxTIYIiIiItIZPdbBaIQj60REREREEsXOOhERERGRRLEMhoiIiIh0hvOsa4Yj60REREREEsXOOhERERFRFi1duhROTk4wMTGBh4cHzp07l6XjLly4AAMDA5QvX16jx2NnnYiIiIh0RqGQzqKpHTt2YPDgwRg7dixu3LgBb29v+Pr6Ijg4OMPjoqOj0bVrV9SpU0fjx2RnnYiIiIgoC+bOnYuePXvip59+QunSpTF//nwUKlQIy5Yty/C4Pn36oGPHjvD09NT4MdlZJyIiIiKd0YNCMosmEhIScO3aNdSvX19lff369XHx4sV0j1u3bh3+++8/TJgw4SvbizK1Y9sW+NavjUruZdG+TStcv3ZV1Dw3rl3FsEH90aSeD6q6u+DMqRMq21ctX4x2LRujpqcH6tWoip/79MDtWzd1njPg+lWMHNwfzRvURHWPMjh76qTK9siIcEybMAbNG9REnWoeGPpzbzwLfqrznJ9LSkrC0sXz0cy3Lrwql0fzRvWwavkSpKSkiJors2v+uRlTJ6Cquwu2b9mow4SfrnezBjXhpeZ6e3mUUbts2bhWpznVkdprPD1i5exX1xn7h3rh1owGuDKlLlb09EDR/GYq+zQoZ4cNfSvj2tR6eDy/MUoXyJPmPDbmxpjbyQ3/TK6DOzMb4I9h1eHrZqeT3+FLcrjmcsgIyCOnHDIC8sn5LYmPj8fbt29Vlvj4eLX7hoeHIzk5Gba2tirrbW1t8fLlS7XHPHjwAKNHj8aWLVtgYPB1kzCys56JI4cPYdYMf/Tq3Q87du9HhQoe6N+nF0JDQkTLFBcXi+IlSmLY6HFqtzsWLoJho8Ziy679WLFuE+wdCmBQ/16IiozUcc44FCtREkNHjU2zTRAE+A0biJAXzzFj7iKs27obdvYOGNyvJ+LiYnWa83Mb1q3Gnl07MNJvHHbtO4hfhgzHpg1rsWPbZtEyAZlf81RnTp3AnVv/Il++/DpK9klG1xsADhw9rbKMmTAVCoUCNWvX03FSVVJ8jasjZs4qznmx6fxTtJp/AV2X/Q19PQU29q0MUyN95T65jPRx9XEkZv15N93zzOvshqL5c6PX6qtoOOssjv77Eou6VYCLmo59TpLDNZdDRkAeOeWQEZBPzm+Nv78/LCwsVBZ/f/8Mj1F8UewuCEKadQCQnJyMjh07YtKkSShRosRXZ2RnPRObNqxDy9at0eqHNijq7IyRfmNhZ2+HnTu2iZapWvUa6DtgEGrVUd/JaeDbBJWrVkOBgoVQ1Lk4Bg8bhfcxMXj44J5Oc3p6eaN3/0HwUdMZexb8FHdu3cQwv/EoXaYsHIs4YdjoXxEXF4sTRw7pNOfnbt0MgE/N2qheoyYcChRA3XoNUMXTC4F3bouWCcj8mgPA69evMGfGNEyaPgv6X/nXe3akXu/0Ot/WNvlUlnOn/0KFipVRoGAhHSdVJcXXuDpi5vxxxRXs+ec5HryMQVDIO4zc+i8K5M2FsgUtlPvsu/oCi44+xPn74emex72IFTace4KbwdF4FhGHxccf4m1cIlw/O48uyOGayyEjII+ccsgIyCenNoh9U+nni5+fH6Kjo1UWPz8/tbltbGygr6+fZhT99evXaUbbAeDdu3e4evUqfv75ZxgYGMDAwACTJ0/GzZs3YWBggL/++itL7SV6Zz00NBTjx49H7dq1Ubp0abi6uqJp06ZYs2YNkpOTRc2WmJCAoMA78KxWXWW9ZzUv3Ay4IVIqzSQmJmD/3p3IndscxUuUEjuOUmJCAgDA2MhIuU5fXx+GBob4N+C6WLFQ3t0DV/65jKdPHgMA7t+7i5s3rsPL20e0TFmRkpKCSeNGo3O3HijqXFzsOJmKjAjHxfNn0aR5K1FzyOU1LrWc5qYf/xh8E5ug0XFXH0Wisbs9LHIZQqEAmrjbw8hAD5cfRuRETLWk1pbqyCEjII+ccsgIyCfnt8jY2Bh58uRRWYyNjdXua2RkBA8PDxw/flxl/fHjx1GtWrU0++fJkwe3bt1CQECAcunbty9KliyJgIAAVKlSJUsZRf0G06tXr6Ju3bpwcnKCqakp7t+/j06dOiEhIQHDhw/HmjVrcPToUZibm4uSL+pNFJKTk2Ftba2y3traBuHhYaJkyqrzZ0/j19HD8OHDB9jY5MPC5athaWUldiylwkWcYGfvgOWL52PE2AkwNTXF9s0bEBERjggR27Zbj58QE/MOP7RoDD19faQkJ6P/L4PR0LexaJmyYtO61dDX10fbDp3FjpIlh//8HbnMcqn91EWX5PIal1rOcS1ccOW/SNx/GaPRcb9suIFF3dwRML0+EpNTEJeQjL5rriE4Qnelb1JrS3XkkBGQR045ZATkk5OAoUOHokuXLqhYsSI8PT2xcuVKBAcHo2/fvgA+jtS/ePECGzduhJ6eHlxdXVWOz58/P0xMTNKsz4ionfXBgwdjyJAhyrtjN2/ejMWLF+Py5cuIiopC7dq1MW7cOCxYsCDD88THx6e5GUDQN073LyNNZbU2SUo8KlXGxu17Ef3mDX7fuwtjRw7Fmk3bkTevdeYH64CBoSGmzp6PGZN/RaNa1aCvrw+PylVR1ctb1FzHjhzC4YN/YKr/bDgXK457d4Mwd7Y/8uXLjybNWoiaLT13A+9gx7ZN2LB1j+Sfl6n+/H0f6vs20dprNLvk8hqXQs7JrcuglIM52iy4pPGxwxqVhEUuQ3RachlR7xNQr6wdlnSvgLYLL+Fe6LscSJs+KbRlZuSQEZBHTjlkBOSTM7v0ZPwrtWvXDhEREZg8eTJCQ0Ph6uqKQ4cOoXDhwgA+VoxkNue6pkQtg7l+/Tq6dOmi/Lljx464fv06Xr16BSsrK8yaNQu7d+/O9Dzqbg6YPTPjmwOywsrSCvr6+ggPV63BjIyMgLW1TbbPn5NMTXOhkGNhuJZzw9iJU6Gvr48/9u0RO5aKUqXLYP22vThy+jL2Hz2NuYtXIvrNG9g7FBAt08J5c9Ctx09o4NsYxYqXQOOmzdGhczesW7NStEyZCbhxDVGRkWjRqA68KpaFV8WyeBkagoVzZ6FFo7pix0sj4MY1BD99jKYtWosdRTavcanknNiqDOq42qLD4st4Gf1Bo2MdrXOhW40iGLntX1x8EIGgkHdYePQB/g2ORpfqhXMocVpSacuMyCEjII+ccsgIyCcnfdS/f388efIE8fHxuHbtGmrUqKHctn79epw+fTrdYydOnIiAgACNHk/Uznr+/PkRGhqq/PnVq1dISkpCnjwfZwYoXrw4IrMwg4m6mwNGjFJ/c4AmDI2MUNqlDC5fvKCy/vLFi3Ar757t8+uWgIREzepLdSW3uTmsrPLiWfBT3Au6A2+f2qJl+fAhDnp6qi8LfX19CCJP3ZgR38bNsHnnfmzcvle55MuXH5269sCCpavEjpfGn/v3oGTpMpK4h0Iur3Ep5JzUugwalLNDpyWX8TwyTuPjU2eOSRFU16cIAvR0OHIohbbMjBwyAvLIKYeMgHxykjhELYNp0aIF+vbti9mzZ8PY2BhTpkyBj48PTE1NAQD37t1DgQKZj7IaG6ctefmQpJ2MXbp1x9jRI+Hi6go3N3fs2bUDoaGhaNOuvXYe4CvExr7H82efPmIJefEC9+8FIU8eC1hYWmL96hXw9qkNaxsbREdHY8/ObXj96hXq1Gug85wvPssZGvIcD+4FwTyPBezsHfDX8aOwtLKCrZ09Hj18gAVz/OFdszYqe3rpNOfnvH1qYe2qFbCzs0dR5+K4dzcQWzatRzORb4TM6Jrb2TvAwtJSZX99AwNY29igcBEn8TKGPFfJCADvY2Jw6sQx/DxkhM5yZUaKr3F1xMw5+QdXNPdwQO/VVxETnwwb84/vt+8+JCI+8eMfsha5DOFgZQrbPB+3pc7DHvY2HuHv4vHfqxg8DnuP6W1dMf33IES9T0T9sraoXsIGPVddyfHf4XNyuOZyyAjII6ccMgLyyakNuvwD/Vsgamd96tSpCA0NRdOmTZGcnAxPT09s3vxpPmuFQpHpXJc5raFvI0S/icLKZUsRFvYaxYqXwJLlK+EgYqlGUOAdDOj1o/LnBb/NBAA0atoCo8ZOwJMnj3Hoj0F48yYKFhaWKF3GFcvXbtL5LCF3A+9gYJ/uyp8XzZ0FAPBt0hxjJ01HRHgYFs+bhciIcFjb5EPDxs3wY6++Os34pRGjx2H5kgWYMX0yoiIjYZMvP1r90Ba9+vQXNVdG13z85OkipVJ1N/AOfknneo+b9DHjiWOHIAgC6jVoJEpGdaT4GldHzJypZSrbf1H9muzhW29izz/PAQB1XW0xp6ObctvibhUAAPOP3MeCIw+QlCKgx4p/MLJpKazuVQm5jPTxNDwWw7fexOkg3d5AJ4drLoeMgDxyyiEjIJ+cpHsKQRCEzHfLWR8+fEBSUhJy586tvXNqaWQ9p8UliDs9ZVYkffm5tUSZGIg+E2mm5NKWyTLImdtE1LGGb0rp4QfFjpAlQXOkPSsTkVRJ7e1y1d/iflv553pV0d09M19LEpfPxMRE7AhERERERJIj/aFIIiIiIqLvlCRG1omIiIjo+8AbTDXDkXUiIiIiIoliZ52IiIiISKJYBkNEREREOsMqGM1wZJ2IiIiISKI4sk5EREREOsORYs2wvYiIiIiIJIqddSIiIiIiiWIZDBERERHpjIJ3mGqEI+tERERERBLFzjoRERERkUSxDIaIiIiIdIZFMJrhyDoRERERkUSxs05EREREJFEsgyEiIiIindHjbDAa4cg6EREREZFEcWSdiIiIiHSG4+qa4cg6EREREZFEcWRdZKZG+mJHIB0yFDsA6Vx8YorYETIVNKex2BGypECPbWJHyNSLtR3EjpApOTwnAeDdh0SxI2TKxtxY7Aj0HWBnnYiIiIh0hveXaoZlMEREREREEsXOOhERERGRRLEMhoiIiIh0RsE6GI1wZJ2IiIiISKLYWSciIiIikiiWwRARERGRznCkWDNsLyIiIiIiieLIOhERERHpDG8w1QxH1omIiIiIJIqddSIiIiIiiWIZDBERERHpDItgNMORdSIiIiIiiWJnnYiIiIhIolgGQ0REREQ6w9lgNMORdSIiIiIiiWJnnYiIiIhIolgGQ0REREQ6w5FizbC9smDHti3wrV8bldzLon2bVrh+7arYkdSSQ045ZATkkVMOGQF55JR6xqSkJCxbPB/NG9WFd5XyaNG4HlavWIKUlBSxo6UhZlt6lsyHLUNq4M6C5ojY2AGNKhRQ2W5mbICZXTxwa35zPF/dBpdmNEL32sXSPd+OYT5qz6MrfF5qbuuG1ejfvQOa1K6K1r4++HXkIDx7+lhlnw2rluLHds3QuGZlNK/nhRE/90LQ7X9FSqxK6tecxCGJzvr79++xatUqdO/eHb6+vmjUqBG6d++O1atX4/3796JmO3L4EGbN8Eev3v2wY/d+VKjggf59eiE0JETUXF+SQ045ZATkkVMOGQF55JRDxo3rVmPv7h0YMXocduw9iF8GD8fmDWuxc9tmsaOpELstcxkb4E5wFEZtuqZ2+9RO7qhdzh59l1+C5+hDWHbkHmZ08YCvms543wYlIeR04AyI3ZZZIcXn5b83rqJZ6/ZYvHozZi1cieTkZIwc1BdxcbHKfQo6FsYvw8Zg1Za9WLBiA2ztHTBqUF+8iYoULTcgj2uuLQqFQjKLHIjeWQ8MDESJEiUwcuRIREVFwdHREQULFkRUVBRGjBiBkiVLIjAwULR8mzasQ8vWrdHqhzYo6uyMkX5jYWdvh507tomWSR055JRDRkAeOeWQEZBHTjlkvPVvAGrUrI3qNWrCoUAB1KnXAFU8vRAUeFvsaCrEbsuT/4Zi+p5b+PPqc7XbKxWzwfbzj3Hh7ms8C3+Pjaf/w+3gNyjvlFdlvzKFLNG/YUkMXP23LmKrJXZbZoUUn5cz5i9HwybNUaRoMTgXL4mR4ybj9ctQPLj7qR9Rp0FjeFSuCocCBVGkaDH0GzwC79/H4NHD+6LlBuRxzUkconfWBwwYgBo1auDVq1fYv38/VqxYgZUrV2L//v149eoVatSogQEDBoiSLTEhAUGBd+BZrbrKes9qXrgZcEOUTOrIIaccMgLyyCmHjP9r777joq4fOI6/T8aByEYZmojiwBECTpRwpaKhuE1T0rShlaNITQs3pma598hy4M4sU1SiDDeu1Bw5cIDKEBGUdd/fH/64OjlWHvf9fuz9/D3u8fj5veN7r74n+OHD5z4AYnSK0AgADX38cPzIYdz4/4/zL138E6dPxsG/ZaDMZX8T4VoevnQfQT6V4WpvCQBo6VUJni7WOHA2QfsYS3MTLB/mjzHfnsC9tCeydIpwLQEx/l5mPHoEALC2sdV7f05ODn7csQVWFaxRo2ZtY6bpdgjympM8ZH+D6ZEjR3D8+HGYm5sXuM/c3ByffvopmjRpIkMZkPogFXl5eXB0dNQ57ujohKSk+7I06SNCpwiNgBidIjQCYnSK0AgAAwcNwaNH6egd0hnlTEygycvDe++PRIegznKnaYlwLcd9G4ev32qCP+aGICdXA40kYeTKozhyKUn7mKn9fHH0chJ2x92WrVOEawko/++lJElYPHcW6nv7wKNGTZ37Dh2MwdTPPkHWkydwcKqImfOWwtbOXqZScV5zQxFj8YlyyD5Yt7e3x+XLl1G3bl2991+5cgX29kV/AmVlZSErK0vnmGSihlqtNkjjs2uaJElS5DonETpFaATE6BShERCjU+mNUXt+wu4ff8CUiFmoXqMmLl28gDmzIuBUsRJe6xIid54OJV/Lt9vXQqMajug3JwY3kzPhX7siZoU2wt20x4g5dxcdfSojoK4zWn/2s9ypAJR9LQHl/72cN3s6rl65jLnL1hS4r6FfYyxbuxlpaan48fttmDL+YyxYuQ72Do4FT2RESn/NSR6yD9aHDh2K0NBQTJgwAa+++iqcnZ2hUqmQmJiIqKgoTJ8+HSNHjizyHBEREZg0aZLOsfGfhWPC5xOfq83ezh4mJiZISkrSOZ6SkgxHR6fnOrchidApQiMgRqcIjYAYnSI0AsC8r2YjdNAQtO/4dMbSs2YtJCTcwTerliliUAQo/1pamJlgQq+XMXDuQUSdfvqGvfM3H6B+VXsMD/JCzLm7CKjrDI9KFXB1SQ+dj13zYUscungfXSMOGKVV6dcyn5L/Xs6fHYFDv/2Cr5asRsVKLgXut7Qsj8ovVUXll6qibn1vDOz5Gnb/sB39QocYPxbivOYkD9nXrE+cOBHjxo3DnDlz4OPjg8qVK8PNzQ0+Pj6YM2cOxo4di88//7zIc4wbNw5paWk6t7Ax4567zczcHF516+Fw7O86xw/HxsK7oc9zn99QROgUoREQo1OERkCMThEaAeDJk8dQldP9cm1SzkRRWzcq/VqamahgbmoCjaS7x0ueRkK5/09czt11HgHjdyNwws/aGwBMWHcSHyw33ptNlX4t8ynx76UkSZg3ezp+i9mP2QtWwNWtSsk+DhJysrPLuK5worzmhqJSKecmAtln1gFgzJgxGDNmDK5du4bExEQAgIuLCzw8PEr08Wp1wSUvT3IN0zYgdBDGj/0EdevXh7e3D7ZujkRCQgJ69elrmCcwEBE6RWgExOgUoREQo1OExoBXWmPNiqVwcXFF9Ro1cfHieaz/bg2Cu3aXO02H3NfSSm0KD+cK2j9XrVgB9avaITUjG7eTM3Hwwl1M6tsQT7LzcDMpAy3qVEKfltXw2fqnb+C7l/ZE75tKbyVnID7JuNsIy30tS0KJfy/nzZqG/Xt3Y8rMuShvZYWU5Kcz1VZWFaC2sMDjx5lYt2Y5/ANawdGxItLSHmDn1kjcv3cXgW3by9YNiPGakzwUMVjP5+HhUWCAfvPmTYSHh2PVqlWyNHUM6oS0B6lYtngR7t+/B8+atbBwyTK4ucnzSzIKI0KnCI2AGJ0iNAJidIrQ+PHYCVi6cC5mRkxGakoKnCpWQrcevTHknWFyp+mQ+1o29HDAzk/bav88rb8vAGDDb1fx/vIjGLooFp/18sbSd5vDroI5biVlYtqWM1h94IpR+kpD7mtZEkr8e7lz2yYAwOhhg3WOh02Ygo6vdYVJORPcvH4dE3/6CA8fpMLG1g61verh6yVrUK164b8gyxhEeM0NpRzfYloqKkmS5Py9D8U6ffo0fH19kZeXV6qPM9TMOhHR88jKUc5SlcKozWRfEVkilQcrf7/p26telzuhWCL8nQSA9Cc5cicUy8naMBtZlDULRU3NAj+cvSt3glZwA2e5E4ol+8u3c+fOIu+/evWqkUqIiIiIiJRF9sF6SEgIVCoViprg57ZFRERERC8GDutKR/affbq6umLr1q3QaDR6b3FxcXInEhERERHJQvbBup+fX5ED8uJm3YmIiIiIXlSyL4MJCwtDRkbhW2J5enoiOjraiEVEREREVFZU3A2mVGQfrAcEBBR5v5WVFQIDA41UQ0RERESkHLIvgyEiIiIiIv1kn1knIiIiov8O7gZTOpxZJyIiIiJSKM6sExEREZHRlOMbTEuFM+tERERERArFwToRERERkUJxGQwRERERGQ3fYFo6nFknIiIiIlIoDtaJiIiIiBSKy2CIiIiIyGi4DKZ0OLNORERERKRQHKwTERERESkUl8EQERERkdGo+EuRSoUz60RERERECsWZdSKiMnQ/PUvuhGJVcbCUO6FEbq96Xe6EYlUZslHuhGJdX9pH7oQScbJWy51QLI0kyZ1QQsqayS6nrBzF48w6EREREZFCcbBORERERKRQXAZDREREREbDN5iWDmfWiYiIiIgUioN1IiIiIiKF4jIYIiIiIjIaFVfBlApn1omIiIiIFIoz60RERERkNHyDaelwZp2IiIiISKE4WCciIiIiUigugyEiIiIioynHVTClwpl1IiIiIiKF4mCdiIiIiEihuAyGiIiIiIyGu8GUDmfWiYiIiIgUioN1IiIiIiKF4jIYIiIiIjIaFVfBlApn1omIiIiIFIqD9RKI3LAOQe3boLFPA/Tt1R1xJ47LnaSXCJ0iNAJidIrQCIjRqeTGTd+uROeAhlg2b6b2mCRJWLdqMQaEvIpubZti7Adv4ca1KzJW/k3J1xIAThw/hg+GvYt2rVrCu15tHNi/z6jPP6KzF6I+fxXXF/fAhXkhWPthS3i6WGvvNzVR4fNe3vh1SkfcWNoTf3zVFQuHNoWLnYXOeapVrIBvPmiJP+eF4NriHlgxzB8VbdRG/W8BgHt372LCuDC0CWgK/yYN8XqvEFw4/4fRO4oi92teEps2bkDvbl3QsqkfWjb1w8D+fXDwt1/lziozKgXdRKD4wfrdu3cxefJk2Z7/590/YeaMCAx9+z1EbtkBX18/DHtnKBLu3JGtSR8ROkVoBMToFKEREKNTyY2XLvyBn3/YCo8atXSOb1m/Btsjv8O7o8biq+XrYO/ghAmj3kNmZoZMpU8p+Vrme/w4E7Vr18bY8Z/L8vz+dSph5YEr6DAlCj1n/QLTcips/rgVypubAAAszU3xsrs9vtx5Dm3D9yB0wUHUcLHGdyNe0Z6jvLkJNoe1giRJ6DYzGp2m7YO5aTmsG/mKUZcXPHyYhsGhr8PU1BTzFi3Hlu27MOqjMahgbWO8iBKQ+zUvCWcXZ3ww6iOsi9yCdZFb0KRJM4z6YDj+unJZ7jRSAJUkSZLcEUU5ffo0fH19kZeXV6qPe5JrmOfv37cXvOrWxYTPJ2mPhQQHoXWbdhgx6iPDPIkBiNApQiMgRqcIjYAYnWXdeCvl8b/6uMeZmfjwrb4Y9tGniPxmOarXrI23P/wEkiRhQMir6Nq7P3r1HwQAyMnORv+ubTDo3ZEI6tqz1M9VxcHyXzU+S4TX+5+869XGV/MWok3bdgY7Z5UhG0v1eEdrNS7O74bg6ftx6NJ9vY/x8XBAVHh7eI/eidspmWhVzwWRH72CGsO24dH//7GzLW+Gvxb1QPeZ0fj1/N0in/P60j6laizMvK+/xOmTcVj5zTqDnO9ZpiaG/87D0K+5pgyHUIH+TTHyozB061H6z+lnlTdT1hzy75dT5U7QalHTXu6EYsk+s37mzJkibxcvXpStLSc7GxfOn0Nz/5Y6x5v7t8DpUydlqipIhE4RGgExOkVoBMToVHLj4q+mo3HzAPg0aqZzPDHhNlJTkuDbuLn2mJm5Oeo3bIQLf5wycuXflHwtlczG0gwAkJqRXehjrC3NoNFISMt8+hi1WTlIEpCdq9E+JitHgzyNBs1qVSzb4H/49ZcDqFuvPj75aATaBfqjX+9u2LZlk9Ge/0WVl5eHn3/6EY8fZ+Llhg3lzikT5VQqxdxEIPtuMA0bNoRKpYK+Cf784yqZLmbqg1Tk5eXB0dFR57ijoxOSkvTPgMhBhE4RGgExOkVoBMToVGpjzL6fceXSn/h6WcEZy9TkJACAnYODznE7ewfcT0wwSp8+Sr2WSjfldR8cungff95O03u/2qwcPu/lja2Hb2hn0Y//lYzMrFx83tsb07acgQrA5729YVKuHJxtLfSepyzcvnUTWzZtQP8Bb2LwkHdw7o8zmP3FNJibm+O1LiFG63hRXL50EaH9X0d2dhYsy5fHl3MXoEYNT7mzSAFkH6w7Ojriiy++QNu2bfXef+7cOQQHBxd5jqysLGRlZekck0zUUKsN82abZ79ZkPMbiKKI0ClCIyBGpwiNgBidSmq8fzcRy+bNxJQ5i2FexNewAr8BUJIUsR+akq6l0n0xwA91X7JD52n63/BoaqLC8vf8UU4FhK39+426yelZGLwwFrNCG+HtdrWgkSRsOxKP09dTkKcx3spWjUZC3Xr18P6I0QCAOl518ddfV7Bl0wYO1v+Fah4e2Lh1O9IfPsT+qL34fPxYrFjzLQfsJP9g3c/PD3fu3IG7u7ve+x88eKB31v2fIiIiMGnSJJ1j4z8Lx4TPJz5Xm72dPUxMTJCUlKRzPCUlGY6OTs91bkMSoVOERkCMThEaATE6ldh45eJ5PEhNwYgh/bTHNHl5+ON0HH7YFoll63YAAFJTkuHg9PeShwcPUmH/zGy7MSnxWipZxBu+6NiwMoIj9iMhteD7GkxNVFg5rAWqOlmh2xfR2ln1fL+cS0TjT3bBoYI5cjUSHmbm4NzcrohPMt6bjJ0qVoRHdd2BpIdHDRzYt9doDS8SMzNzVK36dCxUr34DnDv3BzZ8txYTwuXbZKOs8Nv30pF9zfo777yDatWqFXp/1apVsXr16iLPMW7cOKSlpencwsaMe+42M3NzeNWth8Oxv+scPxwbC++GPs99fkMRoVOERkCMThEaATE6ldjo3agpFn6zBfNXRWpvNevURatXO2H+qki4uFWBvYMTTh47pP2YnJwc/HHqOLzqN5SlGVDmtVSqGW/44jW/Kug284DewXX+QL26cwX0mPVLkevZUx5l42FmDgK8KqGitQV+Pnm7LNN1eDf0wY3r13SOxd+4DldXN6M1vNAkCdnZhb/29N8h+8x6t27dirzf3t4eoaGhRT5GrS645MVQu8EMCB2E8WM/Qd369eHt7YOtmyORkJCAXn36GuYJDESEThEaATE6RWgExOhUWmP58lao9sxspYWFJWxsbbXHu/buj03frYTbS+5wq1IVm75dAbXaEoGvBsmRrKW0a6lPZkYG4uPjtX++fesW/rxwAba2tnB1K/tB5swBfujR3B0D5v6GR09yUen/a8wfZubgSU4eTMqpsHp4C7zs7oB+X/8Kk3Iq7WNSH2UjJ+/pm0pfb+mBSwkPkfwwC409HTGtvy+W7L2IK4npZf7fkK//gDcxaODrWLV8CV7tEIQ/zp7Bti2bMF5hM8Fyv+YlMf/rOWgR8ApcXFyQkZGBPbt/wvFjR7FwyXK500gBZB+sF+fmzZsIDw/HqlWrZHn+jkGdkPYgFcsWL8L9+/fgWbMWFi5ZBje3yrL0FEaEThEaATE6RWgExOgUofFZPfu9ieysJ1j05XQ8evQQtb0aYMqcxShf3krWLhGu5blzf2DIoIHaP8+eGQEA6NK1G6ZMn1Hmzz+4bU0AwM5xuu/Ten/FEWw8eA1uDuUR5FsFABAzpaPOY7rOOIDf/7wHAPB0tcaEXi/D3socN5My8NUP57F4j3F3T6tXvwFmfzUfC+bOwfKli+BWuQo++mQcOnUu+n1mxib3a14SycnJmDDuEyTdv48K1taoWas2Fi5Zjmb+LeROKxtcB1Mq3GediKgM/dt91o3JUPusU+n3WZeDofZZL2tlsc+6oZXlPuuGpLR91g//9UDuBK1mNezkTiiW7DPrO3fuLPL+q1evGqmEiIiIiMpagd2sqEiyD9ZDQkIK3Wc9H7f9IiIiIqL/Itl3g3F1dcXWrVuh0Wj03uLi4uROJCIiIiKSheyDdT8/vyIH5MXNuhMRERGROFQq5dxEIPsymLCwMGRkFP5LHDw9PREdHW3EIiIiIiIiZZB9sB4QEFDk/VZWVggMDDRSDRERERGRcsg+WCciIiKi/w5BVp8ohuxr1omIiIiISD8O1omIiIiIFIrLYIiIiIjIeLgOplQ4s05EREREpFCcWSciIiIio1Fxar1UOLNORERERKRQHKwTERERESkUl8EQERERkdGouAqmVDizTkRERESkUBysExEREREpFJfBEBEREZHRcBVM6XBmnYiIiIhIoTizTkRERETGw6n1UlFJkiTJHVEWnuTKXUBERP81Go3y/0l19B8td0KJpB7+Su6EF4aFwqZm4248lDtBy9fdRu6EYnEZDBERERGRQinsey0iIiIiepGpuA6mVDizTkRERESkUBysExEREREpFAfrRERERGQ0KpVybv/GokWL4OHhAQsLC/j5+eG3334r9LHbtm3Dq6++iooVK8LGxgbNmzfHnj17SvV8HKwTEREREZVAZGQkRo4cifHjx+PkyZMICAhAUFAQ4uPj9T7+119/xauvvoqffvoJJ06cQOvWrREcHIyTJ0+W+Dm5dSMREZGBcOtGw+HWjYajtK0bT8Wny52g1bCqdake37RpU/j6+mLx4sXaY15eXggJCUFERESJzlGvXj306dMHn3/+eYkez5l1IiIiIjIalYJupZGdnY0TJ06gffv2Osfbt2+P2NjYEp1Do9EgPT0dDg4OJX5ehX2vRURERERkHFlZWcjKytI5plaroVarCzw2KSkJeXl5cHZ21jnu7OyMxMTEEj3fl19+iYyMDPTu3bvEjZxZJyIiIiLjkXs6/R+3iIgI2Nra6tyKW86ieuadqZIkFTimz4YNGzBx4kRERkaiUqVKxT4+H2fWiYiIiOg/ady4cRg9Wvd9HPpm1QHAyckJJiYmBWbR7927V2C2/VmRkZF46623sHnzZrRr165UjZxZJyIiIqL/JLVaDRsbG51bYYN1c3Nz+Pn5ISoqSud4VFQU/P39C32ODRs24M0338T69evRuXPnUjdyZp2IiIiIjEZV6rd2Ksfo0aMxYMAANGrUCM2bN8eyZcsQHx+Pd999F8DTmfrbt29j7dq1AJ4O1AcOHIi5c+eiWbNm2ll5S0tL2Nralug5OVgnIiIiIiqBPn36IDk5GZMnT0ZCQgLq16+Pn376Ce7u7gCAhIQEnT3Xly5ditzcXAwfPhzDhw/XHg8NDcWaNWtK9JzcZ52IiMhAuM+64XCfdcNR2j7rZ24+kjtB6+WXKsidUCyFvXxERERE9CIrwcYp9A98gykRERERkUJxsE5EREREpFAcrJdA5IZ1CGrfBo19GqBvr+6IO3Fc7iS9ROgUoREQo1OERkCMThEaATE6RWgElN25csVS9O/bEy2a+qJNoD9GfTgc169dNWpDC5/q2DJnCK7unojHx79CcGB9nfuXhb+Ox8e/0rnFrB5R6Pl2zH1b73mMRcmv9z+J0vm8FPC7kLQ3EShmsH7r1i08elTwDQc5OTn49ddfZSh66ufdP2HmjAgMffs9RG7ZAV9fPwx7ZygS7tyRrUkfETpFaATE6BShERCjU4RGQIxOERoB5XfGHT+GPn37Ye26SCxetgp5ebl4750heJyZabQGK0tznL18G6Nmbi30MXt+v4BqHT7X3kJGLNf7uA/6BUKCfG+8VfrrnU+UTjI+2QfrCQkJaNKkCdzd3WFnZ4fQ0FCdQXtKSgpat24tW9+336xGtx490L1nL1SvUQOfjBsPF1cXbIrcIFuTPiJ0itAIiNEpQiMgRqcIjYAYnSI0AsrvXLhkBbqEdEcNz5qoXbsOJk6JQGLCHZw/f85oDXtj/8SkxbvxffTZQh+TnZOLu8np2lvqw4LfTDSo6YYP+wXi3ckbyzK3SEp/vfOJ0mkQck+nCza1LvtgfezYsTAxMcGRI0fw888/4/z582jVqhVSU1O1j5Frd8mc7GxcOH8Ozf1b6hxv7t8Cp0+dlKVJHxE6RWgExOgUoREQo1OERkCMThEaAXE6/+nRo3QAKPEvUDGWAD9P3Ng7GWe2jsPC8b1R0V53CzxLtRm+mTYAo2Ztw93kdFkaRXm9Rekkeci+deO+ffuwfft2NGrUCAAQEBCAPn36oE2bNti/fz8AQCXTHj+pD1KRl5cHR0dHneOOjk5ISrovS5M+InSK0AiI0SlCIyBGpwiNgBidIjQC4nTmkyQJX86aAR9fP3jWrCV3jtbe2AvYtu804hNTUM3NEZ+/G4TdS4bB/40vkZ2TBwCY+VEIDp+5jl0xf8jWKcrrLUonyUP2wXpaWhrs7e21f1ar1diyZQt69eqF1q1b47vvviv2HFlZWcjKytI5JpmooVarDdL47DcLkiTJ9g1EUUToFKEREKNThEZAjE4RGgExOkVoBMTpnDFtCi5fuojV36yXO0XHlqhT2v9//q9ExJ2/iYu7PkNQy7r4PvosOr9SD60a1USz/rPli/wHUV5vUTqfl0qU9ScKIfsymOrVq+PMmTM6x0xNTbF582ZUr14dr732WrHniIiIgK2trc5t1hcRz91mb2cPExMTJCUl6RxPSUmGo6PTc5/fUEToFKEREKNThEZAjE4RGgExOkVoBMTpBIAZ06cg5pcDWL5yLZxdXOTOKVJi8kPEJ6TCs2pFAECrRjVRvYojEqOnI/3wbKQffjpo3zBzEPYsHV7UqQxKlNdblE6Sh+yD9aCgICxbtqzA8fwBe8OGDYtdsz5u3DikpaXp3MLGjHvuNjNzc3jVrYfDsb/rHD8cGwvvhj7PfX5DEaFThEZAjE4RGgExOkVoBMToFKEREKNTkiTMmDYZB/ZHYenKNahcpYrcScVysC2PKs52SEh6CACY/c1+NH59Fpr2n629AcAnc3bg7UnGe8OkCK83IE4nyUP2ZTDTpk1DZiHbUZmammLbtm24detWkedQqwsueXmSa5i+AaGDMH7sJ6hbvz68vX2wdXMkEhIS0KtPX8M8gYGI0ClCIyBGpwiNgBidIjQCYnSK0AgovzNi2mTs/mkXvpq7EFZWVto1yxUqWMPCwsIoDVaW5qjx0t8zutUqO+LlWm5ITctEysNMTHi7I3YcOI2EpIdwd3PA5GGdkfwgAzv/v3tM/g4xz7qZmIobd1KM8t+QT+mvdz5ROg3hBVzZU6ZkH6ybmprCxsam0Pvv3LmDSZMmYdWqVUas+lvHoE5Ie5CKZYsX4f79e/CsWQsLlyyDm1tlWXoKI0KnCI2AGJ0iNAJidIrQCIjRKUIjoPzOzf/fqm/o4IE6xydNmY4uId2N0uBb9yXsXfq+9s8zR4cAAL794Sg+nLEF9Txd0a9zI9hZWyIx6SFijl/BgE/X4lFmViFnlI/SX+98onSS8akkufZFLKHTp0/D19cXeXl5pfo4Q82sExERlZRGo+h/UgEAjv6j5U4okdTDX8md8MKwkH1qVtf5OxlyJ2jVdbOSO6FYsr98O3fuLPL+q1eN+yuWiYiIiKjscBVM6cg+WA8JCYFKpSryTaQv4rZFRERERETFkX03GFdXV2zduhUajUbvLS4uTu5EIiIiIjIUlYJuApB9sO7n51fkgLy4WXciIiIioheV7MtgwsLCkJFR+BsNPD09ER0dbcQiIiIiIiJlkH2wHhAQUOT9VlZWCAwMNFINEREREZUllSjrTxRC9mUwRERERESkHwfrREREREQKJfsyGCIiIiL67+CO3KXDmXUiIiIiIoXizDoRERERGQ0n1kuHM+tERERERArFwToRERERkUJxGQwRERERGQ/XwZQKZ9aJiIiIiBSKg3UiIiIiIoXiMhgiIiIiMhoV18GUCmfWiYiIiIgUioN1IiIiIiKF4jIYIiIiIjIaFVfBlIpKkiRJ7oiy8CRX7gIiIiAnVyN3QrHMTMX4IeuTnDy5E4plLsC1TE7PljuhRHw/2iF3QrFuLu8jd0KJWChsavbKvcdyJ2h5VrKUO6FYCnv5iIiIiOhFxon10lH+FAARERER0X8UB+tERERERArFZTBEREREZDxcB1MqnFknIiIiIlIoDtaJiIiIiBSKy2CIiIiIyGhUXAdTKpxZJyIiIiJSKA7WiYiIiIgUistgiIiIiMhoVFwFUyqcWSciIiIiUijOrBMRERGR0XBivXQ4s05EREREpFAcrBMRERERKRSXwRARERGR8XAdTKlwZp2IiIiISKE4WCciIiIiUigugyEiIiIio1FxHUypcGa9BCI3rENQ+zZo7NMAfXt1R9yJ43In6SVCpwiNgBidIjQCYnQqvTE4qC0aeXsVuH0xfbLcaQUo7VqePHEcH304DJ1fDUTThnURc2Cfzv2SJGH54gXo/GogXmnqg/feCsXVK5dlqn1q5fKl6N+nJ1o08UWbV/wx6sPhuH7tqqxN679ZgWGDX0dw22bo2SkQn48ZgZs3rhV43I3rV/FZ2Afo0s4fwW2b4f0h/XE3MaHMuprXqojvRrTE2TldcH91HwT5VNa5v6KNGvPfaoKzc7rgxpIeiBz9Cqo7V9B5TCUbCywc2hTnvu6C60t6YP/E9ghuVKXMmouitM8fUgZFDNaTk5MRHR2NlJQUAEBSUhK++OILTJ48GRcuXJC17efdP2HmjAgMffs9RG7ZAV9fPwx7ZygS7tyRtetZInSK0AiI0SlCIyBGpwiNa9dtxs/7f9XeFi5dCQBo+2pHmct0KfFaPn6ciZq1auPjsRP03v/tmpVY/903+HjsBKxetwkOTk744L0hyMjIMHLp3+KOH0Of1/th7fpILF62Cnm5uXjv7SF4nJkpW9OZk8fRtUdfzF/+Hb6Yuwx5uXkYM/JdPH78d9OdWzcx8p1QvOTugS8XrsTStVvwxqB3YG5uXmZd5dUmOHfzAcauO6H3/m8+aAn3ilYYMP8g2kzci5vJmdjycSuUNzfRPmbh203h6WKNN+YeROBnP+PHE7ew/L3maFDVrsy69VHi509ZUamUcxOBSpIkSc6Ao0ePon379nj48CHs7OwQFRWFXr16wdTUFJIk4fbt2zh48CB8fX1Ldd4nuYbp69+3F7zq1sWEzydpj4UEB6F1m3YYMeojwzyJAYjQKUIjIEanCI2AGJ1l3ZiTq3nuczzry5nT8duvMdj+w89QGeBfGzNTw8zblPW1fJKT91wf37RhXcycMw+BbdoBeDqr3vnVQPTtPxADBw0BAGRnZyOoTQCGjxyN7j37lPo5zA10Lf8pJSUFbV/xx4o138KvUePnPl9yevZzn+NBagp6dmqFOYtW4WWfRgCAqZ99AlNTU4wNn/7c5wcA3492lOrx91f3wcB5B7H75G0AQHXnCjgyozNajt+Ni3ceAgDKqVS4MK8rpmw+g+9+ffrTiuuLuyNs7QlsPnRDe66L80MwedNprPut4E8P/unm8tL/HSlMWX7+WChs0XN8SpbcCVpVHdRyJxRL9pn18ePHo1evXkhLS8Onn36KkJAQtG3bFpcuXcLly5fRr18/TJkyRZa2nOxsXDh/Ds39W+ocb+7fAqdPnZSlSR8ROkVoBMToFKEREKNThMZn5eRk46cff0CXkO4GGagbiojX8s7tW0hOSkLT5v7aY+bm5vBp1AhnT52SL+wZjx6lAwBsbW1lLvlbxqNHAABrm6dNGo0GR2J/RZWX3DFm5Lvo2SkQ77/VD7/HHJCtUW32dPY86x/f5GkkCTm5GjSt6aQ9duRyEkKaVIWdlTlUKiCkyUtQm5bD73/eM1qriJ8/ZDyyD9ZPnDiB0aNHw9raGiNGjMCdO3cwdOhQ7f3Dhw/HsWPHZGlLfZCKvLw8ODo66hx3dHRCUtJ9WZr0EaFThEZAjE4RGgExOkVofNYvB/bjUXo6grt0kztFh4jXMjkpCQDg4OCkc9zBwQnJyUlyJBUgSRK+nDkDPr5+8KxZS+4cAE+blsybhfrePvCoURPA05n2x5mZ2PjtSjRu2gIzvl6KFoFtMXHcKJyOk2fd9eWEh4hPysCEni/DtrwZzEzK4cNOdeBsZwlnOwvt44YsPgRTExUuL+iG28t64cvQRgid/zuu3zfeUigRP3+eh0pBNxHI/oOR7OxsWFpaAgDMzMxQvnx5ODn9/YXT0dERycnJRZ4jKysLWVm6P1KRTNRQqw3zo41nZ68kSVLUjFY+ETpFaATE6BShERCjU4TGfN9v3wr/FgGoWKmS3Cl6iXQt8xXoU1DzjGlTcPnSRaxeu17uFK35s6fj6pXL+HrpGu0xjebpcq/mAa3R8/UBAADPWnVw/uwp7NqxCd6+jYzemZsnYdCC3zF3cGNcWdgduXka/Hr+Lvad0V0D/mn3BrAtb47uM6OR8igbQb6VsXK4P4IjDuDCrTSjNov4+UNlT/aZ9ZdeeglXr/79LveNGzfC1dVV++eEhASdwbs+ERERsLW11bnN+iLiudvs7exhYmKCpCTdGZaUlGQ4OhbdZEwidIrQCIjRKUIjIEanCI3/lHDnNo4eOYSu3XvKnVKAaNcSABz//29LcrLuzGVKajIcHBz1fYhRzZg+BTHRB7B81Vo4u7jInQMAmP9lBA4d/AWzF65AxUp/N9na2cPExBTuHjV0Hl+1WnXcS0w0dqbWmRupaB2+F9WHbUP9UTvRZ86vsLdSI/7/s+bVKlphSLuaGLHqKH67cA/nbj7A7O/P4dS1FAxu42m0ThE/f8h4ZB+s9+3bF/fu/b0urHPnztqZdgDYuXMnmjRpUuQ5xo0bh7S0NJ1b2Jhxz91mZm4Or7r1cDj2d53jh2Nj4d3Q57nPbygidIrQCIjRKUIjIEanCI3/tPP77bB3cEDLgEC5UwoQ7VoCgFvlKnB0csLRQ4e0x3JysnHy+HE0aNhQti5JkjBj2mQc2BeFpavWoHIVebYRfLZp/uzpOPjLfsxasAKubrpNZmZmqO1VD7fir+scvxV/A5VcXCG39Mc5SE7PQnXnCmjoYa99E6ql+ukCA80ze21oJAnljDijLeLnz/OQewcY0XaDkX0ZTHh4eJH3jx8/HiYmJkU+Rq0uuOTFULvBDAgdhPFjP0Hd+vXh7e2DrZsjkZCQgF59+hrmCQxEhE4RGgExOkVoBMToFKEReLrM4Ifvt+G14BCYmsr+pVsvJV7LzMwM3IqP1/75zu3buPTnBdjY2sLF1Q19+w/EmpXL8JK7O16q6o41K5bBwtICHYJek605Yupk7P5pF76atxBWVlbaNcsVKljDwsKimI8uG/NmT8OBvbsx+Yu5KF/eCin/X9NvZVUB6v839e7/JqZ+FoYGDX3R0LcJjh3+HYd+j8GXC1eWWZeV2hQelf7eN71qRSvUf8kOqRnZuJ2SiS6NqiApPQu3UzLhVcUW0/r5Ynfcbfxy7i6Ap+var95Nx5ehjRAeeRqpj7IQ5FsFgXVd0H/ub2XWrY8SP39IGWTfurE4N2/eRHh4OFatWlWqjzPUYB14+ksK1qxaifv378GzZi2EjRlnkO2zDE2EThEaATE6RWgExOgsy0ZDbd14OPZ3vP/eEGz9/ie4V/MwyDnzGWrrRqBsr+W/2brxxLGjGDb0zQLHOweH4PMp0yFJElYsWYjtWzch/eFD1GvwMsLGfYYanjX/VaMhtm70qV9H7/FJU6ejS0j35z7/v9m6sV3zl/UeD5swBR06d9X+efcP27Fx7Urcv3cXL7lXw8Ahw9Dildb/qrMkWzf6166I78e2KXB848Fr+GDlUQxtVxPDg+qgoo0adx88wabY6/hy53nk5P39eVnduQI+6/kymtSsCCsLU1y7+wiLfv5TZyvHwhhy60ag7D5/lLZ1461U5WzdWMVe+Vs3Kn6wfvr0afj6+iIvr3RfpA05WCci+rfKYp91QzPkYL0sPe8+68ZQFvusG5oh9lk3htLusy4HQw/Wy4ryBuvK+TtYxb7sfmmXocj+8u3cubPI+//55lMiIiIiov8S2QfrISEhUKlUKGqCn9sWEREREb0YOKwrHdl/Xufq6oqtW7dCo9HovcXFxcmdSEREREQkC9kH635+fkUOyIubdSciIiIielHJvgwmLCwMGRmF/0pfT09PREdHG7GIiIiIiMoKV8GUjuyD9YCAgCLvt7KyQmCg8n4BCBERERFRWZN9GQwREREREekn+8w6EREREf13cDeY0uHMOhERERGRQnGwTkRERESkUFwGQ0RERERGo+J+MKXCmXUiIiIiIoXizDoRERERGQ8n1kuFM+tERERERArFwToRERERkUJxGQwRERERGQ1XwZQOZ9aJiIiIiBSKg3UiIiIiIoXiMhgiIiIiMhoV18GUCmfWiYiIiIgUSiVJkiR3RFl4kit3ARERoNEo/0tsuXKc5jKUBxk5cicUy87KTO6EF4Z913lyJ5TI4x8/lDtBx7105XyeVLJW/ucDl8EQERERkdGouB9MqXAZDBERERGRQnFmnYiIiIiMhxPrpcKZdSIiIiIiheJgnYiIiIhIobgMhoiIiIiMhqtgSocz60RERERECsXBOhERERGRQnEZDBEREREZjYrrYEqFM+tERERERArFmXUiIiIiMhr+BtPS4cw6EREREZFCcbBORERERKRQXAZDREREREbDN5iWDmfWiYiIiIgUioN1IiIiIiKF4mCdiIiIiEihOFgnIiIiIlIoDtZLIHLDOgS1b4PGPg3Qt1d3xJ04LneSXiJ0itAIiNEpQiMgRqfSG08cP4YR77+LV9sEwKdBHUTv3yd3UqGUfi3zKb3z/r27mPr5GAS3a4H2AY3wVv8euHjhnNxZein9WgLKa3RztMKqj9vj1oahSN76Hg7Pfx0+nhW194/v1xSnlryBpK3v4U7k2/hxWgga13aWsZjkpNjBevXq1XH58mW5M/Dz7p8wc0YEhr79HiK37ICvrx+GvTMUCXfuyJ2mQ4ROERoBMTpFaATE6BSh8fHjx6hVqw7GfvqZ3ClFEuFaAsrvTH+YhveHDoCJqRlmzl2CbyK/x7ARYahgbS13WgFKv5aA8hrtKqhxYFYv5ORqEBK+Ez7vfYexK37Dg0fZ2sdcuZ2KUUti0Gj4OrQN24Ibd9Pxw5QQONlYytJsaCqVcm4iUEmSJMkZMG/ePL3HR48ejU8++QQuLi4AgA8//LBU532S+9xpAID+fXvBq25dTPh8kvZYSHAQWrdphxGjPjLMkxiACJ0iNAJidIrQCIjRWdaNGo1hv8T6NKiDOV8vQOu27Qx2znLlDPMvlgivN1C2nQ8ycp43D0sXfIWzp09iwfK1z30ufeyszAx2LhFe87JstO+qfwxTlClv+qO5lyvajdla4o+xtjTHvS3vIujTbfjl9K1SP+fjH0s3hiprDx7nyZ2gZWdpIndCsWTfZ33kyJGoXLkyTE11UzQaDdauXQszMzOoVKpSD9YNISc7GxfOn8PgIW/rHG/u3wKnT500ek9hROgUoREQo1OERkCMThEaRSHKtRSh8/ffotGkaQt8PnY0Tp88DqeKlRDSsy+CQ3rKnaZDhGupxMbOTatjX9wNrBsXhJb1K+NOcgaW/XgGq/foX+ZkZloObwXVw4NHWTh7LcnItWVDBUGmtBVC9sH60KFDcfToUaxfvx5eXl7a42ZmZti7dy/q1q0rW1vqg1Tk5eXB0dFR57ijoxOSku7LVFWQCJ0iNAJidIrQCIjRKUKjKES5liJ0Jty+he+3RaJXv4F4Y9BQ/HnuLOZ9GQEzMzN07NxV7jwtEa6lEhs9XGwwtFMDzNt+EjMjj6NRLWd8+U4gsnLysP7An9rHBTWuhrVjOqK82gyJKRl4bcJ2JD98IkszyUv2wfrSpUuxY8cOdOjQAZ988gnef//9Up8jKysLWVlZOsckEzXUarVBGlXPLGqSJKnAMSUQoVOERkCMThEaATE6RWgUhSjXUsmdGo0Gtb3q4e1hIwEAtWp74drVK/h+6yZFDdbzKfla5lNSYzmVCnFX7iF87SEAwOmr91HX3QFvd2qgM1iPOXMLTT/YACcbSwzqWA/fjQ3CK6M34X7aY1m6ST6KeINpSEgIDh06hO3btyMoKAiJiYml+viIiAjY2trq3GZ9EfHcXfZ29jAxMUFSku6PnVJSkuHo6PTc5zcUETpFaATE6BShERCjU4RGUYhyLUXodHSqiGoeNXSOuVerjnt3E2Qq0k+Ea6nExsTUDFyIT9E59ufNVLxUUfcNxJlZubiakIajFxPx3tz9yM2TENq+njFTy4zcbyoV7Q2mihisA0DlypWxb98+vPLKK/Dx8UFp3vc6btw4pKWl6dzCxox77iYzc3N41a2Hw7G/6xw/HBsL74Y+z31+QxGhU4RGQIxOERoBMTpFaBSFKNdShM76L/sg/sZ1nWO34m/A2cVVnqBCiHAtldh46HwCalW20zlWs7Id4u+nF/lxKhWgNlP+myHJ8GRfBvNPKpUK48aNQ/v27XHw4EG4upbsC5NaXXDJi6F2gxkQOgjjx36CuvXrw9vbB1s3RyIhIQG9+vQ1zBMYiAidIjQCYnSK0AiI0SlCY2ZmBm7Gx2v/fPv2LVz88wJsbG3h6uomY5kuEa4loPzOXv0GYPhbA/Dt6mVo3a4jLpw7ix92bMHHn4bLnVaA0q8loLzG+TtOInp2L4T1boStv11G41rOGNyxPt6ffwAAUF5tijF9GuPHI9eQmJIBBxsLvN35ZVR2qoBtB+Xf0pqMT1GD9Xx+fn7w8/MDANy8eRPh4eFYtWqVLC0dgzoh7UEqli1ehPv378GzZi0sXLIMbm6VZekpjAidIjQCYnSK0AiI0SlC4/lzf2Do4FDtn7+cNQMAENwlBJOnzZArqwARriWg/E6vug0wdebXWLZoLtauXAIXt8p4f/QYvNrxNbnTClD6tQSU13ji8j30mfojJr/pj09fb4Lrdx8ibNmv2PjLRQBAnkZC7Zfs8UZbLzjaWiLl4WMcv3wP7T7ZUmD5jKgEWX2iGLLvs16c06dPw9fXF3l5pduT01Az60REz8PQ+6yXBUPts06G2We9rBlyn/X/un+zz7oclLbPevoTjdwJWtYWilkRXijZZ9Z37txZ5P1Xr141UgkRERERkbLIPlgPCQmBSqUq8g2lStsCioiIiIj+JQ7rSkX2uX9XV1ds3boVGo1G7y0uLk7uRCIiIiIiWcg+WPfz8ytyQF7crDsRERERiUOloP+JQPZlMGFhYcjIyCj0fk9PT0RHRxuxiIiIiIhIGWQfrAcEBBR5v5WVFQIDA41UQ0RERESkHLIP1omIiIjov4P7hpSO7GvWiYiIiIhIPw7WiYiIiIgUistgiIiIiMhouAqmdDizTkRERESkUBysExEREREpFJfBEBEREZHxcB1MqXBmnYiIiIhIoTizTkRERERGo+LUeqlwZp2IiIiIqIQWLVoEDw8PWFhYwM/PD7/99luRj4+JiYGfnx8sLCxQvXp1LFmypFTPx8E6EREREVEJREZGYuTIkRg/fjxOnjyJgIAABAUFIT4+Xu/jr127hk6dOiEgIAAnT57Ep59+ig8//BBbt24t8XOqJEmSDPUfoCRPcuUuICICNBrlf4ktV44/kjaUBxk5cicUy87KTO6EF4Z913lyJ5TI4x8/lDtBh5LGaBalXBDetGlT+Pr6YvHixdpjXl5eCAkJQURERIHHjxkzBjt37sSFCxe0x959912cPn0ahw4dKtFzcmadiIiIiKgY2dnZOHHiBNq3b69zvH379oiNjdX7MYcOHSrw+A4dOuD48ePIySnZN/d8gykRERER/SdlZWUhKytL55harYZarS7w2KSkJOTl5cHZ2VnnuLOzMxITE/WePzExUe/jc3NzkZSUBFdX1+IjJSqRJ0+eSOHh4dKTJ0/kTimUCI2SJEanCI2SJEanCI2SJEanCI2SJEanCI2SJEanCI2SJEanCI0vmvDwcAmAzi08PFzvY2/fvi0BkGJjY3WOT506Vapdu7bej6lZs6Y0ffp0nWMHDx6UAEgJCQklanxh16wb2sOHD2Fra4u0tDTY2NjInaOXCI2AGJ0iNAJidIrQCIjRKUIjIEanCI2AGJ0iNAJidIrQ+KIpzcx6dnY2ypcvj82bN6Nbt27a4yNGjMCpU6cQExNT4GNeeeUV+Pj4YO7cudpj27dvR+/evZGZmQkzs+LfQ8I160RERET0n6RWq2FjY6Nz0zdQBwBzc3P4+fkhKipK53hUVBT8/f31fkzz5s0LPH7v3r1o1KhRiQbqAAfrREREREQlMnr0aKxYsQKrVq3ChQsXMGrUKMTHx+Pdd98FAIwbNw4DBw7UPv7dd9/FjRs3MHr0aFy4cAGrVq3CypUr8fHHH5f4OfkGUyIiIiKiEujTpw+Sk5MxefJkJCQkoH79+vjpp5/g7u4OAEhISNDZc93DwwM//fQTRo0ahYULF8LNzQ3z5s1Djx49SvycHKyXkFqtRnh4eKE/GlECERoBMTpFaATE6BShERCjU4RGQIxOERoBMTpFaATE6BShkYBhw4Zh2LBheu9bs2ZNgWOBgYGIi4v718/HN5gSERERESkU16wTERERESkUB+tERERERArFwToRERERkUJxsF6MX3/9FcHBwXBzc4NKpcKOHTvkTiogIiICjRs3hrW1NSpVqoSQkBBcvHhR7qwCFi9ejJdfflm7j2nz5s2xe/duubOKFBERAZVKhZEjR8qdomPixIlQqVQ6NxcXF7mzCrh9+zbeeOMNODo6onz58mjYsCFOnDghd5aOatWqFbiWKpUKw4cPlztNKzc3FxMmTICHhwcsLS1RvXp1TJ48GRqNRu40Henp6Rg5ciTc3d1haWkJf39/HDt2TNam4r6GS5KEiRMnws3NDZaWlmjVqhXOnTunqMZt27ahQ4cOcHJygkqlwqlTp4zaV5LOnJwcjBkzBg0aNICVlRXc3NwwcOBA3LlzRzGNwNOvnXXq1IGVlRXs7e3Rrl07HDlyxKiNJen8p3feeQcqlQpff/210fpIWThYL0ZGRga8vb2xYMECuVMKFRMTg+HDh+Pw4cOIiopCbm4u2rdvj4yMDLnTdFSpUgUzZszA8ePHcfz4cbRp0wZdu3Y1+j+MJXXs2DEsW7YML7/8stwpetWrVw8JCQna29mzZ+VO0pGamooWLVrAzMwMu3fvxvnz5/Hll1/Czs5O7jQdx44d07mO+b+8olevXjKX/e2LL77AkiVLsGDBAly4cAEzZ87ErFmzMH/+fLnTdAwZMgRRUVH49ttvcfbsWbRv3x7t2rXD7du3ZWsq7mv4zJkzMWfOHCxYsADHjh2Di4sLXn31VaSnpyumMSMjAy1atMCMGTOM1lRYR2GdmZmZiIuLw2effYa4uDhs27YNly5dQpcuXRTTCAC1atXCggULcPbsWRw8eBDVqlVD+/btcf/+fUV15tuxYweOHDkCNzc3I5WRIklUYgCk7du3y51RrHv37kkApJiYGLlTimVvby+tWLFC7owC0tPTpZo1a0pRUVFSYGCgNGLECLmTdISHh0ve3t5yZxRpzJgxUsuWLeXOKLURI0ZINWrUkDQajdwpWp07d5YGDx6sc6x79+7SG2+8IVNRQZmZmZKJiYm0a9cunePe3t7S+PHjZarS9ezXcI1GI7m4uEgzZszQHnvy5Ilka2srLVmyRIbCov+duXbtmgRAOnnypFGb9CnJv4dHjx6VAEg3btwwTtQzStKYlpYmAZD27dtnnCg9Cuu8deuWVLlyZemPP/6Q3N3dpa+++srobaQMnFl/AaWlpQEAHBwcZC4pXF5eHjZu3IiMjAw0b95c7pwChg8fjs6dO6Ndu3ZypxTq8uXLcHNzg4eHB/r27YurV6/KnaRj586daNSoEXr16oVKlSrBx8cHy5cvlzurSNnZ2fjuu+8wePBgqFQquXO0WrZsif379+PSpUsAgNOnT+PgwYPo1KmTzGV/y83NRV5eHiwsLHSOW1pa4uDBgzJVFe3atWtITExE+/bttcfUajUCAwMRGxsrY9mLIS0tDSqVSnE/TcuXnZ2NZcuWwdbWFt7e3nLn6NBoNBgwYADCwsJQr149uXNIZvylSC8YSZIwevRotGzZEvXr15c7p4CzZ8+iefPmePLkCSpUqIDt27ejbt26cmfp2LhxI+Li4mRfa1uUpk2bYu3atahVqxbu3r2LqVOnwt/fH+fOnYOjo6PceQCAq1evYvHixRg9ejQ+/fRTHD16FB9++CHUarXOr2JWkh07duDBgwd488035U7RMWbMGKSlpaFOnTowMTFBXl4epk2bhtdff13uNC1ra2s0b94cU6ZMgZeXF5ydnbFhwwYcOXIENWvWlDtPr8TERACAs7OzznFnZ2fcuHFDjqQXxpMnTzB27Fj069cPNjY2cufo2LVrF/r27YvMzEy4uroiKioKTk5Ocmfp+OKLL2BqaooPP/xQ7hRSAA7WXzDvv/8+zpw5o9iZrNq1a+PUqVN48OABtm7ditDQUMTExChmwH7z5k2MGDECe/fuLTBDqCRBQUHa/9+gQQM0b94cNWrUwDfffIPRo0fLWPY3jUaDRo0aYfr06QAAHx8fnDt3DosXL1bsYH3lypUICgpS3PrQyMhIfPfdd1i/fj3q1auHU6dOYeTIkXBzc0NoaKjceVrffvstBg8ejMqVK8PExAS+vr7o16/fc/3mPmN49qcokiQp6icrosnJyUHfvn2h0WiwaNEiuXMKaN26NU6dOoWkpCQsX74cvXv3xpEjR1CpUiW50wAAJ06cwNy5cxEXF8e/hwSAbzB9oXzwwQfYuXMnoqOjUaVKFblz9DI3N4enpycaNWqEiIgIeHt7Y+7cuXJnaZ04cQL37t2Dn58fTE1NYWpqipiYGMybNw+mpqbIy8uTO1EvKysrNGjQAJcvX5Y7RcvV1bXAN2FeXl6Ij4+XqahoN27cwL59+zBkyBC5UwoICwvD2LFj0bdvXzRo0AADBgzAqFGjEBERIXeajho1aiAmJgaPHj3CzZs3cfToUeTk5MDDw0PuNL3yd1DKn2HPd+/evQKz7VQyOTk56N27N65du4aoqCjFzaoDT79eenp6olmzZli5ciVMTU2xcuVKubO0fvvtN9y7dw9Vq1bV/jt048YNfPTRR6hWrZrceSQDDtZfAJIk4f3338e2bdtw4MABxf7DqI8kScjKypI7Q6tt27Y4e/YsTp06pb01atQI/fv3x6lTp2BiYiJ3ol5ZWVm4cOECXF1d5U7RatGiRYEtRC9dugR3d3eZioq2evVqVKpUCZ07d5Y7pYDMzEyUK6f75drExERxWzfms7KygqurK1JTU7Fnzx507dpV7iS9PDw84OLiot0BCHi6jjkmJgb+/v4ylokpf6B++fJl7Nu3TzFL8oqjtH+HBgwYgDNnzuj8O+Tm5oawsDDs2bNH7jySAZfBFOPRo0e4cuWK9s/Xrl3DqVOn4ODggKpVq8pY9rfhw4dj/fr1+P7772Ftba2dJbK1tYWlpaXMdX/79NNPERQUhJdeegnp6enYuHEjfvnlF/z8889yp2lZW1sXWOtvZWUFR0dHRb0H4OOPP0ZwcDCqVq2Ke/fuYerUqXj48KGilkSMGjUK/v7+mD59Onr37o2jR49i2bJlWLZsmdxpBWg0GqxevRqhoaEwNVXel8Xg4GBMmzYNVatWRb169XDy5EnMmTMHgwcPljtNx549eyBJEmrXro0rV64gLCwMtWvXxqBBg2RrKu5r+MiRIzF9+nTUrFkTNWvWxPTp01G+fHn069dPMY0pKSmIj4/X7lme/02wi4uLUX+/QlGdbm5u6NmzJ+Li4rBr1y7k5eVp/y1ycHCAubm57I2Ojo6YNm0aunTpAldXVyQnJ2PRokW4deuW0bdqLe41f/YbHTMzM7i4uKB27dpG7SSFkHMrGhFER0dLAArcQkND5U7T0tcHQFq9erXcaToGDx4subu7S+bm5lLFihWltm3bSnv37pU7q1hK3LqxT58+kqurq2RmZia5ublJ3bt3l86dOyd3VgE//PCDVL9+fUmtVkt16tSRli1bJneSXnv27JEASBcvXpQ7Ra+HDx9KI0aMkKpWrSpZWFhI1atXl8aPHy9lZWXJnaYjMjJSql69umRubi65uLhIw4cPlx48eCBrU3FfwzUajRQeHi65uLhIarVaeuWVV6SzZ88qqnH16tV67w8PD1dMZ/62kvpu0dHRimh8/Pix1K1bN8nNzU0yNzeXXF1dpS5dukhHjx41Wl9JOvXh1o3/bSpJkiTDfwtARERERETPi2vWiYiIiIgUioN1IiIiIiKF4mCdiIiIiEihOFgnIiIiIlIoDtaJiIiIiBSKg3UiIiIiIoXiYJ2IiIiISKE4WCciIiIiUigO1omoTK1ZswYqlUp7MzU1RZUqVTBo0CDcvn3bKA3VqlXDm2++qf3zL7/8ApVKhV9++aVU54mNjcXEiRPx4MEDg/YBwJtvvolq1aoV+7hWrVqhfv36BnnO/Nfm+PHjBjnfP895/fp1g52TiOi/jIN1IjKK1atX49ChQ4iKisLQoUOxYcMGBAQEICMjw+gtvr6+OHToEHx9fUv1cbGxsZg0aVKZDNaJiIj0MZU7gIj+G+rXr49GjRoBAFq3bo28vDxMmTIFO3bsQP/+/fV+TGZmJsqXL2/wFhsbGzRr1szg5yUiIjI0zqwTkSzyB8s3btwA8HQZSIUKFXD27Fm0b98e1tbWaNu2LQAgOzsbU6dORZ06daBWq1GxYkUMGjQI9+/f1zlnTk4OPvnkE7i4uKB8+fJo2bIljh49WuC5C1sGc+TIEQQHB8PR0REWFhaoUaMGRo4cCQCYOHEiwsLCAAAeHh7aZT3/PEdkZCSaN28OKysrVKhQAR06dMDJkycLPP+aNWtQu3ZtqNVqeHl5Ye3atf/qGhbm+PHj6Nu3L6pVqwZLS0tUq1YNr7/+uvZaPys1NRWDBg2Cg4MDrKysEBwcjKtXrxZ43L59+9C2bVvY2NigfPnyaNGiBfbv32/QdiIi0sXBOhHJ4sqVKwCAihUrao9lZ2ejS5cuaNOmDb7//ntMmjQJGo0GXbt2xYwZM9CvXz/8+OOPmDFjBqKiotCqVSs8fvxY+/FDhw7F7NmzMXDgQHz//ffo0aMHunfvjtTU1GJ79uzZg4CAAMTHx2POnDnYvXs3JkyYgLt37wIAhgwZgg8++AAAsG3bNhw6dEhnKc306dPx+uuvo27duti0aRO+/fZbpKenIyAgAOfPn9c+z5o1azBo0CB4eXlh69atmDBhAqZMmYIDBw48/0X9v+vXr6N27dr4+uuvsWfPHnzxxRdISEhA48aNkZSUVODxb731FsqVK4f169fj66+/xtGjR9GqVSud5T7fffcd2rdvDxsbG3zzzTfYtGkTHBwc0KFDBw7YiYjKkkREVIZWr14tAZAOHz4s5eTkSOnp6dKuXbukihUrStbW1lJiYqIkSZIUGhoqAZBWrVql8/EbNmyQAEhbt27VOX7s2DEJgLRo0SJJkiTpwoULEgBp1KhROo9bt26dBEAKDQ3VHouOjpYASNHR0dpjNWrUkGrUqCE9fvy40P+WWbNmSQCka9eu6RyPj4+XTE1NpQ8++EDneHp6uuTi4iL17t1bkiRJysvLk9zc3CRfX19Jo9FoH3f9+nXJzMxMcnd3L/S58wUGBkr16tUr9nH/lJubKz169EiysrKS5s6dqz2e/9p069ZN5/G///67BECaOnWqJEmSlJGRITk4OEjBwcE6j8vLy5O8vb2lJk2aFDjns9eIiIj+Hc6sE5FRNGvWDGZmZrC2tsZrr70GFxcX7N69G87OzjqP69Gjh86fd+3aBTs7OwQHByM3N1d7a9iwIVxcXLTLUKKjowGgwPr33r17w9S06LfnXLp0CX/99RfeeustWFhYlPq/bc+ePcjNzcXAgQN1Gi0sLBAYGKhtvHjxIu7cuYN+/fpBpVJpP97d3R3+/v6lft7CPHr0CGPGjIGnpydMTU1hamqKChUqICMjAxcuXCjw+Gevmb+/P9zd3bXXNDY2FikpKQgNDdX579NoNOjYsSOOHTsmyxuFiYj+C/gGUyIyirVr18LLywumpqZwdnaGq6trgceUL18eNjY2Osfu3r2LBw8ewNzcXO9585d1JCcnAwBcXFx07jc1NYWjo2ORbflr36tUqVKy/5hn5C+Vady4sd77y5UrV2Rj/jFDbXfYr18/7N+/H5999hkaN24MGxsbqFQqdOrUSWfZ0D+fW9+x/N78/76ePXsW+pwpKSmwsrIySD8REf2Ng3UiMgovLy/tbjCF+edscz4nJyc4Ojri559/1vsx1tbWAKAdkCcmJqJy5cra+3Nzc7WDzsLkr5u/detWkY8rjJOTEwBgy5YtcHd3L/Rx/2x8lr5j/0ZaWhp27dqF8PBwjB07Vns8KysLKSkpej+msB5PT08Af//3zZ8/v9BddJ79CQkRERkGB+tEpGivvfYaNm7ciLy8PDRt2rTQx7Vq1QoAsG7dOvj5+WmPb9q0Cbm5uUU+R61atVCjRg2sWrUKo0ePhlqt1vu4/OPPzk536NABpqam+Ouvvwos4/mn2rVrw9XVFRs2bMDo0aO135zcuHEDsbGxcHNzK7KzJFQqFSRJKvDfsGLFCuTl5en9mHXr1ul0x8bG4saNGxgyZAgAoEWLFrCzs8P58+fx/vvvP3cjERGVHAfrRKRoffv2xbp169CpUyeMGDECTZo0gZmZGW7duoXo6Gh07doV3bp1g5eXF9544w18/fXXMDMzQ7t27fDHH39g9uzZBZbW6LNw4UIEBwejWbNmGDVqFKpWrYr4+Hjs2bMH69atAwA0aNAAADB37lyEhobCzMwMtWvXRrVq1TB58mSMHz8eV69eRceOHWFvb4+7d+/i6NGjsLKywqRJk1CuXDlMmTIFQ4YMQbdu3TB06FA8ePAAEydO1LsUpTAPHz7Eli1bChyvWLEiAgMD8corr2DWrFlwcnJCtWrVEBMTg5UrV8LOzk7v+Y4fP44hQ4agV69euHnzJsaPH4/KlStj2LBhAIAKFSpg/vz5CA0NRUpKCnr27IlKlSrh/v37OH36NO7fv4/FixeXuJ+IiEpB7ne4EtGLLX93kGPHjhX5uNDQUMnKykrvfTk5OdLs2bMlb29vycLCQqpQoYJUp04d6Z133pEuX76sfVxWVpb00UcfSZUqVZIsLCykZs2aSYcOHZLc3d2L3Q1GkiTp0KFDUlBQkGRrayup1WqpRo0aBXaXGTdunOTm5iaVK1euwDl27NghtW7dWrKxsZHUarXk7u4u9ezZU9q3b5/OOVasWCHVrFlTMjc3l2rVqiWtWrVKCg0NLfFuMAD03gIDAyVJkqRbt25JPXr0kOzt7SVra2upY8eO0h9//FHgOuS/Nnv37pUGDBgg2dnZSZaWllKnTp10rmu+mJgYqXPnzpKDg4NkZmYmVa5cWercubO0efPmAufkbjBERIahkiRJkun7BCIiIiIiKgK3biQiIiIiUigO1omIiIiIFIqDdSIiIiIiheJgnYiIiIhIoThYJyIiIiJSKA7WiYiIiIgUioN1IiIiIiKF4mCdiIiIiEihOFgnIiIiIlIoDtaJiIiIiBSKg3UiIiIiIoXiYJ2IiIiISKH+B9tIdmxh1+ZtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 78.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 51.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 86.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 85.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 87.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 87.44%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:03:30.617416Z",
     "iopub.status.busy": "2025-05-08T19:03:30.617416Z",
     "iopub.status.idle": "2025-05-08T19:03:30.625614Z",
     "shell.execute_reply": "2025-05-08T19:03:30.625614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.65\n",
      "1    LRM (CAE)          78.40\n",
      "2    MLP (CAE)          51.55\n",
      "3     TSCL LRM          86.23\n",
      "4     TSCL MLP          85.89\n",
      "5  SCL_SDL LRM          87.09\n",
      "6  SCL_SDL MLP          87.44\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.65\n",
      "6  SCL_SDL MLP          87.44\n",
      "5  SCL_SDL LRM          87.09\n",
      "3     TSCL LRM          86.23\n",
      "4     TSCL MLP          85.89\n",
      "1    LRM (CAE)          78.40\n",
      "2    MLP (CAE)          51.55\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
